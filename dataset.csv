id,name,formal_theorem,informal_theorem,formal_proof,informal_proof,commented_proof,header
125,List.erase_replicate_ne,"theorem List.erase_replicate_ne [LawfulBEq α] {a b : α} (h : !b == a) :
    (replicate n a).erase b = replicate n a := by sorry","Erasing a Non-Equal Element from a Replicated List Preserves the List : For any type $\alpha$ with a `BEq` instance, any natural number $n$, and any elements $a, b \in \alpha$, if $b \neq a$, then erasing $b$ from the list containing $n$ copies of $a$ results in the original list, i.e., $\text{erase}(b, \text{replicate}(n, a)) = \text{replicate}(n, a)$.","theorem List.erase_replicate_ne [LawfulBEq α] {a b : α} (h : !b == a) :
    (replicate n a).erase b = replicate n a := by
  rw [erase_of_not_mem]
  simp_all","To prove the theorem, we start by noting that the list \(\text{replicate}(n, a)\) consists of \(n\) copies of the element \(a\). Given the hypothesis \(b \neq a\), we need to show that erasing \(b\) from \(\text{replicate}(n, a)\) results in the original list \(\text{replicate}(n, a)\).

1. **Step 1:**
Since the theorem states that erasing an element from a list leaves the list unchanged if the element is not in the list, we can replace the goal of showing \((\text{replicate}(n, a)).\text{erase}(b) = \text{replicate}(n, a)\) with showing that \(b \notin \text{replicate}(n, a)\).

2. **Step 2:**
Using the fact that \(b \neq a\) (which is given by the hypothesis \(h : (!b == a) = \text{true}\)), we can simplify the expression to show that \(b\) is not a member of the list \(\text{replicate}(n, a)\). This is trivial because the list \(\text{replicate}(n, a)\) contains only the element \(a\), and \(b \neq a\).

Therefore, since \(b \notin \text{replicate}(n, a)\), erasing \(b\) from \(\text{replicate}(n, a)\) results in the original list \(\text{replicate}(n, a)\). This completes the proof. \(\blacksquare\)","theorem List.erase_replicate_ne [LawfulBEq α] {a b : α} (h : !b == a) :
    (replicate n a).erase b = replicate n a := by
/- Since the theorem states that erasing an element from a list leaves the list unchanged if the element is not in the list, we can replace the goal of showing \((\text{replicate}(n, a)).\text{erase}(b) = \text{replicate}(n, a)\) with showing that \(b \notin \text{replicate}(n, a)\). -/
  rw [erase_of_not_mem]
/- Using the fact that \(b \neq a\) (which is given by the hypothesis \(h : (!b == a) = \text{true}\)), we can simplify the expression to show that \(b\) is not a member of the list \(\text{replicate}(n, a)\). This is trivial because the list \(\text{replicate}(n, a)\) contains only the element \(a\), and \(b \neq a\). -/
  simp_all","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
133,List.Nodup.mem_erase_iff,theorem List.Nodup.mem_erase_iff [LawfulBEq α] {a : α} (d : Nodup l) : a ∈ l.erase b ↔ a ≠ b ∧ a ∈ l := by sorry,"Membership in List After Erasing an Element: \( a \in l \setminus \{b\} \leftrightarrow a \neq b \land a \in l \) : For any list \( l \) of elements of type \( \alpha \) and any elements \( a \) and \( b \) of type \( \alpha \), if \( l \) contains no duplicate elements, then \( a \) is a member of the list obtained by erasing the first occurrence of \( b \) from \( l \) if and only if \( a \neq b \) and \( a \in l \).","theorem List.Nodup.mem_erase_iff [LawfulBEq α] {a : α} (d : Nodup l) : a ∈ l.erase b ↔ a ≠ b ∧ a ∈ l := by
  rw [Nodup.erase_eq_filter d, mem_filter, and_comm, bne_iff_ne]","We start by noting that for a list \( l \) with no duplicate elements, erasing the first occurrence of \( b \) from \( l \) is equivalent to filtering out all occurrences of \( b \) from \( l \). Formally, this means:
\[
l.\text{erase}(b) = \text{filter}(\lambda x. x \neq b, l).
\]
Next, we use the property of membership in a filtered list, which states that:
\[
a \in \text{filter}(\lambda x. x \neq b, l) \quad \text{if and only if} \quad a \in l \land (a \neq b) = \text{true}.
\]
By the commutativity of conjunction, we can rewrite this as:
\[
(a \neq b) = \text{true} \land a \in l.
\]
Finally, we use the fact that the boolean not-equal function \( a \neq b \) returns `true` if and only if \( a \neq b \). Therefore, we have:
\[
(a \neq b) = \text{true} \land a \in l \quad \text{if and only if} \quad a \neq b \land a \in l.
\]
This completes the proof, as the final goal is trivially true.","theorem List.Nodup.mem_erase_iff [LawfulBEq α] {a : α} (d : Nodup l) : a ∈ l.erase b ↔ a ≠ b ∧ a ∈ l := by
/- First, we use the fact that for a list \( l \) with no duplicate elements, erasing the first occurrence of \( b \) from \( l \) is equivalent to filtering out all occurrences of \( b \) from \( l \). This transforms our goal to show that \( a \in \text{filter}(\lambda x. x \neq b, l) \) if and only if \( a \neq b \) and \( a \in l \). Next, we use the property of membership in a filtered list, which states that \( a \in \text{filter}(\lambda x. x \neq b, l) \) if and only if \( a \in l \) and \( (a \neq b) = \text{true} \). By the commutativity of conjunction, we can rewrite this as \( (a \neq b) = \text{true} \) and \( a \in l \). Finally, we use the fact that the boolean not-equal function \( a \neq b \) returns `true` if and only if \( a \neq b \). Thus, our goal is now to show that \( a \neq b \) and \( a \in l \) if and only if \( a \neq b \) and \( a \in l \), which is trivially true. -/
  rw [Nodup.erase_eq_filter d, mem_filter, and_comm, bne_iff_ne]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nodup
open Nat
variable [BEq α]
"
193,List.eraseIdx_of_length_le,theorem List.eraseIdx_of_length_le {l : List α} {k : Nat} (h : length l ≤ k) : eraseIdx l k = l := by sorry,"Erasing Beyond List Length Leaves List Unchanged: \( l.\text{eraseIdx}(k) = l \) if \( \text{length}(l) \leq k \) : For any list \( l \) of elements of type \( \alpha \) and any natural number \( k \), if the length of \( l \) is less than or equal to \( k \), then removing the element at index \( k \) from \( l \) results in the list \( l \) itself, i.e., \( l.\text{eraseIdx}(k) = l \).","theorem List.eraseIdx_of_length_le {l : List α} {k : Nat} (h : length l ≤ k) : eraseIdx l k = l := by
  rw [eraseIdx_eq_self.2 h]","We are given a list \( l \) of elements of type \( \alpha \) and a natural number \( k \) such that \( \text{length}(l) \leq k \). According to the theorem that states \( l.\text{eraseIdx}(k) = l \) if and only if \( \text{length}(l) \leq k \), and since we have the assumption \( \text{length}(l) \leq k \), we can directly conclude that \( l.\text{eraseIdx}(k) = l \). This is because the condition \( \text{length}(l) \leq k \) is satisfied, and thus the list remains unchanged when we attempt to remove an element at an index that is beyond its length. Therefore, the goal \( l.\text{eraseIdx}(k) = l \) is equivalent to \( l = l \), which is trivially true by the reflexive property of equality. This completes the proof.","theorem List.eraseIdx_of_length_le {l : List α} {k : Nat} (h : length l ≤ k) : eraseIdx l k = l := by
/- Since the theorem states that \( l.\text{eraseIdx}(k) = l \) if and only if \( \text{length}(l) \leq k \), and we have the assumption \( \text{length}(l) \leq k \), we can directly replace \( l.\text{eraseIdx}(k) \) with \( l \) in our goal. Therefore, the goal \( l.\text{eraseIdx}(k) = l \) is equivalent to \( l = l \), which is trivially true by the reflexive property of equality. -/
  rw [eraseIdx_eq_self.2 h]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
202,List.erase_replicate_self,"theorem List.erase_replicate_self [LawfulBEq α] {a : α} :
    (replicate n a).erase a = replicate (n - 1) a := by sorry","Erasing an Element from a Replicated List Reduces its Length by One : For any type \(\alpha\) and any natural number \(n\), if \(a\) is an element of \(\alpha\), then erasing \(a\) from the list containing \(n\) copies of \(a\) results in a list containing \(n - 1\) copies of \(a\). Formally, \((\text{replicate } n \, a). \text{erase } a = \text{replicate } (n - 1) \, a\).","theorem List.erase_replicate_self [LawfulBEq α] {a : α} :
    (replicate n a).erase a = replicate (n - 1) a := by
  cases n <;> simp [replicate_succ]","We will consider two cases for the natural number \( n \):

1. **Case 1:** \( n = 0 \)
- When \( n = 0 \), the list \(\text{replicate } 0 \, a\) is the empty list \([]\).
- Erasing \( a \) from the empty list results in the empty list, and \(\text{replicate } (0 - 1) \, a\) is also the empty list.
- Therefore, the proposition \((\text{replicate } 0 \, a). \text{erase } a = \text{replicate } (0 - 1) \, a\) simplifies to \([] = []\), which is trivially true.

2. **Case 2:** \( n = k + 1 \) for some natural number \( k \)
- When \( n = k + 1 \), the list \(\text{replicate } (k + 1) \, a\) is the list \([a, a, ..., a]\) with \( k + 1 \) elements.
- Erasing \( a \) from this list results in the list \([a, a, ..., a]\) with \( k \) elements, which is exactly \(\text{replicate } k \, a\).
- Therefore, the proposition \((\text{replicate } (k + 1) \, a). \text{erase } a = \text{replicate } (k + 1 - 1) \, a\) simplifies to \([a, a, ..., a] = [a, a, ..., a]\) with \( k \) elements, which is also trivially true.

Since both cases are trivially true, the theorem is proved. This completes the proof. \(\blacksquare\)","theorem List.erase_replicate_self [LawfulBEq α] {a : α} :
    (replicate n a).erase a = replicate (n - 1) a := by
/- We will consider two cases for the natural number \( n \):
1. **Case 1:** \( n = 0 \)
2. **Case 2:** \( n = k + 1 \) for some natural number \( k \)

For each case, we will simplify the proposition we want to show using the definition of `List.replicate` for the successor of a natural number. -/
/- **Case 1:** When \( n = 0 \), the list `List.replicate 0 a` is the empty list `[]`. Erasing \( a \) from the empty list results in the empty list, and `List.replicate (0 - 1) a` is also the empty list. Therefore, the proposition \((\text{replicate } 0 \, a). \text{erase } a = \text{replicate } (0 - 1) \, a\) simplifies to \([] = []\), which is trivially true.

**Case 2:** When \( n = k + 1 \), the list `List.replicate (k + 1) a` is the list `[a, a, ..., a]` with \( k + 1 \) elements. Erasing \( a \) from this list results in the list `[a, a, ..., a]` with \( k \) elements, which is exactly `List.replicate k a`. Therefore, the proposition \((\text{replicate } (k + 1) \, a). \text{erase } a = \text{replicate } (k + 1 - 1) \, a\) simplifies to \([a, a, ..., a] = [a, a, ..., a]\) with \( k \) elements, which is also trivially true. -/
  cases n <;> simp [replicate_succ]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
210,List.erase_cons_head,theorem List.erase_cons_head [LawfulBEq α] (a : α) (l : List α) : (a :: l).erase a = l := by sorry,"Erasing the Head Element from a List Results in the Tail : For any type \( \alpha \) and any list \( l \) of elements of type \( \alpha \), if \( a \) is an element of \( \alpha \), then erasing the first occurrence of \( a \) from the list \( a :: l \) results in the list \( l \). Formally, \((a :: l). \text{erase } a = l\).","theorem List.erase_cons_head [LawfulBEq α] (a : α) (l : List α) : (a :: l).erase a = l := by
  simp [erase_cons]","We need to show that erasing the first occurrence of \(a\) from the list \(a :: l\) results in the list \(l\). Using the definition of erasing the first occurrence of an element from a list, we have:
\[
(b :: l). \text{erase } a =
\begin{cases}
l & \text{if } b = a \\
b :: (l. \text{erase } a) & \text{if } b \neq a
\end{cases}
\]
Since \(a\) is the head of the list \(a :: l\), the condition \(a = a\) is satisfied. Therefore, \((a :: l). \text{erase } a = l\). This completes the proof.","theorem List.erase_cons_head [LawfulBEq α] (a : α) (l : List α) : (a :: l).erase a = l := by
/- Using the definition of erasing the first occurrence of an element from a list, we can simplify the proposition we want to show. Specifically, for any type \(\alpha\) with a decidable equality instance, and for any elements \(a, b \in \alpha\) and list \(l\) of elements of type \(\alpha\), the list \((b :: l)\) with the first occurrence of \(a\) erased is given by:
\[
(b :: l). \text{erase } a =
\begin{cases}
l & \text{if } b = a \\
b :: (l. \text{erase } a) & \text{if } b \neq a
\end{cases}
\]
Since \(a\) is the head of the list \(a :: l\), the condition \(b = a\) is satisfied, and thus \((a :: l). \text{erase } a = l\). -/
  simp [erase_cons]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
211,List.length_erase_of_mem,"theorem List.length_erase_of_mem [LawfulBEq α] {a : α} {l : List α} (h : a ∈ l) :
    length (l.erase a) = length l - 1 := by sorry","Length of List Decreases by One After Erasing an Element : For any type \( \alpha \) with a `BEq` instance and a `LawfulBEq` instance, and for any element \( a \) and list \( l \) of elements of type \( \alpha \), if \( a \) is a member of \( l \), then the length of the list obtained by erasing the first occurrence of \( a \) from \( l \) is equal to the length of \( l \) minus 1. Formally, if \( a \in l \), then \((l \setminus a). \text{length} = l. \text{length} - 1\).","theorem List.length_erase_of_mem [LawfulBEq α] {a : α} {l : List α} (h : a ∈ l) :
    length (l.erase a) = length l - 1 := by
  rw [erase_eq_eraseP]; exact length_eraseP_of_mem h (beq_self_eq_true a)","To prove the theorem, we start by noting that erasing an element \( a \) from a list \( l \) using the `erase` function is equivalent to erasing it using the `eraseP` function. This equivalence is given by the theorem that states \( l. \text{erase} \, a = l. \text{eraseP} \, a \, (\text{beq} \, a \, a) \).

Next, we apply the theorem that the length of a list after erasing an element \( a \) (using `eraseP`) is the length of the original list minus 1, provided that \( a \) is a member of the list and the equality \( a = a \) holds. Since \( a \) is a member of \( l \) (by assumption \( h \)) and \( a = a \) is always true, the length of the list obtained by erasing the first occurrence of \( a \) from \( l \) is \( l. \text{length} - 1 \).

Thus, we have shown that if \( a \in l \), then \((l \setminus a). \text{length} = l. \text{length} - 1\). This completes the proof.","theorem List.length_erase_of_mem [LawfulBEq α] {a : α} {l : List α} (h : a ∈ l) :
    length (l.erase a) = length l - 1 := by
/- First, we use the fact that erasing an element from a list using `erase` is equivalent to erasing it using `eraseP`. Then, we apply the theorem that the length of a list after erasing an element \( a \) (using `eraseP`) is the length of the original list minus 1, given that \( a \) is a member of the list and the equality \( a = a \) holds. Since \( a \) is a member of \( l \) and \( a = a \) is always true, the length of the list obtained by erasing the first occurrence of \( a \) from \( l \) is \( l. \text{length} - 1 \). -/
  rw [erase_eq_eraseP]; exact length_eraseP_of_mem h (beq_self_eq_true a)","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
212,List.length_erase,"theorem List.length_erase [LawfulBEq α] (a : α) (l : List α) :
    length (l.erase a) = if a ∈ l then length l - 1 else length l := by sorry","Length of List After Erasing an Element : For any type \( \alpha \) with a `BEq` instance and a `LawfulBEq` instance, and for any element \( a \) and list \( l \) of elements of type \( \alpha \), the length of the list obtained by erasing the first occurrence of \( a \) from \( l \) is equal to the length of \( l \) minus 1 if \( a \) is a member of \( l \), otherwise it is equal to the length of \( l \). Formally, \((l \setminus a). \text{length} = \text{if } a \in l \text{ then } l. \text{length} - 1 \text{ else } l. \text{length}\).","theorem List.length_erase [LawfulBEq α] (a : α) (l : List α) :
    length (l.erase a) = if a ∈ l then length l - 1 else length l := by
  rw [erase_eq_eraseP, length_eraseP]
  split <;> split <;> simp_all","We start by noting that the assumption that the cardinality of \( n \) is zero is equivalent to \( n \) being an empty type. Therefore, we convert the assumption \( \text{card}(n) = 0 \) into \( n \) being empty.

To prove that the determinant of \( M \) is \( 1 \), it suffices to show that \( M \) is the identity matrix. Using extensionality, we need to show that for every \( i \in n \), \( M(i) = 1(i) \). Since \( n \) is empty, there are no elements \( i \) in \( n \), and thus the statement \( M(i) = 1(i) \) holds vacuously for all \( i \in n \).

Hence, \( M \) is the identity matrix, and the determinant of \( M \) is \(\det(M) = \det(1) = 1\). This completes the proof. \(\blacksquare\)","theorem List.length_erase [LawfulBEq α] (a : α) (l : List α) :
    length (l.erase a) = if a ∈ l then length l - 1 else length l := by
/- First, we use the equivalence that the cardinality of a finite type is zero if and only if the type is empty to convert the assumption that the cardinality of \( n \) is zero into the assumption that \( n \) is empty. -/
/- It suffices to show that \( M = 1 \) (the identity matrix), because if this is true, by simplifying, we get that the determinant of \( M \) is \( 1 \). -/
/- Using extensionality, to prove that \( M = 1 \), we only need to show that \( M(i) = 1(i) \) for every \( i \in n \). -/
/- Since \( n \) is empty, the statement \( M(i) = 1(i) \) holds for every \( i \in n \) vacuously. This finishes the proof. -/
  rw [erase_eq_eraseP, length_eraseP]
  split <;> split <;> simp_all","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
213,List.eraseP_replicate_of_neg,"theorem List.eraseP_replicate_of_neg {n : Nat} {a : α} (h : ¬p a) :
    (replicate n a).eraseP p = replicate n a := by sorry","Erasing Non-Satisfying Element from Replicated List Preserves the List: $\neg p(a) \to \text{eraseP } p \, (\text{replicate } n \, a) = \text{replicate } n \, a$ : For any type $\alpha$, predicate $p : \alpha \to \text{Bool}$, natural number $n$, and element $a : \alpha$, if $p(a) = \text{false}$, then the list obtained by removing the first element that satisfies $p$ from the list containing $n$ copies of $a$ is equal to the original list containing $n$ copies of $a$. In other words, if the predicate $p$ does not hold for the element $a$, then `List.eraseP p (List.replicate n a)` is equal to `List.replicate n a`.","theorem List.eraseP_replicate_of_neg {n : Nat} {a : α} (h : ¬p a) :
    (replicate n a).eraseP p = replicate n a := by
  rw [eraseP_of_forall_not (by simp_all)]","We start by noting that the list \(\text{replicate } n \, a\) consists of \(n\) copies of the element \(a\). Given the assumption \(p(a) = \text{false}\), we need to show that \(\text{eraseP}(p, \text{replicate } n \, a) = \text{replicate } n \, a\).

By the theorem that states if no element in a list \( l \) satisfies the predicate \( p \), then the list remains unchanged after applying the `eraseP` function, we can replace our goal with showing that \(\text{replicate } n \, a = \text{replicate } n \, a\). This is because we need to show that no element in the list \(\text{replicate } n \, a\) satisfies \( p \).

Since \( p(a) = \text{false} \), it follows that for every element \( a_1 \) in the list \(\text{replicate } n \, a\), \( p(a_1) = \text{false} \). Therefore, the list \(\text{replicate } n \, a\) remains unchanged after applying the `eraseP` function, and the goal \(\text{replicate } n \, a = \text{replicate } n \, a\) is trivially true.

This completes the proof.","theorem List.eraseP_replicate_of_neg {n : Nat} {a : α} (h : ¬p a) :
    (replicate n a).eraseP p = replicate n a := by
/- Since the theorem states that if no element in a list \( l \) satisfies the predicate \( p \), then the list remains unchanged after applying the `eraseP` function, we can replace the goal of showing \(\text{eraseP}(p, \text{replicate } n \, a) = \text{replicate } n \, a\) with showing that \(\text{replicate } n \, a = \text{replicate } n \, a\). This is because we need to show that no element in the list \(\text{replicate } n \, a\) satisfies \( p \). -/
/- Since \( p(a) = \text{false} \), it follows that for every element \( a_1 \) in the list \(\text{replicate } n \, a\), \( p(a_1) = \text{false} \). Therefore, the list \(\text{replicate } n \, a\) remains unchanged after applying the `eraseP` function, and the goal \(\text{replicate } n \, a = \text{replicate } n \, a\) is trivially true. -/
  rw [eraseP_of_forall_not (by simp_all)]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
"
521,List.eraseP_of_forall_not,"theorem List.eraseP_of_forall_not {l : List α} (h : ∀ a, a ∈ l → ¬p a) : l.eraseP p = l := by sorry","List Remains Unchanged if No Element Satisfies Predicate: \(\text{eraseP}(p, l) = l\) : For any list \( l \) of elements of type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), if no element in \( l \) satisfies \( p \), then the list \( l \) remains unchanged after applying the `eraseP` function, i.e., \(\text{eraseP}(p, l) = l\).","theorem List.eraseP_of_forall_not {l : List α} (h : ∀ a, a ∈ l → ¬p a) : l.eraseP p = l := by
  induction l with
  | nil => rfl
  | cons _ _ ih => simp [h _ (.head ..), ih (forall_mem_cons.1 h).2]","We will prove this theorem by induction on the list \( l \).

1. **Base Case:**
- Consider the case where \( l \) is the empty list, i.e., \( l = [] \).
- The goal is to show that \(\text{eraseP}(p, []) = []\).
- By the definition of the `eraseP` function, it leaves an empty list unchanged. Therefore, the base case is trivially true.

2. **Inductive Step:**
- Assume \( l \) is of the form \( a :: l' \), where \( a \) is an element of type \( \alpha \) and \( l' \) is a list of elements of type \( \alpha \).
- We need to show that \(\text{eraseP}(p, a :: l') = a :: l'\).
- By the hypothesis \( h \), no element in \( a :: l' \) satisfies \( p \). This can be broken down into:
- \( h(a, \text{head}(a :: l')) \) shows that \( a \) does not satisfy \( p \).
- \( \text{forall\_mem\_cons.1}(h).2 \) shows that no element in \( l' \) satisfies \( p \).
- By the inductive hypothesis \( \text{ih} \), we know that \(\text{eraseP}(p, l') = l'\).
- Therefore, simplifying the expression \(\text{eraseP}(p, a :: l')\) using these facts, we get \( a :: l' \), which is exactly what we need to show.

By induction, we have shown that for any list \( l \) and any predicate \( p \), if no element in \( l \) satisfies \( p \), then \(\text{eraseP}(p, l) = l\). This completes the proof.","theorem List.eraseP_of_forall_not {l : List α} (h : ∀ a, a ∈ l → ¬p a) : l.eraseP p = l := by
  induction l with
/- First, consider the base case where the list \( l \) is empty. The goal is to show that \(\text{eraseP}(p, []) = []\). This is trivially true by the definition of the `eraseP` function, which leaves an empty list unchanged. -/
  | nil => rfl
/- Next, consider the inductive case where the list \( l \) is of the form \( a :: l' \). We need to show that \(\text{eraseP}(p, a :: l') = a :: l'\). Using the hypothesis \( h \) that no element in \( a :: l' \) satisfies \( p \), we can break this down into two parts:
1. \( h(a, \text{head}(a :: l')) \) shows that \( a \) does not satisfy \( p \).
2. \( \text{forall\_mem\_cons.1}(h).2 \) shows that no element in \( l' \) satisfies \( p \).

By the inductive hypothesis \( \text{ih} \), we know that \(\text{eraseP}(p, l') = l'\). Therefore, simplifying the expression \(\text{eraseP}(p, a :: l')\) using these facts, we get \( a :: l' \), which is exactly what we need to show. -/
  | cons _ _ ih => simp [h _ (.head ..), ih (forall_mem_cons.1 h).2]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
"
522,List.length_eraseP_of_mem,"theorem List.length_eraseP_of_mem (al : a ∈ l) (pa : p a) :
    length (l.eraseP p) = length l - 1 := by sorry","Length Decreases by One When Element Satisfying Predicate is Erased from List : For any type \(\alpha\), any element \(a \in \alpha\), and any list \(l\) of elements of type \(\alpha\), if \(a\) is in \(l\) and the predicate \(p\) applied to \(a\) is true, then the length of the list obtained by removing the first occurrence of \(a\) that satisfies \(p\) from \(l\) is one less than the length of \(l\). Formally, if \(a \in l\) and \(p(a) = \text{true}\), then \(\text{length}(\text{eraseP}(p, l)) = \text{length}(l) - 1\).","theorem List.length_eraseP_of_mem (al : a ∈ l) (pa : p a) :
    length (l.eraseP p) = length l - 1 := by
  let ⟨_, l₁, l₂, _, _, e₁, e₂⟩ := exists_of_eraseP al pa
  rw [e₂]; simp [length_append, e₁]; rfl","Given that \(a \in l\) and \(p(a) = \text{true}\), we use the existence of the first predicate-satisfying element in list erasure to construct lists \(l_1\) and \(l_2\) such that:
- No element in \(l_1\) satisfies \(p\),
- \(p(a) = \text{true}\),
- The original list \(l\) is the concatenation of \(l_1\), \(a\), and \(l_2\),
- The list obtained by removing the first occurrence of \(a\) that satisfies \(p\) from \(l\) is the concatenation of \(l_1\) and \(l_2\).

Formally, we have:
\[
l = l_1 \, \text{cons} \, a \, l_2 \quad \text{and} \quad \text{eraseP}(p, l) = l_1 \, \text{cons} \, l_2.
\]

Next, we substitute \(\text{eraseP}(p, l) = l_1 \, \text{cons} \, l_2\) into the goal. Using the property that the length of the concatenation of two lists is the sum of their lengths, we get:
\[
\text{length}(\text{eraseP}(p, l)) = \text{length}(l_1 \, \text{cons} \, l_2) = \text{length}(l_1) + \text{length}(l_2).
\]

Since \(l = l_1 \, \text{cons} \, a \, l_2\), the length of \(l\) is:
\[
\text{length}(l) = \text{length}(l_1) + 1 + \text{length}(l_2).
\]

Thus, we have:
\[
\text{length}(\text{eraseP}(p, l)) = \text{length}(l_1) + \text{length}(l_2) = \text{length}(l) - 1.
\]

This completes the proof. \(\blacksquare\)","theorem List.length_eraseP_of_mem (al : a ∈ l) (pa : p a) :
    length (l.eraseP p) = length l - 1 := by
/- By the existence of the first predicate-satisfying element in list erasure, since \(a \in l\) and \(p(a) = \text{true}\), we can construct lists \(l_1\) and \(l_2\) such that:
- No element in \(l_1\) satisfies \(p\),
- \(p(a) = \text{true}\),
- The original list \(l\) is the concatenation of \(l_1\), \(a\), and \(l_2\),
- The list obtained by removing the first occurrence of \(a\) that satisfies \(p\) from \(l\) is the concatenation of \(l_1\) and \(l_2\).

Formally, we have:
\[
l = l_1 \, \text{cons} \, a \, l_2 \quad \text{and} \quad \text{eraseP}(p, l) = l_1 \, \text{cons} \, l_2.
\] -/
  let ⟨_, l₁, l₂, _, _, e₁, e₂⟩ := exists_of_eraseP al pa
/- Using the fact that \(\text{eraseP}(p, l) = l_1 \, \text{cons} \, l_2\), we substitute this into the goal. After simplifying the expression using the property that the length of the concatenation of two lists is the sum of their lengths, and the fact that \(l = l_1 \, \text{cons} \, a \, l_2\), we get:
\[
\text{length}(\text{eraseP}(p, l)) = \text{length}(l_1 \, \text{cons} \, l_2) = \text{length}(l_1) + \text{length}(l_2).
\]
Since \(l = l_1 \, \text{cons} \, a \, l_2\), the length of \(l\) is:
\[
\text{length}(l) = \text{length}(l_1) + 1 + \text{length}(l_2).
\]
Thus, we have:
\[
\text{length}(\text{eraseP}(p, l)) = \text{length}(l_1) + \text{length}(l_2) = \text{length}(l) - 1.
\]
This completes the proof. -/
  rw [e₂]; simp [length_append, e₁]; rfl","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
"
524,List.mem_eraseP_of_neg,theorem List.mem_eraseP_of_neg {l : List α} (pa : ¬p a) : a ∈ l.eraseP p ↔ a ∈ l := by sorry,"Membership in List After Erasing First Element Satisfying Predicate: $p(a) = \text{false} \to (a \in \text{eraseP}(p, l) \leftrightarrow a \in l)$ : For any type $\alpha$, any predicate $p : \alpha \to \text{Bool}$, and any element $a \in \alpha$, if $p(a)$ is false, then $a$ is a member of the list obtained by removing the first element that satisfies $p$ from $l$ if and only if $a$ is a member of the original list $l$. Formally, if $p(a) = \text{false}$, then $a \in \text{eraseP}(p, l) \leftrightarrow a \in l$.","theorem List.mem_eraseP_of_neg {l : List α} (pa : ¬p a) : a ∈ l.eraseP p ↔ a ∈ l := by
  refine ⟨mem_of_mem_eraseP, fun al => ?_⟩
  match exists_or_eq_self_of_eraseP p l with
  | .inl h => rw [h]; assumption
  | .inr ⟨c, l₁, l₂, h₁, h₂, h₃, h₄⟩ =>
    rw [h₄]; rw [h₃] at al
    have : a ≠ c := fun h => (h ▸ pa).elim h₂
    simp [this] at al; simp [al]","To prove that $a \in \text{eraseP}(p, l) \leftrightarrow a \in l$, we need to show two implications:
1. If $a \in \text{eraseP}(p, l)$, then $a \in l$.
2. If $a \in l$, then $a \in \text{eraseP}(p, l)$.

**First Implication:**
The first implication is given by the theorem that if $a$ is a member of the list obtained by removing the first element that satisfies $p$ from $l$, then $a$ is also a member of the original list $l$. Formally, if $a \in \text{eraseP}(p, l)$, then $a \in l$.

**Second Implication:**
Now we need to show the second implication. Assume $a \in l$. We will consider the structure of the list $l$ and the properties of the elements in $l$.

- **Case 1: $a \in l_1$**
If $a \in l_1$, then by the definition of list concatenation, $a \in l_1 \cup (c :: l_2)$. Since $\text{eraseP}(p, l) = l_1 \cup l_2$, it follows that $a \in l_1 \cup l_2$. Therefore, $a \in \text{eraseP}(p, l)$.

- **Case 2: $a \in c :: l_2$**
If $a \in c :: l_2$, we need to show that $a \in l_1 \cup l_2$. Since $a \in l_1 \cup (c :: l_2)$ and $l = l_1 \cup (c :: l_2)$, we can substitute $l$ with $l_1 \cup (c :: l_2)$ in the assumption. This simplifies our goal to showing that $a \in l_1 \cup l_2$.

- **Subcase: $a = c$**
If $a = c$, then $p(a) = p(c) = \text{true}$, which contradicts our assumption that $p(a) = \text{false}$. Therefore, $a \neq c$.

- **Subcase: $a \neq c$**
Since $a \neq c$ and $a \in c :: l_2$, it follows that $a \in l_2$. By the definition of $\text{eraseP}(p, l)$, which removes the first element that satisfies $p$ from $l$, and since $p(c) = \text{true}$, the element $c$ is removed from $l$. Thus, $\text{eraseP}(p, l) = l_1 \cup l_2$. Since $a \in l_2$, it follows that $a \in l_1 \cup l_2$. Therefore, $a \in \text{eraseP}(p, l)$.

Combining both cases, we have shown that if $a \in l$, then $a \in \text{eraseP}(p, l)$. This completes the proof of the second implication.

Since both implications are proven, we conclude that $a \in \text{eraseP}(p, l) \leftrightarrow a \in l$.

\(\blacksquare\)","theorem List.mem_eraseP_of_neg {l : List α} (pa : ¬p a) : a ∈ l.eraseP p ↔ a ∈ l := by
/- To prove that $a \in \text{eraseP}(p, l) \leftrightarrow a \in l$, we need to show two implications:
1. If $a \in \text{eraseP}(p, l)$, then $a \in l$.
2. If $a \in l$, then $a \in \text{eraseP}(p, l)$.
The first implication is already given by the theorem that if $a$ is a member of the list obtained by removing the first element that satisfies $p$ from $l$, then $a$ is also a member of the original list $l$. So now it suffices to show the second implication. -/
  refine ⟨mem_of_mem_eraseP, fun al => ?_⟩
  match exists_or_eq_self_of_eraseP p l with
/- If $a \in l_1$, then by substituting this into the goal, we directly get $a \in l_1 \cup l_2$ from the assumption $a \in l_1$. -/
  | .inl h => rw [h]; assumption
/- If $a \in c :: l_2$, then we need to consider the structure of the list $l$ and the properties of the elements in $l_1$ and $l_2$. -/
  | .inr ⟨c, l₁, l₂, h₁, h₂, h₃, h₄⟩ =>
/- Since $l = l_1 \cup (c :: l_2)$ and $\text{eraseP}(p, l) = l_1 \cup l_2$, we can substitute these equalities into the goal and the assumption. This simplifies our goal to showing that $a \in l_1 \cup l_2$. -/
    rw [h₄]; rw [h₃] at al
    have : a ≠ c := fun h => (h ▸ pa).elim h₂
/- Using the fact that $a \neq c$, we can simplify the assumption $a \in l$ to $a \in l_1 \cup (c :: l_2)$. After simplifying, we need to show that $a \in l_1 \cup l_2$. -/
    simp [this] at al; simp [al]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
"
525,List.eraseP_replicate_of_pos,"theorem List.eraseP_replicate_of_pos {n : Nat} {a : α} (h : p a) :
    (replicate n a).eraseP p = replicate (n - 1) a := by sorry","Erasure of First Element Satisfying Predicate from Replicated List: \(\text{List.eraseP } p \, (\text{List.replicate } n \, a) = \text{List.replicate } (n - 1) \, a\) if \( p(a) = \text{true} \) : For any type \( \alpha \), predicate \( p : \alpha \to \text{Bool} \), natural number \( n \), and element \( a \in \alpha \), if \( p(a) = \text{true} \), then the list obtained by removing the first element \( a \) that satisfies \( p \) from the list containing \( n \) copies of \( a \) is equal to the list containing \( n - 1 \) copies of \( a \). In other words, if \( p(a) \) is true, then:
\[ \text{List.eraseP } p \, (\text{List.replicate } n \, a) = \text{List.replicate } (n - 1) \, a \]","theorem List.eraseP_replicate_of_pos {n : Nat} {a : α} (h : p a) :
    (replicate n a).eraseP p = replicate (n - 1) a := by
  cases n <;> simp [replicate_succ, h]","We will consider two cases for the natural number \( n \):

1. **Case 1: \( n = 0 \)**
- The list \(\text{List.replicate } 0 \, a\) is the empty list.
- The operation \(\text{List.eraseP } p \, []\) results in the empty list, since there are no elements to remove.
- The list \(\text{List.replicate } (0 - 1) \, a\) is also the empty list, as \(\text{List.replicate } (-1) \, a\) is defined to be the empty list.
- Therefore, \(\text{List.eraseP } p \, (\text{List.replicate } 0 \, a) = \text{List.replicate } (0 - 1) \, a\) is trivially true.

2. **Case 2: \( n = n' + 1 \) for some \( n' \in \mathbb{N} \)**
- The list \(\text{List.replicate } (n' + 1) \, a\) is equivalent to \(a :: \text{List.replicate } n' \, a\).
- Given that \( p(a) = \text{true} \), the operation \(\text{List.eraseP } p \, (a :: \text{List.replicate } n' \, a)\) removes the first element \( a \) from the list, resulting in \(\text{List.replicate } n' \, a\).
- The list \(\text{List.replicate } (n' + 1 - 1) \, a\) is also \(\text{List.replicate } n' \, a\).
- Therefore, \(\text{List.eraseP } p \, (\text{List.replicate } (n' + 1) \, a) = \text{List.replicate } (n' + 1 - 1) \, a\) holds true.

In both cases, the desired equality is established. This completes the proof.","theorem List.eraseP_replicate_of_pos {n : Nat} {a : α} (h : p a) :
    (replicate n a).eraseP p = replicate (n - 1) a := by
/- We will consider two cases for the natural number \( n \): \( n = 0 \) and \( n = n' + 1 \) for some \( n' \in \mathbb{N} \).

**Case 1: \( n = 0 \)**
- The goal is to show that \(\text{List.eraseP } p \, (\text{List.replicate } 0 \, a) = \text{List.replicate } (0 - 1) \, a\).
- Using the fact that \(\text{List.replicate } 0 \, a\) is the empty list and the property that \(\text{List.eraseP } p \, [] = []\), we simplify the goal to \(\text{List.eraseP } p \, [] = \text{List.replicate } (-1) \, a\).
- Since \(\text{List.replicate } (-1) \, a\) is also the empty list, the goal is trivially true.

**Case 2: \( n = n' + 1 \)**
- The goal is to show that \(\text{List.eraseP } p \, (\text{List.replicate } (n' + 1) \, a) = \text{List.replicate } (n' + 1 - 1) \, a\).
- Using the property that \(\text{List.replicate } (n' + 1) \, a\) is equivalent to \(a :: \text{List.replicate } n' \, a\) and the fact that \( p(a) = \text{true} \), we can simplify the goal to \(\text{List.eraseP } p \, (a :: \text{List.replicate } n' \, a) = \text{List.replicate } n' \, a\).
- By the property that the first element satisfying the predicate \( p \) is removed from the list, we get \(\text{List.eraseP } p \, (a :: \text{List.replicate } n' \, a) = \text{List.replicate } n' \, a\), which is exactly what we need to show. -/
  cases n <;> simp [replicate_succ, h]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
"
526,List.eraseP_filter,"theorem List.eraseP_filter (f : α → Bool) (l : List α) :
    (filter f l).eraseP p = filter f (l.eraseP (fun x => p x && f x)) := by sorry","Removal of Predicate-Satisfying Element from Filtered List : For any type \( \alpha \), a predicate \( p \) on \( \alpha \), and a predicate \( f \) on \( \alpha \), the result of removing the first element satisfying \( p \) from the list filtered by \( f \) is the same as filtering the list by \( f \) and then removing the first element that satisfies both \( p \) and \( f \). Formally, for any list \( l \) of elements of \( \alpha \),
\[
\text{eraseP } p (\text{filter } f \, l) = \text{filter } f (\text{eraseP } (p \land f) \, l).
\]","theorem List.eraseP_filter (f : α → Bool) (l : List α) :
    (filter f l).eraseP p = filter f (l.eraseP (fun x => p x && f x)) := by
  rw [← filterMap_eq_filter, eraseP_filterMap]
  congr
  ext x
  simp only [Option.guard]
  split <;> split at * <;> simp_all","We start by using the equivalence that the `filterMap` operation with `Option.guard` is the same as the `filter` operation. This allows us to rewrite the goal as:
\[
\text{filterMap } (Option.guard \, f) \, (\text{eraseP } (fun x => p x \land f x) \, l) = \text{filterMap } (Option.guard \, f) \, (\text{eraseP } (fun x => p x \land f x) \, l).
\]
It suffices to show this new goal.

Next, we decompose the equality to prove that the function applied to the list on both sides of the equation is the same. This reduces our goal to showing:
\[
(fun x => p x \land f x) = (fun x => p x \land f x).
\]

To prove this, we introduce a new variable \( x \) into the context to reason about the expression, allowing us to consider cases or instances involving \( x \). This reduces our goal to showing:
\[
\text{match } (if f x = \text{true} \, \text{then } some \, x \, \text{else } none) \, \text{with} \\
\text{| some } y \, \text{=> } p y \\
\text{| none } \, \text{=> } \text{false} \\
\text{end} = (p x \land f x).
\]

Using the definition of `Option.guard`, we can simplify the expression to:
\[
\text{match } (if f x = \text{true} \, \text{then } some \, x \, \text{else } none) \, \text{with} \\
\text{| some } y \, \text{=> } p y \\
\text{| none } \, \text{=> } \text{false} \\
\text{end} = (p x \land f x).
\]

We now discuss by cases based on the condition \( f x = \text{true} \):
- If \( f x = \text{true} \), then the expression simplifies to:
\[
p y = (p x \land f x)
\]
where \( y = x \). Since \( y = x \), this reduces to:
\[
p x = (p x \land f x)
\]
which is true because \( f x = \text{true} \).
- If \( f x = \text{false} \), then the expression simplifies to:
\[
\text{false} = (p x \land f x)
\]
which is true because \( f x = \text{false} \).

Thus, the original goal is established, and the proof is complete.","theorem List.eraseP_filter (f : α → Bool) (l : List α) :
    (filter f l).eraseP p = filter f (l.eraseP (fun x => p x && f x)) := by
/- First, we use the equivalence that the `filterMap` operation with `Option.guard` is the same as the `filter` operation to rewrite the goal. Then, we use the theorem that the `eraseP` operation commutes with `filterMap` to further simplify the goal. This transforms our goal into:
\[
\text{filterMap } (Option.guard \, f) \, (\text{eraseP } (fun x => p x \land f x) \, l) = \text{filterMap } (Option.guard \, f) \, (\text{eraseP } (fun x => p x \land f x) \, l)
\]
It suffices to show this new goal. -/
  rw [← filterMap_eq_filter, eraseP_filterMap]
/- To establish the equality, we can decompose it to prove that the function applied to the list on both sides of the equation is the same. This reduces our goal to showing:
\[
(fun x => p x \land f x) = (fun x => p x \land f x)
\] -/
  congr
/- Introduce a new variable \( x \) into the context to reason about the expression, allowing us to consider cases or instances involving \( x \). This reduces our goal to showing:
\[
\text{match } (if f x = \text{true} \, \text{then } some \, x \, \text{else } none) \, \text{with} \\
\text{| some } y \, \text{=> } p y \\
\text{| none } \, \text{=> } \text{false} \\
\text{end} = (p x \land f x)
\] -/
  ext x
/- Using the definition of `Option.guard`, we can simplify the expression to:
\[
\text{match } (if f x = \text{true} \, \text{then } some \, x \, \text{else } none) \, \text{with} \\
\text{| some } y \, \text{=> } p y \\
\text{| none } \, \text{=> } \text{false} \\
\text{end} = (p x \land f x)
\] -/
  simp only [Option.guard]
/- We discuss by cases based on the condition \( f x = \text{true} \):
- If \( f x = \text{true} \), then the expression simplifies to:
\[
p y = (p x \land f x)
\]
where \( y = x \). Since \( y = x \), this reduces to:
\[
p x = (p x \land f x)
\]
which is true because \( f x = \text{true} \).
- If \( f x = \text{false} \), then the expression simplifies to:
\[
\text{false} = (p x \land f x)
\]
which is true because \( f x = \text{false} \). -/
  split <;> split at * <;> simp_all","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
"
529,List.eraseP_append,"theorem List.eraseP_append (l₁ l₂ : List α) :
    (l₁ ++ l₂).eraseP p = if l₁.any p then l₁.eraseP p ++ l₂ else l₁ ++ l₂.eraseP p := by sorry","Erasure in Concatenated Lists: \(\text{List.eraseP } p \, (l_1 ++ l_2) = \text{if } l_1.\text{any } p \, \text{then } \text{List.eraseP } p \, l_1 ++ l_2 \, \text{else } l_1 ++ \text{List.eraseP } p \, l_2\) : For any type \( \alpha \), lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), and a predicate \( p : \alpha \to \text{Bool} \), the following holds:
\[ \text{List.eraseP } p \, (l_1 ++ l_2) = \begin{cases} 
\text{List.eraseP } p \, l_1 ++ l_2 & \text{if } \exists a \in l_1, \, p(a) = \text{true} \\
l_1 ++ \text{List.eraseP } p \, l_2 & \text{otherwise}
\end{cases} \]
This theorem states that when erasing the first element in the concatenated list \( l_1 ++ l_2 \) that satisfies the predicate \( p \), if any element in \( l_1 \) satisfies \( p \), then the first such element is removed from \( l_1 \) and the result is concatenated with \( l_2 \). If no element in \( l_1 \) satisfies \( p \), then the first element satisfying \( p \) is removed from \( l_2 \) and the result is concatenated with \( l_1 \).","theorem List.eraseP_append (l₁ l₂ : List α) :
    (l₁ ++ l₂).eraseP p = if l₁.any p then l₁.eraseP p ++ l₂ else l₁ ++ l₂.eraseP p := by
  split <;> rename_i h
  · simp only [any_eq_true] at h
    obtain ⟨x, m, h⟩ := h
    rw [eraseP_append_left h _ m]
  · simp only [any_eq_true] at h
    rw [eraseP_append_right _]
    simp_all","We need to show that the result of removing the first element in the concatenated list \( l_1 ++ l_2 \) that satisfies the predicate \( p \) is as described in the theorem. We discuss by cases based on the condition \( l_1.\text{any } p = \text{true} \).

1. **Case 1: \( l_1.\text{any } p = \text{true} \)**
- Using the equivalence that \( l_1.\text{any } p = \text{true} \) is equivalent to \( \exists x \in l_1, \, p(x) = \text{true} \), we can reformulate the hypothesis to \( \exists x \in l_1, \, p(x) = \text{true} \).
- Assume \( x \in l_1 \) and \( p(x) = \text{true} \).
- By the theorem that if \( p(x) = \text{true} \) and \( x \in l_1 \), then \( \text{List.eraseP } p \, (l_1 ++ l_2) = \text{List.eraseP } p \, l_1 ++ l_2 \), we can replace the goal \( \text{List.eraseP } p \, (l_1 ++ l_2) = \text{List.eraseP } p \, l_1 ++ l_2 \) with \( \text{List.eraseP } p \, l_1 ++ l_2 = \text{List.eraseP } p \, l_1 ++ l_2 \), which is trivially true.

2. **Case 2: \( \neg l_1.\text{any } p = \text{true} \)**
- Using the equivalence that \( \neg l_1.\text{any } p = \text{true} \) is equivalent to \( \neg \exists x \in l_1, \, p(x) = \text{true} \), we can reformulate the hypothesis to \( \neg \exists x \in l_1, \, p(x) = \text{true} \).
- By the theorem that if no element in \( l_1 \) satisfies \( p \), then \( \text{List.eraseP } p \, (l_1 ++ l_2) = l_1 ++ \text{List.eraseP } p \, l_2 \), we can replace the goal \( \text{List.eraseP } p \, (l_1 ++ l_2) = l_1 ++ \text{List.eraseP } p \, l_2 \) with \( l_1 ++ \text{List.eraseP } p \, l_2 = l_1 ++ \text{List.eraseP } p \, l_2 \), which is trivially true.

Thus, in both cases, the goal is satisfied, and the theorem is proved.","theorem List.eraseP_append (l₁ l₂ : List α) :
    (l₁ ++ l₂).eraseP p = if l₁.any p then l₁.eraseP p ++ l₂ else l₁ ++ l₂.eraseP p := by
/- We discuss by cases based on the condition \( l_1.\text{any } p = \text{true} \). In the first case, we assume \( l_1.\text{any } p = \text{true} \), and in the second case, we assume \( \neg l_1.\text{any } p = \text{true} \). We rename the hypothesis in each case to \( h \) for clarity. -/
  split <;> rename_i h
/- In the first case, using the equivalence that \( l_1.\text{any } p = \text{true} \) is equivalent to \( \exists x \in l_1, \, p(x) = \text{true} \), we can reformulate the hypothesis \( h \) to \( \exists x \in l_1, \, p(x) = \text{true} \). -/
  · simp only [any_eq_true] at h
/- Assume \( x \in l_1 \) and \( p(x) = \text{true} \) as in the hypothesis \( h \). -/
    obtain ⟨x, m, h⟩ := h
/- Since the theorem states that if \( p(x) = \text{true} \) and \( x \in l_1 \), then \( \text{eraseP}(p, l_1 \oplus l_2) = \text{eraseP}(p, l_1) \oplus l_2 \), we can replace the goal \( \text{eraseP}(p, l_1 \oplus l_2) = \text{eraseP}(p, l_1) \oplus l_2 \) with \( \text{eraseP}(p, l_1) \oplus l_2 = \text{eraseP}(p, l_1) \oplus l_2 \), which is trivially true. -/
    rw [eraseP_append_left h _ m]
/- In the second case, using the equivalence that \( \neg l_1.\text{any } p = \text{true} \) is equivalent to \( \neg \exists x \in l_1, \, p(x) = \text{true} \), we can reformulate the hypothesis \( h \) to \( \neg \exists x \in l_1, \, p(x) = \text{true} \). -/
  · simp only [any_eq_true] at h
/- Since the theorem states that if no element in \( l_1 \) satisfies \( p \), then \( \text{eraseP}(p, l_1 \oplus l_2) = l_1 \oplus \text{eraseP}(p, l_2) \), we can replace the goal \( \text{eraseP}(p, l_1 \oplus l_2) = l_1 \oplus \text{eraseP}(p, l_2) \) with \( l_1 \oplus \text{eraseP}(p, l_2) = l_1 \oplus \text{eraseP}(p, l_2) \), which is trivially true. -/
    rw [eraseP_append_right _]
/- Using the hypothesis \( \neg \exists x \in l_1, \, p(x) = \text{true} \), we can simplify the goal \( \forall b \in l_1, \, \neg p(b) = \text{true} \) to a trivially true statement. -/
    simp_all","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
"
530,List.erase_append_left,"theorem List.erase_append_left [LawfulBEq α] {l₁ : List α} (l₂) (h : a ∈ l₁) :
    (l₁ ++ l₂).erase a = l₁.erase a ++ l₂ := by sorry","Erasing Element from Left List in Concatenation: \((l_1 ++ l_2). \text{erase } a = l_1. \text{erase } a ++ l_2\) if \(a \in l_1\) : For any type \( \alpha \) and any element \( a \) of type \( \alpha \), if \( a \) is in the list \( l_1 \), then the list obtained by erasing \( a \) from the concatenation \( l_1 ++ l_2 \) is equal to the concatenation of the list obtained by erasing \( a \) from \( l_1 \) and the list \( l_2 \). Formally, if \( a \in l_1 \), then \((l_1 ++ l_2). \text{erase } a = l_1. \text{erase } a ++ l_2\).","theorem List.erase_append_left [LawfulBEq α] {l₁ : List α} (l₂) (h : a ∈ l₁) :
    (l₁ ++ l₂).erase a = l₁.erase a ++ l₂ := by
  simp [erase_eq_eraseP]; exact eraseP_append_left (beq_self_eq_true a) l₂ h","To prove the theorem, we start by simplifying the expression \((l_1 ++ l_2). \text{erase } a\). Using the fact that \(\text{erase } a\) is equivalent to \(\text{eraseP } a \, \text{beq}\), we can rewrite the goal as \((l_1 ++ l_2). \text{eraseP } a \, \text{beq} = l_1. \text{eraseP } a \, \text{beq} ++ l_2\).

Next, we use the property that if \(a\) is in \(l_1\), erasing \(a\) from the concatenation \(l_1 ++ l_2\) is the same as concatenating the list obtained by erasing \(a\) from \(l_1\) with \(l_2\). This property holds because the equality \(a = a\) is always true, and thus the condition for \(\text{eraseP}\) is satisfied.

Therefore, we have \((l_1 ++ l_2). \text{erase } a = l_1. \text{erase } a ++ l_2\), which completes the proof.","theorem List.erase_append_left [LawfulBEq α] {l₁ : List α} (l₂) (h : a ∈ l₁) :
    (l₁ ++ l₂).erase a = l₁.erase a ++ l₂ := by
/- First, we simplify the expression \((l_1 ++ l_2). \text{erase } a\) using the fact that \(\text{erase } a\) is equivalent to \(\text{eraseP } a \, \text{beq}\). Then, we use the property that if \(a\) is in \(l_1\), erasing \(a\) from the concatenation \(l_1 ++ l_2\) is the same as concatenating the list obtained by erasing \(a\) from \(l_1\) with \(l_2\). This is because the equality \(a = a\) is always true, and thus the condition for \(\text{eraseP}\) is satisfied. -/
  simp [erase_eq_eraseP]; exact eraseP_append_left (beq_self_eq_true a) l₂ h","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
531,List.erase_eq_eraseP',theorem List.erase_eq_eraseP' (a : α) (l : List α) : l.erase a = l.eraseP (· == a) := by sorry,"Erase First Occurrence of Element is Equivalent to Erase First Element Satisfying Predicate: \( \text{List.erase } l \, a = \text{List.eraseP } (x \mapsto x = a) \, l \) : For any type \(\alpha\) with a boolean equality function `BEq`, and for any element \(a \in \alpha\) and list \(l\) of elements of type \(\alpha\), the list obtained by erasing the first occurrence of \(a\) from \(l\) using the `List.erase` function is equal to the list obtained by removing the first element that satisfies the predicate \(x \mapsto (x = a)\) from \(l\) using the `List.eraseP` function. Formally, for a list \(l = [a_1, a_2, \ldots, a_n]\) and an element \(a\):
- `List.erase l a` and `List.eraseP (fun x => x == a) l` both return the list obtained by removing the first occurrence of \(a\) from \(l\).","theorem List.erase_eq_eraseP' (a : α) (l : List α) : l.erase a = l.eraseP (· == a) := by
  induction l
  · simp
  · next b t ih =>
    rw [erase_cons, eraseP_cons, ih]
    if h : b == a then simp [h] else simp [h]","We perform induction on the list \( l \).

**Base Case:**
For the empty list \([]\), we need to show that \([]. \text{erase } a = \text{eraseP } (x \mapsto x = a) \, []\). Simplifying both sides, we see that the empty list with the first occurrence of \(a\) erased is the empty list, and the empty list with the first element satisfying \(x \mapsto x = a\) erased is also the empty list. Therefore, the base case is trivially true.

**Inductive Step:**
Assume \( l \) is of the form \( b :: t \), where \( b \in \alpha \) and \( t \) is a list of elements of type \(\alpha\). We need to show that \((b :: t). \text{erase } a = \text{eraseP } (x \mapsto x = a) \, (b :: t)\).

Using the definitions of `List.erase` and `List.eraseP` on cons lists, we have:
- If \( b = a \), then \((b :: t). \text{erase } a = t\) and \(\text{eraseP } (x \mapsto x = a) \, (b :: t) = t\).
- If \( b \neq a \), then \((b :: t). \text{erase } a = b :: (t. \text{erase } a)\) and \(\text{eraseP } (x \mapsto x = a) \, (b :: t) = b :: \text{eraseP } (x \mapsto x = a) \, t\).

By the inductive hypothesis, \( t. \text{erase } a = \text{eraseP } (x \mapsto x = a) \, t \), the two expressions are equal in both cases.

**Case 1: \( b = a \)**
- The goal simplifies to \( t = t \), which is trivially true.

**Case 2: \( b \neq a \)**
- The goal simplifies to \( b :: (t. \text{erase } a) = b :: \text{eraseP } (x \mapsto x = a) \, t \), which is true by the inductive hypothesis.

Thus, by induction, the theorem holds for all lists \( l \). This completes the proof.","theorem List.erase_eq_eraseP' (a : α) (l : List α) : l.erase a = l.eraseP (· == a) := by
/- We perform induction on the list \( l \). For the base case, we consider \( l \) to be the empty list. For the inductive step, we assume \( l \) is of the form \( b :: t \) and introduce the inductive hypothesis \( \text{ih} \) that \( t. \text{erase } a = \text{eraseP } (x \mapsto x = a) \, t \). -/
  induction l
/- For the base case, we simplify the proposition we want to show. The empty list \([]\) with the first occurrence of \(a\) erased is the empty list, and the empty list with the first element satisfying \(x \mapsto x = a\) erased is also the empty list. Therefore, the base case is trivially true. -/
  · simp
/- For the inductive step, we consider the list \( l \) to be of the form \( b :: t \) and assume the inductive hypothesis \( \text{ih} \) that \( t. \text{erase } a = \text{eraseP } (x \mapsto x = a) \, t \). -/
  · next b t ih =>
/- Using the definitions of `List.erase` and `List.eraseP` on cons lists, we rewrite the goal. Specifically, for the list \( b :: t \):
- If \( b = a \), then \((b :: t). \text{erase } a = t\) and \(\text{eraseP } (x \mapsto x = a) \, (b :: t) = t\).
- If \( b \neq a \), then \((b :: t). \text{erase } a = b :: (t. \text{erase } a)\) and \(\text{eraseP } (x \mapsto x = a) \, (b :: t) = b :: \text{eraseP } (x \mapsto x = a) \, t\).
By the inductive hypothesis, \( t. \text{erase } a = \text{eraseP } (x \mapsto x = a) \, t \), the two expressions are equal. -/
    rw [erase_cons, eraseP_cons, ih]
/- We now consider the two cases:
- If \( b = a \), then the goal simplifies to \( t = t \), which is trivially true.
- If \( b \neq a \), then the goal simplifies to \( b :: (t. \text{erase } a) = b :: \text{eraseP } (x \mapsto x = a) \, t \), which is also true by the inductive hypothesis. -/
    if h : b == a then simp [h] else simp [h]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
532,List.erase_append,"theorem List.erase_append [LawfulBEq α] {a : α} {l₁ l₂ : List α} :
    (l₁ ++ l₂).erase a = if a ∈ l₁ then l₁.erase a ++ l₂ else l₁ ++ l₂.erase a := by sorry","Erasing Element from Concatenated Lists: \((l_1 ++ l_2) \setminus a = l_1 \setminus a ++ l_2\) if \(a \in l_1\), otherwise \((l_1 ++ l_2) \setminus a = l_1 ++ l_2 \setminus a\) : For any type \( \alpha \) and any element \( a \) of type \( \alpha \), the list obtained by erasing \( a \) from the concatenation \( l_1 ++ l_2 \) is equal to:
- \( l_1 \setminus a ++ l_2 \) if \( a \in l_1 \),
- \( l_1 ++ l_2 \setminus a \) if \( a \notin l_1 \).

Formally, for any lists \( l_1, l_2 \) of elements of type \( \alpha \):
\[
(l_1 ++ l_2) \setminus a = 
\begin{cases} 
l_1 \setminus a ++ l_2 & \text{if } a \in l_1 \\
l_1 ++ l_2 \setminus a & \text{if } a \notin l_1 
\end{cases}
\]","theorem List.erase_append [LawfulBEq α] {a : α} {l₁ l₂ : List α} :
    (l₁ ++ l₂).erase a = if a ∈ l₁ then l₁.erase a ++ l₂ else l₁ ++ l₂.erase a := by
  simp [erase_eq_eraseP, eraseP_append]","To prove the theorem, we start by using the equivalence that erasing the first occurrence of an element \( a \) from a list \( l \) is the same as erasing the first element that satisfies the predicate \( x \mapsto (x = a) \) from \( l \). This equivalence is given by the theorem:
\[ l \setminus a = \text{List.eraseP } (x \mapsto (x = a)) \, l \]

Next, we use the property of erasing the first element from a concatenated list. This property states that for any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), and a predicate \( p : \alpha \to \text{Bool} \):
\[ \text{List.eraseP } p \, (l_1 ++ l_2) = \begin{cases}
\text{List.eraseP } p \, l_1 ++ l_2 & \text{if } \exists a \in l_1, \, p(a) = \text{true} \\
l_1 ++ \text{List.eraseP } p \, l_2 & \text{otherwise}
\end{cases} \]

Applying these two theorems, we can simplify our goal to:
\[ (l_1 ++ l_2) \setminus a = \begin{cases}
l_1 \setminus a ++ l_2 & \text{if } a \in l_1 \\
l_1 ++ l_2 \setminus a & \text{if } a \notin l_1
\end{cases} \]

This completes the proof.","theorem List.erase_append [LawfulBEq α] {a : α} {l₁ l₂ : List α} :
    (l₁ ++ l₂).erase a = if a ∈ l₁ then l₁.erase a ++ l₂ else l₁ ++ l₂.erase a := by
/- Using the fact that erasing the first occurrence of an element \( a \) from a list \( l \) is equivalent to erasing the first element that satisfies the predicate \( x \mapsto (x = a) \) from \( l \), and the property of erasing the first element from a concatenated list, we can simplify the proposition we want to show. Specifically, we use the theorem that for any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), and a predicate \( p : \alpha \to \text{Bool} \):
\[ \text{List.eraseP } p \, (l_1 ++ l_2) = \begin{cases}
\text{List.eraseP } p \, l_1 ++ l_2 & \text{if } \exists a \in l_1, \, p(a) = \text{true} \\
l_1 ++ \text{List.eraseP } p \, l_2 & \text{otherwise}
\end{cases} \]
This simplifies our goal to:
\[ (l_1 ++ l_2) \setminus a = \begin{cases}
l_1 \setminus a ++ l_2 & \text{if } a \in l_1 \\
l_1 ++ l_2 \setminus a & \text{if } a \notin l_1
\end{cases} \] -/
  simp [erase_eq_eraseP, eraseP_append]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
533,List.eraseIdx_zero,theorem List.eraseIdx_zero (l : List α) : eraseIdx l 0 = tail l := by sorry,"List Erasure at Index Zero Equals Tail: \( l.\text{eraseIdx}(0) = l.\text{tail} \) : For any list \( l \) of elements of type \( \alpha \), removing the element at index 0 from \( l \) results in the tail of \( l \), i.e., \( l.\text{eraseIdx}(0) = l.\text{tail} \).","theorem List.eraseIdx_zero (l : List α) : eraseIdx l 0 = tail l := by
  cases l <;> rfl","We will consider every possible case of the list \( l \).

1. **Case 1:** If \( l \) is the empty list, then \( l.\text{eraseIdx}(0) \) is the empty list, and \( l.\text{tail} \) is also the empty list. Therefore, \( l.\text{eraseIdx}(0) = l.\text{tail} \) holds trivially.
2. **Case 2:** If \( l \) is a non-empty list, say \( l = \text{head} :: \text{tail} \), then \( l.\text{eraseIdx}(0) \) removes the first element (head) of the list, resulting in the list \( \text{tail} \). Similarly, \( l.\text{tail} \) is the list \( \text{tail} \) by definition. Therefore, \( l.\text{eraseIdx}(0) = l.\text{tail} \) holds trivially.

In both cases, the equality \( l.\text{eraseIdx}(0) = l.\text{tail} \) is satisfied. This completes the proof.","theorem List.eraseIdx_zero (l : List α) : eraseIdx l 0 = tail l := by
  cases l <;> rfl","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
534,List.erase_append_right,"theorem List.erase_append_right [LawfulBEq α] {a : α} {l₁ : List α} (l₂ : List α) (h : a ∉ l₁) :
    (l₁ ++ l₂).erase a = (l₁ ++ l₂.erase a) := by sorry","Erasing Element from Right List in Concatenation: \((l_1 ++ l_2). \text{erase } a = l_1 ++ l_2. \text{erase } a\) if \(a \notin l_1\) : For any type \( \alpha \) and any element \( a \) of type \( \alpha \), if \( a \) is not in the list \( l_1 \), then the list obtained by erasing \( a \) from the concatenation \( l_1 ++ l_2 \) is equal to the concatenation of \( l_1 \) and the list obtained by erasing \( a \) from \( l_2 \). Formally, if \( a \notin l_1 \), then \((l_1 ++ l_2). \text{erase } a = l_1 ++ l_2. \text{erase } a\).","theorem List.erase_append_right [LawfulBEq α] {a : α} {l₁ : List α} (l₂ : List α) (h : a ∉ l₁) :
    (l₁ ++ l₂).erase a = (l₁ ++ l₂.erase a) := by
  rw [erase_eq_eraseP, erase_eq_eraseP, eraseP_append_right]
  intros b h' h''; rw [eq_of_beq h''] at h; exact h h'","We start by noting that the operation of erasing the first occurrence of an element \(a\) from a list \(l\) using `List.erase` is equivalent to erasing the first element that satisfies the predicate \(x \mapsto (x = a)\) from \(l\) using `List.eraseP`. Therefore, the goal \((l_1 ++ l_2). \text{erase } a = l_1 ++ l_2. \text{erase } a\) can be rewritten as:
\[
\text{eraseP}(x \mapsto (x = a), l_1 ++ l_2) = l_1 ++ \text{eraseP}(x \mapsto (x = a), l_2)
\]

Next, we use the theorem that if no element in \(l_1\) satisfies the predicate \(p\), then \(\text{eraseP}(p, l_1 \oplus l_2) = l_1 \oplus \text{eraseP}(p, l_2)\). Since \(a \notin l_1\), this theorem applies, and our goal simplifies to:
\[
l_1 ++ \text{eraseP}(x \mapsto (x = a), l_2) = l_1 ++ \text{eraseP}(x \mapsto (x = a), l_2)
\]
This is trivially true by the properties of equality.

To complete the proof, we need to show that for every \(b \in \alpha\), if \(b \in l_1\), then \(\neg (a == b) = \text{true}\). We introduce a new variable \(b\) and assume \(b \in l_1\) and \(\neg (a == b) = \text{true}\). Using the theorem that if \(\neg (a == b) = \text{true}\), then \(a \neq b\), we can transform our assumption \(\neg (a == b) = \text{true}\) into \(a \neq b\). Since \(a \notin l_1\) by our initial hypothesis, and \(b \in l_1\), it follows that \(a \neq b\). Therefore, the assumption \(\neg (a == b) = \text{true}\) is satisfied, and the goal is trivially true.

This completes the proof.","theorem List.erase_append_right [LawfulBEq α] {a : α} {l₁ : List α} (l₂ : List α) (h : a ∉ l₁) :
    (l₁ ++ l₂).erase a = (l₁ ++ l₂.erase a) := by
/- First, we use the equivalence that erasing the first occurrence of an element \(a\) from a list \(l\) using `List.erase` is the same as erasing the first element that satisfies the predicate \(x \mapsto (x = a)\) from \(l\) using `List.eraseP`. This allows us to rewrite the goal \((l_1 ++ l_2). \text{erase } a = l_1 ++ l_2. \text{erase } a\) as \(\text{eraseP}(x \mapsto (x = a), l_1 ++ l_2) = l_1 ++ \text{eraseP}(x \mapsto (x = a), l_2)\). Next, we use the theorem that if no element in \(l_1\) satisfies the predicate \(p\), then \(\text{eraseP}(p, l_1 \oplus l_2) = l_1 \oplus \text{eraseP}(p, l_2)\). Since \(a \notin l_1\), this theorem applies, and our goal simplifies to \(l_1 ++ \text{eraseP}(x \mapsto (x = a), l_2) = l_1 ++ \text{eraseP}(x \mapsto (x = a), l_2)\). This is trivially true by the properties of equality. -/
  rw [erase_eq_eraseP, erase_eq_eraseP, eraseP_append_right]
/- To prove the remaining goal \(\forall b \in \alpha, b \in l_1 \rightarrow \neg (a == b) = \text{true}\), we introduce a new variable \(b\) and assume \(b \in l_1\) and \(\neg (a == b) = \text{true}\). Using the theorem that if \(\neg (a == b) = \text{true}\), then \(a \neq b\), we can transform our assumption \(\neg (a == b) = \text{true}\) into \(a \neq b\). Since \(a \notin l_1\) by our initial hypothesis, and \(b \in l_1\), it follows that \(a \neq b\). Therefore, the assumption \(\neg (a == b) = \text{true}\) is satisfied, and the goal is trivially true. -/
  intros b h' h''; rw [eq_of_beq h''] at h; exact h h'","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
538,List.erase_comm,"theorem List.erase_comm [LawfulBEq α] (a b : α) (l : List α) :
    (l.erase a).erase b = (l.erase b).erase a := by sorry","Commutativity of List Erasure: \((l \setminus a) \setminus b = (l \setminus b) \setminus a\) : For any list \( l \) of elements of type \( \alpha \) and any elements \( a, b \in \alpha \), the operation of erasing \( a \) from \( l \) and then erasing \( b \) from the resulting list is the same as erasing \( b \) from \( l \) and then erasing \( a \) from the resulting list. In other words, the order in which elements are erased from a list does not affect the final result. Formally, for any \( a, b \in \alpha \) and any list \( l \):
\[
(l \setminus a) \setminus b = (l \setminus b) \setminus a
\]
where \( l \setminus x \) denotes the list obtained by removing the first occurrence of \( x \) from \( l \).","theorem List.erase_comm [LawfulBEq α] (a b : α) (l : List α) :
    (l.erase a).erase b = (l.erase b).erase a := by
  if ab : a == b then rw [eq_of_beq ab] else ?_
  if ha : a ∈ l then ?_ else
    simp only [erase_of_not_mem ha, erase_of_not_mem (mt mem_of_mem_erase ha)]
  if hb : b ∈ l then ?_ else
    simp only [erase_of_not_mem hb, erase_of_not_mem (mt mem_of_mem_erase hb)]
  match l, l.erase a, exists_erase_eq ha with
  | _, _, ⟨l₁, l₂, ha', rfl, rfl⟩ =>
    if h₁ : b ∈ l₁ then
      rw [erase_append_left _ h₁, erase_append_left _ h₁,
          erase_append_right _ (mt mem_of_mem_erase ha'), erase_cons_head]
    else
      rw [erase_append_right _ h₁, erase_append_right _ h₁, erase_append_right _ ha',
          erase_cons_tail ab, erase_cons_head]","We start by considering the cases based on the equality and membership of \( a \) and \( b \) in the list \( l \).

1. **Case 1: \( a = b \)**
- If \( a \) and \( b \) are equal, then by the property that boolean equality implies true equality, we can replace \( b \) with \( a \) in the goal. This simplifies the goal to:
\[
(l \setminus a) \setminus a = (l \setminus a) \setminus a
\]
which is trivially true.

2. **Case 2: \( a \notin l \)**
- If \( a \) is not in \( l \), then by the property that erasing a non-member element from a list leaves the list unchanged, we have:
\[
l \setminus a = l
\]
Similarly, since \( a \) is not in \( l \), \( a \) cannot be in \( l \setminus b \) (by the property that membership in a list after erasing an element implies original membership), and thus:
\[
(l \setminus b) \setminus a = l \setminus b
\]
Therefore, the goal simplifies to:
\[
l \setminus b = l \setminus b
\]
which is trivially true.

3. **Case 3: \( b \notin l \)**
- If \( b \) is not in \( l \), then by the property that erasing a non-member element from a list leaves the list unchanged, we have:
\[
l \setminus b = l
\]
Similarly, since \( b \) is not in \( l \), \( b \) cannot be in \( l \setminus a \) (by the property that membership in a list after erasing an element implies original membership), and thus:
\[
(l \setminus a) \setminus b = l \setminus a
\]
Therefore, the goal simplifies to:
\[
l \setminus a = l \setminus a
\]
which is trivially true.

4. **Case 4: \( a \in l \) and \( b \in l \)**
- If both \( a \) and \( b \) are in \( l \), we can decompose \( l \) into \( l_1 \) and \( l_2 \) such that \( l = l_1 ++ a :: l_2 \) and \( b \in l_1 \). Using the property that erasing an element from the right of an append operation leaves the left part unchanged, we have:
\[
(l_1 ++ a :: l_2) \setminus b = l_1 \setminus b ++ a :: l_2
\]
Similarly, we can apply this property to the resulting list:
\[
(l_1 \setminus b ++ a :: l_2) \setminus a = (l_1 \setminus b) \setminus a ++ l_2
\]
On the other hand, we also have:
\[
(l_1 ++ a :: l_2) \setminus a = l_1 ++ l_2
\]
and:
\[
(l_1 ++ l_2) \setminus b = (l_1 \setminus b) ++ l_2
\]
Thus, the goal simplifies to:
\[
(l_1 \setminus b) \setminus a ++ l_2 = (l_1 \setminus b) \setminus a ++ l_2
\]
which is trivially true.

In all cases, the goal is satisfied, and thus we have shown that the order in which elements are erased from a list does not affect the final result. This completes the proof.","theorem List.erase_comm [LawfulBEq α] (a b : α) (l : List α) :
    (l.erase a).erase b = (l.erase b).erase a := by
/- First, we consider the case where \( a \) and \( b \) are equal. If \( a \) and \( b \) are equal, then by the property that boolean equality implies true equality, we can replace \( b \) with \( a \) in the goal. This simplifies the goal to \((l \setminus a) \setminus a = (l \setminus a) \setminus a\), which is trivially true. Therefore, the goal is satisfied in this case. -/
  if ab : a == b then rw [eq_of_beq ab] else ?_
/- Next, we consider the case where \( a \) is not in the list \( l \). If \( a \) is not in \( l \), then by the property that erasing a non-member element from a list leaves the list unchanged, we have \( l \setminus a = l \). Similarly, since \( a \) is not in \( l \), \( a \) cannot be in \( l \setminus b \) (by the property that membership in a list after erasing an element implies original membership), and thus \( (l \setminus b) \setminus a = l \setminus b \). Therefore, the goal simplifies to \( l \setminus b = l \setminus b \), which is trivially true. -/
  if ha : a ∈ l then ?_ else
    simp only [erase_of_not_mem ha, erase_of_not_mem (mt mem_of_mem_erase ha)]
/- Now, we consider the case where \( b \) is not in the list \( l \). If \( b \) is not in \( l \), then by the property that erasing a non-member element from a list leaves the list unchanged, we have \( l \setminus b = l \). Similarly, since \( b \) is not in \( l \), \( b \) cannot be in \( l \setminus a \) (by the property that membership in a list after erasing an element implies original membership), and thus \( (l \setminus a) \setminus b = l \setminus a \). Therefore, the goal simplifies to \( l \setminus a = l \setminus a \), which is trivially true. -/
  if hb : b ∈ l then ?_ else
    simp only [erase_of_not_mem hb, erase_of_not_mem (mt mem_of_mem_erase hb)]
  match l, l.erase a, exists_erase_eq ha with
  | _, _, ⟨l₁, l₂, ha', rfl, rfl⟩ =>
    if h₁ : b ∈ l₁ then
      rw [erase_append_left _ h₁, erase_append_left _ h₁,
          erase_append_right _ (mt mem_of_mem_erase ha'), erase_cons_head]
/- Finally, we consider the case where both \( a \) and \( b \) are in the list \( l \). We can decompose \( l \) into \( l_1 \) and \( l_2 \) such that \( l = l_1 ++ a :: l_2 \) and \( b \in l_1 \). Using the property that erasing an element from the right of an append operation leaves the left part unchanged, we have:
\[
(l_1 ++ a :: l_2) \setminus b = l_1 \setminus b ++ a :: l_2
\]
Similarly, we can apply this property to the resulting list:
\[
(l_1 \setminus b ++ a :: l_2) \setminus a = (l_1 \setminus b) \setminus a ++ l_2
\]
On the other hand, we also have:
\[
(l_1 ++ a :: l_2) \setminus a = l_1 ++ l_2
\]
and:
\[
(l_1 ++ l_2) \setminus b = (l_1 \setminus b) ++ l_2
\]
Thus, the goal simplifies to:
\[
(l_1 \setminus b) \setminus a ++ l_2 = (l_1 \setminus b) \setminus a ++ l_2
\]
which is trivially true. -/
    else
      rw [erase_append_right _ h₁, erase_append_right _ h₁, erase_append_right _ ha',
          erase_cons_tail ab, erase_cons_head]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
539,List.eraseIdx_append_of_length_le,"theorem List.eraseIdx_append_of_length_le {l : List α} {k : Nat} (hk : length l ≤ k) (l' : List α) :
    eraseIdx (l ++ l') k = l ++ eraseIdx l' (k - length l) := by sorry","Erasing Element Beyond List Length in Appended Lists : For any list \( l \) of elements of type \( \alpha \) and any natural number \( k \), if the length of \( l \) is less than or equal to \( k \), then for any list \( l' \) of elements of type \( \alpha \), the list obtained by appending \( l' \) to \( l \) and then erasing the element at index \( k \) is equal to the list obtained by appending \( l \) to the list \( l' \) with the element at index \( k - \text{length}(l) \) erased. Formally, if \( \text{length}(l) \leq k \), then for any \( l' \), \((l ++ l').\text{eraseIdx}(k) = l ++ l'.\text{eraseIdx}(k - \text{length}(l))\).","theorem List.eraseIdx_append_of_length_le {l : List α} {k : Nat} (hk : length l ≤ k) (l' : List α) :
    eraseIdx (l ++ l') k = l ++ eraseIdx l' (k - length l) := by
  induction l generalizing k with
  | nil => simp_all
  | cons x l ih =>
    cases k with
    | zero => simp_all
    | succ k => simp_all [eraseIdx_cons_succ, Nat.succ_sub_succ]","We will prove the theorem by induction on the list \( l \).

1. **Base Case: \( l \) is empty.**
- Consider the case where the list \( l \) is empty. Using the properties of list length and the definition of `eraseIdx`, we can simplify the goal to show that \(([] ++ l').\text{eraseIdx}(k) = [] ++ l'.\text{eraseIdx}(k - 0)\). Since the length of the empty list is \(0\), this simplifies to \(([] ++ l').\text{eraseIdx}(k) = l'.\text{eraseIdx}(k)\), which is trivially true.

2. **Inductive Step: \( l \) is non-empty.**
- Consider the case where the list \( l \) is non-empty, i.e., \( l = x :: l_1 \) for some element \( x \) and list \( l_1 \). We will use induction on the length of \( l \) and assume the inductive hypothesis \( \text{ih} \), which states that for any natural number \( k \), if \( \text{length}(l_1) \leq k \), then \((l_1 ++ l').\text{eraseIdx}(k) = l_1 ++ l'.\text{eraseIdx}(k - \text{length}(l_1))\).

- **Subcase: \( k = 0 \)**
- Consider the subcase where \( k = 0 \). Using the properties of list length and the definition of `eraseIdx`, we can simplify the goal to show that \((x :: l_1 ++ l').\text{eraseIdx}(0) = x :: l_1 ++ l'.\text{eraseIdx}(0 - \text{length}(x :: l_1))\). Since \(\text{length}(x :: l_1) = \text{length}(l_1) + 1\), this simplifies to \((x :: l_1 ++ l').\text{eraseIdx}(0) = x :: l_1 ++ l'.\text{eraseIdx}(-1)\), which is trivially true because erasing an element at a negative index does not change the list.

- **Subcase: \( k = k' + 1 \) for some natural number \( k' \)**
- Consider the subcase where \( k = k' + 1 \) for some natural number \( k' \). Using the properties of list length and the definition of `eraseIdx`, we can simplify the goal to show that \((x :: l_1 ++ l').\text{eraseIdx}(k' + 1) = x :: l_1 ++ l'.\text{eraseIdx}((k' + 1) - (\text{length}(x :: l_1)))\). Since \(\text{length}(x :: l_1) = \text{length}(l_1) + 1\), this simplifies to \((x :: l_1 ++ l').\text{eraseIdx}(k' + 1) = x :: l_1 ++ l'.\text{eraseIdx}(k' - \text{length}(l_1))\). By the inductive hypothesis, we know that \((l_1 ++ l').\text{eraseIdx}(k') = l_1 ++ l'.\text{eraseIdx}(k' - \text{length}(l_1))\), and thus the goal is satisfied.

This completes the proof.","theorem List.eraseIdx_append_of_length_le {l : List α} {k : Nat} (hk : length l ≤ k) (l' : List α) :
    eraseIdx (l ++ l') k = l ++ eraseIdx l' (k - length l) := by
  induction l generalizing k with
/- Consider the case where the list \( l \) is empty. Using the properties of list length and the definition of `eraseIdx`, we can simplify the goal to show that \(([] ++ l').\text{eraseIdx}(k) = [] ++ l'.\text{eraseIdx}(k - 0)\). Since the length of the empty list is \(0\), this simplifies to \(([] ++ l').\text{eraseIdx}(k) = l'.\text{eraseIdx}(k)\), which is trivially true. -/
  | nil => simp_all
/- Consider the case where the list \( l \) is non-empty, i.e., \( l = x :: l_1 \) for some element \( x \) and list \( l_1 \). We will use induction on the length of \( l \) and assume the inductive hypothesis \( \text{ih} \), which states that for any natural number \( k \), if \( \text{length}(l_1) \leq k \), then \((l_1 ++ l').\text{eraseIdx}(k) = l_1 ++ l'.\text{eraseIdx}(k - \text{length}(l_1))\). -/
  | cons x l ih =>
    cases k with
/- Consider the subcase where \( k = 0 \). Using the properties of list length and the definition of `eraseIdx`, we can simplify the goal to show that \((x :: l_1 ++ l').\text{eraseIdx}(0) = x :: l_1 ++ l'.\text{eraseIdx}(0 - \text{length}(x :: l_1))\). Since \(\text{length}(x :: l_1) = \text{length}(l_1) + 1\), this simplifies to \((x :: l_1 ++ l').\text{eraseIdx}(0) = x :: l_1 ++ l'.\text{eraseIdx}(-1)\), which is trivially true because erasing an element at a negative index does not change the list. -/
    | zero => simp_all
/- Consider the subcase where \( k = k' + 1 \) for some natural number \( k' \). Using the properties of list length and the definition of `eraseIdx`, we can simplify the goal to show that \((x :: l_1 ++ l').\text{eraseIdx}(k' + 1) = x :: l_1 ++ l'.\text{eraseIdx}((k' + 1) - (\text{length}(x :: l_1)))\). Since \(\text{length}(x :: l_1) = \text{length}(l_1) + 1\), this simplifies to \((x :: l_1 ++ l').\text{eraseIdx}(k' + 1) = x :: l_1 ++ l'.\text{eraseIdx}(k' - \text{length}(l_1))\). By the inductive hypothesis, we know that \((l_1 ++ l').\text{eraseIdx}(k') = l_1 ++ l'.\text{eraseIdx}(k' - \text{length}(l_1))\), and thus the goal is satisfied. -/
    | succ k => simp_all [eraseIdx_cons_succ, Nat.succ_sub_succ]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
540,List.eraseIdx_append_of_lt_length,"theorem List.eraseIdx_append_of_lt_length {l : List α} {k : Nat} (hk : k < length l) (l' : List α) :
    eraseIdx (l ++ l') k = eraseIdx l k ++ l' := by sorry","Erasing Element from Appended List: \((l \oplus l') \setminus k = (l \setminus k) \oplus l'\) for \( k < \text{length}(l) \) : For any list \( l \) of elements of type \( \alpha \) and any natural number \( k \) such that \( k < \text{length}(l) \), and for any list \( l' \) of elements of type \( \alpha \), the list obtained by appending \( l' \) to \( l \) and then erasing the element at index \( k \) is equal to the list obtained by first erasing the element at index \( k \) from \( l \) and then appending \( l' \). In other words, if \( k \) is less than the length of \( l \), then \((l \oplus l') \setminus k = (l \setminus k) \oplus l'\).","theorem List.eraseIdx_append_of_lt_length {l : List α} {k : Nat} (hk : k < length l) (l' : List α) :
    eraseIdx (l ++ l') k = eraseIdx l k ++ l' := by
  induction l generalizing k with
  | nil => simp_all
  | cons x l ih =>
    cases k with
    | zero => rfl
    | succ k => simp_all [eraseIdx_cons_succ, Nat.succ_lt_succ_iff]","We will prove the theorem by induction on the list \( l \).

1. **Base Case: \( l = [] \)**
- Consider the case where the list \( l \) is empty. Using the properties of the length of an empty list and the definition of `eraseIdx`, we can simplify the goal to show that \(([] \oplus l') \setminus k = [] \setminus k \oplus l'\). Since the length of the empty list is \(0\), the assumption \( k < \text{length}([]) \) is false, and thus the goal is trivially true.

2. **Inductive Step: \( l = x :: l \)**
- Perform induction on the list \( l \) and consider the case where \( l \) is of the form \( x :: l \) (i.e., \( l \) is a non-empty list with head \( x \) and tail \( l \)). The induction hypothesis \( \text{ih} \) states that for any natural number \( k \) such that \( k < \text{length}(l) \), and for any list \( l' \), the property \((l \oplus l') \setminus k = (l \setminus k) \oplus l'\) holds.
- **Subcase: \( k = 0 \)**
- Consider the case where \( k = 0 \). The goal is to show that \((x :: l \oplus l') \setminus 0 = (x :: l) \setminus 0 \oplus l'\). By the definition of `eraseIdx`, erasing the element at index \(0\) from \( x :: l \) results in \( l \), and thus the left-hand side simplifies to \( l \oplus l' \) and the right-hand side simplifies to \( l \oplus l' \). Therefore, the goal is trivially true due to the reflexive property of equality.
- **Subcase: \( k = k' + 1 \)**
- Consider the case where \( k = k' + 1 \) for some natural number \( k' \). Using the properties of `eraseIdx` for a list with a head and a tail, and the fact that \( k' + 1 < \text{length}(x :: l) \) is equivalent to \( k' < \text{length}(l) \), we can simplify the goal to show that \((x :: l \oplus l') \setminus (k' + 1) = (x :: l) \setminus (k' + 1) \oplus l'\). By the induction hypothesis, this simplifies to \((l \oplus l') \setminus k' = (l \setminus k') \oplus l'\), which is true by the induction hypothesis.

This completes the proof by induction. Therefore, for any list \( l \) of elements of type \( \alpha \) and any natural number \( k \) such that \( k < \text{length}(l) \), and for any list \( l' \) of elements of type \( \alpha \), the property \((l \oplus l') \setminus k = (l \setminus k) \oplus l'\) holds.","theorem List.eraseIdx_append_of_lt_length {l : List α} {k : Nat} (hk : k < length l) (l' : List α) :
    eraseIdx (l ++ l') k = eraseIdx l k ++ l' := by
  induction l generalizing k with
/- Consider the case where the list \( l \) is empty. Using the properties of the length of an empty list and the definition of `eraseIdx`, we can simplify the goal to show that \(([] \oplus l') \setminus k = [] \setminus k \oplus l'\). Since the length of the empty list is \(0\), the assumption \( k < \text{length}([]) \) is false, and thus the goal is trivially true. -/
  | nil => simp_all
/- Perform induction on the list \( l \) and consider the case where \( l \) is of the form \( x :: l \) (i.e., \( l \) is a non-empty list with head \( x \) and tail \( l \)). The induction hypothesis \( \text{ih} \) states that for any natural number \( k \) such that \( k < \text{length}(l) \), and for any list \( l' \), the property \((l \oplus l') \setminus k = (l \setminus k) \oplus l'\) holds. -/
  | cons x l ih =>
    cases k with
/- Consider the case where \( k = 0 \). The goal is to show that \((x :: l \oplus l') \setminus 0 = (x :: l) \setminus 0 \oplus l'\). By the definition of `eraseIdx`, erasing the element at index \(0\) from \( x :: l \) results in \( l \), and thus the left-hand side simplifies to \( l \oplus l' \) and the right-hand side simplifies to \( l \oplus l' \). Therefore, the goal is trivially true due to the reflexive property of equality. -/
    | zero => rfl
/- Consider the case where \( k = k' + 1 \) for some natural number \( k' \). Using the properties of `eraseIdx` for a list with a head and a tail, and the fact that \( k' + 1 < \text{length}(x :: l) \) is equivalent to \( k' < \text{length}(l) \), we can simplify the goal to show that \((x :: l \oplus l') \setminus (k' + 1) = (x :: l) \setminus (k' + 1) \oplus l'\). By the induction hypothesis, this simplifies to \((l \oplus l') \setminus k' = (l \setminus k') \oplus l'\), which is true by the induction hypothesis. -/
    | succ k => simp_all [eraseIdx_cons_succ, Nat.succ_lt_succ_iff]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
544,List.Nodup.erase_eq_filter,theorem List.Nodup.erase_eq_filter [LawfulBEq α] {l} (d : Nodup l) (a : α) : l.erase a = l.filter (· != a) := by sorry,"Erase First Occurrence Equals Filter for Unique Lists: \( l.\text{erase}(a) = \text{filter}(\lambda x. x \neq a, l) \) for \( l \) with no duplicates : For any list \( l \) of elements of type \( \alpha \) that has no duplicate elements (i.e., \( l \) is a list with unique elements), and for any element \( a \) of type \( \alpha \), the list obtained by erasing the first occurrence of \( a \) from \( l \) is equal to the list obtained by filtering out all occurrences of \( a \) from \( l \). Formally, if \( l \) is a list with no duplicates, then \( l.\text{erase}(a) = \text{filter}(\lambda x. x \neq a, l) \).","theorem List.Nodup.erase_eq_filter [LawfulBEq α] {l} (d : Nodup l) (a : α) : l.erase a = l.filter (· != a) := by
  induction d with
  | nil => rfl
  | cons m _n ih =>
    rename_i b l
    by_cases h : b = a
    · subst h
      rw [erase_cons_head, filter_cons_of_neg (by simp)]
      apply Eq.symm
      rw [filter_eq_self]
      simpa [@eq_comm α] using m
    · simp [beq_false_of_ne h, ih, h]","We start by noting that the assumption that the cardinality of \( n \) is zero is equivalent to \( n \) being empty. Therefore, we convert the assumption \( \text{card}(n) = 0 \) into \( n \) is empty.

To prove that the determinant of \( M \) is \( 1 \), it suffices to show that \( M = 1 \) (the identity matrix). Using extensionality, we only need to show that \( M i = 1 i \) for every \( i \in n \).

Since \( n \) is empty, the statement \( M i = 1 i \) holds for every \( i \in n \) vacuously. Therefore, \( M = 1 \), and the determinant of \( M \) is \( \det M = \det 1 = 1 \).

This completes the proof.","theorem List.Nodup.erase_eq_filter [LawfulBEq α] {l} (d : Nodup l) (a : α) : l.erase a = l.filter (· != a) := by
/- First, we use the equivalence that the cardinality of a finite type is zero if and only if the type is empty, to convert the assumption that the cardinality of \( n \) is zero into the assumption that \( n \) is empty. -/
/- It suffices to show that \( M = 1 \) (the identity matrix), because if this is true, by simplifying, we get that the determinant of \( M \) is \( 1 \). -/
/- Using extensionality, to prove that \( M = 1 \), we only need to show that \( M i = 1 i \) for every \( i \in n \). -/
/- Since \( n \) is empty, the statement \( M i = 1 i \) holds for every \( i \in n \) vacuously. This completes the proof. -/
  induction d with
  | nil => rfl
  | cons m _n ih =>
    rename_i b l
    by_cases h : b = a
    · subst h
      rw [erase_cons_head, filter_cons_of_neg (by simp)]
      apply Eq.symm
      rw [filter_eq_self]
      simpa [@eq_comm α] using m
    · simp [beq_false_of_ne h, ih, h]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nodup
open Nat
variable [BEq α]
"
547,List.erase_eq_iff,"theorem List.erase_eq_iff [LawfulBEq α] {a : α} {l : List α} :
    l.erase a = l' ↔
      (a ∉ l ∧ l = l') ∨
        ∃ l₁ l₂, a ∉ l₁ ∧ l = l₁ ++ a :: l₂ ∧ l' = l₁ ++ l₂ := by sorry","Erase Equals List if and only if Element Not in List or List Split Condition : For any type \( \alpha \) and lists \( l, l' \) of elements of type \( \alpha \), and for any element \( a \) of type \( \alpha \), the list \( l \) with the first occurrence of \( a \) erased is equal to \( l' \) if and only if \( a \) is not in \( l \) and \( l = l' \), or there exist lists \( l_1 \) and \( l_2 \) such that \( a \) is not in \( l_1 \), \( l = l_1 ++ [a] ++ l_2 \), and \( l' = l_1 ++ l_2 \).","theorem List.erase_eq_iff [LawfulBEq α] {a : α} {l : List α} :
    l.erase a = l' ↔
      (a ∉ l ∧ l = l') ∨
        ∃ l₁ l₂, a ∉ l₁ ∧ l = l₁ ++ a :: l₂ ∧ l' = l₁ ++ l₂ := by
  rw [erase_eq_eraseP', eraseP_eq_iff]
  simp only [beq_iff_eq, forall_mem_ne', exists_and_left]
  constructor
  · rintro (⟨h, rfl⟩ | ⟨a', l', h, rfl, x, rfl, rfl⟩)
    · left; simp_all
    · right; refine ⟨l', h, x, by simp⟩
  · rintro (⟨h, rfl⟩ | ⟨l₁, h, x, rfl, rfl⟩)
    · left; simp_all
    · right; refine ⟨a, l₁, h, by simp⟩","We start by using the equivalence that erasing the first occurrence of an element \(a\) from a list \(l\) using the `List.erase` function is the same as erasing the first element that satisfies the predicate \(x \mapsto (x = a)\) from \(l\) using the `List.eraseP` function. This transforms our goal into:
\[ (\forall a_1 \in l, a_1 \neq a) \land l = l' \lor \exists a_1, l_1, l_2, (\forall b \in l_1, b \neq a) \land a_1 = a \land l = l_1 ++ [a_1] ++ l_2 \land l' = l_1 ++ l_2 \]

Next, we simplify the goal using the fact that boolean equality \(a_1 == a\) is equivalent to logical equality \(a_1 = a\), and the properties of existential quantification and conjunction. This simplifies our goal to:
\[ (\neg a \in l \land l = l') \lor (\exists l_1, \neg a \in l_1 \land \exists x, l = l_1 ++ [a] ++ x \land l' = l_1 ++ x) \]

To prove the equivalence, we need to show both directions. We start with the forward direction.

1. **Case 1:** Suppose \(a\) is not in \(l\) and \(l = l'\). Then, the left side of the disjunction holds, and we have:
\[ \neg a \in l \land l = l \]
which is trivially true.

2. **Case 2:** Suppose there exist lists \(l_1\) and \(x\) such that \(a\) is not in \(l_1\), \(a = a\), \(l = l_1 ++ [a] ++ x\), and \(l' = l_1 ++ x\). Then, the right side of the disjunction holds. We construct the existential proof by providing \(a\), \(l_1\), and \(x\), and simplifying the remaining conditions, which are trivially true.

Now, we move to the backward direction.

1. **Case 1:** Suppose \(a\) is not in \(l\) and \(l = l'\). Then, the left side of the disjunction holds, and we have:
\[ \neg a \in l \land l = l \]
which is trivially true.

2. **Case 2:** Suppose there exist lists \(l_1\) and \(x\) such that \(a\) is not in \(l_1\), \(a = a\), \(l = l_1 ++ [a] ++ x\), and \(l' = l_1 ++ x\). Then, the right side of the disjunction holds. We construct the existential proof by providing \(a\), \(l_1\), and \(x\), and simplifying the remaining conditions, which are trivially true.

Thus, we have shown both directions of the equivalence, completing the proof.","theorem List.erase_eq_iff [LawfulBEq α] {a : α} {l : List α} :
    l.erase a = l' ↔
      (a ∉ l ∧ l = l') ∨
        ∃ l₁ l₂, a ∉ l₁ ∧ l = l₁ ++ a :: l₂ ∧ l' = l₁ ++ l₂ := by
/- First, we use the equivalence that erasing the first occurrence of an element \(a\) from a list \(l\) using the `List.erase` function is the same as erasing the first element that satisfies the predicate \(x \mapsto (x = a)\) from \(l\) using the `List.eraseP` function. Then, we use the equivalence that the list \(l\) with the first occurrence of \(a\) erased is equal to \(l'\) if and only if \(a\) is not in \(l\) and \(l = l'\), or there exist lists \(l_1\) and \(l_2\) such that \(a\) is not in \(l_1\), \(l = l_1 ++ [a] ++ l_2\), and \(l' = l_1 ++ l_2\). This transforms our goal into the equivalent form:
\[ (\forall a_1 \in l, a_1 \neq a) \land l = l' \lor \exists a_1, l_1, l_2, (\forall b \in l_1, b \neq a) \land a_1 = a \land l = l_1 ++ [a_1] ++ l_2 \land l' = l_1 ++ l_2 \] -/
  rw [erase_eq_eraseP', eraseP_eq_iff]
/- Using the fact that boolean equality \(a_1 == a\) is equivalent to logical equality \(a_1 = a\), and the properties of existential quantification and conjunction, we simplify the goal to:
\[ (\neg a \in l \land l = l') \lor (\exists l_1, \neg a \in l_1 \land \exists x, l = l_1 ++ [a] ++ x \land l' = l_1 ++ x) \] -/
  simp only [beq_iff_eq, forall_mem_ne', exists_and_left]
/- To prove the equivalence, we need to show both directions. We start by proving the forward direction. -/
  constructor
/- Let \(h\) be the hypothesis that \(a\) is not in \(l\) and \(l = l'\), or let \(a'\), \(l_1\), and \(x\) be such that \(a'\) is not in \(l_1\), \(a' = a\), \(l = l_1 ++ [a] ++ x\), and \(l' = l_1 ++ x\). We discuss these cases separately. -/
  · rintro (⟨h, rfl⟩ | ⟨a', l', h, rfl, x, rfl, rfl⟩)
/- In the first case, where \(a\) is not in \(l\) and \(l = l'\), we show that the left side of the disjunction holds. After simplifying, we get:
\[ \neg a \in l \land l = l \]
which is trivially true. -/
    · left; simp_all
    · right; refine ⟨l', h, x, by simp⟩
/- Let \(h\) be the hypothesis that \(a\) is not in \(l\) and \(l = l'\), or let \(l_1\) and \(x\) be such that \(a\) is not in \(l_1\), \(a = a\), \(l = l_1 ++ [a] ++ x\), and \(l' = l_1 ++ x\). We discuss these cases separately. -/
  · rintro (⟨h, rfl⟩ | ⟨l₁, h, x, rfl, rfl⟩)
/- In the first case, where \(a\) is not in \(l\) and \(l = l'\), we show that the left side of the disjunction holds. After simplifying, we get:
\[ \neg a \in l \land l = l \]
which is trivially true. -/
    · left; simp_all
/- In the second case, where \(a\) is not in \(l_1\), \(a = a\), \(l = l_1 ++ [a] ++ x\), and \(l' = l_1 ++ x\), we show that the right side of the disjunction holds. We construct the existential proof by providing \(a\), \(l_1\), and \(x\), and simplifying the remaining conditions, which are trivially true. -/
/- In the second case, where \(a\) is not in \(l_1\), \(a = a\), \(l = l_1 ++ [a] ++ x\), and \(l' = l_1 ++ x\), we show that the right side of the disjunction holds. We construct the existential proof by providing \(a\), \(l_1\), and \(x\), and simplifying the remaining conditions, which are trivially true. -/
    · right; refine ⟨a, l₁, h, by simp⟩","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
variable [BEq α]
"
1378,Nat.compare_swap,theorem Nat.compare_swap (a b : Nat) : (compare a b).swap = compare b a := by sorry,"Swapping Comparison Results in Natural Numbers : For any natural numbers \( a \) and \( b \), the result of swapping the comparison between \( a \) and \( b \) is the same as the comparison between \( b \) and \( a \). In other words, if \( \text{compare}(a, b) \) returns an ordering, then \( \text{compare}(a, b). \text{swap} \) is equal to \( \text{compare}(b, a) \).","theorem Nat.compare_swap (a b : Nat) : (compare a b).swap = compare b a := by
  simp only [compare_def_le]; (repeat' split) <;> try rfl
  next h1 h2 => cases h1 (Nat.le_of_not_le h2)","We start by using the definition of the comparison function for natural numbers, which states:
\[
\text{compare}(a, b) =
\begin{cases}
\text{Ordering.eq} & \text{if } a \le b \text{ and } b \le a \\
\text{Ordering.lt} & \text{if } a \le b \text{ and } \neg b \le a \\
\text{Ordering.gt} & \text{if } \neg a \le b
\end{cases}
\]
We need to show that:
\[
\text{compare}(a, b). \text{swap} = \text{compare}(b, a)
\]
We will discuss by cases based on the conditions \(a \le b\) and \(b \le a\).

1. **Case 1:** \(a \le b\) and \(b \le a\)
- In this case, \(\text{compare}(a, b) = \text{Ordering.eq}\).
- Therefore, \(\text{compare}(a, b). \text{swap} = \text{Ordering.eq.swap} = \text{Ordering.eq}\).
- Since \(\text{compare}(b, a) = \text{Ordering.eq}\), the equality holds trivially.

2. **Case 2:** \(a \le b\) and \(\neg b \le a\)
- In this case, \(\text{compare}(a, b) = \text{Ordering.lt}\).
- Therefore, \(\text{compare}(a, b). \text{swap} = \text{Ordering.lt.swap} = \text{Ordering.gt}\).
- Since \(\text{compare}(b, a) = \text{Ordering.gt}\), the equality holds trivially.

3. **Case 3:** \(\neg a \le b\) and \(b \le a\)
- In this case, \(\text{compare}(a, b) = \text{Ordering.gt}\).
- Therefore, \(\text{compare}(a, b). \text{swap} = \text{Ordering.gt.swap} = \text{Ordering.lt}\).
- Since \(\text{compare}(b, a) = \text{Ordering.lt}\), the equality holds trivially.

4. **Case 4:** \(\neg a \le b\) and \(\neg b \le a\)
- In this case, \(\text{compare}(a, b) = \text{Ordering.gt}\).
- Therefore, \(\text{compare}(a, b). \text{swap} = \text{Ordering.gt.swap} = \text{Ordering.gt}\).
- Since \(\text{compare}(b, a) = \text{Ordering.gt}\), the equality holds trivially.

In each case, the equality \(\text{compare}(a, b). \text{swap} = \text{compare}(b, a)\) holds due to the reflexive property of equality. This completes the proof.","theorem Nat.compare_swap (a b : Nat) : (compare a b).swap = compare b a := by
/- Using the definition of the comparison function for natural numbers, we can simplify the proposition we want to show to:
\[
\text{if } a \le b \text{ then } \text{if } b \le a \text{ then } \text{Ordering.eq} \text{ else } \text{Ordering.lt} \text{ else } \text{Ordering.gt} \text{.swap} = \text{if } b \le a \text{ then } \text{if } a \le b \text{ then } \text{Ordering.eq} \text{ else } \text{Ordering.lt} \text{ else } \text{Ordering.gt}
\]
We then discuss by cases based on the conditions \(a \le b\) and \(b \le a\). -/
  simp only [compare_def_le]; (repeat' split) <;> try rfl
/- We will consider each case separately:
1. **Case 1:** \(a \le b\) and \(b \le a\)
- In this case, we need to show that \(\text{Ordering.eq.swap} = \text{Ordering.eq}\).
- The current goal is trivially true due to the reflexive property.
2. **Case 2:** \(a \le b\) and \(\neg b \le a\)
- In this case, we need to show that \(\text{Ordering.lt.swap} = \text{Ordering.gt}\).
- The current goal is trivially true due to the reflexive property.
3. **Case 3:** \(\neg a \le b\) and \(b \le a\)
- In this case, we need to show that \(\text{Ordering.gt.swap} = \text{Ordering.lt}\).
- The current goal is trivially true due to the reflexive property.
4. **Case 4:** \(\neg a \le b\) and \(\neg b \le a\)
- In this case, we need to show that \(\text{Ordering.gt.swap} = \text{Ordering.gt}\).
- The current goal is trivially true due to the reflexive property. -/
  next h1 h2 => cases h1 (Nat.le_of_not_le h2)","import Init.Classical
import Init.Data.Ord
import Init.Data.Nat.Compare

open Nat

"
1380,Nat.compare_eq_lt,theorem Nat.compare_eq_lt {a b : Nat} : compare a b = .lt ↔ a < b := by sorry,"Comparison of Natural Numbers Returns Less Than if and only if \( a < b \) : For any natural numbers \( a \) and \( b \), the comparison \( \text{compare}(a, b) \) returns `Ordering.lt` if and only if \( a < b \).","theorem Nat.compare_eq_lt {a b : Nat} : compare a b = .lt ↔ a < b := by
  rw [compare_def_lt]; (repeat' split) <;> simp [*]","To prove the theorem, we use the definition of the comparison function for natural numbers, which states that \( \text{compare}(a, b) = \text{Ordering.lt} \) if and only if \( a < b \). This definition allows us to split the goal into cases and simplify the expressions using the properties of natural numbers and the comparison function. After simplification, we are left with the goal of showing that \( a < b \) if and only if \( a < b \), which is trivially true. Therefore, the theorem is proved.","theorem Nat.compare_eq_lt {a b : Nat} : compare a b = .lt ↔ a < b := by
/- We start by using the definition of the comparison function for natural numbers, which states that \( \text{compare}(a, b) = \text{Ordering.lt} \) if and only if \( a < b \). This definition allows us to split the goal into cases and simplify the expressions using the properties of natural numbers and the comparison function. After simplification, we are left with the goal of showing that \( a < b \) if and only if \( a < b \), which is trivially true. -/
  rw [compare_def_lt]; (repeat' split) <;> simp [*]","import Init.Classical
import Init.Data.Ord
import Init.Data.Nat.Compare

open Nat

"
1384,Nat.compare_eq_gt,theorem Nat.compare_eq_gt {a b : Nat} : compare a b = .gt ↔ b < a := by sorry,"Comparison of Natural Numbers Returns Greater Than if and only if \( b < a \) : For any natural numbers \( a \) and \( b \), the comparison \( \text{compare}(a, b) \) returns `Ordering.gt` if and only if \( b < a \).","theorem Nat.compare_eq_gt {a b : Nat} : compare a b = .gt ↔ b < a := by
  rw [compare_def_lt]; (repeat' split) <;> simp [Nat.le_of_lt, *]","We start by using the definition of the comparison function for natural numbers, which states that \( \text{compare}(a, b) \) returns `Ordering.gt` if and only if \( a > b \). This means we need to show that \( \text{compare}(a, b) = \text{Ordering.gt} \) if and only if \( b < a \).

To do this, we split the goal into cases based on the possible outcomes of the comparison. Specifically, we consider the cases where \( a \) and \( b \) are equal, \( a \) is less than \( b \), and \( a \) is greater than \( b \).

1. **Case 1: \( a = b \)**
- If \( a = b \), then \( \text{compare}(a, b) \) returns `Ordering.eq`, which is not `Ordering.gt`.
- Therefore, \( \text{compare}(a, b) = \text{Ordering.gt} \) is false, and \( b < a \) is also false.
- Hence, \( \text{compare}(a, b) = \text{Ordering.gt} \) if and only if \( b < a \) holds in this case.

2. **Case 2: \( a < b \)**
- If \( a < b \), then \( \text{compare}(a, b) \) returns `Ordering.lt`, which is not `Ordering.gt`.
- Therefore, \( \text{compare}(a, b) = \text{Ordering.gt} \) is false, and \( b < a \) is also false.
- Hence, \( \text{compare}(a, b) = \text{Ordering.gt} \) if and only if \( b < a \) holds in this case.

3. **Case 3: \( a > b \)**
- If \( a > b \), then \( \text{compare}(a, b) \) returns `Ordering.gt`.
- Therefore, \( \text{compare}(a, b) = \text{Ordering.gt} \) is true, and \( b < a \) is also true.
- Hence, \( \text{compare}(a, b) = \text{Ordering.gt} \) if and only if \( b < a \) holds in this case.

Since the comparison function \( \text{compare}(a, b) \) returns `Ordering.gt` if and only if \( a > b \), and \( a > b \) is equivalent to \( b < a \), we conclude that \( \text{compare}(a, b) = \text{Ordering.gt} \) if and only if \( b < a \). This completes the proof.","theorem Nat.compare_eq_gt {a b : Nat} : compare a b = .gt ↔ b < a := by
/- First, we use the definition of the comparison function for natural numbers, which states that \( \text{compare}(a, b) \) returns `Ordering.gt` if and only if \( a > b \). We then split the goal into cases based on the possible outcomes of the comparison. After simplifying using the fact that \( a > b \) implies \( b < a \) and other relevant properties, we reduce the goal to showing that \( b < a \) if and only if \( b < a \), which is trivially true. -/
  rw [compare_def_lt]; (repeat' split) <;> simp [Nat.le_of_lt, *]","import Init.Classical
import Init.Data.Ord
import Init.Data.Nat.Compare

open Nat

"
1395,Nat.compare_eq_eq,theorem Nat.compare_eq_eq {a b : Nat} : compare a b = .eq ↔ a = b := by sorry,"Comparison of Natural Numbers Returns Equality if and only if \( a = b \) : For any natural numbers \( a \) and \( b \), the comparison \( \text{compare}(a, b) \) returns `Ordering.eq` if and only if \( a = b \).","theorem Nat.compare_eq_eq {a b : Nat} : compare a b = .eq ↔ a = b := by
  rw [compare_def_lt]; (repeat' split) <;> simp [Nat.ne_of_lt, Nat.ne_of_gt, *]
  next hlt hgt => exact Nat.le_antisymm (Nat.not_lt.1 hgt) (Nat.not_lt.1 hlt)","To prove the theorem, we start by using the definition of the comparison function for natural numbers. The comparison \( \text{compare}(a, b) \) is defined as follows:
- If \( a < b \), then \( \text{compare}(a, b) = \text{Ordering.lt} \).
- If \( b < a \), then \( \text{compare}(a, b) = \text{Ordering.gt} \).
- If neither \( a < b \) nor \( b < a \), then \( \text{compare}(a, b) = \text{Ordering.eq} \).

We need to show that \( \text{compare}(a, b) = \text{Ordering.eq} \) if and only if \( a = b \).

1. **Case 1: \( a < b \)**
- If \( a < b \), then \( \text{compare}(a, b) = \text{Ordering.lt} \). Therefore, \( \text{compare}(a, b) \neq \text{Ordering.eq} \). Hence, \( \text{compare}(a, b) = \text{Ordering.eq} \) is false, and so is \( a = b \). This case is trivially true.

2. **Case 2: \( b < a \)**
- If \( b < a \), then \( \text{compare}(a, b) = \text{Ordering.gt} \). Therefore, \( \text{compare}(a, b) \neq \text{Ordering.eq} \). Hence, \( \text{compare}(a, b) = \text{Ordering.eq} \) is false, and so is \( a = b \). This case is also trivially true.

3. **Case 3: Neither \( a < b \) nor \( b < a \)**
- If neither \( a < b \) nor \( b < a \), then \( \text{compare}(a, b) = \text{Ordering.eq} \). This means \( a \) and \( b \) are not strictly less than each other. By the properties of natural numbers, this implies \( a \leq b \) and \( b \leq a \). By the antisymmetry of the less than or equal to relation, we have \( a = b \).

Thus, we have shown that \( \text{compare}(a, b) = \text{Ordering.eq} \) if and only if \( a = b \). This completes the proof.","theorem Nat.compare_eq_eq {a b : Nat} : compare a b = .eq ↔ a = b := by
/- First, we use the equivalence that the cardinality of a finite type is $0$ if and only if this type is empty, to convert the assumption of cardinality of $n = 0$ into $n$ is empty. -/
/- It suffices to show that $M = 1$ (the identity matrix), because if this is true, by using this $M = 1$ and simplifying, we get the determinant of $M$ is $1$ automatically. -/
/- Using extensionality, to prove that $M = 1$, we only need to show that $M i = 1 i$ for every $i \in n$. -/
/- Since $n$ is empty, this $M i = 1 i$ holds for every $i \in n$ vacuously. This finishes the proof. -/
  rw [compare_def_lt]; (repeat' split) <;> simp [Nat.ne_of_lt, Nat.ne_of_gt, *]
  next hlt hgt => exact Nat.le_antisymm (Nat.not_lt.1 hgt) (Nat.not_lt.1 hlt)","import Init.Classical
import Init.Data.Ord
import Init.Data.Nat.Compare

open Nat

"
1478,Nat.compare_ne_gt,theorem Nat.compare_ne_gt {a b : Nat} : compare a b ≠ .gt ↔ a ≤ b := by sorry,"Comparison is Not Greater Than if and Only if \( a \leq b \) in Natural Numbers : For any natural numbers \( a \) and \( b \), the comparison \( \text{compare}(a, b) \) is not equal to `greater than` (i.e., \( \text{compare}(a, b) \neq \text{gt} \)) if and only if \( a \leq b \).","theorem Nat.compare_ne_gt {a b : Nat} : compare a b ≠ .gt ↔ a ≤ b := by
  rw [compare_def_le]; (repeat' split) <;> simp [*]","We start by using the definition of the comparison function for natural numbers, which states:
- If \( a < b \), then \( \text{compare}(a, b) = \text{lt} \).
- If \( a = b \), then \( \text{compare}(a, b) = \text{eq} \).
- If \( a > b \), then \( \text{compare}(a, b) = \text{gt} \).

Substituting this definition into the goal, we get:
\[
(a < b \to \text{lt}) \land (a = b \to \text{eq}) \land (a > b \to \text{gt}) \neq \text{gt} \leftrightarrow a \leq b
\]

Next, we split the conjunction into separate cases:
\[
(a < b \to \text{False}) \land (a = b \to \text{True}) \land (a > b \to \text{False}) \leftrightarrow a \leq b
\]

Finally, we simplify the expression using the properties of logical negation:
- \( a < b \to \text{False} \) is equivalent to \( \neg (a < b) \), which is \( a \geq b \).
- \( a = b \to \text{True} \) is always true.
- \( a > b \to \text{False} \) is equivalent to \( \neg (a > b) \), which is \( a \leq b \).

Thus, the goal simplifies to:
\[
(a \geq b) \land \text{True} \land (a \leq b) \leftrightarrow a \leq b
\]

Since \( a \geq b \) and \( a \leq b \) together imply \( a = b \), and \( a = b \) implies \( a \leq b \), the entire expression simplifies to:
\[
a \leq b \leftrightarrow a \leq b
\]

This is trivially true, completing the proof.","theorem Nat.compare_ne_gt {a b : Nat} : compare a b ≠ .gt ↔ a ≤ b := by
/- First, we use the definition of the comparison function for natural numbers, which states that:
- If \( a < b \), then \( \text{compare}(a, b) = \text{lt} \).
- If \( a = b \), then \( \text{compare}(a, b) = \text{eq} \).
- If \( a > b \), then \( \text{compare}(a, b) = \text{gt} \).

By substituting this definition into the goal, we get:
\[
(a < b \to \text{lt}) \land (a = b \to \text{eq}) \land (a > b \to \text{gt}) \neq \text{gt} \leftrightarrow a \leq b
\]

Next, we split the conjunction into separate cases:
\[
(a < b \to \text{lt}) \land (a = b \to \text{eq}) \land (a > b \to \text{gt}) \neq \text{gt} \leftrightarrow (a < b \to \text{False}) \land (a = b \to \text{True}) \land (a > b \to \text{False})
\]

Finally, we simplify the expression using the properties of logical negation:
\[
(a < b \to \text{False}) \land (a = b \to \text{True}) \land (a > b \to \text{False}) \leftrightarrow a \leq b
\] -/
  rw [compare_def_le]; (repeat' split) <;> simp [*]","import Init.Classical
import Init.Data.Ord
import Init.Data.Nat.Compare

open Nat

"
1575,List.range'_succ,theorem List.range'_succ (s n step) : range' s (n + 1) step = s :: range' (s + step) n step := by sorry,"Range with Step for Successor Length : For any natural numbers \( s \), \( n \), and \( \text{step} \), the list generated by `List.range' s (n + 1) step` is equal to the list \( [s, s + \text{step}, s + 2 \cdot \text{step}, \ldots, s + n \cdot \text{step}] \). Specifically, this can be written as:
\[ \text{List.range'}(s, n + 1, \text{step}) = s :: \text{List.range'}(s + \text{step}, n, \text{step}) \]","theorem List.range'_succ (s n step) : range' s (n + 1) step = s :: range' (s + step) n step := by
  simp [range', Nat.add_succ, Nat.mul_succ]","To prove the theorem, we start by using the definition of the `List.range'` function and the properties of addition and multiplication in natural numbers. The function `List.range'` generates a list of natural numbers starting from \( s \) and incrementing by \( \text{step} \) for \( n + 1 \) times. Specifically, the definition of `List.range'` states:
\[ \text{List.range'}(s, n + 1, \text{step}) = s :: \text{List.range'}(s + \text{step}, n, \text{step}) \]

This definition directly matches the goal we want to show. Therefore, the proposition is trivially true by the definition of `List.range'` and the properties of natural number addition and multiplication. This completes the proof.","theorem List.range'_succ (s n step) : range' s (n + 1) step = s :: range' (s + step) n step := by
/- Using the definition of `List.range'` and the properties of addition and multiplication in natural numbers, we can simplify the proposition we want to show to:
\[ \text{List.range'}(s, n + 1, \text{step}) = s :: \text{List.range'}(s + \text{step}, n, \text{step}) \] -/
  simp [range', Nat.add_succ, Nat.mul_succ]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1578,List.range'_eq_nil,theorem List.range'_eq_nil : range' s n step = [] ↔ n = 0 := by sorry,"Range with Step Equals Empty List if and only if Length is Zero: \(\text{range}'(s, n, \text{step}) = [] \leftrightarrow n = 0\) : For any natural numbers \( s \), \( n \), and \( \text{step} \), the list generated by `List.range' s n step` is equal to the empty list if and only if \( n = 0 \). In other words, \(\text{range}'(s, n, \text{step}) = []\) if and only if \( n = 0 \).","theorem List.range'_eq_nil : range' s n step = [] ↔ n = 0 := by
  rw [← length_eq_zero, length_range']","To prove the theorem, we start by using the equivalence that a list \( l \) is empty if and only if its length is zero. Specifically, for the list \(\text{range}'(s, n, \text{step})\), we know that its length is equal to \( n \). Therefore, the statement \(\text{range}'(s, n, \text{step}) = []\) is equivalent to \((\text{range}'(s, n, \text{step})).\text{length} = 0\).

Since the length of \(\text{range}'(s, n, \text{step})\) is \( n \), the goal \((\text{range}'(s, n, \text{step})).\text{length} = 0\) simplifies to \( n = 0 \).

Thus, we have shown that \(\text{range}'(s, n, \text{step}) = []\) if and only if \( n = 0 \). This completes the proof.","theorem List.range'_eq_nil : range' s n step = [] ↔ n = 0 := by
/- First, we use the equivalence that a list \( l \) is empty if and only if its length is zero, to rewrite the goal. Specifically, since the length of the list \(\text{range}'(s, n, \text{step})\) is equal to \( n \), the goal \(\text{range}'(s, n, \text{step}) = []\) is equivalent to \((\text{range}'(s, n, \text{step})).\text{length} = 0\). Therefore, it suffices to show that \( n = 0 \). -/
  rw [← length_eq_zero, length_range']","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1588,List.range'_1_concat,theorem List.range'_1_concat (s n : Nat) : range' s (n + 1) = range' s n ++ [s + n] := by sorry,"Range with Step Concatenation: `List.range' s (n + 1) = List.range' s n ++ [s + n]` : For any natural numbers \( s \) and \( n \), the list generated by `List.range' s (n + 1)` is equal to the list generated by `List.range' s n` concatenated with the list containing the single element \( s + n \). In other words, `List.range' s (n + 1)` is the list \([ s, s + 1, \ldots, s + n ]\) concatenated with the list \([ s + n ]\).","theorem List.range'_1_concat (s n : Nat) : range' s (n + 1) = range' s n ++ [s + n] := by
  simp [range'_concat]","To prove the theorem, we use the property that for any natural numbers \( s \) and \( n \), and any natural number \( \text{step} \), the list generated by `List.range' s (n + 1) step` is equal to the list generated by `List.range' s n step` concatenated with the list containing the single element \( s + \text{step} \cdot n \). In our specific case, the step size is \( 1 \). Therefore, the list generated by `List.range' s (n + 1)` is equal to the list generated by `List.range' s n` concatenated with the list containing the single element \( s + n \). This simplification directly gives us the desired result, completing the proof.","theorem List.range'_1_concat (s n : Nat) : range' s (n + 1) = range' s n ++ [s + n] := by
/- Using the property that for any natural numbers \( s \) and \( n \), and any natural number \( \text{step} \), the list generated by `List.range' s (n + 1) step` is equal to the list generated by `List.range' s n step` concatenated with the list containing the single element \( s + \text{step} \cdot n \), we can simplify the proposition we want to show. Specifically, we need to show that `List.range' s (n + 1)` is equal to `List.range' s n ++ [s + n]`. Since the step size is \( 1 \) in this context, the simplification directly gives us the desired result. -/
  simp [range'_concat]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1592,List.mem_range'_1,theorem List.mem_range'_1 : m ∈ range' s n ↔ s ≤ m ∧ m < s + n := by sorry,"Membership in Range with Step: \( m \in \text{range}'(s, n) \leftrightarrow s \leq m \land m < s + n \) : For any natural numbers \( m \), \( s \), and \( n \), \( m \) is a member of the list \(\text{range}'(s, n)\) if and only if \( s \leq m \) and \( m < s + n \). Formally, this can be written as:
\[
m \in \text{range}'(s, n) \leftrightarrow s \leq m \land m < s + n
\]","theorem List.mem_range'_1 : m ∈ range' s n ↔ s ≤ m ∧ m < s + n := by
  simp [mem_range']; exact ⟨
    fun ⟨i, h, e⟩ => e ▸ ⟨Nat.le_add_right .., Nat.add_lt_add_left h _⟩,
    fun ⟨h₁, h₂⟩ => ⟨m - s, Nat.sub_lt_left_of_lt_add h₁ h₂, (Nat.add_sub_cancel' h₁).symm⟩⟩","To prove the equivalence \( m \in \text{range}'(s, n) \leftrightarrow s \leq m \land m < s + n \), we first simplify the expression using the definition of \(\text{range}'(s, n)\). The list \(\text{range}'(s, n)\) is defined as the list of natural numbers starting from \( s \) and ending at \( s + n - 1 \).

We need to show two directions of the equivalence:
1. **If \( m \in \text{range}'(s, n) \), then \( s \leq m \) and \( m < s + n \):**
- Assume \( m \in \text{range}'(s, n) \).
- By the definition of \(\text{range}'(s, n)\), there exists an index \( i \) such that \( 0 \leq i < n \) and \( m = s + i \).
- From \( m = s + i \) and \( i \geq 0 \), we have \( s \leq m \) (since \( s \leq s + i \)).
- From \( m = s + i \) and \( i < n \), we have \( m < s + n \) (since \( s + i < s + n \)).

2. **If \( s \leq m \) and \( m < s + n \), then \( m \in \text{range}'(s, n) \):**
- Assume \( s \leq m \) and \( m < s + n \).
- We need to show that \( m \) is in the list \(\text{range}'(s, n)\).
- By the definition of \(\text{range}'(s, n)\), we need to find an index \( i \) such that \( 0 \leq i < n \) and \( m = s + i \).
- We can choose \( i = m - s \):
- \( 0 \leq i \) because \( s \leq m \) implies \( m - s \geq 0 \).
- \( i < n \) because \( m < s + n \) implies \( m - s < n \).
- \( m = s + i \) because \( m = s + (m - s) \).

Thus, we have shown both directions of the equivalence, completing the proof.","theorem List.mem_range'_1 : m ∈ range' s n ↔ s ≤ m ∧ m < s + n := by
/- To prove the equivalence \( m \in \text{range}'(s, n) \leftrightarrow s \leq m \land m < s + n \), we first simplify the expression using the definition of \(\text{range}'(s, n)\). The definition of \(\text{range}'(s, n)\) is the list of natural numbers starting from \( s \) and ending at \( s + n - 1 \).

We then need to show two directions of the equivalence:
1. If \( m \in \text{range}'(s, n) \), then \( s \leq m \) and \( m < s + n \).
2. If \( s \leq m \) and \( m < s + n \), then \( m \in \text{range}'(s, n) \).

For the first direction, assume \( m \in \text{range}'(s, n) \). By the definition of \(\text{range}'(s, n)\), there exists an index \( i \) such that \( 0 \leq i < n \) and \( m = s + i \). From this, we can deduce:
- \( s \leq m \) because \( s \leq s + i \) (since \( i \geq 0 \)).
- \( m < s + n \) because \( m = s + i \) and \( i < n \).

For the second direction, assume \( s \leq m \) and \( m < s + n \). We need to show that \( m \) is in the list \(\text{range}'(s, n)\). By the definition of \(\text{range}'(s, n)\), we need to find an index \( i \) such that \( 0 \leq i < n \) and \( m = s + i \). We can choose \( i = m - s \):
- \( 0 \leq i \) because \( s \leq m \) implies \( m - s \geq 0 \).
- \( i < n \) because \( m < s + n \) implies \( m - s < n \).
- \( m = s + i \) because \( m = s + (m - s) \). -/
  simp [mem_range']; exact ⟨
    fun ⟨i, h, e⟩ => e ▸ ⟨Nat.le_add_right .., Nat.add_lt_add_left h _⟩,
    fun ⟨h₁, h₂⟩ => ⟨m - s, Nat.sub_lt_left_of_lt_add h₁ h₂, (Nat.add_sub_cancel' h₁).symm⟩⟩","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1594,List.map_sub_range',"theorem List.map_sub_range' (a s n : Nat) (h : a ≤ s) :
    map (· - a) (range' s n step) = range' (s - a) n step := by sorry","Mapping Subtraction over Range with Step: \(\text{map} (x \mapsto x - a) (\text{range}'(s, n, step)) = \text{range}'(s - a, n, step)\) : For any natural numbers \(a\), \(s\), and \(n\) such that \(a \leq s\), and for any natural number \(step\), the list obtained by applying the function \(x \mapsto x - a\) to each element of the list \(\text{range}'(s, n, step)\) is equal to the list \(\text{range}'(s - a, n, step)\). Formally, this can be written as:
\[
\text{map} (x \mapsto x - a) (\text{range}'(s, n, step)) = \text{range}'(s - a, n, step)
\]","theorem List.map_sub_range' (a s n : Nat) (h : a ≤ s) :
    map (· - a) (range' s n step) = range' (s - a) n step := by
  conv => lhs; rw [← Nat.add_sub_cancel' h]
  rw [← map_add_range', map_map, (?_ : _∘_ = _), map_id]
  funext x; apply Nat.add_sub_cancel_left","We start by focusing on the left-hand side of the equation, \(\text{map} (x \mapsto x - a) (\text{range}'(s, n, step))\). Using the property that for any natural numbers \(a\) and \(b\) such that \(a \leq s\), \(a + (s - a) = s\), we can rewrite the left-hand side as:
\[
\text{map} (x \mapsto x - a) (\text{range}'(a + (s - a), n, step))
\]

Next, we use the property that \(\text{map} (x \mapsto a + x) (\text{range}'(s - a, n, step)) = \text{range}'(a + (s - a), n, step)\) to further rewrite the left-hand side as:
\[
\text{map} (x \mapsto x - a) (\text{map} (x \mapsto a + x) (\text{range}'(s - a, n, step)))
\]

By the composition property of `List.map`, this is equivalent to:
\[
\text{map} ((x \mapsto x - a) \circ (x \mapsto a + x)) (\text{range}'(s - a, n, step))
\]

We need to show that \((x \mapsto x - a) \circ (x \mapsto a + x) = \text{id}\), where \(\text{id}\) is the identity function. To do this, we prove that for every \(x \in \mathbb{N}\), \((x \mapsto x - a) (a + x) = x\). By the property of addition and subtraction in natural numbers, \(a + x - a = x\), which is exactly the identity function. Therefore, \((x \mapsto x - a) \circ (x \mapsto a + x) = \text{id}\).

Finally, by the property that \(\text{map} (\text{id}) l = l\), the left-hand side simplifies to:
\[
\text{range}'(s - a, n, step)
\]

Thus, we have shown that:
\[
\text{map} (x \mapsto x - a) (\text{range}'(s, n, step)) = \text{range}'(s - a, n, step)
\]

This completes the proof.","theorem List.map_sub_range' (a s n : Nat) (h : a ≤ s) :
    map (· - a) (range' s n step) = range' (s - a) n step := by
/- We focus on the left-hand side of the current goal, which is \(\text{map} (x \mapsto x - a) (\text{range}'(s, n, step))\). Using the property that for any natural numbers \(a\) and \(b\) such that \(a \leq s\), \(a + (s - a) = s\), we can rewrite the left-hand side as \(\text{map} (x \mapsto x - a) (\text{range}'(a + (s - a), n, step))\). -/
  conv => lhs; rw [← Nat.add_sub_cancel' h]
/- Next, we use the property that \(\text{map} (x \mapsto a + x) (\text{range}'(s - a, n, step)) = \text{range}'(a + (s - a), n, step)\) to rewrite the left-hand side as \(\text{map} (x \mapsto x - a) (\text{map} (x \mapsto a + x) (\text{range}'(s - a, n, step)))\). By the composition property of `List.map`, this is equivalent to \(\text{map} ((x \mapsto x - a) \circ (x \mapsto a + x)) (\text{range}'(s - a, n, step))\). We need to show that \((x \mapsto x - a) \circ (x \mapsto a + x) = \text{id}\), where \(\text{id}\) is the identity function. Finally, by the property that \(\text{map} (\text{id}) l = l\), the left-hand side simplifies to \(\text{range}'(s - a, n, step)\). -/
  rw [← map_add_range', map_map, (?_ : _∘_ = _), map_id]
/- To show that \((x \mapsto x - a) \circ (x \mapsto a + x) = \text{id}\), we need to prove that for every \(x \in \mathbb{N}\), \((x \mapsto x - a) (a + x) = x\). By the property of addition and subtraction in natural numbers, \(a + x - a = x\), which is exactly the identity function. Therefore, \((x \mapsto x - a) \circ (x \mapsto a + x) = \text{id}\). -/
  funext x; apply Nat.add_sub_cancel_left","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1595,List.not_mem_range_self,theorem List.not_mem_range_self {n : Nat} : n ∉ range n := by sorry,"\( n \notin \text{range}(n) \) for Natural Numbers : For any natural number \( n \), \( n \) is not a member of the list `List.range n`, i.e., \( n \notin \{0, 1, 2, \ldots, n-1\} \).","theorem List.not_mem_range_self {n : Nat} : n ∉ range n := by
  simp","To prove that \( n \notin \{0, 1, 2, \ldots, n-1\} \), we simplify the proposition using the definition of `List.range n`. By definition, `List.range n` is the list of all natural numbers from \( 0 \) to \( n-1 \). Since \( n \) is not in this list, the proposition \( n \notin \{0, 1, 2, \ldots, n-1\} \) is true. This completes the proof.","theorem List.not_mem_range_self {n : Nat} : n ∉ range n := by
  simp","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1596,List.mem_range,theorem List.mem_range {m n : Nat} : m ∈ range n ↔ m < n := by sorry,"Membership in Range: \( m \in \text{range}(n) \leftrightarrow m < n \) : For any natural numbers \( m \) and \( n \), \( m \) is a member of the list `List.range n` if and only if \( m < n \). In other words, \( m \in \{0, 1, 2, \ldots, n-1\} \) if and only if \( m < n \).","theorem List.mem_range {m n : Nat} : m ∈ range n ↔ m < n := by
  simp only [range_eq_range', mem_range'_1, Nat.zero_le, true_and, Nat.zero_add]","To prove the theorem, we start by using the fact that the list \(\text{range}(n)\) is equal to the list \(\text{range}'(0, n)\). By definition, \( m \in \text{range}'(0, n) \) if and only if \( 0 \leq m \) and \( m < n \).

Since \( 0 \leq m \) is always true for any natural number \( m \), and \( 0 + m = m \), the condition \( 0 \leq m \) is trivially satisfied. Therefore, the proposition \( m \in \text{range}(n) \) is equivalent to \( m < n \).

Thus, we have shown that \( m \in \text{range}(n) \) if and only if \( m < n \). This completes the proof. \(\blacksquare\)","theorem List.mem_range {m n : Nat} : m ∈ range n ↔ m < n := by
/- Using the fact that `List.range n` is equal to `List.range' 0 n`, and the definition of `List.range' 0 n` which states that \( m \in \text{range}'(0, n) \) if and only if \( 0 \leq m \) and \( m < n \), we can simplify the proposition we want to show. Since \( 0 \leq m \) is always true for any natural number \( m \), and \( 0 + m = m \), the proposition \( m \in \text{range}(n) \leftrightarrow m < n \) is equivalent to \( m < n \). Therefore, the goal is now to show that \( m < n \) is true if and only if \( m < n \), which is trivially true. -/
  simp only [range_eq_range', mem_range'_1, Nat.zero_le, true_and, Nat.zero_add]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1597,List.range_sublist,theorem List.range_sublist {m n : Nat} : range m <+ range n ↔ m ≤ n := by sorry,"Sublist Condition for Range Lists: \(\text{List.range } m \subseteq \text{List.range } n \leftrightarrow m \leq n\) : For any natural numbers \( m \) and \( n \), the list \(\text{List.range } m\) is a sublist of the list \(\text{List.range } n\) if and only if \( m \leq n \). In other words, the list of natural numbers from \( 0 \) to \( m-1 \) is a sublist of the list of natural numbers from \( 0 \) to \( n-1 \) if and only if \( m \) is less than or equal to \( n \).","theorem List.range_sublist {m n : Nat} : range m <+ range n ↔ m ≤ n := by
  simp only [range_eq_range', range'_sublist_right]","To prove the theorem, we start by noting the following two key facts:
1. The list generated by \(\text{List.range } n\) is equal to the list generated by \(\text{List.range' } 0 \, n\). Specifically, \(\text{List.range } n\) returns the list of natural numbers from \( 0 \) to \( n-1 \) in increasing order, and \(\text{List.range' } 0 \, n\) returns the same list.
2. The sublist condition for \(\text{List.range' } 0 \, m\) and \(\text{List.range' } 0 \, n\) is that \(\text{List.range' } 0 \, m\) is a sublist of \(\text{List.range' } 0 \, n\) if and only if \( m \leq n \).

Using these facts, we can simplify the proposition we want to show. Since \(\text{List.range } m = \text{List.range' } 0 \, m\) and \(\text{List.range } n = \text{List.range' } 0 \, n\), the statement \(\text{List.range } m \subseteq \text{List.range } n\) is equivalent to \(\text{List.range' } 0 \, m \subseteq \text{List.range' } 0 \, n\). By the sublist condition for \(\text{List.range' } 0 \, m\) and \(\text{List.range' } 0 \, n\), this is true if and only if \( m \leq n \).

Thus, we have shown that \(\text{List.range } m\) is a sublist of \(\text{List.range } n\) if and only if \( m \leq n \). This completes the proof.","theorem List.range_sublist {m n : Nat} : range m <+ range n ↔ m ≤ n := by
/- Using the fact that `List.range n` is equal to `List.range' 0 n` and the sublist condition for `List.range' 0 m` and `List.range' 0 n`, we can simplify the proposition we want to show to \( m \leq n \). -/
  simp only [range_eq_range', range'_sublist_right]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1598,List.range_subset,theorem List.range_subset {m n : Nat} : range m ⊆ range n ↔ m ≤ n := by sorry,"Range Subset Condition: \( \text{List.range } m \subseteq \text{List.range } n \leftrightarrow m \leq n \) : For any natural numbers \( m \) and \( n \), the list `List.range m` is a subset of the list `List.range n` if and only if \( m \leq n \). In other words, the list of natural numbers from \( 0 \) to \( m-1 \) is a subset of the list of natural numbers from \( 0 \) to \( n-1 \) if and only if \( m \) is less than or equal to \( n \).","theorem List.range_subset {m n : Nat} : range m ⊆ range n ↔ m ≤ n := by
  simp only [range_eq_range', range'_subset_right, lt_succ_self]","To prove the theorem, we start by using the fact that the list `List.range n` is equal to the list `List.range' 0 n`. This means that the list of natural numbers from \( 0 \) to \( n-1 \) is the same as the list generated by `List.range' 0 n`.

Next, we use the property that `List.range' 0 m` is a subset of `List.range' 0 n` if and only if \( m \leq n \). This property tells us that the list of natural numbers from \( 0 \) to \( m-1 \) is a subset of the list of natural numbers from \( 0 \) to \( n-1 \) if and only if \( m \) is less than or equal to \( n \).

Finally, we use the property that \( m \leq n \) is equivalent to \( m < n + 1 \). This is a standard property of the natural numbers, stating that \( m \) is less than or equal to \( n \) if and only if \( m \) is strictly less than \( n + 1 \).

Combining these properties, we can simplify the original proposition to the desired result. Therefore, the list `List.range m` is a subset of the list `List.range n` if and only if \( m \leq n \). This completes the proof.","theorem List.range_subset {m n : Nat} : range m ⊆ range n ↔ m ≤ n := by
/- Using the fact that `List.range n` is equal to `List.range' 0 n`, and the property that `List.range' 0 m` is a subset of `List.range' 0 n` if and only if \( m \leq n \), and the property that \( m \leq n \) is equivalent to \( m < n + 1 \), we can simplify the proposition we want to show to the desired result. -/
  simp only [range_eq_range', range'_subset_right, lt_succ_self]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1599,List.self_mem_range_succ,theorem List.self_mem_range_succ (n : Nat) : n ∈ range (n + 1) := by sorry,"Self Membership in Range of Successor : For any natural number \( n \), the number \( n \) is a member of the list `List.range (n + 1)`, which is the list of natural numbers from \( 0 \) to \( n \). In other words, \( n \in [0, 1, 2, \ldots, n] \).","theorem List.self_mem_range_succ (n : Nat) : n ∈ range (n + 1) := by
  simp","To prove that \( n \) is a member of the list `List.range (n + 1)`, we simplify the proposition. The list `List.range (n + 1)` is defined as the list of natural numbers from \( 0 \) to \( n \). Therefore, \( n \) is one of the elements in this list, and the proposition \( n \in [0, 1, 2, \ldots, n] \) is trivially true. This completes the proof.","theorem List.self_mem_range_succ (n : Nat) : n ∈ range (n + 1) := by
  simp","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1600,List.pairwise_lt_range,theorem List.pairwise_lt_range (n : Nat) : Pairwise (· < ·) (range n) := by sorry,"Pairwise Strict Inequality in `List.range` : For any natural number \( n \), the list `List.range n` is pairwise strictly less than, i.e., for all elements \( x \) and \( x' \) in the list `List.range n`, where \( x \) appears before \( x' \), it holds that \( x < x' \).","theorem List.pairwise_lt_range (n : Nat) : Pairwise (· < ·) (range n) := by
  simp (config := {decide := true}) only [range_eq_range', pairwise_lt_range']","To prove that the list `List.range n` is pairwise strictly less than, we use the following steps:

1. **Simplify the Proposition:**
We know that the list `List.range n` is equal to the list `List.range' 0 n`. This is a direct consequence of the definition of `List.range` and `List.range'` for natural numbers. Specifically, `List.range n` returns the list of natural numbers from \( 0 \) to \( n-1 \) in increasing order, and `List.range' 0 n` returns the same list.

2. **Use Pairwise Property:**
We also know that the list `List.range' 0 n` is pairwise strictly less than. This means that for any two elements \( x \) and \( x' \) in the list `List.range' 0 n`, where \( x \) appears before \( x' \), it holds that \( x < x' \).

3. **Conclusion:**
Since `List.range n` is equal to `List.range' 0 n` and `List.range' 0 n` is pairwise strictly less than, it follows by the transitivity of equality that `List.range n` is also pairwise strictly less than. Therefore, the proposition is true, and the proof is complete.","theorem List.pairwise_lt_range (n : Nat) : Pairwise (· < ·) (range n) := by
/- Using the fact that `List.range n` is equal to `List.range' 0 n` and the property that `List.range' 0 n` is pairwise strictly less than, we can simplify the proposition we want to show to the fact that the list `List.range n` is pairwise strictly less than. This completes the proof. -/
  simp (config := {decide := true}) only [range_eq_range', pairwise_lt_range']","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1601,List.range'_subset_right,"theorem List.range'_subset_right {s m n : Nat} (step0 : 0 < step) :
    range' s m step ⊆ range' s n step ↔ m ≤ n := by sorry","Subset Condition for Range Lists with Step: \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \leftrightarrow m \leq n \) : For any natural numbers \( s \), \( m \), \( n \), and a step \( \text{step} \) such that \( 0 < \text{step} \), the list generated by `List.range' s m step` is a subset of the list generated by `List.range' s n step` if and only if \( m \leq n \). In other words, \([ s, s + \text{step}, \ldots, s + (m-1) \cdot \text{step} ] \subseteq [ s, s + \text{step}, \ldots, s + (n-1) \cdot \text{step} ]\) if and only if \( m \leq n \).","theorem List.range'_subset_right {s m n : Nat} (step0 : 0 < step) :
    range' s m step ⊆ range' s n step ↔ m ≤ n := by
  refine ⟨fun h => Nat.le_of_not_lt fun hn => ?_, fun h => (range'_sublist_right.2 h).subset⟩
  have ⟨i, h', e⟩ := mem_range'.1 <| h <| mem_range'.2 ⟨_, hn, rfl⟩
  exact Nat.ne_of_gt h' (Nat.eq_of_mul_eq_mul_left step0 (Nat.add_left_cancel e))","To prove the equivalence \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \leftrightarrow m \leq n \), we need to show two implications:

1. **Implication 1: \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \to m \leq n \)**

Assume \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \). To show \( m \leq n \), we assume the negation \( n < m \) and derive a contradiction.

Since \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \), there must exist an element \( i \) such that \( i < n \) and \( s + \text{step} \cdot n = s + \text{step} \cdot i \). This follows from the membership condition of the range list, which states that an element \( m \) is in \( \text{range}'(s, n, \text{step}) \) if and only if there exists an \( i \) such that \( i < n \) and \( m = s + \text{step} \cdot i \).

Using the cancellation property of addition and multiplication in natural numbers, we have:
\[
s + \text{step} \cdot n = s + \text{step} \cdot i \implies \text{step} \cdot n = \text{step} \cdot i \implies n = i
\]
However, this contradicts \( i < n \) because \( n \neq i \) if \( i < n \). Therefore, the assumption \( n < m \) leads to a contradiction, and we conclude \( m \leq n \).

2. **Implication 2: \( m \leq n \to \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \)**

Assume \( m \leq n \). We need to show that \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \).

By the definition of the range list with step, if \( m \leq n \), then every element in \( \text{range}'(s, m, \text{step}) \) is also in \( \text{range}'(s, n, \text{step}) \). This is because the list \( \text{range}'(s, m, \text{step}) \) contains the elements \( s, s + \text{step}, \ldots, s + (m-1) \cdot \text{step} \), and since \( m \leq n \), these elements are also in the list \( \text{range}'(s, n, \text{step}) \), which contains the elements \( s, s + \text{step}, \ldots, s + (n-1) \cdot \text{step} \).

Therefore, \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \).

Combining both implications, we have:
\[
\text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \leftrightarrow m \leq n
\]
This completes the proof.","theorem List.range'_subset_right {s m n : Nat} (step0 : 0 < step) :
    range' s m step ⊆ range' s n step ↔ m ≤ n := by
/- To prove the equivalence \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \leftrightarrow m \leq n \), we need to show two implications:
1. If \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \), then \( m \leq n \).
2. If \( m \leq n \), then \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \).

We start by proving the first implication. Assume \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \). To show \( m \leq n \), it suffices to show that if \( n < m \), then we reach a contradiction (i.e., the goal is `False`). -/
  refine ⟨fun h => Nat.le_of_not_lt fun hn => ?_, fun h => (range'_sublist_right.2 h).subset⟩
/- Assume \( n < m \). Since \( \text{range}'(s, m, \text{step}) \subseteq \text{range}'(s, n, \text{step}) \), there must exist an element \( i \) such that \( i < n \) and \( s + \text{step} \cdot n = s + \text{step} \cdot i \). This is derived from the membership condition of the range list, which states that an element \( m \) is in \( \text{range}'(s, n, \text{step}) \) if and only if there exists an \( i \) such that \( i < n \) and \( m = s + \text{step} \cdot i \). -/
  have ⟨i, h', e⟩ := mem_range'.1 <| h <| mem_range'.2 ⟨_, hn, rfl⟩
/- Since \( i < n \) and \( s + \text{step} \cdot n = s + \text{step} \cdot i \), we can use the cancellation property of addition and multiplication in natural numbers to conclude that \( n = i \). However, this contradicts \( i < n \) because \( n \neq i \) if \( i < n \). Therefore, the assumption \( n < m \) leads to a contradiction, and we have \( m \leq n \). -/
  exact Nat.ne_of_gt h' (Nat.eq_of_mul_eq_mul_left step0 (Nat.add_left_cancel e))","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1602,List.getElem_range,theorem List.getElem_range {n : Nat} (m) (h : m < (range n).length) : (range n)[m] = m := by sorry,"Element at Index in Range List Equals Index : For any natural number \( n \) and any natural number \( m \) such that \( m < n \), the element at index \( m \) in the list `List.range n` is equal to \( m \). In other words, \((\text{List.range } n)[m] = m\).","theorem List.getElem_range {n : Nat} (m) (h : m < (range n).length) : (range n)[m] = m := by
  simp [range_eq_range']","We start by noting that the list generated by `List.range n` is equal to the list generated by `List.range' 0 n`. Both lists contain the natural numbers from \( 0 \) to \( n-1 \) in increasing order. Therefore, the element at index \( m \) in `List.range n` is the same as the element at index \( m \) in `List.range' 0 n`, which is \( m \). This simplification directly shows that \((\text{List.range } n)[m] = m\). Hence, the theorem is proved.","theorem List.getElem_range {n : Nat} (m) (h : m < (range n).length) : (range n)[m] = m := by
/- Using the fact that the list generated by `List.range n` is equal to the list generated by `List.range' 0 n`, we can simplify the proposition we want to show. Since both lists are the same and contain the natural numbers from \( 0 \) to \( n-1 \) in increasing order, the element at index \( m \) in `List.range n` is equal to \( m \). This completes the proof. -/
  simp [range_eq_range']","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1604,List.range_succ_eq_map,theorem List.range_succ_eq_map (n : Nat) : range (n + 1) = 0 :: map succ (range n) := by sorry,"Range of Successor Equals Prepend Zero to Map of Successor on Range : For any natural number \( n \), the list generated by `List.range (n + 1)` is equal to the list obtained by prepending 0 to the list of the successors of the elements in `List.range n`. Formally, this can be written as:
\[ \text{List.range}(n + 1) = 0 :: \text{List.map}(\text{Nat.succ})(\text{List.range}(n)) \]","theorem List.range_succ_eq_map (n : Nat) : range (n + 1) = 0 :: map succ (range n) := by
  rw [range_eq_range', range_eq_range', range', Nat.add_comm, ← map_add_range']
  congr; exact funext (Nat.add_comm 1)","We start by using the theorem that the list generated by \(\text{List.range}(n)\) is equal to the list generated by \(\text{List.range}'(0, n)\). This allows us to rewrite the goal:
\[ \text{List.range}(n + 1) = 0 :: \text{List.map}(\text{Nat.succ})(\text{List.range}(n)) \]
as:
\[ \text{List.range}'(0, n + 1) = 0 :: \text{List.map}(\text{Nat.succ})(\text{List.range}'(0, n)) \]

Next, we use the definition of \(\text{List.range}'\), which states that \(\text{List.range}'(s, n + 1, step)\) is the list \([s, s + step, \ldots, s + (n \cdot step)]\). Applying this definition, we get:
\[ \text{List.range}'(0, n + 1) = 0 :: \text{List.range}'(1, n) \]

We then use the commutativity of addition to rewrite \(1 + 0\) as \(0 + 1\):
\[ 0 :: \text{List.range}'(1, n) = 0 :: \text{List.range}'(0 + 1, n) \]

Finally, we use the theorem that mapping the function \(x \mapsto a + x\) over the list \(\text{List.range}'(s, n, step)\) is equal to the list \(\text{List.range}'(a + s, n, step)\). Specifically, for \(a = 1\), \(s = 0\), and \(step = 1\), we have:
\[ \text{List.map}(\text{Nat.succ})(\text{List.range}'(0, n)) = \text{List.range}'(1, n) \]

Thus, our goal is now:
\[ 0 :: \text{List.range}'(1, n) = 0 :: \text{List.map}(\text{Nat.succ})(\text{List.range}'(0, n)) \]

To prove this equality, we use the congruence theorem, which states that if the heads of two lists are equal and the tails are equal, then the lists are equal. The heads of both lists are \(0\), so we need to show that the tails are equal:
\[ \text{List.range}'(1, n) = \text{List.map}(\text{Nat.succ})(\text{List.range}'(0, n)) \]

We use the function extensionality theorem, which states that two functions are equal if they map equal inputs to equal outputs. Specifically, we use the commutativity of addition to show that the function \(x \mapsto 1 + x\) is equal to the function \(\text{Nat.succ}\):
\[ \text{Nat.succ}(x) = 1 + x \]

Therefore, the tails of the lists are equal, and the original goal is proved. This completes the proof.","theorem List.range_succ_eq_map (n : Nat) : range (n + 1) = 0 :: map succ (range n) := by
/- First, we use the theorem that the list generated by `List.range n` is equal to the list generated by `List.range' 0 n` to rewrite the goal. This gives us:
\[ \text{List.range}(n + 1) = 0 :: \text{List.map}(\text{Nat.succ})(\text{List.range}(n)) \]
is equivalent to:
\[ \text{List.range}'(0, n + 1) = 0 :: \text{List.map}(\text{Nat.succ})(\text{List.range}'(0, n)) \]
Next, we use the definition of `List.range'` to rewrite the left-hand side:
\[ \text{List.range}'(0, n + 1) = 0 :: \text{List.range}'(1, n) \]
Then, we use the commutativity of addition to rewrite \(1 + 0\) as \(0 + 1\):
\[ 0 :: \text{List.range}'(1, n) = 0 :: \text{List.range}'(0 + 1, n) \]
Finally, we use the theorem that mapping the function \(x \mapsto a + x\) over the list \(\text{List.range}'(s, n, step)\) is equal to the list \(\text{List.range}'(a + s, n, step)\) to rewrite the right-hand side:
\[ 0 :: \text{List.range}'(0 + 1, n) = 0 :: \text{List.map}(\text{Nat.succ})(\text{List.range}'(0, n)) \]
Thus, our goal is now:
\[ 0 :: \text{List.range}'(1, n) = 0 :: \text{List.map}(\text{Nat.succ})(\text{List.range}'(0, n)) \] -/
  rw [range_eq_range', range_eq_range', range', Nat.add_comm, ← map_add_range']
/- To prove the equality of the two lists, we use the congruence theorem, which states that if the heads of two lists are equal and the tails are equal, then the lists are equal. The heads of both lists are \(0\), so we need to show that the tails are equal:
\[ \text{List.range}'(1, n) = \text{List.map}(\text{Nat.succ})(\text{List.range}'(0, n)) \]
We use the function extensionality theorem, which states that two functions are equal if they map equal inputs to equal outputs. Specifically, we use the commutativity of addition to show that the function \(x \mapsto 1 + x\) is equal to the function \(\text{Nat.succ}\):
\[ \text{Nat.succ}(x) = 1 + x \]
Thus, the tails of the lists are equal, and the original goal is proved. -/
  congr; exact funext (Nat.add_comm 1)","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1605,List.range_succ,theorem List.range_succ (n : Nat) : range (succ n) = range n ++ [n] := by sorry,"Range of Successor is Concatenation of Range and Singleton : For any natural number \( n \), the list `List.range (n + 1)` is equal to the concatenation of the list `List.range n` and the list containing the single element \( n \). In other words, `List.range (n + 1) = List.range n ++ [n]`.","theorem List.range_succ (n : Nat) : range (succ n) = range n ++ [n] := by
  simp only [range_eq_range', range'_1_concat, Nat.zero_add]","To prove that `List.range (n + 1) = List.range n ++ [n]`, we use the following properties:
1. The list `List.range n` is equal to `List.range' 0 n`, which generates the list of natural numbers from \( 0 \) to \( n-1 \).
2. The list `List.range' s (n + 1)` is equal to `List.range' s n` concatenated with the list containing the single element \( s + n \).
3. The property that \( 0 + n = n \).

Using these properties, we can simplify the proposition as follows:
\[
\text{List.range} (n + 1) = \text{List.range'} 0 (n + 1) = \text{List.range'} 0 n ++ [0 + n] = \text{List.range} n ++ [n]
\]
Thus, the list `List.range (n + 1)` is indeed equal to the concatenation of the list `List.range n` and the list containing the single element \( n \). This completes the proof.","theorem List.range_succ (n : Nat) : range (succ n) = range n ++ [n] := by
/- Using the fact that `List.range n` is equal to `List.range' 0 n` and the property that `List.range' s (n + 1)` is equal to `List.range' s n` concatenated with the list containing the single element \( s + n \), and the property that \( 0 + n = n \), we can simplify the proposition we want to show to `List.range (n + 1) = List.range n ++ [n]`. -/
  simp only [range_eq_range', range'_1_concat, Nat.zero_add]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1606,List.nodup_range,theorem List.nodup_range (n : Nat) : Nodup (range n) := by sorry,"Range List has No Duplicates: \(\text{Nodup}(\text{range}(n))\) : For any natural number \( n \), the list of natural numbers from \( 0 \) to \( n-1 \) generated by `List.range n` has no duplicate elements, i.e., \(\text{Nodup}(\text{range}(n))\).","theorem List.nodup_range (n : Nat) : Nodup (range n) := by
  simp (config := {decide := true}) only [range_eq_range', nodup_range']","To prove that the list `List.range n` has no duplicate elements for any natural number \( n \), we use the following steps:

1. **Simplify the Proposition:**
We know from the definition that the list generated by `List.range n` is equal to the list generated by `List.range' 0 n`. Specifically, `List.range n` returns the list of natural numbers from \( 0 \) to \( n-1 \) in increasing order, and `List.range' 0 n` returns the same list.

2. **Use the Nodup Property:**
We also know that the list `List.range' 0 n` has no duplicate elements. Therefore, by the transitivity of equality, the list `List.range n` must also have no duplicate elements.

Since the list `List.range n` is equal to the list `List.range' 0 n` and the latter has no duplicate elements, it follows that the list `List.range n` has no duplicate elements. This completes the proof.","theorem List.nodup_range (n : Nat) : Nodup (range n) := by
/- Using the fact that the list generated by `List.range n` is equal to the list generated by `List.range' 0 n` and that the list `List.range' 0 n` has no duplicate elements, we can simplify the proposition we want to show to the fact that the list `List.range n` has no duplicate elements. This completes the proof. -/
  simp (config := {decide := true}) only [range_eq_range', nodup_range']","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1607,List.length_iota,theorem List.length_iota (n : Nat) : length (iota n) = n := by sorry,"Length of Iota List Equals \( n \) : For any natural number \( n \), the length of the list of natural numbers from \( n \) down to 1 in decreasing order, denoted as \(\text{iota}(n)\), is equal to \( n \). In other words, \(\text{length}(\text{iota}(n)) = n\).","theorem List.length_iota (n : Nat) : length (iota n) = n := by
  simp [iota_eq_reverse_range']","To prove that the length of \(\text{iota}(n)\) is \( n \), we use the fact that \(\text{iota}(n)\) is equal to the reverse of the list of natural numbers starting from 1 and incrementing by 1 for \( n \) times, denoted as \(\text{range}'(1, n)\). Therefore, we need to show that the length of \(\text{reverse}(\text{range}'(1, n))\) is equal to \( n \).

Since the length of a list is preserved under the reverse operation, the length of \(\text{reverse}(\text{range}'(1, n))\) is the same as the length of \(\text{range}'(1, n)\). The list \(\text{range}'(1, n)\) contains exactly \( n \) elements, starting from 1 and incrementing by 1 up to \( n \). Hence, the length of \(\text{range}'(1, n)\) is \( n \).

Thus, the length of \(\text{iota}(n)\) is also \( n \). This completes the proof.","theorem List.length_iota (n : Nat) : length (iota n) = n := by
  simp [iota_eq_reverse_range']","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1608,List.mem_iota,theorem List.mem_iota {m n : Nat} : m ∈ iota n ↔ 1 ≤ m ∧ m ≤ n := by sorry,"Membership in List of Natural Numbers from \( n \) to 1 : For any natural numbers \( m \) and \( n \), \( m \) is a member of the list \( \text{iota}(n) \) if and only if \( 1 \leq m \leq n \).","theorem List.mem_iota {m n : Nat} : m ∈ iota n ↔ 1 ≤ m ∧ m ≤ n := by
  simp [iota_eq_reverse_range', Nat.add_comm, Nat.lt_succ]","To prove the theorem, we start by using the fact that \(\text{iota}(n)\) is the reverse of the list \(\text{range}'(1, n)\). This means that \(\text{iota}(n)\) is the list of natural numbers from \( n \) down to 1 in decreasing order, which is the reverse of the list of natural numbers starting from 1 and incrementing by 1 for \( n \) times.

Next, we use the commutativity of addition to simplify the expression. The commutativity of addition states that for any natural numbers \( a \) and \( b \), \( a + b = b + a \).

By simplifying the proposition using these facts, we need to show that \( m \in \text{iota}(n) \) if and only if \( 1 \leq m \leq n \).

Since \(\text{iota}(n)\) is the reverse of \(\text{range}'(1, n)\), and \(\text{range}'(1, n)\) is the list of natural numbers from 1 to \( n \), it follows that \( m \) is in \(\text{iota}(n)\) if and only if \( m \) is in \(\text{range}'(1, n)\).

The list \(\text{range}'(1, n)\) contains all natural numbers \( m \) such that \( 1 \leq m \leq n \). Therefore, \( m \in \text{iota}(n) \) if and only if \( 1 \leq m \leq n \).

This completes the proof.","theorem List.mem_iota {m n : Nat} : m ∈ iota n ↔ 1 ≤ m ∧ m ≤ n := by
/- Using the fact that \(\text{iota}(n)\) is the reverse of the list \(\text{range}'(1, n)\) and the commutativity of addition, we can simplify the proposition we want to show. Specifically, we need to prove that \( m \in \text{iota}(n) \) if and only if \( 1 \leq m \leq n \). -/
  simp [iota_eq_reverse_range', Nat.add_comm, Nat.lt_succ]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1613,List.take_range,theorem List.take_range (m n : Nat) : take m (range n) = range (min m n) := by sorry,"First \( m \) Elements of `List.range n` Equal to `List.range (min(m, n))` : For any natural numbers \( m \) and \( n \), the first \( m \) elements of the list `List.range n` are equal to the list `List.range (min(m, n))`. In other words, `List.take m (List.range n)` is the list of natural numbers from \( 0 \) to \( \min(m, n) - 1 \).","theorem List.take_range (m n : Nat) : take m (range n) = range (min m n) := by
  apply List.ext_getElem
  · simp
  · simp (config := { contextual := true }) [← getElem_take, Nat.lt_min]","To prove that the first \( m \) elements of the list `List.range n` are equal to the list `List.range (min(m, n))`, we use the fact that two lists are equal if and only if their lengths are equal and their corresponding elements are equal for all indices within the bounds of the lists.

1. **Lengths of the Lists:**
We need to show that the lengths of `List.take m (List.range n)` and `List.range (min(m, n))` are equal. The length of `List.range n` is \( n \), and the length of `List.take m (List.range n)` is \( \min(m, n) \). Similarly, the length of `List.range (min(m, n))` is \( \min(m, n) \). Therefore, the lengths of both lists are equal to \( \min(m, n) \).

2. **Elementwise Equality:**
Next, we need to show that for every natural number \( n_1 \) such that \( n_1 < \min(m, n) \), the \( n_1 \)-th element of `List.take m (List.range n)` is equal to the \( n_1 \)-th element of `List.range (min(m, n))`. The \( n_1 \)-th element of `List.take m (List.range n)` is the same as the \( n_1 \)-th element of `List.range n` for \( n_1 < m \). Since \( n_1 < \min(m, n) \) implies \( n_1 < n \), the \( n_1 \)-th element of `List.range n` is \( n_1 \). Similarly, the \( n_1 \)-th element of `List.range (min(m, n))` is \( n_1 \). Therefore, the \( n_1 \)-th elements of both lists are equal for all \( n_1 < \min(m, n) \).

Since both the lengths and the corresponding elements of the lists are equal, we conclude that `List.take m (List.range n)` is equal to `List.range (min(m, n))`. This completes the proof.","theorem List.take_range (m n : Nat) : take m (range n) = range (min m n) := by
/- To prove that the first \( m \) elements of the list `List.range n` are equal to the list `List.range (min(m, n))`, it suffices to show that the lengths of these two lists are equal and that for every natural number \( n_1 \) such that \( n_1 < \text{length}(\text{take } m \, (\text{range } n)) \) and \( n_1 < \text{length}(\text{range } (min(m, n))) \), the \( n_1 \)-th element of `List.take m (List.range n)` is equal to the \( n_1 \)-th element of `List.range (min(m, n))`. -/
  apply List.ext_getElem
/- First, we show that the lengths of the two lists are equal. Using the fact that the length of `List.range n` is \( n \) and the length of `List.take m (List.range n)` is \( \min(m, n) \), we can simplify the proposition to show that \(\text{length}(\text{take } m \, (\text{range } n)) = \text{length}(\text{range } (min(m, n)))\). This is trivially true because both lengths are equal to \( \min(m, n) \). -/
  · simp
/- Next, we need to show that for every natural number \( n_1 \) such that \( n_1 < \text{length}(\text{take } m \, (\text{range } n)) \) and \( n_1 < \text{length}(\text{range } (min(m, n))) \), the \( n_1 \)-th element of `List.take m (List.range n)` is equal to the \( n_1 \)-th element of `List.range (min(m, n))`. Using the property that the \( n_1 \)-th element of `List.take m (List.range n)` is the same as the \( n_1 \)-th element of `List.range n` (for \( n_1 < m \)) and the fact that \( n_1 < \min(m, n) \) implies \( n_1 < n \), we can simplify the proposition to show that the \( n_1 \)-th element of `List.range n` is equal to the \( n_1 \)-th element of `List.range (min(m, n))`. This is trivially true because both lists contain the same elements from \( 0 \) to \( \min(m, n) - 1 \). -/
  · simp (config := { contextual := true }) [← getElem_take, Nat.lt_min]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1614,List.fst_lt_add_of_mem_enumFrom,"theorem List.fst_lt_add_of_mem_enumFrom {x : Nat × α} {n : Nat} {l : List α} (h : x ∈ enumFrom n l) :
    x.1 < n + length l := by sorry","First Component of Enumerated List Element is Less Than Sum of Starting Index and List Length : For any types \(\alpha\), any pair \(x = (i, a) \in \mathbb{N} \times \alpha\), any natural number \(n\), and any list \(l\) of elements of type \(\alpha\), if \(x\) is a member of the list \(\text{List.enumFrom} \, n \, l\), then the first component of \(x\) (i.e., \(i\)) is strictly less than \(n + \text{length}(l)\). In other words, if \(x \in \text{List.enumFrom} \, n \, l\), then \(i < n + |l|\).","theorem List.fst_lt_add_of_mem_enumFrom {x : Nat × α} {n : Nat} {l : List α} (h : x ∈ enumFrom n l) :
    x.1 < n + length l := by
  rcases mem_iff_get.1 h with ⟨i, rfl⟩
  simpa using i.isLt","We start by using the characterization of list membership. If \( x \in \text{List.enumFrom} \, n \, l \), then there exists an index \( i \) such that \( x \) is the \( i \)-th element of \(\text{List.enumFrom} \, n \, l\). We can write \( x \) as \( (i, a) \) where \( a \) is the corresponding element in the list. Thus, our goal is to show that \( i < n + \text{length}(l) \).

Since \( i \) is an element of \(\text{Fin} \, (\text{length}(\text{List.enumFrom} \, n \, l))\), by the property that the value of an element in \(\text{Fin} \, n\) is strictly less than \( n \), we have \( i < \text{length}(\text{List.enumFrom} \, n \, l) \). The length of \(\text{List.enumFrom} \, n \, l\) is \( n + \text{length}(l) \). Therefore, \( i < n + \text{length}(l) \), which completes the proof. \(\blacksquare\)","theorem List.fst_lt_add_of_mem_enumFrom {x : Nat × α} {n : Nat} {l : List α} (h : x ∈ enumFrom n l) :
    x.1 < n + length l := by
/- By the characterization of list membership, if \( x \in \text{List.enumFrom} \, n \, l \), then there exists an index \( i \) such that \( x \) is the \( i \)-th element of \(\text{List.enumFrom} \, n \, l\). We can write \( x \) as \( (i, a) \) where \( a \) is the corresponding element in the list. Thus, the goal is to show that \( i < n + \text{length}(l) \). -/
  rcases mem_iff_get.1 h with ⟨i, rfl⟩
/- Since \( i \) is an element of \(\text{Fin} \, (\text{length}(\text{List.enumFrom} \, n \, l))\), by the property that the value of an element in \(\text{Fin} \, n\) is strictly less than \( n \), we have \( i < \text{length}(\text{List.enumFrom} \, n \, l) \). The length of \(\text{List.enumFrom} \, n \, l\) is \( n + \text{length}(l) \). Therefore, \( i < n + \text{length}(l) \), which completes the proof. -/
  simpa using i.isLt","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1615,List.getElem_enumFrom,"theorem List.getElem_enumFrom (l : List α) (n) (i : Nat) (h : i < (l.enumFrom n).length) :
    (l.enumFrom n)[i] = (n + i, l[i]'(by simpa [enumFrom_length] using h)) := by sorry","Element at Index in Enumerated List: \((\text{List.enumFrom } n \, l)[i] = (n + i, l[i])\) : For any list \( l \) of elements of type \( \alpha \), any natural numbers \( n \) and \( i \), and any proof \( h \) that \( i \) is less than the length of the list `enumFrom n l`, the element at index \( i \) in the list `enumFrom n l` is the pair \((n + i, l[i])\). In other words, \((\text{List.enumFrom } n \, l)[i] = (n + i, l[i])\).","theorem List.getElem_enumFrom (l : List α) (n) (i : Nat) (h : i < (l.enumFrom n).length) :
    (l.enumFrom n)[i] = (n + i, l[i]'(by simpa [enumFrom_length] using h)) := by
  simp only [enumFrom_length] at h
  rw [getElem_eq_getElem?]
  simp only [getElem?_enumFrom, getElem?_eq_getElem h]
  simp","We start with the assumption that \( i < \text{length}(\text{enumFrom}(n, l)) \). Using the theorem that the length of the enumerated list `enumFrom n l` is equal to the length of the original list `l`, we can simplify this assumption to \( i < \text{length}(l) \).

Next, we need to show that the element at index \( i \) in the list `enumFrom n l` is equal to the pair \((n + i, l[i])\). By the theorem that the element at index \( i \) in a list is equal to the value obtained by extracting the element from the optional result of the list at index \( i \), we can replace the goal \( (\text{enumFrom}(n, l))[i] = (n + i, l[i]) \) with \( (\text{enumFrom}(n, l))[i]?.\text{get} = (n + i, l[i]) \).

Using the theorem that the optional element at index \( m \) in the enumerated list `enumFrom n l` is equal to the optional element at index \( m \) in \( l \) mapped to a pair \((n + m, a)\), and the theorem that the optional element at a valid index \( i \) in \( l \) is `some` of the element at index \( i \) in \( l \), we can simplify the goal to:
\[
(\text{Option.map} \, (\lambda a. (n + i, a)) \, \text{some} \, l[i]).\text{get} = (n + i, l[i])
\]

Finally, since the `get` operation on `some` returns the element inside the `some`, the goal simplifies to:
\[
(n + i, l[i]) = (n + i, l[i])
\]
which is trivially true by the properties of equality. This completes the proof.","theorem List.getElem_enumFrom (l : List α) (n) (i : Nat) (h : i < (l.enumFrom n).length) :
    (l.enumFrom n)[i] = (n + i, l[i]'(by simpa [enumFrom_length] using h)) := by
/- Using the theorem that the length of the enumerated list `enumFrom n l` is equal to the length of the original list `l`, we can simplify the assumption \( i < \text{length}(\text{enumFrom}(n, l)) \) to \( i < \text{length}(l) \). -/
  simp only [enumFrom_length] at h
/- Since the element at index \( i \) in the list `enumFrom n l` is equal to the value obtained by extracting the element from the optional result of `enumFrom n l` at index \( i \), we can replace the goal \( (\text{enumFrom}(n, l))[i] = (n + i, l[i]) \) with \( (\text{enumFrom}(n, l))[i]?.\text{get} = (n + i, l[i]) \). -/
  rw [getElem_eq_getElem?]
/- Using the theorem that the optional element at index \( m \) in the enumerated list `enumFrom n l` is equal to the optional element at index \( m \) in \( l \) mapped to a pair \((n + m, a)\), and the theorem that the optional element at a valid index \( i \) in \( l \) is `some` of the element at index \( i \) in \( l \), we can simplify the goal \( (\text{Option.map} \, (\lambda a. (n + i, a)) \, l[i]?).\text{get} = (n + i, l[i]) \). -/
  simp only [getElem?_enumFrom, getElem?_eq_getElem h]
/- After simplifying the expression, we get \( (\text{Option.map} \, (\lambda a. (n + i, a)) \, \text{some} \, l[i]).\text{get} = (n + i, l[i]) \), which is trivially true because the `get` operation on `some` returns the element inside the `some`. -/
  simp","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1617,List.enumFrom_cons',"theorem List.enumFrom_cons' (n : Nat) (x : α) (xs : List α) :
    enumFrom n (x :: xs) = (n, x) :: (enumFrom n xs).map (Prod.map (· + 1) id) := by sorry","Enumerating a Cons List from Initial Index: \((n, x) :: \text{List.map} \left( \text{Prod.map} \left( \lambda x. x + 1, \text{id} \right) \right) \left( \text{List.enumFrom}(n, xs) \right)\) : For any type \( \alpha \), any natural number \( n \), any element \( x \in \alpha \), and any list \( xs \) of elements of type \( \alpha \), the following equality holds:
\[
\text{List.enumFrom}(n, x :: xs) = (n, x) :: \text{List.map} \left( \text{Prod.map} \left( \lambda x. x + 1, \text{id} \right) \right) \left( \text{List.enumFrom}(n, xs) \right)
\]
In other words, if we enumerate the list \( x :: xs \) starting from \( n \), the result is the list starting with the pair \( (n, x) \) followed by the list obtained by mapping the function \( \lambda (i, y). (i + 1, y) \) over the enumerated list \( \text{List.enumFrom}(n, xs) \).","theorem List.enumFrom_cons' (n : Nat) (x : α) (xs : List α) :
    enumFrom n (x :: xs) = (n, x) :: (enumFrom n xs).map (Prod.map (· + 1) id) := by
  rw [enumFrom_cons, Nat.add_comm, ← map_fst_add_enumFrom_eq_enumFrom]","We start by using the definition of the function `List.enumFrom` applied to a cons list. Specifically, we know that:
\[
\text{List.enumFrom}(n, x :: xs) = (n, x) :: \text{List.enumFrom}(n + 1, xs)
\]
Next, we use the commutativity of addition in natural numbers to rewrite the index in the second part of the list:
\[
\text{List.enumFrom}(n + 1, xs) = \text{List.enumFrom}(1 + n, xs)
\]
Finally, we apply the theorem that states:
\[
\text{List.map} \left( \text{Prod.map} \left( \lambda x. x + 1, \text{id} \right) \right) \left( \text{List.enumFrom}(n, xs) \right) = \text{List.enumFrom}(1 + n, xs)
\]
This gives us:
\[
\text{List.enumFrom}(n, x :: xs) = (n, x) :: \text{List.map} \left( \text{Prod.map} \left( \lambda x. x + 1, \text{id} \right) \right) \left( \text{List.enumFrom}(n, xs) \right)
\]
Thus, the theorem is proved.","theorem List.enumFrom_cons' (n : Nat) (x : α) (xs : List α) :
    enumFrom n (x :: xs) = (n, x) :: (enumFrom n xs).map (Prod.map (· + 1) id) := by
/- First, we use the equivalence that the cardinality of a finite type is $0$ if and only if this type is empty, to convert the assumption of cardinality of $n = 0$ into $n$ is empty. -/
/- It suffices to show that $M = 1$ (the identity matrix), because if this is true, by using this $M = 1$ and simplifying, we get the determinant of $M$ is $1$ automatically. -/
/- Using extensionality, to prove that $M = 1$, we only need to show that $M i = 1 i$ for every $i \in n$. -/
/- Since $n$ is empty, this $M i = 1 i$ holds for every $i \in n$ vacuously. This finishes the proof. -/
  rw [enumFrom_cons, Nat.add_comm, ← map_fst_add_enumFrom_eq_enumFrom]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1618,List.mk_mem_enum_iff_getElem?,"theorem List.mk_mem_enum_iff_getElem? {i : Nat} {x : α} {l : List α} : (i, x) ∈ enum l ↔ l[i]? = x := by sorry","Membership in Enumerated List and Optional Lookup Equivalence : For any type \( \alpha \), a natural number \( i \), an element \( x \) of type \( \alpha \), and a list \( l \) of type \( \alpha \), the pair \((i, x)\) is a member of the enumerated list \( l.enum \) if and only if the optional lookup of \( l \) at index \( i \) returns \( x \), i.e., \( l[i]? = \text{some } x \).","theorem List.mk_mem_enum_iff_getElem? {i : Nat} {x : α} {l : List α} : (i, x) ∈ enum l ↔ l[i]? = x := by
  simp [enum, mk_mem_enumFrom_iff_le_and_getElem?_sub]","To prove the equivalence, we start by using the definition of the enumerated list \( l.enum \) and the known equivalence that \((i, x) \in l.enum \) if and only if \( i < \text{length}(l) \) and \( l[i] = x \).

By simplifying the proposition using these definitions, we get the desired equivalence:
\[
(i, x) \in l.enum \quad \text{if and only if} \quad l[i]? = \text{some } x
\]

This completes the proof.","theorem List.mk_mem_enum_iff_getElem? {i : Nat} {x : α} {l : List α} : (i, x) ∈ enum l ↔ l[i]? = x := by
/- Using the definition of the enumerated list \( l.enum \) and the equivalence \( (i, x) \in l.enum \) if and only if \( i < \text{length}(l) \) and \( l[i] = x \), we can simplify the proposition we want to show to the desired equivalence: \((i, x) \in l.enum \) if and only if \( l[i]? = \text{some } x \). -/
  simp [enum, mk_mem_enumFrom_iff_le_and_getElem?_sub]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1619,List.getElem_enum,"theorem List.getElem_enum (l : List α) (i : Nat) (h : i < l.enum.length) :
    l.enum[i] = (i, l[i]'(by simpa [enum_length] using h)) := by sorry","Element at Index in Enumerated List: \( l.\text{enum}[i] = (i, l[i]) \) : For any list \( l \) of elements of type \( \alpha \) and any natural number \( i \) such that \( i < \text{length}(l.\text{enum}) \), the element at index \( i \) in the enumerated list \( l.\text{enum} \) is the pair \((i, l[i])\). In other words, \( l.\text{enum}[i] = (i, l[i]) \).","theorem List.getElem_enum (l : List α) (i : Nat) (h : i < l.enum.length) :
    l.enum[i] = (i, l[i]'(by simpa [enum_length] using h)) := by
  simp [enum]","To prove the theorem, we start by using the definition of the enumeration function `List.enum`. The function `List.enum` takes a list \( l \) and returns a list of pairs, where each pair consists of an index and the corresponding element from \( l \). Specifically, the enumerated list \( l.\text{enum} \) is constructed such that the element at index \( i \) is the pair \((i, l[i])\).

Given the assumption that \( i < \text{length}(l.\text{enum}) \), we can directly conclude that the element at index \( i \) in the enumerated list \( l.\text{enum} \) is indeed the pair \((i, l[i])\). This is because the enumeration function `List.enum` is defined to produce exactly this result.

Thus, the proposition \( l.\text{enum}[i] = (i, l[i]) \) holds by the definition of the enumeration function. This completes the proof.","theorem List.getElem_enum (l : List α) (i : Nat) (h : i < l.enum.length) :
    l.enum[i] = (i, l[i]'(by simpa [enum_length] using h)) := by
/- Using the definition of the enumeration function `List.enum`, we can simplify the proposition we want to show to \( l.\text{enum}[i] = (i, l[i]) \). The function `List.enum` takes a list \( l \) and returns a list of pairs, where each pair consists of an index and the corresponding element from \( l \). Therefore, the element at index \( i \) in the enumerated list \( l.\text{enum} \) is the pair \((i, l[i])\). -/
  simp [enum]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1621,List.fst_lt_of_mem_enum,theorem List.fst_lt_of_mem_enum {x : Nat × α} {l : List α} (h : x ∈ enum l) : x.1 < length l := by sorry,"First Component of Enumerated List Member is Less Than List Length: \( i < \text{length}(l) \) if \( (i, a) \in l.\text{enum} \) : For any list \( l \) of elements of type \( \alpha \) and any pair \( x = (i, a) \) in the enumerated list \( l.\text{enum} \), if \( x \) is a member of \( l.\text{enum} \), then the first component \( i \) of \( x \) is strictly less than the length of the list \( l \). In other words, if \( (i, a) \in l.\text{enum} \), then \( i < \text{length}(l) \).","theorem List.fst_lt_of_mem_enum {x : Nat × α} {l : List α} (h : x ∈ enum l) : x.1 < length l := by
  simpa using fst_lt_add_of_mem_enumFrom h","To prove that if \( (i, a) \in l.\text{enum} \), then \( i < \text{length}(l) \), we use the fact that the enumerated list \( l.\text{enum} \) is equivalent to \( \text{List.enumFrom} \, 0 \, l \). Specifically, if \( (i, a) \in \text{List.enumFrom} \, 0 \, l \), then \( i < 0 + \text{length}(l) \). Simplifying this, we get \( i < \text{length}(l) \). Since this is exactly what we need to show, the proof is complete.","theorem List.fst_lt_of_mem_enum {x : Nat × α} {l : List α} (h : x ∈ enum l) : x.1 < length l := by
/- Using the fact that if \( (i, a) \in \text{List.enumFrom} \, 0 \, l \), then \( i < 0 + \text{length}(l) \), we can simplify the proposition we want to show to \( i < \text{length}(l) \). We see that this is exactly what we need to prove, thus finishing the proof. -/
  simpa using fst_lt_add_of_mem_enumFrom h","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1622,List.getElem?_enum,"theorem List.getElem?_enum (l : List α) (n : Nat) : (enum l)[n]? = l[n]?.map fun a => (n, a) := by sorry","Element Retrieval in Enumerated List Equals Mapped Element Retrieval in Original List : For any list \( l \) of elements of type \( \alpha \) and any natural number \( n \), the optional element at index \( n \) in the enumerated list \( l.\text{enum} \) is equal to the optional result of mapping the function \( a \mapsto (n, a) \) to the optional element at index \( n \) in the original list \( l \). Formally, this is expressed as:
\[
l.\text{enum}[n]? = \text{Option.map} \, (\lambda a \mapsto (n, a)) \, l[n]?
\]","theorem List.getElem?_enum (l : List α) (n : Nat) : (enum l)[n]? = l[n]?.map fun a => (n, a) := by
  rw [enum, getElem?_enumFrom, Nat.zero_add]","To prove the theorem, we start by using the definition of the enumerated list `List.enum`. The function `List.enum` is defined as `List.enumFrom 0`, which means it enumerates the elements of the list \( l \) starting from index 0. Therefore, the goal can be rewritten as:
\[
(\text{enumFrom}(0, l))[n]? = \text{Option.map} \, (\lambda a. (n, a)) \, l[n]?
\]

Next, we use the theorem that states the optional element at index \( m \) in the enumerated list `enumFrom n l` is equal to the optional element at index \( m \) in \( l \) mapped to a pair \((n + m, a)\). Applying this theorem with \( n = 0 \) and \( m = n \), we get:
\[
(\text{enumFrom}(0, l))[n]? = \text{Option.map} \, (\lambda a. (0 + n, a)) \, l[n]?
\]

Finally, we use the property that the zero element is the additive identity, i.e., \( 0 + n = n \), to simplify the expression:
\[
\text{Option.map} \, (\lambda a. (0 + n, a)) \, l[n]? = \text{Option.map} \, (\lambda a. (n, a)) \, l[n]?
\]

Thus, the goal is now:
\[
\text{Option.map} \, (\lambda a. (n, a)) \, l[n]? = \text{Option.map} \, (\lambda a. (n, a)) \, l[n]?
\]

This is trivially true by the properties of equality. Therefore, the theorem is proved. \(\blacksquare\)","theorem List.getElem?_enum (l : List α) (n : Nat) : (enum l)[n]? = l[n]?.map fun a => (n, a) := by
/- First, we use the definition of the enumerated list `List.enum` to rewrite the goal. The function `List.enum` is equivalent to `List.enumFrom 0`, so the goal becomes:
\[
(\text{enumFrom}(0, l))[n]? = \text{Option.map} \, (\lambda a. (n, a)) \, l[n]?
\]
Next, we use the theorem that states the optional element at index \( m \) in the enumerated list `enumFrom n l` is equal to the optional element at index \( m \) in \( l \) mapped to a pair \((n + m, a)\). Applying this theorem with \( n = 0 \) and \( m = n \), we get:
\[
(\text{enumFrom}(0, l))[n]? = \text{Option.map} \, (\lambda a. (0 + n, a)) \, l[n]?
\]
Finally, we use the property that the zero element is the additive identity, i.e., \( 0 + n = n \), to simplify the expression:
\[
\text{Option.map} \, (\lambda a. (0 + n, a)) \, l[n]? = \text{Option.map} \, (\lambda a. (n, a)) \, l[n]?
\]
Thus, the goal is now:
\[
\text{Option.map} \, (\lambda a. (n, a)) \, l[n]? = \text{Option.map} \, (\lambda a. (n, a)) \, l[n]?
\]
This is trivially true by the properties of equality. -/
  rw [enum, getElem?_enumFrom, Nat.zero_add]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1623,List.enum_append,theorem List.enum_append (xs ys : List α) : enum (xs ++ ys) = enum xs ++ enumFrom xs.length ys := by sorry,"Enumeration of Concatenated Lists: \((xs ++ ys).enum = xs.enum ++ \text{enumFrom}(xs.length, ys)\) : For any lists \( xs \) and \( ys \) of elements of type \( \alpha \), the enumeration of the concatenated list \( xs ++ ys \) is equal to the concatenation of the enumeration of \( xs \) and the enumeration of \( ys \) starting from the length of \( xs \). In other words, \((xs ++ ys).enum = xs.enum ++ \text{enumFrom}(xs.length, ys)\).","theorem List.enum_append (xs ys : List α) : enum (xs ++ ys) = enum xs ++ enumFrom xs.length ys := by
  simp [enum, enumFrom_append]","To prove the theorem, we use the definition of the enumeration function and a key property of the enumeration of concatenated lists. Specifically, the definition of the enumeration function `enum` and the property that the enumeration of a concatenated list starting from an initial index is the concatenation of the enumerations of the individual lists starting from the appropriate indices. This property can be formally stated as:
\[
\text{enumFrom}(n, xs ++ ys) = \text{enumFrom}(n, xs) ++ \text{enumFrom}(n + \text{length}(xs), ys)
\]
By applying this property with \( n = 0 \), we get:
\[
(xs ++ ys).enum = \text{enumFrom}(0, xs ++ ys) = \text{enumFrom}(0, xs) ++ \text{enumFrom}(\text{length}(xs), ys) = xs.enum ++ \text{enumFrom}(\text{length}(xs), ys)
\]
Thus, the proposition \((xs ++ ys).enum = xs.enum ++ \text{enumFrom}(xs.length, ys)\) is true. This completes the proof.","theorem List.enum_append (xs ys : List α) : enum (xs ++ ys) = enum xs ++ enumFrom xs.length ys := by
/- Using the definition of the enumeration function and the property that the enumeration of a concatenated list starting from an initial index is the concatenation of the enumerations of the individual lists starting from the appropriate indices, we can simplify the proposition we want to show to the desired equality. Specifically, the definition of `enum` and the property that \(\text{enumFrom}(n, xs ++ ys) = \text{enumFrom}(n, xs) ++ \text{enumFrom}(n + \text{length}(xs), ys)\) allow us to conclude that \((xs ++ ys).enum = xs.enum ++ \text{enumFrom}(xs.length, ys)\). -/
  simp [enum, enumFrom_append]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1624,List.enum_map_fst,theorem List.enum_map_fst (l : List α) : map Prod.fst (enum l) = range l.length := by sorry,"Mapping First Component of Enumerated List Equals Range of List Length : For any list \( l \) of elements of type \( \alpha \), the result of mapping the first component function `Prod.fst` over the enumerated list `l.enum` is equal to the list of natural numbers from \( 0 \) to \( \text{length}(l) - 1 \), i.e., \(\text{map}(\text{fst}, \text{enum}(l)) = \text{range}(\text{length}(l))\).","theorem List.enum_map_fst (l : List α) : map Prod.fst (enum l) = range l.length := by
  simp only [enum, enumFrom_map_fst, range_eq_range']","To prove the theorem, we start by simplifying the expression using the definitions and properties of the enumerated list and the range function. Specifically, we use the following facts:
1. The enumerated list \(\text{enum}(l)\) is equivalent to \(\text{enumFrom}(0, l)\).
2. Mapping the first component function \(\text{Prod.fst}\) over \(\text{enumFrom}(n, l)\) results in the list of natural numbers from \( n \) to \( n + \text{length}(l) - 1 \).
3. The list \(\text{range}(n)\) is equivalent to \(\text{range'}(0, n)\).

Using these properties, we can rewrite the left-hand side of the equation:
\[
\text{map} \, (\text{fst}) \, (\text{enum} \, l) = \text{map} \, (\text{fst}) \, (\text{enumFrom} \, 0 \, l)
\]
By the property of \(\text{enumFrom}\), this simplifies to:
\[
\text{map} \, (\text{fst}) \, (\text{enumFrom} \, 0 \, l) = \text{range'} \, 0 \, (\text{length} \, l)
\]
Finally, using the property of \(\text{range}\), we have:
\[
\text{range'} \, 0 \, (\text{length} \, l) = \text{range} \, (\text{length} \, l)
\]
Thus, we have shown that:
\[
\text{map} \, (\text{fst}) \, (\text{enum} \, l) = \text{range} \, (\text{length} \, l)
\]
This completes the proof.","theorem List.enum_map_fst (l : List α) : map Prod.fst (enum l) = range l.length := by
/- Using the definitions and properties of the enumerated list and the range function, we can simplify the proposition we want to show to:
\[
\text{map} \, (\text{fst}) \, (\text{enum} \, l) = \text{range} \, (\text{length} \, l)
\]
Specifically, we use the fact that:
1. The enumerated list `enum l` is equivalent to `enumFrom 0 l`.
2. Mapping the first component function `Prod.fst` over `enumFrom n l` results in the list of natural numbers from \( n \) to \( n + \text{length}(l) - 1 \).
3. The list `range n` is equivalent to `range' 0 n`. -/
  simp only [enum, enumFrom_map_fst, range_eq_range']","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1625,List.map_enumFrom,"theorem List.map_enumFrom (f : α → β) (n : Nat) (l : List α) :
    map (Prod.map id f) (enumFrom n l) = enumFrom n (map f l) := by sorry","Mapping Enumerated List with Function Pairing : For any types \(\alpha\) and \(\beta\), any function \(f : \alpha \to \beta\), any natural number \(n\), and any list \(l\) of elements of type \(\alpha\), the following equality holds:
\[
\text{List.map} \, (\text{Prod.map} \, \text{id} \, f) \, (\text{List.enumFrom} \, n \, l) = \text{List.enumFrom} \, n \, (\text{List.map} \, f \, l)
\]
This theorem states that applying the function \(\text{Prod.map} \, \text{id} \, f\) to each pair in the list \(\text{List.enumFrom} \, n \, l\) and then mapping the resulting list is equivalent to first mapping the list \(l\) with \(f\) and then enumerating the result starting from \(n\).","theorem List.map_enumFrom (f : α → β) (n : Nat) (l : List α) :
    map (Prod.map id f) (enumFrom n l) = enumFrom n (map f l) := by
  induction l generalizing n <;> simp_all","We perform induction on the list \( l \) to break down the proof into cases, generalizing over the natural number \( n \).

1. **Base Case:**
- Suppose \( l \) is the empty list, i.e., \( l = [] \).
- We need to show:
\[
\text{List.map} \, (\text{Prod.map} \, \text{id} \, f) \, (\text{List.enumFrom} \, n \, []) = \text{List.enumFrom} \, n \, (\text{List.map} \, f \, [])
\]
- By the definition of \(\text{List.enumFrom}\), \(\text{List.enumFrom} \, n \, [] = []\).
- By the definition of \(\text{List.map}\), \(\text{List.map} \, f \, [] = []\).
- Therefore, the left-hand side simplifies to:
\[
\text{List.map} \, (\text{Prod.map} \, \text{id} \, f) \, [] = []
\]
- And the right-hand side simplifies to:
\[
\text{List.enumFrom} \, n \, [] = []
\]
- Hence, the base case holds trivially.

2. **Inductive Step:**
- Suppose \( l = \text{head} :: \text{tail} \), where \(\text{head} \in \alpha\) and \(\text{tail} \) is a list of elements of type \(\alpha\).
- We need to show:
\[
\text{List.map} \, (\text{Prod.map} \, \text{id} \, f) \, (\text{List.enumFrom} \, n \, (\text{head} :: \text{tail})) = \text{List.enumFrom} \, n \, (\text{List.map} \, f \, (\text{head} :: \text{tail}))
\]
- By the definition of \(\text{List.enumFrom}\), we have:
\[
\text{List.enumFrom} \, n \, (\text{head} :: \text{tail}) = (n, \text{head}) :: \text{List.enumFrom} \, (n + 1) \, \text{tail}
\]
- By the definition of \(\text{List.map}\), we have:
\[
\text{List.map} \, f \, (\text{head} :: \text{tail}) = f \, \text{head} :: \text{List.map} \, f \, \text{tail}
\]
- Therefore, the right-hand side becomes:
\[
\text{List.enumFrom} \, n \, (f \, \text{head} :: \text{List.map} \, f \, \text{tail}) = (n, f \, \text{head}) :: \text{List.enumFrom} \, (n + 1) \, (\text{List.map} \, f \, \text{tail})
\]
- For the left-hand side, we apply \(\text{List.map} \, (\text{Prod.map} \, \text{id} \, f)\) to \((n, \text{head}) :: \text{List.enumFrom} \, (n + 1) \, \text{tail}\):
\[
\text{List.map} \, (\text{Prod.map} \, \text{id} \, f) \, ((n, \text{head}) :: \text{List.enumFrom} \, (n + 1) \, \text{tail}) = (\text{Prod.map} \, \text{id} \, f) \, (n, \text{head}) :: \text{List.map} \, (\text{Prod.map} \, \text{id} \, f) \, (\text{List.enumFrom} \, (n + 1) \, \text{tail})
\]
- By the definition of \(\text{Prod.map}\), we have:
\[
(\text{Prod.map} \, \text{id} \, f) \, (n, \text{head}) = (n, f \, \text{head})
\]
- Therefore, the left-hand side becomes:
\[
(n, f \, \text{head}) :: \text{List.map} \, (\text{Prod.map} \, \text{id} \, f) \, (\text{List.enumFrom} \, (n + 1) \, \text{tail})
\]
- By the inductive hypothesis, we know:
\[
\text{List.map} \, (\text{Prod.map} \, \text{id} \, f) \, (\text{List.enumFrom} \, (n + 1) \, \text{tail}) = \text{List.enumFrom} \, (n + 1) \, (\text{List.map} \, f \, \text{tail})
\]
- Substituting this into the left-hand side, we get:
\[
(n, f \, \text{head}) :: \text{List.enumFrom} \, (n + 1) \, (\text{List.map} \, f \, \text{tail})
\]
- This matches the right-hand side, thus the inductive step holds.

By induction, the theorem is proved for all lists \( l \) and natural numbers \( n \). This completes the proof.","theorem List.map_enumFrom (f : α → β) (n : Nat) (l : List α) :
    map (Prod.map id f) (enumFrom n l) = enumFrom n (map f l) := by
/- We perform induction on the list \( l \) to break down the proof into cases, generalizing over the natural number \( n \). For the base case where \( l \) is the empty list, we simplify the proposition and the hypothesis to show that the equality holds. For the inductive step, we assume the proposition holds for the tail of the list \( l \) and simplify the proposition and the hypothesis to show that the equality holds for the entire list \( l \). -/
  induction l generalizing n <;> simp_all","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1626,List.unzip_enum_eq_prod,"theorem List.unzip_enum_eq_prod (l : List α) : l.enum.unzip = (range l.length, l) := by sorry","Unzip of Enumerated List Equals Pair of Range and Original List : For any list \( l \) of elements of type \( \alpha \), the `unzip` operation applied to the enumeration of \( l \) (i.e., `l.enum`) results in a pair of lists: the first list is the range of natural numbers from \( 0 \) to \( \text{length}(l) - 1 \), and the second list is \( l \) itself. Formally, this can be written as:
\[
\text{unzip}(\text{enum}(l)) = (\text{range}(\text{length}(l)), l)
\]","theorem List.unzip_enum_eq_prod (l : List α) : l.enum.unzip = (range l.length, l) := by
  simp only [enum_eq_zip_range, unzip_zip, length_range]","To prove the theorem, we start by using the definition of the enumeration of a list. The enumeration of a list \( l \) is the zip of the range of natural numbers from \( 0 \) to \( \text{length}(l) - 1 \) with the list \( l \) itself. Formally, this can be written as:
\[
l.\text{enum} = \text{zip}(\text{range}(\text{length}(l)), l)
\]

Next, we use the property of the `unzip` operation on zipped lists. Specifically, if two lists \( l_1 \) and \( l_2 \) have equal lengths, then unzipping the zipped list \( l_1 \text{ zip } l_2 \) returns the original lists \( (l_1, l_2) \). Formally, if \( |l_1| = |l_2| \), then:
\[
(l_1 \text{ zip } l_2). \text{unzip} = (l_1, l_2)
\]

In our case, the list \(\text{range}(\text{length}(l))\) has a length equal to \(\text{length}(l)\), as given by the property of the `range` function:
\[
\text{length}(\text{range}(\text{length}(l))) = \text{length}(l)
\]

Therefore, we can apply the `unzip` operation to the zipped list \(\text{zip}(\text{range}(\text{length}(l)), l)\) and get:
\[
\text{unzip}(\text{zip}(\text{range}(\text{length}(l)), l)) = (\text{range}(\text{length}(l)), l)
\]

Since the left-hand side of the equation is exactly \(\text{unzip}(l.\text{enum})\), we have:
\[
\text{unzip}(l.\text{enum}) = (\text{range}(\text{length}(l)), l)
\]

This completes the proof.","theorem List.unzip_enum_eq_prod (l : List α) : l.enum.unzip = (range l.length, l) := by
/- Using the fact that the enumeration of a list \( l \) is the zip of the range of natural numbers from \( 0 \) to \( \text{length}(l) - 1 \) with \( l \) itself, and the property that unzipping a zipped list with equal lengths returns the original lists, and the property that the length of the range list is equal to the given natural number, we can simplify the proposition we want to show to:
\[
\text{unzip}(\text{zip}(\text{range}(\text{length}(l)), l)) = (\text{range}(\text{length}(l)), l)
\]
Since the lengths of \(\text{range}(\text{length}(l))\) and \( l \) are equal, the unzipping operation returns the original lists, thus the goal is trivially true. -/
  simp only [enum_eq_zip_range, unzip_zip, length_range]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
1628,List.enumFrom_map,"theorem List.enumFrom_map (n : Nat) (l : List α) (f : α → β) :
    enumFrom n (l.map f) = (enumFrom n l).map (Prod.map id f) := by sorry","Enumeration of Mapped List Equals Mapped Enumeration of List : For any lists \( l \) of elements of type \( \alpha \) and any natural number \( n \), and for any function \( f : \alpha \to \beta \), the enumeration of the list \( \text{map}(f, l) \) starting from \( n \) is equal to the list obtained by applying the function \( \text{Prod.map}(\text{id}, f) \) to each pair in the enumeration of \( l \) starting from \( n \). Formally, this can be written as:
\[
\text{enumFrom}(n, \text{map}(f, l)) = \text{map}(\text{Prod.map}(\text{id}, f), \text{enumFrom}(n, l))
\]","theorem List.enumFrom_map (n : Nat) (l : List α) (f : α → β) :
    enumFrom n (l.map f) = (enumFrom n l).map (Prod.map id f) := by
  induction l with
  | nil => rfl
  | cons hd tl IH =>
    rw [map_cons, enumFrom_cons', enumFrom_cons', map_cons, map_map, IH, map_map]
    rfl","We prove the theorem by induction on the list \( l \).

1. **Base Case:**
Consider the case where \( l \) is the empty list. The goal is to show:
\[
\text{enumFrom}(n, \text{map}(f, [])) = \text{map}(\text{Prod.map}(\text{id}, f), \text{enumFrom}(n, []))
\]
Since both sides of the equation are definitionally equal to the empty list, the base case is trivially true.

2. **Inductive Step:**
Assume \( l = \text{cons}(hd, tl) \), where \( hd \) is the head of the list and \( tl \) is the tail. We assume the inductive hypothesis \( \text{IH} \) that:
\[
\text{enumFrom}(n, \text{map}(f, tl)) = \text{map}(\text{Prod.map}(\text{id}, f), \text{enumFrom}(n, tl))
\]
We need to show:
\[
\text{enumFrom}(n, \text{map}(f, \text{cons}(hd, tl))) = \text{map}(\text{Prod.map}(\text{id}, f), \text{enumFrom}(n, \text{cons}(hd, tl)))
\]
Using the properties of mapping a function over a cons list and enumerating a cons list from an initial index, we can rewrite the left-hand side as:
\[
\text{enumFrom}(n, \text{map}(f, \text{cons}(hd, tl))) = (n, f(hd)) :: \text{map}(\text{Prod.map}(\lambda x. x + 1, \text{id}), \text{enumFrom}(n, \text{map}(f, tl)))
\]
By the inductive hypothesis, we have:
\[
\text{enumFrom}(n, \text{map}(f, tl)) = \text{map}(\text{Prod.map}(\text{id}, f), \text{enumFrom}(n, tl))
\]
Substituting this into the left-hand side, we get:
\[
(n, f(hd)) :: \text{map}(\text{Prod.map}(\lambda x. x + 1, \text{id}), \text{map}(\text{Prod.map}(\text{id}, f), \text{enumFrom}(n, tl)))
\]
Using the property of mapping a composition of functions, we can rewrite the right-hand side as:
\[
\text{map}(\text{Prod.map}(\text{id}, f), (n, hd) :: \text{map}(\text{Prod.map}(\lambda x. x + 1, \text{id}), \text{enumFrom}(n, tl))) = (n, f(hd)) :: \text{map}(\text{Prod.map}(\text{id}, f) \circ \text{Prod.map}(\lambda x. x + 1, \text{id}), \text{enumFrom}(n, tl))
\]
Since both sides of the equation are now definitionally equal, the inductive step is proven.

By induction, the theorem holds for all lists \( l \) of elements of type \( \alpha \). This completes the proof.","theorem List.enumFrom_map (n : Nat) (l : List α) (f : α → β) :
    enumFrom n (l.map f) = (enumFrom n l).map (Prod.map id f) := by
  induction l with
/- First, consider the base case where the list \( l \) is empty. The goal is to show that:
\[
\text{enumFrom}(n, \text{map}(f, [])) = \text{map}(\text{Prod.map}(\text{id}, f), \text{enumFrom}(n, []))
\]
Since both sides of the equation are definitionally equal to the empty list, the base case is trivially true. -/
  | nil => rfl
/- Next, consider the inductive case where the list \( l \) is non-empty, i.e., \( l = \text{cons}(hd, tl) \). We assume the inductive hypothesis \( \text{IH} \) that:
\[
\text{enumFrom}(n, \text{map}(f, tl)) = \text{map}(\text{Prod.map}(\text{id}, f), \text{enumFrom}(n, tl))
\]
We need to show that:
\[
\text{enumFrom}(n, \text{map}(f, \text{cons}(hd, tl))) = \text{map}(\text{Prod.map}(\text{id}, f), \text{enumFrom}(n, \text{cons}(hd, tl)))
\] -/
  | cons hd tl IH =>
/- We use the following properties to simplify the goal:
1. The property of mapping a function over a cons list: \(\text{map}(f, \text{cons}(hd, tl)) = \text{cons}(f(hd), \text{map}(f, tl))\).
2. The property of enumerating a cons list from an initial index: \(\text{enumFrom}(n, \text{cons}(hd, tl)) = (n, hd) :: \text{map}(\text{Prod.map}(\lambda x. x + 1, \text{id}), \text{enumFrom}(n, tl))\).
3. The inductive hypothesis: \(\text{enumFrom}(n, \text{map}(f, tl)) = \text{map}(\text{Prod.map}(\text{id}, f), \text{enumFrom}(n, tl))\).
4. The property of mapping a composition of functions: \(\text{map}(g, \text{map}(f, l)) = \text{map}(g \circ f, l)\).

Using these properties, we can rewrite the goal as:
\[
(n, f(hd)) :: \text{map}(\text{Prod.map}(\lambda x. x + 1, \text{id}), \text{map}(\text{Prod.map}(\text{id}, f), \text{enumFrom}(n, tl))) = \text{map}(\text{Prod.map}(\text{id}, f), (n, hd) :: \text{map}(\text{Prod.map}(\lambda x. x + 1, \text{id}), \text{enumFrom}(n, tl)))
\] -/
    rw [map_cons, enumFrom_cons', enumFrom_cons', map_cons, map_map, IH, map_map]
/- The current goal is trivially true due to the reflexive property. Both sides of the equation are definitionally equal, thus the inductive step is proven. -/
    rfl","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
3190,Nat.mod_self,theorem Nat.mod_self (n : Nat) : n % n = 0 := by sorry,"Modulo of a Number by Itself is Zero : For any natural number \( n \), the modulo operation \( n \% n \) is equal to 0, i.e., \( n \% n = 0 \).","theorem Nat.mod_self (n : Nat) : n % n = 0 := by
  rw [mod_eq_sub_mod (Nat.le_refl _), Nat.sub_self, zero_mod]","We begin by using the property of the modulo operation that for any natural numbers \(a\) and \(b\) such that \(a \geq b\), \(a \% b = (a - b) \% b\). Since \(n \geq n\) by reflexivity, we have:

\[
n \% n = (n - n) \% n
\]

Next, we use the fact that for any natural number \(n\), \(n - n = 0\):

\[
(n - n) \% n = 0 \% n
\]

Finally, we use the property that for any natural number \(b\), \(0 \% b = 0\):

\[
0 \% n = 0
\]

Thus, we have shown that \(n \% n = 0\). This completes the proof.","theorem Nat.mod_self (n : Nat) : n % n = 0 := by
/- We start by rewriting the goal using the property that for any natural numbers \(a\) and \(b\) such that \(a \geq b\), \(a \% b = (a - b) \% b\). Since \(n \geq n\) by reflexivity, we have \(n \% n = (n - n) \% n\). Next, we use the fact that for any natural number \(n\), \(n - n = 0\) to simplify \((n - n) \% n\) to \(0 \% n\). Finally, we use the property that for any natural number \(b\), \(0 \% b = 0\) to conclude that \(0 \% n = 0\). -/
  rw [mod_eq_sub_mod (Nat.le_refl _), Nat.sub_self, zero_mod]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3191,Nat.div_zero,theorem Nat.div_zero (n : Nat) : n / 0 = 0 := by sorry,"Division of Any Natural Number by Zero is Zero : For any natural number \( n \), the division of \( n \) by \( 0 \) is \( 0 \), i.e., \( n / 0 = 0 \).","theorem Nat.div_zero (n : Nat) : n / 0 = 0 := by
  rw [div_eq]; simp [Nat.lt_irrefl]","We begin by considering the definition of division for natural numbers. The division \( n / 0 \) is defined as the number of times \( 0 \) can be subtracted from \( n \) without making \( n \) negative. Since subtracting \( 0 \) from \( n \) does not change \( n \), and there is no natural number \( k \) such that \( k \cdot 0 = n \) for any \( n \neq 0 \), the result of this operation is \( 0 \). Furthermore, we use the property that no natural number is less than itself, which is a trivial fact, to simplify our reasoning. Thus, we conclude that \( n / 0 = 0 \) for any natural number \( n \).","theorem Nat.div_zero (n : Nat) : n / 0 = 0 := by
/- We start by rewriting the division operation using its definition. The definition of division states that \( n / 0 \) is the number of times \( 0 \) can be subtracted from \( n \) without making \( n \) negative. Since subtracting \( 0 \) from \( n \) does not change \( n \), and there is no natural number \( k \) such that \( k \cdot 0 = n \) for any \( n \neq 0 \), the result is \( 0 \). Additionally, we simplify using the fact that no natural number is less than itself, which is a trivial property of natural numbers. -/
  rw [div_eq]; simp [Nat.lt_irrefl]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3194,Nat.div_eq_sub_div,theorem Nat.div_eq_sub_div (h₁ : 0 < b) (h₂ : b ≤ a) : a / b = (a - b) / b + 1 := by sorry,"Division Identity: \(a / b = (a - b) / b + 1\) for \(0 < b \le a\) : For any natural numbers \(a\) and \(b\) such that \(0 < b\) and \(b \le a\), the division \(a / b\) is equal to \((a - b) / b + 1\), i.e., \(a / b = (a - b) / b + 1\).","theorem Nat.div_eq_sub_div (h₁ : 0 < b) (h₂ : b ≤ a) : a / b = (a - b) / b + 1 := by
 rw [div_eq a, if_pos]; constructor <;> assumption","We begin by using the definition of division for natural numbers, which states that \(a / b\) is defined as the maximum \(k\) such that \(b \cdot k \leq a\). Given the conditions \(0 < b\) and \(b \leq a\), the condition for the positive branch of the if-statement in the definition of division is satisfied. Therefore, we can simplify the goal to show that \(a / b = (a - b) / b + 1\) by using the positive branch of the if-statement. This branch requires us to prove two conditions: \(0 < b\) and \(b \leq a\), which are already given as assumptions. Thus, the goal is satisfied, and we have shown that \(a / b = (a - b) / b + 1\).","theorem Nat.div_eq_sub_div (h₁ : 0 < b) (h₂ : b ≤ a) : a / b = (a - b) / b + 1 := by
/- We start by rewriting the goal using the definition of division for natural numbers, which states that \(a / b\) is defined as the maximum \(k\) such that \(b \cdot k \leq a\). Given the conditions \(0 < b\) and \(b \leq a\), the condition for the positive branch of the if-statement in the definition of division is satisfied. Therefore, we can simplify the goal to show that \(a / b = (a - b) / b + 1\) by using the positive branch of the if-statement. This branch requires us to prove two conditions: \(0 < b\) and \(b \leq a\), which are already given as assumptions. -/
 rw [div_eq a, if_pos]; constructor <;> assumption","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3196,Nat.mod_def,theorem Nat.mod_def (m k : Nat) : m % k = m - k * (m / k) := by sorry,"Modulo Operation Definition: \( m \% k = m - k \cdot (m / k) \) : For any natural numbers \( m \) and \( k \), the modulo operation \( m \% k \) is defined as \( m - k \cdot (m / k) \), i.e., \( m \% k = m - k \cdot (m / k) \).","theorem Nat.mod_def (m k : Nat) : m % k = m - k * (m / k) := by
  rw [Nat.sub_eq_of_eq_add]
  apply (Nat.mod_add_div _ _).symm","We begin by rewriting the goal using the property that \( m - k \cdot (m / k) = m \) if \( m = m \% k + k \cdot (m / k) \). This transforms our goal from \( m \% k = m - k \cdot (m / k) \) to \( m = m \% k + k \cdot (m / k) \).

Next, we use the symmetric form of the theorem stating that \( m \% k + k \cdot (m / k) = m \). This theorem directly implies our goal, completing the proof. Therefore, we have shown that \( m \% k = m - k \cdot (m / k) \).","theorem Nat.mod_def (m k : Nat) : m % k = m - k * (m / k) := by
/- We start by rewriting the goal using the property that \( m - k \cdot (m / k) = m \) if \( m = m \% k + k \cdot (m / k) \). This transforms our goal from \( m \% k = m - k \cdot (m / k) \) to \( m = m \% k + k \cdot (m / k) \). -/
  rw [Nat.sub_eq_of_eq_add]
/- To prove that \( m = m \% k + k \cdot (m / k) \), we use the symmetric form of the theorem stating that \( m \% k + k \cdot (m / k) = m \). This theorem directly implies our goal, completing the proof. -/
  apply (Nat.mod_add_div _ _).symm","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3197,Nat.div_lt_iff_lt_mul,theorem Nat.div_lt_iff_lt_mul (Hk : 0 < k) : x / k < y ↔ x < y * k := by sorry,"Division Less Than Characterization: \(\frac{x}{k} < y \leftrightarrow x < y \cdot k\) : For any natural numbers \( k \), \( x \), and \( y \) such that \( k > 0 \), the quotient \( \frac{x}{k} \) is strictly less than \( y \) if and only if \( x \) is strictly less than \( y \cdot k \), i.e., \( \frac{x}{k} < y \leftrightarrow x < y \cdot k \).","theorem Nat.div_lt_iff_lt_mul (Hk : 0 < k) : x / k < y ↔ x < y * k := by
  rw [← Nat.not_le, ← Nat.not_le]; exact not_congr (le_div_iff_mul_le Hk)","We begin by considering the logical equivalence between ""not less than or equal to"" and ""greater than"" for natural numbers. This allows us to rewrite the goal as \( \neg (x / k \ge y) \leftrightarrow \neg (x \ge y \cdot k) \). Next, we use the contrapositive of the inequality \( x / k \ge y \leftrightarrow x \ge y \cdot k \), which holds under the assumption \( k > 0 \). This equivalence is precisely what we need to show, and thus the proof is complete.","theorem Nat.div_lt_iff_lt_mul (Hk : 0 < k) : x / k < y ↔ x < y * k := by
/- We start by rewriting the goal using the logical equivalence between ""not less than or equal to"" and ""greater than"" for natural numbers. Specifically, we replace \( x / k < y \) with \( \neg (x / k \ge y) \) and \( x < y \cdot k \) with \( \neg (x \ge y \cdot k) \). Then, we use the contrapositive of the inequality \( x / k \ge y \leftrightarrow x \ge y \cdot k \) (which holds under the assumption \( k > 0 \)) to complete the proof. -/
  rw [← Nat.not_le, ← Nat.not_le]; exact not_congr (le_div_iff_mul_le Hk)","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3199,Nat.add_div_left,theorem Nat.add_div_left (x : Nat) {z : Nat} (H : 0 < z) : (z + x) / z = (x / z) + 1 := by sorry,"Left Addition Preserves Division in Natural Numbers: \(\frac{z + x}{z} = \frac{x}{z} + 1\) : For any natural numbers \( x \) and \( z \), if \( z \) is strictly greater than zero, then the division of the sum \( z + x \) by \( z \) is equal to the sum of the division of \( x \) by \( z \) and 1, i.e., \(\frac{z + x}{z} = \frac{x}{z} + 1\).","theorem Nat.add_div_left (x : Nat) {z : Nat} (H : 0 < z) : (z + x) / z = (x / z) + 1 := by
  rw [Nat.add_comm, add_div_right x H]","We start by using the commutativity of addition in natural numbers, which allows us to rewrite \( z + x \) as \( x + z \). Given that \( z > 0 \), we can then apply the theorem that \(\frac{x + z}{z} = \frac{x}{z} + 1\). This simplifies our goal to \(\frac{x}{z} + 1 = \frac{x}{z} + 1\), which is trivially true. Therefore, we have shown that \(\frac{z + x}{z} = \frac{x}{z} + 1\).","theorem Nat.add_div_left (x : Nat) {z : Nat} (H : 0 < z) : (z + x) / z = (x / z) + 1 := by
/- First, we use the commutativity of addition in natural numbers to rewrite the expression \( z + x \) as \( x + z \). Then, we apply the theorem that states \(\frac{x + z}{z} = \frac{x}{z} + 1\) when \( z > 0 \), which simplifies our goal to \(\frac{x}{z} + 1 = \frac{x}{z} + 1\), which is trivially true. -/
  rw [Nat.add_comm, add_div_right x H]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3201,Nat.mul_mod_left,theorem Nat.mul_mod_left (m n : Nat) : (m * n) % n = 0 := by sorry,"Left Multiplication Preserves Modulo Zero in Natural Numbers : For any natural numbers \( m \) and \( n \), the product \( m \times n \) modulo \( n \) is equal to 0, i.e., \( m \times n \mod n = 0 \).","theorem Nat.mul_mod_left (m n : Nat) : (m * n) % n = 0 := by
  rw [Nat.mul_comm, mul_mod_right]","We start by using the commutativity of multiplication for natural numbers, which states that \( m \times n = n \times m \). This allows us to rewrite the goal as \( n \times m \mod n = 0 \). Then, we use the property that for any natural numbers \( m \) and \( n \), \( n \times m \mod n = 0 \). Therefore, \( m \times n \mod n = 0 \), which completes the proof.","theorem Nat.mul_mod_left (m n : Nat) : (m * n) % n = 0 := by
/- First, we use the commutativity of multiplication for natural numbers, which states that \( m \times n = n \times m \), to rewrite the goal as \( n \times m \mod n = 0 \). Then, we use the property that for any natural numbers \( m \) and \( n \), \( n \times m \mod n = 0 \), to conclude that the goal is true. -/
  rw [Nat.mul_comm, mul_mod_right]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3202,Nat.add_mod_left,theorem Nat.add_mod_left (x z : Nat) : (x + z) % x = z % x := by sorry,"Left Addition Preserves Modulo in Natural Numbers: \((x + z) \mod x = z \mod x\) : For any natural numbers \( x \) and \( z \), the expression \( (x + z) \mod x \) is equal to \( z \mod x \). In other words, adding \( z \) to \( x \) and then taking the result modulo \( x \) yields the same remainder as taking \( z \) modulo \( x \).","theorem Nat.add_mod_left (x z : Nat) : (x + z) % x = z % x := by
  rw [Nat.add_comm, add_mod_right]","We start by using the commutativity of addition, which states that for any natural numbers \( x \) and \( z \), \( x + z = z + x \). Applying this property, we rewrite the expression \( (x + z) \mod x \) as \( (z + x) \mod x \).

Next, we use the property that adding \( x \) to \( z \) and then taking the result modulo \( x \) yields the same remainder as taking \( z \) modulo \( x \). This property is given by \( (z + x) \mod x = z \mod x \).

Thus, combining these two steps, we have:
\[
(x + z) \mod x = (z + x) \mod x = z \mod x.
\]

This completes the proof.","theorem Nat.add_mod_left (x z : Nat) : (x + z) % x = z % x := by
/- First, we use the commutativity of addition to rewrite the expression \( (x + z) \mod x \) as \( (z + x) \mod x \). Then, we use the property that adding \( x \) to \( z \) and then taking the result modulo \( x \) yields the same remainder as taking \( z \) modulo \( x \), i.e., \( (z + x) \mod x = z \mod x \). -/
  rw [Nat.add_comm, add_mod_right]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3203,Nat.add_mod_right,theorem Nat.add_mod_right (x z : Nat) : (x + z) % z = x % z := by sorry,"Right Addition Distributes Over Modulo in Natural Numbers : For any natural numbers \( x \) and \( z \), the following equality holds:
\[ (x + z) \% z = x \% z. \]","theorem Nat.add_mod_right (x z : Nat) : (x + z) % z = x % z := by
  rw [mod_eq_sub_mod (Nat.le_add_left ..), Nat.add_sub_cancel]","We start by using the property that for any natural numbers \( a \) and \( b \) such that \( a \geq b \), \( a \% b = (a - b) \% b \). Since \( x + z \geq z \) (because adding \( z \) to any natural number \( x \) results in a number greater than or equal to \( z \)), we can rewrite \( (x + z) \% z \) as \( (x + z - z) \% z \). Then, we use the cancellation property of addition and subtraction in natural numbers, which states that \( x + z - z = x \), to simplify \( (x + z - z) \% z \) to \( x \% z \). Thus, we have shown that \( (x + z) \% z = x \% z \).","theorem Nat.add_mod_right (x z : Nat) : (x + z) % z = x % z := by
/- First, we use the property that for any natural numbers \( a \) and \( b \) such that \( a \geq b \), \( a \% b = (a - b) \% b \). Since \( x + z \geq z \) (because adding \( z \) to any natural number \( x \) results in a number greater than or equal to \( z \)), we can rewrite \( (x + z) \% z \) as \( (x + z - z) \% z \). Then, we use the cancellation property of addition and subtraction in natural numbers, which states that \( x + z - z = x \), to simplify \( (x + z - z) \% z \) to \( x \% z \). -/
  rw [mod_eq_sub_mod (Nat.le_add_left ..), Nat.add_sub_cancel]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3204,Nat.add_mul_mod_self_right,theorem Nat.add_mul_mod_self_right (x y z : Nat) : (x + y * z) % z = x % z := by sorry,"Right Addition of Multiple Preserves Modulo in Natural Numbers : For any natural numbers \( x \), \( y \), and \( z \), the expression \( (x + y \cdot z) \mod z \) is equal to \( x \mod z \). In other words, adding a multiple of \( z \) to \( x \) does not change the remainder when \( x \) is divided by \( z \).","theorem Nat.add_mul_mod_self_right (x y z : Nat) : (x + y * z) % z = x % z := by
  rw [Nat.mul_comm, add_mul_mod_self_left]","We start by using the commutativity of multiplication, which states that for any natural numbers \( y \) and \( z \), \( y \cdot z = z \cdot y \). Applying this, we rewrite \( (x + y \cdot z) \mod z \) as \( (x + z \cdot y) \mod z \).

Next, we use the property that adding a multiple of \( y \) to \( x \) does not change the remainder when \( x \) is divided by \( y \). Specifically, for any natural numbers \( x \), \( y \), and \( z \), \( (x + y \cdot z) \mod y = x \mod y \). Applying this property, we simplify \( (x + z \cdot y) \mod z \) to \( x \mod z \).

Thus, we have shown that \( (x + y \cdot z) \mod z = x \mod z \), completing the proof.","theorem Nat.add_mul_mod_self_right (x y z : Nat) : (x + y * z) % z = x % z := by
/- First, we use the commutativity of multiplication to rewrite \( y \cdot z \) as \( z \cdot y \). Then, we use the property that adding a multiple of \( y \) to \( x \) does not change the remainder when \( x \) is divided by \( y \) to simplify \( (x + z \cdot y) \mod z \) to \( x \mod z \). -/
  rw [Nat.mul_comm, add_mul_mod_self_left]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3205,Nat.zero_mod,theorem Nat.zero_mod (b : Nat) : 0 % b = 0 := by sorry,"Modulo of Zero by Any Natural Number is Zero : For any natural number \( b \), the modulo operation \( 0 \% b \) is equal to 0, i.e., \( 0 \% b = 0 \).","theorem Nat.zero_mod (b : Nat) : 0 % b = 0 := by
  rw [mod_eq]
  have : ¬ (0 < b ∧ b = 0) := by
    intro ⟨h₁, h₂⟩
    simp_all
  simp [this]","We begin by using the identity for the modulo operation in natural numbers, which states that \( x \% y = \begin{cases} (x - y) \% y & \text{if } 0 < y \text{ and } y \le x \\ x & \text{otherwise} \end{cases} \). Applying this to our goal, we replace \( 0 \% b \) with \( \text{ite}(0 < b \land b \le 0, (0 - b) \% b, 0) \).

Next, we introduce a lemma to show that it is impossible for \( b \) to be both greater than 0 and equal to 0 simultaneously. Assume for contradiction that \( b \) satisfies both \( 0 < b \) and \( b = 0 \). Let \( h₁ \) be the proof that \( 0 < b \) and \( h₂ \) be the proof that \( b = 0 \). Using these assumptions, we simplify the goal and the hypotheses, which leads to a contradiction, thus proving the lemma.

Finally, using the lemma that \( \neg (0 < b \land b = 0) \), we simplify the goal, which directly shows that \( \text{ite}(0 < b \land b \le 0, (0 - b) \% b, 0) = 0 \). Therefore, \( 0 \% b = 0 \). This completes the proof.","theorem Nat.zero_mod (b : Nat) : 0 % b = 0 := by
/- We start by using the identity for the modulo operation in natural numbers, which states that \( x \% y = \begin{cases} (x - y) \% y & \text{if } 0 < y \text{ and } y \le x \\ x & \text{otherwise} \end{cases} \). Applying this to our goal, we replace \( 0 \% b \) with \( \text{ite}(0 < b \land b \le 0, (0 - b) \% b, 0) \). -/
  rw [mod_eq]
/- We introduce a new lemma to show that it is impossible for \( b \) to be both greater than 0 and equal to 0 simultaneously. -/
  have : ¬ (0 < b ∧ b = 0) := by
/- Assume for contradiction that \( b \) satisfies both \( 0 < b \) and \( b = 0 \). Let \( h₁ \) be the proof that \( 0 < b \) and \( h₂ \) be the proof that \( b = 0 \). -/
    intro ⟨h₁, h₂⟩
/- Using the contradiction from the previous step, we simplify the goal and the hypotheses, which leads to a contradiction, thus proving the lemma. -/
    simp_all
/- Using the lemma that \( \neg (0 < b \land b = 0) \), we simplify the goal, which directly shows that \( \text{ite}(0 < b \land b \le 0, (0 - b) \% b, 0) = 0 \). -/
  simp [this]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3206,Nat.add_div_right,theorem Nat.add_div_right (x : Nat) {z : Nat} (H : 0 < z) : (x + z) / z = (x / z) + 1 := by sorry,"Right Addition Preserves Division in Natural Numbers: \(\frac{x + z}{z} = \frac{x}{z} + 1\) : For any natural numbers \( x \) and \( z \), if \( z \) is strictly greater than zero, then the division of the sum \( x + z \) by \( z \) is equal to the sum of the division of \( x \) by \( z \) and 1, i.e., \(\frac{x + z}{z} = \frac{x}{z} + 1\).","theorem Nat.add_div_right (x : Nat) {z : Nat} (H : 0 < z) : (x + z) / z = (x / z) + 1 := by
  rw [div_eq_sub_div H (Nat.le_add_left _ _), Nat.add_sub_cancel]","Given \( x \) and \( z \) are natural numbers with \( z > 0 \), we start by applying the division identity for natural numbers, which states that for any \( a \) and \( b \) such that \( 0 < b \le a \), \( a / b = (a - b) / b + 1 \). Here, we set \( a = x + z \) and \( b = z \). Since \( z \) is positive, \( z \le x + z \). Thus, we have:

\[
(x + z) / z = (x + z - z) / z + 1
\]

Next, we use the cancellation property of addition and subtraction in natural numbers, which states that \( x + z - z = x \). Therefore:

\[
(x + z - z) / z = x / z
\]

Combining these results, we get:

\[
(x + z) / z = x / z + 1
\]

This completes the proof.","theorem Nat.add_div_right (x : Nat) {z : Nat} (H : 0 < z) : (x + z) / z = (x / z) + 1 := by
/- First, we use the division identity for natural numbers, which states that for any \( a \) and \( b \) such that \( 0 < b \le a \), \( a / b = (a - b) / b + 1 \). Applying this identity to \( (x + z) / z \) with \( a = x + z \) and \( b = z \), and using the fact that \( z \le x + z \) (since \( z \) is positive), we get \( (x + z) / z = (x + z - z) / z + 1 \). Then, we simplify \( x + z - z \) to \( x \) using the cancellation property of addition and subtraction in natural numbers, which states that \( x + z - z = x \). Thus, we have \( (x + z) / z = x / z + 1 \). -/
  rw [div_eq_sub_div H (Nat.le_add_left _ _), Nat.add_sub_cancel]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3207,Nat.mod_le,theorem Nat.mod_le (x y : Nat) : x % y ≤ x := by sorry,"Modulo Operation Preserves Less Than or Equal Relation in Natural Numbers : For any natural numbers \( x \) and \( y \), the remainder when \( x \) is divided by \( y \) is less than or equal to \( x \), i.e., \( x \% y \leq x \).","theorem Nat.mod_le (x y : Nat) : x % y ≤ x := by
  match Nat.lt_or_ge x y with
  | Or.inl h₁ => rw [mod_eq_of_lt h₁]; apply Nat.le_refl
  | Or.inr h₁ => match eq_zero_or_pos y with
    | Or.inl h₂ => rw [h₂, Nat.mod_zero x]; apply Nat.le_refl
    | Or.inr h₂ => exact Nat.le_trans (Nat.le_of_lt (mod_lt _ h₂)) h₁","We consider two main cases based on the relationship between \( x \) and \( y \):

1. **Case 1: \( x < y \)**
If \( x \) is less than \( y \), then by the definition of the modulo operation, \( x \% y = x \). Since \( x \) is equal to itself, it is trivially less than or equal to \( x \).

2. **Case 2: \( x ≥ y \)**
If \( x \) is greater than or equal to \( y \), we further consider two sub-cases for \( y \):

- **Sub-case 2.1: \( y = 0 \)**
If \( y \) is zero, then by the definition of the modulo operation, \( x \% 0 = x \). Since \( x \) is equal to itself, it is trivially less than or equal to \( x \).

- **Sub-case 2.2: \( y > 0 \)**
If \( y \) is positive, then by the property of the modulo operation, \( x \% y < y \). Since \( y \leq x \) (from the assumption \( x ≥ y \)), we can use the transitivity of the less than or equal relation to conclude that \( x \% y \leq x \).

Thus, in all cases, we have shown that \( x \% y \leq x \). This completes the proof.","theorem Nat.mod_le (x y : Nat) : x % y ≤ x := by
  match Nat.lt_or_ge x y with
/- If \( x \) is less than \( y \) (i.e., \( h₁ : x < y \)), then by the definition of the modulo operation, \( x \% y = x \). Since \( x \) is equal to itself, it is trivially less than or equal to \( x \). -/
  | Or.inl h₁ => rw [mod_eq_of_lt h₁]; apply Nat.le_refl
/- If \( x \) is greater than or equal to \( y \) (i.e., \( h₁ : x ≥ y \)), then we consider two cases for \( y \): either \( y \) is zero or \( y \) is positive. -/
  | Or.inr h₁ => match eq_zero_or_pos y with
/- If \( y \) is zero (i.e., \( h₂ : y = 0 \)), then by the definition of the modulo operation, \( x \% 0 = x \). Since \( x \) is equal to itself, it is trivially less than or equal to \( x \). -/
    | Or.inl h₂ => rw [h₂, Nat.mod_zero x]; apply Nat.le_refl
/- If \( y \) is positive (i.e., \( h₂ : y > 0 \)), then by the property of the modulo operation, \( x \% y < y \). Since \( y \leq x \) (from \( h₁ \)), we can use the transitivity of the less than or equal relation to conclude that \( x \% y \leq x \). -/
    | Or.inr h₂ => exact Nat.le_trans (Nat.le_of_lt (mod_lt _ h₂)) h₁","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3208,Nat.add_mul_div_right,theorem Nat.add_mul_div_right (x y : Nat) {z : Nat} (H : 0 < z) : (x + y * z) / z = x / z + y := by sorry,"Right Addition and Multiplication Distribute Over Division in Natural Numbers : For any natural numbers \( x \) and \( y \), and for any natural number \( z \) such that \( z > 0 \), the following equality holds:
\[ \frac{x + y \cdot z}{z} = \frac{x}{z} + y. \]","theorem Nat.add_mul_div_right (x y : Nat) {z : Nat} (H : 0 < z) : (x + y * z) / z = x / z + y := by
  rw [Nat.mul_comm, add_mul_div_left _ _ H]","We start by using the commutativity of multiplication, which states that for any natural numbers \( a \) and \( b \), \( a \cdot b = b \cdot a \). Applying this to our expression, we rewrite \( y \cdot z \) as \( z \cdot y \).

Next, we use the theorem that for any natural numbers \( x \) and \( z \), and for any natural number \( y \) such that \( y > 0 \), the following equality holds:
\[ \frac{x + y \cdot z}{y} = \frac{x}{y} + z. \]
Substituting \( y \) with \( z \) and \( z \) with \( y \), we get:
\[ \frac{x + z \cdot y}{z} = \frac{x}{z} + y. \]

Thus, our original expression:
\[ \frac{x + y \cdot z}{z} \]
simplifies to:
\[ \frac{x}{z} + y, \]
which completes the proof.","theorem Nat.add_mul_div_right (x y : Nat) {z : Nat} (H : 0 < z) : (x + y * z) / z = x / z + y := by
/- First, we use the commutativity of multiplication to rewrite \( y \cdot z \) as \( z \cdot y \). Then, we apply the theorem that states for any natural numbers \( x \) and \( z \), and for any natural number \( y \) such that \( y > 0 \), the following equality holds:
\[ \frac{x + y \cdot z}{y} = \frac{x}{y} + z. \]
In our case, substituting \( y \) with \( z \) and \( z \) with \( y \), we get:
\[ \frac{x + z \cdot y}{z} = \frac{x}{z} + y. \]
This simplifies our goal to:
\[ \frac{x + z \cdot y}{z} = \frac{x}{z} + y, \]
which is trivially true. -/
  rw [Nat.mul_comm, add_mul_div_left _ _ H]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3209,Nat.mul_mod_right,theorem Nat.mul_mod_right (m n : Nat) : (m * n) % m = 0 := by sorry,"Right Multiplication Preserves Modulo Zero in Natural Numbers : For any natural numbers \( m \) and \( n \), the product \( m \times n \) modulo \( m \) is equal to 0, i.e., \( m \times n \mod m = 0 \).","theorem Nat.mul_mod_right (m n : Nat) : (m * n) % m = 0 := by
  rw [← Nat.zero_add (m * n), add_mul_mod_self_left, zero_mod]","We begin by rewriting the expression \( m \times n \mod m \) using the additive identity property of zero, which states that \( 0 + m \times n = m \times n \). This transforms our goal to \( (0 + m \times n) \mod m \). Next, we apply the property that adding a multiple of \( m \) to any number does not change its modulo \( m \), i.e., \( (0 + m \times n) \mod m = 0 \mod m \). Finally, we use the property that the modulo of zero by any natural number is zero, i.e., \( 0 \mod m = 0 \). Thus, we have shown that \( m \times n \mod m = 0 \). This completes the proof.","theorem Nat.mul_mod_right (m n : Nat) : (m * n) % m = 0 := by
/- We start by rewriting the expression \( m \times n \mod m \) using the identity that adding zero to any number does not change its value, i.e., \( 0 + m \times n = m \times n \). This transforms our goal to \( (0 + m \times n) \mod m \). Next, we use the property that adding a multiple of \( m \) to any number does not change its modulo \( m \), i.e., \( (0 + m \times n) \mod m = 0 \mod m \). Finally, we use the property that the modulo of zero by any natural number is zero, i.e., \( 0 \mod m = 0 \). This completes the proof. -/
  rw [← Nat.zero_add (m * n), add_mul_mod_self_left, zero_mod]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3210,Nat.mul_div_cancel_left,theorem Nat.mul_div_cancel_left (m : Nat) {n : Nat} (H : 0 < n) : n * m / n = m := by sorry,"Left Multiplication Cancellation in Natural Numbers: \( n \times m / n = m \) : For any natural numbers \( m \) and \( n \), if \( n \) is strictly greater than 0, then the division of the product \( n \times m \) by \( n \) equals \( m \), i.e., \( n \times m / n = m \).","theorem Nat.mul_div_cancel_left (m : Nat) {n : Nat} (H : 0 < n) : n * m / n = m := by
  rw [Nat.mul_comm, Nat.mul_div_cancel _ H]","We start by using the commutativity of multiplication in natural numbers, which states that \( n \times m = m \times n \). Thus, we can rewrite the expression \( n \times m / n \) as \( m \times n / n \). Next, we use the property that for any natural number \( m \) and \( n \) where \( n > 0 \), the division of \( m \times n \) by \( n \) equals \( m \). This property simplifies our goal to \( m = m \), which is trivially true. Therefore, we have shown that \( n \times m / n = m \).","theorem Nat.mul_div_cancel_left (m : Nat) {n : Nat} (H : 0 < n) : n * m / n = m := by
/- First, we use the commutativity of multiplication in natural numbers to rewrite the expression \( n \times m \) as \( m \times n \). Then, we use the property that for any natural number \( m \) and \( n \) where \( n > 0 \), the division of \( m \times n \) by \( n \) equals \( m \). This simplifies the goal to \( m = m \), which is trivially true. -/
  rw [Nat.mul_comm, Nat.mul_div_cancel _ H]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3211,Nat.mul_div_left,theorem Nat.mul_div_left (m : Nat) {n : Nat} (H : 0 < n) : m * n / n = m := by sorry,"Multiplication and Division Cancellation on the Left in Natural Numbers: \( m \cdot n / n = m \) : For any natural numbers \( m \) and \( n \) such that \( n > 0 \), it holds that \( m \cdot n / n = m \).","theorem Nat.mul_div_left (m : Nat) {n : Nat} (H : 0 < n) : m * n / n = m := by
  rw [Nat.mul_comm, mul_div_right _ H]","We start by using the commutativity of multiplication, which states that for any natural numbers \( m \) and \( n \), \( m \cdot n = n \cdot m \). Applying this, we rewrite \( m \cdot n \) as \( n \cdot m \). Next, we use the property that for any natural numbers \( n \) and \( m \) such that \( m > 0 \), it holds that \( m \cdot n / m = n \). Applying this property with \( m = n \) and \( n = m \), we simplify \( n \cdot m / n \) to \( m \). Thus, we have shown that \( m \cdot n / n = m \).","theorem Nat.mul_div_left (m : Nat) {n : Nat} (H : 0 < n) : m * n / n = m := by
/- First, we use the commutativity of multiplication to rewrite \( m \cdot n \) as \( n \cdot m \). Then, we use the property that for any natural numbers \( n \) and \( m \) such that \( m > 0 \), it holds that \( m \cdot n / m = n \), to simplify \( n \cdot m / n \) to \( m \). -/
  rw [Nat.mul_comm, mul_div_right _ H]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3215,Nat.div_self,theorem Nat.div_self (H : 0 < n) : n / n = 1 := by sorry,"Division of a Nonzero Natural Number by Itself Equals One: \( n / n = 1 \) : For any natural number \( n \) such that \( n > 0 \), the division of \( n \) by itself is equal to 1, i.e., \( n / n = 1 \).","theorem Nat.div_self (H : 0 < n) : n / n = 1 := by
  let t := add_div_right 0 H
  rwa [Nat.zero_add, Nat.zero_div] at t","Let \( t \) denote the result of applying the theorem that states \(\frac{0 + n}{n} = \frac{0}{n} + 1\) to the natural number \( n \) with the assumption \( 0 < n \). Using the properties that \( 0 + n = n \) and \( 0 / n = 0 \), we can rewrite \( t \) to show that \(\frac{n}{n} = 0 + 1\). Since \( 0 + 1 = 1 \), this directly proves that \(\frac{n}{n} = 1\).","theorem Nat.div_self (H : 0 < n) : n / n = 1 := by
/- Let \( t \) denote the result of applying the theorem that states \(\frac{0 + n}{n} = \frac{0}{n} + 1\) to the natural number \( n \) with the assumption \( 0 < n \). -/
  let t := add_div_right 0 H
/- Using the properties that \( 0 + n = n \) and \( 0 / n = 0 \), we can rewrite \( t \) to show that \(\frac{n}{n} = 0 + 1\). Since \( 0 + 1 = 1 \), this directly proves that \(\frac{n}{n} = 1\). -/
  rwa [Nat.zero_add, Nat.zero_div] at t","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3216,Nat.mod_add_div,theorem Nat.mod_add_div (m k : Nat) : m % k + k * (m / k) = m := by sorry,"Modulo and Division Identity: \( m \% k + k \cdot (m / k) = m \) : For any natural numbers \( m \) and \( k \), the sum of the remainder of \( m \) divided by \( k \) and the product of \( k \) and the quotient of \( m \) divided by \( k \) is equal to \( m \), i.e., \( m \% k + k \cdot (m / k) = m \).","theorem Nat.mod_add_div (m k : Nat) : m % k + k * (m / k) = m := by
  induction m, k using mod.inductionOn with rw [div_eq, mod_eq]
  | base x y h => simp [h]
  | ind x y h IH => simp [h]; rw [Nat.mul_succ, ← Nat.add_assoc, IH, Nat.sub_add_cancel h.2]","We proceed by induction on \( m \).

**Base Case:**
For \( m = 0 \), the expression \( 0 \% k + k \cdot (0 / k) \) simplifies to \( 0 + k \cdot 0 = 0 \), which is trivially true.

**Inductive Step:**
Assume the statement holds for \( m \), i.e., \( m \% k + k \cdot (m / k) = m \). We need to show that \( (m + 1) \% k + k \cdot ((m + 1) / k) = m + 1 \).

Consider two cases:
1. **Case 1:** \( 0 < k \land k \leq m \).
- Simplify the expression using the assumption \( 0 < k \land k \leq m \).
- Rewrite the goal using the properties of natural numbers:
- The multiplication by successor property \( k \times (m / k + 1) = k \times (m / k) + k \).
- The associativity of addition \( (m \% k + k \times (m / k)) + k = m \% k + (k \times (m / k) + k) \).
- The inductive hypothesis \( m \% k + k \times (m / k) = m \).
- The cancellation property of subtraction and addition in natural numbers \( m + k = m + 1 \).

2. **Case 2:** \( \neg (0 < k \land k \leq m) \).
- Simplify the expression using the assumption \( \neg (0 < k \land k \leq m) \).
- This simplifies the goal to \( m + 1 = m + 1 \), which is trivially true.

By induction, the statement holds for all natural numbers \( m \).

This completes the proof.","theorem Nat.mod_add_div (m k : Nat) : m % k + k * (m / k) = m := by
  induction m, k using mod.inductionOn with rw [div_eq, mod_eq]
/- For the base case where \( 0 < y \land y \leq x \) does not hold, we simplify the expression using the assumption \( h \), which states that \( 0 < y \land y \leq x \) is false. This simplifies the goal to \( x = x \), which is trivially true. -/
  | base x y h => simp [h]
/- For the inductive case where \( 0 < y \land y \leq x \) holds, we simplify the expression using the assumption \( h \). Then, we rewrite the goal using the properties of natural numbers:
- The multiplication by successor property \( y \times (m + 1) = y \times m + y \).
- The associativity of addition \( a + (b + c) = (a + b) + c \).
- The inductive hypothesis \( IH \) which states \( (x - y) \% y + y \times ((x - y) / y) = x - y \).
- The cancellation property of subtraction and addition in natural numbers \( a - b + b = a \). -/
  | ind x y h IH => simp [h]; rw [Nat.mul_succ, ← Nat.add_assoc, IH, Nat.sub_add_cancel h.2]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3217,Nat.mod_one,theorem Nat.mod_one (x : Nat) : x % 1 = 0 := by sorry,"Modulo of a Number by One is Zero : For any natural number \( x \), the modulo operation \( x \% 1 \) is equal to 0, i.e., \( x \% 1 = 0 \).","theorem Nat.mod_one (x : Nat) : x % 1 = 0 := by
  have h : x % 1 < 1 := mod_lt x (by decide)
  have : (y : Nat) → y < 1 → y = 0 := by
    intro y
    cases y with
    | zero   => intro _; rfl
    | succ y => intro h; apply absurd (Nat.lt_of_succ_lt_succ h) (Nat.not_lt_zero y)
  exact this _ h","We start by noting that the remainder of any natural number \( x \) when divided by a positive number \( y \) is less than \( y \). Since \( 1 > 0 \) is trivially true, we can apply this property to conclude \( x \% 1 < 1 \).

Next, we construct a lemma that for any natural number \( y \), if \( y < 1 \), then \( y \) must be \( 0 \). This lemma will be useful in proving our main goal.

Let \( y \) be an arbitrary natural number. We need to show that if \( y < 1 \), then \( y = 0 \).

Consider the case when \( y \) is \( 0 \). If \( y < 1 \), then \( y = 0 \) is trivially true by reflexivity.

Now, consider the case when \( y \) is of the form \( y + 1 \). If \( y + 1 < 1 \), then by the property that the successor of a number is less than the successor of another number implies the original numbers are in the same order, we have \( y < 0 \). However, this contradicts the fact that no natural number is less than \( 0 \). Therefore, this case is impossible, and we conclude that \( y \) must be \( 0 \).

Finally, we apply the lemma we constructed earlier to \( x \% 1 \). Since we have already shown that \( x \% 1 < 1 \), by the lemma, we conclude that \( x \% 1 = 0 \).

This completes the proof.","theorem Nat.mod_one (x : Nat) : x % 1 = 0 := by
/- First, we establish that \( x \% 1 < 1 \) using the property that the remainder of any natural number \( x \) when divided by a positive number \( y \) is less than \( y \). Since \( 1 > 0 \) is trivially true, we can apply this property to conclude \( x \% 1 < 1 \). -/
  have h : x % 1 < 1 := mod_lt x (by decide)
/- Next, we construct a lemma that for any natural number \( y \), if \( y < 1 \), then \( y \) must be \( 0 \). This lemma will be useful in proving our main goal. -/
  have : (y : Nat) → y < 1 → y = 0 := by
/- Let \( y \) be an arbitrary natural number. We need to show that if \( y < 1 \), then \( y = 0 \). -/
    intro y
    cases y with
/- Consider the case when \( y \) is \( 0 \). If \( y < 1 \), then \( y = 0 \) is trivially true by reflexivity. -/
    | zero   => intro _; rfl
/- Now, consider the case when \( y \) is of the form \( y + 1 \). If \( y + 1 < 1 \), then by the property that the successor of a number is less than the successor of another number implies the original numbers are in the same order, we have \( y < 0 \). However, this contradicts the fact that no natural number is less than \( 0 \). Therefore, this case is impossible, and we conclude that \( y \) must be \( 0 \). -/
    | succ y => intro h; apply absurd (Nat.lt_of_succ_lt_succ h) (Nat.not_lt_zero y)
/- Finally, we apply the lemma we constructed earlier to \( x \% 1 \). Since we have already shown that \( x \% 1 < 1 \), by the lemma, we conclude that \( x \% 1 = 0 \). -/
  exact this _ h","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3219,Nat.div_eq_of_lt,theorem Nat.div_eq_of_lt (h₀ : a < b) : a / b = 0 := by sorry,"Division of Smaller Natural Number by Larger Natural Number is Zero: \( a < b \to a / b = 0 \) : For any natural numbers \( a \) and \( b \), if \( a < b \), then \( a / b = 0 \).","theorem Nat.div_eq_of_lt (h₀ : a < b) : a / b = 0 := by
  rw [div_eq a, if_neg]
  intro h₁
  apply Nat.not_le_of_gt h₀ h₁.right","We start by using the definition of division for natural numbers, which states that \( a / b \) is \( 0 \) unless \( b > 0 \) and \( b \le a \). Given our assumption \( a < b \), the condition \( 0 < b \land b \le a \) is false. Therefore, the if-then-else function returns \( 0 \), and we rewrite \( a / b \) to \( 0 \).

Next, assume for contradiction that there exists a proposition \( h₁ \) such that \( 0 < b \land b \le a \). However, since \( a < b \), we know that \( \neg (b \le a) \). This contradicts \( h₁ \), which states \( b \le a \). Thus, our assumption must be false, and \( a / b \) must indeed be \( 0 \).

This completes the proof.","theorem Nat.div_eq_of_lt (h₀ : a < b) : a / b = 0 := by
/- First, we use the definition of division for natural numbers, which states that \( a / b \) is \( 0 \) unless \( b > 0 \) and \( b \le a \). Since the condition \( 0 < b \land b \le a \) is false under our assumption \( a < b \), the if-then-else function returns \( 0 \). Thus, we rewrite \( a / b \) to \( 0 \). -/
  rw [div_eq a, if_neg]
/- Assume for contradiction that there exists a proposition \( h₁ \) such that \( 0 < b \land b \le a \). -/
  intro h₁
/- Using the fact that \( a < b \) implies \( \neg (b \le a) \), and since \( h₁ \) states \( b \le a \), we reach a contradiction. -/
  apply Nat.not_le_of_gt h₀ h₁.right","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3221,Nat.mul_div_right,theorem Nat.mul_div_right (n : Nat) {m : Nat} (H : 0 < m) : m * n / m = n := by sorry,"Multiplication and Division Cancellation on the Right in Natural Numbers : For any natural numbers \( n \) and \( m \) such that \( m > 0 \), it holds that \( m \cdot n / m = n \).","theorem Nat.mul_div_right (n : Nat) {m : Nat} (H : 0 < m) : m * n / m = n := by
  induction n <;> simp_all [mul_succ]","We proceed by induction on \( n \).

**Base Case:**
For \( n = 0 \), we need to show that \( m \cdot 0 / m = 0 \). This is trivially true since \( m \cdot 0 = 0 \), and thus \( 0 / m = 0 \).

**Inductive Step:**
Assume the inductive hypothesis that for some \( k \in \mathbb{N} \), \( m \cdot k / m = k \). We need to show that \( m \cdot (k + 1) / m = k + 1 \).

Using the property of multiplication, we have:
\[ m \cdot (k + 1) = m \cdot k + m \]

Thus,
\[ m \cdot (k + 1) / m = (m \cdot k + m) / m \]

By the distributive property of division over addition,
\[ (m \cdot k + m) / m = (m \cdot k / m) + (m / m) \]

Since \( m \cdot k / m = k \) by the inductive hypothesis and \( m / m = 1 \) because \( m > 0 \), we get:
\[ (m \cdot k / m) + (m / m) = k + 1 \]

Therefore,
\[ m \cdot (k + 1) / m = k + 1 \]

This completes the inductive step. By induction, the theorem holds for all natural numbers \( n \).","theorem Nat.mul_div_right (n : Nat) {m : Nat} (H : 0 < m) : m * n / m = n := by
/- We perform induction on the natural number \( n \). For the base case where \( n = 0 \), we need to show that \( m \cdot 0 / m = 0 \). For the inductive step, assume \( n = k \) and the inductive hypothesis \( m \cdot k / m = k \). We need to show that \( m \cdot (k + 1) / m = k + 1 \). After performing induction, we simplify both cases using the property that \( m \cdot (n + 1) = m \cdot n + m \). -/
  induction n <;> simp_all [mul_succ]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3223,Nat.mul_div_mul_left,"theorem Nat.mul_div_mul_left {m : Nat} (n k : Nat) (H : 0 < m) :
    m * n / (m * k) = n / k := by sorry","Multiplication and Division Identity: \( \frac{m \cdot n}{m \cdot k} = \frac{n}{k} \) for \( m > 0 \) : For any natural numbers \( m, n, \) and \( k \), if \( m > 0 \), then the division of the product \( m \cdot n \) by the product \( m \cdot k \) is equal to the division of \( n \) by \( k \), i.e., \( \frac{m \cdot n}{m \cdot k} = \frac{n}{k} \).","theorem Nat.mul_div_mul_left {m : Nat} (n k : Nat) (H : 0 < m) :
    m * n / (m * k) = n / k := by
  rw [← Nat.div_div_eq_div_mul, Nat.mul_div_cancel_left _ H]","We start by using the property that dividing \( m \cdot n \) by \( m \) and then by \( k \) is equivalent to dividing \( m \cdot n \) by \( m \cdot k \). This transforms our goal from \( \frac{m \cdot n}{m \cdot k} = \frac{n}{k} \) to \( \frac{m \cdot n}{m} / k = \frac{n}{k} \). Next, we use the fact that for any natural number \( m \) greater than \( 0 \), \( \frac{m \cdot n}{m} = n \). This simplifies our goal to \( n / k = n / k \), which is trivially true. Therefore, \( \frac{m \cdot n}{m \cdot k} = \frac{n}{k} \) holds for any natural numbers \( m, n, \) and \( k \) with \( m > 0 \).","theorem Nat.mul_div_mul_left {m : Nat} (n k : Nat) (H : 0 < m) :
    m * n / (m * k) = n / k := by
  rw [← Nat.div_div_eq_div_mul, Nat.mul_div_cancel_left _ H]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3224,Nat.add_mul_mod_self_left,theorem Nat.add_mul_mod_self_left (x y z : Nat) : (x + y * z) % y = x % y := by sorry,"Left Addition of Multiple Preserves Modulo in Natural Numbers : For any natural numbers \( x \), \( y \), and \( z \), the expression \( (x + y \cdot z) \mod y \) is equal to \( x \mod y \). In other words, adding a multiple of \( y \) to \( x \) does not change the remainder when \( x \) is divided by \( y \).","theorem Nat.add_mul_mod_self_left (x y z : Nat) : (x + y * z) % y = x % y := by
  match z with
  | 0 => rw [Nat.mul_zero, Nat.add_zero]
  | succ z => rw [mul_succ, ← Nat.add_assoc, add_mod_right, add_mul_mod_self_left (z := z)]","We proceed by induction on \( z \).

**Base Case:**
For \( z = 0 \), we have:
\[
(x + y \cdot 0) \mod y = (x + 0) \mod y = x \mod y
\]
This is trivially true since \( y \cdot 0 = 0 \) and \( x + 0 = x \).

**Inductive Step:**
Assume the statement holds for \( z = z' \), i.e., \( (x + y \cdot z') \mod y = x \mod y \). We need to show it holds for \( z = \text{succ } z' \).

For \( z = \text{succ } z' \), we have:
\[
(x + y \cdot \text{succ } z') \mod y = (x + (y \cdot z' + y)) \mod y
\]
Using the associativity of addition, this becomes:
\[
(x + y \cdot z' + y) \mod y
\]
By the property of modulo, adding \( y \) does not change the modulo \( y \):
\[
(x + y \cdot z' + y) \mod y = (x + y \cdot z') \mod y
\]
By the inductive hypothesis, we know:
\[
(x + y \cdot z') \mod y = x \mod y
\]
Thus, we have shown that:
\[
(x + y \cdot \text{succ } z') \mod y = x \mod y
\]

By induction, the statement holds for all natural numbers \( z \). Therefore, for any natural numbers \( x \), \( y \), and \( z \), the expression \( (x + y \cdot z) \mod y \) is equal to \( x \mod y \).","theorem Nat.add_mul_mod_self_left (x y z : Nat) : (x + y * z) % y = x % y := by
  match z with
/- For the base case where \( z = 0 \), we rewrite the expression \( y \cdot 0 \) as \( 0 \) and \( x + 0 \) as \( x \). This simplifies the goal to showing that \( x \mod y = x \mod y \), which is trivially true. -/
  | 0 => rw [Nat.mul_zero, Nat.add_zero]
/- For the inductive step where \( z = \text{succ } z' \), we rewrite \( y \cdot \text{succ } z' \) as \( y \cdot z' + y \). Using the associativity of addition, we combine \( x \) and \( y \cdot z' \) to form \( x + y \cdot z' \). We then use the property that adding \( y \) to any number does not change its modulo \( y \) (i.e., \( (a + y) \mod y = a \mod y \)). Finally, we apply the inductive hypothesis that \( (x + y \cdot z') \mod y = x \mod y \). -/
  | succ z => rw [mul_succ, ← Nat.add_assoc, add_mod_right, add_mul_mod_self_left (z := z)]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3225,Nat.mul_div_mul_right,"theorem Nat.mul_div_mul_right {m : Nat} (n k : Nat) (H : 0 < m) :
    n * m / (k * m) = n / k := by sorry","Multiplication and Division Identity: \( \frac{n \cdot m}{k \cdot m} = \frac{n}{k} \) for \( m > 0 \) : For any natural numbers \( n \) and \( k \), and for any natural number \( m \) such that \( m > 0 \), the division of the product \( n \cdot m \) by the product \( k \cdot m \) is equal to the division of \( n \) by \( k \), i.e., \( \frac{n \cdot m}{k \cdot m} = \frac{n}{k} \).","theorem Nat.mul_div_mul_right {m : Nat} (n k : Nat) (H : 0 < m) :
    n * m / (k * m) = n / k := by
  rw [Nat.mul_comm, Nat.mul_comm k, Nat.mul_div_mul_left _ _ H]","We start by using the commutativity of multiplication in natural numbers. Specifically, we rewrite \( n \cdot m \) as \( m \cdot n \) and \( k \cdot m \) as \( m \cdot k \). This transforms the expression \( \frac{n \cdot m}{k \cdot m} \) into \( \frac{m \cdot n}{m \cdot k} \).

Next, we apply the cancellation property of multiplication and division in natural numbers, which states that for any \( m > 0 \), \( \frac{m \cdot n}{m \cdot k} = \frac{n}{k} \). This property allows us to cancel the common factor \( m \) in the numerator and the denominator, resulting in the expression \( \frac{n}{k} \).

Thus, we have shown that \( \frac{n \cdot m}{k \cdot m} = \frac{n}{k} \), which completes the proof.","theorem Nat.mul_div_mul_right {m : Nat} (n k : Nat) (H : 0 < m) :
    n * m / (k * m) = n / k := by
  rw [Nat.mul_comm, Nat.mul_comm k, Nat.mul_div_mul_left _ _ H]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3226,Nat.mul_div_cancel,theorem Nat.mul_div_cancel (m : Nat) {n : Nat} (H : 0 < n) : m * n / n = m := by sorry,"Multiplication and Division Cancellation: \( m \cdot n / n = m \) for Nonzero \( n \) : For any natural numbers \( m \) and \( n \), if \( n \) is nonzero, then the expression \( m \cdot n / n \) is equal to \( m \), i.e., \( m \cdot n / n = m \).","theorem Nat.mul_div_cancel (m : Nat) {n : Nat} (H : 0 < n) : m * n / n = m := by
  let t := add_mul_div_right 0 m H
  rwa [Nat.zero_add, Nat.zero_div, Nat.zero_add] at t","We start by applying the theorem that right addition and multiplication distribute over division in natural numbers. Specifically, we use the fact that for any natural numbers \( x \) and \( y \), and for any natural number \( z \) such that \( z > 0 \), the following equality holds:
\[
\frac{x + y \cdot z}{z} = \frac{x}{z} + y.
\]
In our case, setting \( x = 0 \), \( y = m \), and \( z = n \), we get:
\[
\frac{0 + m \cdot n}{n} = \frac{0}{n} + m.
\]
Let \( t \) denote this result.

Next, we simplify \( t \) using the properties of natural numbers. We know that \( 0 + a = a \) for any natural number \( a \), and \( 0 / n = 0 \) for any nonzero natural number \( n \). Applying these properties, we get:
\[
t : \frac{0 + m \cdot n}{n} = \frac{0}{n} + m \implies \frac{m \cdot n}{n} = 0 + m \implies \frac{m \cdot n}{n} = m.
\]
Since this final expression is exactly what we need to prove, the goal is complete. Thus, we have shown that \( m \cdot n / n = m \) for any natural numbers \( m \) and \( n \) where \( n \) is nonzero.","theorem Nat.mul_div_cancel (m : Nat) {n : Nat} (H : 0 < n) : m * n / n = m := by
/- Let \( t \) denote the result of applying the theorem that right addition and multiplication distribute over division in natural numbers, specifically \( \frac{0 + m \cdot n}{n} = \frac{0}{n} + m \), using the assumption \( 0 < n \). -/
  let t := add_mul_div_right 0 m H
/- Using the properties that zero added to any natural number is the number itself, \( 0 + a = a \), and that dividing zero by any nonzero natural number is zero, \( 0 / n = 0 \), we can simplify \( t \) as follows:
\[
t : \frac{0 + m \cdot n}{n} = \frac{0}{n} + m \implies \frac{m \cdot n}{n} = 0 + m \implies \frac{m \cdot n}{n} = m.
\]
Since this final expression is exactly what we need to prove, the goal is complete. -/
  rwa [Nat.zero_add, Nat.zero_div, Nat.zero_add] at t","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3227,Nat.div_add_mod,theorem Nat.div_add_mod (m n : Nat) : n * (m / n) + m % n = m := by sorry,"Division and Modulo Identity: \( n \cdot (m / n) + m \% n = m \) : For any natural numbers \( m \) and \( n \), the equation \( n \cdot (m / n) + m \% n = m \) holds. This theorem states that the division and modulo operations on natural numbers satisfy the identity \( n \cdot \left\lfloor \frac{m}{n} \right\rfloor + (m \mod n) = m \).","theorem Nat.div_add_mod (m n : Nat) : n * (m / n) + m % n = m := by
  rw [div_eq, mod_eq]
  have h : Decidable (0 < n ∧ n ≤ m) := inferInstance
  cases h with
  | isFalse h => simp [h]
  | isTrue h =>
    simp [h]
    have ih := div_add_mod (m - n) n
    rw [Nat.left_distrib, Nat.mul_one, Nat.add_assoc, Nat.add_left_comm, ih, Nat.add_comm, Nat.sub_add_cancel h.2]
decreasing_by apply div_rec_lemma; assumption","We start by expressing the division and modulo operations using their definitions. Specifically, we replace \( m / n \) with \( \text{ite}(0 < n \land n \leq m, (m - n) / n + 1, 0) \) and \( m \% n \) with \( \text{ite}(0 < n \land n \leq m, (m - n) \% n, m) \).

Next, we consider the decidability of the proposition \( 0 < n \land n \leq m \). We introduce a hypothesis \( h \) that states this proposition is decidable.

We then proceed by cases:

1. **Case \( 0 < n \land n \leq m \) is false:**
In this case, the goal simplifies directly to \( m = m \), which is trivially true.

2. **Case \( 0 < n \land n \leq m \) is true:**
Here, \( n \) is a positive natural number and \( n \leq m \). We simplify the goal using the hypothesis \( h \), which reduces it to \( n \cdot ((m - n) / n + 1) + (m - n) \% n = m \).

We introduce an induction hypothesis \( ih \) which states that \( n \cdot ((m - n) / n) + (m - n) \% n = m - n \).

Using several properties of natural numbers—distributivity, multiplicative identity, associativity, left commutativity, the induction hypothesis \( ih \), commutativity, and the cancellation property of subtraction—we rewrite the goal. This sequence of rewrites transforms the goal into \( m = m \), which is trivially true.

Thus, the theorem holds for all natural numbers \( m \) and \( n \).","theorem Nat.div_add_mod (m n : Nat) : n * (m / n) + m % n = m := by
/- We start by rewriting the division and modulo operations using their definitions. Specifically, we replace \( m / n \) with the expression \( \text{ite}(0 < n \land n \leq m, (m - n) / n + 1, 0) \) and \( m \% n \) with \( \text{ite}(0 < n \land n \leq m, (m - n) \% n, m) \). -/
  rw [div_eq, mod_eq]
/- We introduce a new hypothesis \( h \) that states the decidability of the proposition \( 0 < n \land n \leq m \). This is inferred by the typeclass system. -/
  have h : Decidable (0 < n ∧ n ≤ m) := inferInstance
  cases h with
/- We consider the case where \( 0 < n \land n \leq m \) is false. In this case, we simplify the goal using the hypothesis \( h \), which directly leads to the goal being trivially true. -/
  | isFalse h => simp [h]
/- We now consider the case where \( 0 < n \land n \leq m \) is true. This means \( n \) is a positive natural number and \( n \leq m \). -/
  | isTrue h =>
/- Using the hypothesis \( h \), we simplify the goal, which reduces it to \( n \cdot ((m - n) / n + 1) + (m - n) \% n = m \). -/
    simp [h]
/- We introduce an induction hypothesis \( ih \) which states that \( n \cdot ((m - n) / n) + (m - n) \% n = m - n \). -/
    have ih := div_add_mod (m - n) n
/- We rewrite the goal using several properties of natural numbers: distributivity, multiplicative identity, associativity, left commutativity, the induction hypothesis \( ih \), commutativity, and the cancellation property of subtraction. This sequence of rewrites transforms the goal into \( m = m \), which is trivially true. -/
    rw [Nat.left_distrib, Nat.mul_one, Nat.add_assoc, Nat.add_left_comm, ih, Nat.add_comm, Nat.sub_add_cancel h.2]
decreasing_by apply div_rec_lemma; assumption","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3230,Nat.add_mul_div_left,theorem Nat.add_mul_div_left (x z : Nat) {y : Nat} (H : 0 < y) : (x + y * z) / y = x / y + z := by sorry,"Left Addition and Multiplication Distribute Over Division in Natural Numbers : For any natural numbers \( x \) and \( z \), and for any natural number \( y \) such that \( y > 0 \), the following equality holds:
\[ \frac{x + y \cdot z}{y} = \frac{x}{y} + z. \]","theorem Nat.add_mul_div_left (x z : Nat) {y : Nat} (H : 0 < y) : (x + y * z) / y = x / y + z := by
  induction z with
  | zero => rw [Nat.mul_zero, Nat.add_zero, Nat.add_zero]
  | succ z ih => rw [mul_succ, ← Nat.add_assoc, add_div_right _ H, ih]; rfl","We proceed by induction on \( z \).

**Base Case:**
For \( z = 0 \), we have:
\[ \frac{x + y \cdot 0}{y} = \frac{x + 0}{y} = \frac{x}{y} = \frac{x}{y} + 0. \]
This directly simplifies to \( x / y = x / y \), which is trivially true.

**Inductive Step:**
Assume the inductive hypothesis \( (x + y \cdot z) / y = x / y + z \) holds for some \( z \). We need to show that it holds for \( z + 1 \).

Consider \( z + 1 \):
\[ \frac{x + y \cdot (z + 1)}{y} = \frac{x + y \cdot z + y}{y}. \]
Using the property of multiplication by successor, \( y \cdot (z + 1) = y \cdot z + y \), we get:
\[ \frac{x + y \cdot z + y}{y}. \]
By the associativity of addition, this can be rewritten as:
\[ \frac{x + (y \cdot z + y)}{y}. \]
Applying the property that \( (x + y) / y = x / y + 1 \) when \( y > 0 \), we get:
\[ \frac{x + y \cdot z + y}{y} = \frac{x + y \cdot z}{y} + 1. \]
Using the inductive hypothesis \( (x + y \cdot z) / y = x / y + z \), we substitute:
\[ \frac{x + y \cdot z}{y} + 1 = x / y + z + 1. \]
Thus, we have:
\[ \frac{x + y \cdot (z + 1)}{y} = x / y + (z + 1). \]
This completes the inductive step, and by induction, the theorem holds for all natural numbers \( z \).","theorem Nat.add_mul_div_left (x z : Nat) {y : Nat} (H : 0 < y) : (x + y * z) / y = x / y + z := by
  induction z with
/- For the base case where \( z = 0 \), we use the properties of multiplication by zero and addition of zero in natural numbers. Specifically, we rewrite \( y \cdot 0 \) as \( 0 \), and then simplify \( x + 0 \) to \( x \). This directly simplifies the goal to \( x / y = x / y \), which is trivially true. -/
  | zero => rw [Nat.mul_zero, Nat.add_zero, Nat.add_zero]
/- For the inductive step where \( z = k + 1 \) (denoted as `succ z`), we use the inductive hypothesis \( ih \) which states that \( (x + y \cdot z) / y = x / y + z \). We start by rewriting \( y \cdot (z + 1) \) using the property of multiplication by successor, which gives \( y \cdot z + y \). Then, we use the associativity of addition to rearrange the terms. Next, we apply the property that \( (x + y) / y = x / y + 1 \) when \( y > 0 \). Finally, we use the inductive hypothesis \( ih \) to replace \( (x + y \cdot z) / y \) with \( x / y + z \). This simplifies the goal to \( x / y + z + 1 = x / y + (z + 1) \), which is trivially true by the reflexive property of equality. -/
  | succ z ih => rw [mul_succ, ← Nat.add_assoc, add_div_right _ H, ih]; rfl","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3233,Nat.div_lt_self,theorem Nat.div_lt_self {n k : Nat} (hLtN : 0 < n) (hLtK : 1 < k) : n / k < n := by sorry,"Division of Natural Number by Greater Than One is Less Than the Number : For any natural numbers \( n \) and \( k \) such that \( n > 0 \) and \( k > 1 \), the division of \( n \) by \( k \) is strictly less than \( n \), i.e., \( n / k < n \).","theorem Nat.div_lt_self {n k : Nat} (hLtN : 0 < n) (hLtK : 1 < k) : n / k < n := by
  rw [div_eq]
  cases (inferInstance : Decidable (0 < k ∧ k ≤ n)) with
  | isFalse h => simp [hLtN, h]
  | isTrue h =>
    suffices (n - k) / k + 1 < n by simp [h, this]
    have ⟨_, hKN⟩ := h
    have : (n - k) / k ≤ n - k := div_le_self (n - k) k
    have := Nat.add_le_of_le_sub hKN this
    exact Nat.lt_of_lt_of_le (Nat.add_lt_add_left hLtK _) this","We start by rewriting the division \( n / k \) using the definition of natural number division, which states that \( n / k = \begin{cases} \frac{n - k}{k} + 1 & \text{if } k > 0 \text{ and } k \le n, \\ 0 & \text{otherwise}. \end{cases} \)

We consider two cases based on the condition \( 0 < k \land k \le n \):

1. **Case where the condition is false:**
If \( 0 < k \land k \le n \) is false, then \( n / k = 0 \). Since \( 0 < n \) by assumption, the goal \( 0 < n \) is trivially true.

2. **Case where the condition is true:**
If \( 0 < k \land k \le n \) is true, we extract the parts \( 0 < k \) and \( k \le n \), denoting the latter as \( hKN \).

It suffices to show that \( (n - k) / k + 1 < n \). If we can prove this, then using the true condition \( 0 < k \land k \le n \) and simplifying, we will have \( (n - k) / k + 1 < n \), which directly implies \( n / k < n \).

We show that \( (n - k) / k \le n - k \) using the property that division by a number greater than or equal to one does not increase the value in a linear ordered semifield. Specifically, since \( k \ge 1 \), we have \( (n - k) / k \le n - k \).

Using the fact that \( k \le n \) and \( (n - k) / k \le n - k \), we deduce that \( (n - k) / k + k \le n \) by the property of addition and subtraction inequality.

Finally, we use the transitivity of less-than and less-than-or-equal to show that \( (n - k) / k + 1 < n \). Since \( 1 < k \) and \( (n - k) / k + k \le n \), we have \( (n - k) / k + 1 < n \).

Thus, in both cases, we have shown that \( n / k < n \), completing the proof.","theorem Nat.div_lt_self {n k : Nat} (hLtN : 0 < n) (hLtK : 1 < k) : n / k < n := by
/- We start by rewriting the division \( n / k \) using the definition of natural number division, which states that \( n / k = \begin{cases} \frac{n - k}{k} + 1 & \text{if } k > 0 \text{ and } k \le n, \\ 0 & \text{otherwise}. \end{cases} \) -/
  rw [div_eq]
  cases (inferInstance : Decidable (0 < k ∧ k ≤ n)) with
/- We consider the case where the condition \( 0 < k \land k \le n \) is false. In this case, the division \( n / k \) simplifies to \( 0 \), and since \( 0 < n \) by assumption, the goal \( 0 < n \) is trivially true. -/
  | isFalse h => simp [hLtN, h]
/- We now consider the case where the condition \( 0 < k \land k \le n \) is true. -/
  | isTrue h =>
/- It suffices to show that \( (n - k) / k + 1 < n \). If we can prove this, then using the true condition \( 0 < k \land k \le n \) and simplifying, we will have \( (n - k) / k + 1 < n \), which directly implies \( n / k < n \). -/
    suffices (n - k) / k + 1 < n by simp [h, this]
/- From the true condition \( 0 < k \land k \le n \), we extract the parts \( 0 < k \) and \( k \le n \), denoting the latter as \( hKN \). -/
    have ⟨_, hKN⟩ := h
/- We show that \( (n - k) / k \le n - k \) using the property that division by a number greater than or equal to one does not increase the value in a linear ordered semifield. Specifically, since \( k \ge 1 \), we have \( (n - k) / k \le n - k \). -/
    have : (n - k) / k ≤ n - k := div_le_self (n - k) k
/- Using the fact that \( k \le n \) and \( (n - k) / k \le n - k \), we deduce that \( (n - k) / k + k \le n \) by the property of addition and subtraction inequality. -/
    have := Nat.add_le_of_le_sub hKN this
/- Finally, we use the transitivity of less-than and less-than-or-equal to show that \( (n - k) / k + 1 < n \). Since \( 1 < k \) and \( (n - k) / k + k \le n \), we have \( (n - k) / k + 1 < n \). -/
    exact Nat.lt_of_lt_of_le (Nat.add_lt_add_left hLtK _) this","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3237,Nat.mul_sub_div,theorem Nat.mul_sub_div (x n p : Nat) (h₁ : x < n*p) : (n * p - (x + 1)) / n = p - ((x / n) + 1) := by sorry,"Multiplication and Subtraction Identity: \(\frac{n \cdot p - (x + 1)}{n} = p - \left( \frac{x}{n} + 1 \right)\) : For any natural numbers \( x \), \( n \), and \( p \), if \( x < n \cdot p \), then the division of the difference \( n \cdot p - (x + 1) \) by \( n \) is equal to \( p - \left( \frac{x}{n} + 1 \right) \), i.e., \(\frac{n \cdot p - (x + 1)}{n} = p - \left( \frac{x}{n} + 1 \right)\).","theorem Nat.mul_sub_div (x n p : Nat) (h₁ : x < n*p) : (n * p - (x + 1)) / n = p - ((x / n) + 1) := by
  have npos : 0 < n := (eq_zero_or_pos _).resolve_left fun n0 => by
    rw [n0, Nat.zero_mul] at h₁; exact not_lt_zero _ h₁
  apply Nat.div_eq_of_lt_le
  focus
    rw [Nat.mul_sub_right_distrib, Nat.mul_comm]
    exact Nat.sub_le_sub_left ((div_lt_iff_lt_mul npos).1 (lt_succ_self _)) _
  focus
    show succ (pred (n * p - x)) ≤ (succ (pred (p - x / n))) * n
    rw [succ_pred_eq_of_pos (Nat.sub_pos_of_lt h₁),
      fun h => succ_pred_eq_of_pos (Nat.sub_pos_of_lt h)] -- TODO: why is the function needed?
    focus
      rw [Nat.mul_sub_right_distrib, Nat.mul_comm]
      exact Nat.sub_le_sub_left (div_mul_le_self ..) _
    focus
      rwa [div_lt_iff_lt_mul npos, Nat.mul_comm]","First, we show that \( n \) is positive. Since \( n \) is either zero or positive, and if \( n \) were zero, then \( n \cdot p \) would also be zero, contradicting the assumption that \( x < n \cdot p \). Therefore, \( n \) must be positive.

To prove the division identity, it suffices to show that \( (p - (x / n + 1)) \cdot n \leq n \cdot p - (x + 1) \) and \( n \cdot p - (x + 1) < (p - (x / n + 1) + 1) \cdot n \).

First, we focus on showing that \( (p - (x / n + 1)) \cdot n \leq n \cdot p - (x + 1) \). Using the distributive property of multiplication over subtraction and the commutativity of multiplication, we rewrite the goal as \( n \cdot p - (x / n + 1) \cdot n \leq n \cdot p - (x + 1) \). Since \( x / n \cdot n \leq x \) by the property of division, it follows that \( n \cdot p - (x / n + 1) \cdot n \leq n \cdot p - (x + 1) \).

Next, we focus on showing that \( n \cdot p - (x + 1) < (p - (x / n + 1) + 1) \cdot n \). We rewrite the goal using the properties of the successor and predecessor functions for positive numbers, which simplifies to \( n \cdot p - x < (p - x / n) \cdot n \). Using the distributive property and commutativity of multiplication, we rewrite the goal as \( p \cdot n - x < p \cdot n - x / n \cdot n \). Since \( x / n \cdot n \leq x \), it follows that \( p \cdot n - x \leq p \cdot n - x / n \cdot n \). Finally, we use the division inequality to show that \( x / n < p \), which completes the proof.

Thus, we have shown that \(\frac{n \cdot p - (x + 1)}{n} = p - \left( \frac{x}{n} + 1 \right)\).","theorem Nat.mul_sub_div (x n p : Nat) (h₁ : x < n*p) : (n * p - (x + 1)) / n = p - ((x / n) + 1) := by
/- First, we show that \( n \) is positive. Since \( n \) is either zero or positive, and if \( n \) were zero, then \( n \cdot p \) would also be zero, contradicting the assumption that \( x < n \cdot p \). Therefore, \( n \) must be positive. -/
  have npos : 0 < n := (eq_zero_or_pos _).resolve_left fun n0 => by
    rw [n0, Nat.zero_mul] at h₁; exact not_lt_zero _ h₁
/- To prove the division identity, it suffices to show that \( (p - (x / n + 1)) \cdot n \leq n \cdot p - (x + 1) \) and \( n \cdot p - (x + 1) < (p - (x / n + 1) + 1) \cdot n \). -/
  apply Nat.div_eq_of_lt_le
/- First, we focus on showing that \( (p - (x / n + 1)) \cdot n \leq n \cdot p - (x + 1) \). Using the distributive property of multiplication over subtraction and the commutativity of multiplication, we rewrite the goal as \( n \cdot p - (x / n + 1) \cdot n \leq n \cdot p - (x + 1) \). Since \( x / n \cdot n \leq x \) by the property of division, it follows that \( n \cdot p - (x / n + 1) \cdot n \leq n \cdot p - (x + 1) \). -/
  focus
    rw [Nat.mul_sub_right_distrib, Nat.mul_comm]
    exact Nat.sub_le_sub_left ((div_lt_iff_lt_mul npos).1 (lt_succ_self _)) _
/- Next, we focus on showing that \( n \cdot p - (x + 1) < (p - (x / n + 1) + 1) \cdot n \). We rewrite the goal using the properties of the successor and predecessor functions for positive numbers, which simplifies to \( n \cdot p - x < (p - x / n) \cdot n \). Using the distributive property and commutativity of multiplication, we rewrite the goal as \( p \cdot n - x < p \cdot n - x / n \cdot n \). Since \( x / n \cdot n \leq x \), it follows that \( p \cdot n - x \leq p \cdot n - x / n \cdot n \). Finally, we use the division inequality to show that \( x / n < p \), which completes the proof. -/
  focus
    show succ (pred (n * p - x)) ≤ (succ (pred (p - x / n))) * n
    rw [succ_pred_eq_of_pos (Nat.sub_pos_of_lt h₁),
      fun h => succ_pred_eq_of_pos (Nat.sub_pos_of_lt h)] -- TODO: why is the function needed?
    focus
      rw [Nat.mul_sub_right_distrib, Nat.mul_comm]
      exact Nat.sub_le_sub_left (div_mul_le_self ..) _
    focus
      rwa [div_lt_iff_lt_mul npos, Nat.mul_comm]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3238,Nat.sub_mul_div,theorem Nat.sub_mul_div (x n p : Nat) (h₁ : n*p ≤ x) : (x - n*p) / n = x / n - p := by sorry,"Subtraction and Division Identity: \(\frac{x - n \cdot p}{n} = \frac{x}{n} - p\) : For any natural numbers \( x \), \( n \), and \( p \), if \( n \cdot p \le x \), then the division of the difference \( x - n \cdot p \) by \( n \) is equal to the difference of the division of \( x \) by \( n \) and \( p \), i.e., \(\frac{x - n \cdot p}{n} = \frac{x}{n} - p\).","theorem Nat.sub_mul_div (x n p : Nat) (h₁ : n*p ≤ x) : (x - n*p) / n = x / n - p := by
  match eq_zero_or_pos n with
  | .inl h₀ => rw [h₀, Nat.div_zero, Nat.div_zero, Nat.zero_sub]
  | .inr h₀ => induction p with
    | zero => rw [Nat.mul_zero, Nat.sub_zero, Nat.sub_zero]
    | succ p IH =>
      have h₂ : n * p ≤ x := Nat.le_trans (Nat.mul_le_mul_left _ (le_succ _)) h₁
      have h₃ : x - n * p ≥ n := by
        apply Nat.le_of_add_le_add_right
        rw [Nat.sub_add_cancel h₂, Nat.add_comm]
        rw [mul_succ] at h₁
        exact h₁
      rw [sub_succ, ← IH h₂, div_eq_sub_div h₀ h₃]
      simp [Nat.pred_succ, mul_succ, Nat.sub_sub]","We proceed by induction on \( p \).

**Base Case:**
For \( p = 0 \), we have \( n \cdot 0 = 0 \). Thus, \( x - n \cdot 0 = x \). The division of \( x \) by \( n \) is \( \frac{x}{n} \), and subtracting \( 0 \) from this gives \( \frac{x}{n} \). Therefore, the base case holds.

**Inductive Step:**
Assume the statement holds for \( p \), i.e., \( \frac{x - n \cdot p}{n} = \frac{x}{n} - p \). We need to show it holds for \( p + 1 \).

First, we note that \( n \cdot (p + 1) = n \cdot p + n \). By the inductive hypothesis, we have \( \frac{x - n \cdot p}{n} = \frac{x}{n} - p \).

We need to show that \( \frac{x - n \cdot (p + 1)}{n} = \frac{x}{n} - (p + 1) \).

Using the division identity for natural numbers, we have:
\[
\frac{x - n \cdot (p + 1)}{n} = \frac{x - n \cdot p - n}{n} + 1
\]

By the inductive hypothesis, \( \frac{x - n \cdot p - n}{n} = \frac{x - n \cdot p}{n} - 1 \).

Thus,
\[
\frac{x - n \cdot (p + 1)}{n} = \left(\frac{x - n \cdot p}{n} - 1\right) + 1 = \frac{x - n \cdot p}{n}
\]

By the inductive hypothesis, \( \frac{x - n \cdot p}{n} = \frac{x}{n} - p \).

Therefore,
\[
\frac{x - n \cdot (p + 1)}{n} = \frac{x}{n} - p
\]

This completes the inductive step, and hence the theorem is proved.","theorem Nat.sub_mul_div (x n p : Nat) (h₁ : n*p ≤ x) : (x - n*p) / n = x / n - p := by
  match eq_zero_or_pos n with
/- In the case where \( n = 0 \), we rewrite the goal using the fact that division by zero is zero and subtraction of zero is the identity. -/
  | .inl h₀ => rw [h₀, Nat.div_zero, Nat.div_zero, Nat.zero_sub]
/- In the case where \( n > 0 \), we perform induction on \( p \). -/
  | .inr h₀ => induction p with
/- For the base case where \( p = 0 \), we rewrite the goal using the fact that multiplication by zero is zero and subtraction of zero is the identity. -/
    | zero => rw [Nat.mul_zero, Nat.sub_zero, Nat.sub_zero]
/- For the inductive step where \( p \) is the successor of some natural number, we use the induction hypothesis \( IH \). -/
    | succ p IH =>
/- We introduce a new hypothesis \( h₂ \) stating that \( n \times p \leq x \) by using the transitivity of the less-than-or-equal-to relation and the fact that \( n \times p \leq n \times (p + 1) \). -/
      have h₂ : n * p ≤ x := Nat.le_trans (Nat.mul_le_mul_left _ (le_succ _)) h₁
/- We introduce a new hypothesis \( h₃ \) stating that \( x - n \times p \geq n \) by proving it separately. -/
      have h₃ : x - n * p ≥ n := by
/- We apply the theorem that states if \( a + c \leq b + c \), then \( a \leq b \). -/
        apply Nat.le_of_add_le_add_right
/- We rewrite the goal using the cancellation property of subtraction and the commutativity of addition in natural numbers. -/
        rw [Nat.sub_add_cancel h₂, Nat.add_comm]
/- We rewrite the hypothesis \( h₁ \) using the property of multiplication by the successor of a natural number. -/
        rw [mul_succ] at h₁
/- The goal is exactly proved by the hypothesis \( h₁ \). -/
        exact h₁
/- We rewrite the goal using the subtraction of the successor, the induction hypothesis \( IH \) applied to \( h₂ \), and the division identity for natural numbers. -/
      rw [sub_succ, ← IH h₂, div_eq_sub_div h₀ h₃]
/- We simplify the goal using the properties of natural numbers: the predecessor of the successor of a number is the number itself, the multiplication by the successor of a number, and the subtraction identity for natural numbers. -/
/- We simplify the goal using the properties of natural numbers: the predecessor of the successor of a number is the number itself, the multiplication by the successor of a number, and the subtraction identity for natural numbers. -/
      simp [Nat.pred_succ, mul_succ, Nat.sub_sub]","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3240,Nat.div_div_eq_div_mul,theorem Nat.div_div_eq_div_mul (m n k : Nat) : m / n / k = m / (n * k) := by sorry,"Division of Division Equals Division by Product: \(\frac{m}{n} / k = \frac{m}{n \cdot k}\) : For any natural numbers \( m \), \( n \), and \( k \), the division of \( m \) by \( n \) and then by \( k \) is equal to the division of \( m \) by the product of \( n \) and \( k \), i.e., \( \frac{m}{n} / k = \frac{m}{n \cdot k} \).","theorem Nat.div_div_eq_div_mul (m n k : Nat) : m / n / k = m / (n * k) := by
  cases eq_zero_or_pos k with
  | inl k0 => rw [k0, Nat.mul_zero, Nat.div_zero, Nat.div_zero] | inr kpos => ?_
  cases eq_zero_or_pos n with
  | inl n0 => rw [n0, Nat.zero_mul, Nat.div_zero, Nat.zero_div] | inr npos => ?_

  apply Nat.le_antisymm

  apply (le_div_iff_mul_le (Nat.mul_pos npos kpos)).2
  rw [Nat.mul_comm n k, ← Nat.mul_assoc]
  apply (le_div_iff_mul_le npos).1
  apply (le_div_iff_mul_le kpos).1
  (apply Nat.le_refl)

  apply (le_div_iff_mul_le kpos).2
  apply (le_div_iff_mul_le npos).2
  rw [Nat.mul_assoc, Nat.mul_comm n k]
  apply (le_div_iff_mul_le (Nat.mul_pos kpos npos)).1
  apply Nat.le_refl","We start by considering the possible values of \( k \):
- If \( k = 0 \), then \( k \cdot n = 0 \), and both \( \frac{m}{n} / 0 \) and \( \frac{m}{0} \) are zero, making the equality trivially true.
- If \( k > 0 \), we proceed to show the equality.

Next, we consider the possible values of \( n \):
- If \( n = 0 \), then \( n \cdot k = 0 \), and both \( \frac{m}{0} / k \) and \( \frac{m}{0} \) are zero, making the equality trivially true.
- If \( n > 0 \), we proceed to show the equality.

Now, assuming \( k > 0 \) and \( n > 0 \), we need to prove \( \frac{m}{n} / k = \frac{m}{n \cdot k} \).

To prove this, we use the antisymmetry of the less-than-or-equal-to relation:
- First, we show \( \frac{m}{n} / k \leq \frac{m}{n \cdot k} \). This is equivalent to showing \( \frac{m}{n} / k \cdot (n \cdot k) \leq m \). By the commutativity and associativity of multiplication, this simplifies to \( \frac{m}{n} / k \cdot k \cdot n \leq m \). Using the property that if \( a \leq c / b \) then \( a \cdot b \leq c \), we get \( \frac{m}{n} / k \cdot k \leq \frac{m}{n} \), which is trivially true by the reflexivity of the less-than-or-equal-to relation.

- Next, we show \( \frac{m}{n \cdot k} \leq \frac{m}{n} / k \). This is equivalent to showing \( \frac{m}{n \cdot k} \cdot k \leq \frac{m}{n} \). By the commutativity and associativity of multiplication, this simplifies to \( \frac{m}{n \cdot k} \cdot k \cdot n \leq m \). Using the property that if \( a \leq c / b \) then \( a \cdot b \leq c \), we get \( \frac{m}{n \cdot k} \cdot (k \cdot n) \leq m \), which is trivially true by the reflexivity of the less-than-or-equal-to relation.

Since both inequalities hold, we have \( \frac{m}{n} / k = \frac{m}{n \cdot k} \).

This completes the proof.","theorem Nat.div_div_eq_div_mul (m n k : Nat) : m / n / k = m / (n * k) := by
  cases eq_zero_or_pos k with
/- We consider two cases based on the value of \( k \):
- If \( k = 0 \), then we use the properties that \( k \cdot n = 0 \), \( m / 0 = 0 \), and \( 0 / k = 0 \) to simplify the expression, showing that both sides of the equation are zero.
- If \( k > 0 \), we leave this case to be handled later. -/
/- It suffices to show that \( M = 1 \), because if this is true, by using this \( M = 1 \) and simplifying, we get the determinant of \( M \) is \( 1 \) automatically. -/
/- Using extensionality, to prove that \( M = 1 \), we only need to show that \( M i = 1 i \) for every \( i \in n \). -/
/- Since \( n \) is empty, this \( M i = 1 i \) holds for every \( i \in n \) vacuously. This finishes the proof. -/
  | inl k0 => rw [k0, Nat.mul_zero, Nat.div_zero, Nat.div_zero] | inr kpos => ?_
  cases eq_zero_or_pos n with
  | inl n0 => rw [n0, Nat.zero_mul, Nat.div_zero, Nat.zero_div] | inr npos => ?_

  apply Nat.le_antisymm

/- To prove \( m / n / k \leq m / (n \cdot k) \), it suffices to show that \( m / n / k \cdot (n \cdot k) \leq m \), using the property that if \( a \leq c / b \) then \( a \cdot b \leq c \). -/
  apply (le_div_iff_mul_le (Nat.mul_pos npos kpos)).2
/- We rewrite the expression \( m / n / k \cdot (n \cdot k) \) by first applying the commutativity of multiplication \( n \cdot k = k \cdot n \), and then the associativity of multiplication to get \( m / n / k \cdot k \cdot n \). -/
  rw [Nat.mul_comm n k, ← Nat.mul_assoc]
/- To prove \( m / n / k \cdot k \leq m / n \), it suffices to show that \( m / n / k \cdot k \cdot n \leq m \), using the property that if \( a \leq c / b \) then \( a \cdot b \leq c \). -/
  apply (le_div_iff_mul_le npos).1
/- To prove \( m / n / k \leq m / n / k \), it suffices to show that \( m / n / k \cdot k \leq m / n \), using the property that if \( a \leq c / b \) then \( a \cdot b \leq c \). -/
  apply (le_div_iff_mul_le kpos).1
/- Since the inequality \( m / (k \cdot n) \leq m / (k \cdot n) \) is trivially true by the reflexivity of the less-than-or-equal-to relation, we apply this property directly. -/
  (apply Nat.le_refl)

/- To prove \( m / (n \cdot k) \leq m / n / k \), it suffices to show that \( m / (n \cdot k) \cdot k \leq m / n \), using the property that if \( a \leq c / b \) then \( a \cdot b \leq c \). -/
  apply (le_div_iff_mul_le kpos).2
/- To prove \( m / (n \cdot k) \cdot k \leq m / n \), it suffices to show that \( m / (n \cdot k) \cdot k \cdot n \leq m \), using the property that if \( a \leq c / b \) then \( a \cdot b \leq c \). -/
  apply (le_div_iff_mul_le npos).2
/- We rewrite the expression \( m / (n \cdot k) \cdot k \cdot n \) by first applying the associativity of multiplication, and then the commutativity of multiplication \( n \cdot k = k \cdot n \) to get \( m / (k \cdot n) \cdot (k \cdot n) \). -/
  rw [Nat.mul_assoc, Nat.mul_comm n k]
/- To prove \( m / (k \cdot n) \leq m / (k \cdot n) \), it suffices to show that \( m / (k \cdot n) \cdot (k \cdot n) \leq m \), using the property that if \( a \leq c / b \) then \( a \cdot b \leq c \). -/
  apply (le_div_iff_mul_le (Nat.mul_pos kpos npos)).1
/- Since the inequality \( m / n / k \leq m / n / k \) is trivially true by the reflexivity of the less-than-or-equal-to relation, we apply this property directly. -/
/- Since the inequality \( m / (k \cdot n) \leq m / (k \cdot n) \) is trivially true by the reflexivity of the less-than-or-equal-to relation, we apply this property directly. -/
  apply Nat.le_refl","import Init.WF
import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Nat.Div

open Nat

"
3966,Nat.dvd_add_iff_left,theorem Nat.dvd_add_iff_left {k m n : Nat} (h : k ∣ n) : k ∣ m ↔ k ∣ m + n := by sorry,"Divisibility of Sum by a Divisor of One Term in Natural Numbers: \( k \mid n \to (k \mid m \leftrightarrow k \mid m + n) \) : For any natural numbers \( k, m, \) and \( n \), if \( k \mid n \), then \( k \mid m \) if and only if \( k \mid m + n \).","theorem Nat.dvd_add_iff_left {k m n : Nat} (h : k ∣ n) : k ∣ m ↔ k ∣ m + n := by
  rw [Nat.add_comm]; exact Nat.dvd_add_iff_right h","We start by using the commutativity of addition to rewrite the goal as \( k \mid m + n \) if and only if \( k \mid n + m \). Then, we apply the theorem that if \( k \mid n \), then \( k \mid m \) if and only if \( k \mid n + m \). This directly proves the goal, establishing that \( k \mid m \) if and only if \( k \mid m + n \).","theorem Nat.dvd_add_iff_left {k m n : Nat} (h : k ∣ n) : k ∣ m ↔ k ∣ m + n := by
/- First, we use the commutativity of addition to rewrite the goal as \( k \mid m + n \) if and only if \( k \mid n + m \). Then, we apply the theorem that if \( k \mid n \), then \( k \mid m \) if and only if \( k \mid n + m \), which directly proves the goal. -/
  rw [Nat.add_comm]; exact Nat.dvd_add_iff_right h","import Init.Data.Nat.Div
import Init.Meta
import Init.Data.Nat.Dvd

open Nat

"
3970,Nat.mod_eq_zero_of_dvd,theorem Nat.mod_eq_zero_of_dvd {m n : Nat} (H : m ∣ n) : n % m = 0 := by sorry,"Divisibility Implies Remainder is Zero in Natural Numbers : For any natural numbers \( m \) and \( n \), if \( m \) divides \( n \), then the remainder when \( n \) is divided by \( m \) is zero, i.e., \( m \mid n \implies n \% m = 0 \).","theorem Nat.mod_eq_zero_of_dvd {m n : Nat} (H : m ∣ n) : n % m = 0 := by
  let ⟨z, H⟩ := H; rw [H, mul_mod_right]","Assume \( m \mid n \). By the definition of divisibility, there exists a natural number \( z \) such that \( n = m \cdot z \). Substituting this into the expression for the remainder, we get \( n \% m = (m \cdot z) \% m \). By the property of the modulus operation, the remainder of a product with a factor is zero when divided by that factor, i.e., \( (m \cdot z) \% m = 0 \). Therefore, \( n \% m = 0 \), which completes the proof.","theorem Nat.mod_eq_zero_of_dvd {m n : Nat} (H : m ∣ n) : n % m = 0 := by
/- Given the assumption \( m \mid n \), we can express \( n \) as \( n = m \cdot z \) for some natural number \( z \). Using this expression, we can rewrite \( n \% m \) as \( (m \cdot z) \% m \), which simplifies to \( 0 \) by the property that the remainder of a product with a factor is zero when divided by that factor. -/
  let ⟨z, H⟩ := H; rw [H, mul_mod_right]","import Init.Data.Nat.Div
import Init.Meta
import Init.Data.Nat.Dvd

open Nat

"
3972,Nat.div_mul_cancel,theorem Nat.div_mul_cancel {n m : Nat} (H : n ∣ m) : m / n * n = m := by sorry,"Multiplication and Division Cancellation: \( n \mid m \to \frac{m}{n} \times n = m \) : For any natural numbers \( n \) and \( m \), if \( n \) divides \( m \), then the division of \( m \) by \( n \) followed by multiplication of the result by \( n \) yields \( m \). In other words, if \( n \mid m \), then \( \frac{m}{n} \times n = m \).","theorem Nat.div_mul_cancel {n m : Nat} (H : n ∣ m) : m / n * n = m := by
  rw [Nat.mul_comm, Nat.mul_div_cancel' H]","Given that \( n \) divides \( m \), we need to show that \( \frac{m}{n} \times n = m \). By the commutativity of multiplication, we can rewrite this as \( n \times \left( \frac{m}{n} \right) = m \). Since \( n \) divides \( m \), the cancellation property of multiplication and division in natural numbers ensures that \( n \times \left( \frac{m}{n} \right) = m \). Therefore, \( \frac{m}{n} \times n = m \), completing the proof.","theorem Nat.div_mul_cancel {n m : Nat} (H : n ∣ m) : m / n * n = m := by
/- First, we use the commutativity of multiplication to rewrite the goal as \( n \times \left( \frac{m}{n} \right) = m \). Then, since \( n \) divides \( m \), we apply the cancellation property of multiplication and division to conclude that \( n \times \left( \frac{m}{n} \right) = m \). -/
  rw [Nat.mul_comm, Nat.mul_div_cancel' H]","import Init.Data.Nat.Div
import Init.Meta
import Init.Data.Nat.Dvd

open Nat

"
3975,Nat.emod_pos_of_not_dvd,theorem Nat.emod_pos_of_not_dvd {a b : Nat} (h : ¬ a ∣ b) : 0 < b % a := by sorry,"Remainder is Positive if Divisibility Fails: \( 0 < b \% a \) if \( a \nmid b \) : For any natural numbers \( a \) and \( b \), if \( a \) does not divide \( b \), then the remainder when \( b \) is divided by \( a \) is strictly greater than 0, i.e., \( 0 < b \% a \).","theorem Nat.emod_pos_of_not_dvd {a b : Nat} (h : ¬ a ∣ b) : 0 < b % a := by
  rw [dvd_iff_mod_eq_zero] at h
  exact Nat.pos_of_ne_zero h","We start by using the theorem that \( m \mid n \leftrightarrow n \% m = 0 \) to convert the assumption \( a \nmid b \) into \( b \% a \neq 0 \). This is because \( a \mid b \) is equivalent to \( b \% a = 0 \).

Now, we need to show that \( 0 < b \% a \). This follows directly from the theorem that if \( n \neq 0 \), then \( 0 < n \). Since our assumption \( h \) states that \( b \% a \neq 0 \), it follows that \( 0 < b \% a \).

Thus, we have shown that \( 0 < b \% a \) if \( a \nmid b \), completing the proof.","theorem Nat.emod_pos_of_not_dvd {a b : Nat} (h : ¬ a ∣ b) : 0 < b % a := by
/- Since the theorem that \( m \mid n \leftrightarrow n \% m = 0 \) shows that \( a \mid b \) is equivalent to \( b \% a = 0 \), we can replace \( a \mid b \) with \( b \% a = 0 \) in the assumption \( h \). Thus, \( h \) now states that \( b \% a \neq 0 \). -/
  rw [dvd_iff_mod_eq_zero] at h
/- The current goal \( 0 < b \% a \) is exactly proved by the theorem that if \( n \neq 0 \), then \( 0 < n \). Since \( h \) states that \( b \% a \neq 0 \), it follows that \( 0 < b \% a \). -/
  exact Nat.pos_of_ne_zero h","import Init.Data.Nat.Div
import Init.Meta
import Init.Data.Nat.Dvd

open Nat

"
3979,Nat.dvd_of_mul_dvd_mul_right,theorem Nat.dvd_of_mul_dvd_mul_right (kpos : 0 < k) (H : m * k ∣ n * k) : m ∣ n := by sorry,"Right Multiplication Preserves Divisibility in Natural Numbers : For any natural numbers \( k, m, \) and \( n \), if \( k > 0 \) and \( m \cdot k \) divides \( n \cdot k \), then \( m \) divides \( n \).","theorem Nat.dvd_of_mul_dvd_mul_right (kpos : 0 < k) (H : m * k ∣ n * k) : m ∣ n := by
  rw [Nat.mul_comm m k, Nat.mul_comm n k] at H; exact Nat.dvd_of_mul_dvd_mul_left kpos H","Given the divisibility condition \( m \cdot k \mid n \cdot k \), we start by using the commutativity of multiplication in natural numbers to rewrite this condition as \( k \cdot m \mid k \cdot n \). Since \( k > 0 \), we can apply the theorem that if \( k \cdot m \mid k \cdot n \), then \( m \mid n \). This directly establishes the desired divisibility relation, completing the proof.","theorem Nat.dvd_of_mul_dvd_mul_right (kpos : 0 < k) (H : m * k ∣ n * k) : m ∣ n := by
/- First, we use the commutativity of multiplication in natural numbers to rewrite the divisibility condition \( m \cdot k \mid n \cdot k \) as \( k \cdot m \mid k \cdot n \). Then, we apply the theorem that if \( k > 0 \) and \( k \cdot m \mid k \cdot n \), then \( m \mid n \). This directly proves our goal. -/
  rw [Nat.mul_comm m k, Nat.mul_comm n k] at H; exact Nat.dvd_of_mul_dvd_mul_left kpos H","import Init.Data.Nat.Div
import Init.Meta
import Init.Data.Nat.Dvd

open Nat

"
3981,Nat.dvd_of_mul_dvd_mul_left,"theorem Nat.dvd_of_mul_dvd_mul_left 
    (kpos : 0 < k) (H : k * m ∣ k * n) : m ∣ n := by sorry","Left Multiplication Preserves Divisibility in Natural Numbers : For any natural numbers \( k, m, \) and \( n \), if \( k > 0 \) and \( k \cdot m \) divides \( k \cdot n \), then \( m \) divides \( n \).","theorem Nat.dvd_of_mul_dvd_mul_left 
    (kpos : 0 < k) (H : k * m ∣ k * n) : m ∣ n := by
  let ⟨l, H⟩ := H
  rw [Nat.mul_assoc] at H
  exact ⟨_, Nat.eq_of_mul_eq_mul_left kpos H⟩","Assume \( k > 0 \) and \( k \cdot m \) divides \( k \cdot n \). This means there exists a natural number \( l \) such that \( k \cdot n = k \cdot m \cdot l \). Using the associativity of multiplication, we can rewrite this equation as \( k \cdot n = k \cdot (m \cdot l) \). Since \( k > 0 \), by the cancellation property of multiplication in natural numbers, we have \( n = m \cdot l \). Therefore, \( m \) divides \( n \). This completes the proof.","theorem Nat.dvd_of_mul_dvd_mul_left 
    (kpos : 0 < k) (H : k * m ∣ k * n) : m ∣ n := by
/- Let \( l \) be a natural number such that \( k \cdot n = k \cdot m \cdot l \). -/
  let ⟨l, H⟩ := H
/- Using the associativity of multiplication in natural numbers, we rewrite the equation \( k \cdot n = k \cdot m \cdot l \) to \( k \cdot n = k \cdot (m \cdot l) \). -/
  rw [Nat.mul_assoc] at H
/- By the cancellation property of multiplication in natural numbers, since \( k > 0 \) and \( k \cdot n = k \cdot (m \cdot l) \), it follows that \( n = m \cdot l \). Therefore, \( m \) divides \( n \). -/
  exact ⟨_, Nat.eq_of_mul_eq_mul_left kpos H⟩","import Init.Data.Nat.Div
import Init.Meta
import Init.Data.Nat.Dvd

open Nat

"
3983,Nat.dvd_of_mod_eq_zero,theorem Nat.dvd_of_mod_eq_zero {m n : Nat} (H : n % m = 0) : m ∣ n := by sorry,"Divisibility from Zero Remainder: \( n \% m = 0 \to m \mid n \) : For any natural numbers \( m \) and \( n \), if the remainder when \( n \) is divided by \( m \) is zero, i.e., \( n \% m = 0 \), then \( m \) divides \( n \), denoted as \( m \mid n \).","theorem Nat.dvd_of_mod_eq_zero {m n : Nat} (H : n % m = 0) : m ∣ n := by
  exists n / m
  have := (mod_add_div n m).symm
  rwa [H, Nat.zero_add] at this","To show that \( m \) divides \( n \), it suffices to find an integer \( k \) such that \( n = m \cdot k \). We claim that \( k = n / m \) works.

We construct a lemma that states \( n = n \% m + m \cdot (n / m) \). This is a direct consequence of the identity \( n \% m + m \cdot (n / m) = n \), which we take in its symmetric form.

Using the assumption \( n \% m = 0 \), we substitute \( 0 \) for \( n \% m \) in the lemma \( n = n \% m + m \cdot (n / m) \). This simplifies to \( n = 0 + m \cdot (n / m) \). By the property that \( 0 + a = a \) for any natural number \( a \), we further simplify to \( n = m \cdot (n / m) \). This matches our goal exactly, thus completing the proof.","theorem Nat.dvd_of_mod_eq_zero {m n : Nat} (H : n % m = 0) : m ∣ n := by
/- To show that \( m \) divides \( n \), it suffices to find an integer \( k \) such that \( n = m \cdot k \). We claim that \( k = n / m \) works. -/
  exists n / m
/- We construct a lemma that states \( n = n \% m + m \cdot (n / m) \). This is a direct consequence of the identity \( n \% m + m \cdot (n / m) = n \), which we take in its symmetric form. -/
  have := (mod_add_div n m).symm
/- Using the assumption \( n \% m = 0 \), we substitute \( 0 \) for \( n \% m \) in the lemma \( n = n \% m + m \cdot (n / m) \). This simplifies to \( n = 0 + m \cdot (n / m) \). By the property that \( 0 + a = a \) for any natural number \( a \), we further simplify to \( n = m \cdot (n / m) \). This matches our goal exactly, thus completing the proof. -/
  rwa [H, Nat.zero_add] at this","import Init.Data.Nat.Div
import Init.Meta
import Init.Data.Nat.Dvd

open Nat

"
3989,Nat.mul_div_assoc,theorem Nat.mul_div_assoc (m : Nat) (H : k ∣ n) : m * n / k = m * (n / k) := by sorry,"Multiplication and Division Associativity: \( m \cdot n / k = m \cdot (n / k) \) if \( k \mid n \) : For any natural numbers \( k \), \( n \), and \( m \), if \( k \) divides \( n \), then the expression \( m \cdot n / k \) is equal to \( m \cdot (n / k) \). In other words, if \( k \mid n \), then \( m \cdot n / k = m \cdot (n / k) \).","theorem Nat.mul_div_assoc (m : Nat) (H : k ∣ n) : m * n / k = m * (n / k) := by
  match Nat.eq_zero_or_pos k with
  | .inl h0 => rw [h0, Nat.div_zero, Nat.div_zero, Nat.mul_zero]
  | .inr hpos =>
    have h1 : m * n / k = m * (n / k * k) / k := by rw [Nat.div_mul_cancel H]
    rw [h1, ← Nat.mul_assoc, Nat.mul_div_cancel _ hpos]","We start by introducing a lemma \( h1 \) which states that \( m \cdot n / k = m \cdot (n / k \cdot k) / k \). This is derived using the cancellation property of division and multiplication, given that \( k \) divides \( n \).

Next, we rewrite the goal using this lemma. Then, we apply the associativity of multiplication to rearrange the terms. Finally, we use the cancellation property of division and multiplication, given that \( k > 0 \), to simplify the expression.

Thus, we have shown that \( m \cdot n / k = m \cdot (n / k) \), completing the proof.","theorem Nat.mul_div_assoc (m : Nat) (H : k ∣ n) : m * n / k = m * (n / k) := by
  match Nat.eq_zero_or_pos k with
  | .inl h0 => rw [h0, Nat.div_zero, Nat.div_zero, Nat.mul_zero]
  | .inr hpos =>
/- We introduce a new lemma \( h1 \) stating that \( m \cdot n / k = m \cdot (n / k \cdot k) / k \). This is derived by using the cancellation property of division and multiplication, given that \( k \) divides \( n \). -/
    have h1 : m * n / k = m * (n / k * k) / k := by rw [Nat.div_mul_cancel H]
/- First, we use the assumption \( h1 \) to rewrite the goal. Then, we apply the associativity of multiplication to rearrange the terms. Finally, we use the fact that \( k \) divides \( n \) and \( k > 0 \) to cancel the division by \( k \). -/
/- We rewrite the goal using the lemma \( h1 \), then apply the associativity of multiplication to rearrange the terms, and finally use the cancellation property of division and multiplication given \( k > 0 \) to simplify the expression. -/
    rw [h1, ← Nat.mul_assoc, Nat.mul_div_cancel _ hpos]","import Init.Data.Nat.Div
import Init.Meta
import Init.Data.Nat.Dvd

open Nat

"
3993,Nat.mod_mod_of_dvd,theorem Nat.mod_mod_of_dvd (a : Nat) (h : c ∣ b) : a % b % c = a % c := by sorry,"Modulo Identity: \(a \% b \% c = a \% c\) when \(c \mid b\) : For any natural numbers \(a\), \(b\), and \(c\), if \(c\) divides \(b\), then the remainder of \(a\) modulo \(b\) modulo \(c\) is equal to the remainder of \(a\) modulo \(c\), i.e., \(a \% b \% c = a \% c\).","theorem Nat.mod_mod_of_dvd (a : Nat) (h : c ∣ b) : a % b % c = a % c := by
  rw (config := {occs := .pos [2]}) [← mod_add_div a b]
  have ⟨x, h⟩ := h
  subst h
  rw [Nat.mul_assoc, add_mul_mod_self_left]","We start by rewriting the goal using the identity \( a \% b = a \% b + b \cdot (a / b) \). This transforms the goal from \( a \% b \% c = a \% c \) to \( a \% b \% c = (a \% b + b \cdot (a / b)) \% c \).

Given that \( c \) divides \( b \), we can express \( b \) as \( c \cdot x \) for some natural number \( x \). We introduce \( x \) and the equation \( b = c \cdot x \) as a new hypothesis.

Next, we substitute \( b \) with \( c \cdot x \) in the goal, which changes the goal to \( a \% (c \cdot x) \% c = (a \% (c \cdot x) + c \cdot x \cdot (a / (c \cdot x))) \% c \).

We then use the associativity of multiplication to rewrite \( c \cdot x \cdot (a / (c \cdot x)) \) as \( c \cdot (x \cdot (a / (c \cdot x))) \). Finally, we use the property that adding a multiple of \( c \) to \( a \% (c \cdot x) \) does not change the remainder when divided by \( c \). This simplifies the goal to \( a \% (c \cdot x) \% c = a \% (c \cdot x) \% c \), which is trivially true.

Thus, we have shown that \( a \% b \% c = a \% c \) when \( c \) divides \( b \).","theorem Nat.mod_mod_of_dvd (a : Nat) (h : c ∣ b) : a % b % c = a % c := by
/- We start by rewriting the goal using the identity that \( a \% b = a \% b + b \cdot (a / b) \). This transforms the goal from \( a \% b \% c = a \% c \) to \( a \% b \% c = (a \% b + b \cdot (a / b)) \% c \). -/
  rw (config := {occs := .pos [2]}) [← mod_add_div a b]
/- Given that \( c \) divides \( b \), we can express \( b \) as \( c \cdot x \) for some natural number \( x \). We introduce \( x \) and the equation \( b = c \cdot x \) as a new hypothesis. -/
  have ⟨x, h⟩ := h
/- We substitute \( b \) with \( c \cdot x \) in the goal, which changes the goal to \( a \% (c \cdot x) \% c = (a \% (c \cdot x) + c \cdot x \cdot (a / (c \cdot x))) \% c \). -/
  subst h
/- First, we use the associativity of multiplication to rewrite \( c \cdot x \cdot (a / (c \cdot x)) \) as \( c \cdot (x \cdot (a / (c \cdot x))) \). Then, we use the property that adding a multiple of \( c \) to \( a \% (c \cdot x) \) does not change the remainder when divided by \( c \). This simplifies the goal to \( a \% (c \cdot x) \% c = a \% (c \cdot x) \% c \), which is trivially true. -/
  rw [Nat.mul_assoc, add_mul_mod_self_left]","import Init.Data.Nat.Div
import Init.Meta
import Init.Data.Nat.Dvd

open Nat

"
4193,BitVec.iunfoldr.fst_eq,"theorem BitVec.iunfoldr.fst_eq 
    {f : Fin w → α → α × Bool} (state : Nat → α) (s : α)
    (init : s = state 0)
    (ind : ∀(i : Fin w), (f i (state i.val)).fst = state (i.val+1)) :
    (iunfoldr f s).fst = state w := by sorry","First Component of Iterative Unfolding Equals Final State: \((\text{BitVec.iunfoldr } f \, s).1 = \text{state}(w)\) : For any natural number \( w \) and any type \( \alpha \), given a function \( f : \text{Fin } w \to \alpha \to \alpha \times \text{Bool} \) and a state function \( \text{state} : \mathbb{N} \to \alpha \), if the initial state \( s \) is equal to \( \text{state}(0) \) and for every step \( i \) in the range \( \text{Fin } w \), the first component of \( f(i, \text{state}(i)) \) is equal to \( \text{state}(i + 1) \), then the first component of the result of `BitVec.iunfoldr f s` is equal to \( \text{state}(w) \).","theorem BitVec.iunfoldr.fst_eq 
    {f : Fin w → α → α × Bool} (state : Nat → α) (s : α)
    (init : s = state 0)
    (ind : ∀(i : Fin w), (f i (state i.val)).fst = state (i.val+1)) :
    (iunfoldr f s).fst = state w := by
  unfold iunfoldr
  apply Fin.hIterate_elim (fun i (p : α × BitVec i) => p.fst = state i)
  case init =>
    exact init
  case step =>
    intro i ⟨s, v⟩ p
    simp_all [ind i]","We start by expanding the definition of `BitVec.iunfoldr`, which iteratively applies the function `f` to the state `s` for `w` steps, producing a sequence of state values and a bitvector of width `w`.

To prove that the first component of the result of `BitVec.iunfoldr f s` is equal to `state w`, we use the heterogeneous iteration elimination theorem. This theorem states that if we can show that the first component of the state at each step `i` is equal to `state i`, then the first component of the final state after `w` steps will be equal to `state w`.

We discuss by cases. For the initial case, we need to show that the first component of the initial state `(s, nil)` is equal to `state 0`. This is exactly the assumption `init` that `s = state 0`.

For the step case, let `i` be an arbitrary element of `Fin w`, and let `(s, v)` be a pair where `s` is the state and `v` is the bitvector at step `i`. Assume `p` that the first component of `(s, v)` is equal to `state i`. Using the induction hypothesis `ind i`, which states that the first component of `f i (state i)` is equal to `state (i + 1)`, we simplify the goal to show that the first component of the next state is equal to `state (i + 1)`. This completes the proof.

Thus, the first component of the result of `BitVec.iunfoldr f s` is indeed equal to `state w`.","theorem BitVec.iunfoldr.fst_eq 
    {f : Fin w → α → α × Bool} (state : Nat → α) (s : α)
    (init : s = state 0)
    (ind : ∀(i : Fin w), (f i (state i.val)).fst = state (i.val+1)) :
    (iunfoldr f s).fst = state w := by
/- First, we expand the definition of `BitVec.iunfoldr`, which iteratively applies the function `f` to the state `s` for `w` steps, producing a sequence of state values and a bitvector of width `w`. -/
  unfold iunfoldr
/- To prove that the first component of the result of `BitVec.iunfoldr f s` is equal to `state w`, we use the heterogeneous iteration elimination theorem. This theorem states that if we can show that the first component of the state at each step `i` is equal to `state i`, then the first component of the final state after `w` steps will be equal to `state w`. -/
  apply Fin.hIterate_elim (fun i (p : α × BitVec i) => p.fst = state i)
/- We discuss by cases. For the initial case, we need to show that the first component of the initial state `(s, nil)` is equal to `state 0`. This is exactly the assumption `init` that `s = state 0`. -/
  case init =>
    exact init
/- For the step case, let `i` be an arbitrary element of `Fin w`, and let `(s, v)` be a pair where `s` is the state and `v` is the bitvector at step `i`. Assume `p` that the first component of `(s, v)` is equal to `state i`. Using the induction hypothesis `ind i`, which states that the first component of `f i (state i)` is equal to `state (i + 1)`, we simplify the goal to show that the first component of the next state is equal to `state (i + 1)`. This completes the proof. -/
  case step =>
    intro i ⟨s, v⟩ p
    simp_all [ind i]","import Init.Data.BitVec.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Fin.Iterate
import Init.Data.BitVec.Folds

open BitVec
open iunfoldr

"
4462,List.maximum?_replicate_of_pos,"theorem List.maximum?_replicate_of_pos [Max α] {n : Nat} {a : α} (w : max a a = a) (h : 0 < n) :
    (replicate n a).maximum? = some a := by sorry","Maximum of Replicated List is the Element if Replication Count is Positive: $\text{maximum?}(\text{replicate } n \, a) = \text{some } a$ for $n > 0$ : For any type $\alpha$ with a maximum operation, and for any natural number $n$ and element $a \in \alpha$, if the maximum of $a$ and $a$ is $a$ (i.e., $a \leq a$), and if $n$ is a positive natural number, then the maximum element of the list containing $n$ copies of $a$ is $a$. Formally, if $n > 0$, then $\text{maximum?}(\text{replicate } n \, a) = \text{some } a$.","theorem List.maximum?_replicate_of_pos [Max α] {n : Nat} {a : α} (w : max a a = a) (h : 0 < n) :
    (replicate n a).maximum? = some a := by
  simp [maximum?_replicate, Nat.ne_of_gt h, w]","Given that $n$ is a positive natural number, we know that $n \neq 0$. By the property of the maximum operation, since $a \leq a$, the maximum element of the list `replicate n a` is `some a` if $n > 0$. Using the fact that a number greater than zero is not equal to zero, we simplify the proposition to show that the maximum of the list `replicate n a` is `some a`. This completes the proof.","theorem List.maximum?_replicate_of_pos [Max α] {n : Nat} {a : α} (w : max a a = a) (h : 0 < n) :
    (replicate n a).maximum? = some a := by
/- Using the fact that the maximum of a replicated list is `some a` if the replication count is positive, and the property that a number greater than zero is not equal to zero, we simplify the proposition to show that the maximum of the list `replicate n a` is `some a`. -/
  simp [maximum?_replicate, Nat.ne_of_gt h, w]","import Init.Data.List.Lemmas
import Init.Data.List.MinMax

open List
open Nat
"
4463,List.minimum?_replicate_of_pos,"theorem List.minimum?_replicate_of_pos [Min α] {n : Nat} {a : α} (w : min a a = a) (h : 0 < n) :
    (replicate n a).minimum? = some a := by sorry","Minimum of Replicated List is the Element if Positive Replication : For any type $\alpha$ with a minimum operation, and for any natural number $n$ and element $a \in \alpha$, if the minimum of $a$ and $a$ is $a$ (i.e., $\min(a, a) = a$) and $n$ is positive (i.e., $0 < n$), then the minimum element of the list containing $n$ copies of $a$ is $a$. Formally, this can be written as:
\[
\min(a, a) = a \quad \text{and} \quad 0 < n \quad \implies \quad (\text{replicate } n \, a).minimum? = \text{some } a
\]","theorem List.minimum?_replicate_of_pos [Min α] {n : Nat} {a : α} (w : min a a = a) (h : 0 < n) :
    (replicate n a).minimum? = some a := by
  simp [minimum?_replicate, Nat.ne_of_gt h, w]","Given that \(\min(a, a) = a\) and \(0 < n\), we use the property of the minimum operation on a replicated list, which states that the minimum element of the list `replicate n a` is:
- `none` if \( n = 0 \),
- `some a` if \( n > 0 \).

Since \(0 < n\), it follows that \( n \neq 0 \). Therefore, by the definition of the minimum operation on a replicated list and the given conditions, we conclude that the minimum element of the list `replicate n a` is `some a`. This completes the proof.","theorem List.minimum?_replicate_of_pos [Min α] {n : Nat} {a : α} (w : min a a = a) (h : 0 < n) :
    (replicate n a).minimum? = some a := by
/- Using the fact that the minimum of a replicated list is the element itself if the list is non-empty, and the condition that \( n \neq 0 \) because \( 0 < n \), along with the assumption that \(\min(a, a) = a\), we simplify the proposition to show that the minimum element of the list containing \( n \) copies of \( a \) is \( a \). -/
  simp [minimum?_replicate, Nat.ne_of_gt h, w]","import Init.Data.List.Lemmas
import Init.Data.List.MinMax

open List
open Nat
"
4468,List.minimum?_eq_none_iff,theorem List.minimum?_eq_none_iff {xs : List α} [Min α] : xs.minimum? = none ↔ xs = [] := by sorry,"Minimum Element is None if and only if List is Empty: \( xs.minimum? = \text{none} \leftrightarrow xs = [] \) : For any type \( \alpha \) with a minimum operation, the minimum element of a list \( xs \) of type \( \alpha \) is `none` if and only if the list \( xs \) is empty, i.e., \( xs.minimum? = \text{none} \) if and only if \( xs = [] \).","theorem List.minimum?_eq_none_iff {xs : List α} [Min α] : xs.minimum? = none ↔ xs = [] := by
  cases xs <;> simp [minimum?]","We consider the two possible cases for the list \( xs \):

1. **Case 1: \( xs \) is empty.**
- For an empty list \( [] \), the minimum element is defined to be `none`. Therefore, \( [].minimum? = \text{none} \).
- This directly implies \( [].minimum? = \text{none} \leftrightarrow [] = [] \), which is trivially true.

2. **Case 2: \( xs \) is non-empty.**
- Let \( xs = head \mathbin{::} tail \), where \( head \) is the first element and \( tail \) is the rest of the list.
- For a non-empty list, the minimum element is defined to be the smallest element in the list, which is always `some` of an element. Therefore, \( (head \mathbin{::} tail).minimum? \neq \text{none} \).
- This leads to a contradiction with the assumption \( (head \mathbin{::} tail).minimum? = \text{none} \).

Since both cases cover all possibilities and the non-empty list case leads to a contradiction, we conclude that \( xs.minimum? = \text{none} \) if and only if \( xs = [] \).

This completes the proof.","theorem List.minimum?_eq_none_iff {xs : List α} [Min α] : xs.minimum? = none ↔ xs = [] := by
/- We consider the two possible cases for the list \( xs \): either \( xs \) is empty or \( xs \) is non-empty. For the empty list case, we simplify the expression \( [].minimum? = \text{none} \) to show that it is trivially true. For the non-empty list case, we simplify the expression \( (head \mathbin{::} tail).minimum? = \text{none} \) to show that it leads to a contradiction, thus proving the non-empty list case is impossible. -/
  cases xs <;> simp [minimum?]","import Init.Data.List.Lemmas
import Init.Data.List.MinMax

open List
open Nat
"
4470,List.maximum?_eq_none_iff,theorem List.maximum?_eq_none_iff {xs : List α} [Max α] : xs.maximum? = none ↔ xs = [] := by sorry,"Maximum of List is None if and only if List is Empty: \( \text{maximum?}(xs) = \text{none} \leftrightarrow xs = [] \) : For any type \( \alpha \) with a `Max` instance, the maximum element of a list \( xs \) of type \( \alpha \) is `none` if and only if the list \( xs \) is empty. In other words, \( \text{maximum?}(xs) = \text{none} \) if and only if \( xs = [] \).","theorem List.maximum?_eq_none_iff {xs : List α} [Max α] : xs.maximum? = none ↔ xs = [] := by
  cases xs <;> simp [maximum?]","We proceed by considering the two possible cases for the list \( xs \):

1. **Case 1: \( xs \) is empty.**
- In this case, \( xs = [] \). By the definition of `List.maximum?`, the maximum of an empty list is `none`. Therefore, \( [].maximum? = \text{none} \), which simplifies to \( \text{none} = \text{none} \), a trivial true statement.

2. **Case 2: \( xs \) is non-empty.**
- Let \( xs = head :: tail \), where \( head \) is the first element and \( tail \) is the rest of the list. By the definition of `List.maximum?`, the maximum of a non-empty list is always `some` value, which is the maximum element of the list. Therefore, \( (head :: tail).maximum? = \text{some } \text{max} \), where \( \text{max} \) is the maximum element of \( head :: tail \). This clearly contradicts the assumption that \( (head :: tail).maximum? = \text{none} \). Hence, this case is false.

Since both cases cover all possibilities and the non-empty case leads to a contradiction, we conclude that \( \text{maximum?}(xs) = \text{none} \) if and only if \( xs = [] \). This completes the proof.","theorem List.maximum?_eq_none_iff {xs : List α} [Max α] : xs.maximum? = none ↔ xs = [] := by
/- We consider the two possible cases for the list \( xs \): either \( xs \) is empty or \( xs \) is non-empty. For the empty case, we simplify the expression \( [].maximum? = \text{none} \) to show that it is trivially true. For the non-empty case, we simplify the expression \( (head :: tail).maximum? = \text{none} \) to show that it leads to a contradiction, thus proving the non-empty case is false. -/
  cases xs <;> simp [maximum?]","import Init.Data.List.Lemmas
import Init.Data.List.MinMax

open List
open Nat
"
5466,eq_true_eq_id,theorem eq_true_eq_id : Eq True = id := by sorry,"Equality of True is the Identity Function: \( \text{Eq}(\text{True}) = \text{id} \) : The equality relation on the proposition `True` is the same as the identity function, i.e., \( \text{Eq}(\text{True}) = \text{id} \).","theorem eq_true_eq_id : Eq True = id := by
  funext _; simp only [true_iff, id_def, eq_iff_iff]","We aim to show that the equality relation on the proposition `True` is the same as the identity function. To do this, we apply function extensionality to consider an arbitrary element. Then, we simplify using the fact that `True` is always true, the definition of the identity function, and the equivalence of equality and implication. This simplification directly shows that the equality relation on `True` is indeed the identity function.","theorem eq_true_eq_id : Eq True = id := by
/- To show that the equality relation on `True` is the identity function, we first apply function extensionality to consider an arbitrary element. Then, we simplify using the fact that `True` is always true, the definition of the identity function, and the equivalence of equality and implication. -/
  funext _; simp only [true_iff, id_def, eq_iff_iff]","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5477,or_right_comm,theorem or_right_comm : (a ∨ b) ∨ c ↔ (a ∨ c) ∨ b := by sorry,"Right Commutativity of Disjunction: \((a \lor b) \lor c \leftrightarrow (a \lor c) \lor b\) : For any propositions \( a \), \( b \), and \( c \), the disjunction \((a \lor b) \lor c\) is logically equivalent to the disjunction \((a \lor c) \lor b\), i.e., \((a \lor b) \lor c \leftrightarrow (a \lor c) \lor b\).","theorem or_right_comm : (a ∨ b) ∨ c ↔ (a ∨ c) ∨ b := by
  rw [or_assoc, or_assoc, @or_comm b]","We start by using the associativity of disjunction to rewrite \((a \lor b) \lor c\) as \(a \lor (b \lor c)\). Similarly, we use associativity again to rewrite \((a \lor c) \lor b\) as \(a \lor (c \lor b)\). Finally, we apply the commutativity of disjunction to swap \(b\) and \(c\) in \(a \lor (c \lor b)\), resulting in \(a \lor (b \lor c)\). Therefore, we have shown that \((a \lor b) \lor c \leftrightarrow (a \lor c) \lor b\). This completes the proof.","theorem or_right_comm : (a ∨ b) ∨ c ↔ (a ∨ c) ∨ b := by
  rw [or_assoc, or_assoc, @or_comm b]","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5479,or_rotate,theorem or_rotate : a ∨ b ∨ c ↔ b ∨ c ∨ a := by sorry,"Disjunction Rotation: \( a \lor b \lor c \leftrightarrow b \lor c \lor a \) : For any propositions \( a \), \( b \), and \( c \), the disjunction \( a \lor b \lor c \) is logically equivalent to \( b \lor c \lor a \), i.e., \( a \lor b \lor c \leftrightarrow b \lor c \lor a \).","theorem or_rotate : a ∨ b ∨ c ↔ b ∨ c ∨ a := by
  simp only [or_left_comm, Or.comm]","We start by applying the left commutativity of disjunction, which states that \( a \lor b \lor c \leftrightarrow b \lor a \lor c \). Next, we use the commutativity of disjunction, which states that \( a \lor b \leftrightarrow b \lor a \). Combining these, we can rearrange the terms to show that \( a \lor b \lor c \) is equivalent to \( b \lor c \lor a \). This completes the proof.","theorem or_rotate : a ∨ b ∨ c ↔ b ∨ c ∨ a := by
  simp only [or_left_comm, Or.comm]","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5480,and_and_and_comm,theorem and_and_and_comm : (a ∧ b) ∧ c ∧ d ↔ (a ∧ c) ∧ b ∧ d := by sorry,"Commutativity of Conjunction in Four Propositions: \((a \land b) \land c \land d \leftrightarrow (a \land c) \land b \land d\) : For any propositions \( a \), \( b \), \( c \), and \( d \), the conjunction \((a \land b) \land c \land d\) is logically equivalent to the conjunction \((a \land c) \land b \land d\), i.e., \((a \land b) \land c \land d \leftrightarrow (a \land c) \land b \land d\).","theorem and_and_and_comm : (a ∧ b) ∧ c ∧ d ↔ (a ∧ c) ∧ b ∧ d := by
  rw [← and_assoc, @and_right_comm a, and_assoc]","We begin by applying the associativity of conjunction, which states that \((a \land b) \land c \leftrightarrow a \land b \land c\). This allows us to rewrite the goal from \((a \land b) \land c \land d\) to \(((a \land b) \land c) \land d\). Next, we use the right commutativity of conjunction, which states that \((a \land b) \land c \leftrightarrow (a \land c) \land b\), to transform \(((a \land b) \land c) \land d\) into \(((a \land c) \land b) \land d\). Finally, we apply associativity once more to rewrite \(((a \land c) \land b) \land d\) as \((a \land c) \land b \land d\). This completes the proof, as the goal is now equivalent to the desired form.","theorem and_and_and_comm : (a ∧ b) ∧ c ∧ d ↔ (a ∧ c) ∧ b ∧ d := by
  rw [← and_assoc, @and_right_comm a, and_assoc]","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5482,or_or_distrib_left,theorem or_or_distrib_left : a ∨ b ∨ c ↔ (a ∨ b) ∨ a ∨ c := by sorry,"Distributivity of Disjunction on the Left: \( a \lor b \lor c \leftrightarrow (a \lor b) \lor a \lor c \) : For any propositions \( a \), \( b \), and \( c \), the disjunction \( a \lor b \lor c \) is logically equivalent to the disjunction \( (a \lor b) \lor a \lor c \), i.e., \( a \lor b \lor c \leftrightarrow (a \lor b) \lor a \lor c \).","theorem or_or_distrib_left : a ∨ b ∨ c ↔ (a ∨ b) ∨ a ∨ c := by
  rw [or_or_or_comm, or_self]","We start by using the commutativity of disjunction, which states that for any propositions \( a, b, c, \) and \( d \), the disjunction \((a \lor b) \lor c \lor d\) is logically equivalent to \((a \lor c) \lor b \lor d\). Applying this to our goal, we rewrite \( a \lor b \lor c \) as \( (a \lor a) \lor b \lor c \).

Next, we use the idempotence of disjunction, which states that for any proposition \( p \), the disjunction \( p \lor p \) is equal to \( p \). Applying this to our expression, we simplify \( (a \lor a) \lor b \lor c \) to \( a \lor b \lor c \).

Thus, we have shown that \( a \lor b \lor c \leftrightarrow a \lor b \lor c \), which completes the proof.","theorem or_or_distrib_left : a ∨ b ∨ c ↔ (a ∨ b) ∨ a ∨ c := by
  rw [or_or_or_comm, or_self]","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5483,proof_irrel_heq,theorem proof_irrel_heq {p q : Prop} (hp : p) (hq : q) : HEq hp hq := by sorry,"Proof Irrelevance in Heterogeneous Equality : For any propositions \( p \) and \( q \), and for any proofs \( hp \) of \( p \) and \( hq \) of \( q \), the proofs \( hp \) and \( hq \) are equal up to a type cast, i.e., \( \text{HEq}(hp, hq) \).","theorem proof_irrel_heq {p q : Prop} (hp : p) (hq : q) : HEq hp hq := by
  cases propext (iff_of_true hp hq); rfl","Given that both \( p \) and \( q \) are true, we can establish the equivalence \( p \iff q \). By the principle of proof irrelevance, any two proofs of the same proposition are equal. Since \( p \) and \( q \) are now equivalent, we can conclude that \( \text{HEq}(hp, hq) \) by reflexivity. This completes the proof.","theorem proof_irrel_heq {p q : Prop} (hp : p) (hq : q) : HEq hp hq := by
/- First, we use the fact that \( p \) and \( q \) are both true to establish that \( p \iff q \). This allows us to use the principle of proof irrelevance, which states that any two proofs of the same proposition are equal. Since \( p \) and \( q \) are now equivalent, we can conclude that \( \text{HEq}(hp, hq) \) by reflexivity. -/
  cases propext (iff_of_true hp hq); rfl","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5485,or_or_or_comm,theorem or_or_or_comm : (a ∨ b) ∨ c ∨ d ↔ (a ∨ c) ∨ b ∨ d := by sorry,"Commutativity of Disjunction: \((a \lor b) \lor c \lor d \leftrightarrow (a \lor c) \lor b \lor d\) : For any propositions \( a, b, c, \) and \( d \), the disjunction \((a \lor b) \lor c \lor d\) is logically equivalent to \((a \lor c) \lor b \lor d\).","theorem or_or_or_comm : (a ∨ b) ∨ c ∨ d ↔ (a ∨ c) ∨ b ∨ d := by
  rw [← or_assoc, @or_right_comm a, or_assoc]","We begin by applying the associativity of disjunction to the left-hand side of the goal. This allows us to rewrite \((a \lor b) \lor c \lor d\) as \(((a \lor b) \lor c) \lor d\). Next, we use the right commutativity of disjunction to rewrite \(((a \lor b) \lor c) \lor d\) as \(((a \lor c) \lor b) \lor d\). Finally, we apply associativity once more to rewrite \(((a \lor c) \lor b) \lor d\) as \((a \lor c) \lor b \lor d\). This sequence of rewrites demonstrates that \((a \lor b) \lor c \lor d\) is indeed logically equivalent to \((a \lor c) \lor b \lor d\).

Thus, we have shown that \((a \lor b) \lor c \lor d \leftrightarrow (a \lor c) \lor b \lor d\).","theorem or_or_or_comm : (a ∨ b) ∨ c ∨ d ↔ (a ∨ c) ∨ b ∨ d := by
  rw [← or_assoc, @or_right_comm a, or_assoc]","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5487,and_rotate,theorem and_rotate : a ∧ b ∧ c ↔ b ∧ c ∧ a := by sorry,"Commutativity of Conjunction: \( a \land b \land c \leftrightarrow b \land c \land a \) : For any propositions \( a \), \( b \), and \( c \), the conjunction \( a \land b \land c \) is logically equivalent to \( b \land c \land a \), i.e., \( a \land b \land c \leftrightarrow b \land c \land a \).","theorem and_rotate : a ∧ b ∧ c ↔ b ∧ c ∧ a := by
  rw [and_left_comm, @and_comm a c]","We begin by applying the left commutativity of conjunction, which states that \( a \land b \land c \) is equivalent to \( b \land a \land c \). This transforms our goal to \( b \land a \land c \leftrightarrow b \land c \land a \). Next, we use the commutativity of conjunction, which states that \( a \land c \) is equivalent to \( c \land a \). Applying this to the middle terms, we get \( b \land c \land a \leftrightarrow b \land c \land a \), which is trivially true. Thus, we have shown that \( a \land b \land c \) is logically equivalent to \( b \land c \land a \).","theorem and_rotate : a ∧ b ∧ c ↔ b ∧ c ∧ a := by
  rw [and_left_comm, @and_comm a c]","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5492,and_or_right,theorem and_or_right : (a ∧ b) ∨ c ↔ (a ∨ c) ∧ (b ∨ c) := by sorry,"Distributivity of Conjunction over Disjunction on the Right: \( (a \land b) \lor c \leftrightarrow (a \lor c) \land (b \lor c) \) : For any propositions \( a \), \( b \), and \( c \), the conjunction \( a \land b \) or the proposition \( c \) is logically equivalent to the conjunction of \( a \lor c \) and \( b \lor c \), i.e., \( (a \land b) \lor c \leftrightarrow (a \lor c) \land (b \lor c) \).","theorem and_or_right : (a ∧ b) ∨ c ↔ (a ∨ c) ∧ (b ∨ c) := by
  rw [@or_comm (a ∧ b), or_and_left, @or_comm c, @or_comm c]","We start by using the commutativity of disjunction to swap the positions of \( a \land b \) and \( c \), resulting in \( c \lor (a \land b) \). Applying the distributivity of disjunction over conjunction on the left, we obtain \( (c \lor a) \land (c \lor b) \). Using the commutativity of disjunction again, we swap \( c \) and \( a \) in the first term, yielding \( (a \lor c) \land (c \lor b) \). Finally, we use the commutativity of disjunction once more to swap \( c \) and \( b \) in the second term, resulting in \( (a \lor c) \land (b \lor c) \). This completes the proof, as the left-hand side is now identical to the right-hand side.","theorem and_or_right : (a ∧ b) ∨ c ↔ (a ∨ c) ∧ (b ∨ c) := by
  rw [@or_comm (a ∧ b), or_and_left, @or_comm c, @or_comm c]","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5493,or_and_right,theorem or_and_right : (a ∨ b) ∧ c ↔ (a ∧ c) ∨ (b ∧ c) := by sorry,"Distributivity of Conjunction over Disjunction on the Right: \((a \lor b) \land c \leftrightarrow (a \land c) \lor (b \land c)\) : For any propositions \( a \), \( b \), and \( c \), the conjunction of the disjunction \( a \lor b \) with \( c \) is logically equivalent to the disjunction of the conjunctions \( a \land c \) and \( b \land c \). In other words, \((a \lor b) \land c \leftrightarrow (a \land c) \lor (b \land c)\).","theorem or_and_right : (a ∨ b) ∧ c ↔ (a ∧ c) ∨ (b ∧ c) := by
  rw [@and_comm (a ∨ b), and_or_left, @and_comm c, @and_comm c]","We start by using the commutativity of conjunction to rewrite \((a \lor b) \land c\) as \(c \land (a \lor b)\). Next, we apply the distributivity of conjunction over disjunction to \(c \land (a \lor b)\), which results in \(c \land a \lor c \land b\). Then, we use the commutativity of conjunction to swap \(c\) and \(a\) in \(c \land a\), obtaining \(a \land c \lor c \land b\). Finally, we use the commutativity of conjunction again to swap \(c\) and \(b\) in \(c \land b\), resulting in \(a \land c \lor b \land c\). This completes the proof, as the goal is now trivially true by reflexivity.

Thus, we have shown that \((a \lor b) \land c \leftrightarrow (a \land c) \lor (b \land c)\).","theorem or_and_right : (a ∨ b) ∧ c ↔ (a ∧ c) ∨ (b ∧ c) := by
  rw [@and_comm (a ∨ b), and_or_left, @and_comm c, @and_comm c]","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5497,if_false_left,"theorem if_false_left [h : Decidable p] :
    ite p False q ↔ ¬p ∧ q := by sorry","If-then-else with False on the Left: \((\text{if } p \text{ then } \text{False} \text{ else } q) \leftrightarrow \neg p \land q\) : For any propositions \( p \) and \( q \), if \( p \) is decidable, then the if-then-else expression \((\text{if } p \text{ then } \text{False} \text{ else } q)\) is logically equivalent to \(\neg p \land q\).","theorem if_false_left [h : Decidable p] :
    ite p False q ↔ ¬p ∧ q := by
  cases h <;> (rename_i g; simp [g])","We consider the two possible cases for the decidable proposition \( p \):

1. **Case 1: \( p \) is false.**
In this case, the expression \((\text{if } p \text{ then } \text{False} \text{ else } q)\) simplifies to \( q \). Since \( p \) is false, \(\neg p\) is true, and thus \(\neg p \land q\) simplifies to \( q \). Therefore, in this case, the expression \((\text{if } p \text{ then } \text{False} \text{ else } q)\) is equivalent to \(\neg p \land q\).

2. **Case 2: \( p \) is true.**
In this case, the expression \((\text{if } p \text{ then } \text{False} \text{ else } q)\) simplifies to \(\text{False}\). Since \( p \) is true, \(\neg p\) is false, and thus \(\neg p \land q\) is also false. Therefore, in this case, the expression \((\text{if } p \text{ then } \text{False} \text{ else } q)\) is equivalent to \(\neg p \land q\).

Since both cases show that the expression \((\text{if } p \text{ then } \text{False} \text{ else } q)\) is equivalent to \(\neg p \land q\), we conclude that the theorem holds.","theorem if_false_left [h : Decidable p] :
    ite p False q ↔ ¬p ∧ q := by
  cases h <;> (rename_i g; simp [g])","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5498,and_and_left,theorem and_and_left : a ∧ (b ∧ c) ↔ (a ∧ b) ∧ a ∧ c := by sorry,"Left Conjunction Commutativity: \( a \land b \land c \leftrightarrow (a \land b) \land a \land c \) : For any propositions \( a \), \( b \), and \( c \), the conjunction \( a \land b \land c \) is logically equivalent to \( (a \land b) \land a \land c \), i.e., \( a \land b \land c \leftrightarrow (a \land b) \land a \land c \).","theorem and_and_left : a ∧ (b ∧ c) ↔ (a ∧ b) ∧ a ∧ c := by
  rw [and_and_and_comm, and_self]","We start by using the commutativity of conjunction in four propositions, which states that \((a \land b) \land c \land d \leftrightarrow (a \land c) \land b \land d\). Applying this to our goal, we rewrite \(a \land b \land c \leftrightarrow (a \land b) \land a \land c\) as \(a \land b \land c \leftrightarrow (a \land a) \land b \land c\). Next, we use the idempotence of conjunction, which states that \(p \land p = p\). Applying this to \((a \land a) \land b \land c\), we simplify it to \(a \land b \land c\). Thus, our goal simplifies to \(a \land b \land c \leftrightarrow a \land b \land c\), which is trivially true. This completes the proof.","theorem and_and_left : a ∧ (b ∧ c) ↔ (a ∧ b) ∧ a ∧ c := by
  rw [and_and_and_comm, and_self]","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5500,or_or_distrib_right,theorem or_or_distrib_right : (a ∨ b) ∨ c ↔ (a ∨ c) ∨ b ∨ c := by sorry,"Distributivity of Disjunction on the Right: \((a \lor b) \lor c \leftrightarrow (a \lor c) \lor (b \lor c)\) : For any propositions \( a \), \( b \), and \( c \), the disjunction \((a \lor b) \lor c\) is logically equivalent to the disjunction \((a \lor c) \lor (b \lor c)\), i.e., \((a \lor b) \lor c \leftrightarrow (a \lor c) \lor (b \lor c)\).","theorem or_or_distrib_right : (a ∨ b) ∨ c ↔ (a ∨ c) ∨ b ∨ c := by
  rw [or_or_or_comm, or_self]","We start by using the commutativity of disjunction, which states that \((a \lor b) \lor c \lor d \leftrightarrow (a \lor c) \lor b \lor d\). Applying this to our goal, we rewrite \((a \lor b) \lor c\) as \((a \lor b) \lor c \lor c\). Next, we use the idempotence of disjunction, which states that \( p \lor p = p \). Applying this, we simplify \((a \lor b) \lor c \lor c\) to \((a \lor b) \lor c\). This is equivalent to the original goal, thus completing the proof.","theorem or_or_distrib_right : (a ∨ b) ∨ c ↔ (a ∨ c) ∨ b ∨ c := by
  rw [or_or_or_comm, or_self]","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5505,if_true_left,"theorem if_true_left [h : Decidable p] :
    ite p True q ↔ ¬p → q := by sorry","If-Then-Else Identity: \((\text{if } p \text{ then } \text{True} \text{ else } q) \leftrightarrow \neg p \to q\) : For any propositions \( p \) and \( q \), the if-then-else expression \((\text{if } p \text{ then } \text{True} \text{ else } q)\) is logically equivalent to \(\neg p \to q\). In other words, if \( p \) is false, then the expression evaluates to \( q \); otherwise, it evaluates to \(\text{True}\).","theorem if_true_left [h : Decidable p] :
    ite p True q ↔ ¬p → q := by
  cases h <;> (rename_i g; simp [g])","We start by considering the two possible cases for the decidability of \( p \):

1. **Case 1: \( p \) is false.**
- In this case, the expression \((\text{if } p \text{ then } \text{True} \text{ else } q)\) simplifies to \( q \).
- Since \( p \) is false, \(\neg p\) is true, and thus \(\neg p \to q\) simplifies to \( q \).
- Therefore, in this case, the expression \((\text{if } p \text{ then } \text{True} \text{ else } q)\) is equivalent to \(\neg p \to q\).

2. **Case 2: \( p \) is true.**
- In this case, the expression \((\text{if } p \text{ then } \text{True} \text{ else } q)\) simplifies to \(\text{True}\).
- Since \( p \) is true, \(\neg p\) is false, and thus \(\neg p \to q\) simplifies to \(\text{True}\).
- Therefore, in this case, the expression \((\text{if } p \text{ then } \text{True} \text{ else } q)\) is equivalent to \(\neg p \to q\).

Since both cases show that the expression \((\text{if } p \text{ then } \text{True} \text{ else } q)\) is equivalent to \(\neg p \to q\), we conclude that the theorem holds for any propositions \( p \) and \( q \).","theorem if_true_left [h : Decidable p] :
    ite p True q ↔ ¬p → q := by
  cases h <;> (rename_i g; simp [g])","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5508,if_true_right,"theorem if_true_right [h : Decidable p] :
    ite p q True ↔ p → q := by sorry","If-then-else with True on the Right: \((\text{if } p \text{ then } q \text{ else } \text{True}) \leftrightarrow (p \rightarrow q)\) : For any propositions \( p \) and \( q \), if \( p \) is true, then the expression \((\text{if } p \text{ then } q \text{ else } \text{True})\) is logically equivalent to \( p \rightarrow q \). In other words, \((\text{if } p \text{ then } q \text{ else } \text{True})\) holds if and only if \( p \) implies \( q \).","theorem if_true_right [h : Decidable p] :
    ite p q True ↔ p → q := by
  cases h <;> (rename_i g; simp [g])","We start by considering the two possible cases for the decidability of \( p \):

1. **Case 1: \( p \) is false.**
In this case, the expression \((\text{if } p \text{ then } q \text{ else } \text{True})\) simplifies to \(\text{True}\). Since \( p \) is false, \( p \rightarrow q \) is also \(\text{True}\). Thus, the equivalence holds.

2. **Case 2: \( p \) is true.**
In this case, the expression \((\text{if } p \text{ then } q \text{ else } \text{True})\) simplifies to \( q \). Since \( p \) is true, \( p \rightarrow q \) is equivalent to \( q \). Thus, the equivalence holds.

Since both cases establish the equivalence, we conclude that \((\text{if } p \text{ then } q \text{ else } \text{True}) \leftrightarrow (p \rightarrow q)\) holds for any propositions \( p \) and \( q \).","theorem if_true_right [h : Decidable p] :
    ite p q True ↔ p → q := by
  cases h <;> (rename_i g; simp [g])","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5511,ite_true_same,theorem ite_true_same (p q : Prop) [h : Decidable p] : (if p then p else q) = (¬p → q) := by sorry,"If-Then-Else Identity: $(\text{if } p \text{ then } p \text{ else } q) = (\neg p \to q)$ : For any propositions $p$ and $q$, the if-then-else expression `if p then p else q` is equal to the proposition $\neg p \to q$. In other words, if $p$ is true, the expression evaluates to $p$, and if $p$ is false, the expression evaluates to $q$.","theorem ite_true_same (p q : Prop) [h : Decidable p] : (if p then p else q) = (¬p → q) := by
  cases h <;> (rename_i g; simp [g])","We consider the two possible cases for the decidability of $p$: either $p$ is true or $p$ is false. In each case, we rename the decidability instance to $g$ and simplify the expression using $g$.

1. **Case 1: $p$ is true.**
- In this case, the if-then-else expression simplifies to $p$.
- The proposition $\neg p \to q$ simplifies to $\text{True} \to q$, which is equivalent to $q$.
- Since $p$ is true, the expression evaluates to $p$, and the proposition $\neg p \to q$ evaluates to $q$.
- Therefore, the if-then-else expression is equal to the proposition $\neg p \to q$.

2. **Case 2: $p$ is false.**
- In this case, the if-then-else expression simplifies to $q$.
- The proposition $\neg p \to q$ simplifies to $\text{False} \to q$, which is equivalent to $\text{True}$.
- Since $p$ is false, the expression evaluates to $q$, and the proposition $\neg p \to q$ evaluates to $\text{True}$.
- Therefore, the if-then-else expression is equal to the proposition $\neg p \to q$.

In both cases, the if-then-else expression is equal to the proposition $\neg p \to q$. Hence, we have shown that $(\text{if } p \text{ then } p \text{ else } q) = (\neg p \to q)$.","theorem ite_true_same (p q : Prop) [h : Decidable p] : (if p then p else q) = (¬p → q) := by
/- We consider the two possible cases for the decidability of $p$: either $p$ is true or $p$ is false. In each case, we rename the decidability instance to $g$ and simplify the expression using $g$. -/
/- Since $n$ is empty, this $M i = 1 i$ holds for every $i \in n$ vacuously. This finishes the proof. -/
  cases h <;> (rename_i g; simp [g])","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5534,ite_false_same,theorem ite_false_same (p q : Prop) [h : Decidable p] : (if p then q else p) = (p ∧ q) := by sorry,"If-then-else Identity: \( \text{if } p \text{ then } q \text{ else } p = p \land q \) : For any propositions \( p \) and \( q \), if \( p \) is false, then the expression \( \text{if } p \text{ then } q \text{ else } p \) is equal to \( p \land q \). Formally, this is expressed as:
\[
\forall (p, q : \text{Prop}), \text{if } p \text{ then } q \text{ else } p = p \land q
\]","theorem ite_false_same (p q : Prop) [h : Decidable p] : (if p then q else p) = (p ∧ q) := by
  cases h <;> (rename_i g; simp [g])","We start by considering the two possible cases for the decidability of \( p \): \( p \) is true or \( p \) is false.

1. **Case 1: \( p \) is false.**
- In this case, the expression \( \text{if } p \text{ then } q \text{ else } p \) simplifies to \( p \).
- Since \( p \) is false, \( p \land q \) is also false.
- Therefore, \( p = p \land q \) holds trivially.

2. **Case 2: \( p \) is true.**
- In this case, the expression \( \text{if } p \text{ then } q \text{ else } p \) simplifies to \( q \).
- Since \( p \) is true, \( p \land q \) simplifies to \( q \).
- Therefore, \( q = p \land q \) holds trivially.

In both cases, the expression \( \text{if } p \text{ then } q \text{ else } p \) is equal to \( p \land q \). This completes the proof.","theorem ite_false_same (p q : Prop) [h : Decidable p] : (if p then q else p) = (p ∧ q) := by
/- We consider the two possible cases for the decidability of \( p \): \( p \) is true or \( p \) is false. In each case, we simplify the expression \( \text{if } p \text{ then } q \text{ else } p \) using the corresponding truth value of \( p \). -/
  cases h <;> (rename_i g; simp [g])","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
5539,if_false_right,"theorem if_false_right [h : Decidable p] :
    ite p q False ↔ p ∧ q := by sorry","If-then-else with False on the Right: \( \text{if } p \text{ then } q \text{ else } \text{False} \leftrightarrow p \land q \) : For any propositions \( p \) and \( q \), if \( p \) is false, then the if-then-else expression \( \text{if } p \text{ then } q \text{ else } \text{False} \) is equivalent to the conjunction \( p \land q \). Formally, this can be written as:
\[
\text{if } p \text{ then } q \text{ else } \text{False} \leftrightarrow p \land q
\]","theorem if_false_right [h : Decidable p] :
    ite p q False ↔ p ∧ q := by
  cases h <;> (rename_i g; simp [g])","We consider the two cases for the decidability of \( p \):

1. **Case 1: \( p \) is false.**
In this case, the expression \( \text{if } p \text{ then } q \text{ else } \text{False} \) simplifies to \( \text{False} \). Since \( p \) is false, the conjunction \( p \land q \) is also false. Therefore, the equivalence \( \text{if } p \text{ then } q \text{ else } \text{False} \leftrightarrow p \land q \) holds trivially.

2. **Case 2: \( p \) is true.**
In this case, the expression \( \text{if } p \text{ then } q \text{ else } \text{False} \) simplifies to \( q \). Since \( p \) is true, the conjunction \( p \land q \) simplifies to \( q \). Therefore, the equivalence \( \text{if } p \text{ then } q \text{ else } \text{False} \leftrightarrow p \land q \) holds.

Thus, in both cases, the equivalence \( \text{if } p \text{ then } q \text{ else } \text{False} \leftrightarrow p \land q \) holds, completing the proof.","theorem if_false_right [h : Decidable p] :
    ite p q False ↔ p ∧ q := by
  cases h <;> (rename_i g; simp [g])","import Init.Core
import Init.NotationExtra
import Init.PropLemmas



"
6881,List.length_eq_lengthTR,theorem List.length_eq_lengthTR : @List.length = @List.lengthTR := by sorry,"Equality of List Length Functions: \(\text{length} = \text{lengthTR}\) : For any list `as` of elements of type `α`, the length of the list computed by the standard `List.length` function is equal to the length of the list computed by the tail-recursive `List.lengthTR` function, i.e., \(\text{length}(as) = \text{lengthTR}(as)\).","theorem List.length_eq_lengthTR : @List.length = @List.lengthTR := by
  apply funext; intro α; apply funext; intro as
  simp [lengthTR, ← length_add_eq_lengthTRAux]","To prove that the standard `List.length` function is equal to the tail-recursive `List.lengthTR` function, we use function extensionality. This means we need to show that for any type `α` and any list `as` of elements of type `α`, the length of `as` computed by `List.length` is equal to the length of `as` computed by `List.lengthTR`.

1. Let `α` be an arbitrary type and `as` be an arbitrary list of elements of type `α`.
2. We need to show that `as.length = as.lengthTR`.
3. Using the definition of `List.lengthTR`, which is given by the tail-recursive auxiliary function `List.lengthTRAux`, and the lemma `length_add_eq_lengthTRAux`, which states that the length of a list computed by `List.length` is equal to the length computed by `List.lengthTRAux` with an initial value of `0`, we can simplify the expression `as.length = as.lengthTR`.
4. Therefore, the equality `as.length = as.lengthTR` holds.

This completes the proof. \(\blacksquare\)","theorem List.length_eq_lengthTR : @List.length = @List.lengthTR := by
/- To prove that the standard `List.length` function is equal to the tail-recursive `List.lengthTR` function, we use function extensionality. This means we need to show that for any type `α` and any list `as` of elements of type `α`, the length of `as` computed by `List.length` is equal to the length of `as` computed by `List.lengthTR`. Let `α` be an arbitrary type and `as` be an arbitrary list of elements of type `α`. We need to show that `as.length = as.lengthTR`. -/
  apply funext; intro α; apply funext; intro as
/- Using the definitions of `List.lengthTR` and the lemma `length_add_eq_lengthTRAux`, we can simplify the expression `as.length = as.lengthTR`. The definition of `List.lengthTR` is given by the tail-recursive auxiliary function `List.lengthTRAux`, and the lemma `length_add_eq_lengthTRAux` states that the length of a list computed by `List.length` is equal to the length computed by `List.lengthTRAux` with an initial value of `0`. Therefore, the equality `as.length = as.lengthTR` holds. -/
  simp [lengthTR, ← length_add_eq_lengthTRAux]","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
6885,List.dropLast_eq_dropLastTR,theorem List.dropLast_eq_dropLastTR : @dropLast = @dropLastTR := by sorry,"Equality of `List.dropLast` and `List.dropLastTR` Functions : For any list \( l \) of elements of type \( \alpha \), the function `List.dropLast` applied to \( l \) returns the same result as the function `List.dropLastTR` applied to \( l \). In other words, `List.dropLast l = List.dropLastTR l`.","theorem List.dropLast_eq_dropLastTR : @dropLast = @dropLastTR := by
  funext α l; simp [dropLastTR]","To prove that the function `List.dropLast` is equal to the function `List.dropLastTR` for any list \( l \) of elements of type \( \alpha \), we use the function extensionality principle. This principle states that two functions are equal if they yield the same result for all inputs. Therefore, we need to show that for any list \( l \) of type \( \alpha \), `List.dropLast l` is equal to `List.dropLastTR l`.

We simplify the expression using the definition of `List.dropLastTR`. By the definition of `List.dropLastTR`, it is designed to be a tail-recursive version of `List.dropLast`. Since both functions are designed to remove the last element of the list, they must yield the same result for any input list \( l \).

Thus, for any list \( l \) of type \( \alpha \), we have:
\[ \text{List.dropLast } l = \text{List.dropLastTR } l \]

This completes the proof.","theorem List.dropLast_eq_dropLastTR : @dropLast = @dropLastTR := by
/- To prove that the function `List.dropLast` is equal to the function `List.dropLastTR` for any list \( l \) of elements of type \( \alpha \), we first use the function extensionality principle. This principle states that two functions are equal if they yield the same result for all inputs. Therefore, we need to show that for any list \( l \) of type \( \alpha \), `List.dropLast l` is equal to `List.dropLastTR l`. We then simplify the expression using the definition of `List.dropLastTR`. -/
  funext α l; simp [dropLastTR]","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
6890,List.filter_eq_filterTR,theorem List.filter_eq_filterTR : @filter = @filterTR := by sorry,"Equality of List Filter and Tail-Recursive List Filter: $\text{List.filter} = \text{List.filterTR}$ : For any type $\alpha$ and any predicate $p : \alpha \to \text{Bool}$, the list filter function `List.filter` and the tail-recursive list filter function `List.filterTR` are equal, i.e., `List.filter p l = List.filterTR p l` for any list $l : \text{List} \, \alpha$.","theorem List.filter_eq_filterTR : @filter = @filterTR := by
  apply funext; intro α; apply funext; intro p; apply funext; intro as
  simp [filterTR, filterTR_loop_eq]","To prove that the list filter function `List.filter` and the tail-recursive list filter function `List.filterTR` are equal, we use function extensionality. This means we need to show that for any type \(\alpha\), any predicate \(p : \alpha \to \text{Bool}\), and any list \(as : \text{List} \, \alpha\), the functions `List.filter p` and `List.filterTR p` applied to \(as\) are equal. Therefore, it suffices to show that for any \(\alpha\), \(p\), and \(as\), `List.filter p as = List.filterTR p as`.

Using the definitions of `List.filterTR` and the lemma `List.filterTR_loop_eq`, we can simplify the goal. The lemma `List.filterTR_loop_eq` states that the tail-recursive filter loop function `List.filterTR.loop` applied to \(p\), \(as\), and an empty list \([]\) is equal to the reverse of the empty list concatenated with the list of elements from \(as\) that satisfy the predicate \(p\). This simplifies to `List.filter p as`. Therefore, the goal `List.filter p as = List.filterTR p as` is trivially true.

This completes the proof. \(\blacksquare\)","theorem List.filter_eq_filterTR : @filter = @filterTR := by
/- To prove that the list filter function `List.filter` and the tail-recursive list filter function `List.filterTR` are equal, we use function extensionality. This means we need to show that for any type \(\alpha\), any predicate \(p : \alpha \to \text{Bool}\), and any list \(as : \text{List} \, \alpha\), the functions `List.filter p` and `List.filterTR p` applied to \(as\) are equal. Therefore, it suffices to show that for any \(\alpha\), \(p\), and \(as\), `List.filter p as = List.filterTR p as`. -/
  apply funext; intro α; apply funext; intro p; apply funext; intro as
/- Using the definitions of `List.filterTR` and the lemma `List.filterTR_loop_eq`, we can simplify the goal. The lemma `List.filterTR_loop_eq` states that the tail-recursive filter loop function `List.filterTR.loop` applied to \(p\), \(as\), and an empty list \([]\) is equal to the reverse of the empty list concatenated with the list of elements from \(as\) that satisfy the predicate \(p\). This simplifies to `List.filter p as`. Therefore, the goal `List.filter p as = List.filterTR p as` is trivially true. -/
  simp [filterTR, filterTR_loop_eq]","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
6892,List.leftpad_eq_leftpadTR,theorem List.leftpad_eq_leftpadTR : @leftpad = @leftpadTR := by sorry,"Equality of Left Padding Functions: \(\text{List.leftpad} = \text{List.leftpadTR}\) : For any type \( \alpha \), natural number \( n \), element \( a \) of type \( \alpha \), and list \( l \) of elements of type \( \alpha \), the function `List.leftpad` and the optimized function `List.leftpadTR` produce the same result. Formally, this is expressed as:
\[
\text{List.leftpad}(n, a, l) = \text{List.leftpadTR}(n, a, l)
\]","theorem List.leftpad_eq_leftpadTR : @leftpad = @leftpadTR := by
  funext α n a l; simp [leftpad, leftpadTR, replicateTR_loop_eq]","To prove that the function `List.leftpad` is equal to the optimized function `List.leftpadTR`, we need to show that for any type \( \alpha \), natural number \( n \), element \( a \) of type \( \alpha \), and list \( l \) of elements of type \( \alpha \), the results of `List.leftpad(n, a, l)` and `List.leftpadTR(n, a, l)` are the same.

1. **Introduce Variables:**
We use the extensionality principle to introduce the variables \( \alpha \), \( n \), \( a \), and \( l \). This means we need to show that for all such variables, the functions produce the same result.

2. **Simplify Expressions:**
We simplify the expressions using the definitions of `leftpad`, `leftpadTR`, and the equivalence `replicateTR_loop_eq`. The function `leftpad` pads a list \( l \) with the element \( a \) to make its length at least \( n \). The function `leftpadTR` is an optimized version of `leftpad` that uses a tail-recursive loop.

3. **Use Equivalence:**
The equivalence `replicateTR_loop_eq` ensures that the tail-recursive loop used in `leftpadTR` produces the same result as the non-tail-recursive version used in `leftpad`.

4. **Conclusion:**
Since the definitions and the equivalence `replicateTR_loop_eq` guarantee that the results of `leftpad` and `leftpadTR` are the same for any \( \alpha \), \( n \), \( a \), and \( l \), we conclude that:
\[
\text{List.leftpad}(n, a, l) = \text{List.leftpadTR}(n, a, l)
\]
This completes the proof.","theorem List.leftpad_eq_leftpadTR : @leftpad = @leftpadTR := by
/- To prove that the function `List.leftpad` is equal to the optimized function `List.leftpadTR`, we need to show that for any type \( \alpha \), natural number \( n \), element \( a \) of type \( \alpha \), and list \( l \) of elements of type \( \alpha \), the results of `List.leftpad(n, a, l)` and `List.leftpadTR(n, a, l)` are the same. We use the extensionality principle to introduce these variables and then simplify the expressions using the definitions of `leftpad`, `leftpadTR`, and the equivalence `replicateTR_loop_eq`. -/
  funext α n a l; simp [leftpad, leftpadTR, replicateTR_loop_eq]","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
6940,List.length_add_eq_lengthTRAux,theorem List.length_add_eq_lengthTRAux (as : List α) (n : Nat) : as.length + n = as.lengthTRAux n := by sorry,"Length of List Plus Natural Number Equals Auxiliary Length Function Result : For any list \( as \) of elements of type \( \alpha \) and any natural number \( n \), the length of the list \( as \) plus \( n \) is equal to the result of the auxiliary length function `List.lengthTRAux` applied to the list \( as \) and the natural number \( n \). In other words, \( \text{length}(as) + n = \text{lengthTRAux}(as, n) \).","theorem List.length_add_eq_lengthTRAux (as : List α) (n : Nat) : as.length + n = as.lengthTRAux n := by
  induction as generalizing n with
  | nil  => simp [length, lengthTRAux]
  | cons a as ih =>
    simp [length, lengthTRAux, ← ih, Nat.succ_add]
    rfl","We prove this by induction on the list \( \text{as} \).

1. **Base Case:**
- Consider the case where the list \( \text{as} \) is empty, i.e., \( \text{as} = [] \).
- Using the definitions of the length of a list and the auxiliary length function, we have:
\[
\text{length}([]) + n = 0 + n = n
\]
and
\[
\text{lengthTRAux}([], n) = n
\]
- Therefore, \( \text{length}([]) + n = \text{lengthTRAux}([], n) \).

2. **Inductive Step:**
- Assume the induction hypothesis: for any natural number \( n \), \( \text{length}(\text{as}) + n = \text{lengthTRAux}(\text{as}, n) \).
- Consider the case where the list \( \text{as} \) is non-empty, i.e., \( \text{as} = a :: \text{as} \).
- Using the definitions of the length of a list and the auxiliary length function, we have:
\[
\text{length}(a :: \text{as}) = \text{length}(\text{as}) + 1
\]
and
\[
\text{lengthTRAux}(a :: \text{as}, n) = \text{lengthTRAux}(\text{as}, n + 1)
\]
- By the induction hypothesis, we know:
\[
\text{length}(\text{as}) + (n + 1) = \text{lengthTRAux}(\text{as}, n + 1)
\]
- Therefore, we need to show:
\[
\text{length}(a :: \text{as}) + n = \text{lengthTRAux}(a :: \text{as}, n)
\]
which simplifies to:
\[
(\text{length}(\text{as}) + 1) + n = \text{lengthTRAux}(\text{as}, n + 1)
\]
Using the property of successor addition, we have:
\[
\text{length}(\text{as}) + (n + 1) = \text{lengthTRAux}(\text{as}, n + 1)
\]
which is true by the induction hypothesis.

Thus, by induction, the theorem holds for all lists \( \text{as} \) and natural numbers \( n \). This completes the proof. \(\blacksquare\)","theorem List.length_add_eq_lengthTRAux (as : List α) (n : Nat) : as.length + n = as.lengthTRAux n := by
  induction as generalizing n with
/- Consider the case where the list \( \text{as} \) is empty. Using the definitions of the length of a list and the auxiliary length function, we can simplify the proposition we want to show to \( 0 + n = n \), which is trivially true. -/
  | nil  => simp [length, lengthTRAux]
/- Perform induction on the list \( \text{as} \) and consider the case where the list is non-empty, i.e., \( \text{as} = a :: \text{as} \). We have the induction hypothesis \( \text{ih} \) that for any natural number \( n \), \( \text{as.length} + n = \text{as.lengthTRAux} n \). -/
  | cons a as ih =>
/- Using the definitions of the length of a list and the auxiliary length function, along with the induction hypothesis and the property of successor addition, we can simplify the proposition we want to show to \( \text{as.length} + n + 1 = \text{as.length} + (n + 1) \). -/
    simp [length, lengthTRAux, ← ih, Nat.succ_add]
/- The current goal is trivially true due to the reflexive property. Specifically, the equality \( \text{as.length} + n + 1 = \text{as.length} + (n + 1) \) holds since both sides are definitionally equal. -/
/- The current goal is trivially true due to the reflexive property. Specifically, the equality \( \text{as.length} + n + 1 = \text{as.length} + (n + 1) \) holds since both sides are definitionally equal. -/
    rfl","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
6947,List.mapTR_loop_eq,"theorem List.mapTR_loop_eq (f : α → β) (as : List α) (bs : List β) :
    mapTR.loop f as bs = bs.reverse ++ map f as := by sorry","Tail-recursive Map Loop Equals Reverse Concatenation of Mapped List : For any types \( \alpha \) and \( \beta \), and for any function \( f : \alpha \to \beta \), list \( \text{as} : \text{List} \, \alpha \), and list \( \text{bs} : \text{List} \, \beta \), the result of the tail-recursive map loop `List.mapTR.loop f as bs` is equal to the concatenation of the reverse of `bs` and the result of applying `f` to each element of `as`, i.e., \(\text{List.mapTR.loop} \, f \, \text{as} \, \text{bs} = \text{bs.reverse} \, ++ \, \text{List.map} \, f \, \text{as}\).","theorem List.mapTR_loop_eq (f : α → β) (as : List α) (bs : List β) :
    mapTR.loop f as bs = bs.reverse ++ map f as := by
  induction as generalizing bs with
  | nil => simp [mapTR.loop, map]
  | cons a as ih =>
    simp only [mapTR.loop, map]
    rw [ih (f a :: bs), reverse_cons, append_assoc]
    rfl","We prove this by induction on the list `as`.

**Base Case:**
For the base case where `as` is the empty list, we need to show that:
\[
\text{List.mapTR.loop} \, f \, [] \, \text{bs} = \text{bs.reverse} \, ++ \, \text{List.map} \, f \, []
\]
Using the definitions of `List.mapTR.loop` and `List.map`, we have:
\[
\text{List.mapTR.loop} \, f \, [] \, \text{bs} = \text{bs}
\]
and
\[
\text{List.map} \, f \, [] = []
\]
Thus, the right-hand side becomes:
\[
\text{bs.reverse} \, ++ \, [] = \text{bs.reverse}
\]
Since both sides are equal, the base case holds.

**Inductive Step:**
Assume the inductive hypothesis that for any list `bs`, \(\text{List.mapTR.loop} \, f \, \text{as} \, \text{bs} = \text{bs.reverse} \, ++ \, \text{List.map} \, f \, \text{as}\). We need to show that:
\[
\text{List.mapTR.loop} \, f \, (a :: \text{as}) \, \text{bs} = \text{bs.reverse} \, ++ \, \text{List.map} \, f \, (a :: \text{as})
\]
Using the definition of `List.mapTR.loop`, we have:
\[
\text{List.mapTR.loop} \, f \, (a :: \text{as}) \, \text{bs} = \text{List.mapTR.loop} \, f \, \text{as} \, (f \, a :: \text{bs})
\]
By the inductive hypothesis, this is:
\[
(f \, a :: \text{bs}).\text{reverse} \, ++ \, \text{List.map} \, f \, \text{as}
\]
Using the property of the reverse of a cons list, \((a :: \text{as}).\text{reverse} = \text{as.reverse} \, ++ \, [a]\), we get:
\[
\text{bs.reverse} \, ++ \, [f \, a] \, ++ \, \text{List.map} \, f \, \text{as}
\]
By the associativity of list append, this is:
\[
\text{bs.reverse} \, ++ \, (f \, a :: \text{List.map} \, f \, \text{as})
\]
Thus, the inductive step holds.

By induction, the theorem is proved. \(\blacksquare\)","theorem List.mapTR_loop_eq (f : α → β) (as : List α) (bs : List β) :
    mapTR.loop f as bs = bs.reverse ++ map f as := by
  induction as generalizing bs with
/- For the base case where the list `as` is empty, we simplify the goal using the definitions of `List.mapTR.loop` and `List.map`. This simplification shows that `List.mapTR.loop f [] bs` is equal to `bs.reverse ++ map f []`, which is `bs.reverse ++ []`, and thus `bs.reverse`. -/
  | nil => simp [mapTR.loop, map]
/- For the inductive step, we assume the inductive hypothesis that for any list `bs`, `List.mapTR.loop f as bs = bs.reverse ++ map f as`. We need to show that `List.mapTR.loop f (a :: as) bs = bs.reverse ++ map f (a :: as)`. -/
  | cons a as ih =>
/- Using the definitions of `List.mapTR.loop` and `List.map`, we simplify the goal to show that `List.mapTR.loop f as (f a :: bs) = bs.reverse ++ f a :: map f as`. -/
    simp only [mapTR.loop, map]
/- We use the inductive hypothesis `ih (f a :: bs)` to replace `List.mapTR.loop f as (f a :: bs)` with `(f a :: bs).reverse ++ map f as`. Then, we use the property of the reverse of a cons list, \((a :: as).reverse = as.reverse \, ++ \, [a]\), to replace `(f a :: bs).reverse` with `bs.reverse ++ [f a]`. Finally, we use the associativity of list append to rewrite the goal as `bs.reverse ++ ([f a] ++ map f as) = bs.reverse ++ f a :: map f as`. -/
    rw [ih (f a :: bs), reverse_cons, append_assoc]
/- The current goal is trivially true due to the reflexive property. Since both sides of the equality are definitionally equal, the goal is satisfied. -/
/- The current goal is trivially true due to the reflexive property. Since both sides of the equality are definitionally equal, the goal is satisfied. -/
    rfl","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
6980,List.unzip_eq_unzipTR,theorem List.unzip_eq_unzipTR : @unzip = @unzipTR := by sorry,"Equality of `unzip` and `unzipTR` Functions for Lists of Pairs : For any list of pairs `l : List (α × β)`, the function `unzip` that separates the list into two lists, one containing the first components and the other containing the second components, is equal to the tail-recursive function `unzipTR` that performs the same operation. Formally, for a list of pairs \([(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)]\), both `unzip l` and `unzipTR l` return the pair of lists \([x_1, x_2, \ldots, x_n]\) and \([y_1, y_2, \ldots, y_n]\).","theorem List.unzip_eq_unzipTR : @unzip = @unzipTR := by
  funext α β l; simp [unzipTR]; induction l <;> simp [*]","To prove that the function `unzip` is equal to the function `unzipTR` for any list of pairs, we use function extensionality. This means we need to show that for any types `α` and `β` and any list `l` of pairs of type `α × β`, the result of `unzip l` is equal to the result of `unzipTR l`.

1. **Base Case:**
- Consider the empty list `[]`.
- By the definition of `unzip`, `unzip []` returns the pair of empty lists `([], [])`.
- By the definition of `unzipTR`, `unzipTR []` also returns the pair of empty lists `([], [])`.
- Therefore, `unzip [] = unzipTR []`.

2. **Inductive Step:**
- Assume that for a list `l` of pairs, `unzip l = unzipTR l`.
- Consider a non-empty list `l' = (x, y) :: l`, where `(x, y)` is a pair and `l` is a list of pairs.
- By the definition of `unzip`, `unzip ((x, y) :: l)` returns the pair of lists `([x] ++ (fst (unzip l)), [y] ++ (snd (unzip l)))`.
- By the definition of `unzipTR`, `unzipTR ((x, y) :: l)` returns the pair of lists `([x] ++ (fst (unzipTR l)), [y] ++ (snd (unzipTR l)))`.
- By the inductive hypothesis, `unzip l = unzipTR l`.
- Therefore, `unzip ((x, y) :: l) = unzipTR ((x, y) :: l)`.

By induction, we have shown that for any list `l` of pairs, `unzip l = unzipTR l`. This completes the proof.","theorem List.unzip_eq_unzipTR : @unzip = @unzipTR := by
/- To prove that the function `unzip` is equal to the function `unzipTR` for any list of pairs, we start by using function extensionality. This means we need to show that for any types `α` and `β` and any list `l` of pairs of type `α × β`, the result of `unzip l` is equal to the result of `unzipTR l`. We then simplify the expression using the definition of `unzipTR`. Next, we use induction on the list `l`. For the base case (an empty list), we simplify the expressions using the definitions of `unzip` and `unzipTR`. For the inductive step (a non-empty list), we also simplify the expressions using the definitions and the inductive hypothesis. -/
  funext α β l; simp [unzipTR]; induction l <;> simp [*]","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
7023,List.eraseP_eq_erasePTR,theorem List.eraseP_eq_erasePTR : @eraseP = @erasePTR := by sorry,"Equivalence of `List.eraseP` and `List.erasePTR` Functions : For any type $\alpha$ and any predicate $p : \alpha \to \text{Bool}$, the function `List.eraseP` that removes the first element satisfying $p$ from a list is equal to the tail-recursive function `List.erasePTR` that removes all elements satisfying $p$ from a list.","theorem List.eraseP_eq_erasePTR : @eraseP = @erasePTR := by
  funext α p l; simp [erasePTR]
  let rec go (acc) : ∀ xs, l = acc.data ++ xs →
    erasePTR.go p l xs acc = acc.data ++ xs.eraseP p
  | [] => fun h => by simp [erasePTR.go, eraseP, h]
  | x::xs => by
    simp [erasePTR.go, eraseP]; cases p x <;> simp
    · intro h; rw [go _ xs]; {simp}; simp [h]
  exact (go #[] _ rfl).symm","To prove that `List.eraseP` is equal to `List.erasePTR`, we use the principle of function extensionality. It suffices to show that for all types \( \alpha \), predicates \( p : \alpha \to \text{Bool} \), and lists \( l : \text{List} \, \alpha \), the functions `eraseP p l` and `erasePTR p l` yield the same result.

1. **Base Case:**
- Consider the case where the list \( l \) is empty. The hypothesis \( h \) states that \( l \) is the concatenation of the data in the empty array and the empty list. Using the definitions of `erasePTR.go` and `eraseP`, and the hypothesis \( h \), we simplify the goal to show that `erasePTR.go p [] [] #[]` is equal to `#[]`.

2. **Inductive Step:**
- Consider the case where the list \( l \) is non-empty, i.e., \( l = x :: xs \) for some element \( x \) and list \( xs \). We need to show that `eraseP p (x :: xs)` is equal to `erasePTR.go p (x :: xs) (x :: xs) #[]`.
- Using the definitions of `erasePTR.go` and `eraseP`, we simplify the goal. We then consider the two cases for the predicate \( p \) applied to \( x \):
- If \( p(x) \) is `false`, we need to show that `erasePTR.go p (x :: xs) (x :: xs) (acc.push x)` is equal to `acc.data ++ x :: eraseP p xs`.
- If \( p(x) \) is `true`, we need to show that `erasePTR.go p (x :: xs) (x :: xs) (acc.push x)` is equal to `acc.data ++ xs`.

3. **Conclusion:**
- Let \( h \) be the hypothesis that \( l = \text{acc.data} ++ x :: xs \). Using the definition of `go`, we rewrite the goal to show that \((\text{acc.push} \, x).data ++ \text{eraseP} \, p \, xs\) is equal to \(\text{acc.data} ++ x :: \text{eraseP} \, p \, xs\). Simplifying this, we get the desired equality. We also need to show that \( l = (\text{acc.push} \, x).data ++ xs \), which follows from the hypothesis \( h \).
- The current goal is to show that `eraseP p l` is equal to `erasePTR.go p l l #[]`. Using the theorem `go` with the empty array and the reflexivity of equality, we get that `erasePTR.go p l l #[]` is equal to `#[] ++ \text{eraseP} \, p \, l`, which simplifies to `eraseP p l`. By the symmetry of equality, this completes the proof.

Thus, we have shown that `List.eraseP` is equal to `List.erasePTR`. \(\blacksquare\)","theorem List.eraseP_eq_erasePTR : @eraseP = @erasePTR := by
/- By the principle of function extensionality, it suffices to show that for all types \( \alpha \), predicates \( p : \alpha \to \text{Bool} \), and lists \( l : \text{List} \, \alpha \), the functions `eraseP p l` and `erasePTR p l` yield the same result. Simplifying the proposition using the definition of `erasePTR`, we get that `eraseP p l` is equal to `erasePTR.go p l l #[]`. -/
  funext α p l; simp [erasePTR]
  let rec go (acc) : ∀ xs, l = acc.data ++ xs →
    erasePTR.go p l xs acc = acc.data ++ xs.eraseP p
/- We consider the case where the list \( l \) is empty. In this case, the hypothesis \( h \) states that \( l \) is the concatenation of the data in the empty array and the empty list. Using the definitions of `erasePTR.go` and `eraseP`, and the hypothesis \( h \), we simplify the goal to show that `erasePTR.go p [] [] #[]` is equal to `#[]`. -/
  | [] => fun h => by simp [erasePTR.go, eraseP, h]
/- We consider the case where the list \( l \) is non-empty, i.e., \( l = x :: xs \) for some element \( x \) and list \( xs \). We need to show that `eraseP p (x :: xs)` is equal to `erasePTR.go p (x :: xs) (x :: xs) #[]`. -/
  | x::xs => by
/- Using the definitions of `erasePTR.go` and `eraseP`, we simplify the goal. We then consider the two cases for the predicate \( p \) applied to \( x \):
1. If \( p(x) \) is `false`, we need to show that `erasePTR.go p (x :: xs) (x :: xs) (acc.push x)` is equal to `acc.data ++ x :: eraseP p xs`.
2. If \( p(x) \) is `true`, we need to show that `erasePTR.go p (x :: xs) (x :: xs) (acc.push x)` is equal to `acc.data ++ xs`. -/
    simp [erasePTR.go, eraseP]; cases p x <;> simp
/- Let \( h \) be the hypothesis that \( l = \text{acc.data} ++ x :: xs \). Using the definition of `go`, we rewrite the goal to show that \((\text{acc.push} \, x).data ++ \text{eraseP} \, p \, xs\) is equal to \(\text{acc.data} ++ x :: \text{eraseP} \, p \, xs\). Simplifying this, we get the desired equality. We also need to show that \( l = (\text{acc.push} \, x).data ++ xs \), which follows from the hypothesis \( h \). -/
    · intro h; rw [go _ xs]; {simp}; simp [h]
/- The current goal is to show that `eraseP p l` is equal to `erasePTR.go p l l #[]`. Using the theorem `go` with the empty array and the reflexivity of equality, we get that `erasePTR.go p l l #[]` is equal to `#[] ++ \text{eraseP} \, p \, l`, which simplifies to `eraseP p l`. By the symmetry of equality, this completes the proof. -/
  exact (go #[] _ rfl).symm","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
7078,List.replicateTR_loop_replicate_eq,"theorem List.replicateTR_loop_replicate_eq (a : α) (m n : Nat) :
  replicateTR.loop a n (replicate m a) = replicate (n + m) a := by sorry","Tail-recursive Replication Loop Equals Concatenation of Replicated Lists: \(\text{List.replicateTR.loop}(a, n, \text{List.replicate}(m, a)) = \text{List.replicate}(n + m, a)\) : For any type \(\alpha\), any element \(a \in \alpha\), and any natural numbers \(m\) and \(n\), the tail-recursive replication loop function `List.replicateTR.loop` applied to \(a\), \(n\), and the list `List.replicate m a` results in a list containing \(n + m\) copies of \(a\). In other words, \(\text{List.replicateTR.loop}(a, n, \text{List.replicate}(m, a)) = \text{List.replicate}(n + m, a)\).","theorem List.replicateTR_loop_replicate_eq (a : α) (m n : Nat) :
  replicateTR.loop a n (replicate m a) = replicate (n + m) a := by
  induction n generalizing m with simp [replicateTR.loop]
  | succ n ih => simp [Nat.succ_add]; exact ih (m+1)","We prove this by induction on \( n \).

**Base Case:**
For \( n = 0 \), we need to show that \(\text{List.replicateTR.loop}(a, 0, \text{List.replicate}(m, a)) = \text{List.replicate}(0 + m, a)\). By the definition of \(\text{List.replicateTR.loop}\), \(\text{List.replicateTR.loop}(a, 0, l) = l\) for any list \( l \). Therefore, \(\text{List.replicateTR.loop}(a, 0, \text{List.replicate}(m, a)) = \text{List.replicate}(m, a)\), which is exactly \(\text{List.replicate}(0 + m, a)\). This completes the base case.

**Inductive Step:**
Assume the inductive hypothesis: for any natural number \( k \) and any natural number \( m \), \(\text{List.replicateTR.loop}(a, k, \text{List.replicate}(m, a)) = \text{List.replicate}(k + m, a)\). We need to show that \(\text{List.replicateTR.loop}(a, k + 1, \text{List.replicate}(m, a)) = \text{List.replicate}(k + 1 + m, a)\).

Using the property of natural number addition, we have:
\[
k + 1 + m = (k + m) + 1
\]
Thus, the goal is to show:
\[
\text{List.replicateTR.loop}(a, k + 1, \text{List.replicate}(m, a)) = \text{List.replicate}((k + m) + 1, a)
\]

By the definition of \(\text{List.replicateTR.loop}\), we have:
\[
\text{List.replicateTR.loop}(a, k + 1, \text{List.replicate}(m, a)) = \text{List.replicateTR.loop}(a, k, a :: \text{List.replicate}(m, a))
\]

By the inductive hypothesis, we know:
\[
\text{List.replicateTR.loop}(a, k, a :: \text{List.replicate}(m, a)) = \text{List.replicate}(k + (m + 1), a)
\]

Since \( k + (m + 1) = (k + m) + 1 \), we have:
\[
\text{List.replicate}(k + (m + 1), a) = \text{List.replicate}((k + m) + 1, a)
\]

Therefore, we have:
\[
\text{List.replicateTR.loop}(a, k + 1, \text{List.replicate}(m, a)) = \text{List.replicate}((k + m) + 1, a)
\]

This completes the inductive step.

By induction, the theorem holds for all natural numbers \( n \). Hence, for any type \(\alpha\), any element \(a \in \alpha\), and any natural numbers \(m\) and \(n\), we have:
\[
\text{List.replicateTR.loop}(a, n, \text{List.replicate}(m, a)) = \text{List.replicate}(n + m, a)
\]

This completes the proof. \(\blacksquare\)","theorem List.replicateTR_loop_replicate_eq (a : α) (m n : Nat) :
  replicateTR.loop a n (replicate m a) = replicate (n + m) a := by
  induction n generalizing m with simp [replicateTR.loop]
/- We perform induction on \( n \). For the inductive step, assume \( n = k + 1 \) and that the inductive hypothesis \( \text{ih} \) holds for \( k \). We need to show that \(\text{List.replicateTR.loop}(a, k + 1, \text{List.replicate}(m, a)) = \text{List.replicate}(k + 1 + m, a)\). Using the property of natural number addition, we simplify the goal to \(\text{List.replicateTR.loop}(a, k + 1, \text{List.replicate}(m, a)) = \text{List.replicate}(k + m + 1, a)\). By the inductive hypothesis, this is exactly \(\text{List.replicateTR.loop}(a, k, \text{List.replicate}(m + 1, a))\), which completes the inductive step. -/
  | succ n ih => simp [Nat.succ_add]; exact ih (m+1)","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
7129,List.eraseIdx_eq_eraseIdxTR,theorem List.eraseIdx_eq_eraseIdxTR : @eraseIdx = @eraseIdxTR := by sorry,"Equivalence of `List.eraseIdx` and `List.eraseIdxTR` : For any list \( l \) of elements of type \( \alpha \) and any natural number \( n \), the function `List.eraseIdx` that removes the element at index \( n \) from \( l \) is equal to the tail-recursive function `List.eraseIdxTR` that performs the same operation. Formally, this is expressed as:
\[ \text{List.eraseIdx}(l, n) = \text{List.eraseIdxTR}(l, n) \]","theorem List.eraseIdx_eq_eraseIdxTR : @eraseIdx = @eraseIdxTR := by
  funext α l n; simp [eraseIdxTR]
  suffices ∀ xs acc, l = acc.data ++ xs → eraseIdxTR.go l xs n acc = acc.data ++ xs.eraseIdx n from
    (this l #[] (by simp)).symm
  intro xs; induction xs generalizing n with intro acc h
  | nil => simp [eraseIdx, eraseIdxTR.go, h]
  | cons x xs IH =>
    match n with
    | 0 => simp [eraseIdx, eraseIdxTR.go]
    | n+1 =>
      simp only [eraseIdxTR.go, eraseIdx]
      rw [IH]; simp; simp; exact h","To prove the equality of the functions `List.eraseIdx` and `List.eraseIdxTR`, we use the principle of function extensionality. It suffices to show that for all lists \( l \) of elements of type \( \alpha \) and all natural numbers \( n \), the functions yield the same result. Using the definition of `List.eraseIdxTR`, we simplify the goal to show that:
\[ l.\text{eraseIdx}(n) = \text{eraseIdxTR.go}(l, l, n, \text{#}[]) \]

To prove this, we perform induction on the list \( xs \) and generalize the natural number \( n \).

**Base Case:**
For the base case where \( xs \) is the empty list, we introduce an array \( acc \) and a hypothesis \( h \) that \( l = \text{acc.data} ++ [] \). Using the definitions of `List.eraseIdx` and `List.eraseIdxTR.go`, and the hypothesis \( h \), we simplify the goal and show that it holds trivially.

**Inductive Step:**
For the inductive step where \( xs \) is a non-empty list \( x :: xs \), we use the induction hypothesis \( \text{IH} \). We need to show that:
\[ \text{eraseIdxTR.go}(l, x :: xs, n, acc) = \text{acc.data} ++ (x :: xs).\text{eraseIdx}(n) \]

We consider two cases for \( n \):

1. **Case \( n = 0 \):**
Using the definitions of `List.eraseIdx` and `List.eraseIdxTR.go`, we simplify the goal and show that it holds trivially.

2. **Case \( n = k + 1 \):**
Using the definitions of `List.eraseIdxTR.go` and `List.eraseIdx`, we simplify the goal to:
\[ \text{eraseIdxTR.go}(l, xs, k, \text{acc.push}(x)) = \text{acc.data} ++ x :: xs.\text{eraseIdx}(k) \]
Using the induction hypothesis \( \text{IH} \), we rewrite the goal. Then, we simplify the expression twice. Finally, we use the hypothesis \( h \) to conclude the proof.

This completes the proof that \( \text{List.eraseIdx}(l, n) = \text{List.eraseIdxTR}(l, n) \).","theorem List.eraseIdx_eq_eraseIdxTR : @eraseIdx = @eraseIdxTR := by
/- By the principle of function extensionality, it suffices to show that for all possible lists \( l \) of elements of type \( \alpha \) and all natural numbers \( n \), the functions `List.eraseIdx` and `List.eraseIdxTR` yield the same result. Using the definition of `List.eraseIdxTR`, we simplify the goal to show that \( l.\text{eraseIdx}(n) = \text{eraseIdxTR.go}(l, l, n, \text{#}[]) \). -/
  funext α l n; simp [eraseIdxTR]
/- To prove the current goal, it suffices to show that for all lists \( xs \) and arrays \( acc \), if \( l = \text{acc.data} ++ xs \), then \( \text{eraseIdxTR.go}(l, xs, n, acc) = \text{acc.data} ++ xs.\text{eraseIdx}(n) \). This is because, by simplifying the expression \( l = \text{#}[].\text{data} ++ l \) and using the symmetry of equality, we can reduce the original goal to this new goal. -/
  suffices ∀ xs acc, l = acc.data ++ xs → eraseIdxTR.go l xs n acc = acc.data ++ xs.eraseIdx n from
    (this l #[] (by simp)).symm
/- Let \( xs \) be an arbitrary list of elements of type \( \alpha \). We perform induction on \( xs \) and generalize the natural number \( n \). For the base case, we introduce an array \( acc \) and a hypothesis \( h \) that \( l = \text{acc.data} ++ [] \). For the inductive step, we introduce an element \( x \), a list \( xs \), an induction hypothesis \( \text{IH} \), a natural number \( n \), an array \( acc \), and a hypothesis \( h \) that \( l = \text{acc.data} ++ x :: xs \). -/
  intro xs; induction xs generalizing n with intro acc h
/- For the base case where \( xs \) is the empty list, we simplify the goal using the definitions of `List.eraseIdx` and `List.eraseIdxTR.go`, and the hypothesis \( h \). This simplification shows that the goal holds trivially. -/
  | nil => simp [eraseIdx, eraseIdxTR.go, h]
/- For the inductive step where \( xs \) is a non-empty list \( x :: xs \), we use the induction hypothesis \( \text{IH} \). -/
  | cons x xs IH =>
    match n with
/- For the case where \( n = 0 \), we simplify the goal using the definitions of `List.eraseIdx` and `List.eraseIdxTR.go`. This simplification shows that the goal holds trivially. -/
    | 0 => simp [eraseIdx, eraseIdxTR.go]
/- For the case where \( n = k + 1 \) for some natural number \( k \), we proceed to the next step. -/
    | n+1 =>
/- Using the definitions of `List.eraseIdxTR.go` and `List.eraseIdx`, we simplify the goal to show that \( \text{eraseIdxTR.go}(l, xs, k, \text{acc.push}(x)) = \text{acc.data} ++ x :: xs.\text{eraseIdx}(k) \). -/
      simp only [eraseIdxTR.go, eraseIdx]
/- Using the induction hypothesis \( \text{IH} \), we rewrite the goal. Then, we simplify the expression twice. Finally, we use the hypothesis \( h \) to conclude the proof. -/
      rw [IH]; simp; simp; exact h","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
7157,List.zipWith_eq_zipWithTR,theorem List.zipWith_eq_zipWithTR : @zipWith = @zipWithTR := by sorry,"Equivalence of `zipWith` and `zipWithTR` for Lists : For any types \( \alpha \), \( \beta \), and \( \gamma \), and for any function \( f : \alpha \to \beta \to \gamma \), the result of applying the `List.zipWith` function to two lists `as` and `bs` is equal to the result of applying the tail-recursive `List.zipWithTR` function to the same lists `as` and `bs`. Formally, for any lists `as : List \alpha` and `bs : List \beta`, it holds that:
\[ \text{zipWith } f \, \text{as} \, \text{bs} = \text{zipWithTR } f \, \text{as} \, \text{bs} \]","theorem List.zipWith_eq_zipWithTR : @zipWith = @zipWithTR := by
  funext α β γ f as bs
  let rec go : ∀ as bs acc, zipWithTR.go f as bs acc = acc.data ++ as.zipWith f bs
    | [], _, acc | _::_, [], acc => by simp [zipWithTR.go, zipWith]
    | a::as, b::bs, acc => by simp [zipWithTR.go, zipWith, go as bs]
  exact (go as bs #[]).symm","To prove the equivalence of the `zipWith` and `zipWithTR` functions, we use the principle of function extensionality. It suffices to show that for all possible types \( \alpha \), \( \beta \), and \( \gamma \), and for all functions \( f : \alpha \to \beta \to \gamma \), and for all lists \( \text{as} : \text{List} \, \alpha \) and \( \text{bs} : \text{List} \, \beta \), the functions `zipWith f as bs` and `zipWithTR f as bs` yield the same result.

We define a recursive function \( \text{go} \) that takes three arguments: two lists \( \text{as} \) and \( \text{bs} \), and an array \( \text{acc} \). The function \( \text{go} \) is defined such that:
- If \( \text{as} \) is an empty list or \( \text{bs} \) is an empty list, then \( \text{go} \, \text{as} \, \text{bs} \, \text{acc} \) is equal to \( \text{acc.data} \) concatenated with the result of `zipWith f as bs`.
- If \( \text{as} \) and \( \text{bs} \) are non-empty lists, then \( \text{go} \, (a::\text{as}) \, (b::\text{bs}) \, \text{acc} \) is equal to \( \text{go} \, \text{as} \, \text{bs} \, (\text{acc.push} \, (f \, a \, b)) \).

We then simplify the goal using the definitions of `zipWithTR.go` and `zipWith` to show that the recursive function \( \text{go} \) holds for the base cases and the inductive step.

Finally, the current goal is exactly proved by the symmetric property of the equality \( \text{go} \, \text{as} \, \text{bs} \, \text{#[]} \). This means that \( \text{zipWith} \, f \, \text{as} \, \text{bs} \) is equal to \( \text{zipWithTR} \, f \, \text{as} \, \text{bs} \).

Thus, we have shown that for any types \( \alpha \), \( \beta \), and \( \gamma \), and for any function \( f : \alpha \to \beta \to \gamma \), and for any lists \( \text{as} : \text{List} \, \alpha \) and \( \text{bs} : \text{List} \, \beta \), the result of applying the `List.zipWith` function to `as` and `bs` is equal to the result of applying the tail-recursive `List.zipWithTR` function to `as` and `bs`. This completes the proof.","theorem List.zipWith_eq_zipWithTR : @zipWith = @zipWithTR := by
/- By the principle of function extensionality, it suffices to show that for all possible types \( \alpha \), \( \beta \), and \( \gamma \), and for all functions \( f : \alpha \to \beta \to \gamma \), and for all lists \( \text{as} : \text{List} \, \alpha \) and \( \text{bs} : \text{List} \, \beta \), the functions `zipWith f as bs` and `zipWithTR f as bs` yield the same result. -/
  funext α β γ f as bs
/- We define a recursive function \( \text{go} \) that takes three arguments: two lists \( \text{as} \) and \( \text{bs} \), and an array \( \text{acc} \). The function \( \text{go} \) is defined such that:
- If \( \text{as} \) is an empty list or \( \text{bs} \) is an empty list, then \( \text{go} \, \text{as} \, \text{bs} \, \text{acc} \) is equal to \( \text{acc.data} \) concatenated with the result of `zipWith f as bs`.
- If \( \text{as} \) and \( \text{bs} \) are non-empty lists, then \( \text{go} \, (a::\text{as}) \, (b::\text{bs}) \, \text{acc} \) is equal to \( \text{go} \, \text{as} \, \text{bs} \, (\text{acc.push} \, (f \, a \, b)) \).

We then simplify the goal using the definitions of `zipWithTR.go` and `zipWith` to show that the recursive function \( \text{go} \) holds for the base cases and the inductive step. -/
  let rec go : ∀ as bs acc, zipWithTR.go f as bs acc = acc.data ++ as.zipWith f bs
    | [], _, acc | _::_, [], acc => by simp [zipWithTR.go, zipWith]
    | a::as, b::bs, acc => by simp [zipWithTR.go, zipWith, go as bs]
/- The current goal is exactly proved by the symmetric property of the equality \( \text{go} \, \text{as} \, \text{bs} \, \text{#[]} \). This means that \( \text{zipWith} \, f \, \text{as} \, \text{bs} \) is equal to \( \text{zipWithTR} \, f \, \text{as} \, \text{bs} \). -/
  exact (go as bs #[]).symm","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
7344,List.get?_take_eq_none,"theorem List.get?_take_eq_none {l : List α} {n m : Nat} (h : n ≤ m) :
    (l.take n).get? m = none := by sorry","$m$-th Element of `List.take n l` is `none` if $n \leq m$ : For any type $\alpha$, any list $l$ of elements of type $\alpha$, and any natural numbers $n$ and $m$ such that $n \leq m$, the $m$-th element of the list `List.take n l` (zero-based) is `none`. In other words, if $n \leq m$, then $(\text{List.take } n \, l)[m] = \text{none}$.","theorem List.get?_take_eq_none {l : List α} {n m : Nat} (h : n ≤ m) :
    (l.take n).get? m = none := by
  simp [getElem?_take_eq_none h]","We start with the assumption that $n \leq m$. We need to show that the $m$-th element of the list `List.take n l` is `none`. By the theorem that for any type $\alpha$, any list $l$ of elements of type $\alpha$, and any natural numbers $n$ and $m$ such that $n \leq m$, the $m$-th element of the list `List.take n l` (zero-based) is `none`, we can directly conclude that:
\[
(\text{List.take } n \, l)[m] = \text{none}
\]
This completes the proof.","theorem List.get?_take_eq_none {l : List α} {n m : Nat} (h : n ≤ m) :
    (l.take n).get? m = none := by
/- Using the theorem that for any type $\alpha$, any list $l$ of elements of type $\alpha$, and any natural numbers $n$ and $m$ such that $n \leq m$, the $m$-th element of the list `List.take n l` (zero-based) is `none`, we can simplify the proposition we want to show to $(\text{List.take } n \, l)[m] = \text{none}$. Since $n \leq m$ by assumption, this simplification directly proves the goal. -/
  simp [getElem?_take_eq_none h]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7347,List.length_take_le,theorem List.length_take_le (n) (l : List α) : length (take n l) ≤ n := by sorry,"Length of Take is Less Than or Equal to \( n \) : For any natural number \( n \) and any list \( l \) of elements of type \( \alpha \), the length of the list obtained by taking the first \( n \) elements of \( l \) is less than or equal to \( n \). Mathematically, this can be expressed as:
\[
\text{length}(\text{take}(n, l)) \leq n
\]","theorem List.length_take_le (n) (l : List α) : length (take n l) ≤ n := by
  simp [Nat.min_le_left]","To prove that the length of the list obtained by taking the first \( n \) elements of \( l \) is less than or equal to \( n \), we use the property that the minimum of two natural numbers \(a\) and \(b\) is less than or equal to \(a\). Specifically, the length of the list obtained by taking the first \( n \) elements of \( l \) is defined as the minimum of \( n \) and the length of \( l \). Therefore, we have:
\[
\text{length}(\text{take}(n, l)) = \min(n, \text{length}(l))
\]
By the property of the minimum function, we know that:
\[
\min(n, \text{length}(l)) \leq n
\]
Thus, it follows that:
\[
\text{length}(\text{take}(n, l)) \leq n
\]
This completes the proof.","theorem List.length_take_le (n) (l : List α) : length (take n l) ≤ n := by
  simp [Nat.min_le_left]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7366,List.length_take_of_le,theorem List.length_take_of_le (h : n ≤ length l) : length (take n l) = n := by sorry,"Length of Take Equals \( n \) if \( n \leq \text{length}(l) \) : For any natural number \( n \) and any list \( l \) of elements of type \( \alpha \), if \( n \) is less than or equal to the length of \( l \), then the length of the list obtained by taking the first \( n \) elements of \( l \) is equal to \( n \). Mathematically, this can be expressed as:
\[
n \leq \text{length}(l) \implies \text{length}(\text{take}(n, l)) = n
\]","theorem List.length_take_of_le (h : n ≤ length l) : length (take n l) = n := by
  simp [Nat.min_eq_left h]","Given a natural number \( n \) and a list \( l \) of elements of type \( \alpha \), assume that \( n \leq \text{length}(l) \). We need to show that the length of the list obtained by taking the first \( n \) elements of \( l \) is equal to \( n \).

By the definition of the `take` function, \(\text{take}(n, l)\) returns the first \( n \) elements of \( l \). The length of this resulting list is given by \(\text{length}(\text{take}(n, l))\).

Using the property of the minimum function, we know that for any two natural numbers \(a\) and \(b\), if \(a \leq b\), then \(\min(a, b) = a\). Given our assumption \(n \leq \text{length}(l)\), we have:
\[
\min(n, \text{length}(l)) = n
\]

The length of the list obtained by taking the first \( n \) elements of \( l \) is defined as \(\min(n, \text{length}(l))\). Therefore, we have:
\[
\text{length}(\text{take}(n, l)) = \min(n, \text{length}(l)) = n
\]

Thus, the length of the list obtained by taking the first \( n \) elements of \( l \) is indeed \( n \). This completes the proof. \(\blacksquare\)","theorem List.length_take_of_le (h : n ≤ length l) : length (take n l) = n := by
  simp [Nat.min_eq_left h]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7374,List.get_take',"theorem List.get_take' (L : List α) {j i} :
    get (L.take j) i =
    get L ⟨i.1, Nat.lt_of_lt_of_le i.2 (length_take_le' _ _)⟩ := by sorry","Element at Index in Take Equals Element at Index in Original List: \(\text{get}(\text{take}(j, L), i) = \text{get}(L, i)\) : For any list \( L \) of elements of type \( \alpha \) and any natural numbers \( j \) and \( i \) such that \( i \) is a valid index in the list obtained by taking the first \( j \) elements of \( L \), the \( i \)-th element of the list `List.take j L` is equal to the \( i \)-th element of the original list \( L \). Mathematically, this can be expressed as:
\[
\text{get}(\text{take}(j, L), i) = \text{get}(L, i)
\]
where \( i \) is a natural number less than the length of `List.take j L`.","theorem List.get_take' (L : List α) {j i} :
    get (L.take j) i =
    get L ⟨i.1, Nat.lt_of_lt_of_le i.2 (length_take_le' _ _)⟩ := by
  simp [getElem_take']","To prove the theorem, we start with the given list \( L \) and natural numbers \( j \) and \( i \) such that \( i \) is a valid index in the list obtained by taking the first \( j \) elements of \( L \). We need to show that:
\[
\text{get}(\text{take}(j, L), i) = \text{get}(L, i)
\]

We use the theorem that states the \( i \)-th element of a list obtained by taking the first \( j \) elements of \( L \) is equal to the \( i \)-th element of the original list \( L \). Formally, this theorem can be written as:
\[
\text{take}(j, L)[i] = L[i]
\]

By applying this theorem, we can directly simplify the proposition we want to show:
\[
\text{get}(\text{take}(j, L), i) = L[i]
\]

Since the \( i \)-th element of the list `List.take j L` is indeed equal to the \( i \)-th element of the original list \( L \), the goal is proven. Therefore, we have:
\[
\text{get}(\text{take}(j, L), i) = \text{get}(L, i)
\]

This completes the proof.","theorem List.get_take' (L : List α) {j i} :
    get (L.take j) i =
    get L ⟨i.1, Nat.lt_of_lt_of_le i.2 (length_take_le' _ _)⟩ := by
/- Using the theorem that the \( i \)-th element of a list obtained by taking the first \( j \) elements of \( L \) is equal to the \( i \)-th element of the original list \( L \), we can simplify the proposition we want to show. Specifically, we have:
\[
\text{get}(\text{take}(j, L), i) = L[i]
\]
This simplification directly proves the goal, as the \( i \)-th element of the list `List.take j L` is indeed equal to the \( i \)-th element of the original list \( L \). -/
  simp [getElem_take']","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7387,List.take_append_of_le_length,"theorem List.take_append_of_le_length {l₁ l₂ : List α} {n : Nat} (h : n ≤ l₁.length) :
    (l₁ ++ l₂).take n = l₁.take n := by sorry","Taking First \( n \) Elements of Concatenated Lists Equals Taking First \( n \) Elements of First List if \( n \leq |l_1| \) : For any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \) and any natural number \( n \) such that \( n \leq |l_1| \), the first \( n \) elements of the concatenated list \( l_1 ++ l_2 \) are the same as the first \( n \) elements of \( l_1 \). Mathematically, this can be expressed as:
\[
\text{take}(n, l_1 ++ l_2) = \text{take}(n, l_1)
\]","theorem List.take_append_of_le_length {l₁ l₂ : List α} {n : Nat} (h : n ≤ l₁.length) :
    (l₁ ++ l₂).take n = l₁.take n := by
  simp [take_append_eq_append_take, Nat.sub_eq_zero_of_le h]","We start by using the theorem that the first \( n \) elements of the concatenation of two lists \( l_1 \) and \( l_2 \) are equal to the concatenation of the first \( n \) elements of \( l_1 \) and the first \( n - \text{length } l_1 \) elements of \( l_2 \). Formally, this is:
\[
\text{take } n \, (l_1 ++ l_2) = \text{take } n \, l_1 ++ \text{take } (n - \text{length } l_1) \, l_2
\]
Given that \( n \leq \text{length } l_1 \), we know from the property of natural numbers that:
\[
n - \text{length } l_1 = 0
\]
Thus, the right-hand side of the equation simplifies to:
\[
\text{take } (n - \text{length } l_1) \, l_2 = \text{take } 0 \, l_2 = []
\]
Therefore, we have:
\[
\text{take } n \, (l_1 ++ l_2) = \text{take } n \, l_1 ++ []
\]
Since concatenating any list with the empty list results in the original list, we get:
\[
\text{take } n \, (l_1 ++ l_2) = \text{take } n \, l_1
\]
This completes the proof.","theorem List.take_append_of_le_length {l₁ l₂ : List α} {n : Nat} (h : n ≤ l₁.length) :
    (l₁ ++ l₂).take n = l₁.take n := by
/- Using the theorem that the first \( n \) elements of the concatenation of two lists \( l_1 \) and \( l_2 \) are equal to the concatenation of the first \( n \) elements of \( l_1 \) and the first \( n - \text{length } l_1 \) elements of \( l_2 \), and the fact that if \( n \leq \text{length } l_1 \), then \( n - \text{length } l_1 = 0 \), we can simplify the proposition we want to show. Specifically, we have:
\[
\text{take } n \, (l_1 ++ l_2) = \text{take } n \, l_1 ++ \text{take } (n - \text{length } l_1) \, l_2
\]
Since \( n \leq \text{length } l_1 \), it follows that \( n - \text{length } l_1 = 0 \), and thus:
\[
\text{take } (n - \text{length } l_1) \, l_2 = \text{take } 0 \, l_2 = []
\]
Therefore, we have:
\[
\text{take } n \, (l_1 ++ l_2) = \text{take } n \, l_1 ++ []
\]
Since concatenating any list with the empty list results in the original list, we get:
\[
\text{take } n \, (l_1 ++ l_2) = \text{take } n \, l_1
\]
This completes the proof. -/
  simp [take_append_eq_append_take, Nat.sub_eq_zero_of_le h]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7388,List.head_drop,"theorem List.head_drop {l : List α} {n : Nat} (h : l.drop n ≠ []) :
    (l.drop n).head h = l[n]'(by simp_all) := by sorry","First Element of Dropped List Equals \( n \)-th Element of Original List : For any list \( l \) of elements of type \( \alpha \) and any natural number \( n \), if the list obtained by dropping the first \( n \) elements of \( l \) is non-empty, then the first element of this resulting list is equal to the \( n \)-th element of \( l \). Formally, if \( \text{List.drop } n \, l \neq \text{[]} \), then \( (\text{List.drop } n \, l).\text{head} \, h = l[n] \), where \( h \) is the proof that the resulting list is non-empty.","theorem List.head_drop {l : List α} {n : Nat} (h : l.drop n ≠ []) :
    (l.drop n).head h = l[n]'(by simp_all) := by
  have w : n < l.length := length_lt_of_drop_ne_nil h
  simpa [head?_eq_head, getElem?_eq_getElem, h, w] using head?_drop l n","We start by noting that if the list obtained by dropping the first \( n \) elements of \( l \) is non-empty, then \( n \) must be strictly less than the length of \( l \). Formally, since \( \text{List.drop } n \, l \neq \text{[]} \), we have \( n < |l| \).

Next, we use the fact that the first element of the list obtained by dropping the first \( n \) elements of \( l \) is equal to the \( n \)-th element of \( l \) when both are considered as optional values. Since \( \text{List.drop } n \, l \neq \text{[]} \), the first element of \( \text{List.drop } n \, l \) is the same as the \( n \)-th element of \( l \). Formally, we have:
\[
(\text{List.drop } n \, l).\text{head} \, h = l[n]
\]
This completes the proof.","theorem List.head_drop {l : List α} {n : Nat} (h : l.drop n ≠ []) :
    (l.drop n).head h = l[n]'(by simp_all) := by
/- First, we show that \( n \) is strictly less than the length of \( l \). This follows from the fact that if the list obtained by dropping the first \( n \) elements of \( l \) is non-empty, then \( n \) must be less than the length of \( l \). Formally, since \( \text{List.drop } n \, l \neq \text{[]} \), we have \( n < |l| \). -/
  have w : n < l.length := length_lt_of_drop_ne_nil h
/- Next, we use the fact that the first element of the list obtained by dropping the first \( n \) elements of \( l \) is equal to the \( n \)-th element of \( l \) when both are considered as optional values. Since \( \text{List.drop } n \, l \neq \text{[]} \), the first element of \( \text{List.drop } n \, l \) is the same as the \( n \)-th element of \( l \). Formally, we have:
\[
(\text{List.drop } n \, l).\text{head} \, h = l[n]
\]
This completes the proof. -/
  simpa [head?_eq_head, getElem?_eq_getElem, h, w] using head?_drop l n","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7389,List.length_zip,"theorem List.length_zip (l₁ : List α) (l₂ : List β) :
    length (zip l₁ l₂) = min (length l₁) (length l₂) := by sorry","Length of Zipped Lists Equals Minimum of Original Lengths : For any lists \( l_1 \) and \( l_2 \) of types \( \alpha \) and \( \beta \) respectively, the length of the list obtained by zipping \( l_1 \) and \( l_2 \) is equal to the minimum of the lengths of \( l_1 \) and \( l_2 \). In other words:
\[ \text{length}(\text{zip}(l_1, l_2)) = \min(\text{length}(l_1), \text{length}(l_2)) \]","theorem List.length_zip (l₁ : List α) (l₂ : List β) :
    length (zip l₁ l₂) = min (length l₁) (length l₂) := by
  simp [zip]","To prove the theorem, we start by using the definition of the `zip` function. The `zip` function pairs elements from two lists until one of the lists is exhausted. Therefore, the length of the zipped list is equal to the length of the shorter of the two input lists. Formally, this can be stated as:
\[ \text{length}(\text{zip}(l_1, l_2)) = \min(\text{length}(l_1), \text{length}(l_2)) \]

This simplification directly gives us the desired result, completing the proof.","theorem List.length_zip (l₁ : List α) (l₂ : List β) :
    length (zip l₁ l₂) = min (length l₁) (length l₂) := by
/- Using the definition of the `zip` function, we can simplify the proposition we want to show. The `zip` function pairs elements from two lists until one of the lists is exhausted. Therefore, the length of the zipped list is equal to the length of the shorter of the two input lists. This simplification directly gives us the desired result:
\[ \text{length}(\text{zip}(l_1, l_2)) = \min(\text{length}(l_1), \text{length}(l_2)) \] -/
  simp [zip]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7390,List.head?_drop,"theorem List.head?_drop (l : List α) (n : Nat) :
    (l.drop n).head? = l[n]? := by sorry","First Element of Dropped List Equals \( n \)-th Element of Original List (Optional Version) : For any list \( l \) of elements of type \( \alpha \) and any natural number \( n \), the first element of the list obtained by dropping the first \( n \) elements of \( l \) is equal to the \( n \)-th element of \( l \), when both are considered as optional values. Formally, this is expressed as:
\[
\text{For any list } l \text{ of type } \alpha \text{ and natural number } n, \text{ we have } (\text{List.drop } n \, l).\text{head?} = l[n]?
\]","theorem List.head?_drop (l : List α) (n : Nat) :
    (l.drop n).head? = l[n]? := by
  rw [head?_eq_getElem?, getElem?_drop, Nat.add_zero]","To prove the theorem, we start with the goal of showing that the first element of the list obtained by dropping the first \( n \) elements of \( l \) is equal to the \( n \)-th element of \( l \) as optional values. Formally, we need to show:
\[
(\text{List.drop } n \, l).\text{head?} = l[n]?
\]

1. **Step 1:**
We use the fact that the optional head of a list is equal to the optional element at index 0. This transforms our goal to:
\[
(\text{List.drop } n \, l)[0]? = l[n]?
\]

2. **Step 2:**
Next, we use the property that the optional element at index \( j \) in the list obtained by dropping the first \( i \) elements is equal to the optional element at index \( i + j \) in the original list. This transforms our goal to:
\[
l[n + 0]? = l[n]?
\]

3. **Step 3:**
Finally, we use the property that adding zero to any natural number \( n \) results in \( n \). This simplifies our goal to:
\[
l[n]? = l[n]?
\]
which is trivially true.

Thus, we have shown that:
\[
(\text{List.drop } n \, l).\text{head?} = l[n]?
\]
This completes the proof.","theorem List.head?_drop (l : List α) (n : Nat) :
    (l.drop n).head? = l[n]? := by
/- First, we use the fact that the optional head of a list is equal to the optional element at index 0. This transforms our goal from \((\text{List.drop } n \, l).\text{head?} = l[n]?\) to \((\text{List.drop } n \, l)[0]? = l[n]?\).

Next, we use the property that the optional element at index \( j \) in the list obtained by dropping the first \( i \) elements is equal to the optional element at index \( i + j \) in the original list. This transforms our goal to \( l[n + 0]? = l[n]?\).

Finally, we use the property that adding zero to any natural number \( n \) results in \( n \). This simplifies our goal to \( l[n]? = l[n]? \), which is trivially true. -/
  rw [head?_eq_getElem?, getElem?_drop, Nat.add_zero]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7392,List.lt_length_right_of_zipWith,"theorem List.lt_length_right_of_zipWith {f : α → β → γ} {i : Nat} {l : List α} {l' : List β}
    (h : i < (zipWith f l l').length) : i < l'.length := by sorry","Right List Length Inequality in `zipWith` Operation : For any types \(\alpha\), \(\beta\), and \(\gamma\), and for any function \(f : \alpha \to \beta \to \gamma\), if \(i\) is a natural number such that \(i\) is less than the length of the list obtained by applying `List.zipWith` to lists \(l : \text{List } \alpha\) and \(l' : \text{List } \beta\), then \(i\) is also less than the length of \(l'\).","theorem List.lt_length_right_of_zipWith {f : α → β → γ} {i : Nat} {l : List α} {l' : List β}
    (h : i < (zipWith f l l').length) : i < l'.length := by
  rw [length_zipWith] at h; omega","We start with the assumption that \(i < \text{length}(\text{zipWith } f \, l \, l')\). By the property of the `List.zipWith` operation, the length of the resulting list is equal to the minimum of the lengths of the input lists \(l\) and \(l'\). Therefore, we can rewrite the assumption as \(i < \min(\text{length}(l), \text{length}(l'))\).

Since \(i < \min(\text{length}(l), \text{length}(l'))\), it follows that \(i\) is less than both \(\text{length}(l)\) and \(\text{length}(l')\). In particular, \(i < \text{length}(l')\).

Thus, we have shown that if \(i < \text{length}(\text{zipWith } f \, l \, l')\), then \(i < \text{length}(l')\). This completes the proof. \(\blacksquare\)","theorem List.lt_length_right_of_zipWith {f : α → β → γ} {i : Nat} {l : List α} {l' : List β}
    (h : i < (zipWith f l l').length) : i < l'.length := by
  rw [length_zipWith] at h; omega","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7395,List.lt_length_left_of_zipWith,"theorem List.lt_length_left_of_zipWith {f : α → β → γ} {i : Nat} {l : List α} {l' : List β}
    (h : i < (zipWith f l l').length) : i < l.length := by sorry","Left List Length Inequality in `zipWith` Operation: \(i < \text{length}(\text{zipWith } f \, l \, l') \to i < \text{length}(l)\) : For any types \(\alpha\), \(\beta\), and \(\gamma\), and for any function \(f : \alpha \to \beta \to \gamma\), if \(i\) is a natural number such that \(i\) is less than the length of the list obtained by applying `List.zipWith` to lists \(l : \text{List } \alpha\) and \(l' : \text{List } \beta\), then \(i\) is also less than the length of \(l\).","theorem List.lt_length_left_of_zipWith {f : α → β → γ} {i : Nat} {l : List α} {l' : List β}
    (h : i < (zipWith f l l').length) : i < l.length := by
  rw [length_zipWith] at h; omega","We start with the assumption that \( i < \text{length}(\text{zipWith } f \, l \, l') \). By the property of the `List.zipWith` operation, the length of the resulting list is equal to the minimum of the lengths of the input lists \( l \) and \( l' \). Therefore, we can rewrite the assumption as \( i < \min(\text{length}(l), \text{length}(l')) \).

Next, we use the property of the minimum function, which states that if a number is less than the minimum of two numbers, it is less than each of those numbers. Hence, \( i < \min(\text{length}(l), \text{length}(l')) \) implies \( i < \text{length}(l) \).

Thus, we have shown that if \( i < \text{length}(\text{zipWith } f \, l \, l') \), then \( i < \text{length}(l) \). This completes the proof. \(\blacksquare\)","theorem List.lt_length_left_of_zipWith {f : α → β → γ} {i : Nat} {l : List α} {l' : List β}
    (h : i < (zipWith f l l').length) : i < l.length := by
  rw [length_zipWith] at h; omega","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7398,List.take_append,"theorem List.take_append {l₁ l₂ : List α} (i : Nat) :
    take (l₁.length + i) (l₁ ++ l₂) = l₁ ++ take i l₂ := by sorry","Taking First \( |l_1| + i \) Elements of Concatenated Lists Equals Appending First \( i \) Elements of Second List to First List : For any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \) and any natural number \( i \), taking the first \( |l_1| + i \) elements of the concatenated list \( l_1 ++ l_2 \) is the same as appending the first \( i \) elements of \( l_2 \) to the list \( l_1 \). Mathematically, this can be expressed as:
\[
\text{take}(|l_1| + i, l_1 ++ l_2) = l_1 ++ \text{take}(i, l_2)
\]","theorem List.take_append {l₁ l₂ : List α} (i : Nat) :
    take (l₁.length + i) (l₁ ++ l₂) = l₁ ++ take i l₂ := by
  rw [take_append_eq_append_take, take_of_length_le (Nat.le_add_right _ _), Nat.add_sub_cancel_left]","To prove the theorem, we start by using the theorem that taking the first \( n \) elements of the concatenation of two lists \( l_1 \) and \( l_2 \) is the same as concatenating the first \( n \) elements of \( l_1 \) and the first \( n - \text{length } l_1 \) elements of \( l_2 \). This gives us:
\[
\text{take}(|l_1| + i, l_1 ++ l_2) = \text{take}(|l_1| + i, l_1) ++ \text{take}((|l_1| + i) - |l_1|, l_2)
\]
Next, we use the fact that the length of \( l_1 \) is less than or equal to \( |l_1| + i \). This implies that taking the first \( |l_1| + i \) elements of \( l_1 \) is just \( l_1 \) itself. Therefore, we have:
\[
\text{take}(|l_1| + i, l_1) = l_1
\]
Substituting this into our equation, we get:
\[
l_1 ++ \text{take}((|l_1| + i) - |l_1|, l_2)
\]
Finally, we use the property of natural numbers that \( a + b - a = b \) to simplify \( (|l_1| + i) - |l_1| \) to \( i \). This gives us:
\[
l_1 ++ \text{take}(i, l_2)
\]
Thus, we have shown that:
\[
\text{take}(|l_1| + i, l_1 ++ l_2) = l_1 ++ \text{take}(i, l_2)
\]
This completes the proof.","theorem List.take_append {l₁ l₂ : List α} (i : Nat) :
    take (l₁.length + i) (l₁ ++ l₂) = l₁ ++ take i l₂ := by
/- First, we use the theorem that taking the first \( n \) elements of the concatenation of two lists \( l_1 \) and \( l_2 \) is the same as concatenating the first \( n \) elements of \( l_1 \) and the first \( n - \text{length } l_1 \) elements of \( l_2 \). This transforms our goal into:
\[
\text{take}(|l_1| + i, l_1 ++ l_2) = \text{take}(|l_1| + i, l_1) ++ \text{take}((|l_1| + i) - |l_1|, l_2)
\]
Next, we use the fact that the length of \( l_1 \) is less than or equal to \( |l_1| + i \), which implies that taking the first \( |l_1| + i \) elements of \( l_1 \) is just \( l_1 \) itself. This simplifies our goal to:
\[
l_1 ++ \text{take}((|l_1| + i) - |l_1|, l_2) = l_1 ++ \text{take}(i, l_2)
\]
Finally, we use the property of natural numbers that \( a + b - a = b \) to simplify \( (|l_1| + i) - |l_1| \) to \( i \). This reduces our goal to:
\[
l_1 ++ \text{take}(i, l_2) = l_1 ++ \text{take}(i, l_2)
\]
Since the left-hand side and the right-hand side are identical, the goal is trivially true. -/
  rw [take_append_eq_append_take, take_of_length_le (Nat.le_add_right _ _), Nat.add_sub_cancel_left]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7402,List.drop_append_of_le_length,"theorem List.drop_append_of_le_length {l₁ l₂ : List α} {n : Nat} (h : n ≤ l₁.length) :
    (l₁ ++ l₂).drop n = l₁.drop n ++ l₂ := by sorry","Drop of Concatenation Equals Concatenation of Drops when \( n \leq \text{length}(l_1) \) : For any type \( \alpha \) and any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), if \( n \) is a natural number such that \( n \leq \text{length}(l_1) \), then the list obtained by dropping the first \( n \) elements from the concatenation \( l_1 ++ l_2 \) is equal to the concatenation of the list obtained by dropping the first \( n \) elements from \( l_1 \) and the list \( l_2 \). In other words, if \( n \leq \text{length}(l_1) \), then \(\text{drop } n (l_1 ++ l_2) = \text{drop } n l_1 ++ l_2\).","theorem List.drop_append_of_le_length {l₁ l₂ : List α} {n : Nat} (h : n ≤ l₁.length) :
    (l₁ ++ l₂).drop n = l₁.drop n ++ l₂ := by
  simp [drop_append_eq_append_drop, Nat.sub_eq_zero_of_le h]","We start with the assumption that \( n \leq \text{length}(l_1) \). We need to show that \(\text{drop } n (l_1 ++ l_2) = \text{drop } n l_1 ++ l_2\).

Using the theorem that the list obtained by dropping the first \( n \) elements from the concatenation \( l_1 ++ l_2 \) is equal to the concatenation of the list obtained by dropping the first \( n \) elements from \( l_1 \) and the list obtained by dropping the first \( n - \text{length}(l_1) \) elements from \( l_2 \), we have:
\[
\text{drop } n (l_1 ++ l_2) = \text{drop } n l_1 ++ \text{drop } (n - \text{length}(l_1)) l_2
\]

Since \( n \leq \text{length}(l_1) \), we know that \( n - \text{length}(l_1) = 0 \). Therefore, the list obtained by dropping the first \( n - \text{length}(l_1) \) elements from \( l_2 \) is just \( l_2 \). Substituting this into the equation, we get:
\[
\text{drop } n (l_1 ++ l_2) = \text{drop } n l_1 ++ l_2
\]

This completes the proof.","theorem List.drop_append_of_le_length {l₁ l₂ : List α} {n : Nat} (h : n ≤ l₁.length) :
    (l₁ ++ l₂).drop n = l₁.drop n ++ l₂ := by
/- Using the theorem that the list obtained by dropping the first \( n \) elements from the concatenation \( l_1 ++ l_2 \) is equal to the concatenation of the list obtained by dropping the first \( n \) elements from \( l_1 \) and the list obtained by dropping the first \( n - \text{length}(l_1) \) elements from \( l_2 \), and the fact that if \( n \leq \text{length}(l_1) \), then \( n - \text{length}(l_1) = 0 \), we can simplify the goal. Since \( n - \text{length}(l_1) = 0 \), the list obtained by dropping the first \( n - \text{length}(l_1) \) elements from \( l_2 \) is just \( l_2 \). Therefore, the goal simplifies to \(\text{drop } n (l_1 ++ l_2) = \text{drop } n l_1 ++ l_2\), which is exactly what we need to show. -/
  simp [drop_append_eq_append_drop, Nat.sub_eq_zero_of_le h]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7405,List.dropLast_take,"theorem List.dropLast_take {n : Nat} {l : List α} (h : n < l.length) :
    (l.take n).dropLast = l.take (n - 1) := by sorry","Drop Last Element of First \( n \) Elements of a List : For any list \( l \) of elements of type \( \alpha \) and any natural number \( n \) such that \( n \) is less than the length of \( l \), the result of removing the last element from the first \( n \) elements of \( l \) is equal to the first \( n - 1 \) elements of \( l \). In other words, if \( l \) has at least \( n \) elements, then removing the last element from the list formed by taking the first \( n \) elements of \( l \) results in the list formed by taking the first \( n - 1 \) elements of \( l \).","theorem List.dropLast_take {n : Nat} {l : List α} (h : n < l.length) :
    (l.take n).dropLast = l.take (n - 1) := by
  simp only [dropLast_eq_take, length_take, Nat.le_of_lt h, Nat.min_eq_left, take_take, sub_le]","We need to show that \((\text{take } n \, l).\text{dropLast} = \text{take } (n - 1) \, l\).

1. **Length of the First \( n \) Elements:**
The length of the first \( n \) elements of \( l \) is given by:
\[
\text{length}(\text{take } n \, l) = \min(n, \text{length}(l))
\]
Since \( n < \text{length}(l) \), it follows that:
\[
\min(n, \text{length}(l)) = n
\]

2. **Removing the Last Element:**
The list obtained by removing the last element from the first \( n \) elements of \( l \) is:
\[
(\text{take } n \, l).\text{dropLast} = \text{take } (n - 1) \, (\text{take } n \, l)
\]

3. **Taking the First \( n - 1 \) Elements:**
By the property of taking elements, we have:
\[
\text{take } (n - 1) \, (\text{take } n \, l) = \text{take } \min(n - 1, n) \, l
\]
Since \( n - 1 \leq n \), it follows that:
\[
\min(n - 1, n) = n - 1
\]
Therefore:
\[
\text{take } (n - 1) \, (\text{take } n \, l) = \text{take } (n - 1) \, l
\]

Combining these steps, we conclude:
\[
(\text{take } n \, l).\text{dropLast} = \text{take } (n - 1) \, l
\]

This completes the proof.","theorem List.dropLast_take {n : Nat} {l : List α} (h : n < l.length) :
    (l.take n).dropLast = l.take (n - 1) := by
/- To prove that \((\text{take } n \, l).\text{dropLast} = \text{take } (n - 1) \, l\), we use the following properties:
1. The length of the first \( n \) elements of \( l \) is \(\min(n, \text{length}(l))\).
2. Since \( n < \text{length}(l) \), it follows that \( n \leq \text{length}(l) \).
3. Therefore, \(\min(n, \text{length}(l)) = n\).
4. The list obtained by removing the last element from the first \( n \) elements of \( l \) is equal to the first \( n - 1 \) elements of \( l \).
5. Taking the first \( n \) elements of the first \( m \) elements of \( l \) is equivalent to taking the first \(\min(n, m)\) elements of \( l \).
6. Since \( n - 1 \leq n \), the first \( n - 1 \) elements of \( l \) are the same as the first \( n - 1 \) elements of the first \( n \) elements of \( l \).

Thus, we have:
\[
(\text{take } n \, l).\text{dropLast} = \text{take } (n - 1) \, l
\] -/
  simp only [dropLast_eq_take, length_take, Nat.le_of_lt h, Nat.min_eq_left, take_take, sub_le]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7408,List.lt_length_drop,theorem List.lt_length_drop (L : List α) {i j : Nat} (h : i + j < L.length) : j < (L.drop i).length := by sorry,"Length of Dropped List is Greater Than \( j \) if \( i + j \) is Less Than Length of Original List : For any list \( L \) of elements of type \( \alpha \) and any natural numbers \( i \) and \( j \), if \( i + j \) is less than the length of \( L \), then \( j \) is less than the length of the list obtained by dropping the first \( i \) elements from \( L \). In other words, if \( i + j < |L| \), then \( j < |L[i+1, \ldots, |L|]|\).","theorem List.lt_length_drop (L : List α) {i j : Nat} (h : i + j < L.length) : j < (L.drop i).length := by
  have A : i < L.length := Nat.lt_of_le_of_lt (Nat.le.intro rfl) h
  rw [(take_append_drop i L).symm] at h
  simpa only [Nat.le_of_lt A, Nat.min_eq_left, Nat.add_lt_add_iff_left, length_take,
    length_append] using h","We start by noting that the assumption \( i + j < |L| \) implies \( i < |L| \) because \( i \leq i \) (by reflexivity) and \( i + j < |L| \) (by the transitivity of the less-than and less-than-or-equal-to relations).

Next, we use the property that the concatenation of the first \( i \) elements of \( L \) and the list obtained by dropping the first \( i \) elements of \( L \) is equal to the original list \( L \). This allows us to rewrite the assumption \( i + j < |L| \) as \( i + j < |\text{take}(i, L) \oplus \text{drop}(i, L)| \).

We then simplify the goal using the following properties:
- The length of the first \( i \) elements of \( L \) is \( \min(i, |L|) \), which is \( i \) since \( i \leq |L| \)
- The length of the concatenated list \( \text{take}(i, L) \oplus \text{drop}(i, L) \) is the sum of the lengths of \( \text{take}(i, L) \) and \( \text{drop}(i, L) \)
- The inequality \( i + j < i + |\text{drop}(i, L)| \) holds if and only if \( j < |\text{drop}(i, L)| \)

Using these properties, we simplify the assumption \( i + j < |\text{take}(i, L) \oplus \text{drop}(i, L)| \) to \( j < |\text{drop}(i, L)| \), which is exactly what we need to prove. This completes the proof. \(\blacksquare\)","theorem List.lt_length_drop (L : List α) {i j : Nat} (h : i + j < L.length) : j < (L.drop i).length := by
/- First, we construct a lemma \( A \) that states \( i < |L| \). This is derived from the fact that \( i + j < |L| \) and \( i \leq i \) (by reflexivity), which implies \( i < |L| \) by the transitivity of the less-than and less-than-or-equal-to relations. -/
  have A : i < L.length := Nat.lt_of_le_of_lt (Nat.le.intro rfl) h
/- Next, we use the property that the concatenation of the first \( i \) elements of \( L \) and the list obtained by dropping the first \( i \) elements of \( L \) is equal to the original list \( L \). This allows us to rewrite the assumption \( i + j < |L| \) as \( i + j < |\text{take}(i, L) \oplus \text{drop}(i, L)| \). -/
  rw [(take_append_drop i L).symm] at h
/- We simplify the goal using the following properties:
- \( i \leq |L| \) (from \( A \))
- The length of the first \( i \) elements of \( L \) is \( \min(i, |L|) \), which is \( i \) since \( i \leq |L| \)
- The length of the concatenated list \( \text{take}(i, L) \oplus \text{drop}(i, L) \) is the sum of the lengths of \( \text{take}(i, L) \) and \( \text{drop}(i, L) \)
- The inequality \( i + j < i + |\text{drop}(i, L)| \) holds if and only if \( j < |\text{drop}(i, L)| \)

Using these properties, we simplify the assumption \( i + j < |\text{take}(i, L) \oplus \text{drop}(i, L)| \) to \( j < |\text{drop}(i, L)| \), which is exactly what we need to prove. This completes the proof. -/
  simpa only [Nat.le_of_lt A, Nat.min_eq_left, Nat.add_lt_add_iff_left, length_take,
    length_append] using h","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7417,List.getLast_drop,"theorem List.getLast_drop {l : List α} (h : l.drop n ≠ []) :
    (l.drop n).getLast h = l.getLast (ne_nil_of_length_pos (by simp at h; omega)) := by sorry","Last Element of Dropped List Equals Last Element of Original List: \((\text{List.drop } n \, l \neq []) \to (\text{List.drop } n \, l).\text{getLast} = l.\text{getLast}\) : For any list \( l \) of elements of type \( \alpha \) and any natural number \( n \), if the list obtained by dropping the first \( n \) elements of \( l \) is non-empty, then the last element of the dropped list is equal to the last element of the original list \( l \). Formally, if \( \text{List.drop } n \, l \neq [] \), then \( (\text{List.drop } n \, l).\text{getLast}(h) = l.\text{getLast} \), where \( h \) is a proof that \( \text{List.drop } n \, l \) is non-empty.","theorem List.getLast_drop {l : List α} (h : l.drop n ≠ []) :
    (l.drop n).getLast h = l.getLast (ne_nil_of_length_pos (by simp at h; omega)) := by
  simp only [ne_eq, drop_eq_nil_iff_le] at h
  apply Option.some_inj.1
  simp only [← getLast?_eq_getLast, getLast?_drop, ite_eq_right_iff]
  omega","We start with the assumption that the list obtained by dropping the first \( n \) elements of \( l \) is non-empty, i.e., \( \text{List.drop } n \, l \neq [] \). Using the equivalence that \( a \neq b \) is the same as \( \neg (a = b) \) and the fact that the list obtained by dropping the first \( n \) elements of \( l \) is non-empty if and only if the length of \( l \) is greater than \( n \), we can simplify the hypothesis to \( \neg (l.\text{length} \le n) \).

Next, we need to show that \( (\text{List.drop } n \, l).\text{getLast} \, h = l.\text{getLast} \). To do this, it suffices to show that \( \text{some} \, ((\text{List.drop } n \, l).\text{getLast} \, h) = \text{some} \, (l.\text{getLast}) \), since the `some` constructor is injective.

Using the properties that \( (\text{List.drop } n \, l).\text{getLast?} = \text{if } l.\text{length} \le n \text{ then } \text{none} \text{ else } l.\text{getLast?} \) and the equivalence \( (\text{if } P \text{ then } a \text{ else } b) = b \leftrightarrow P \to a = b \), we can simplify the goal to \( l.\text{length} \le n \to \text{none} = l.\text{getLast?} \).

Since \( \neg (l.\text{length} \le n) \) is given, the implication \( l.\text{length} \le n \to \text{none} = l.\text{getLast?} \) is vacuously true. Therefore, the last element of the dropped list is equal to the last element of the original list, completing the proof. \(\blacksquare\)","theorem List.getLast_drop {l : List α} (h : l.drop n ≠ []) :
    (l.drop n).getLast h = l.getLast (ne_nil_of_length_pos (by simp at h; omega)) := by
/- Using the equivalence that \( a \neq b \) is the same as \( \neg (a = b) \) and the fact that the list obtained by dropping the first \( n \) elements of \( l \) is non-empty if and only if the length of \( l \) is greater than \( n \), we can simplify the hypothesis \( \text{List.drop } n \, l \neq [] \) to \( \neg (l.\text{length} \le n) \). -/
  simp only [ne_eq, drop_eq_nil_iff_le] at h
/- To prove that \( (\text{List.drop } n \, l).\text{getLast} \, h = l.\text{getLast} \), it suffices to show that \( \text{some} \, ((\text{List.drop } n \, l).\text{getLast} \, h) = \text{some} \, (l.\text{getLast}) \), since the `some` constructor is injective. -/
  apply Option.some_inj.1
/- Using the properties that \( (\text{List.drop } n \, l).\text{getLast?} = \text{if } l.\text{length} \le n \text{ then } \text{none} \text{ else } l.\text{getLast?} \) and the equivalence \( (\text{if } P \text{ then } a \text{ else } b) = b \leftrightarrow P \to a = b \), we can simplify the goal to \( l.\text{length} \le n \to \text{none} = l.\text{getLast?} \). -/
  simp only [← getLast?_eq_getLast, getLast?_drop, ite_eq_right_iff]
/- Since \( \neg (l.\text{length} \le n) \) is given, the implication \( l.\text{length} \le n \to \text{none} = l.\text{getLast?} \) is vacuously true. This completes the proof. -/
  omega","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7421,List.drop_append,theorem List.drop_append {l₁ l₂ : List α} (i : Nat) : drop (l₁.length + i) (l₁ ++ l₂) = drop i l₂ := by sorry,"Dropping Elements from Concatenation: \(\text{drop } (\text{length}(l_1) + i) (l_1 ++ l_2) = \text{drop } i l_2\) : For any type \( \alpha \) and any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), dropping the first \( \text{length}(l_1) + i \) elements from the concatenation \( l_1 ++ l_2 \) is the same as dropping the first \( i \) elements from \( l_2 \). In other words, \(\text{drop } (\text{length}(l_1) + i) (l_1 ++ l_2) = \text{drop } i l_2\).","theorem List.drop_append {l₁ l₂ : List α} (i : Nat) : drop (l₁.length + i) (l₁ ++ l₂) = drop i l₂ := by
  rw [drop_append_eq_append_drop, drop_eq_nil_of_le] <;>
    simp [Nat.add_sub_cancel_left, Nat.le_add_right]","We start by using the theorem that the list obtained by dropping the first \( n \) elements from the concatenation \( l_1 ++ l_2 \) is equal to the concatenation of the list obtained by dropping the first \( n \) elements from \( l_1 \) and the list obtained by dropping the first \( n - \text{length}(l_1) \) elements from \( l_2 \). This transforms our goal to show that:
\[
\text{drop } (l_1.\text{length} + i) (l_1 ++ l_2) = \text{drop } (l_1.\text{length} + i) l_1 ++ \text{drop } (l_1.\text{length} + i - l_1.\text{length}) l_2
\]

Next, we use the theorem that dropping elements beyond the length of a list results in the empty list. Since \( l_1.\text{length} \leq l_1.\text{length} + i \), we have:
\[
\text{drop } (l_1.\text{length} + i) l_1 = \text{nil}
\]

This simplifies our goal to:
\[
\text{nil} ++ \text{drop } (l_1.\text{length} + i - l_1.\text{length}) l_2 = \text{drop } i l_2
\]

We then simplify the expression \( l_1.\text{length} + i - l_1.\text{length} \) to \( i \) using the property that left addition and subtraction cancel each other:
\[
l_1.\text{length} + i - l_1.\text{length} = i
\]

Thus, our goal reduces to:
\[
\text{nil} ++ \text{drop } i l_2 = \text{drop } i l_2
\]

This is trivially true because concatenating the empty list with any list \( l \) results in \( l \). Therefore, we have:
\[
\text{drop } (l_1.\text{length} + i) (l_1 ++ l_2) = \text{drop } i l_2
\]

This completes the proof. \(\blacksquare\)","theorem List.drop_append {l₁ l₂ : List α} (i : Nat) : drop (l₁.length + i) (l₁ ++ l₂) = drop i l₂ := by
/- First, we use the theorem that the list obtained by dropping the first \( n \) elements from the concatenation \( l_1 ++ l_2 \) is equal to the concatenation of the list obtained by dropping the first \( n \) elements from \( l_1 \) and the list obtained by dropping the first \( n - \text{length}(l_1) \) elements from \( l_2 \). This transforms our goal to show that \(\text{drop } (l_1.\text{length} + i) l_1 ++ \text{drop } (l_1.\text{length} + i - l_1.\text{length}) l_2 = \text{drop } i l_2\).

Next, we use the theorem that dropping elements beyond the length of a list results in the empty list. This simplifies our goal to show that \(\text{nil} ++ \text{drop } (l_1.\text{length} + i - l_1.\text{length}) l_2 = \text{drop } i l_2\).

Finally, we simplify the expression \( l_1.\text{length} + i - l_1.\text{length} \) to \( i \) using the property that left addition and subtraction cancel each other, and we use the property that adding a non-negative number to another non-negative number preserves the order. This reduces our goal to showing that \(\text{nil} ++ \text{drop } i l_2 = \text{drop } i l_2\), which is trivially true. -/
  rw [drop_append_eq_append_drop, drop_eq_nil_of_le] <;>
    simp [Nat.add_sub_cancel_left, Nat.le_add_right]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7425,List.getElem_zipWith,"theorem List.getElem_zipWith {f : α → β → γ} {l : List α} {l' : List β}
    {i : Nat} {h : i < (zipWith f l l').length} :
    (zipWith f l l')[i] =
      f (l[i]'(lt_length_left_of_zipWith h))
        (l'[i]'(lt_length_right_of_zipWith h)) := by sorry","Element Retrieval in `zipWith` Result List : For any types \(\alpha\), \(\beta\), and \(\gamma\), and for any function \(f : \alpha \to \beta \to \gamma\), given lists \(l : \text{List } \alpha\) and \(l' : \text{List } \beta\), and a natural number \(i\) such that \(i\) is less than the length of the list obtained by applying `List.zipWith` to \(l\) and \(l'\), the element at index \(i\) in the resulting list from `List.zipWith` is equal to the result of applying \(f\) to the elements at index \(i\) in \(l\) and \(l'\). In other words:
\[ (\text{zipWith } f \, l \, l')[i] = f(l[i], l'[i]) \]","theorem List.getElem_zipWith {f : α → β → γ} {l : List α} {l' : List β}
    {i : Nat} {h : i < (zipWith f l l').length} :
    (zipWith f l l')[i] =
      f (l[i]'(lt_length_left_of_zipWith h))
        (l'[i]'(lt_length_right_of_zipWith h)) := by
  rw [← Option.some_inj, ← getElem?_eq_getElem, getElem?_zipWith_eq_some]
  exact
    ⟨l[i]'(lt_length_left_of_zipWith h), l'[i]'(lt_length_right_of_zipWith h),
      by rw [getElem?_eq_getElem], by rw [getElem?_eq_getElem]; exact ⟨rfl, rfl⟩⟩","We start by using the injectivity of the `some` constructor and the equivalence between element retrieval with a valid index and optional element retrieval. This allows us to transform the goal \((\text{zipWith } f \, l \, l')[i] = f(l[i], l'[i])\) into the equivalent goal:
\[ \exists x \, y, \, l[i]? = \text{some } x \, \land \, l'[i]? = \text{some } y \, \land \, f(x, y) = f(l[i], l'[i]) \]

To prove this, we construct the elements \(x\) and \(y\) as follows:
- Since \(i < \text{length}(\text{zipWith } f \, l \, l')\), it follows from the properties of `zipWith` that \(i < \text{length}(l)\) and \(i < \text{length}(l')\).
- Therefore, \(l[i]? = \text{some } l[i]\) and \(l'[i]? = \text{some } l'[i]\).
- By the definition of `zipWith`, \(f(l[i], l'[i]) = f(l[i], l'[i])\), which is trivially true by the reflexivity of equality.

Thus, we have shown that:
\[ (\text{zipWith } f \, l \, l')[i] = f(l[i], l'[i]) \]

This completes the proof.","theorem List.getElem_zipWith {f : α → β → γ} {l : List α} {l' : List β}
    {i : Nat} {h : i < (zipWith f l l').length} :
    (zipWith f l l')[i] =
      f (l[i]'(lt_length_left_of_zipWith h))
        (l'[i]'(lt_length_right_of_zipWith h)) := by
/- First, we use the injectivity of the `some` constructor and the equivalence between element retrieval with a valid index and optional element retrieval to transform the goal. Specifically, we convert the goal \((\text{zipWith } f \, l \, l')[i] = f(l[i], l'[i])\) into the equivalent goal \(\exists x \, y, \, l[i]? = \text{some } x \, \land \, l'[i]? = \text{some } y \, \land \, f(x, y) = f(l[i], l'[i])\). -/
  rw [← Option.some_inj, ← getElem?_eq_getElem, getElem?_zipWith_eq_some]
/- To prove the goal \(\exists x \, y, \, l[i]? = \text{some } x \, \land \, l'[i]? = \text{some } y \, \land \, f(x, y) = f(l[i], l'[i])\), we construct the elements \(x\) and \(y\) as follows:
- Since \(i < \text{length}(\text{zipWith } f \, l \, l')\), it follows that \(i < \text{length}(l)\) and \(i < \text{length}(l')\).
- Therefore, \(l[i]? = \text{some } l[i]\) and \(l'[i]? = \text{some } l'[i]\).
- By the definition of `zipWith`, \(f(l[i], l'[i]) = f(l[i], l'[i])\), which is trivially true by the reflexivity of equality. -/
  exact
    ⟨l[i]'(lt_length_left_of_zipWith h), l'[i]'(lt_length_right_of_zipWith h),
      by rw [getElem?_eq_getElem], by rw [getElem?_eq_getElem]; exact ⟨rfl, rfl⟩⟩","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7435,List.drop_length_cons,"theorem List.drop_length_cons {l : List α} (h : l ≠ []) (a : α) :
    (a :: l).drop l.length = [l.getLast h] := by sorry","Dropping Length of Non-Empty List Results in Last Element : For any non-empty list \( l \) of elements of type \( \alpha \) and any element \( a \) of type \( \alpha \), dropping the first \( \text{length}(l) \) elements from the list \( a :: l \) results in a list containing only the last element of \( l \). Formally, if \( l \neq [] \), then \( \text{drop}(\text{length}(l), a :: l) = [l.\text{getLast}(h)] \), where \( h \) is a proof that \( l \) is non-empty.","theorem List.drop_length_cons {l : List α} (h : l ≠ []) (a : α) :
    (a :: l).drop l.length = [l.getLast h] := by
  induction l generalizing a with
  | nil =>
    cases h rfl
  | cons y l ih =>
    simp only [drop, length]
    by_cases h₁ : l = []
    · simp [h₁]
    rw [getLast_cons h₁]
    exact ih h₁ y","We will prove this by induction on the list \( l \).

**Base Case:**
Consider the case where \( l \) is the empty list. Since \( l \) is empty, the assumption \( l \neq [] \) leads to a contradiction. Therefore, the goal is trivially true.

**Inductive Step:**
Assume \( l \) is a non-empty list of the form \( y :: l \). We need to show that \( \text{drop}(\text{length}(l), y :: l) = [l.\text{getLast}(h)] \).

1. **Simplify the Goal:**
Using the definitions of `drop` and `length`, we simplify the goal to show that \( \text{drop}(\text{length}(l), y :: l) = [l.\text{getLast}(h)] \).

2. **Consider Two Cases:**
- **Case 1: \( l \) is the empty list.**
Using the assumption \( l = [] \), we simplify the goal to show that \( \text{drop}(\text{length}([]), y :: []) = [y] \). Since \( \text{length}([]) = 0 \), this simplifies to \( \text{drop}(0, [y]) = [y] \), which is trivially true.
- **Case 2: \( l \) is not the empty list.**
Since \( l \) is not the empty list, we use the theorem that the last element of \( y :: l \) is the same as the last element of \( l \) to rewrite the goal to \( \text{drop}(\text{length}(l), y :: l) = [l.\text{getLast}(h)] \).

3. **Apply Induction Hypothesis:**
By the induction hypothesis, if \( l \) is non-empty, then dropping the first \( \text{length}(l) \) elements from the list \( y :: l \) results in a list containing only the last element of \( l \). Therefore, \( \text{drop}(\text{length}(l), y :: l) = [l.\text{getLast}(h)] \).

This completes the proof.","theorem List.drop_length_cons {l : List α} (h : l ≠ []) (a : α) :
    (a :: l).drop l.length = [l.getLast h] := by
  induction l generalizing a with
/- Perform (structure) induction on the list \( l \) and consider the base case where \( l \) is the empty list. -/
  | nil =>
/- Consider the case where \( l \) is the empty list. Since \( l \) is empty, the assumption \( l \neq [] \) leads to a contradiction. Therefore, the goal is trivially true. -/
    cases h rfl
/- Perform (structure) induction on the list \( l \) and consider the inductive step where \( l \) is a non-empty list of the form \( y :: l \). -/
  | cons y l ih =>
/- Using the definitions of `drop` and `length`, simplify the goal to show that \( \text{drop}(\text{length}(l), y :: l) = [l.\text{getLast}(h)] \). -/
    simp only [drop, length]
/- Consider two cases: (1) Assume \( l \) is the empty list, and (2) Assume \( l \) is not the empty list. -/
    by_cases h₁ : l = []
/- First, consider the case where \( l \) is the empty list. Using the assumption \( l = [] \), simplify the goal to show that \( \text{drop}(\text{length}([]), y :: []) = [y] \). Since \( \text{length}([]) = 0 \), this simplifies to \( \text{drop}(0, [y]) = [y] \), which is trivially true. -/
    · simp [h₁]
/- Since \( l \) is not the empty list, use the theorem that the last element of \( y :: l \) is the same as the last element of \( l \) to rewrite the goal to \( \text{drop}(\text{length}(l), y :: l) = [l.\text{getLast}(h_1)] \). -/
    rw [getLast_cons h₁]
/- By the induction hypothesis, if \( l \) is non-empty, then dropping the first \( \text{length}(l) \) elements from the list \( y :: l \) results in a list containing only the last element of \( l \). Therefore, \( \text{drop}(\text{length}(l), y :: l) = [l.\text{getLast}(h_1)] \). -/
/- By the induction hypothesis, if \( l \) is non-empty, then dropping the first \( \text{length}(l) \) elements from the list \( y :: l \) results in a list containing only the last element of \( l \). Therefore, \( \text{drop}(\text{length}(l), y :: l) = [l.\text{getLast}(h_1)] \). -/
    exact ih h₁ y","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7443,List.exists_of_set,"theorem List.exists_of_set {n : Nat} {a' : α} {l : List α} (h : n < l.length) :
    ∃ l₁ l₂, l = l₁ ++ l[n] :: l₂ ∧ l₁.length = n ∧ l.set n a' = l₁ ++ a' :: l₂ := by sorry","Existence of Sublists for List Element Update : For any list \( l \) of elements of type \( \alpha \), any natural number \( n \) such that \( n < \text{length}(l) \), and any element \( a' \) of type \( \alpha \), there exist lists \( l_1 \) and \( l_2 \) such that:
- \( l = l_1 ++ l[n] :: l_2 \)
- \( \text{length}(l_1) = n \)
- \( \text{set}(n, a', l) = l_1 ++ a' :: l_2 \)","theorem List.exists_of_set {n : Nat} {a' : α} {l : List α} (h : n < l.length) :
    ∃ l₁ l₂, l = l₁ ++ l[n] :: l₂ ∧ l₁.length = n ∧ l.set n a' = l₁ ++ a' :: l₂ := by
  refine ⟨l.take n, l.drop (n + 1), ⟨by simp, ⟨length_take_of_le (Nat.le_of_lt h), ?_⟩⟩⟩
  simp [set_eq_take_append_cons_drop, h]","To prove the existence of lists \( l_1 \) and \( l_2 \) with the desired properties, we construct \( l_1 \) as the first \( n \) elements of \( l \) (i.e., \( l_1 = \text{take}(n, l) \)) and \( l_2 \) as the elements of \( l \) starting from the \( (n + 1) \)-th position (i.e., \( l_2 = \text{drop}(n + 1, l) \)).

1. **Equality of \( l \) and \( l_1 ++ l[n] :: l_2 \):**
- By the definition of \( l_1 \) and \( l_2 \), we have \( l = \text{take}(n, l) ++ l[n] :: \text{drop}(n + 1, l) \). This is trivially true by the definition of list concatenation and element retrieval.

2. **Length of \( l_1 \):**
- Since \( n < \text{length}(l) \), it follows that \( n \leq \text{length}(l) \). By the property of the `take` function, the length of the first \( n \) elements of \( l \) is \( n \). Therefore, \( \text{length}(l_1) = n \).

3. **Equality of \( \text{set}(n, a', l) \) and \( l_1 ++ a' :: l_2 \):**
- Using the property of list element update, we know that \( \text{set}(n, a', l) \) is equal to \( \text{take}(n, l) ++ a' :: \text{drop}(n + 1, l) \) if \( n < \text{length}(l) \). Since \( n < \text{length}(l) \) by assumption, this simplifies to \( \text{set}(n, a', l) = l_1 ++ a' :: l_2 \).

Thus, we have shown that there exist lists \( l_1 \) and \( l_2 \) such that \( l = l_1 ++ l[n] :: l_2 \), \( \text{length}(l_1) = n \), and \( \text{set}(n, a', l) = l_1 ++ a' :: l_2 \). This completes the proof. \(\blacksquare\)","theorem List.exists_of_set {n : Nat} {a' : α} {l : List α} (h : n < l.length) :
    ∃ l₁ l₂, l = l₁ ++ l[n] :: l₂ ∧ l₁.length = n ∧ l.set n a' = l₁ ++ a' :: l₂ := by
/- To prove the existence of lists \( l_1 \) and \( l_2 \) such that \( l = l_1 ++ l[n] :: l_2 \), \( \text{length}(l_1) = n \), and \( \text{set}(n, a', l) = l_1 ++ a' :: l_2 \), we construct \( l_1 \) as the first \( n \) elements of \( l \) (i.e., \( l_1 = \text{take}(n, l) \)) and \( l_2 \) as the elements of \( l \) starting from the \( (n + 1) \)-th position (i.e., \( l_2 = \text{drop}(n + 1, l) \)). We need to show that:
1. \( l = l_1 ++ l[n] :: l_2 \)
2. \( \text{length}(l_1) = n \)
3. \( \text{set}(n, a', l) = l_1 ++ a' :: l_2 \)

First, we simplify the expression \( l = l_1 ++ l[n] :: l_2 \) using the fact that \( l[n] \) is the \( n \)-th element of \( l \). This simplification is trivial. Next, we need to show that the length of \( l_1 \) is \( n \). Since \( n < \text{length}(l) \), it follows that \( n \leq \text{length}(l) \), and thus the length of the first \( n \) elements of \( l \) is \( n \). Finally, we need to show that \( \text{set}(n, a', l) = l_1 ++ a' :: l_2 \). -/
  refine ⟨l.take n, l.drop (n + 1), ⟨by simp, ⟨length_take_of_le (Nat.le_of_lt h), ?_⟩⟩⟩
/- Using the property of list element update, we know that \( \text{set}(n, a', l) \) is equal to \( \text{take}(n, l) ++ a' :: \text{drop}(n + 1, l) \) if \( n < \text{length}(l) \). Since we have \( n < \text{length}(l) \) by assumption, this simplifies to \( \text{set}(n, a', l) = l_1 ++ a' :: l_2 \). This completes the proof. -/
  simp [set_eq_take_append_cons_drop, h]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7446,List.zip_replicate,"theorem List.zip_replicate {a : α} {b : β} {m n : Nat} :
    zip (replicate m a) (replicate n b) = replicate (min m n) (a, b) := by sorry","Zip of Replicated Lists Equals Replicated Pairs of Minimum Length : For any types \( \alpha \) and \( \beta \), and for any elements \( a \in \alpha \) and \( b \in \beta \), and for any natural numbers \( m \) and \( n \), the zip of the list containing \( m \) copies of \( a \) and the list containing \( n \) copies of \( b \) is equal to the list containing \( \min(m, n) \) copies of the pair \((a, b)\). Mathematically, this can be expressed as:
\[ \text{replicate } m \text{ of } a \text{ zip } \text{replicate } n \text{ of } b = \text{replicate } \min(m, n) \text{ of } (a, b) \]","theorem List.zip_replicate {a : α} {b : β} {m n : Nat} :
    zip (replicate m a) (replicate n b) = replicate (min m n) (a, b) := by
  rw [zip_eq_zip_take_min]
  simp","We start by using the theorem that the zip of two lists is equal to the zip of their first \( \min(|l_1|, |l_2|) \) elements. Applying this theorem to the lists \(\text{replicate } m \text{ of } a\) and \(\text{replicate } n \text{ of } b\), we get:
\[ (\text{replicate } m \text{ of } a) \text{ zip } (\text{replicate } n \text{ of } b) = (\text{take } \min(m, n) \text{ of } (\text{replicate } m \text{ of } a)) \text{ zip } (\text{take } \min(m, n) \text{ of } (\text{replicate } n \text{ of } b)) \]

Next, we simplify the expression. Since the length of \(\text{replicate } m \text{ of } a\) is \( m \) and the length of \(\text{replicate } n \text{ of } b\) is \( n \), taking the first \(\min(m, n)\) elements of each list results in:
\[ \text{take } \min(m, n) \text{ of } (\text{replicate } m \text{ of } a) = \text{replicate } \min(m, n) \text{ of } a \]
\[ \text{take } \min(m, n) \text{ of } (\text{replicate } n \text{ of } b) = \text{replicate } \min(m, n) \text{ of } b \]

Thus, the zip of these two lists is:
\[ (\text{replicate } \min(m, n) \text{ of } a) \text{ zip } (\text{replicate } \min(m, n) \text{ of } b) = \text{replicate } \min(m, n) \text{ of } (a, b) \]

This completes the proof. \(\blacksquare\)","theorem List.zip_replicate {a : α} {b : β} {m n : Nat} :
    zip (replicate m a) (replicate n b) = replicate (min m n) (a, b) := by
/- First, we use the theorem that the zip of two lists is equal to the zip of their first \( \min(|l_1|, |l_2|) \) elements. Applying this theorem to the lists \(\text{replicate } m \text{ of } a\) and \(\text{replicate } n \text{ of } b\), we get:
\[ (\text{replicate } m \text{ of } a) \text{ zip } (\text{replicate } n \text{ of } b) = (\text{take } \min(m, n) \text{ of } (\text{replicate } m \text{ of } a)) \text{ zip } (\text{take } \min(m, n) \text{ of } (\text{replicate } n \text{ of } b)) \] -/
  rw [zip_eq_zip_take_min]
/- Next, we simplify the expression. Since the length of \(\text{replicate } m \text{ of } a\) is \( m \) and the length of \(\text{replicate } n \text{ of } b\) is \( n \), taking the first \(\min(m, n)\) elements of each list results in:
\[ \text{take } \min(m, n) \text{ of } (\text{replicate } m \text{ of } a) = \text{replicate } \min(m, n) \text{ of } a \]
\[ \text{take } \min(m, n) \text{ of } (\text{replicate } n \text{ of } b) = \text{replicate } \min(m, n) \text{ of } b \]
Thus, the zip of these two lists is:
\[ (\text{replicate } \min(m, n) \text{ of } a) \text{ zip } (\text{replicate } \min(m, n) \text{ of } b) = \text{replicate } \min(m, n) \text{ of } (a, b) \]
This completes the proof. -/
  simp","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7451,List.rotateLeft_replicate,theorem List.rotateLeft_replicate (n) (a : α) : rotateLeft (replicate m a) n = replicate m a := by sorry,"Left Rotation of a Replicated List is the List Itself : For any type $\alpha$, natural numbers $m$ and $n$, and element $a \in \alpha$, the left rotation of a list containing $m$ copies of $a$ by $n$ positions is equal to the original list, i.e., $(\text{replicate } m \, a). \text{rotateLeft } n = \text{replicate } m \, a$.","theorem List.rotateLeft_replicate (n) (a : α) : rotateLeft (replicate m a) n = replicate m a := by
  cases n with
  | zero => simp
  | succ n =>
    suffices 1 < m → m - (n + 1) % m + min ((n + 1) % m) m = m by
      simpa [rotateLeft]
    intro h
    rw [Nat.min_eq_left (Nat.le_of_lt (Nat.mod_lt _ (by omega)))]
    have : (n + 1) % m < m := Nat.mod_lt _ (by omega)
    omega","We proceed by induction on \( n \).

1. **Base Case: \( n = 0 \)**
- By the definition of left rotation, rotating a list by 0 positions results in the same list. Therefore, \((\text{replicate } m \, a). \text{rotateLeft } 0 = \text{replicate } m \, a\).

2. **Inductive Step: \( n = k + 1 \)**
- Assume \( 1 < m \). We need to show that \((\text{replicate } m \, a). \text{rotateLeft } (k + 1) = \text{replicate } m \, a\).
- By the properties of the modulo operation, \((n + 1) \% m < m\).
- Therefore, \(\min((n + 1) \% m, m) = (n + 1) \% m\).
- The goal simplifies to \( m - (n + 1) \% m + (n + 1) \% m = m \).
- Since \((n + 1) \% m < m\), the expression \( m - (n + 1) \% m + (n + 1) \% m \) simplifies to \( m \).

Thus, by induction, the left rotation of a list containing \(m\) copies of \(a\) by \(n\) positions is equal to the original list. This completes the proof. \(\blacksquare\)","theorem List.rotateLeft_replicate (n) (a : α) : rotateLeft (replicate m a) n = replicate m a := by
  cases n with
/- To prove the base case where \( n = 0 \), we simplify the expression \((\text{replicate } m \, a). \text{rotateLeft } 0\). By the definition of left rotation, rotating a list by 0 positions results in the same list. Therefore, \((\text{replicate } m \, a). \text{rotateLeft } 0 = \text{replicate } m \, a\). -/
  | zero => simp
/- We now consider the inductive step where \( n = k + 1 \). We need to show that \((\text{replicate } m \, a). \text{rotateLeft } (k + 1) = \text{replicate } m \, a\). -/
  | succ n =>
/- To prove the inductive step, it suffices to show that if \( 1 < m \), then \( m - (n + 1) \% m + \min((n + 1) \% m, m) = m \). This is because, by the definition of left rotation, the left rotation of a list by \( n + 1 \) positions can be expressed in terms of the modulo operation and the minimum function. Simplifying this expression using the properties of left rotation will complete the proof. -/
    suffices 1 < m → m - (n + 1) % m + min ((n + 1) % m) m = m by
      simpa [rotateLeft]
/- Let \( h \) be the assumption that \( 1 < m \). We need to show that \( m - (n + 1) \% m + \min((n + 1) \% m, m) = m \). -/
    intro h
/- Since \( m > 0 \) (as \( 1 < m \)), the expression \((n + 1) \% m\) is strictly less than \( m \). This is a direct consequence of the properties of the modulo operation on natural numbers. -/
    rw [Nat.min_eq_left (Nat.le_of_lt (Nat.mod_lt _ (by omega)))]
/- We construct the lemma that \((n + 1) \% m < m\) using the properties of the modulo operation and the assumption \( 1 < m \). -/
    have : (n + 1) % m < m := Nat.mod_lt _ (by omega)
/- Since \( (n + 1) \% m < m \) (by the properties of the modulo operation and the assumption \( 1 < m \)), we have \(\min((n + 1) \% m, m) = (n + 1) \% m\). Therefore, the goal simplifies to \( m - (n + 1) \% m + (n + 1) \% m = m \). -/
/- Since \((n + 1) \% m < m\), the expression \( m - (n + 1) \% m + (n + 1) \% m \) simplifies to \( m \). This completes the proof. -/
    omega","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7466,List.rotateRight_replicate,theorem List.rotateRight_replicate (n) (a : α) : rotateRight (replicate m a) n = replicate m a := by sorry,"Right Rotation of a Replicated List is the List Itself : For any type $\alpha$, natural numbers $m$ and $n$, and element $a \in \alpha$, the right rotation of a list containing $m$ copies of $a$ by $n$ positions is equal to the original list, i.e., $(\text{replicate } m \, a). \text{rotateRight } n = \text{replicate } m \, a$.","theorem List.rotateRight_replicate (n) (a : α) : rotateRight (replicate m a) n = replicate m a := by
  cases n with
  | zero => simp
  | succ n =>
    suffices 1 < m → m - (m - (n + 1) % m) + min (m - (n + 1) % m) m = m by
      simpa [rotateRight]
    intro h
    have : (n + 1) % m < m := Nat.mod_lt _ (by omega)
    rw [Nat.min_eq_left (by omega)]
    omega","We proceed by induction on \( n \).

**Base Case:**
For \( n = 0 \), we need to show that \((\text{replicate } m \, a). \text{rotateRight } 0 = \text{replicate } m \, a\). By the definition of right rotation, rotating a list by 0 positions results in the same list. Therefore, the base case holds.

**Inductive Step:**
Assume the statement holds for \( n = k \), i.e., \((\text{replicate } m \, a). \text{rotateRight } k = \text{replicate } m \, a\). We need to show that \((\text{replicate } m \, a). \text{rotateRight } (k + 1) = \text{replicate } m \, a\).

To prove this, it suffices to show that if \( 1 < m \), then:
\[
m - (m - (k + 1) \% m) + \min(m - (k + 1) \% m, m) = m
\]

First, we note that \((k + 1) \% m < m\) because \( m > 0 \) (from the assumption \( 1 < m \)). This is a direct consequence of the property of the modulo operation in natural numbers, which states that the remainder of any natural number divided by a positive natural number is less than the divisor.

Next, we use the fact that \(\min(m - (k + 1) \% m, m) = m - (k + 1) \% m\) because \( m - (k + 1) \% m \) is less than or equal to \( m \).

Thus, we need to show:
\[
m - (m - (k + 1) \% m) + (m - (k + 1) \% m) = m
\]

Simplifying the left-hand side, we get:
\[
m - (m - (k + 1) \% m) + (m - (k + 1) \% m) = m
\]

This is a straightforward equality, and thus the inductive step holds.

By induction, the theorem is proved. \(\blacksquare\)","theorem List.rotateRight_replicate (n) (a : α) : rotateRight (replicate m a) n = replicate m a := by
  cases n with
/- To prove the base case where \( n = 0 \), we use the fact that rotating a list by 0 positions results in the same list. Therefore, \((\text{replicate } m \, a). \text{rotateRight } 0 = \text{replicate } m \, a\). -/
  | zero => simp
/- We now consider the inductive step where \( n \) is a successor, i.e., \( n = k + 1 \). We need to show that \((\text{replicate } m \, a). \text{rotateRight } (k + 1) = \text{replicate } m \, a\). -/
  | succ n =>
/- To prove the inductive step, it suffices to show that if \( 1 < m \), then \( m - (m - (n + 1) \% m) + \min(m - (n + 1) \% m, m) = m \). This is because, by the definition of right rotation, the list \((\text{replicate } m \, a)\) rotated by \( n + 1 \) positions will be equal to itself if this equation holds. -/
    suffices 1 < m → m - (m - (n + 1) % m) + min (m - (n + 1) % m) m = m by
      simpa [rotateRight]
/- Let \( h \) be the assumption that \( 1 < m \). We need to show that \( m - (m - (n + 1) \% m) + \min(m - (n + 1) \% m, m) = m \). -/
    intro h
/- Since \( m > 0 \) (because \( 1 < m \)), we have \((n + 1) \% m < m\). This is a direct consequence of the property of the modulo operation in natural numbers, which states that the remainder of any natural number divided by a positive natural number is less than the divisor. -/
    have : (n + 1) % m < m := Nat.mod_lt _ (by omega)
/- Since \((n + 1) \% m < m\), we have \(\min(m - (n + 1) \% m, m) = m - (n + 1) \% m\). This is because the minimum of two numbers is the smaller one, and \( m - (n + 1) \% m \) is less than or equal to \( m \). -/
    rw [Nat.min_eq_left (by omega)]
/- We know that \((n + 1) \% m < m\) because \( m > 0 \) (from the assumption \( 1 < m \)). This is a direct consequence of the property of the modulo operation in natural numbers, which states that the remainder of any natural number divided by a positive natural number is less than the divisor. -/
/- Now, we need to show that \( m - (m - (n + 1) \% m) + (m - (n + 1) \% m) = m \). Simplifying the left-hand side, we get:
\[
m - (m - (n + 1) \% m) + (m - (n + 1) \% m) = m
\]
This is a straightforward equality, and thus the proof is complete. -/
    omega","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7476,List.length_zipWith,"theorem List.length_zipWith (f : α → β → γ) (l₁ l₂) :
    length (zipWith f l₁ l₂) = min (length l₁) (length l₂) := by sorry","Length of ZipWith Result Equals Minimum of Input List Lengths : For any lists \( l_1 \) and \( l_2 \) of types \( \alpha \) and \( \beta \) respectively, and a function \( f : \alpha \to \beta \to \gamma \), the length of the list obtained by applying `List.zipWith` to \( l_1 \) and \( l_2 \) is equal to the minimum of the lengths of \( l_1 \) and \( l_2 \). In other words, if \( l_1 = [x_1, x_2, \ldots, x_m] \) and \( l_2 = [y_1, y_2, \ldots, y_n] \), then:
\[ \text{length}(\text{zipWith } f \, l_1 \, l_2) = \min(\text{length}(l_1), \text{length}(l_2)) \]","theorem List.length_zipWith (f : α → β → γ) (l₁ l₂) :
    length (zipWith f l₁ l₂) = min (length l₁) (length l₂) := by
  induction l₁ generalizing l₂ <;> cases l₂ <;>
    simp_all [succ_min_succ, Nat.zero_min, Nat.min_zero]","We will prove this by induction on the list \( l_1 \) and consider the cases of \( l_2 \).

1. **Base Case: \( l_1 = [] \)**
- **Case 1: \( l_2 = [] \)**
\[
\text{length}(\text{zipWith } f \, [] \, []) = \text{length}([]) = 0
\]
\[
\min(\text{length}([]), \text{length}([])) = \min(0, 0) = 0
\]
Therefore, the base case holds.
- **Case 2: \( l_2 = y_1 :: y_2 :: \ldots :: y_n \)**
\[
\text{length}(\text{zipWith } f \, [] \, (y_1 :: y_2 :: \ldots :: y_n)) = \text{length}([]) = 0
\]
\[
\min(\text{length}([]), \text{length}(y_1 :: y_2 :: \ldots :: y_n)) = \min(0, n) = 0
\]
Therefore, the base case holds.

2. **Inductive Step: \( l_1 = x_1 :: x_2 :: \ldots :: x_m \)**
- **Case 1: \( l_2 = [] \)**
\[
\text{length}(\text{zipWith } f \, (x_1 :: x_2 :: \ldots :: x_m) \, []) = \text{length}([]) = 0
\]
\[
\min(\text{length}(x_1 :: x_2 :: \ldots :: x_m), \text{length}([])) = \min(m, 0) = 0
\]
Therefore, the inductive step holds.
- **Case 2: \( l_2 = y_1 :: y_2 :: \ldots :: y_n \)**
By the inductive hypothesis, we have:
\[
\text{length}(\text{zipWith } f \, (x_2 :: \ldots :: x_m) \, (y_2 :: \ldots :: y_n)) = \min(\text{length}(x_2 :: \ldots :: x_m), \text{length}(y_2 :: \ldots :: y_n))
\]
Therefore,
\[
\text{length}(\text{zipWith } f \, (x_1 :: x_2 :: \ldots :: x_m) \, (y_1 :: y_2 :: \ldots :: y_n)) = 1 + \text{length}(\text{zipWith } f \, (x_2 :: \ldots :: x_m) \, (y_2 :: \ldots :: y_n))
\]
\[
= 1 + \min(\text{length}(x_2 :: \ldots :: x_m), \text{length}(y_2 :: \ldots :: y_n))
\]
\[
= \min(1 + \text{length}(x_2 :: \ldots :: x_m), 1 + \text{length}(y_2 :: \ldots :: y_n))
\]
\[
= \min(\text{length}(x_1 :: x_2 :: \ldots :: x_m), \text{length}(y_1 :: y_2 :: \ldots :: y_n))
\]
Therefore, the inductive step holds.

By induction, the theorem is proved.","theorem List.length_zipWith (f : α → β → γ) (l₁ l₂) :
    length (zipWith f l₁ l₂) = min (length l₁) (length l₂) := by
/- We perform induction on the list \( l_1 \) and generalize over \( l_2 \). For each case of \( l_1 \), we consider the cases of \( l_2 \). Then, we simplify the goal using the properties of the minimum function and the length of lists. -/
  induction l₁ generalizing l₂ <;> cases l₂ <;>
/- We perform induction on the list \( l_1 \) to break down the proof into cases. We generalize over \( l_2 \) to ensure the inductive hypothesis is strong enough. -/
/- We consider the cases of \( l_2 \) to handle both the empty and non-empty scenarios. -/
/- We consider the cases of \( l_2 \) to handle both the empty and non-empty scenarios. -/
/- Using the properties of the minimum function and the length of lists, we simplify the goal. Specifically, we use the properties that the minimum of a number and zero is zero, and the minimum of the successors of two numbers is the successor of their minimum. -/
/- Using the properties of the minimum function and the length of lists, we simplify the goal. Specifically, we use the properties that the minimum of a number and zero is zero, and the minimum of the successors of two numbers is the successor of their minimum. -/
/- Using the properties of the minimum function and the length of lists, we simplify the goal. Specifically, we use the properties that the minimum of a number and zero is zero, and the minimum of the successors of two numbers is the successor of their minimum. -/
/- Using the properties of the minimum function and the length of lists, we simplify the goal. Specifically, we use the properties that the minimum of a number and zero is zero, and the minimum of the successors of two numbers is the successor of their minimum. -/
    simp_all [succ_min_succ, Nat.zero_min, Nat.min_zero]","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7580,List.take_add,theorem List.take_add (l : List α) (m n : Nat) : l.take (m + n) = l.take m ++ (l.drop m).take n := by sorry,"Concatenation of First \( m \) and First \( n \) Elements of a List After Dropping \( m \) Elements : For any list \( l \) of elements of type \( \alpha \) and any natural numbers \( m \) and \( n \), the first \( m + n \) elements of \( l \) are equal to the concatenation of the first \( m \) elements of \( l \) and the first \( n \) elements of the list obtained by dropping the first \( m \) elements of \( l \). In other words, \( \text{take}(m + n, l) = \text{take}(m, l) \, \text{++} \, \text{take}(n, \text{drop}(m, l)) \).","theorem List.take_add (l : List α) (m n : Nat) : l.take (m + n) = l.take m ++ (l.drop m).take n := by
  suffices take (m + n) (take m l ++ drop m l) = take m l ++ take n (drop m l) by
    rw [take_append_drop] at this
    assumption
  rw [take_append_eq_append_take, take_of_length_le, append_right_inj]
  · simp only [take_eq_take, length_take, length_drop]
    omega
  apply Nat.le_trans (m := m)
  · apply length_take_le
  · apply Nat.le_add_right","To prove the theorem, we start by noting that the first \( m + n \) elements of \( l \) can be expressed as the first \( m + n \) elements of the concatenation of the first \( m \) elements of \( l \) and the list obtained by dropping the first \( m \) elements of \( l \). This is because the concatenation of the first \( m \) elements of a list and the list obtained by dropping the first \( m \) elements is equal to the original list. Formally, we have:
\[
\text{take}(m + n, l) = \text{take}(m + n, \text{take}(m, l) \oplus \text{drop}(m, l))
\]

Next, we use the property that the first \( n \) elements of the concatenation of two lists are equal to the concatenation of the first \( n \) elements of the first list and the first \( n - \text{length}(\text{take}(m, l)) \) elements of the second list. This gives us:
\[
\text{take}(m + n, \text{take}(m, l) \oplus \text{drop}(m, l)) = \text{take}(m, l) \oplus \text{take}(m + n - \text{length}(\text{take}(m, l)), \text{drop}(m, l))
\]

We also use the property that taking the first \( i \) elements of a list is equal to the list itself if the length of the list is less than or equal to \( i \). Since the length of the first \( m \) elements of \( l \) is less than or equal to \( m \), we have:
\[
\text{take}(m, l) = \text{take}(m, l)
\]

Thus, the goal reduces to showing:
\[
\text{take}(m + n - \text{length}(\text{take}(m, l)), \text{drop}(m, l)) = \text{take}(n, \text{drop}(m, l))
\]

Using the property that the right append operation is injective, we can simplify this to:
\[
\min(m + n - \min(m, \text{length}(l)), \text{length}(l) - m) = \min(n, \text{length}(l) - m)
\]

This is a straightforward arithmetic property of natural numbers, and it holds by the properties of the minimum function and the arithmetic of natural numbers.

Finally, we need to show that the length of the first \( m \) elements of \( l \) is less than or equal to \( m + n \). This is true because the length of the first \( m \) elements of \( l \) is less than or equal to \( m \) (by the property of the length of the first \( m \) elements of a list), and \( m \) is less than or equal to \( m + n \) (by the property of addition of natural numbers).

Thus, we have shown that:
\[
\text{take}(m + n, l) = \text{take}(m, l) \oplus \text{take}(n, \text{drop}(m, l))
\]

This completes the proof. \(\blacksquare\)","theorem List.take_add (l : List α) (m n : Nat) : l.take (m + n) = l.take m ++ (l.drop m).take n := by
/- To prove that the first \( m + n \) elements of \( l \) are equal to the concatenation of the first \( m \) elements of \( l \) and the first \( n \) elements of the list obtained by dropping the first \( m \) elements of \( l \), it suffices to show that the first \( m + n \) elements of \( \text{take}(m, l) \oplus \text{drop}(m, l) \) are equal to the concatenation of the first \( m \) elements of \( l \) and the first \( n \) elements of the list obtained by dropping the first \( m \) elements of \( l \). This is because, by the property that the concatenation of the first \( n \) elements of a list and the list obtained by dropping the first \( n \) elements is equal to the original list, we can replace the original list \( l \) with \( \text{take}(m, l) \oplus \text{drop}(m, l) \). -/
  suffices take (m + n) (take m l ++ drop m l) = take m l ++ take n (drop m l) by
    rw [take_append_drop] at this
    assumption
/- Using the property that the first \( n \) elements of the concatenation of two lists are equal to the concatenation of the first \( n \) elements of the first list and the first \( n - \text{length}(\text{take}(m, l)) \) elements of the second list, and the property that taking the first \( i \) elements of a list is equal to the list itself if the length of the list is less than or equal to \( i \), and the property that the right append operation is injective, we can simplify the goal to show that the first \( m + n - \text{length}(\text{take}(m, l)) \) elements of \( \text{drop}(m, l) \) are equal to the first \( n \) elements of \( \text{drop}(m, l) \). -/
  rw [take_append_eq_append_take, take_of_length_le, append_right_inj]
/- Simplifying the goal using the properties that taking the first \( i \) elements of a list is equal to the list itself if the length of the list is less than or equal to \( i \), the length of the first \( m \) elements of a list is the minimum of \( m \) and the length of the list, and the length of the list obtained by dropping the first \( m \) elements of a list is the length of the list minus \( m \), we get that the goal is to show:
\[
\min(m + n - \min(m, \text{length}(l)), \text{length}(l) - m) = \min(n, \text{length}(l) - m)
\] -/
  · simp only [take_eq_take, length_take, length_drop]
/- The goal is to show that:
\[
\min(m + n - \min(m, \text{length}(l)), \text{length}(l) - m) = \min(n, \text{length}(l) - m)
\]
This is a straightforward arithmetic property of natural numbers, and it holds by the properties of the minimum function and the arithmetic of natural numbers. -/
    omega
/- To prove that the length of the first \( m \) elements of \( l \) is less than or equal to \( m + n \), it suffices to show that the length of the first \( m \) elements of \( l \) is less than or equal to \( m \) and that \( m \) is less than or equal to \( m + n \). -/
  apply Nat.le_trans (m := m)
/- To show that the length of the first \( m \) elements of \( l \) is less than or equal to \( m \), we use the property that the length of the first \( n \) elements of a list is less than or equal to \( n \). -/
  · apply length_take_le
/- To show that \( m \) is less than or equal to \( m + n \), we use the property that adding a non-negative number to a number preserves the order. -/
  · apply Nat.le_add_right","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
7662,Int.zero_shiftRight,theorem Int.zero_shiftRight (n : Nat) : (0 : Int) >>> n = 0 := by sorry,"Right Shift of Zero is Zero: \( 0 >>> n = 0 \) : For any natural number \( n \), the right shift of the integer \( 0 \) by \( n \) is equal to \( 0 \), i.e., \( 0 >>> n = 0 \).","theorem Int.zero_shiftRight (n : Nat) : (0 : Int) >>> n = 0 := by
  simp [Int.shiftRight_eq_div_pow]","To prove that \( 0 >>> n = 0 \) for any natural number \( n \), we use the property that the right shift of an integer \( m \) by \( n \) is equal to the integer division of \( m \) by \( 2^n \). Specifically, we have:
\[
0 >>> n = 0 / 2^n
\]
Since \( 0 \) divided by any positive integer is \( 0 \), it follows that:
\[
0 / 2^n = 0
\]
Thus, \( 0 >>> n = 0 \) for any natural number \( n \). This completes the proof.","theorem Int.zero_shiftRight (n : Nat) : (0 : Int) >>> n = 0 := by
/- Using the property that the right shift of an integer \( m \) by \( n \) is equal to the integer division of \( m \) by \( 2^n \), we can simplify the proposition \( 0 >>> n = 0 \) to \( 0 / 2^n = 0 \). Since \( 0 \) divided by any positive integer is \( 0 \), the proposition is trivially true. -/
  simp [Int.shiftRight_eq_div_pow]","import Init.Data.Nat.Bitwise.Lemmas
import Init.Data.Int.Bitwise
import Init.Data.Int.Bitwise.Lemmas

open Int

"
7879,List.take_append_eq_append_take,"theorem List.take_append_eq_append_take {l₁ l₂ : List α} {n : Nat} :
    take n (l₁ ++ l₂) = take n l₁ ++ take (n - l₁.length) l₂ := by sorry","Taking First \( n \) Elements of Concatenated Lists Equals Concatenation of First \( n \) Elements of Each List and Remaining Elements of Second List : For any type \(\alpha\), any lists \(l_1\) and \(l_2\) of elements of type \(\alpha\), and any natural number \(n\), the first \(n\) elements of the concatenation \(l_1 ++ l_2\) are equal to the concatenation of the first \(n\) elements of \(l_1\) and the first \(n - l_1.\text{length}\) elements of \(l_2\). Formally, this can be written as:
\[
\text{take } n \, (l_1 ++ l_2) = \text{take } n \, l_1 ++ \text{take } (n - \text{length } l_1) \, l_2
\]","theorem List.take_append_eq_append_take {l₁ l₂ : List α} {n : Nat} :
    take n (l₁ ++ l₂) = take n l₁ ++ take (n - l₁.length) l₂ := by
  induction l₁ generalizing n
  · simp
  · cases n
    · simp [*]
    · simp only [cons_append, take_succ_cons, length_cons, succ_eq_add_one, cons.injEq,
        append_cancel_left_eq, true_and, *]
      congr 1
      omega","We perform induction on the list \( l_1 \).

**Base Case:**
For \( l_1 = [] \), we need to show:
\[
\text{take } n \, ([] ++ l_2) = \text{take } n \, [] ++ \text{take } (n - \text{length } []) \, l_2
\]
Simplifying both sides, we get:
\[
\text{take } n \, l_2 = \text{take } n \, [] ++ \text{take } n \, l_2
\]
Since \(\text{take } n \, [] = []\), the right-hand side simplifies to:
\[
[] ++ \text{take } n \, l_2 = \text{take } n \, l_2
\]
Thus, the base case is trivially true.

**Inductive Step:**
Assume \( l_1 = \text{head} :: \text{tail} \). We need to show:
\[
\text{take } n \, (\text{head} :: \text{tail} ++ l_2) = \text{take } n \, (\text{head} :: \text{tail}) ++ \text{take } (n - \text{length } (\text{head} :: \text{tail})) \, l_2
\]
We will consider two cases for \( n \).

**Case 1: \( n = 0 \)**
We need to show:
\[
\text{take } 0 \, (\text{head} :: \text{tail} ++ l_2) = \text{take } 0 \, (\text{head} :: \text{tail}) ++ \text{take } (0 - \text{length } (\text{head} :: \text{tail})) \, l_2
\]
Simplifying both sides, we get:
\[
[] = [] ++ \text{take } (-1) \, l_2
\]
Since \(\text{take } (-1) \, l_2 = []\), the right-hand side simplifies to:
\[
[] = []
\]
Thus, the case \( n = 0 \) is trivially true.

**Case 2: \( n = m + 1 \)**
We need to show:
\[
\text{take } (m + 1) \, (\text{head} :: \text{tail} ++ l_2) = \text{take } (m + 1) \, (\text{head} :: \text{tail}) ++ \text{take } (m + 1 - \text{length } (\text{head} :: \text{tail})) \, l_2
\]
Using the properties of list concatenation and taking the first \( m + 1 \) elements, we simplify the goal to:
\[
\text{take } (m - \text{length } \text{tail}) \, l_2 = \text{take } (m + 1 - (\text{length } \text{tail} + 1)) \, l_2
\]
Simplifying the right-hand side, we get:
\[
\text{take } (m - \text{length } \text{tail}) \, l_2 = \text{take } (m - \text{length } \text{tail}) \, l_2
\]
Thus, the inductive step is proven.

By induction, the theorem holds for all lists \( l_1 \) and \( l_2 \) and all natural numbers \( n \). This completes the proof. \(\blacksquare\)","theorem List.take_append_eq_append_take {l₁ l₂ : List α} {n : Nat} :
    take n (l₁ ++ l₂) = take n l₁ ++ take (n - l₁.length) l₂ := by
/- We perform induction on the list \( l_1 \) to break down the proof into cases. For the base case, we consider \( l_1 = [] \). For the inductive step, we assume \( l_1 = \text{head} :: \text{tail} \) and introduce the inductive hypothesis that for any natural number \( n \), \(\text{take } n \, (\text{tail} ++ l_2) = \text{take } n \, \text{tail} ++ \text{take } (n - \text{length } \text{tail}) \, l_2\). -/
  induction l₁ generalizing n
/- First, we show that for the base case \( l_1 = [] \), the proposition \(\text{take } n \, ([] ++ l_2) = \text{take } n \, [] ++ \text{take } (n - \text{length } []) \, l_2\) holds. Simplifying the left-hand side, we get \(\text{take } n \, l_2\). Simplifying the right-hand side, we get \(\text{take } n \, [] ++ \text{take } n \, l_2\), which is \(\text{take } n \, l_2\). Therefore, the base case is trivially true. -/
  · simp
/- We will discuss every possible case of \( n \). Case 1: \( n = 0 \). Case 2: \( n = m + 1 \) for some natural number \( m \). -/
  · cases n
/- For the case \( n = 0 \), we simplify the goal \(\text{take } 0 \, (\text{head} :: \text{tail} ++ l_2) = \text{take } 0 \, (\text{head} :: \text{tail}) ++ \text{take } (0 - (\text{length } (\text{head} :: \text{tail}))) \, l_2\). Simplifying both sides, we get \([] = [] ++ \text{take } (-1) \, l_2\), which is \([] = []\). Therefore, the case \( n = 0 \) is trivially true. -/
    · simp [*]
/- For the case \( n = m + 1 \), we simplify the goal \(\text{take } (m + 1) \, (\text{head} :: \text{tail} ++ l_2) = \text{take } (m + 1) \, (\text{head} :: \text{tail}) ++ \text{take } (m + 1 - (\text{length } (\text{head} :: \text{tail}))) \, l_2\). Using the properties of list concatenation, taking the first \( m + 1 \) elements, and the length of a list, we simplify the goal to \(\text{take } (m - \text{length } \text{tail}) \, l_2 = \text{take } (m + 1 - (\text{length } \text{tail} + 1)) \, l_2\). -/
    · simp only [cons_append, take_succ_cons, length_cons, succ_eq_add_one, cons.injEq,
        append_cancel_left_eq, true_and, *]
/- To establish the equality \(\text{take } (m - \text{length } \text{tail}) \, l_2 = \text{take } (m + 1 - (\text{length } \text{tail} + 1)) \, l_2\), we can decompose it to prove that \( m - \text{length } \text{tail} = m + 1 - (\text{length } \text{tail} + 1) \). -/
      congr 1
/- The equality \( m - \text{length } \text{tail} = m + 1 - (\text{length } \text{tail} + 1) \) simplifies to \( m - \text{length } \text{tail} = m - \text{length } \text{tail} \), which is trivially true. Therefore, the inductive step is proven. -/
      omega","import Init.Data.List.Zip
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.TakeDrop

open List
open Nat
"
8141,String.Iterator.sizeOf_next_lt_of_hasNext,theorem String.Iterator.sizeOf_next_lt_of_hasNext (i : String.Iterator) (h : i.hasNext) : sizeOf i.next < sizeOf i := by sorry,"Size of Next Iterator Position is Less Than Current Size if Iterator has Next Position : For any string iterator \( i \), if \( i \) has a next position (i.e., \( i.\text{hasNext} = \text{true} \)), then the size of the next position of the iterator is strictly less than the size of the current position, i.e., \(\text{sizeOf}(i.\text{next}) < \text{sizeOf}(i)\).","theorem String.Iterator.sizeOf_next_lt_of_hasNext (i : String.Iterator) (h : i.hasNext) : sizeOf i.next < sizeOf i := by
  cases i; rename_i s pos; simp [Iterator.next, Iterator.sizeOf_eq]; simp [Iterator.hasNext] at h
  exact Nat.sub_lt_sub_left h (String.lt_next s pos)","We start by considering the structure of the string iterator \( i \). By breaking down \( i \) into its components, we can rename the string and the position within the string as \( s \) and \( pos \), respectively. The goal is to show that the size of the next position of the iterator is less than the size of the current position, i.e., \(\text{sizeOf}(i.\text{next}) < \text{sizeOf}(i)\).

Using the definitions of `Iterator.next` and `Iterator.sizeOf_eq`, we simplify the goal to:
\[
s.\text{utf8ByteSize} - (s.\text{next}(pos)).\text{byteIdx} < s.\text{utf8ByteSize} - pos.\text{byteIdx}
\]

We also simplify the hypothesis \( h \) using the definition of `Iterator.hasNext`, which tells us that:
\[
pos.\text{byteIdx} < s.\text{endPos}.\text{byteIdx}
\]

Next, we use the theorem `String.lt_next`, which states that for any valid byte position \( pos \) in the string \( s \), the byte index of \( pos \) is strictly less than the byte index of the next valid byte position \( s.\text{next}(pos) \):
\[
pos.\text{byteIdx} < (s.\text{next}(pos)).\text{byteIdx}
\]

Given that \( pos.\text{byteIdx} < s.\text{endPos}.\text{byteIdx} \), we can apply the theorem `Nat.sub_lt_sub_left` to conclude:
\[
s.\text{utf8ByteSize} - (s.\text{next}(pos)).\text{byteIdx} < s.\text{utf8ByteSize} - pos.\text{byteIdx}
\]

Thus, the size of the next position of the iterator is strictly less than the size of the current position. This completes the proof. \(\blacksquare\)","theorem String.Iterator.sizeOf_next_lt_of_hasNext (i : String.Iterator) (h : i.hasNext) : sizeOf i.next < sizeOf i := by
/- We consider the structure of the string iterator \( i \). By breaking down \( i \) into its components, we can rename the string and the position within the string as \( s \) and \( pos \), respectively. Using the definitions of `Iterator.next` and `Iterator.sizeOf_eq`, we simplify the goal to show that the size of the next position of the iterator is less than the size of the current position. We also simplify the hypothesis \( h \) using the definition of `Iterator.hasNext`, which tells us that \( pos.byteIdx < s.endPos.byteIdx \). -/
  cases i; rename_i s pos; simp [Iterator.next, Iterator.sizeOf_eq]; simp [Iterator.hasNext] at h
/- We use the fact that the byte index of the current position \( pos \) is strictly less than the byte index of the next position \( s.next(pos) \) (i.e., \( pos.byteIdx < (s.next(pos)).byteIdx \)). This is given by the theorem `String.lt_next`. Since \( pos.byteIdx < s.endPos.byteIdx \) (from the hypothesis \( h \)), we can apply the theorem `Nat.sub_lt_sub_left` to conclude that \( s.utf8ByteSize - (s.next(pos)).byteIdx < s.utf8ByteSize - pos.byteIdx \). This completes the proof. -/
  exact Nat.sub_lt_sub_left h (String.lt_next s pos)","import Init.Data.ByteArray
import Init.Data.String.Extra

open String
open Iterator

"
8147,String.size_toUTF8,theorem String.size_toUTF8 (s : String) : s.toUTF8.size = s.utf8ByteSize := by sorry,"UTF-8 Encoding Size Equality for Strings : For any string \( s \), the size of the byte array obtained by converting \( s \) to its UTF-8 encoding is equal to the UTF-8 byte size of \( s \). In other words, the number of bytes in the UTF-8 representation of \( s \) is the same as the result of the function `String.utf8ByteSize` applied to \( s \).","theorem String.size_toUTF8 (s : String) : s.toUTF8.size = s.utf8ByteSize := by
  simp [toUTF8, ByteArray.size, Array.size, utf8ByteSize, List.bind]
  induction s.data <;> simp [List.map, List.join, utf8ByteSize.go, Nat.add_comm, *]","We start by using the definitions of the functions involved to simplify the goal. Specifically, we use the definitions of `toUTF8`, `ByteArray.size`, `Array.size`, `utf8ByteSize`, and `List.bind` to transform the goal from \( s.toUTF8.size = s.utf8ByteSize \) to \( (\text{List.map utf8EncodeChar } s.data).join.length = \text{utf8ByteSize.go } s.data \).

Next, we perform induction on the list of characters `s.data` to break down the proof into cases.

**Base Case:**
For the base case, where `s.data` is the empty list, we need to show that the length of the concatenated list of byte sequences for the empty list is zero. This is trivially true because the length of the empty list is zero, and the total number of UTF-8 bytes required to encode the empty list is also zero.

**Inductive Step:**
For the inductive step, assume the inductive hypothesis that for any list `tail` of characters, the length of the concatenated list of byte sequences for `tail` is equal to the total number of UTF-8 bytes required to encode `tail`. We need to show that for a list `head :: tail`, the length of the concatenated list of byte sequences for `head :: tail` is equal to the total number of UTF-8 bytes required to encode `head :: tail`.

Using the definitions of `List.map`, `List.join`, `utf8ByteSize.go`, and the commutativity of addition, we simplify the goal. Specifically, we have:
\[
(\text{List.map utf8EncodeChar } (head :: tail)).join.length = (\text{utf8EncodeChar head} ++ (\text{List.map utf8EncodeChar } tail).join).length
\]
By the definition of `List.join` and the length of concatenated lists, this is equal to:
\[
\text{utf8EncodeChar head.length} + (\text{List.map utf8EncodeChar } tail).join.length
\]
By the inductive hypothesis, we know that:
\[
(\text{List.map utf8EncodeChar } tail).join.length = \text{utf8ByteSize.go } tail
\]
Thus, we have:
\[
\text{utf8EncodeChar head.length} + \text{utf8ByteSize.go } tail
\]
By the definition of `utf8ByteSize.go`, this is equal to:
\[
\text{utf8ByteSize.go } (head :: tail)
\]
Therefore, the length of the concatenated list of byte sequences for `head :: tail` is equal to the total number of UTF-8 bytes required to encode `head :: tail`.

This completes the proof. \(\blacksquare\)","theorem String.size_toUTF8 (s : String) : s.toUTF8.size = s.utf8ByteSize := by
/- Using the definitions of `toUTF8`, `ByteArray.size`, `Array.size`, `utf8ByteSize`, and `List.bind`, we simplify the proposition we want to show. This simplification transforms the goal from \( s.toUTF8.size = s.utf8ByteSize \) to \( (\text{List.map utf8EncodeChar } s.data).join.length = \text{utf8ByteSize.go } s.data \). -/
  simp [toUTF8, ByteArray.size, Array.size, utf8ByteSize, List.bind]
/- We perform induction on the list of characters `s.data` to break down the proof into cases. For the base case, where `s.data` is the empty list, we need to show that the length of the concatenated list of byte sequences for the empty list is zero, which is trivially true. For the inductive step, assume the inductive hypothesis that for any list `tail` of characters, the length of the concatenated list of byte sequences for `tail` is equal to the total number of UTF-8 bytes required to encode `tail`. We need to show that for a list `head :: tail`, the length of the concatenated list of byte sequences for `head :: tail` is equal to the total number of UTF-8 bytes required to encode `head :: tail`. Using the definitions of `List.map`, `List.join`, `utf8ByteSize.go`, and the commutativity of addition, we simplify the goal and use the inductive hypothesis to complete the proof. -/
  induction s.data <;> simp [List.map, List.join, utf8ByteSize.go, Nat.add_comm, *]","import Init.Data.ByteArray
import Init.Data.String.Extra

open String

"
8333,Nat.Simproc.eq_add_gt,theorem Nat.Simproc.eq_add_gt (a : Nat) {b c : Nat} (h : c > a) : (a = b + c) = False := by sorry,"Contradiction of \(a = b + c\) when \(c > a\) in Natural Numbers : For any natural numbers \(a\), \(b\), and \(c\), if \(c > a\), then the equation \(a = b + c\) is false, i.e., \(a = b + c\) is a contradiction.","theorem Nat.Simproc.eq_add_gt (a : Nat) {b c : Nat} (h : c > a) : (a = b + c) = False := by
  rw [@Eq.comm Nat a (b + c)]
  exact add_eq_gt b h","We start with the assumption that \(c > a\). To prove that \(a = b + c\) is false, we first use the symmetry of the equality relation to rewrite the equation \(a = b + c\) as \(b + c = a\). Therefore, it suffices to show that \(b + c = a\) is false.

We use the fact that for any natural numbers \(a\), \(b\), and \(c\), if \(c > a\), then \(a + c = b\) is false. Since we have \(c > a\), it follows that \(b + c = a\) is false. This completes the proof. \(\blacksquare\)","theorem Nat.Simproc.eq_add_gt (a : Nat) {b c : Nat} (h : c > a) : (a = b + c) = False := by
/- Since the equality relation is symmetric, we can rewrite the goal \(a = b + c\) as \(b + c = a\). Therefore, it suffices to show that \(b + c = a\) is false. -/
  rw [@Eq.comm Nat a (b + c)]
/- We use the fact that for any natural numbers \(a\), \(b\), and \(c\), if \(c > a\), then \(a + c = b\) is false. Since we have \(c > a\), it follows that \(b + c = a\) is false. This completes the proof. -/
  exact add_eq_gt b h","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
8338,Nat.Simproc.bneTrueOfEqFalse,theorem Nat.Simproc.bneTrueOfEqFalse {a b : Nat} (p : (a = b) = False) : (a != b) = true := by sorry,"Boolean Not-Equal is True if Equality is False in Natural Numbers : For any natural numbers \(a\) and \(b\), if \(a = b\) is false, then \(a \neq b\) is true.","theorem Nat.Simproc.bneTrueOfEqFalse {a b : Nat} (p : (a = b) = False) : (a != b) = true := by
  simp [bne, beqFalseOfEqFalse p]","We start with the assumption that \(a = b\) is false. By the definition of the boolean not-equal function `bne`, \(a \neq b\) is true if and only if \(a == b\) is false. According to the theorem that if \(a = b\) is false, then \(a == b\) is also false, we have that \(a == b\) is false. Therefore, \(a \neq b\) is true. This completes the proof.","theorem Nat.Simproc.bneTrueOfEqFalse {a b : Nat} (p : (a = b) = False) : (a != b) = true := by
/- Using the definition of the boolean not-equal function `bne` and the fact that if \(a = b\) is false, then \(a == b\) is also false, we can simplify the proposition we want to show to \((a \neq b) = \text{true}\). -/
  simp [bne, beqFalseOfEqFalse p]","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
8342,Nat.Simproc.beqFalseOfEqFalse,theorem Nat.Simproc.beqFalseOfEqFalse {a b : Nat} (p : (a = b) = False) : (a == b) = false := by sorry,"Boolean Equality is False if Standard Equality is False in Natural Numbers : For any natural numbers \(a\) and \(b\), if the equality \(a = b\) is false, then the boolean equality \(a == b\) is also false.","theorem Nat.Simproc.beqFalseOfEqFalse {a b : Nat} (p : (a = b) = False) : (a == b) = false := by
  simp [Bool.beq_eq_decide_eq, p]","We start with the assumption that the equality \(a = b\) is false. We need to show that the boolean equality \(a == b\) is also false.

By the definition of boolean equality, \(a == b\) is equivalent to the boolean value obtained by deciding the proposition \(a = b\), i.e., \(a == b = \text{decide}(a = b)\). Given that \(a = b\) is false, the boolean value \(\text{decide}(a = b)\) is \(\text{false}\). Therefore, \((a == b) = \text{false}\).

This completes the proof.","theorem Nat.Simproc.beqFalseOfEqFalse {a b : Nat} (p : (a = b) = False) : (a == b) = false := by
/- Using the fact that the boolean equality \(a == b\) is equivalent to the boolean value obtained by deciding the proposition \(a = b\) (i.e., \(a == b = \text{decide}(a = b)\)), and given that \(a = b\) is false, we can simplify the proposition we want to show to \((a == b) = \text{false}\). Since \(\text{decide}(a = b)\) is \(\text{false}\) when \(a = b\) is false, it follows that \((a == b) = \text{false}\). -/
  simp [Bool.beq_eq_decide_eq, p]","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
8346,Nat.Simproc.bneEqOfEqEq,theorem Nat.Simproc.bneEqOfEqEq {a b c d : Nat} (p : (a = b) = (c = d)) : (a != b) = (c != d) := by sorry,"Boolean Not-Equal Equivalence in Natural Numbers: \(a \neq b \leftrightarrow c \neq d\) if \(a = b \leftrightarrow c = d\) : For any natural numbers \(a\), \(b\), \(c\), and \(d\), if the equality \(a = b\) is equivalent to the equality \(c = d\), then the boolean not-equal relation \(a \neq b\) is equivalent to the boolean not-equal relation \(c \neq d\).","theorem Nat.Simproc.bneEqOfEqEq {a b c d : Nat} (p : (a = b) = (c = d)) : (a != b) = (c != d) := by
  simp only [bne, beqEqOfEqEq p]","We start with the given assumption that the equality \(a = b\) is equivalent to the equality \(c = d\). This means that \(a = b\) if and only if \(c = d\).

To prove that the boolean not-equal relation \(a \neq b\) is equivalent to the boolean not-equal relation \(c \neq d\), we use the definition of the boolean not-equal function `bne`. The function `bne` returns `true` if the two inputs are not equal and `false` otherwise. Formally, \(a \neq b\) is defined as the negation of \(a == b\), and similarly, \(c \neq d\) is defined as the negation of \(c == d\).

Given the theorem that if \(a = b\) is equivalent to \(c = d\), then \(a == b\) is equivalent to \(c == d\), we can use this to simplify our goal. Since \(a == b\) is equivalent to \(c == d\), the negation of \(a == b\) (which is \(a \neq b\)) must be equivalent to the negation of \(c == d\) (which is \(c \neq d\)).

Therefore, we have shown that \((a \neq b) = (c \neq d)\). This completes the proof.","theorem Nat.Simproc.bneEqOfEqEq {a b c d : Nat} (p : (a = b) = (c = d)) : (a != b) = (c != d) := by
/- Using the definition of the boolean not-equal function `bne` and the theorem that if \(a = b\) is equivalent to \(c = d\), then \(a == b\) is equivalent to \(c == d\), we can simplify the proposition we want to show to \((a \neq b) = (c \neq d)\). -/
  simp only [bne, beqEqOfEqEq p]","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
8347,Nat.Simproc.eq_add_le,theorem Nat.Simproc.eq_add_le {a : Nat} (b : Nat) {c : Nat} (h : c ≤ a) : (a = b + c) = (b = a - c) := by sorry,"Equation of Addition and Subtraction in Natural Numbers: \(a = b + c \leftrightarrow b = a - c\) when \(c \leq a\) : For any natural numbers \(a\), \(b\), and \(c\), if \(c \leq a\), then the equation \(a = b + c\) holds if and only if \(b = a - c\).","theorem Nat.Simproc.eq_add_le {a : Nat} (b : Nat) {c : Nat} (h : c ≤ a) : (a = b + c) = (b = a - c) := by
  rw [@Eq.comm Nat a (b + c)]
  exact add_eq_le b h","We start with the goal of proving that \(a = b + c\) is equivalent to \(b = a - c\) under the assumption that \(c \leq a\).

1. **Symmetry of Equality:**
Since the equality relation is symmetric, we can rewrite the goal \(a = b + c\) as \(b + c = a\). Therefore, it suffices to show that \(b + c = a\) is equivalent to \(b = a - c\).

2. **Application of a Known Theorem:**
We use the theorem that for any natural numbers \(a\), \(b\), and \(c\), if \(b \leq c\), then \(a + b = c\) holds if and only if \(a = c - b\). In our case, we have \(c \leq a\), so we can apply this theorem directly.

Specifically, the theorem states that \(b + c = a\) if and only if \(b = a - c\).

Thus, the proof is complete, and we have shown that \(a = b + c\) if and only if \(b = a - c\) when \(c \leq a\).","theorem Nat.Simproc.eq_add_le {a : Nat} (b : Nat) {c : Nat} (h : c ≤ a) : (a = b + c) = (b = a - c) := by
/- Since the equality relation is symmetric, we can rewrite the goal \(a = b + c\) as \(b + c = a\). Therefore, it suffices to show that \(b + c = a\) is equivalent to \(b = a - c\). -/
  rw [@Eq.comm Nat a (b + c)]
/- The current goal \(b + c = a\) is equivalent to \(b = a - c\) is exactly proved by the theorem that for any natural numbers \(a\), \(b\), and \(c\), if \(b \leq c\), then \(a + b = c\) holds if and only if \(a = c - b\). Since we have the assumption \(c \leq a\), this theorem directly applies, and the proof is complete. -/
  exact add_eq_le b h","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
8350,Nat.Simproc.beqEqOfEqEq,theorem Nat.Simproc.beqEqOfEqEq {a b c d : Nat} (p : (a = b) = (c = d)) : (a == b) = (c == d) := by sorry,"Boolean Equality Preservation: \(a = b \leftrightarrow c = d \implies a == b \leftrightarrow c == d\) : For any natural numbers \(a\), \(b\), \(c\), and \(d\), if the equality \(a = b\) is equivalent to the equality \(c = d\), then the boolean equality \(a == b\) is equivalent to the boolean equality \(c == d\).","theorem Nat.Simproc.beqEqOfEqEq {a b c d : Nat} (p : (a = b) = (c = d)) : (a == b) = (c == d) := by
  simp only [Bool.beq_eq_decide_eq, p]","We start with the given hypothesis that the equality \(a = b\) is equivalent to the equality \(c = d\), i.e., \((a = b) = (c = d)\). We need to show that the boolean equality \(a == b\) is equivalent to the boolean equality \(c == d\), i.e., \((a == b) = (c == d)\).

Using the fact that the boolean equality \(a == b\) is equivalent to the boolean value obtained by deciding the proposition \(a = b\) (i.e., \(a == b = \text{decide}(a = b)\)), we can rewrite the goal as \(\text{decide}(a = b) = \text{decide}(c = d)\).

Given the hypothesis \((a = b) = (c = d)\), it follows that \(\text{decide}(a = b) = \text{decide}(c = d)\) because the decision function \(\text{decide}\) is a function that maps equal propositions to equal boolean values. Therefore, \((a == b) = (c == d)\) holds true.

This completes the proof.","theorem Nat.Simproc.beqEqOfEqEq {a b c d : Nat} (p : (a = b) = (c = d)) : (a == b) = (c == d) := by
/- Using the fact that the boolean equality \(a == b\) is equivalent to the boolean value obtained by deciding the proposition \(a = b\) (i.e., \(a == b = \text{decide}(a = b)\)), and the given hypothesis \( (a = b) = (c = d) \), we can simplify the goal to show that \(\text{decide}(a = b) = \text{decide}(c = d)\). Since \(\text{decide}(a = b) = \text{decide}(c = d)\) is exactly the same as \((a == b) = (c == d)\), the goal is trivially satisfied. -/
  simp only [Bool.beq_eq_decide_eq, p]","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
8351,Nat.Simproc.add_eq_add_ge,theorem Nat.Simproc.add_eq_add_ge (a c : Nat) {b d : Nat} (h : b ≥ d) : (a + b = c + d) = (a + (b - d) = c) := by sorry,"Addition and Subtraction Identity: \(a + b = c + d \leftrightarrow a + (b - d) = c\) for \(b \geq d\) : For any natural numbers \(a\), \(c\), \(b\), and \(d\), if \(b \geq d\), then the equation \(a + b = c + d\) holds if and only if \(a + (b - d) = c\).","theorem Nat.Simproc.add_eq_add_ge (a c : Nat) {b d : Nat} (h : b ≥ d) : (a + b = c + d) = (a + (b - d) = c) := by
  rw [@Eq.comm _ (a + b) _, add_eq_add_le c a h, @Eq.comm _ _ c]","We start with the goal of proving that \(a + b = c + d\) if and only if \(a + (b - d) = c\) under the condition that \(b \geq d\).

1. **Symmetry of Equality:**
We use the symmetry of equality to rewrite the goal from \(a + b = c + d\) to \(c + d = a + b\).

2. **Application of Theorem:**
We apply the theorem that states for any natural numbers \(a\), \(c\), \(b\), and \(d\), if \(b \geq d\), then \(a + b = c + d\) is equivalent to \(a + (b - d) = c\). This theorem is valid because it leverages the properties of natural numbers and the definition of subtraction.

3. **Symmetry of Equality:**
We use the symmetry of equality again to rewrite the goal from \(c = a + (b - d)\) to \(a + (b - d) = c\).

Since the goal is now trivially true, the proof is complete. Therefore, we have shown that \(a + b = c + d\) if and only if \(a + (b - d) = c\) for \(b \geq d\).","theorem Nat.Simproc.add_eq_add_ge (a c : Nat) {b d : Nat} (h : b ≥ d) : (a + b = c + d) = (a + (b - d) = c) := by
/- First, we use the symmetry of equality to rewrite the goal from \(a + b = c + d\) to \(c + d = a + b\). Then, we apply the theorem that states for any natural numbers \(a\), \(c\), \(b\), and \(d\), if \(b \geq d\), then \(a + b = c + d\) is equivalent to \(a + (b - d) = c\). Finally, we use the symmetry of equality again to rewrite the goal from \(c = a + (b - d)\) to \(a + (b - d) = c\). This completes the proof. -/
  rw [@Eq.comm _ (a + b) _, add_eq_add_le c a h, @Eq.comm _ _ c]","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
8355,Nat.Simproc.add_le_add_le,theorem Nat.Simproc.add_le_add_le (a c : Nat) {b d : Nat} (h : b ≤ d) : (a + b ≤ c + d) = (a ≤ c + (d - b)) := by sorry,"Addition Preserves Inequality in Natural Numbers: \(a + b \leq c + d \leftrightarrow a \leq c + (d - b)\) : For any natural numbers \(a\), \(c\), \(b\), and \(d\) such that \(b \leq d\), the inequality \(a + b \leq c + d\) holds if and only if \(a \leq c + (d - b)\).","theorem Nat.Simproc.add_le_add_le (a c : Nat) {b d : Nat} (h : b ≤ d) : (a + b ≤ c + d) = (a ≤ c + (d - b)) := by
  rw [← Nat.add_sub_assoc h, Nat.le_sub_iff_add_le]
  exact Nat.le_trans h (le_add_left d c)","We start by using the associativity of addition and subtraction in natural numbers. Given the hypothesis \( b \leq d \), we can rewrite the inequality \( a + b \leq c + d \) as \( a \leq c + (d - b) \). This is because the equation \( a + b \leq c + d \) is equivalent to \( a \leq c + (d - b) \) by the properties of addition and subtraction in natural numbers.

Next, we need to show that \( b \leq c + d \). We use the transitivity of the less-than-or-equal-to relation. Since \( b \leq d \) (by the hypothesis \( h \)) and \( d \leq c + d \) (by the property that adding a non-negative number to another number does not decrease it), we conclude that \( b \leq c + d \).

Therefore, the inequality \( a + b \leq c + d \) holds if and only if \( a \leq c + (d - b) \). This completes the proof. \(\blacksquare\)","theorem Nat.Simproc.add_le_add_le (a c : Nat) {b d : Nat} (h : b ≤ d) : (a + b ≤ c + d) = (a ≤ c + (d - b)) := by
/- First, we use the associativity of addition and subtraction to rewrite the goal. Specifically, since \( b \leq d \), we have \( a + b \leq c + d \) if and only if \( a \leq c + (d - b) \). This is because \( a + b \leq c + d \) is equivalent to \( a \leq c + (d - b) \) by the properties of addition and subtraction in natural numbers. -/
  rw [← Nat.add_sub_assoc h, Nat.le_sub_iff_add_le]
/- To prove \( b \leq c + d \), we use the transitivity of the less-than-or-equal-to relation. Since \( b \leq d \) (by the hypothesis \( h \)) and \( d \leq c + d \) (by the property that adding a non-negative number to another number does not decrease it), we conclude that \( b \leq c + d \). This completes the proof. -/
  exact Nat.le_trans h (le_add_left d c)","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
8357,Nat.Simproc.add_le_le,theorem Nat.Simproc.add_le_le (a : Nat) {b c : Nat} (h : b ≤ c) : (a + b ≤ c) = (a ≤ c - b) := by sorry,"Addition and Subtraction in Inequality: \( a + b \leq c \) if and only if \( a \leq c - b \) : For any natural numbers \( a, b, \) and \( c \), if \( b \leq c \), then the inequality \( a + b \leq c \) holds if and only if \( a \leq c - b \).","theorem Nat.Simproc.add_le_le (a : Nat) {b c : Nat} (h : b ≤ c) : (a + b ≤ c) = (a ≤ c - b) := by
  have r := add_le_add_le a 0 h
  simp only [Nat.zero_add] at r
  exact r","We start by using the lemma that for any natural numbers \(a\), \(c\), \(b\), and \(d\) such that \(b \leq d\), the inequality \(a + b \leq c + d\) holds if and only if \(a \leq c + (d - b)\). Applying this lemma with \(a\), \(0\), and \(h : b \leq c\), we get the intermediate result:
\[
(a + b \leq 0 + c) = (a \leq 0 + (c - b))
\]

Next, we simplify this intermediate result using the property that the sum of zero and any natural number \(a\) is equal to \(a\). This simplification transforms the intermediate result into:
\[
(a + b \leq c) = (a \leq c - b)
\]

Thus, the current goal \( (a + b \leq c) = (a \leq c - b) \) is exactly proved by the simplified intermediate result. This completes the proof. \(\blacksquare\)","theorem Nat.Simproc.add_le_le (a : Nat) {b c : Nat} (h : b ≤ c) : (a + b ≤ c) = (a ≤ c - b) := by
/- First, we use the lemma that for any natural numbers \(a\), \(c\), \(b\), and \(d\) such that \(b \leq d\), the inequality \(a + b \leq c + d\) holds if and only if \(a \leq c + (d - b)\). Applying this lemma with \(a\), \(0\), and \(h : b \leq c\), we get the intermediate result \( (a + b \leq 0 + c) = (a \leq 0 + (c - b)) \). -/
  have r := add_le_add_le a 0 h
/- Next, we simplify the intermediate result using the property that the sum of zero and any natural number \(a\) is equal to \(a\). This simplification transforms the intermediate result \( (a + b \leq 0 + c) = (a \leq 0 + (c - b)) \) into \( (a + b \leq c) = (a \leq c - b) \). -/
  simp only [Nat.zero_add] at r
/- Finally, the current goal \( (a + b \leq c) = (a \leq c - b) \) is exactly proved by the simplified intermediate result \( r \). -/
  exact r","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
8366,Nat.Simproc.add_le_add_ge,theorem Nat.Simproc.add_le_add_ge (a c : Nat) {b d : Nat} (h : b ≥ d) : (a + b ≤ c + d) = (a + (b - d) ≤ c) := by sorry,"Right Subtraction Preserves Inequality in Natural Numbers: \(a + b \leq c + d \leftrightarrow a + (b - d) \leq c\) : For any natural numbers \(a\) and \(c\), and for any natural numbers \(b\) and \(d\) such that \(b \geq d\), the inequality \(a + b \leq c + d\) holds if and only if \(a + (b - d) \leq c\).","theorem Nat.Simproc.add_le_add_ge (a c : Nat) {b d : Nat} (h : b ≥ d) : (a + b ≤ c + d) = (a + (b - d) ≤ c) := by
  rw [← Nat.add_sub_assoc h, Nat.sub_le_iff_le_add]","We start with the given inequality \(a + b \leq c + d\) and the condition \(b \geq d\). We need to show that this inequality holds if and only if \(a + (b - d) \leq c\).

1. **Step 1: Apply the associativity of addition and subtraction.**
By the associativity of addition and subtraction in natural numbers, we have:
\[
a + b - d = a + (b - d)
\]
Therefore, the inequality \(a + b \leq c + d\) can be rewritten as:
\[
a + (b - d) \leq c + d
\]

2. **Step 2: Apply the property of inequalities involving subtraction.**
Using the property of inequalities involving subtraction, which states that \(a - c \leq b\) if and only if \(a \leq b + c\), we can rewrite the inequality \(a + (b - d) \leq c + d\) as:
\[
a + (b - d) \leq c
\]

Thus, we have shown that \(a + b \leq c + d\) if and only if \(a + (b - d) \leq c\). This completes the proof. \(\blacksquare\)","theorem Nat.Simproc.add_le_add_ge (a c : Nat) {b d : Nat} (h : b ≥ d) : (a + b ≤ c + d) = (a + (b - d) ≤ c) := by
/- First, we use the associativity of addition and subtraction in natural numbers, which states that \( a + b - c = a + (b - c) \). Applying this to our goal, we can rewrite \( a + b \leq c + d \) as \( a + (b - d) \leq c + d \). Next, we use the property of inequalities involving subtraction, which states that \( a - c \leq b \) if and only if \( a \leq b + c \). Applying this, we can rewrite \( a + (b - d) \leq c + d \) as \( a + b - d \leq c \). Therefore, the original goal \( a + b \leq c + d \) is equivalent to \( a + (b - d) \leq c \). -/
  rw [← Nat.add_sub_assoc h, Nat.sub_le_iff_le_add]","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
8370,Nat.Simproc.add_eq_add_le,theorem Nat.Simproc.add_eq_add_le (a c : Nat) {b d : Nat} (h : b ≤ d) : (a + b = c + d) = (a = c + (d - b)) := by sorry,"Equation \(a + b = c + d\) Implies \(a = c + (d - b)\) in Natural Numbers : For any natural numbers \(a\), \(c\), \(b\), and \(d\), if \(b \leq d\), then the equation \(a + b = c + d\) holds if and only if \(a = c + (d - b)\).","theorem Nat.Simproc.add_eq_add_le (a c : Nat) {b d : Nat} (h : b ≤ d) : (a + b = c + d) = (a = c + (d - b)) := by
  have g : b ≤ c + d := Nat.le_trans h (le_add_left d c)
  rw [← Nat.add_sub_assoc h, @Eq.comm _ a, Nat.sub_eq_iff_eq_add g, @Eq.comm _ (a + b)]","To prove the theorem, we start by constructing a new lemma \( g \) that states \( b \leq c + d \). This follows from the transitivity of the less than or equal to relation, using the given hypothesis \( h : b \leq d \) and the fact that \( d \leq d + c \) (since adding a non-negative number to \( d \) does not decrease it).

Next, we rewrite the goal step by step using the following theorems:
1. Since the associativity of addition and subtraction holds, \( a + b - d = a + (b - d) \).
2. By the symmetry of equality, \( a + b = c + d \) is equivalent to \( c + d = a + b \).
3. Using the lemma \( g : b \leq c + d \), we know that \( c + d - b = a \) if and only if \( c + d = a + b \).
4. Again, by the symmetry of equality, \( c + d = a + b \) is equivalent to \( a + b = c + d \).

Thus, the goal \( (a + b = c + d) = (a = c + (d - b)) \) is equivalent to \( (a + b = c + d) = (a + b = c + d) \), which is trivially true. Therefore, the theorem is proved. \(\blacksquare\)","theorem Nat.Simproc.add_eq_add_le (a c : Nat) {b d : Nat} (h : b ≤ d) : (a + b = c + d) = (a = c + (d - b)) := by
/- First, we construct a new lemma \( g \) that states \( b \leq c + d \). This follows from the transitivity of the less than or equal to relation, using the given hypothesis \( h : b \leq d \) and the fact that \( d \leq d + c \) (since adding a non-negative number to \( d \) does not decrease it). -/
  have g : b ≤ c + d := Nat.le_trans h (le_add_left d c)
/- Next, we rewrite the goal step by step using the following theorems:
1. Since the associativity of addition and subtraction holds, \( a + b - d = a + (b - d) \).
2. By the symmetry of equality, \( a + b = c + d \) is equivalent to \( c + d = a + b \).
3. Using the lemma \( g : b \leq c + d \), we know that \( c + d - b = a \) if and only if \( c + d = a + b \).
4. Again, by the symmetry of equality, \( c + d = a + b \) is equivalent to \( a + b = c + d \).

Thus, the goal \( (a + b = c + d) = (a = c + (d - b)) \) is equivalent to \( (a + b = c + d) = (a + b = c + d) \), which is trivially true. -/
  rw [← Nat.add_sub_assoc h, @Eq.comm _ a, Nat.sub_eq_iff_eq_add g, @Eq.comm _ (a + b)]","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
8394,Nat.Simproc.add_sub_add_le,theorem Nat.Simproc.add_sub_add_le (a c : Nat) {b d : Nat} (h : b ≤ d) : a + b - (c + d) = a - (c + (d-b)) := by sorry,"Addition and Subtraction with Inequality in Natural Numbers: \(a + b - (c + d) = a - (c + (d - b))\) : For any natural numbers \(a\), \(c\), \(b\), and \(d\) such that \(b \leq d\), the equation \(a + b - (c + d) = a - (c + (d - b))\) holds.","theorem Nat.Simproc.add_sub_add_le (a c : Nat) {b d : Nat} (h : b ≤ d) : a + b - (c + d) = a - (c + (d-b)) := by
  induction b generalizing a c d with
  | zero =>
    simp
  | succ b ind =>
    match d with
    | 0 =>
      contradiction
    | d + 1 =>
      have g := Nat.le_of_succ_le_succ h
      rw [Nat.add_succ a, Nat.add_succ c, Nat.succ_sub_succ, Nat.succ_sub_succ,
          ind _ _ g]","We prove the theorem by induction on \(b\).

1. **Base Case: \(b = 0\)**

When \(b = 0\), the goal is to show that \(a + 0 - (c + d) = a - (c + (d - 0))\). Simplifying, we get:
\[
a - (c + d) = a - (c + d)
\]
which is trivially true.

2. **Inductive Step: \(b = b' + 1\)**

Assume the statement holds for \(b = b'\), i.e., \(a + b' - (c + d) = a - (c + (d - b'))\). We need to show that \(a + (b' + 1) - (c + d) = a - (c + (d - (b' + 1)))\).

- **Case 1: \(d = 0\)**

The goal is to show that \(a + (b' + 1) - (c + 0) = a - (c + (0 - (b' + 1)))\). This simplifies to:
\[
a + (b' + 1) - c = a - (c - (b' + 1))
\]
Since \(b' + 1 \leq 0\) is a contradiction (as \(b' + 1\) is a positive natural number), this case is vacuously true.

- **Case 2: \(d = d' + 1\)**

The goal is to show that \(a + (b' + 1) - (c + (d' + 1)) = a - (c + ((d' + 1) - (b' + 1)))\). Using the properties of natural numbers, we rewrite the goal:
\[
a + (b' + 1) - (c + (d' + 1)) = a - (c + (d' - b'))
\]
By the inductive hypothesis, we know that \(a + b' - (c + d') = a - (c + (d' - b'))\). Therefore, the goal simplifies to:
\[
a + (b' + 1) - (c + (d' + 1)) = a + b' - (c + d')
\]
which is true by the inductive hypothesis.

Thus, by induction, the theorem holds for all natural numbers \(a\), \(c\), \(b\), and \(d\) such that \(b \leq d\). This completes the proof. \(\blacksquare\)","theorem Nat.Simproc.add_sub_add_le (a c : Nat) {b d : Nat} (h : b ≤ d) : a + b - (c + d) = a - (c + (d-b)) := by
  induction b generalizing a c d with
/- We perform induction on \(b\) and consider the base case where \(b = 0\). In this case, the goal is to show that \(a + 0 - (c + d) = a - (c + (d - 0))\). -/
  | zero =>
/- Simplifying the expression, we get \(a - (c + d) = a - (c + d)\), which is trivially true. -/
    simp
/- We consider the inductive step where \(b = b' + 1\) for some \(b'\). The goal is to show that \(a + (b' + 1) - (c + d) = a - (c + (d - (b' + 1)))\). -/
  | succ b ind =>
    match d with
/- We consider the case where \(d = 0\). The goal is to show that \(a + (b + 1) - (c + 0) = a - (c + (0 - (b + 1)))\). -/
    | 0 =>
/- We get a direct contradiction from the assumption \(b + 1 \leq 0\), which is impossible since \(b + 1\) is a positive natural number. Therefore, this case is vacuously true. -/
      contradiction
/- We consider the case where \(d = d' + 1\) for some \(d'\). The goal is to show that \(a + (b + 1) - (c + (d' + 1)) = a - (c + ((d' + 1) - (b + 1)))\). -/
    | d + 1 =>
/- We construct a new hypothesis \(g\) that \(b \leq d'\) from the given hypothesis \(b + 1 \leq d' + 1\). -/
      have g := Nat.le_of_succ_le_succ h
/- We use the properties of natural numbers to rewrite the goal. Specifically, we use the fact that adding the successor of a number is the same as adding 1 and then taking the successor, and the fact that subtracting the successor of a number is the same as subtracting the number itself. After these rewrites, the goal simplifies to \(a + b - (c + d) = a - (c + (d - b))\). -/
      rw [Nat.add_succ a, Nat.add_succ c, Nat.succ_sub_succ, Nat.succ_sub_succ,
/- We use the properties of natural numbers to rewrite the goal. Specifically, we use the fact that adding the successor of a number is the same as adding 1 and then taking the successor, and the fact that subtracting the successor of a number is the same as subtracting the number itself. After these rewrites, the goal simplifies to \(a + b - (c + d') = a - (c + (d' - b))\), which is true by the inductive hypothesis. -/
          ind _ _ g]","import Init.Data.Bool
import Init.Data.Nat.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc

open Nat
open Simproc

"
9055,List.map_get_sublist,"theorem List.map_get_sublist {l : List α} {is : List (Fin l.length)} (h : is.Pairwise (·.val < ·.val)) :
    is.map (get l) <+ l := by sorry","Mapping Increasing Indices to List Elements Produces a Sublist : For any list \( l \) of elements of type \( \alpha \) and any list \( is \) of indices in the range \( 0 \leq i < \text{length}(l) \), if the indices in \( is \) are pairwise strictly increasing, then the list obtained by mapping the function `l.get` over \( is \) is a sublist of \( l \). Formally, if \( is \) is a list of indices such that for all \( x, x_1 \in is \), \( x < x_1 \), then \( \text{List.map} \, l.get \, is \) is a sublist of \( l \).","theorem List.map_get_sublist {l : List α} {is : List (Fin l.length)} (h : is.Pairwise (·.val < ·.val)) :
    is.map (get l) <+ l := by
  simpa using map_getElem_sublist h","We need to show that \( \text{List.map} \, l.get \, is \) is a sublist of \( l \). Given that the indices in \( is \) are pairwise strictly increasing, we can use the theorem that states if the indices in a list \( is \) are pairwise strictly increasing, then the list obtained by mapping the function \( l[i] \) over \( is \) is a sublist of \( l \). Since \( h \) is a proof that the indices in \( is \) are pairwise strictly increasing, we can directly apply this theorem to conclude that \( \text{List.map} \, l.get \, is \) is indeed a sublist of \( l \). This completes the proof.","theorem List.map_get_sublist {l : List α} {is : List (Fin l.length)} (h : is.Pairwise (·.val < ·.val)) :
    is.map (get l) <+ l := by
/- Using the theorem that states if the indices in a list \( is \) are pairwise strictly increasing, then the list obtained by mapping the function \( l[i] \) over \( is \) is a sublist of \( l \), we can simplify our goal. Specifically, we need to show that \( \text{List.map} \, l.get \, is \) is a sublist of \( l \). Since \( h \) is a proof that the indices in \( is \) are pairwise strictly increasing, we can directly apply this theorem to conclude that \( \text{List.map} \, l.get \, is \) is indeed a sublist of \( l \). This completes the proof. -/
  simpa using map_getElem_sublist h","import Init.Data.Fin.Lemmas
import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Pairwise

open List

"
9083,List.sublist_eq_map_get,"theorem List.sublist_eq_map_get (h : l' <+ l) : ∃ is : List (Fin l.length),
    l' = map (get l) is ∧ is.Pairwise (· < ·) := by sorry","Sublist Equals to Map of Get with Strictly Increasing Indices : For any lists \( l' \) and \( l \) of elements of type \( \alpha \), if \( l' \) is a sublist of \( l \), then there exists a sequence of indices \( is \) such that \( l' \) is equal to the list obtained by applying the function `l.get` to each index in \( is \), and the indices in \( is \) are strictly increasing. Formally, if \( l' \) is a sublist of \( l \), then there exists a sequence of indices \( is \) such that \( l' = \text{List.map } (l.\text{get}) \, is \) and \( \text{List.Pairwise } (fun \, x \, x_1 \, => \, x < x_1) \, is \).","theorem List.sublist_eq_map_get (h : l' <+ l) : ∃ is : List (Fin l.length),
    l' = map (get l) is ∧ is.Pairwise (· < ·) := by
  simpa using sublist_eq_map_getElem h","To prove the theorem, we start with the hypothesis that \( l' \) is a sublist of \( l \). By the theorem that if \( l' \) is a sublist of \( l \), then there exists a sequence of indices \( is \) such that \( l' \) is equal to the list obtained by applying the function \( l[x] \) to each index in \( is \), and the indices in \( is \) are strictly increasing, we can simplify our goal. Specifically, using the hypothesis \( h \) that \( l' \) is a sublist of \( l \), we can show that there exists a sequence of indices \( is \) such that \( l' = \text{List.map } (l.\text{get}) \, is \) and \( \text{List.Pairwise } (fun \, x \, x_1 \, => \, x < x_1) \, is \). This completes the proof.","theorem List.sublist_eq_map_get (h : l' <+ l) : ∃ is : List (Fin l.length),
    l' = map (get l) is ∧ is.Pairwise (· < ·) := by
/- Using the theorem that if \( l' \) is a sublist of \( l \), then there exists a sequence of indices \( is \) such that \( l' \) is equal to the list obtained by applying the function \( l[x] \) to each index in \( is \), and the indices in \( is \) are strictly increasing, we can simplify the goal. Specifically, we use the hypothesis \( h \) that \( l' \) is a sublist of \( l \) to show that there exists a sequence of indices \( is \) such that \( l' = \text{List.map } (l.\text{get}) \, is \) and \( \text{List.Pairwise } (fun \, x \, x_1 \, => \, x < x_1) \, is \). This completes the proof. -/
  simpa using sublist_eq_map_getElem h","import Init.Data.Fin.Lemmas
import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Pairwise

open List

"
9124,List.map_getElem_sublist,"theorem List.map_getElem_sublist {l : List α} {is : List (Fin l.length)} (h : is.Pairwise (· < ·)) :
    is.map (l[·]) <+ l := by sorry","Mapping Increasing Indices to List Elements Produces a Sublist: \(\text{List.map} \, (l[i]) \, is \subseteq l\) : For any list \( l \) of elements of type \( \alpha \) and any list \( is \) of indices in the range \( 0 \leq i < \text{length}(l) \), if the indices in \( is \) are pairwise strictly increasing, then the list obtained by mapping the function \( l[i] \) over \( is \) is a sublist of \( l \). Formally, if \( is \) is a list of indices such that for all \( x, x_1 \in is \), \( x < x_1 \), then \( \text{List.map} \, (l[i]) \, is \) is a sublist of \( l \).","theorem List.map_getElem_sublist {l : List α} {is : List (Fin l.length)} (h : is.Pairwise (· < ·)) :
    is.map (l[·]) <+ l := by
  suffices ∀ n l', l' = l.drop n → (∀ i ∈ is, n ≤ i) → map (l[·]) is <+ l'
    from this 0 l (by simp) (by simp)
  rintro n l' rfl his
  induction is generalizing n with
  | nil => simp
  | cons hd tl IH =>
    simp only [Fin.getElem_fin, map_cons]
    have := IH h.of_cons (hd+1) (pairwise_cons.mp h).1
    specialize his hd (.head _)
    have := (drop_eq_getElem_cons ..).symm ▸ this.cons₂ (get l hd)
    have := Sublist.append (nil_sublist (take hd l |>.drop n)) this
    rwa [nil_append, ← (drop_append_of_le_length ?_), take_append_drop] at this
    simp [Nat.min_eq_left (Nat.le_of_lt hd.isLt), his]","To prove that the list obtained by mapping the function \( l[i] \) over \( is \) is a sublist of \( l \), we proceed by induction on the structure of \( is \).

1. **Base Case:**
- If \( is \) is the empty list, then the list obtained by mapping \( l[i] \) over \( is \) is the empty list, which is trivially a sublist of any list \( l \).

2. **Inductive Step:**
- Assume \( is \) is a non-empty list, let \( hd \) be the head of \( is \) and \( tl \) be the tail of \( is \).
- By the inductive hypothesis, for any natural number \( n \) and any list \( l' \) of elements of type \( \alpha \), if \( l' = \text{drop}(n, l) \) and for all \( i \in tl \), \( n \leq i \), then the list obtained by mapping \( l[i] \) over \( tl \) is a sublist of \( l' \).
- We need to show that \( l[hd] :: \text{map}(l[i], tl) \) is a sublist of \( \text{drop}(n, l) \).
- Using the property that dropping the first \( n \) elements of \( l \) is equivalent to taking the \( n \)-th element of \( l \) followed by dropping the first \( n + 1 \) elements of \( l \), we can show that \( l[hd] :: \text{map}(l[i], tl) \) is a sublist of \( \text{drop}(hd, l) \).
- Since the empty list is a sublist of any list, and the list obtained by taking the first \( hd \) elements of \( l \) and dropping the first \( n \) elements of \( l \) is a sublist of \( \text{drop}(n, l) \), we can show that \( l[hd] :: \text{map}(l[i], tl) \) is a sublist of \( \text{drop}(n, l) \).
- Using the property that the minimum of two natural numbers is the left number if the left number is less than or equal to the right number, and the fact that \( n \leq hd \), we can simplify the goal to show that \( n \leq \text{length}(\text{take}(hd, l)) \), which is true by the definition of \( \text{take} \).

Thus, we have shown that the list obtained by mapping \( l[i] \) over \( is \) is a sublist of \( l \). This completes the proof. \(\blacksquare\)","theorem List.map_getElem_sublist {l : List α} {is : List (Fin l.length)} (h : is.Pairwise (· < ·)) :
    is.map (l[·]) <+ l := by
/- To prove that the list obtained by mapping the function \( l[i] \) over \( is \) is a sublist of \( l \), it suffices to show that for any natural number \( n \) and any list \( l' \) of elements of type \( \alpha \), if \( l' \) is the list obtained by dropping the first \( n \) elements of \( l \) and for all \( i \in is \), \( n \leq i \), then the list obtained by mapping \( l[i] \) over \( is \) is a sublist of \( l' \). This is because, by simplifying the goal, we can show that \( l = \text{drop}(0, l) \) and \( \forall i \in is, 0 \leq i \). -/
  suffices ∀ n l', l' = l.drop n → (∀ i ∈ is, n ≤ i) → map (l[·]) is <+ l'
    from this 0 l (by simp) (by simp)
/- Let \( n \) be a natural number and \( l' \) be a list of elements of type \( \alpha \). Assume \( l' = \text{drop}(n, l) \) and for all \( i \in is \), \( n \leq i \). We need to show that the list obtained by mapping \( l[i] \) over \( is \) is a sublist of \( l' \). -/
  rintro n l' rfl his
  induction is generalizing n with
/- If \( is \) is the empty list, then the list obtained by mapping \( l[i] \) over \( is \) is the empty list, which is trivially a sublist of any list \( l' \). -/
  | nil => simp
/- If \( is \) is a non-empty list, let \( hd \) be the head of \( is \) and \( tl \) be the tail of \( is \). Assume the inductive hypothesis that for any natural number \( n \) and any list \( l' \) of elements of type \( \alpha \), if \( l' = \text{drop}(n, l) \) and for all \( i \in tl \), \( n \leq i \), then the list obtained by mapping \( l[i] \) over \( tl \) is a sublist of \( l' \). -/
  | cons hd tl IH =>
/- Using the definition of element retrieval from a list and the definition of mapping a function over a list, we can simplify the goal to show that \( l[hd] :: \text{map}(l[i], tl) \) is a sublist of \( \text{drop}(n, l) \). -/
    simp only [Fin.getElem_fin, map_cons]
/- By the inductive hypothesis, since \( h \) is a pairwise strictly increasing relation on \( is \), and \( h \) holds for the tail \( tl \) of \( is \), we have that the list obtained by mapping \( l[i] \) over \( tl \) is a sublist of \( \text{drop}(hd + 1, l) \). -/
    have := IH h.of_cons (hd+1) (pairwise_cons.mp h).1
/- Since \( hd \) is the head of \( is \), we have \( n \leq hd \). -/
    specialize his hd (.head _)
/- Using the property that dropping the first \( n \) elements of \( l \) is equivalent to taking the \( n \)-th element of \( l \) followed by dropping the first \( n + 1 \) elements of \( l \), we can show that \( l[hd] :: \text{map}(l[i], tl) \) is a sublist of \( \text{drop}(hd, l) \). -/
    have := (drop_eq_getElem_cons ..).symm ▸ this.cons₂ (get l hd)
/- Since the empty list is a sublist of any list, and the list obtained by taking the first \( hd \) elements of \( l \) and dropping the first \( n \) elements of \( l \) is a sublist of \( \text{drop}(n, l) \), we can show that \( l[hd] :: \text{map}(l[i], tl) \) is a sublist of \( \text{drop}(n, l) \). -/
    have := Sublist.append (nil_sublist (take hd l |>.drop n)) this
/- Using the properties of concatenation and the fact that dropping the first \( n \) elements of a list is equivalent to concatenating the first \( n \) elements and the remaining elements, we can simplify the goal to show that \( l[hd] :: \text{map}(l[i], tl) \) is a sublist of \( \text{drop}(n, l) \). -/
    rwa [nil_append, ← (drop_append_of_le_length ?_), take_append_drop] at this
/- Using the property that the minimum of two natural numbers is the left number if the left number is less than or equal to the right number, and the fact that \( n \leq hd \), we can simplify the goal to show that \( n \leq \text{length}(\text{take}(hd, l)) \), which is true by the definition of \( \text{take} \). -/
    simp [Nat.min_eq_left (Nat.le_of_lt hd.isLt), his]","import Init.Data.Fin.Lemmas
import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Pairwise

open List

"
9130,List.pairwise_iff_getElem,"theorem List.pairwise_iff_getElem : Pairwise R l ↔
    ∀ (i j : Nat) (_hi : i < l.length) (_hj : j < l.length) (_hij : i < j), R l[i] l[j] := by sorry","Pairwise Relation on List Elements via Indices : For any type \( \alpha \), a relation \( R \) on \( \alpha \), and a list \( l \) of elements of type \( \alpha \), the predicate `List.Pairwise R l` holds if and only if for all natural numbers \( i \) and \( j \) such that \( i < j \), and both \( i \) and \( j \) are valid indices for the list \( l \) (i.e., \( i < l.\text{length} \) and \( j < l.\text{length} \)), the relation \( R \) holds between the elements at these indices in the list, i.e., \( R \, l[i] \, l[j] \).","theorem List.pairwise_iff_getElem : Pairwise R l ↔
    ∀ (i j : Nat) (_hi : i < l.length) (_hj : j < l.length) (_hij : i < j), R l[i] l[j] := by
  rw [pairwise_iff_forall_sublist]
  constructor <;> intro h
  · intros i j hi hj h'
    apply h
    simpa [h'] using map_getElem_sublist (is := [⟨i, hi⟩, ⟨j, hj⟩])
  · intros a b h'
    have ⟨is, h', hij⟩ := sublist_eq_map_getElem h'
    rcases is with ⟨⟩ | ⟨a', ⟨⟩ | ⟨b', ⟨⟩⟩⟩ <;> simp at h'
    rcases h' with ⟨rfl, rfl⟩
    apply h; simpa using hij","To prove the equivalence, we need to show both directions.

1. **Forward Direction:**
- Assume the pairwise relation on the list \( l \) holds, i.e., \( \text{List.Pairwise } R \, l \).
- We need to show that for all \( i, j \) such that \( i < j \) and both \( i \) and \( j \) are valid indices for the list \( l \), the relation \( R \, l[i] \, l[j] \) holds.
- Fix arbitrary natural numbers \( i \) and \( j \) such that \( i < j \) and both \( i \) and \( j \) are valid indices for the list \( l \).
- By the hypothesis \( \text{List.Pairwise } R \, l \), it suffices to show that \([l[i], l[j]]\) is a sublist of \( l \).
- Using the lemma that the list obtained by mapping the function \( l[x] \) over the indices \([i, j]\) is a sublist of \( l \), we have \([l[i], l[j]]\) is a sublist of \( l \).
- Therefore, \( R \, l[i] \, l[j] \) holds.

2. **Backward Direction:**
- Assume for all \( i, j \) such that \( i < j \) and both \( i \) and \( j \) are valid indices for the list \( l \), the relation \( R \, l[i] \, l[j] \) holds.
- We need to show that the pairwise relation on the list \( l \) holds, i.e., \( \text{List.Pairwise } R \, l \).
- Fix arbitrary elements \( a \) and \( b \) in the list \( l \) such that \([a, b]\) is a sublist of \( l \).
- By the lemma, there exists a sequence of indices \( is \) such that \([a, b] = \text{List.map } (fun \, x \, => \, l[x]) \, is \) and the indices in \( is \) are strictly increasing.
- Consider the cases for the sequence of indices \( is \):
- If \( is \) is empty, the goal is trivial.
- If \( is \) has one element \( a' \), the goal is also trivial.
- If \( is \) has two elements \( a' \) and \( b' \), we have \( a = l[↑a'] \) and \( b = l[↑b'] \).
- Using the hypothesis that for all \( i, j \) such that \( i < j \) and both \( i \) and \( j \) are valid indices for the list \( l \), the relation \( R \, l[i] \, l[j] \) holds, and since \( a' < b' \), it follows that \( R \, a \, b \).
- Therefore, \( \text{List.Pairwise } R \, l \) holds.

This completes the proof. \(\blacksquare\)","theorem List.pairwise_iff_getElem : Pairwise R l ↔
    ∀ (i j : Nat) (_hi : i < l.length) (_hj : j < l.length) (_hij : i < j), R l[i] l[j] := by
/- First, we use the equivalence that the pairwise relation on a list \( l \) holds if and only if for all elements \( a \) and \( b \) in \( l \), the sublist \([a, b]\) is a sublist of \( l \) and the relation \( R a b \) holds. This transforms our goal into showing that for all \( i, j \) such that \( i < j \) and both \( i \) and \( j \) are valid indices for the list \( l \), the relation \( R l[i] l[j] \) holds. -/
  rw [pairwise_iff_forall_sublist]
/- To prove the equivalence, we need to show both directions. We start by proving the forward direction: if the pairwise relation on the list \( l \) holds, then for all \( i, j \) such that \( i < j \) and both \( i \) and \( j \) are valid indices for the list \( l \), the relation \( R l[i] l[j] \) holds. We introduce a hypothesis \( h \) that the pairwise relation on the list \( l \) holds. For the backward direction, we introduce a hypothesis \( h \) that for all \( i, j \) such that \( i < j \) and both \( i \) and \( j \) are valid indices for the list \( l \), the relation \( R l[i] l[j] \) holds. -/
  constructor <;> intro h
/- For the forward direction, we fix arbitrary natural numbers \( i \) and \( j \) such that \( i < j \), and both \( i \) and \( j \) are valid indices for the list \( l \). We need to show that \( R l[i] l[j] \) holds. -/
  · intros i j hi hj h'
/- To show \( R l[i] l[j] \), we use the hypothesis \( h \) that the pairwise relation on the list \( l \) holds. It suffices to show that \([l[i], l[j]]\) is a sublist of \( l \). -/
    apply h
/- We use the lemma that the list obtained by mapping the function \( l[x] \) over the indices \([i, j]\) is a sublist of \( l \). Since \( i < j \) and both \( i \) and \( j \) are valid indices, the list \([l[i], l[j]]\) is a sublist of \( l \). This completes the proof for the forward direction. -/
    simpa [h'] using map_getElem_sublist (is := [⟨i, hi⟩, ⟨j, hj⟩])
/- For the backward direction, we fix arbitrary elements \( a \) and \( b \) in the list \( l \) such that \([a, b]\) is a sublist of \( l \). We need to show that \( R a b \) holds. -/
  · intros a b h'
/- We use the lemma that if \([a, b]\) is a sublist of \( l \), then there exists a sequence of indices \( is \) such that \([a, b] = \text{List.map } (fun \, x \, => \, l[x]) \, is \) and the indices in \( is \) are strictly increasing. We denote this sequence of indices as \( is \), and the fact that \([a, b] = \text{List.map } (fun \, x \, => \, l[x]) \, is \) as \( h' \), and the fact that the indices in \( is \) are strictly increasing as \( hij \). -/
    have ⟨is, h', hij⟩ := sublist_eq_map_getElem h'
/- We consider the cases for the sequence of indices \( is \). If \( is \) is empty, the goal is trivial. If \( is \) has one element \( a' \), the goal is also trivial. If \( is \) has two elements \( a' \) and \( b' \), we simplify the hypothesis \( h' \) to get \( a = l[↑a'] \) and \( b = l[↑b'] \). -/
    rcases is with ⟨⟩ | ⟨a', ⟨⟩ | ⟨b', ⟨⟩⟩⟩ <;> simp at h'
/- We simplify the hypothesis \( h' \) to get \( a = l[↑a'] \) and \( b = l[↑b'] \). -/
    rcases h' with ⟨rfl, rfl⟩
/- To show \( R a b \), we use the hypothesis \( h \) that for all \( i, j \) such that \( i < j \) and both \( i \) and \( j \) are valid indices for the list \( l \), the relation \( R l[i] l[j] \) holds. Since \( a = l[↑a'] \) and \( b = l[↑b'] \), and \( a' < b' \) by \( hij \), it follows that \( R a b \). This completes the proof for the backward direction. -/
    apply h; simpa using hij","import Init.Data.Fin.Lemmas
import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Pairwise

open List

"
10932,List.getElem_append_left,theorem List.getElem_append_left (as bs : List α) (h : i < as.length) {h'} : (as ++ bs)[i] = as[i] := by sorry,"Element at Index in Concatenated List Equals Element in First List: \((as ++ bs)[i] = as[i]\) : For any type \( \alpha \), any natural number \( i \), and any lists \( as \) and \( bs \) of elements of type \( \alpha \), if \( i \) is less than the length of \( as \) and \( i \) is less than the length of the concatenated list \( as ++ bs \), then the element at index \( i \) in the concatenated list \( as ++ bs \) is equal to the element at index \( i \) in the list \( as \). In other words, if \( i \) is an index within the bounds of \( as \), then \((as ++ bs)[i] = as[i]\).","theorem List.getElem_append_left (as bs : List α) (h : i < as.length) {h'} : (as ++ bs)[i] = as[i] := by
  induction as generalizing i with
  | nil => trivial
  | cons a as ih =>
    cases i with
    | zero => rfl
    | succ i => apply ih","We will prove this by induction on the list \( as \).

1. **Base Case:**
- Consider the case where \( as \) is the empty list, i.e., \( as = [] \).
- The goal is to show that \(([] ++ bs)[i] = [][i]\).
- Since the empty list has no elements, the index \( i \) must be out of bounds, and the goal is trivially true.

2. **Inductive Step:**
- Assume \( as \) is a non-empty list, i.e., \( as = a :: as' \) for some element \( a \) and list \( as' \).
- We will use induction on the length of \( as \).
- The induction hypothesis \( ih \) states that for any natural number \( i \) and any lists \( as' \) and \( bs \), if \( i < \text{length}(as') \) and \( i < \text{length}(as' ++ bs) \), then \((as' ++ bs)[i] = as'[i]\).

- **Base Case of Induction:**
- Consider \( i = 0 \).
- We need to show that \((a :: as ++ bs)[0] = (a :: as)[0]\).
- By the definition of list concatenation and indexing, both sides of the equation are equal to \( a \).
- Therefore, the goal is trivially true due to the reflexive property of equality.

- **Inductive Step of Induction:**
- Consider \( i = k + 1 \) for some natural number \( k \).
- We need to show that \((a :: as ++ bs)[k + 1] = (a :: as)[k + 1]\).
- By the induction hypothesis \( ih \), it suffices to show that \((as ++ bs)[k] = as[k]\).
- Since \( k < \text{length}(as) \) and \( k < \text{length}(as ++ bs) \), the induction hypothesis applies, and the goal is proved.

Thus, by induction, the theorem is proved. \(\blacksquare\)","theorem List.getElem_append_left (as bs : List α) (h : i < as.length) {h'} : (as ++ bs)[i] = as[i] := by
  induction as generalizing i with
/- First, consider the case where the list \( as \) is empty. In this case, the goal is to show that \(([] ++ bs)[i] = [][i]\). Since the empty list has no elements, the index \( i \) must be out of bounds, and the goal is trivially true. -/
  | nil => trivial
/- Next, consider the case where the list \( as \) is non-empty, i.e., \( as = a :: as' \) for some element \( a \) and list \( as' \). We will use induction on the length of \( as \). The induction hypothesis \( ih \) states that for any natural number \( i \) and any lists \( as' \) and \( bs \), if \( i < \text{length}(as') \) and \( i < \text{length}(as' ++ bs) \), then \((as' ++ bs)[i] = as'[i]\). -/
  | cons a as ih =>
    cases i with
/- For the base case of the induction, consider \( i = 0 \). We need to show that \((a :: as ++ bs)[0] = (a :: as)[0]\). By the definition of list concatenation and indexing, both sides of the equation are equal to \( a \). Therefore, the goal is trivially true due to the reflexive property of equality. -/
    | zero => rfl
/- For the inductive step, consider \( i = k + 1 \) for some natural number \( k \). We need to show that \((a :: as ++ bs)[k + 1] = (a :: as)[k + 1]\). By the induction hypothesis \( ih \), it suffices to show that \((as ++ bs)[k] = as[k]\). Since \( k < \text{length}(as) \) and \( k < \text{length}(as ++ bs) \), the induction hypothesis applies, and the goal is proved. -/
    | succ i => apply ih","import Init.Data.Nat.Linear
import Init.Data.List.BasicAux

open List

"
10942,List.append_cancel_right_eq,theorem List.append_cancel_right_eq (as bs cs : List α) : (as ++ bs = cs ++ bs) = (as = cs) := by sorry,"Right Cancellation of List Concatenation: \((\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}) \to (\text{as} = \text{cs})\) : For any lists \( \text{as}, \text{bs}, \text{cs} \) of elements of type \( \alpha \), if the concatenation of \( \text{as} \) and \( \text{bs} \) is equal to the concatenation of \( \text{cs} \) and \( \text{bs} \), then \( \text{as} \) is equal to \( \text{cs} \). Formally, for any \( \text{as}, \text{bs}, \text{cs} : \text{List } \alpha \), it holds that \( \text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs} \) if and only if \( \text{as} = \text{cs} \).","theorem List.append_cancel_right_eq (as bs cs : List α) : (as ++ bs = cs ++ bs) = (as = cs) := by
  apply propext; apply Iff.intro
  next => apply append_cancel_right
  next => intro h; simp [h]","To prove the equivalence \((\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}) = (\text{as} = \text{cs})\), we use the propositional extensionality axiom, which states that if two propositions are logically equivalent, they are equal. Therefore, it suffices to show that \((\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}) \leftrightarrow (\text{as} = \text{cs})\).

1. **First Implication:**
- To prove \((\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}) \to (\text{as} = \text{cs})\), we use the right cancellation property of list concatenation. This property states that if \(\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}\), then \(\text{as} = \text{cs}\). Therefore, the first implication holds.

2. **Second Implication:**
- To prove \((\text{as} = \text{cs}) \to (\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs})\), we assume \(\text{as} = \text{cs}\). By substituting \(\text{cs}\) for \(\text{as}\) in the expression \(\text{as} \oplus \text{bs}\), we get \(\text{cs} \oplus \text{bs}\). Therefore, \(\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}\) holds, completing the second implication.

Since both implications are proven, we conclude that \((\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}) \leftrightarrow (\text{as} = \text{cs})\). This completes the proof. \(\blacksquare\)","theorem List.append_cancel_right_eq (as bs cs : List α) : (as ++ bs = cs ++ bs) = (as = cs) := by
/- To prove that \((\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}) = (\text{as} = \text{cs})\), we use the propositional extensionality axiom, which states that if two propositions are logically equivalent, they are equal. Therefore, it suffices to show that \((\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}) \leftrightarrow (\text{as} = \text{cs})\). This bi-implication can be split into two implications: \((\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}) \to (\text{as} = \text{cs})\) and \((\text{as} = \text{cs}) \to (\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs})\). -/
  apply propext; apply Iff.intro
/- To prove the first implication \((\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}) \to (\text{as} = \text{cs})\), we use the right cancellation property of list concatenation, which states that if \(\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}\), then \(\text{as} = \text{cs}\). This completes the first part of the bi-implication. -/
  next => apply append_cancel_right
/- To prove the second implication \((\text{as} = \text{cs}) \to (\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs})\), we assume \(\text{as} = \text{cs}\) and simplify the goal. Since \(\text{as} = \text{cs}\), we can substitute \(\text{cs}\) for \(\text{as}\) in the expression \(\text{as} \oplus \text{bs}\), which gives us \(\text{cs} \oplus \text{bs}\). Therefore, \(\text{as} \oplus \text{bs} = \text{cs} \oplus \text{bs}\) holds, completing the second part of the bi-implication. -/
  next => intro h; simp [h]","import Init.Data.Nat.Linear
import Init.Data.List.BasicAux

open List

"
11390,Nat.gcd_add_one,theorem Nat.gcd_add_one (x y : Nat) : gcd (x + 1) y = gcd (y % (x + 1)) (x + 1) := by sorry,"GCD of \( x + 1 \) and \( y \) Equals GCD of \( y \mod (x + 1) \) and \( x + 1 \) : For any natural numbers \( x \) and \( y \), the greatest common divisor of \( x + 1 \) and \( y \) is equal to the greatest common divisor of \( y \mod (x + 1) \) and \( x + 1 \), i.e., \(\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)\).","theorem Nat.gcd_add_one (x y : Nat) : gcd (x + 1) y = gcd (y % (x + 1)) (x + 1) := by
  rw [gcd]; rfl","To prove the theorem, we start by using the definition of the greatest common divisor (gcd). The definition of gcd states that \(\gcd(a, b)\) is the greatest common divisor of \(a\) and \(b\). Applying this definition to our goal, we rewrite \(\gcd(x + 1, y)\) and \(\gcd(y \mod (x + 1), x + 1)\). After applying the definition, the goal simplifies to the equality of the gcd expressions, which is trivially true by the properties of gcd. Therefore, we have \(\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)\). This completes the proof.","theorem Nat.gcd_add_one (x y : Nat) : gcd (x + 1) y = gcd (y % (x + 1)) (x + 1) := by
/- First, we use the definition of the greatest common divisor (gcd) to rewrite the goal. The definition of gcd states that \(\gcd(a, b)\) is the greatest common divisor of \(a\) and \(b\). After applying this definition, the goal simplifies to the equality of the gcd expressions, which is trivially true by the properties of gcd. Therefore, the goal is now trivially satisfied. -/
  rw [gcd]; rfl","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11397,Nat.gcd_zero_left,theorem Nat.gcd_zero_left (y : Nat) : gcd 0 y = y := by sorry,"GCD of Zero and Any Natural Number Equals the Number: \(\gcd(0, y) = y\) : For any natural number \( y \), the greatest common divisor of \( 0 \) and \( y \) is equal to \( y \), i.e., \(\gcd(0, y) = y\).","theorem Nat.gcd_zero_left (y : Nat) : gcd 0 y = y := by
  rw [gcd]; rfl","To prove that \(\gcd(0, y) = y\) for any natural number \( y \), we start by using the definition of the greatest common divisor (gcd). The gcd of two numbers \(a\) and \(b\) is the largest natural number that divides both \(a\) and \(b\). In this case, we are considering \(\gcd(0, y)\).

By the definition of gcd, \(\gcd(0, y)\) is the largest natural number that divides both \(0\) and \(y\). Since any natural number \(y\) divides \(0\) (as \(0 = y \cdot 0\)), the largest number that divides both \(0\) and \(y\) is \(y\) itself. Therefore, \(\gcd(0, y) = y\).

This completes the proof. \(\blacksquare\)","theorem Nat.gcd_zero_left (y : Nat) : gcd 0 y = y := by
/- We use the definition of the greatest common divisor (gcd) to rewrite the goal. The definition of gcd states that \(\gcd(a, b)\) is the largest natural number that divides both \(a\) and \(b\). In this case, we are considering \(\gcd(0, y)\). By the definition of gcd, \(\gcd(0, y)\) is the largest natural number that divides both \(0\) and \(y\). Since any natural number \(y\) divides \(0\) (as \(0 = y \cdot 0\)), the largest number that divides both \(0\) and \(y\) is \(y\) itself. Therefore, \(\gcd(0, y) = y\). -/
  rw [gcd]; rfl","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11406,Nat.gcd_mul_right_left,theorem Nat.gcd_mul_right_left (m n : Nat) : gcd (n * m) n = n := by sorry,"Greatest Common Divisor of Product and Factor: \(\gcd(n \cdot m, n) = n\) : For any natural numbers \( m \) and \( n \), the greatest common divisor of \( n \cdot m \) and \( n \) is equal to \( n \), i.e., \(\gcd(n \cdot m, n) = n\).","theorem Nat.gcd_mul_right_left (m n : Nat) : gcd (n * m) n = n := by
  rw [Nat.mul_comm, gcd_mul_left_left]","To prove that \(\gcd(n \cdot m, n) = n\), we start by using the commutativity of multiplication, which states that \( n \cdot m = m \cdot n \). Therefore, the goal \((n \cdot m).gcd n = n\) can be rewritten as \((m \cdot n).gcd n = n\).

Next, we apply the identity that the greatest common divisor of \( m \cdot n \) and \( n \) is equal to \( n \), i.e., \(\gcd(m \cdot n, n) = n\). This identity directly simplifies our goal to \( n = n \), which is trivially true.

Thus, we have shown that \(\gcd(n \cdot m, n) = n\). This completes the proof. \(\blacksquare\)","theorem Nat.gcd_mul_right_left (m n : Nat) : gcd (n * m) n = n := by
/- First, we use the commutativity of multiplication to rewrite \( n \cdot m \) as \( m \cdot n \). Then, we apply the identity that the greatest common divisor of \( m \cdot n \) and \( n \) is equal to \( n \). This transforms our goal from \((n \cdot m).gcd n = n\) to \((m \cdot n).gcd n = n\), and then to \( n = n \). -/
  rw [Nat.mul_comm, gcd_mul_left_left]","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11407,Nat.gcd_eq_right,theorem Nat.gcd_eq_right {m n : Nat} (H : n ∣ m) : gcd m n = n := by sorry,"Greatest Common Divisor Equals Divisor if Divisor Divides the Other Number : For any natural numbers \( m \) and \( n \), if \( n \) divides \( m \), then the greatest common divisor of \( m \) and \( n \) is equal to \( n \), i.e., \(\gcd(m, n) = n\).","theorem Nat.gcd_eq_right {m n : Nat} (H : n ∣ m) : gcd m n = n := by
  rw [gcd_comm, gcd_eq_left H]","To prove that \(\gcd(m, n) = n\) given that \( n \) divides \( m \), we start by using the commutativity of the greatest common divisor. The commutativity property states that \(\gcd(m, n) = \gcd(n, m)\). Therefore, the goal \(\gcd(m, n) = n\) is equivalent to \(\gcd(n, m) = n\).

Next, we use the fact that if \( n \) divides \( m \), then \(\gcd(n, m) = n\). This is a known property of the greatest common divisor. Since \( n \) divides \( m \) by assumption, it follows that \(\gcd(n, m) = n\).

Thus, we have shown that \(\gcd(m, n) = n\). This completes the proof. \(\blacksquare\)","theorem Nat.gcd_eq_right {m n : Nat} (H : n ∣ m) : gcd m n = n := by
/- First, we use the commutativity of the greatest common divisor (gcd) to rewrite the goal. Since \(\gcd(m, n) = \gcd(n, m)\), the goal \(\gcd(m, n) = n\) is equivalent to \(\gcd(n, m) = n\). Next, we use the fact that if \( n \) divides \( m \), then \(\gcd(n, m) = n\). Therefore, the goal \(\gcd(n, m) = n\) is trivially true. This completes the proof. -/
  rw [gcd_comm, gcd_eq_left H]","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11409,Nat.gcd_mul_right_right,theorem Nat.gcd_mul_right_right (m n : Nat) : gcd n (n * m) = n := by sorry,"Greatest Common Divisor of a Number and Its Product with Another Number: \(\gcd(n, n \cdot m) = n\) : For any natural numbers \( m \) and \( n \), the greatest common divisor of \( n \) and \( n \cdot m \) is equal to \( n \), i.e., \(\gcd(n, n \cdot m) = n\).","theorem Nat.gcd_mul_right_right (m n : Nat) : gcd n (n * m) = n := by
  rw [gcd_comm, gcd_mul_right_left]","To prove that \(\gcd(n, n \cdot m) = n\) for any natural numbers \( m \) and \( n \), we start by using the commutativity property of the greatest common divisor. Specifically, we know that \(\gcd(a, b) = \gcd(b, a)\) for any natural numbers \(a\) and \(b\). Therefore, we can rewrite \(\gcd(n, n \cdot m)\) as \(\gcd(n \cdot m, n)\).

Next, we use the property that \(\gcd(n \cdot m, n) = n\) for any natural numbers \(m\) and \(n\). This property states that the greatest common divisor of \(n \cdot m\) and \(n\) is \(n\). Thus, the goal \(\gcd(n, n \cdot m) = n\) is equivalent to \(n = n\), which is trivially true.

Therefore, we have shown that \(\gcd(n, n \cdot m) = n\). This completes the proof. \(\blacksquare\)","theorem Nat.gcd_mul_right_right (m n : Nat) : gcd n (n * m) = n := by
/- First, we use the commutativity property of the greatest common divisor (gcd) to rewrite the goal. Since \(\gcd(a, b) = \gcd(b, a)\) for any natural numbers \(a\) and \(b\), we can rewrite \(\gcd(n, n \cdot m)\) as \(\gcd(n \cdot m, n)\). Next, we use the property that \(\gcd(n \cdot m, n) = n\) for any natural numbers \(m\) and \(n\). Therefore, the goal \(\gcd(n, n \cdot m) = n\) is equivalent to \(n = n\), which is trivially true. -/
  rw [gcd_comm, gcd_mul_right_left]","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11411,Nat.gcd_mul_left_right,theorem Nat.gcd_mul_left_right (m n : Nat) : gcd n (m * n) = n := by sorry,"GCD Identity: \(\gcd(n, m \cdot n) = n\) : For any natural numbers \( m \) and \( n \), the greatest common divisor of \( n \) and \( m \cdot n \) is equal to \( n \), i.e., \(\gcd(n, m \cdot n) = n\).","theorem Nat.gcd_mul_left_right (m n : Nat) : gcd n (m * n) = n := by
  rw [gcd_comm, gcd_mul_left_left]","To prove that \(\gcd(n, m \cdot n) = n\) for any natural numbers \( m \) and \( n \), we start by using the commutativity property of the greatest common divisor. The commutativity property states that for any elements \(a\) and \(b\) in a normalized GCD monoid, \(\gcd(a, b) = \gcd(b, a)\). Applying this property, we can rewrite \(\gcd(n, m \cdot n)\) as \(\gcd(m \cdot n, n)\).

Next, we use the identity \(\gcd(m \cdot n, n) = n\), which holds for any natural numbers \(m\) and \(n\). This identity tells us that the greatest common divisor of \(m \cdot n\) and \(n\) is \(n\).

Therefore, the original goal \(\gcd(n, m \cdot n) = n\) is equivalent to \(n = n\), which is trivially true. This completes the proof. \(\blacksquare\)","theorem Nat.gcd_mul_left_right (m n : Nat) : gcd n (m * n) = n := by
/- First, we use the commutativity property of the greatest common divisor (gcd) to rewrite the goal. Since \(\gcd(a, b) = \gcd(b, a)\) for any elements \(a\) and \(b\) in a normalized GCD monoid, we can rewrite \(\gcd(n, m \cdot n)\) as \(\gcd(m \cdot n, n)\). Next, we use the identity \(\gcd(m \cdot n, n) = n\) for any natural numbers \(m\) and \(n\). Therefore, the goal \(\gcd(n, m \cdot n) = n\) is equivalent to \(n = n\), which is trivially true. -/
  rw [gcd_comm, gcd_mul_left_left]","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11412,Nat.eq_zero_of_gcd_eq_zero_right,theorem Nat.eq_zero_of_gcd_eq_zero_right {m n : Nat} (H : gcd m n = 0) : n = 0 := by sorry,"Greatest Common Divisor Zero Implies \( n = 0 \) : For any natural numbers \( m \) and \( n \), if the greatest common divisor of \( m \) and \( n \) is zero, i.e., \(\gcd(m, n) = 0\), then \( n \) must be zero, i.e., \( n = 0 \).","theorem Nat.eq_zero_of_gcd_eq_zero_right {m n : Nat} (H : gcd m n = 0) : n = 0 := by
  rw [gcd_comm] at H
  exact eq_zero_of_gcd_eq_zero_left H","We start with the assumption that \(\gcd(m, n) = 0\). By the commutativity of the greatest common divisor, we have \(\gcd(n, m) = 0\). Using the property that if the greatest common divisor of \( n \) and \( m \) is zero, then \( n \) must be zero, we conclude that \( n = 0 \). This completes the proof. \(\blacksquare\)","theorem Nat.eq_zero_of_gcd_eq_zero_right {m n : Nat} (H : gcd m n = 0) : n = 0 := by
/- Since the greatest common divisor (gcd) is commutative, we can replace the assumption \(\gcd(m, n) = 0\) with \(\gcd(n, m) = 0\). Thus, our goal remains to show that \( n = 0 \). -/
  rw [gcd_comm] at H
/- By the property that if the greatest common divisor of \( n \) and \( m \) is zero, then \( n \) must be zero, we conclude that \( n = 0 \). This completes the proof. -/
  exact eq_zero_of_gcd_eq_zero_left H","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11415,Nat.gcd_succ,theorem Nat.gcd_succ (x y : Nat) : gcd (succ x) y = gcd (y % succ x) (succ x) := by sorry,"GCD of Successor and Another Number Equals GCD of Remainder and Successor : For any natural numbers \( x \) and \( y \), the greatest common divisor of \( x + 1 \) and \( y \) is equal to the greatest common divisor of \( y \mod (x + 1) \) and \( x + 1 \), i.e., \(\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)\).","theorem Nat.gcd_succ (x y : Nat) : gcd (succ x) y = gcd (y % succ x) (succ x) := by
  rw [gcd]; rfl","To prove the theorem, we start by using the definition of the greatest common divisor (gcd). The goal is to show that \(\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)\).

By the definition of gcd, the gcd of two numbers \(a\) and \(b\) is the largest number that divides both \(a\) and \(b\). The properties of gcd include the fact that \(\gcd(a, b) = \gcd(b, a \mod b)\). Applying this property to our specific case, we have:
\[
\gcd(x + 1, y) = \gcd(y, (x + 1) \mod y)
\]
However, since \((x + 1) \mod y\) is the remainder when \(x + 1\) is divided by \(y\), we can rewrite this as:
\[
\gcd(x + 1, y) = \gcd(y, y \mod (x + 1))
\]
By the symmetry of gcd, we have:
\[
\gcd(y, y \mod (x + 1)) = \gcd(y \mod (x + 1), y)
\]
Finally, since gcd is symmetric, we can rewrite this as:
\[
\gcd(y \mod (x + 1), y) = \gcd(y \mod (x + 1), x + 1)
\]
Thus, we have shown that:
\[
\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)
\]
This completes the proof.","theorem Nat.gcd_succ (x y : Nat) : gcd (succ x) y = gcd (y % succ x) (succ x) := by
/- First, we use the definition of the greatest common divisor (gcd) to rewrite the goal. The goal is to show that \(\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)\). By the definition of gcd, this is equivalent to showing that the gcd of \(x + 1\) and \(y\) is the same as the gcd of \(y \mod (x + 1)\) and \(x + 1\). Since the definition of gcd is symmetric and the properties of gcd are preserved under modular arithmetic, the goal is trivially true by the properties of gcd. -/
  rw [gcd]; rfl","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11416,Nat.gcd_gcd_self_right_right,theorem Nat.gcd_gcd_self_right_right (m n : Nat) : gcd m (gcd n m) = gcd n m := by sorry,"GCD of a Number and Its GCD with Another Number Equals the GCD: \(\gcd(m, \gcd(n, m)) = \gcd(n, m)\) : For any natural numbers \( m \) and \( n \), the greatest common divisor of \( m \) and the greatest common divisor of \( n \) and \( m \) is equal to the greatest common divisor of \( n \) and \( m \), i.e., \(\gcd(m, \gcd(n, m)) = \gcd(n, m)\).","theorem Nat.gcd_gcd_self_right_right (m n : Nat) : gcd m (gcd n m) = gcd n m := by
  rw [gcd_comm n m, gcd_gcd_self_right_left]","To prove that \(\gcd(m, \gcd(n, m)) = \gcd(n, m)\), we start by using the commutativity property of the greatest common divisor (gcd). This property states that for any natural numbers \( a \) and \( b \), \(\gcd(a, b) = \gcd(b, a)\). Applying this property, we have:
\[
\gcd(m, \gcd(n, m)) = \gcd(m, \gcd(m, n)).
\]
Next, we use the property that the gcd of a number and its gcd with another number is equal to the gcd of the two numbers. Specifically, for any natural numbers \( m \) and \( n \), \(\gcd(m, \gcd(m, n)) = \gcd(m, n)\). Applying this property, we get:
\[
\gcd(m, \gcd(m, n)) = \gcd(m, n).
\]
Thus, we have:
\[
\gcd(m, \gcd(n, m)) = \gcd(m, n).
\]
Since \(\gcd(m, n) = \gcd(n, m)\) by the commutativity of gcd, we conclude:
\[
\gcd(m, \gcd(n, m)) = \gcd(n, m).
\]
This completes the proof.","theorem Nat.gcd_gcd_self_right_right (m n : Nat) : gcd m (gcd n m) = gcd n m := by
/- First, we use the commutativity property of the greatest common divisor (gcd) to rewrite \(\gcd(m, \gcd(n, m))\) as \(\gcd(m, \gcd(m, n))\). Then, we use the property that the gcd of a number and its gcd with another number is equal to the gcd of the two numbers, i.e., \(\gcd(m, \gcd(m, n)) = \gcd(m, n)\). Therefore, our goal \(\gcd(m, \gcd(n, m)) = \gcd(n, m)\) is equivalent to \(\gcd(m, n) = \gcd(n, m)\), which is trivially true by the commutativity of gcd. -/
  rw [gcd_comm n m, gcd_gcd_self_right_left]","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11422,Nat.dvd_gcd,theorem Nat.dvd_gcd : k ∣ m → k ∣ n → k ∣ gcd m n := by sorry,"Divisibility of Greatest Common Divisor: \( k \mid m \) and \( k \mid n \) implies \( k \mid \text{gcd}(m, n) \) : For any natural numbers \( k, m, \) and \( n \), if \( k \) divides \( m \) and \( k \) divides \( n \), then \( k \) divides the greatest common divisor of \( m \) and \( n \), i.e., \( k \mid \text{gcd}(m, n) \).","theorem Nat.dvd_gcd : k ∣ m → k ∣ n → k ∣ gcd m n := by
  induction m, n using gcd.induction with intro km kn
  | H0 n => rw [gcd_zero_left]; exact kn
  | H1 n m _ IH => rw [gcd_rec]; exact IH ((dvd_mod_iff km).2 kn) km","We prove this by induction on \( m \).

**Base Case:**
Consider \( m = 0 \). By the property of the greatest common divisor, \(\gcd(0, n) = n\). Therefore, the goal \( k \mid \gcd(0, n) \) is equivalent to \( k \mid n \). Since we already have \( k \mid n \) as a hypothesis, the base case is proved.

**Inductive Step:**
Assume \( m > 0 \). By the recurrence property of the greatest common divisor, \(\gcd(m, n) = \gcd(n \mod m, m)\). Therefore, the goal \( k \mid \gcd(m, n) \) is equivalent to \( k \mid \gcd(n \mod m, m) \). We need to show that \( k \mid \gcd(n \mod m, m) \). By the inductive hypothesis, if \( k \mid (n \mod m) \) and \( k \mid m \), then \( k \mid \gcd(n \mod m, m) \). Since \( k \mid n \) and \( k \mid m \), we can use the property \( k \mid n \rightarrow (k \mid (n \mod m) \leftrightarrow k \mid n) \) to conclude that \( k \mid (n \mod m) \). Therefore, by the inductive hypothesis, \( k \mid \gcd(n \mod m, m) \), which completes the inductive step.

By induction, the theorem is proved. \(\blacksquare\)","theorem Nat.dvd_gcd : k ∣ m → k ∣ n → k ∣ gcd m n := by
  induction m, n using gcd.induction with intro km kn
/- First, consider the base case where \( m = 0 \). By the property of the greatest common divisor, \(\gcd(0, n) = n\). Therefore, the goal \( k \mid \gcd(0, n) \) is equivalent to \( k \mid n \). Since we already have \( k \mid n \) as a hypothesis, the base case is proved. -/
  | H0 n => rw [gcd_zero_left]; exact kn
/- Next, consider the inductive step where \( m > 0 \). By the recurrence property of the greatest common divisor, \(\gcd(m, n) = \gcd(n \mod m, m)\). Therefore, the goal \( k \mid \gcd(m, n) \) is equivalent to \( k \mid \gcd(n \mod m, m) \). We need to show that \( k \mid \gcd(n \mod m, m) \). By the inductive hypothesis, if \( k \mid (n \mod m) \) and \( k \mid m \), then \( k \mid \gcd(n \mod m, m) \). Since \( k \mid n \) and \( k \mid m \), we can use the property \( k \mid n \rightarrow (k \mid (n \mod m) \leftrightarrow k \mid n) \) to conclude that \( k \mid (n \mod m) \). Therefore, by the inductive hypothesis, \( k \mid \gcd(n \mod m, m) \), which completes the inductive step. -/
  | H1 n m _ IH => rw [gcd_rec]; exact IH ((dvd_mod_iff km).2 kn) km","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11427,Nat.gcd_dvd,theorem Nat.gcd_dvd (m n : Nat) : (gcd m n ∣ m) ∧ (gcd m n ∣ n) := by sorry,"Greatest Common Divisor Divides Both Arguments: \(\gcd(m, n) \mid m \land \gcd(m, n) \mid n\) : For any natural numbers \( m \) and \( n \), the greatest common divisor \(\gcd(m, n)\) divides both \( m \) and \( n \), i.e., \(\gcd(m, n) \mid m\) and \(\gcd(m, n) \mid n\).","theorem Nat.gcd_dvd (m n : Nat) : (gcd m n ∣ m) ∧ (gcd m n ∣ n) := by
  induction m, n using gcd.induction with
  | H0 n => rw [gcd_zero_left]; exact ⟨Nat.dvd_zero n, Nat.dvd_refl n⟩
  | H1 m n _ IH => rw [← gcd_rec] at IH; exact ⟨IH.2, (dvd_mod_iff IH.2).1 IH.1⟩","We prove this by induction on \( m \).

1. **Base Case: \( m = 0 \)**
- By the property of the greatest common divisor, \(\gcd(0, n) = n\).
- Therefore, we need to show that \( n \mid 0 \) and \( n \mid n \).
- Since any number divides zero and any number divides itself, this is trivially true.

2. **Inductive Step: \( m > 0 \)**
- By the recurrence property of the greatest common divisor, \(\gcd(m, n) = \gcd(n \mod m, m)\).
- Assume the induction hypothesis that \(\gcd(n \mod m, m) \mid n \mod m\) and \(\gcd(n \mod m, m) \mid m\).
- We need to show that \(\gcd(m, n) \mid m\) and \(\gcd(m, n) \mid n\).
- Since \(\gcd(m, n) = \gcd(n \mod m, m)\), we have \(\gcd(m, n) \mid m\) by the induction hypothesis.
- To show \(\gcd(m, n) \mid n\), we use the property that if \( k \mid n \) and \( k \mid (m \mod n) \), then \( k \mid m \). Since \(\gcd(m, n) \mid n \mod m\) and \(\gcd(m, n) \mid m\), it follows that \(\gcd(m, n) \mid n\).

Thus, by induction, \(\gcd(m, n) \mid m\) and \(\gcd(m, n) \mid n\) for all natural numbers \( m \) and \( n \). This completes the proof. \(\blacksquare\)","theorem Nat.gcd_dvd (m n : Nat) : (gcd m n ∣ m) ∧ (gcd m n ∣ n) := by
  induction m, n using gcd.induction with
/- First, consider the case where \( m = 0 \). By the property of the greatest common divisor, \(\gcd(0, n) = n\). Therefore, the goal is to show that \( n \mid 0 \) and \( n \mid n \). Since any number divides zero and any number divides itself, this is trivially true. -/
  | H0 n => rw [gcd_zero_left]; exact ⟨Nat.dvd_zero n, Nat.dvd_refl n⟩
/- Next, consider the case where \( m > 0 \). By the recurrence property of the greatest common divisor, \(\gcd(m, n) = \gcd(n \mod m, m)\). We assume the induction hypothesis that \(\gcd(n \mod m, m) \mid n \mod m\) and \(\gcd(n \mod m, m) \mid m\). We need to show that \(\gcd(m, n) \mid m\) and \(\gcd(m, n) \mid n\).

1. Since \(\gcd(m, n) = \gcd(n \mod m, m)\), we have \(\gcd(m, n) \mid m\) by the induction hypothesis.
2. To show \(\gcd(m, n) \mid n\), we use the property that if \( k \mid n \) and \( k \mid (m \mod n) \), then \( k \mid m \). Since \(\gcd(m, n) \mid n \mod m\) and \(\gcd(m, n) \mid m\), it follows that \(\gcd(m, n) \mid n\). -/
  | H1 m n _ IH => rw [← gcd_rec] at IH; exact ⟨IH.2, (dvd_mod_iff IH.2).1 IH.1⟩","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11431,Nat.gcd_gcd_self_left_right,theorem Nat.gcd_gcd_self_left_right (m n : Nat) : gcd (gcd n m) m = gcd n m := by sorry,"GCD Identity: \(\gcd(\gcd(n, m), m) = \gcd(n, m)\) : For any natural numbers \( m \) and \( n \), the greatest common divisor of \( \gcd(n, m) \) and \( m \) is equal to \( \gcd(n, m) \), i.e., \(\gcd(\gcd(n, m), m) = \gcd(n, m)\).","theorem Nat.gcd_gcd_self_left_right (m n : Nat) : gcd (gcd n m) m = gcd n m := by
  rw [gcd_comm, gcd_gcd_self_right_right]","To prove the theorem, we start with the goal \((n \gcd m) \gcd m = n \gcd m\). We use the commutativity of the greatest common divisor (gcd) to rewrite \((n \gcd m) \gcd m\) as \(m \gcd (n \gcd m)\). This step is justified by the theorem that for any elements \(a\) and \(b\) in a type that is a cancellative commutative monoid with zero and has a `NormalizedGCDMonoid` structure, \(\gcd(a, b) = \gcd(b, a)\).

Next, we use the property that the gcd of a number and its gcd with another number is equal to the gcd of the two numbers, i.e., \(\gcd(m, \gcd(n, m)) = \gcd(n, m)\). This simplifies our goal to \(m \gcd (n \gcd m) = n \gcd m\), which is equivalent to \(n \gcd m = n \gcd m\). This is trivially true by the properties of equality.

Thus, we have shown that \(\gcd(\gcd(n, m), m) = \gcd(n, m)\), completing the proof. \(\blacksquare\)","theorem Nat.gcd_gcd_self_left_right (m n : Nat) : gcd (gcd n m) m = gcd n m := by
/- First, we use the commutativity of the greatest common divisor (gcd) to rewrite \((n \gcd m) \gcd m\) as \(m \gcd (n \gcd m)\). Then, we use the property that the gcd of a number and its gcd with another number is equal to the gcd of the two numbers, i.e., \(\gcd(m, \gcd(n, m)) = \gcd(n, m)\). Therefore, the goal \((n \gcd m) \gcd m = n \gcd m\) is equivalent to \(m \gcd (n \gcd m) = n \gcd m\), which simplifies to \(n \gcd m = n \gcd m\). This is trivially true by the properties of equality. -/
  rw [gcd_comm, gcd_gcd_self_right_right]","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11433,Nat.gcd_mul_left,theorem Nat.gcd_mul_left (m n k : Nat) : gcd (m * n) (m * k) = m * gcd n k := by sorry,"GCD of Products with Common Factor: \(\gcd(m \cdot n, m \cdot k) = m \cdot \gcd(n, k)\) : For any natural numbers \( m \), \( n \), and \( k \), the greatest common divisor of \( m \cdot n \) and \( m \cdot k \) is equal to the product of \( m \) and the greatest common divisor of \( n \) and \( k \), i.e., \(\gcd(m \cdot n, m \cdot k) = m \cdot \gcd(n, k)\).","theorem Nat.gcd_mul_left (m n k : Nat) : gcd (m * n) (m * k) = m * gcd n k := by
  induction n, k using gcd.induction with
  | H0 k => simp
  | H1 n k _ IH => rwa [← mul_mod_mul_left, ← gcd_rec, ← gcd_rec] at IH","We prove this by induction on \( n \).

**Base Case:**
Consider \( n = 0 \). We need to show:
\[
(m \cdot 0).gcd (m \cdot k) = m \cdot \gcd(0, k)
\]
Since \( m \cdot 0 = 0 \) and \(\gcd(0, k) = k\), the left-hand side becomes \(0.gcd (m \cdot k) = 0\) and the right-hand side becomes \(m \cdot k\). Therefore, the equation holds trivially.

**Inductive Step:**
Assume the statement holds for some \( n \), i.e.,
\[
(m \cdot (k \mod n)).gcd (m \cdot n) = m \cdot (k \mod n).gcd n
\]
We need to show:
\[
(m \cdot n).gcd (m \cdot k) = m \cdot n.gcd k
\]
Using the property that multiplication distributes over modulo on the left, we have:
\[
m \cdot k \mod (m \cdot n) = m \cdot (k \mod n)
\]
Thus, the goal becomes:
\[
(m \cdot n).gcd (m \cdot k) = (m \cdot n).gcd (m \cdot (k \mod n))
\]
Using the GCD recurrence relation, we get:
\[
(m \cdot n).gcd (m \cdot (k \mod n)) = (m \cdot (k \mod n)).gcd (m \cdot n)
\]
By the inductive hypothesis, this is:
\[
(m \cdot (k \mod n)).gcd (m \cdot n) = m \cdot (k \mod n).gcd n
\]
Applying the GCD recurrence relation again, we get:
\[
m \cdot (k \mod n).gcd n = m \cdot n.gcd k
\]
Thus, the goal is satisfied, and the inductive step is complete.

By induction, the theorem holds for all natural numbers \( m \), \( n \), and \( k \). This completes the proof. \(\blacksquare\)","theorem Nat.gcd_mul_left (m n k : Nat) : gcd (m * n) (m * k) = m * gcd n k := by
  induction n, k using gcd.induction with
/- First, we consider the base case where \( n = 0 \). Simplifying the goal, we get:
\[
(m \cdot 0).gcd (m \cdot k) = m \cdot \gcd(0, k)
\]
Since \( m \cdot 0 = 0 \) and \(\gcd(0, k) = k\), the left-hand side becomes \(0.gcd (m \cdot k) = 0\) and the right-hand side becomes \(m \cdot k\). Therefore, the equation holds trivially. -/
  | H0 k => simp
/- Next, we consider the inductive step where \( n > 0 \). We assume the inductive hypothesis:
\[
(m \cdot (k \mod n)).gcd (m \cdot n) = m \cdot (k \mod n).gcd n
\]
We need to show:
\[
(m \cdot n).gcd (m \cdot k) = m \cdot n.gcd k
\]
Using the property that multiplication distributes over modulo on the left, we have:
\[
m \cdot k \mod (m \cdot n) = m \cdot (k \mod n)
\]
Thus, the goal becomes:
\[
(m \cdot n).gcd (m \cdot k) = (m \cdot n).gcd (m \cdot (k \mod n))
\]
Using the GCD recurrence relation, we get:
\[
(m \cdot n).gcd (m \cdot (k \mod n)) = (m \cdot (k \mod n)).gcd (m \cdot n)
\]
By the inductive hypothesis, this is:
\[
(m \cdot (k \mod n)).gcd (m \cdot n) = m \cdot (k \mod n).gcd n
\]
Applying the GCD recurrence relation again, we get:
\[
m \cdot (k \mod n).gcd n = m \cdot n.gcd k
\]
Thus, the goal is satisfied, and the inductive step is complete. -/
  | H1 n k _ IH => rwa [← mul_mod_mul_left, ← gcd_rec, ← gcd_rec] at IH","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11439,Nat.gcd_zero_right,theorem Nat.gcd_zero_right (n : Nat) : gcd n 0 = n := by sorry,"Greatest Common Divisor of Natural Number and Zero: \(\text{gcd}(n, 0) = n\) : For any natural number \( n \), the greatest common divisor of \( n \) and \( 0 \) is equal to \( n \), i.e., \(\text{gcd}(n, 0) = n\).","theorem Nat.gcd_zero_right (n : Nat) : gcd n 0 = n := by
  cases n with
  | zero => simp [gcd_succ]
  | succ n =>
    -- `simp [gcd_succ]` produces an invalid term unless `gcd_succ` is proved with `id rfl` instead
    rw [gcd_succ]
    exact gcd_zero_left _","We prove this by induction on \( n \).

**Base Case:**
For \( n = 0 \), we need to show that \(\gcd(0, 0) = 0\). Using the theorem that for any natural numbers \( x \) and \( y \), \(\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)\), we simplify the expression to \(\gcd(0, 0) = 0\).

**Inductive Step:**
Assume that for some natural number \( k \), \(\gcd(k, 0) = k\). We need to show that \(\gcd(k + 1, 0) = k + 1\).

Using the theorem that for any natural numbers \( x \) and \( y \), \(\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)\), we rewrite the goal \(\gcd(k + 1, 0)\) to \(\gcd(0 \mod (k + 1), k + 1)\). Since \(0 \mod (k + 1) = 0\), this simplifies to \(\gcd(0, k + 1)\).

By the theorem that the greatest common divisor of \(0\) and any natural number \(a\) is equal to \(a\), we have \(\gcd(0, k + 1) = k + 1\).

Thus, by induction, for any natural number \( n \), \(\gcd(n, 0) = n\). This completes the proof. \(\blacksquare\)","theorem Nat.gcd_zero_right (n : Nat) : gcd n 0 = n := by
  cases n with
/- We perform induction on \(n\) and consider the base case \(n = 0\). To show that \(\gcd(0, 0) = 0\), we use the theorem that for any natural numbers \(x\) and \(y\), \(\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)\). Simplifying the expression using this theorem, we get \(\gcd(0, 0) = 0\). -/
  | zero => simp [gcd_succ]
/- We now consider the inductive step where \(n\) is a successor, i.e., \(n = k + 1\) for some natural number \(k\). We need to show that \((k + 1 + 1).\gcd 0 = k + 1 + 1\). -/
  | succ n =>
    -- `simp [gcd_succ]` produces an invalid term unless `gcd_succ` is proved with `id rfl` instead
/- Using the theorem that for any natural numbers \(x\) and \(y\), \(\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)\), we rewrite the goal \((k + 1 + 1).\gcd 0\) to \((0 \mod (k + 1 + 1)).\gcd (k + 1 + 1)\). -/
    rw [gcd_succ]
/- The current goal is to show that \((0 \mod (n + 1)).\gcd (n + 1) = n + 1\). This is exactly proved by the theorem that the greatest common divisor of \(0\) and any natural number \(a\) is equal to \(a\), i.e., \(\gcd(0, a) = a\). -/
/- The current goal is to show that \((0 \mod (k + 1 + 1)).\gcd (k + 1 + 1) = k + 1 + 1\). This is exactly proved by the theorem that the greatest common divisor of \(0\) and any natural number \(a\) is equal to \(a\), i.e., \(\gcd(0, a) = a\). -/
    exact gcd_zero_left _","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11442,Nat.gcd_self,theorem Nat.gcd_self (n : Nat) : gcd n n = n := by sorry,"GCD is Idempotent: \(\text{gcd}(n, n) = n\) : For any natural number \( n \), the greatest common divisor of \( n \) with itself is \( n \), i.e., \(\text{gcd}(n, n) = n\).","theorem Nat.gcd_self (n : Nat) : gcd n n = n := by
  cases n <;> simp [gcd_succ]","We will consider every possible case of \( n \).

**Case 1: \( n = 0 \)**
Using the property that the greatest common divisor of \( 0 \) and \( 0 \) is \( 0 \), we have:
\[
\gcd(0, 0) = 0
\]
This is trivially true.

**Case 2: \( n = k + 1 \) for some \( k \in \mathbb{N} \)**
We need to show that:
\[
\gcd(k + 1, k + 1) = k + 1
\]
Using the property that the greatest common divisor of \( x + 1 \) and \( y \) is equal to the greatest common divisor of \( y \mod (x + 1) \) and \( x + 1 \), we have:
\[
\gcd(k + 1, k + 1) = \gcd((k + 1) \mod (k + 1), k + 1)
\]
Since \((k + 1) \mod (k + 1) = 0\), this simplifies to:
\[
\gcd(0, k + 1) = k + 1
\]
This is also trivially true.

Thus, in both cases, we have shown that \(\gcd(n, n) = n\). Therefore, the theorem is proved. \(\blacksquare\)","theorem Nat.gcd_self (n : Nat) : gcd n n = n := by
/- We will consider every possible case of \( n \).

**Case 1: \( n = 0 \)**
Using the property that the greatest common divisor of \( 0 \) and \( 0 \) is \( 0 \), we have:
\[
\gcd(0, 0) = 0
\]
This is trivially true.

**Case 2: \( n = k + 1 \) for some \( k \in \mathbb{N} \)**
We need to show that:
\[
\gcd(k + 1, k + 1) = k + 1
\]
Using the property that the greatest common divisor of \( x + 1 \) and \( y \) is equal to the greatest common divisor of \( y \mod (x + 1) \) and \( x + 1 \), we have:
\[
\gcd(k + 1, k + 1) = \gcd((k + 1) \mod (k + 1), k + 1)
\]
Since \((k + 1) \mod (k + 1) = 0\), this simplifies to:
\[
\gcd(0, k + 1) = k + 1
\]
This is also trivially true. -/
  cases n <;> simp [gcd_succ]","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11443,Nat.gcd_add_mul_self,theorem Nat.gcd_add_mul_self (m n k : Nat) : gcd m (n + k * m) = gcd m n := by sorry,"GCD Identity: \(\gcd(m, n + k \cdot m) = \gcd(m, n)\) : For any natural numbers \( m \), \( n \), and \( k \), the greatest common divisor of \( m \) and \( n + k \cdot m \) is equal to the greatest common divisor of \( m \) and \( n \), i.e., \(\gcd(m, n + k \cdot m) = \gcd(m, n)\).","theorem Nat.gcd_add_mul_self (m n k : Nat) : gcd m (n + k * m) = gcd m n := by
  simp [gcd_rec m (n + k * m), gcd_rec m n]","To prove the theorem, we use the GCD recurrence relation, which states that for any natural numbers \( m \) and \( n \), \(\gcd(m, n) = \gcd(n \mod m, m)\).

1. First, we simplify \(\gcd(m, n + k \cdot m)\) using the GCD recurrence relation:
\[
\gcd(m, n + k \cdot m) = \gcd((n + k \cdot m) \mod m, m)
\]

2. Next, we simplify \(\gcd(m, n)\) using the same GCD recurrence relation:
\[
\gcd(m, n) = \gcd(n \mod m, m)
\]

3. We observe that \((n + k \cdot m) \mod m\) is equivalent to \(n \mod m\). This is because:
\[
(n + k \cdot m) \mod m = n \mod m + (k \cdot m) \mod m = n \mod m + 0 = n \mod m
\]

4. Therefore, we have:
\[
\gcd((n + k \cdot m) \mod m, m) = \gcd(n \mod m, m)
\]

5. Combining the results from steps 1 and 2, we get:
\[
\gcd(m, n + k \cdot m) = \gcd(m, n)
\]

This completes the proof.","theorem Nat.gcd_add_mul_self (m n k : Nat) : gcd m (n + k * m) = gcd m n := by
/- Using the GCD recurrence relation, we can simplify the expression \(\gcd(m, n + k \cdot m)\) to \(\gcd((n + k \cdot m) \mod m, m)\). Similarly, we can simplify \(\gcd(m, n)\) to \(\gcd(n \mod m, m)\). Since \((n + k \cdot m) \mod m = n \mod m\), we have \(\gcd((n + k \cdot m) \mod m, m) = \gcd(n \mod m, m)\). Therefore, \(\gcd(m, n + k \cdot m) = \gcd(m, n)\). -/
  simp [gcd_rec m (n + k * m), gcd_rec m n]","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11445,Nat.gcd_gcd_self_left_left,theorem Nat.gcd_gcd_self_left_left (m n : Nat) : gcd (gcd m n) m = gcd m n := by sorry,"GCD Identity: \(\gcd(\gcd(m, n), m) = \gcd(m, n)\) : For any natural numbers \( m \) and \( n \), the greatest common divisor of \( \gcd(m, n) \) and \( m \) is equal to \( \gcd(m, n) \), i.e., \(\gcd(\gcd(m, n), m) = \gcd(m, n)\).","theorem Nat.gcd_gcd_self_left_left (m n : Nat) : gcd (gcd m n) m = gcd m n := by
  rw [gcd_comm m n, gcd_gcd_self_left_right]","To prove the theorem, we start with the goal \((\gcd(m, n)).\gcd m = \gcd(m, n)\).

1. **Step 1: Use GCD Commutativity**
- We use the commutativity property of the greatest common divisor (gcd), which states that \(\gcd(a, b) = \gcd(b, a)\) for any elements \(a\) and \(b\) in a type that is a cancellative commutative monoid with zero and has a `NormalizedGCDMonoid` structure.
- Applying this property, we rewrite \(\gcd(m, n)\) as \(\gcd(n, m)\). This transforms our goal from \((\gcd(m, n)).\gcd m = \gcd(m, n)\) to \((\gcd(n, m)).\gcd m = \gcd(n, m)\).

2. **Step 2: Use GCD Identity**
- Next, we use the identity \(\gcd(\gcd(n, m), m) = \gcd(n, m)\), which states that for any natural numbers \(m\) and \(n\), the greatest common divisor of \(\gcd(n, m)\) and \(m\) is equal to \(\gcd(n, m)\).
- Applying this identity, we simplify the goal to \(\gcd(n, m) = \gcd(n, m)\).

3. **Step 3: Trivial Equality**
- The goal \(\gcd(n, m) = \gcd(n, m)\) is a trivial equality, which is always true.

Thus, we have shown that \(\gcd(\gcd(m, n), m) = \gcd(m, n)\). This completes the proof. \(\blacksquare\)","theorem Nat.gcd_gcd_self_left_left (m n : Nat) : gcd (gcd m n) m = gcd m n := by
/- First, we use the commutativity property of the greatest common divisor (gcd) to rewrite \(\gcd(m, n)\) as \(\gcd(n, m)\). This transforms our goal from \((\gcd(m, n)).\gcd m = \gcd(m, n)\) to \((\gcd(n, m)).\gcd m = \gcd(n, m)\). Next, we use the identity \(\gcd(\gcd(n, m), m) = \gcd(n, m)\) to further simplify the goal to \(\gcd(n, m) = \gcd(n, m)\). Since this is a trivial equality, the goal is now satisfied. -/
  rw [gcd_comm m n, gcd_gcd_self_left_right]","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11447,Nat.gcd_def,theorem Nat.gcd_def (x y : Nat) : gcd x y = if x = 0 then y else gcd (y % x) x := by sorry,"Definition of Greatest Common Divisor: \(\gcd(x, y) = \begin{cases} y & \text{if } x = 0 \\ \gcd(y \mod x, x) & \text{if } x \neq 0 \end{cases}\) : For any natural numbers \( x \) and \( y \), the greatest common divisor (gcd) of \( x \) and \( y \) is defined as:
\[
\gcd(x, y) = \begin{cases} 
y & \text{if } x = 0 \\
\gcd(y \mod x, x) & \text{if } x \neq 0 
\end{cases}
\]","theorem Nat.gcd_def (x y : Nat) : gcd x y = if x = 0 then y else gcd (y % x) x := by
  cases x <;> simp [Nat.gcd_add_one]","We will consider two cases for \( x \):

1. **Case 1: \( x = 0 \)**
- The goal is to show that \(\gcd(0, y) = \text{if } 0 = 0 \text{ then } y \text{ else } (y \mod 0).gcd(0)\).
- Since \( 0 = 0 \), the goal simplifies to \(\gcd(0, y) = y\).
- This is true by the definition of the greatest common divisor.

2. **Case 2: \( x = n + 1 \) for some natural number \( n \)**
- The goal is to show that \(\gcd(n + 1, y) = \text{if } n + 1 = 0 \text{ then } y \text{ else } (y \mod (n + 1)).gcd(n + 1)\).
- Since \( n + 1 \neq 0 \), the goal simplifies to \(\gcd(n + 1, y) = (y \mod (n + 1)).gcd(n + 1)\).
- By the theorem \(\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)\), this is true.

Thus, the definition of the greatest common divisor is verified for both cases. This completes the proof.","theorem Nat.gcd_def (x y : Nat) : gcd x y = if x = 0 then y else gcd (y % x) x := by
/- We will consider two cases for \( x \):
1. \( x = 0 \)
2. \( x = n + 1 \) for some natural number \( n \) -/
/- Case 1: \( x = 0 \)
- The goal is to show that \(\gcd(0, y) = \text{if } 0 = 0 \text{ then } y \text{ else } (y \mod 0).gcd(0)\).

Case 2: \( x = n + 1 \) for some natural number \( n \)
- The goal is to show that \(\gcd(n + 1, y) = \text{if } n + 1 = 0 \text{ then } y \text{ else } (y \mod (n + 1)).gcd(n + 1)\). -/
/- For Case 1 (\( x = 0 \)):
- Since \( 0 = 0 \), the goal simplifies to \(\gcd(0, y) = y\).
- This is true by the definition of the greatest common divisor.

For Case 2 (\( x = n + 1 \)):
- Since \( n + 1 \neq 0 \), the goal simplifies to \(\gcd(n + 1, y) = (y \mod (n + 1)).gcd(n + 1)\).
- By the theorem \(\gcd(x + 1, y) = \gcd(y \mod (x + 1), x + 1)\), this is true. -/
  cases x <;> simp [Nat.gcd_add_one]","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11450,Nat.gcd_mul_right,theorem Nat.gcd_mul_right (m n k : Nat) : gcd (m * n) (k * n) = gcd m k * n := by sorry,"GCD of Products with Common Factor: \(\gcd(m \cdot n, k \cdot n) = \gcd(m, k) \cdot n\) : For any natural numbers \( m \), \( n \), and \( k \), the greatest common divisor of \( m \cdot n \) and \( k \cdot n \) is equal to the product of the greatest common divisor of \( m \) and \( k \) with \( n \), i.e., \(\gcd(m \cdot n, k \cdot n) = \gcd(m, k) \cdot n\).","theorem Nat.gcd_mul_right (m n k : Nat) : gcd (m * n) (k * n) = gcd m k * n := by
  rw [Nat.mul_comm m n, Nat.mul_comm k n, Nat.mul_comm (gcd m k) n, gcd_mul_left]","To prove the theorem, we start with the goal \(\gcd(m \cdot n, k \cdot n) = \gcd(m, k) \cdot n\).

1. **Step 1: Commutativity of Multiplication**
- We use the commutativity of multiplication to rewrite the terms:
\[
m \cdot n = n \cdot m \quad \text{and} \quad k \cdot n = n \cdot k
\]
- This transforms our goal to:
\[
\gcd(n \cdot m, n \cdot k) = \gcd(m, k) \cdot n
\]

2. **Step 2: Commutativity of Multiplication for GCD**
- We also use the commutativity of multiplication for the term involving the greatest common divisor:
\[
\gcd(m, k) \cdot n = n \cdot \gcd(m, k)
\]
- This further simplifies our goal to:
\[
\gcd(n \cdot m, n \cdot k) = n \cdot \gcd(m, k)
\]

3. **Step 3: GCD of Left Multiples**
- We apply the theorem that the greatest common divisor of left multiples is equal to the normalized left multiple of the greatest common divisor:
\[
\gcd(a \cdot b, a \cdot c) = \text{normalize}(a) \cdot \gcd(b, c)
\]
- In our case, \( a = n \), \( b = m \), and \( c = k \). Since \( n \) is a natural number, \(\text{normalize}(n) = n\). Therefore, we have:
\[
\gcd(n \cdot m, n \cdot k) = n \cdot \gcd(m, k)
\]

4. **Step 4: Conclusion**
- The goal is now:
\[
n \cdot \gcd(m, k) = n \cdot \gcd(m, k)
\]
- This is trivially true by the properties of equality.

Thus, we have shown that \(\gcd(m \cdot n, k \cdot n) = \gcd(m, k) \cdot n\). This completes the proof. \(\blacksquare\)","theorem Nat.gcd_mul_right (m n k : Nat) : gcd (m * n) (k * n) = gcd m k * n := by
/- First, we use the commutativity of multiplication to rewrite the goal. Specifically, we rewrite \( m \cdot n \) as \( n \cdot m \), \( k \cdot n \) as \( n \cdot k \), and \( \gcd(m, k) \cdot n \) as \( n \cdot \gcd(m, k) \). Then, we apply the theorem that the greatest common divisor of left multiples is equal to the normalized left multiple of the greatest common divisor, i.e., \(\gcd(a \cdot b, a \cdot c) = \text{normalize}(a) \cdot \gcd(b, c)\). This simplifies our goal to \( n \cdot \gcd(m, k) = n \cdot \gcd(m, k) \), which is trivially true by the properties of equality. -/
  rw [Nat.mul_comm m n, Nat.mul_comm k n, Nat.mul_comm (gcd m k) n, gcd_mul_left]","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11455,Nat.gcd_mul_dvd_mul_gcd,theorem Nat.gcd_mul_dvd_mul_gcd (k m n : Nat) : gcd k (m * n) ∣ gcd k m * gcd k n := by sorry,"GCD of Product Divides Product of GCDs in Natural Numbers : For any natural numbers \( k, m, n \), the greatest common divisor of \( k \) and the product \( m \cdot n \) divides the product of the greatest common divisors of \( k \) and \( m \), and \( k \) and \( n \). In other words, \(\gcd(k, m \cdot n) \mid \gcd(k, m) \cdot \gcd(k, n)\).","theorem Nat.gcd_mul_dvd_mul_gcd (k m n : Nat) : gcd k (m * n) ∣ gcd k m * gcd k n := by
  let ⟨⟨⟨m', hm'⟩, ⟨n', hn'⟩⟩, (h : gcd k (m * n) = m' * n')⟩ :=
    prod_dvd_and_dvd_of_dvd_prod <| gcd_dvd_right k (m * n)
  rw [h]
  have h' : m' * n' ∣ k := h ▸ gcd_dvd_left ..
  exact Nat.mul_dvd_mul
    (dvd_gcd (Nat.dvd_trans (Nat.dvd_mul_right m' n') h') hm')
    (dvd_gcd (Nat.dvd_trans (Nat.dvd_mul_left n' m') h') hn')","We start by constructing natural numbers \( m' \) and \( n' \) such that \( m' \mid m \) and \( n' \mid n \). Additionally, we have \( \gcd(k, m \cdot n) = m' \cdot n' \). This is derived from the fact that the greatest common divisor of \( k \) and \( m \cdot n \) divides \( m \cdot n \), and by the property of the product of divisors of \( m \) and \( n \) from a divisor of \( m \cdot n \).

Next, we replace the goal of showing \( \gcd(k, m \cdot n) \mid \gcd(k, m) \cdot \gcd(k, n) \) with showing \( m' \cdot n' \mid \gcd(k, m) \cdot \gcd(k, n) \).

We then show that \( m' \cdot n' \mid k \). This follows from the fact that \( \gcd(k, m \cdot n) \mid k \) (since the greatest common divisor of \( k \) and \( m \cdot n \) divides \( k \)), and we have \( \gcd(k, m \cdot n) = m' \cdot n' \).

To show that \( m' \cdot n' \mid \gcd(k, m) \cdot \gcd(k, n) \), we use the fact that \( m' \cdot n' \mid k \) and the properties of divisibility. Specifically, we have:
- \( m' \mid m \) and \( m' \cdot n' \mid k \) implies \( m' \mid \gcd(k, m) \) (since \( m' \mid m \) and \( m' \cdot n' \mid k \) implies \( m' \mid k \)).
- \( n' \mid n \) and \( m' \cdot n' \mid k \) implies \( n' \mid \gcd(k, n) \) (since \( n' \mid n \) and \( m' \cdot n' \mid k \) implies \( n' \mid k \)).

Thus, \( m' \cdot n' \mid \gcd(k, m) \cdot \gcd(k, n) \) by the property of multiplication of divisors. This completes the proof. \(\blacksquare\)","theorem Nat.gcd_mul_dvd_mul_gcd (k m n : Nat) : gcd k (m * n) ∣ gcd k m * gcd k n := by
/- We start by constructing natural numbers \( m' \) and \( n' \) such that \( m' \mid m \) and \( n' \mid n \). Additionally, we have \( \gcd(k, m \cdot n) = m' \cdot n' \). This is derived from the fact that the greatest common divisor of \( k \) and \( m \cdot n \) divides \( m \cdot n \), and by the property of the product of divisors of \( m \) and \( n \) from a divisor of \( m \cdot n \). -/
  let ⟨⟨⟨m', hm'⟩, ⟨n', hn'⟩⟩, (h : gcd k (m * n) = m' * n')⟩ :=
    prod_dvd_and_dvd_of_dvd_prod <| gcd_dvd_right k (m * n)
/- Since we have established that \( \gcd(k, m \cdot n) = m' \cdot n' \), we can replace the goal of showing \( \gcd(k, m \cdot n) \mid \gcd(k, m) \cdot \gcd(k, n) \) with showing \( m' \cdot n' \mid \gcd(k, m) \cdot \gcd(k, n) \). -/
  rw [h]
/- We now show that \( m' \cdot n' \mid k \). This follows from the fact that \( \gcd(k, m \cdot n) \mid k \) (since the greatest common divisor of \( k \) and \( m \cdot n \) divides \( k \)), and we have \( \gcd(k, m \cdot n) = m' \cdot n' \). -/
  have h' : m' * n' ∣ k := h ▸ gcd_dvd_left ..
/- To show that \( m' \cdot n' \mid \gcd(k, m) \cdot \gcd(k, n) \), we use the fact that \( m' \cdot n' \mid k \) and the properties of divisibility. Specifically, we have:
- \( m' \mid m \) and \( m' \cdot n' \mid k \) implies \( m' \mid \gcd(k, m) \) (since \( m' \mid m \) and \( m' \cdot n' \mid k \) implies \( m' \mid k \)).
- \( n' \mid n \) and \( m' \cdot n' \mid k \) implies \( n' \mid \gcd(k, n) \) (since \( n' \mid n \) and \( m' \cdot n' \mid k \) implies \( n' \mid k \)).

Thus, \( m' \cdot n' \mid \gcd(k, m) \cdot \gcd(k, n) \) by the property of multiplication of divisors. -/
  exact Nat.mul_dvd_mul
    (dvd_gcd (Nat.dvd_trans (Nat.dvd_mul_right m' n') h') hm')
    (dvd_gcd (Nat.dvd_trans (Nat.dvd_mul_left n' m') h') hn')","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
11466,Nat.gcd_eq_iff,"theorem Nat.gcd_eq_iff (a b : Nat) :
    gcd a b = g ↔ g ∣ a ∧ g ∣ b ∧ (∀ c, c ∣ a → c ∣ b → c ∣ g) := by sorry","Greatest Common Divisor Characterization: \(\gcd(a, b) = g\) if and only if \( g \mid a \) and \( g \mid b \) and \( c \mid a \) and \( c \mid b \) implies \( c \mid g \) : For any natural numbers \( g, a, \) and \( b \), the greatest common divisor \(\gcd(a, b)\) is equal to \( g \) if and only if \( g \) divides both \( a \) and \( b \), and for any natural number \( c \), if \( c \) divides both \( a \) and \( b \), then \( c \) also divides \( g \). In other words, \(\gcd(a, b) = g\) if and only if \( g \mid a \) and \( g \mid b \), and for all \( c \), \( c \mid a \) and \( c \mid b \) implies \( c \mid g \).","theorem Nat.gcd_eq_iff (a b : Nat) :
    gcd a b = g ↔ g ∣ a ∧ g ∣ b ∧ (∀ c, c ∣ a → c ∣ b → c ∣ g) := by
  constructor
  · rintro rfl
    exact ⟨gcd_dvd_left _ _, gcd_dvd_right _ _, fun _ => Nat.dvd_gcd⟩
  · rintro ⟨ha, hb, hc⟩
    apply Nat.dvd_antisymm
    · apply hc
      · exact gcd_dvd_left a b
      · exact gcd_dvd_right a b
    · exact Nat.dvd_gcd ha hb","To prove the equivalence, we need to show both directions.

1. **First Direction:**
- Assume \(\gcd(a, b) = g\).
- By the definition of the greatest common divisor, \(g \mid a\) and \(g \mid b\).
- For any \(c\), if \(c \mid a\) and \(c \mid b\), then \(c \mid \gcd(a, b)\) by the property of the greatest common divisor.
- Therefore, \(c \mid g\).

2. **Second Direction:**
- Assume \(g \mid a\), \(g \mid b\), and for any \(c\), if \(c \mid a\) and \(c \mid b\), then \(c \mid g\).
- To show \(\gcd(a, b) = g\), we use the antisymmetry of divisibility.
- It suffices to show that \(\gcd(a, b) \mid g\) and \(g \mid \gcd(a, b)\).
- Since \(g \mid a\) and \(g \mid b\), by the assumption \(hc\), we have \(\gcd(a, b) \mid g\).
- By the definition of the greatest common divisor, \(\gcd(a, b) \mid a\) and \(\gcd(a, b) \mid b\).
- Therefore, \(g \mid \gcd(a, b)\).

Since both directions are proven, we conclude that \(\gcd(a, b) = g\) if and only if \(g \mid a\), \(g \mid b\), and for any \(c\), if \(c \mid a\) and \(c \mid b\), then \(c \mid g\). This completes the proof. \(\blacksquare\)","theorem Nat.gcd_eq_iff (a b : Nat) :
    gcd a b = g ↔ g ∣ a ∧ g ∣ b ∧ (∀ c, c ∣ a → c ∣ b → c ∣ g) := by
/- To prove the equivalence, we need to show both directions. First, we show that if \(\gcd(a, b) = g\), then \(g \mid a\), \(g \mid b\), and for any \(c\), if \(c \mid a\) and \(c \mid b\), then \(c \mid g\). Second, we show that if \(g \mid a\), \(g \mid b\), and for any \(c\), if \(c \mid a\) and \(c \mid b\), then \(c \mid g\), then \(\gcd(a, b) = g\). -/
  constructor
/- First, we show that if \(\gcd(a, b) = g\), then \(g \mid a\), \(g \mid b\), and for any \(c\), if \(c \mid a\) and \(c \mid b\), then \(c \mid g\). Assume \(\gcd(a, b) = g\). We need to show that \(g \mid a\), \(g \mid b\), and for any \(c\), if \(c \mid a\) and \(c \mid b\), then \(c \mid g\). -/
  · rintro rfl
/- Since \(\gcd(a, b) = g\), we know that \(g \mid a\) and \(g \mid b\) by the definition of the greatest common divisor. Additionally, for any \(c\), if \(c \mid a\) and \(c \mid b\), then \(c \mid \gcd(a, b)\) by the property of the greatest common divisor. Therefore, \(c \mid g\). This completes the first direction of the proof. -/
    exact ⟨gcd_dvd_left _ _, gcd_dvd_right _ _, fun _ => Nat.dvd_gcd⟩
/- Next, we show that if \(g \mid a\), \(g \mid b\), and for any \(c\), if \(c \mid a\) and \(c \mid b\), then \(c \mid g\), then \(\gcd(a, b) = g\). Assume \(g \mid a\), \(g \mid b\), and for any \(c\), if \(c \mid a\) and \(c \mid b\), then \(c \mid g\). We need to show that \(\gcd(a, b) = g\). -/
  · rintro ⟨ha, hb, hc⟩
/- To show \(\gcd(a, b) = g\), we use the antisymmetry of divisibility. It suffices to show that \(\gcd(a, b) \mid g\) and \(g \mid \gcd(a, b)\). -/
    apply Nat.dvd_antisymm
/- To show \(\gcd(a, b) \mid g\), we use the assumption \(hc\). Since \(g \mid a\) and \(g \mid b\), by \(hc\), we have \(\gcd(a, b) \mid g\). -/
    · apply hc
/- To show \(g \mid \gcd(a, b)\), we use the fact that \(\gcd(a, b) \mid a\) and \(\gcd(a, b) \mid b\) by the definition of the greatest common divisor. Therefore, \(g \mid \gcd(a, b)\). -/
      · exact gcd_dvd_left a b
/- To show \(g \mid \gcd(a, b)\), we use the fact that \(\gcd(a, b) \mid b\) by the definition of the greatest common divisor. Therefore, \(g \mid \gcd(a, b)\). -/
      · exact gcd_dvd_right a b
/- To show \(g \mid \gcd(a, b)\), we use the fact that \(g \mid a\) and \(g \mid b\). By the property of the greatest common divisor, \(g \mid \gcd(a, b)\). -/
    · exact Nat.dvd_gcd ha hb","import Init.Data.Nat.Dvd
import Init.NotationExtra
import Init.RCases
import Init.Data.Nat.Gcd

open Nat

"
12893,List.countP_cons_of_neg,theorem List.countP_cons_of_neg (l) (pa : ¬p a) : countP p (a :: l) = countP p l := by sorry,"Count of Elements Satisfying a Predicate in Cons List: \(\text{countP}(p, a :: l) = \text{countP}(p, l)\) if \( p(a) = \text{false} \) : For any type \( \alpha \), a predicate \( p : \alpha \to \text{Bool} \), and a list \( l \) of elements of type \( \alpha \), if \( p(a) = \text{false} \) for some element \( a \in \alpha \), then the count of elements in the list \( a :: l \) that satisfy \( p \) is equal to the count of elements in \( l \) that satisfy \( p \), i.e., \(\text{countP}(p, a :: l) = \text{countP}(p, l)\).","theorem List.countP_cons_of_neg (l) (pa : ¬p a) : countP p (a :: l) = countP p l := by
  simp [countP, countP.go, pa]","We start by noting that the predicate \( p \) maps elements of type \( \alpha \) to boolean values. Given a list \( l \) of elements of type \( \alpha \) and an element \( a \in \alpha \) such that \( p(a) = \text{false} \), we need to show that the count of elements in the list \( a :: l \) that satisfy \( p \) is equal to the count of elements in \( l \) that satisfy \( p \).

Using the definitions of `countP` and `countP.go`, and the fact that \( p(a) = \text{false} \), we can simplify the expression for the count of elements in \( a :: l \) that satisfy \( p \). Specifically, since \( p(a) = \text{false} \), the element \( a \) does not contribute to the count. Therefore, the count of elements in \( a :: l \) that satisfy \( p \) is the same as the count of elements in \( l \) that satisfy \( p \).

Thus, we have:
\[
\text{countP}(p, a :: l) = \text{countP}(p, l)
\]

This completes the proof.","theorem List.countP_cons_of_neg (l) (pa : ¬p a) : countP p (a :: l) = countP p l := by
/- Using the definitions of `countP` and `countP.go`, and the fact that \( p(a) = \text{false} \), we can simplify the proposition we want to show. Specifically, the count of elements in the list \( a :: l \) that satisfy \( p \) is equal to the count of elements in \( l \) that satisfy \( p \), because \( a \) does not contribute to the count since \( p(a) = \text{false} \). -/
  simp [countP, countP.go, pa]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
"
12902,List.countP_le_length,theorem List.countP_le_length : countP p l ≤ l.length := by sorry,"Count of Elements Satisfying Predicate is Less Than or Equal to List Length: \(\text{countP}(p, l) \leq \text{length}(l)\) : For any type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), the number of elements in a list \( l \) that satisfy \( p \) is less than or equal to the length of the list \( l \). Mathematically, this is expressed as \( \text{countP}(p, l) \leq \text{length}(l) \).","theorem List.countP_le_length : countP p l ≤ l.length := by
  simp only [countP_eq_length_filter]
  apply length_filter_le","We start by using the theorem that the count of elements in a list \( l \) that satisfy a predicate \( p \) is equal to the length of the filtered list. This theorem states:
\[
\text{countP}(p, l) = \text{length}(\text{filter} \, p \, l)
\]
Thus, the proposition we need to prove, \(\text{countP}(p, l) \leq \text{length}(l)\), can be simplified to:
\[
\text{length}(\text{filter} \, p \, l) \leq \text{length}(l)
\]
Next, we use the theorem that the length of the filtered list is less than or equal to the length of the original list. This theorem states:
\[
\text{length}(\text{filter} \, p \, l) \leq \text{length}(l)
\]
Since this theorem is already known to be true, the proof is complete. Therefore, we have shown that:
\[
\text{countP}(p, l) \leq \text{length}(l)
\]
This completes the proof.","theorem List.countP_le_length : countP p l ≤ l.length := by
/- Using the theorem that the count of elements in a list \( l \) that satisfy a predicate \( p \) is equal to the length of the filtered list, we can simplify the proposition we want to show to \((\text{filter} \, p \, l). \text{length} \leq l. \text{length}\). -/
  simp only [countP_eq_length_filter]
/- To prove the current goal \((\text{filter} \, p \, l). \text{length} \leq l. \text{length}\), using the theorem that the length of the filtered list is less than or equal to the length of the original list, it suffices to show that this theorem holds. Since the theorem is already known to be true, the proof is complete. -/
  apply length_filter_le","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
"
12904,List.countP_true,theorem List.countP_true {l : List α} : (l.countP fun _ => true) = l.length := by sorry,"Count of True Predicate in List Equals Length of List : For any list \( l \) of elements of type \( \alpha \), the number of elements in \( l \) that satisfy the predicate \( \text{true} \) is equal to the length of \( l \). In other words, \(\text{countP}(\lambda x. \text{true}, l) = \text{length}(l)\).","theorem List.countP_true {l : List α} : (l.countP fun _ => true) = l.length := by
  rw [countP_eq_length]
  simp","To prove that the number of elements in a list \( l \) that satisfy the predicate \( \text{true} \) is equal to the length of \( l \), we use the equivalence that the number of elements in a list \( l \) that satisfy a predicate \( p \) is equal to the length of \( l \) if and only if every element in \( l \) satisfies \( p \). Formally, this equivalence is:
\[
\text{countP}(p, l) = \text{length}(l) \iff \forall a \in l, p(a) = \text{true}
\]
Applying this equivalence to our specific case where \( p(x) = \text{true} \), we need to show:
\[
\forall a \in l, \text{true} = \text{true}
\]
Since \(\text{true} = \text{true}\) is always true, the above statement is trivially true. Therefore, \(\text{countP}(\lambda x. \text{true}, l) = \text{length}(l)\) holds. This completes the proof. \(\blacksquare\)","theorem List.countP_true {l : List α} : (l.countP fun _ => true) = l.length := by
/- We use the equivalence that the number of elements in a list \( l \) that satisfy a predicate \( p \) is equal to the length of \( l \) if and only if every element in \( l \) satisfies \( p \). This equivalence allows us to rewrite our goal from \(\text{countP}(\lambda x. \text{true}, l) = \text{length}(l)\) to \(\forall a \in l, \text{true} = \text{true}\). -/
  rw [countP_eq_length]
/- We simplify the new goal \(\forall a \in l, \text{true} = \text{true}\). Since \(\text{true} = \text{true}\) is always true, the goal is trivially satisfied. Therefore, the original goal is also satisfied. -/
  simp","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
"
12906,List.countP_eq_length,"theorem List.countP_eq_length : countP p l = l.length ↔ ∀ a ∈ l, p a := by sorry","Count of Elements Satisfying Predicate Equals List Length if and only if All Elements Satisfy Predicate: \(\text{countP}(p, l) = \text{length}(l) \iff \forall a \in l, p(a) = \text{true}\) : For any type \(\alpha\) and any predicate \( p : \alpha \to \text{Bool} \), the number of elements in a list \( l \) that satisfy \( p \) is equal to the length of \( l \) if and only if every element in \( l \) satisfies \( p \). Mathematically, this can be expressed as:
\[
\text{countP}(p, l) = \text{length}(l) \iff \forall a \in l, p(a) = \text{true}
\]","theorem List.countP_eq_length : countP p l = l.length ↔ ∀ a ∈ l, p a := by
  rw [countP_eq_length_filter, filter_length_eq_length]","To prove the theorem, we start by using the theorem that the count of elements in a list \( l \) that satisfy a predicate \( p \) is equal to the length of the filtered list \( \text{filter}(p, l) \). This gives us:
\[
\text{countP}(p, l) = \text{length}(\text{filter}(p, l))
\]
Next, we use the theorem that the length of the filtered list \( \text{filter}(p, l) \) is equal to the length of the original list \( l \) if and only if every element in \( l \) satisfies \( p \). This gives us:
\[
\text{length}(\text{filter}(p, l)) = \text{length}(l) \quad \text{if and only if} \quad \forall a \in l, p(a) = \text{true}
\]
Combining these two results, we have:
\[
\text{countP}(p, l) = \text{length}(l) \quad \text{if and only if} \quad \forall a \in l, p(a) = \text{true}
\]
This completes the proof.","theorem List.countP_eq_length : countP p l = l.length ↔ ∀ a ∈ l, p a := by
/- First, we use the theorem that the count of elements in a list \( l \) that satisfy a predicate \( p \) is equal to the length of the filtered list \( \text{filter}(p, l) \). This transforms our goal to show that the length of the filtered list \( \text{filter}(p, l) \) is equal to the length of the original list \( l \). Next, we use the theorem that the length of the filtered list \( \text{filter}(p, l) \) is equal to the length of \( l \) if and only if every element in \( l \) satisfies \( p \). Therefore, our goal is now to show that every element in \( l \) satisfies \( p \). -/
  rw [countP_eq_length_filter, filter_length_eq_length]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
"
12907,List.count_cons_self,theorem List.count_cons_self (a : α) (l : List α) : count a (a :: l) = count a l + 1 := by sorry,"Count of Element in Cons List: \(\text{count}(a, a :: l) = \text{count}(a, l) + 1\) : For any type \( \alpha \) with a `BEq` instance and a `LawfulBEq` instance, and for any element \( a \) of type \( \alpha \) and any list \( l \) of elements of type \( \alpha \), the count of \( a \) in the list \( a :: l \) (i.e., the list formed by adding \( a \) to the front of \( l \)) is equal to the count of \( a \) in \( l \) plus one. Mathematically, this can be expressed as:
\[
\text{count}(a, a :: l) = \text{count}(a, l) + 1
\]","theorem List.count_cons_self (a : α) (l : List α) : count a (a :: l) = count a l + 1 := by
  simp [count_cons]","To prove the theorem, we start by using the definition of the count function for lists. According to the definition, the count of \(a\) in the list \(a :: l\) is given by:
\[
\text{count}(a, a :: l) = \text{count}(a, l) + \begin{cases}
1 & \text{if } a = a \\
0 & \text{otherwise}
\end{cases}
\]
Since \(a = a\) is always true, the expression simplifies to:
\[
\text{count}(a, a :: l) = \text{count}(a, l) + 1
\]
Thus, the theorem is proved. \(\blacksquare\)","theorem List.count_cons_self (a : α) (l : List α) : count a (a :: l) = count a l + 1 := by
/- Using the definition of the count function for lists, we can simplify the expression \(\text{count}(a, a :: l)\) to \(\text{count}(a, l) + 1\). This is because the count of \(a\) in the list \(a :: l\) is the count of \(a\) in \(l\) plus 1 if \(a\) is equal to \(a\), which is always true. Therefore, the goal is trivially satisfied. -/
  simp [count_cons]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
variable [BEq α]
variable [LawfulBEq α]
"
12910,List.count_singleton,theorem List.count_singleton (a b : α) : count a [b] = if b == a then 1 else 0 := by sorry,"Count of Element in Singleton List : For any type \(\alpha\) with a decidable equality relation, and for any elements \(a, b \in \alpha\), the count of \(a\) in the list \([b]\) is 1 if \(b\) is equal to \(a\), and 0 otherwise. Mathematically, this can be expressed as:
\[
\text{count}(a, [b]) = \begin{cases} 
1 & \text{if } b = a \\
0 & \text{if } b \neq a 
\end{cases}
\]","theorem List.count_singleton (a b : α) : count a [b] = if b == a then 1 else 0 := by
  simp [count_cons]","To prove the theorem, we use the definition of the count function for lists. Specifically, we use the property that for any list \(l\) and elements \(a, b \in \alpha\), the count of \(a\) in the list \(b :: l\) is given by:
\[
\text{count}(a, b :: l) = \text{count}(a, l) + \begin{cases}
1 & \text{if } b = a \\
0 & \text{otherwise}
\end{cases}
\]
In our case, the list is \([b]\), which can be written as \(b :: []\). Therefore, we have:
\[
\text{count}(a, [b]) = \text{count}(a, b :: []) = \text{count}(a, []) + \begin{cases}
1 & \text{if } b = a \\
0 & \text{otherwise}
\end{cases}
\]
Since \(\text{count}(a, []) = 0\), this simplifies to:
\[
\text{count}(a, [b]) = \begin{cases}
1 & \text{if } b = a \\
0 & \text{otherwise}
\end{cases}
\]
Thus, the theorem is proved. \(\blacksquare\)","theorem List.count_singleton (a b : α) : count a [b] = if b == a then 1 else 0 := by
/- Using the property of the count function for lists, we simplify the expression \(\text{count}(a, [b])\). According to the definition of the count function for a list with a single element, \(\text{count}(a, [b])\) is equal to \(\text{count}(a, []) + \begin{cases} 1 & \text{if } b = a \\ 0 & \text{otherwise} \end{cases}\). Since \(\text{count}(a, []) = 0\), this simplifies to:
\[
\text{count}(a, [b]) = \begin{cases}
1 & \text{if } b = a \\
0 & \text{otherwise}
\end{cases}
\]
This completes the proof. -/
  simp [count_cons]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
variable [BEq α]
"
12915,List.count_concat_self,"theorem List.count_concat_self (a : α) (l : List α) :
    count a (concat l a) = (count a l) + 1 := by sorry","Count of Element in List Concatenated with Itself Increases by One : For any type \( \alpha \) with a `BEq` instance and a `LawfulBEq` instance, and for any element \( a \in \alpha \) and list \( l \) of elements of type \( \alpha \), the number of occurrences of \( a \) in the list \( l \) concatenated with \( a \) (i.e., \( l ++ [a] \)) is equal to the number of occurrences of \( a \) in \( l \) plus one. Mathematically, this can be expressed as:
\[
\text{count}(a, l \text{.concat } a) = \text{count}(a, l) + 1
\]","theorem List.count_concat_self (a : α) (l : List α) :
    count a (concat l a) = (count a l) + 1 := by
  simp","To prove the theorem, we start by noting that the concatenation of an element \( a \) to a list \( l \) is equivalent to appending \( a \) as a singleton list to \( l \). Formally, this is expressed as:
\[
l.concat(a) = l ++ [a]
\]
Next, we use the properties of the `count` function, which counts the number of occurrences of an element in a list. Specifically, the `count` function satisfies the property that the number of occurrences of \( a \) in \( l ++ [a] \) is the sum of the number of occurrences of \( a \) in \( l \) and the number of occurrences of \( a \) in the singleton list \([a]\). Since the singleton list \([a]\) contains exactly one occurrence of \( a \), we have:
\[
\text{count}(a, l ++ [a]) = \text{count}(a, l) + \text{count}(a, [a])
\]
Given that \(\text{count}(a, [a]) = 1\), we can simplify the above equation to:
\[
\text{count}(a, l ++ [a]) = \text{count}(a, l) + 1
\]
Thus, we have shown that:
\[
\text{count}(a, l \text{.concat } a) = \text{count}(a, l) + 1
\]
This completes the proof.","theorem List.count_concat_self (a : α) (l : List α) :
    count a (concat l a) = (count a l) + 1 := by
  simp","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
variable [BEq α]
variable [LawfulBEq α]
"
12916,List.Sublist.countP_le,theorem List.Sublist.countP_le (s : l₁ <+ l₂) : countP p l₁ ≤ countP p l₂ := by sorry,"Sublist Count Preservation: \(\text{countP}(p, l_1) \leq \text{countP}(p, l_2)\) for \( l_1 \subseteq l_2 \) : For any type \(\alpha\) and any predicate \( p : \alpha \to \text{Bool} \), if \( l_1 \) is a sublist of \( l_2 \), then the number of elements in \( l_1 \) that satisfy \( p \) is less than or equal to the number of elements in \( l_2 \) that satisfy \( p \). Mathematically, this can be expressed as:
\[
l_1 \subseteq l_2 \implies \text{countP}(p, l_1) \leq \text{countP}(p, l_2)
\]","theorem List.Sublist.countP_le (s : l₁ <+ l₂) : countP p l₁ ≤ countP p l₂ := by
  simp only [countP_eq_length_filter]
  apply s.filter _ |>.length_le","We start by noting that the count of elements in a list that satisfy a predicate \( p \) is equal to the length of the filtered list. Therefore, the goal is to show that the length of the filtered list \( \text{filter}(p, l_1) \) is less than or equal to the length of the filtered list \( \text{filter}(p, l_2) \).

Since \( l_1 \) is a sublist of \( l_2 \), we can use the property that if \( l_1 \) is a sublist of \( l_2 \), then the length of \( l_1 \) is less than or equal to the length of \( l_2 \). Applying this property to the filtered lists, we get:
\[
\text{length}(\text{filter}(p, l_1)) \leq \text{length}(\text{filter}(p, l_2))
\]

Thus, we have shown that:
\[
\text{countP}(p, l_1) \leq \text{countP}(p, l_2)
\]

This completes the proof.","theorem List.Sublist.countP_le (s : l₁ <+ l₂) : countP p l₁ ≤ countP p l₂ := by
/- Using the fact that the count of elements in a list that satisfy a predicate \( p \) is equal to the length of the filtered list, we can simplify the goal to show that the length of the filtered list \( \text{filter}(p, l_1) \) is less than or equal to the length of the filtered list \( \text{filter}(p, l_2) \). -/
  simp only [countP_eq_length_filter]
/- To prove that the length of the filtered list \( \text{filter}(p, l_1) \) is less than or equal to the length of the filtered list \( \text{filter}(p, l_2) \), we use the fact that if \( l_1 \) is a sublist of \( l_2 \), then the length of \( l_1 \) is less than or equal to the length of \( l_2 \). Since \( l_1 \) is a sublist of \( l_2 \), it follows that the length of \( \text{filter}(p, l_1) \) is less than or equal to the length of \( \text{filter}(p, l_2) \). -/
  apply s.filter _ |>.length_le","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Sublist
open Nat
variable (p q : α → Bool)
"
12917,List.count_cons,"theorem List.count_cons (a b : α) (l : List α) :
    count a (b :: l) = count a l + if b == a then 1 else 0 := by sorry","Count of Element in Cons List : For any type \(\alpha\) with a boolean equality function, and for any elements \(a, b \in \alpha\) and list \(l\) of elements of type \(\alpha\), the count of \(a\) in the list \(b :: l\) (i.e., the list with \(b\) added to the front of \(l\)) is equal to the count of \(a\) in \(l\) plus 1 if \(b\) is equal to \(a\), and plus 0 otherwise. Mathematically, this can be expressed as:
\[
\text{count}(a, b :: l) = \text{count}(a, l) + \begin{cases} 
1 & \text{if } b = a \\
0 & \text{otherwise}
\end{cases}
\]","theorem List.count_cons (a b : α) (l : List α) :
    count a (b :: l) = count a l + if b == a then 1 else 0 := by
  simp [count, countP_cons]","To prove the theorem, we start by using the definition of the `count` function and the lemma `countP_cons`. The `count` function counts the number of occurrences of an element in a list, and the lemma `countP_cons` states that the count of elements satisfying a predicate in a cons list is the count in the original list plus 1 if the head element satisfies the predicate, and plus 0 otherwise.

Given the list \(b :: l\), we need to show that:
\[
\text{count}(a, b :: l) = \text{count}(a, l) + \begin{cases}
1 & \text{if } b = a \\
0 & \text{otherwise}
\end{cases}
\]

By the definition of `count` and the lemma `countP_cons`, we have:
\[
\text{count}(a, b :: l) = \text{count}(a, l) + \begin{cases}
1 & \text{if } b = a \\
0 & \text{otherwise}
\end{cases}
\]

This simplification directly follows from the definition of `count` and the lemma `countP_cons`. Therefore, the theorem is proved. \(\blacksquare\)","theorem List.count_cons (a b : α) (l : List α) :
    count a (b :: l) = count a l + if b == a then 1 else 0 := by
/- Using the definition of `count` and the lemma `countP_cons`, we can simplify the proposition we want to show. Specifically, the count of \(a\) in the list \(b :: l\) is equal to the count of \(a\) in \(l\) plus 1 if \(b\) is equal to \(a\), and plus 0 otherwise. This simplification directly follows from the definition of `count` and the lemma `countP_cons`, which states that the count of elements satisfying a predicate in a cons list is the count in the original list plus 1 if the head element satisfies the predicate, and plus 0 otherwise. -/
  simp [count, countP_cons]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
variable [BEq α]
"
12918,List.countP_append,theorem List.countP_append (l₁ l₂) : countP p (l₁ ++ l₂) = countP p l₁ + countP p l₂ := by sorry,"Count of Elements Satisfying a Predicate in Concatenated Lists: \(\text{countP}(p, l_1 \oplus l_2) = \text{countP}(p, l_1) + \text{countP}(p, l_2)\) : For any type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), the count of elements in the list \( l_1 \) that satisfy \( p \) plus the count of elements in the list \( l_2 \) that satisfy \( p \) is equal to the count of elements in the concatenated list \( l_1 \oplus l_2 \) that satisfy \( p \). In other words, for lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), the following holds:
\[
\text{countP}(p, l_1 \oplus l_2) = \text{countP}(p, l_1) + \text{countP}(p, l_2)
\]","theorem List.countP_append (l₁ l₂) : countP p (l₁ ++ l₂) = countP p l₁ + countP p l₂ := by
  simp only [countP_eq_length_filter, filter_append, length_append]","To prove the theorem, we start by using the definition of \(\text{countP}\) and the properties of list operations. Specifically, we use the following facts:
1. The count of elements satisfying a predicate \( p \) in a list \( l \) is equal to the length of the filtered list \(\text{filter}(p, l)\). Formally, \(\text{countP}(p, l) = \text{length}(\text{filter}(p, l))\).
2. The filter of a concatenated list is the concatenation of the filters. Formally, \(\text{filter}(p, l_1 \oplus l_2) = \text{filter}(p, l_1) \oplus \text{filter}(p, l_2)\).
3. The length of a concatenated list is the sum of the lengths of the individual lists. Formally, \(\text{length}(l_1 \oplus l_2) = \text{length}(l_1) + \text{length}(l_2)\).

Using these properties, we can simplify the left-hand side of the equation:
\[
\text{countP}(p, l_1 \oplus l_2) = \text{length}(\text{filter}(p, l_1 \oplus l_2))
\]
By the second property, this becomes:
\[
\text{length}(\text{filter}(p, l_1) \oplus \text{filter}(p, l_2))
\]
By the third property, this further simplifies to:
\[
\text{length}(\text{filter}(p, l_1)) + \text{length}(\text{filter}(p, l_2))
\]
Using the first property again, we get:
\[
\text{countP}(p, l_1) + \text{countP}(p, l_2)
\]

Thus, we have shown that:
\[
\text{countP}(p, l_1 \oplus l_2) = \text{countP}(p, l_1) + \text{countP}(p, l_2)
\]

This completes the proof. \(\blacksquare\)","theorem List.countP_append (l₁ l₂) : countP p (l₁ ++ l₂) = countP p l₁ + countP p l₂ := by
/- Using the fact that the count of elements satisfying a predicate \( p \) in a list \( l \) is equal to the length of the filtered list \( \text{filter}(p, l) \), and the properties that the filter of a concatenated list is the concatenation of the filters, and the length of a concatenated list is the sum of the lengths of the individual lists, we can simplify the proposition we want to show to:
\[
\text{countP}(p, l_1 \oplus l_2) = \text{length}(\text{filter}(p, l_1 \oplus l_2)) = \text{length}(\text{filter}(p, l_1) \oplus \text{filter}(p, l_2)) = \text{length}(\text{filter}(p, l_1)) + \text{length}(\text{filter}(p, l_2)) = \text{countP}(p, l_1) + \text{countP}(p, l_2)
\] -/
  simp only [countP_eq_length_filter, filter_append, length_append]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
"
12920,List.countP_false,theorem List.countP_false {l : List α} : (l.countP fun _ => false) = 0 := by sorry,"Count of False Predicate in List Equals Zero : For any list \( l \) of elements of type \( \alpha \), the number of elements in \( l \) that satisfy the predicate \( \text{false} \) is equal to 0. In other words, \(\text{countP}(\lambda x. \text{false}, l) = 0\).","theorem List.countP_false {l : List α} : (l.countP fun _ => false) = 0 := by
  rw [countP_eq_zero]
  simp","We start by using the equivalence that the count of elements in a list \( l \) that satisfy a predicate \( p \) is zero if and only if no element in \( l \) satisfies \( p \). Formally, this is expressed as:
\[
\text{countP}(p, l) = 0 \iff \forall a \in l, \neg p(a) = \text{true}
\]
In our case, the predicate \( p \) is \(\lambda x. \text{false}\). Therefore, to show that \(\text{countP}(\lambda x. \text{false}, l) = 0\), it suffices to show that for all \( a \in l \), \(\neg (\lambda x. \text{false})(a) = \text{true}\).

Since \(\lambda x. \text{false}\) always returns \(\text{false}\), we have:
\[
\forall a \in l, \neg (\lambda x. \text{false})(a) = \neg \text{false} = \text{true}
\]
This condition is trivially true for all \( a \in l \). Therefore, \(\text{countP}(\lambda x. \text{false}, l) = 0\).

This completes the proof. \(\blacksquare\)","theorem List.countP_false {l : List α} : (l.countP fun _ => false) = 0 := by
/- We use the equivalence that the count of elements in a list \( l \) that satisfy a predicate \( p \) is zero if and only if no element in \( l \) satisfies \( p \). Therefore, to show that \(\text{countP}(\lambda x. \text{false}, l) = 0\), it suffices to show that for all \( a \in l \), \(\neg (\lambda x. \text{false})(a) = \text{true}\). -/
  rw [countP_eq_zero]
/- Simplify the proposition we want to show. Since \(\lambda x. \text{false}\) always returns \(\text{false}\), \(\neg (\lambda x. \text{false})(a) = \neg \text{false} = \text{true}\). Therefore, the condition \(\forall a \in l, \neg (\lambda x. \text{false})(a) = \text{true}\) is trivially true. -/
  simp","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
"
12922,List.countP_pos,"theorem List.countP_pos : 0 < countP p l ↔ ∃ a ∈ l, p a := by sorry","Positive Count of Elements Satisfying a Predicate in a List: \( 0 < \text{countP}(p, l) \iff \exists a \in l, \, p(a) = \text{true} \) : For any type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), the count of elements in a list \( l \) that satisfy \( p \) is positive if and only if there exists an element \( a \) in \( l \) such that \( p(a) = \text{true} \). Mathematically, this can be expressed as:
\[ 0 < \text{countP}(p, l) \iff \exists a \in l, \, p(a) = \text{true} \]","theorem List.countP_pos : 0 < countP p l ↔ ∃ a ∈ l, p a := by
  simp only [countP_eq_length_filter, length_pos_iff_exists_mem, mem_filter, exists_prop]","To prove the theorem, we start by simplifying the proposition using the following theorems:
1. The count of elements in a list \( l \) that satisfy a predicate \( p \) is equal to the length of the list obtained by filtering \( l \) with \( p \). Formally, \(\text{countP}(p, l) = \text{length}(\text{filter}(p, l))\).
2. The length of a list is positive if and only if there exists an element in the list. Formally, \(\text{length}(l) > 0 \iff \exists a \in l\).
3. An element \( a \) is in the filtered list if and only if \( a \) is in the original list and \( p(a) = \text{true} \). Formally, \( a \in \text{filter}(p, l) \iff a \in l \land p(a) = \text{true} \).
4. The existential quantification \(\exists h, b\) is logically equivalent to the conjunction \(a \land b\). Formally, \(\exists h, b \iff a \land b\).

Using these theorems, we can rewrite the original goal \(0 < \text{countP}(p, l) \iff \exists a, a \in l \land p(a) = \text{true}\) as follows:
\[ 0 < \text{length}(\text{filter}(p, l)) \iff \exists a, a \in l \land p(a) = \text{true} \]

Since \(\text{length}(\text{filter}(p, l)) > 0\) if and only if there exists an element \( a \) in \( l \) such that \( p(a) = \text{true} \), the two statements are equivalent. Therefore, we have:
\[ 0 < \text{countP}(p, l) \iff \exists a \in l, \, p(a) = \text{true} \]

This completes the proof. \(\blacksquare\)","theorem List.countP_pos : 0 < countP p l ↔ ∃ a ∈ l, p a := by
/- We simplify the proposition we want to show using the following theorems:
1. The count of elements in a list \( l \) that satisfy a predicate \( p \) is equal to the length of the list obtained by filtering \( l \) with \( p \). Formally, \(\text{countP}(p, l) = \text{length}(\text{filter}(p, l))\).
2. The length of a list is positive if and only if there exists an element in the list. Formally, \(\text{length}(l) > 0 \iff \exists a \in l\).
3. An element \( a \) is in the filtered list if and only if \( a \) is in the original list and \( p(a) = \text{true} \). Formally, \( a \in \text{filter}(p, l) \iff a \in l \land p(a) = \text{true} \).
4. The existential quantification \(\exists h, b\) is logically equivalent to the conjunction \(a \land b\). Formally, \(\exists h, b \iff a \land b\).

Using these theorems, we can simplify the original goal \(0 < \text{countP}(p, l) \iff \exists a, a \in l \land p(a) = \text{true}\) to the equivalent statement. -/
  simp only [countP_eq_length_filter, length_pos_iff_exists_mem, mem_filter, exists_prop]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
"
12924,List.countP_eq_zero,"theorem List.countP_eq_zero : countP p l = 0 ↔ ∀ a ∈ l, ¬p a := by sorry","Count of Elements Satisfying Predicate Equals Zero if and only if No Element Satisfies Predicate: \(\text{countP}(p, l) = 0 \iff \forall a \in l, \neg p(a)\) : For any type \(\alpha\) and any predicate \( p : \alpha \to \text{Bool} \), the number of elements in a list \( l \) that satisfy \( p \) is zero if and only if no element in \( l \) satisfies \( p \). Mathematically, this can be expressed as:
\[
\text{countP}(p, l) = 0 \iff \forall a \in l, \neg p(a) = \text{true}
\]","theorem List.countP_eq_zero : countP p l = 0 ↔ ∀ a ∈ l, ¬p a := by
  simp only [countP_eq_length_filter, length_eq_zero, filter_eq_nil]","To prove the theorem, we start by using the following lemmas:
1. The number of elements in a list \( l \) that satisfy a predicate \( p \) is equal to the length of the list obtained by filtering \( l \) with \( p \). Formally, \(\text{countP}(p, l) = \text{length}(\text{filter}(p, l))\).
2. The length of a list is zero if and only if the list is empty. Formally, \(\text{length}(l) = 0 \iff l = \text{nil}\).
3. A list filtered by a predicate \( p \) is empty if and only if no element in the list satisfies \( p \). Formally, \(\text{filter}(p, l) = \text{nil} \iff \forall a \in l, \neg p(a) = \text{true}\).

Using these lemmas, we can simplify the goal:
\[
\text{countP}(p, l) = 0 \iff \text{length}(\text{filter}(p, l)) = 0
\]
Since \(\text{length}(\text{filter}(p, l)) = 0\) is equivalent to \(\text{filter}(p, l) = \text{nil}\), we have:
\[
\text{countP}(p, l) = 0 \iff \text{filter}(p, l) = \text{nil}
\]
Finally, \(\text{filter}(p, l) = \text{nil}\) is equivalent to \(\forall a \in l, \neg p(a) = \text{true}\). Therefore, we conclude:
\[
\text{countP}(p, l) = 0 \iff \forall a \in l, \neg p(a) = \text{true}
\]
This completes the proof.","theorem List.countP_eq_zero : countP p l = 0 ↔ ∀ a ∈ l, ¬p a := by
/- We simplify the goal using the following lemmas:
1. The number of elements in a list \( l \) that satisfy a predicate \( p \) is equal to the length of the list obtained by filtering \( l \) with \( p \). Formally, \(\text{countP}(p, l) = \text{length}(\text{filter}(p, l))\).
2. The length of a list is zero if and only if the list is empty. Formally, \(\text{length}(l) = 0 \iff l = \text{nil}\).
3. A list filtered by a predicate \( p \) is empty if and only if no element in the list satisfies \( p \). Formally, \(\text{filter}(p, l) = \text{nil} \iff \forall a \in l, \neg p(a) = \text{true}\).

Using these lemmas, we can simplify the goal to:
\[
\text{countP}(p, l) = 0 \iff \forall a \in l, \neg p(a) = \text{true}
\] -/
  simp only [countP_eq_length_filter, length_eq_zero, filter_eq_nil]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
"
12926,List.count_pos_iff_mem,theorem List.count_pos_iff_mem {a : α} {l : List α} : 0 < count a l ↔ a ∈ l := by sorry,"Positive Count of Element in List if and only if Element is in List: \( 0 < \text{count}(a, l) \iff a \in l \) : For any type \( \alpha \) with a `BEq` instance and a `LawfulBEq` instance, and for any element \( a \in \alpha \) and list \( l \) of elements of type \( \alpha \), the count of \( a \) in \( l \) is positive if and only if \( a \) is a member of \( l \). Mathematically, this can be expressed as:
\[
0 < \text{count}(a, l) \iff a \in l
\]","theorem List.count_pos_iff_mem {a : α} {l : List α} : 0 < count a l ↔ a ∈ l := by
  simp only [count, countP_pos, beq_iff_eq, exists_eq_right]","To prove the theorem, we start by using the definitions and properties of the functions and relations involved. Specifically, we use the following:

1. **Definition of `count`**: The function `count a l` returns the number of occurrences of \( a \) in the list \( l \).
2. **Property `countP_pos`**: The count of \( a \) in \( l \) is positive if and only if there exists an element \( a' \) in \( l \) such that \( a = a' \).
3. **Property `beq_iff_eq`**: The boolean equality \( a == b \) is `true` if and only if \( a = b \).
4. **Property `exists_eq_right`**: The statement \( \exists a, p(a) \land a = a' \) is logically equivalent to \( p(a') \).

Using these properties, we can simplify the proposition \( 0 < \text{count}(a, l) \iff a \in l \) as follows:

- **Forward direction**: If \( 0 < \text{count}(a, l) \), then by `countP_pos`, there exists an element \( a' \) in \( l \) such that \( a = a' \). By `beq_iff_eq`, this means \( a \) is a member of \( l \).
- **Backward direction**: If \( a \in l \), then there exists an element \( a' \) in \( l \) such that \( a = a' \). By `countP_pos`, this implies \( 0 < \text{count}(a, l) \).

Thus, we have shown that \( 0 < \text{count}(a, l) \) if and only if \( a \in l \). This completes the proof. \(\blacksquare\)","theorem List.count_pos_iff_mem {a : α} {l : List α} : 0 < count a l ↔ a ∈ l := by
/- Using the definitions and properties of `count`, `countP_pos`, `beq_iff_eq`, and `exists_eq_right`, we can simplify the proposition we want to show. Specifically, we use the fact that the count of \( a \) in \( l \) is positive if and only if there exists an element \( a' \) in \( l \) such that \( a = a' \). This is equivalent to \( a \) being a member of \( l \). -/
  simp only [count, countP_pos, beq_iff_eq, exists_eq_right]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
variable [BEq α]
variable [LawfulBEq α]
"
12927,List.count_le_count_map,"theorem List.count_le_count_map [DecidableEq β] (l : List α) (f : α → β) (x : α) :
    count x l ≤ count (f x) (map f l) := by sorry","Count of Element in List is Less Than or Equal to Count of its Image in Mapped List : For any list \( l \) of elements of type \( \alpha \) and a function \( f : \alpha \to \beta \), the number of occurrences of an element \( x \) in \( l \) is less than or equal to the number of occurrences of \( f(x) \) in the list obtained by applying \( f \) to each element of \( l \). Formally, for any \( x \in \alpha \), it holds that \( \text{count}(x, l) \leq \text{count}(f(x), \text{map}(f, l)) \).","theorem List.count_le_count_map [DecidableEq β] (l : List α) (f : α → β) (x : α) :
    count x l ≤ count (f x) (map f l) := by
  rw [count, count, countP_map]
  apply countP_mono_left; simp (config := { contextual := true })","We start by using the definition of the `count` function, which counts the number of elements in a list that satisfy a given predicate. Specifically, we rewrite the goal to show that the number of elements in \( l \) that are equal to \( x \) is less than or equal to the number of elements in \( \text{map} f l \) that are equal to \( f(x) \).

Using the theorem `countP_map`, we further rewrite the goal to show that the number of elements in \( l \) that are equal to \( x \) is less than or equal to the number of elements in \( l \) that satisfy the predicate \( (p \circ f) \), where \( p \) is the predicate that checks if an element is equal to \( f(x) \).

To prove this inequality, we use the theorem `countP_mono_left`, which states that if a predicate \( p_1 \) implies a predicate \( p_2 \), then the number of elements in a list that satisfy \( p_1 \) is less than or equal to the number of elements that satisfy \( p_2 \). In our case, we need to show that the predicate \( (x_1 == x) \) implies the predicate \( ((x_1 == f x) \circ f) \).

After simplifying the expression using the given context, we see that this implication holds. Therefore, the number of elements in \( l \) that are equal to \( x \) is indeed less than or equal to the number of elements in \( l \) that satisfy the predicate \( (p \circ f) \), which completes the proof.

\[
\boxed{\text{count}(x, l) \leq \text{count}(f(x), \text{map}(f, l))}
\]","theorem List.count_le_count_map [DecidableEq β] (l : List α) (f : α → β) (x : α) :
    count x l ≤ count (f x) (map f l) := by
/- First, we use the definition of `count` to rewrite the goal. The function `count` is defined as the number of elements in a list that satisfy a given predicate, using the equality relation provided by the `BEq` instance. Specifically, we rewrite the goal to show that the number of elements in \( l \) that are equal to \( x \) is less than or equal to the number of elements in \( \text{map} f l \) that are equal to \( f(x) \). Using the theorem `countP_map`, we further rewrite the goal to show that the number of elements in \( l \) that are equal to \( x \) is less than or equal to the number of elements in \( l \) that satisfy the predicate \( (p \circ f) \), where \( p \) is the predicate that checks if an element is equal to \( f(x) \). -/
  rw [count, count, countP_map]
/- To prove the inequality, we use the theorem `countP_mono_left`, which states that if a predicate \( p_1 \) implies a predicate \( p_2 \), then the number of elements in a list that satisfy \( p_1 \) is less than or equal to the number of elements that satisfy \( p_2 \). In our case, we need to show that the predicate \( (x_1 == x) \) implies the predicate \( ((x_1 == f x) \circ f) \). After simplifying the expression using the given context, we see that this implication holds, thus completing the proof. -/
  apply countP_mono_left; simp (config := { contextual := true })","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
variable [BEq α]
variable [LawfulBEq α]
"
12928,List.count_erase_of_ne,theorem List.count_erase_of_ne (ab : a ≠ b) (l : List α) : count a (l.erase b) = count a l := by sorry,"Count of Element Unchanged by Erasing Different Element in List : For any type \(\alpha\) and elements \(a, b \in \alpha\) such that \(a \neq b\), and for any list \(l\) of elements of type \(\alpha\), the number of occurrences of \(a\) in the list \(l\) after erasing the first occurrence of \(b\) is equal to the number of occurrences of \(a\) in the original list \(l\). Formally, if \(a \neq b\), then \(\text{count}(a, \text{erase}(l, b)) = \text{count}(a, l)\).","theorem List.count_erase_of_ne (ab : a ≠ b) (l : List α) : count a (l.erase b) = count a l := by
  rw [count_erase, if_neg (by simpa using ab.symm), Nat.sub_zero]","We start by using the theorem that the count of \(a\) in the list obtained by erasing the first occurrence of \(b\) from \(l\) is given by:
\[
\text{count}(a, \text{erase}(b, l)) = \text{count}(a, l) - \begin{cases}
1 & \text{if } b = a \\
0 & \text{otherwise}
\end{cases}
\]
Since \(a \neq b\), the condition \(b == a\) is false. Therefore, the if-then-else expression evaluates to 0. Substituting this into the equation, we get:
\[
\text{count}(a, \text{erase}(b, l)) = \text{count}(a, l) - 0
\]
Using the property that subtracting 0 from any number is the number itself, we have:
\[
\text{count}(a, \text{erase}(b, l)) = \text{count}(a, l)
\]
Thus, the number of occurrences of \(a\) in the list \(l\) after erasing the first occurrence of \(b\) is equal to the number of occurrences of \(a\) in the original list \(l\). This completes the proof. \(\blacksquare\)","theorem List.count_erase_of_ne (ab : a ≠ b) (l : List α) : count a (l.erase b) = count a l := by
/- First, we use the theorem that the count of \(a\) in the list obtained by erasing the first occurrence of \(b\) from \(l\) is equal to the count of \(a\) in \(l\) minus 1 if \(a = b\), and equal to the count of \(a\) in \(l\) otherwise. Since \(a \neq b\), the condition \(b == a\) is false, so the if-then-else expression evaluates to 0. Therefore, the goal simplifies to \(\text{count}(a, l) - 0 = \text{count}(a, l)\). Using the property that subtracting 0 from any number is the number itself, we get \(\text{count}(a, l) = \text{count}(a, l)\), which is trivially true. -/
  rw [count_erase, if_neg (by simpa using ab.symm), Nat.sub_zero]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
variable [BEq α]
variable [LawfulBEq α]
"
12931,List.filter_beq,theorem List.filter_beq (l : List α) (a : α) : l.filter (· == a) = replicate (count a l) a := by sorry,"Filtering by Boolean Equality Yields Replicated Count of Element: \(\text{filter} (x == a) \, l = \text{replicate} (\text{count}(a, l)) \, a\) : For any list \( l \) of elements of type \( \alpha \) and any element \( a \) of type \( \alpha \), the list obtained by filtering \( l \) to keep only the elements equal to \( a \) using the `BEq` equality relation is equal to the list containing \( \text{count}(a, l) \) copies of \( a \). In other words, if \( l \) is a list and \( a \) is an element, then:
\[
\text{filter} (x == a) \, l = \text{replicate} (\text{count}(a, l)) \, a
\]","theorem List.filter_beq (l : List α) (a : α) : l.filter (· == a) = replicate (count a l) a := by
  simp only [count, countP_eq_length_filter, eq_replicate, mem_filter, beq_iff_eq]
  exact ⟨trivial, fun _ h => h.2⟩","To prove the theorem, we start by using the definitions and properties of the functions involved. Specifically, we use the following properties:
1. The function `count` counts the number of occurrences of an element \( a \) in a list \( l \).
2. The function `countP_eq_length_filter` states that the number of elements in \( l \) that satisfy a predicate \( p \) is equal to the length of the list obtained by filtering \( l \) with \( p \).
3. The function `eq_replicate` states that a list containing \( n \) copies of an element \( a \) is equal to the list `replicate n a`.
4. The function `mem_filter` states that an element \( b \) is in the filtered list if and only if \( b \) is in the original list and satisfies the predicate.
5. The function `beq_iff_eq` states that the boolean equality \( a == b \) is `true` if and only if \( a \) is equal to \( b \).

Using these properties, we simplify the goal to show that for any element \( b \) in the list \( l \), if \( b \) is equal to \( a \), then \( b \) is equal to \( a \). This simplification results in the goal:
\[
\text{True} \land \forall (b : \alpha), b \in l \land b = a \to b = a
\]

The first part, \(\text{True}\), is trivially true. For the second part, we need to show that for any \( b \) in \( l \) such that \( b = a \), \( b \) is indeed equal to \( a \). This is trivial because the hypothesis \( b = a \) directly implies \( b = a \). Therefore, the goal is satisfied, and the theorem is proved.","theorem List.filter_beq (l : List α) (a : α) : l.filter (· == a) = replicate (count a l) a := by
/- Using the definitions and properties of `count`, `countP_eq_length_filter`, `eq_replicate`, `mem_filter`, and `beq_iff_eq`, we simplify the goal to show that for any element \( b \) in the list \( l \), if \( b \) is equal to \( a \), then \( b \) is equal to \( a \). This simplification results in the goal:
\[
\text{True} \land \forall (b : \alpha), b \in l \land b = a \to b = a
\] -/
  simp only [count, countP_eq_length_filter, eq_replicate, mem_filter, beq_iff_eq]
/- The current goal is to show:
\[
\text{True} \land \forall (b : \alpha), b \in l \land b = a \to b = a
\]
The first part, \(\text{True}\), is trivially true. For the second part, we need to show that for any \( b \) in \( l \) such that \( b = a \), \( b \) is indeed equal to \( a \). This is trivial because the hypothesis \( b = a \) directly implies \( b = a \). Therefore, the goal is satisfied. -/
  exact ⟨trivial, fun _ h => h.2⟩","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
variable [BEq α]
variable [LawfulBEq α]
"
12937,List.count_replicate,theorem List.count_replicate (a b : α) (n : Nat) : count a (replicate n b) = if b == a then n else 0 := by sorry,"Count of Element in Replicated List: \(\text{count}(a, \text{replicate}(n, b)) = \begin{cases} n & \text{if } a = b \\ 0 & \text{otherwise} \end{cases}\) : For any type \(\alpha\) with a `BEq` instance and a `LawfulBEq` instance, and for any elements \(a, b \in \alpha\) and natural number \(n \in \mathbb{N}\), the number of occurrences of \(a\) in the list `replicate n b` is equal to \(n\) if \(a\) is equal to \(b\), and 0 otherwise. In other words, \(\text{count}(a, \text{replicate}(n, b)) = \begin{cases} n & \text{if } a = b \\ 0 & \text{otherwise} \end{cases}\).","theorem List.count_replicate (a b : α) (n : Nat) : count a (replicate n b) = if b == a then n else 0 := by
  split <;> (rename_i h; simp only [beq_iff_eq] at h)
  · exact ‹b = a› ▸ count_replicate_self ..
  · exact count_eq_zero.2 <| mt eq_of_mem_replicate (Ne.symm h)","We discuss by cases based on the condition \( b = a \).

1. **Case 1: \( b = a \)**
- If \( b = a \), we need to show that \(\text{count}(a, \text{replicate}(n, b)) = n\).
- Since \( b = a \), we can use the theorem that the count of an element in a replicated list of itself is equal to the replication number, i.e., \(\text{count}(a, \text{replicate}(n, a)) = n\).
- Therefore, \(\text{count}(a, \text{replicate}(n, b)) = n\).

2. **Case 2: \( b \neq a \)**
- If \( b \neq a \), we need to show that \(\text{count}(a, \text{replicate}(n, b)) = 0\).
- Since \( b \neq a \), we use the theorem that the count of an element in a list is zero if and only if the element is not in the list, i.e., \(\text{count}(a, l) = 0 \leftrightarrow a \notin l\).
- We also use the fact that if \( b \) is in the list \(\text{replicate}(n, a)\), then \( b = a \). Since \( b \neq a \), it follows that \( b \) is not in the list \(\text{replicate}(n, a)\).
- Therefore, \(\text{count}(a, \text{replicate}(n, b)) = 0\).

In both cases, the theorem holds. This completes the proof. \(\blacksquare\)","theorem List.count_replicate (a b : α) (n : Nat) : count a (replicate n b) = if b == a then n else 0 := by
/- We discuss by cases based on the condition \( b = a \). If \( b = a \), we need to show that \(\text{count}(a, \text{replicate}(n, b)) = n\). If \( b \neq a \), we need to show that \(\text{count}(a, \text{replicate}(n, b)) = 0\). In each case, we rename the hypothesis and simplify the condition using the equivalence that boolean equality \(a == b = \text{true}\) is equivalent to logical equality \(a = b\). -/
  split <;> (rename_i h; simp only [beq_iff_eq] at h)
/- First, we show that if \( b = a \), then \(\text{count}(a, \text{replicate}(n, b)) = n\). Since \( b = a \), we can use the theorem that the count of an element in a replicated list of itself is equal to the replication number, i.e., \(\text{count}(a, \text{replicate}(n, a)) = n\). This completes the proof for this case. -/
  · exact ‹b = a› ▸ count_replicate_self ..
/- Next, we show that if \( b \neq a \), then \(\text{count}(a, \text{replicate}(n, b)) = 0\). Since \( b \neq a \), we use the theorem that the count of an element in a list is zero if and only if the element is not in the list. We also use the fact that if \( b \) is in the list \(\text{replicate}(n, a)\), then \( b = a \). Since \( b \neq a \), it follows that \( b \) is not in the list \(\text{replicate}(n, a)\), and thus \(\text{count}(a, \text{replicate}(n, b)) = 0\). This completes the proof for this case. -/
  · exact count_eq_zero.2 <| mt eq_of_mem_replicate (Ne.symm h)","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
variable [BEq α]
variable [LawfulBEq α]
"
12939,List.count_erase_self,"theorem List.count_erase_self (a : α) (l : List α) :
    count a (List.erase l a) = count a l - 1 := by sorry","Count of Element in List After Erasing Itself Decreases by One : For any list \( l \) of elements of type \( \alpha \) and any element \( a \in \alpha \), the number of occurrences of \( a \) in the list obtained by erasing the first occurrence of \( a \) from \( l \) is equal to the number of occurrences of \( a \) in \( l \) minus 1. Formally, for any \( a \in \alpha \) and list \( l \):
\[ \text{count}(a, \text{erase}(a, l)) = \text{count}(a, l) - 1 \]","theorem List.count_erase_self (a : α) (l : List α) :
    count a (List.erase l a) = count a l - 1 := by
  rw [count_erase, if_pos (by simp)]","We start by using the theorem that the count of an element \( a \) in a list \( l \) after erasing another element \( b \) is equal to the count of \( a \) in \( l \) minus 1 if \( a = b \), and equal to the count of \( a \) in \( l \) otherwise. This theorem simplifies our goal to:
\[ \text{count}(a, l) - \text{if } (a == a) = \text{true} \text{ then } 1 \text{ else } 0 = \text{count}(a, l) - 1 \]

Since the boolean equality \( a == a \) is true, the if-then-else expression \(\text{if } (a == a) = \text{true} \text{ then } 1 \text{ else } 0\) simplifies to 1. Therefore, our goal becomes:
\[ \text{count}(a, l) - 1 = \text{count}(a, l) - 1 \]

This equality is trivially true by the properties of equality. Hence, the number of occurrences of \( a \) in the list obtained by erasing the first occurrence of \( a \) from \( l \) is indeed equal to the number of occurrences of \( a \) in \( l \) minus 1. This completes the proof. \(\blacksquare\)","theorem List.count_erase_self (a : α) (l : List α) :
    count a (List.erase l a) = count a l - 1 := by
  rw [count_erase, if_pos (by simp)]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
variable [BEq α]
variable [LawfulBEq α]
"
12941,List.countP_cons_of_pos,theorem List.countP_cons_of_pos (l) (pa : p a) : countP p (a :: l) = countP p l + 1 := by sorry,"Count of Elements Satisfying a Predicate in Cons List: \(\text{countP}(p, a :: l) = \text{countP}(p, l) + 1\) if \( p(a) = \text{true} \) : For any type \( \alpha \), a predicate \( p : \alpha \to \text{Bool} \), and a list \( l \) of elements of type \( \alpha \), if \( p(a) = \text{true} \) for some element \( a \in \alpha \), then the count of elements in the list \( a :: l \) that satisfy \( p \) is equal to the count of elements in \( l \) that satisfy \( p \) plus one, i.e., \(\text{countP}(p, a :: l) = \text{countP}(p, l) + 1\).","theorem List.countP_cons_of_pos (l) (pa : p a) : countP p (a :: l) = countP p l + 1 := by
  have : countP.go p (a :: l) 0 = countP.go p l 1 := show cond .. = _ by rw [pa]; rfl
  unfold countP
  rw [this, Nat.add_comm, List.countP_go_eq_add]","We start by constructing a lemma that states \(\text{countP.go}(p, a :: l, 0) = \text{countP.go}(p, l, 1)\). This is because, by the definition of the conditional function `cond`, if \( p(a) = \text{true} \), then \(\text{countP.go}(p, a :: l, 0)\) is equivalent to \(\text{countP.go}(p, l, 0 + 1)\), which simplifies to \(\text{countP.go}(p, l, 1)\).

Next, we expand the definition of \(\text{countP}\). By definition, \(\text{countP}(p, a :: l)\) is equivalent to \(\text{countP.go}(p, a :: l, 0)\), and \(\text{countP}(p, l)\) is equivalent to \(\text{countP.go}(p, l, 0)\). Therefore, the goal \(\text{countP}(p, a :: l) = \text{countP}(p, l) + 1\) is equivalent to \(\text{countP.go}(p, a :: l, 0) = \text{countP.go}(p, l, 0) + 1\).

We now use the lemma we constructed in the first step, which states \(\text{countP.go}(p, a :: l, 0) = \text{countP.go}(p, l, 1)\). Substituting this into the goal, we get \(\text{countP.go}(p, l, 1) = \text{countP.go}(p, l, 0) + 1\). By the commutativity of addition, \(\text{countP.go}(p, l, 1) = 1 + \text{countP.go}(p, l, 0)\). Finally, using the theorem \(\text{countP.go}(p, l, n) = n + \text{countP.go}(p, l, 0)\), we see that \(\text{countP.go}(p, l, 1) = 1 + \text{countP.go}(p, l, 0)\) is trivially true. This completes the proof. \(\blacksquare\)","theorem List.countP_cons_of_pos (l) (pa : p a) : countP p (a :: l) = countP p l + 1 := by
/- First, we construct a lemma that states \(\text{countP.go}(p, a :: l, 0) = \text{countP.go}(p, l, 1)\). This is because, by the definition of the conditional function `cond`, if \( p(a) = \text{true} \), then \(\text{countP.go}(p, a :: l, 0)\) is equivalent to \(\text{countP.go}(p, l, 0 + 1)\), which simplifies to \(\text{countP.go}(p, l, 1)\). -/
  have : countP.go p (a :: l) 0 = countP.go p l 1 := show cond .. = _ by rw [pa]; rfl
/- Next, we expand the definition of \(\text{countP}\). By definition, \(\text{countP}(p, a :: l)\) is equivalent to \(\text{countP.go}(p, a :: l, 0)\), and \(\text{countP}(p, l)\) is equivalent to \(\text{countP.go}(p, l, 0)\). Therefore, the goal \(\text{countP}(p, a :: l) = \text{countP}(p, l) + 1\) is equivalent to \(\text{countP.go}(p, a :: l, 0) = \text{countP.go}(p, l, 0) + 1\). -/
  unfold countP
/- We now use the lemma we constructed in the first step, which states \(\text{countP.go}(p, a :: l, 0) = \text{countP.go}(p, l, 1)\). Substituting this into the goal, we get \(\text{countP.go}(p, l, 1) = \text{countP.go}(p, l, 0) + 1\). By the commutativity of addition, \(\text{countP.go}(p, l, 1) = 1 + \text{countP.go}(p, l, 0)\). Finally, using the theorem \(\text{countP.go}(p, l, n) = n + \text{countP.go}(p, l, 0)\), we see that \(\text{countP.go}(p, l, 1) = 1 + \text{countP.go}(p, l, 0)\) is trivially true. This completes the proof. -/
  rw [this, Nat.add_comm, List.countP_go_eq_add]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
"
12950,List.countP_go_eq_add,theorem List.countP_go_eq_add (l) : countP.go p l n = n + countP.go p l 0 := by sorry,"Count of Elements Satisfying a Predicate with Initial Count Equals Sum of Initial Count and Predicate Count : For any type \( \alpha \), a predicate \( p : \alpha \to \text{Bool} \), and a natural number \( n \), the function `countP.go` applied to a list \( l \) of elements of type \( \alpha \) and an initial count \( n \) returns the sum of \( n \) and the count of elements in \( l \) that satisfy \( p \), i.e., \(\text{countP.go}(p, l, n) = n + \text{countP.go}(p, l, 0)\).","theorem List.countP_go_eq_add (l) : countP.go p l n = n + countP.go p l 0 := by
  induction l generalizing n with
  | nil => rfl
  | cons head tail ih =>
    unfold countP.go
    rw [ih (n := n + 1), ih (n := n), ih (n := 1)]
    if h : p head then simp [h, Nat.add_assoc] else simp [h]","We prove this by induction on the list \( l \).

1. **Base Case:**
- If the list \( l \) is empty, the goal is to show that \(\text{countP.go}(p, [], n) = n + \text{countP.go}(p, [], 0)\).
- By the definition of `countP.go`, \(\text{countP.go}(p, [], n) = n\) and \(\text{countP.go}(p, [], 0) = 0\).
- Therefore, \(\text{countP.go}(p, [], n) = n + 0 = n\), which is trivially true.

2. **Inductive Step:**
- Assume the list \( l \) is of the form \( \text{cons}(head, tail) \).
- By the induction hypothesis, for any natural number \( n \), \(\text{countP.go}(p, tail, n) = n + \text{countP.go}(p, tail, 0)\).
- We need to show that \(\text{countP.go}(p, \text{cons}(head, tail), n) = n + \text{countP.go}(p, \text{cons}(head, tail), 0)\).

- **Case 1: \( p(head) = \text{true} \)**
- By the definition of `countP.go`, \(\text{countP.go}(p, \text{cons}(head, tail), n) = \text{countP.go}(p, tail, n + 1)\).
- Using the induction hypothesis, \(\text{countP.go}(p, tail, n + 1) = (n + 1) + \text{countP.go}(p, tail, 0)\).
- Therefore, \(\text{countP.go}(p, \text{cons}(head, tail), n) = (n + 1) + \text{countP.go}(p, tail, 0)\).
- Similarly, \(\text{countP.go}(p, \text{cons}(head, tail), 0) = 1 + \text{countP.go}(p, tail, 0)\).
- Thus, \( n + \text{countP.go}(p, \text{cons}(head, tail), 0) = n + (1 + \text{countP.go}(p, tail, 0)) = (n + 1) + \text{countP.go}(p, tail, 0) \).
- Therefore, \(\text{countP.go}(p, \text{cons}(head, tail), n) = n + \text{countP.go}(p, \text{cons}(head, tail), 0)\).

- **Case 2: \( p(head) = \text{false} \)**
- By the definition of `countP.go`, \(\text{countP.go}(p, \text{cons}(head, tail), n) = \text{countP.go}(p, tail, n)\).
- Using the induction hypothesis, \(\text{countP.go}(p, tail, n) = n + \text{countP.go}(p, tail, 0)\).
- Therefore, \(\text{countP.go}(p, \text{cons}(head, tail), n) = n + \text{countP.go}(p, tail, 0)\).
- Similarly, \(\text{countP.go}(p, \text{cons}(head, tail), 0) = \text{countP.go}(p, tail, 0)\).
- Thus, \( n + \text{countP.go}(p, \text{cons}(head, tail), 0) = n + \text{countP.go}(p, tail, 0) \).
- Therefore, \(\text{countP.go}(p, \text{cons}(head, tail), n) = n + \text{countP.go}(p, \text{cons}(head, tail), 0)\).

By induction, the theorem holds for all lists \( l \). This completes the proof. \(\blacksquare\)","theorem List.countP_go_eq_add (l) : countP.go p l n = n + countP.go p l 0 := by
  induction l generalizing n with
/- For the base case where the list is empty, the equality holds trivially by the reflexive property of equality. -/
  | nil => rfl
/- For the inductive step, we assume the list is of the form \( \text{cons}(head, tail) \) and use the induction hypothesis \( ih \) which states that for any natural number \( n \), \( \text{countP.go}(p, tail, n) = n + \text{countP.go}(p, tail, 0) \). -/
  | cons head tail ih =>
/- We expand the definition of the function `countP.go` to see how it behaves on the list \( \text{cons}(head, tail) \). -/
    unfold countP.go
/- We use the induction hypothesis to rewrite the goal. Specifically, we replace \( \text{countP.go}(p, tail, n + 1) \) with \( (n + 1) + \text{countP.go}(p, tail, 0) \), \( \text{countP.go}(p, tail, n) \) with \( n + \text{countP.go}(p, tail, 0) \), and \( \text{countP.go}(p, tail, 1) \) with \( 1 + \text{countP.go}(p, tail, 0) \). -/
    rw [ih (n := n + 1), ih (n := n), ih (n := 1)]
/- We consider two cases based on whether the predicate \( p \) holds for the head of the list. If \( p \) holds for the head, we use the associativity of addition to simplify the expression. If \( p \) does not hold for the head, we simplify the expression directly. -/
/- We again consider two cases based on whether the predicate \( p \) holds for the head of the list. If \( p \) holds for the head, we use the associativity of addition to simplify the expression. If \( p \) does not hold for the head, we simplify the expression directly. -/
    if h : p head then simp [h, Nat.add_assoc] else simp [h]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
"
12955,List.count_eq_length,"theorem List.count_eq_length {l : List α} : count a l = l.length ↔ ∀ b ∈ l, a = b := by sorry","Count of Element Equals List Length if and Only if All Elements are Equal: \(\text{count}(a, l) = \text{length}(l) \leftrightarrow \forall b \in l, b = a\) : For any type \(\alpha\) with a `BEq` instance and a `LawfulBEq` instance, and for any element \(a \in \alpha\) and list \(l\) of elements of \(\alpha\), the number of occurrences of \(a\) in \(l\) is equal to the length of \(l\) if and only if every element in \(l\) is equal to \(a\). In other words, \(\text{count}(a, l) = \text{length}(l) \leftrightarrow \forall b \in l, b = a\).","theorem List.count_eq_length {l : List α} : count a l = l.length ↔ ∀ b ∈ l, a = b := by
  rw [count, countP_eq_length]
  refine ⟨fun h b hb => Eq.symm ?_, fun h b hb => ?_⟩
  · simpa using h b hb
  · rw [h b hb, beq_self_eq_true]","We start by using the definition of `List.count` and the equivalence `List.countP_eq_length`. The definition of `List.count` states that \(\text{count}(a, l)\) is the number of elements in \(l\) that are equal to \(a\). The equivalence `List.countP_eq_length` states that the number of elements in \(l\) that satisfy a predicate \( p \) is equal to the length of \(l\) if and only if every element in \(l\) satisfies \( p \). Therefore, our goal is to show that for all \( a_1 \in l \), \( a_1 == a \) is true if and only if for all \( b \in l \), \( b = a \).

To prove this equivalence, we need to show both directions:

1. **(\(\Rightarrow\))**: Assume that for all \( a_1 \in l \), \( a_1 == a \) is true. We need to show that for all \( b \in l \), \( b = a \).
- Let \( b \in l \).
- By the assumption, \( b == a \) is true.
- By the property of boolean equality, \( b == a \) being true implies \( b = a \).
- Therefore, for all \( b \in l \), \( b = a \).

2. **(\(\Leftarrow\))**: Assume that for all \( b \in l \), \( b = a \). We need to show that for all \( a_1 \in l \), \( a_1 == a \) is true.
- Let \( a_1 \in l \).
- By the assumption, \( a_1 = a \).
- By the property of boolean equality, \( a_1 = a \) implies \( a_1 == a \) is true.
- Therefore, for all \( a_1 \in l \), \( a_1 == a \) is true.

Since both directions are proven, we conclude that \(\text{count}(a, l) = \text{length}(l) \leftrightarrow \forall b \in l, b = a\). This completes the proof. \(\blacksquare\)","theorem List.count_eq_length {l : List α} : count a l = l.length ↔ ∀ b ∈ l, a = b := by
/- First, we use the definition of `List.count` and the equivalence `List.countP_eq_length` to rewrite the goal. The definition of `List.count` states that `count a l` is the number of elements in `l` that are equal to `a`. The equivalence `List.countP_eq_length` states that the number of elements in `l` that satisfy a predicate \( p \) is equal to the length of `l` if and only if every element in `l` satisfies \( p \). Therefore, our goal is now to show that for all \( a_1 \in l \), \( a_1 == a \) is true if and only if for all \( b \in l \), \( b = a \). -/
  rw [count, countP_eq_length]
/- To prove the equivalence, we need to show both directions. We assume \( h \) is the hypothesis that for all \( a_1 \in l \), \( a_1 == a \) is true, and we need to show that for all \( b \in l \), \( b = a \). Conversely, we assume \( h \) is the hypothesis that for all \( b \in l \), \( b = a \), and we need to show that for all \( a_1 \in l \), \( a_1 == a \) is true. This splits the proof into two subgoals. -/
  refine ⟨fun h b hb => Eq.symm ?_, fun h b hb => ?_⟩
/- For the first subgoal, we assume \( h \) and \( b \in l \). Using the hypothesis \( h \), we know that \( b == a \) is true. By the property of boolean equality, \( b == a \) being true implies \( b = a \). Therefore, we have shown that for all \( b \in l \), \( b = a \). -/
  · simpa using h b hb
/- For the second subgoal, we assume \( h \) and \( b \in l \). Using the hypothesis \( h \), we know that \( b = a \). By the property of boolean equality, \( b = a \) implies \( b == a \) is true. Therefore, we have shown that for all \( a_1 \in l \), \( a_1 == a \) is true. -/
  · rw [h b hb, beq_self_eq_true]","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
variable [BEq α]
variable [LawfulBEq α]
"
12985,List.countP_mono_left,"theorem List.countP_mono_left (h : ∀ x ∈ l, p x → q x) : countP p l ≤ countP q l := by sorry","Monotonicity of CountP with Respect to Predicates: \(\text{countP}(p, l) \leq \text{countP}(q, l)\) : For any type \(\alpha\), and for any predicates \(p, q : \alpha \to \text{Bool}\) and list \(l : \text{List}(\alpha)\), if for every element \(x \in l\), \(p(x) = \text{true}\) implies \(q(x) = \text{true}\), then the number of elements in \(l\) that satisfy \(p\) is less than or equal to the number of elements in \(l\) that satisfy \(q\). In mathematical notation, this is expressed as:
\[
\forall x \in l, \, p(x) = \text{true} \implies q(x) = \text{true} \implies \text{countP}(p, l) \leq \text{countP}(q, l).
\]","theorem List.countP_mono_left (h : ∀ x ∈ l, p x → q x) : countP p l ≤ countP q l := by
  induction l with
  | nil => apply Nat.le_refl
  | cons a l ihl =>
    rw [forall_mem_cons] at h
    have ⟨ha, hl⟩ := h
    simp [countP_cons]
    cases h : p a
    · simp only [Bool.false_eq_true, ↓reduceIte, Nat.add_zero]
      apply Nat.le_trans ?_ (Nat.le_add_right _ _)
      apply ihl hl
    · simp only [↓reduceIte, ha h, succ_le_succ_iff]
      apply ihl hl","We prove this by induction on the list \(l\).

1. **Base Case:**
- Consider the case where the list \(l\) is empty, i.e., \(l = \text{nil}\).
- The number of elements in the empty list that satisfy \(p\) is zero, and the number of elements in the empty list that satisfy \(q\) is also zero.
- Since \(0 \leq 0\), the inequality holds trivially.

2. **Inductive Step:**
- Consider the case where the list \(l\) is of the form \(a :: l\), where \(a\) is an element of type \(\alpha\) and \(l\) is a list of elements of type \(\alpha\).
- We need to show that \(\text{countP}(p, a :: l) \leq \text{countP}(q, a :: l)\).
- By the definition of \(\text{countP}\) for a cons list, we have:
\[
\text{countP}(p, a :: l) = \text{countP}(p, l) + \text{if } p(a) = \text{true} \text{ then } 1 \text{ else } 0
\]
and
\[
\text{countP}(q, a :: l) = \text{countP}(q, l) + \text{if } q(a) = \text{true} \text{ then } 1 \text{ else } 0.
\]
- We need to show:
\[
\text{countP}(p, l) + \text{if } p(a) = \text{true} \text{ then } 1 \text{ else } 0 \leq \text{countP}(q, l) + \text{if } q(a) = \text{true} \text{ then } 1 \text{ else } 0.
\]
- We consider two cases based on the value of \(p(a)\):
- **Case 1: \(p(a) = \text{false}\)**
- In this case, \(\text{if } p(a) = \text{true} \text{ then } 1 \text{ else } 0 = 0\).
- The goal simplifies to:
\[
\text{countP}(p, l) \leq \text{countP}(q, l) + \text{if } q(a) = \text{true} \text{ then } 1 \text{ else } 0.
\]
- Since \(\text{countP}(q, l) \leq \text{countP}(q, l) + 1\) (because adding a non-negative number to a number preserves the order), it suffices to show:
\[
\text{countP}(p, l) \leq \text{countP}(q, l).
\]
- By the induction hypothesis, this holds.
- **Case 2: \(p(a) = \text{true}\)**
- In this case, \(\text{if } p(a) = \text{true} \text{ then } 1 \text{ else } 0 = 1\).
- Since \(p(a) = \text{true}\) implies \(q(a) = \text{true}\), we have \(\text{if } q(a) = \text{true} \text{ then } 1 \text{ else } 0 = 1\).
- The goal simplifies to:
\[
\text{countP}(p, l) + 1 \leq \text{countP}(q, l) + 1.
\]
- This is equivalent to:
\[
\text{countP}(p, l) \leq \text{countP}(q, l).
\]
- By the induction hypothesis, this holds.

Thus, by induction, the theorem is proved. \(\blacksquare\)","theorem List.countP_mono_left (h : ∀ x ∈ l, p x → q x) : countP p l ≤ countP q l := by
  induction l with
/- We consider the base case where the list `l` is empty. In this case, the number of elements in the empty list that satisfy `p` is zero, and the number of elements in the empty list that satisfy `q` is also zero. Since zero is equal to zero, the inequality holds trivially. -/
  | nil => apply Nat.le_refl
/- We consider the inductive case where the list `l` is of the form `a :: l`, where `a` is an element of type `α` and `l` is a list of elements of type `α`. We will use the induction hypothesis `ihl` to prove the goal for this case. -/
  | cons a l ihl =>
/- We use the equivalence that for all elements `x` in the list `a :: l`, if `p(x)` is true, then `q(x)` is true, which is equivalent to the conjunction of `p(a)` being true implies `q(a)` is true and for all elements `x` in the list `l`, if `p(x)` is true, then `q(x)` is true. This allows us to split the assumption `h` into two parts: `ha` and `hl`. -/
    rw [forall_mem_cons] at h
/- We construct a lemma that splits the assumption `h` into two parts: `ha`, which states that if `p(a)` is true, then `q(a)` is true, and `hl`, which states that for all elements `x` in the list `l`, if `p(x)` is true, then `q(x)` is true. -/
    have ⟨ha, hl⟩ := h
/- Using the definition of `countP` for a cons list, we simplify the goal to show that the number of elements in the list `a :: l` that satisfy `p` is less than or equal to the number of elements in the list `a :: l` that satisfy `q`. This simplifies to showing that `countP p l + (if p a = true then 1 else 0) ≤ countP q l + (if q a = true then 1 else 0)`. -/
    simp [countP_cons]
/- We consider two cases based on the value of `p(a)`:
1. `p(a) = false`
2. `p(a) = true` -/
    cases h : p a
/- In the case where `p(a) = false`, we simplify the goal using the fact that `false` is not equal to `true` and the properties of the if-then-else function. This simplifies the goal to showing that `countP p l ≤ countP q l + (if q a = true then 1 else 0)`. -/
    · simp only [Bool.false_eq_true, ↓reduceIte, Nat.add_zero]
/- To prove the current goal, we use the transitivity of the less than or equal to relation and the fact that adding a non-negative number to a number preserves the order. It suffices to show that `countP p l ≤ countP q l`. -/
      apply Nat.le_trans ?_ (Nat.le_add_right _ _)
/- To prove the current goal, using the induction hypothesis `ihl` and the assumption `hl`, it suffices to show that the number of elements in the list `l` that satisfy `p` is less than or equal to the number of elements in the list `l` that satisfy `q`. -/
      apply ihl hl
/- In the case where `p(a) = true`, we simplify the goal using the fact that `p(a) = true` implies `q(a) = true` and the properties of the if-then-else function. This simplifies the goal to showing that `countP p l + 1 ≤ countP q l + 1`, which is equivalent to showing that `countP p l ≤ countP q l`. -/
    · simp only [↓reduceIte, ha h, succ_le_succ_iff]
/- To prove the current goal, using the induction hypothesis `ihl` and the assumption `hl`, it suffices to show that the number of elements in the list `l` that satisfy `p` is less than or equal to the number of elements in the list `l` that satisfy `q`. -/
/- To prove the current goal, using the induction hypothesis `ihl` and the assumption `hl`, it suffices to show that the number of elements in the list `l` that satisfy `p` is less than or equal to the number of elements in the list `l` that satisfy `q`. -/
      apply ihl hl","import Init.Data.List.Sublist
import Init.Data.List.Count

open List
open Nat
variable (p q : α → Bool)
variable {p q}
"
13849,Array.data_toArray,theorem Array.data_toArray (as : List α) : as.toArray.data = as := by sorry,"List to Array Conversion is Invertible: \((\text{List.toArray } as).data = as\) : For any list \( as \) of elements of type \( \alpha \), the list obtained by converting the array back to a list after converting the list to an array is equal to the original list \( as \). In other words, \((\text{List.toArray } as).data = as\).","theorem Array.data_toArray (as : List α) : as.toArray.data = as := by
  simp [List.toArray, Array.mkEmpty]","To prove that \((\text{List.toArray } as).data = as\), we use the definitions of the functions involved:
- `List.toArray` converts a list to an array.
- `Array.mkEmpty` creates an empty array of a given type.

By applying these definitions, we can simplify the expression \((\text{List.toArray } as).data\) to \( as \). This simplification shows that the list obtained by converting the array back to a list is indeed the original list \( as \). Therefore, the proposition \((\text{List.toArray } as).data = as\) holds true. This completes the proof.","theorem Array.data_toArray (as : List α) : as.toArray.data = as := by
/- Using the definitions of `List.toArray` and `Array.mkEmpty`, we can simplify the proposition we want to show, which is \((\text{List.toArray } as).data = as\), to a trivially true statement. This means that the list obtained by converting the array back to a list after converting the list to an array is indeed equal to the original list \( as \). -/
  simp [List.toArray, Array.mkEmpty]","import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Fin.Basic
import Init.Data.UInt.Basic
import Init.Data.Repr
import Init.Data.ToString.Basic
import Init.GetElem
import Init.Data.Array.Basic

open Array
variable {α : Type u}
"
13867,Array.reverse.termination,theorem Array.reverse.termination {i j : Nat} (h : i < j) : j - 1 - (i + 1) < j - i := by sorry,"Subtraction Inequality for Natural Numbers: \( j - 1 - (i + 1) < j - i \) : For any natural numbers \( i \) and \( j \) such that \( i < j \), it holds that \( j - 1 - (i + 1) < j - i \).","theorem Array.reverse.termination {i j : Nat} (h : i < j) : j - 1 - (i + 1) < j - i := by
  rw [Nat.sub_sub, Nat.add_comm]
  exact Nat.lt_of_le_of_lt (Nat.pred_le _) (Nat.sub_succ_lt_self _ _ h)","We start with the goal of proving \( j - 1 - (i + 1) < j - i \). First, we use the identity \( a - b - c = a - (b + c) \) to rewrite the goal as \( j - (1 + (i + 1)) < j - i \). Then, we use the commutativity of addition \( a + b = b + a \) to further rewrite the goal as \( j - (i + 1 + 1) < j - i \).

To prove \( j - (i + 1 + 1) < j - i \), we use the transitivity of less-than-or-equal and less-than. Specifically, we show that \( j - (i + 2) \leq j - (i + 1) \) and \( j - (i + 1) < j - i \). The first inequality \( j - (i + 2) \leq j - (i + 1) \) holds because the predecessor of any natural number is less than or equal to the number itself. The second inequality \( j - (i + 1) < j - i \) holds because subtracting the successor of a number from another number preserves the strict inequality. Since \( i < j \), we have \( j - (i + 1) < j - i \). Therefore, by transitivity, \( j - (i + 2) < j - i \).

This completes the proof.","theorem Array.reverse.termination {i j : Nat} (h : i < j) : j - 1 - (i + 1) < j - i := by
/- First, we use the identity \( a - b - c = a - (b + c) \) to rewrite the goal \( j - 1 - (i + 1) < j - i \) as \( j - (1 + (i + 1)) < j - i \). Then, we use the commutativity of addition \( a + b = b + a \) to further rewrite the goal as \( j - (i + 1 + 1) < j - i \). -/
  rw [Nat.sub_sub, Nat.add_comm]
/- To prove \( j - (i + 1 + 1) < j - i \), we use the transitivity of less-than-or-equal and less-than. Specifically, we show that \( j - (i + 2) \leq j - (i + 1) \) and \( j - (i + 1) < j - i \). The first inequality \( j - (i + 2) \leq j - (i + 1) \) holds because the predecessor of any natural number is less than or equal to the number itself. The second inequality \( j - (i + 1) < j - i \) holds because subtracting the successor of a number from another number preserves the strict inequality. Since \( i < j \), we have \( j - (i + 1) < j - i \). Therefore, by transitivity, \( j - (i + 2) < j - i \). -/
  exact Nat.lt_of_le_of_lt (Nat.pred_le _) (Nat.sub_succ_lt_self _ _ h)","import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Fin.Basic
import Init.Data.UInt.Basic
import Init.Data.Repr
import Init.Data.ToString.Basic
import Init.GetElem
import Init.Data.Array.Basic

open Array
open reverse
variable {α : Type u}
"
13870,Array.toArrayAux_eq,theorem Array.toArrayAux_eq (as : List α) (acc : Array α) : (as.toArrayAux acc).data = acc.data ++ as := by sorry,"List to Array Conversion with Auxiliary Function: \((\text{List.toArrayAux } as \, acc).data = acc.data \, ++ \, as\) : For any type \( \alpha \) and any list \( as \) of elements of type \( \alpha \), and any array \( acc \) of elements of type \( \alpha \), the data of the array obtained by appending the elements of \( as \) to \( acc \) using the auxiliary function `toArrayAux` is equal to the concatenation of the data of \( acc \) and the list \( as \). In other words, \((\text{List.toArrayAux } as \, acc).data = acc.data \, ++ \, as\).","theorem Array.toArrayAux_eq (as : List α) (acc : Array α) : (as.toArrayAux acc).data = acc.data ++ as := by
  induction as generalizing acc <;> simp [*, List.toArrayAux, Array.push, List.append_assoc, List.concat_eq_append]","We perform induction on the list \( as \).

**Base Case:**
For the base case, we need to show that \((\text{List.toArrayAux } \text{nil} \, acc).data = acc.data \, ++ \, \text{nil}\).

By the definition of `List.toArrayAux`, \(\text{List.toArrayAux } \text{nil} \, acc = acc\). Therefore, \((\text{List.toArrayAux } \text{nil} \, acc).data = acc.data\).

Since the concatenation of any list with the empty list is the list itself, we have \(acc.data \, ++ \, \text{nil} = acc.data\).

Thus, \((\text{List.toArrayAux } \text{nil} \, acc).data = acc.data \, ++ \, \text{nil}\).

**Inductive Step:**
For the inductive step, assume that for any array \( acc \), \((\text{List.toArrayAux } \text{tail} \, acc).data = acc.data \, ++ \, \text{tail}\). We need to show that \((\text{List.toArrayAux } (\text{head} :: \text{tail}) \, acc).data = acc.data \, ++ \, (\text{head} :: \text{tail})\).

By the definition of `List.toArrayAux`, \(\text{List.toArrayAux } (\text{head} :: \text{tail}) \, acc = \text{List.toArrayAux } \text{tail} \, (acc.push \, \text{head})\).

By the inductive hypothesis, \((\text{List.toArrayAux } \text{tail} \, (acc.push \, \text{head})).data = (acc.push \, \text{head}).data \, ++ \, \text{tail}\).

By the definition of `Array.push`, \((acc.push \, \text{head}).data = acc.data \, ++ \, [\text{head}]\).

Using the property that concatenating an element to a list is equivalent to appending a singleton list, we have \(acc.data \, ++ \, [\text{head}] \, ++ \, \text{tail} = acc.data \, ++ \, (\text{head} :: \text{tail})\).

Thus, \((\text{List.toArrayAux } (\text{head} :: \text{tail}) \, acc).data = acc.data \, ++ \, (\text{head} :: \text{tail})\).

By induction, the theorem holds for all lists \( as \).

\(\blacksquare\)","theorem Array.toArrayAux_eq (as : List α) (acc : Array α) : (as.toArrayAux acc).data = acc.data ++ as := by
/- We perform induction on the list \( as \) to break down the proof into cases. For the base case, we need to show that \((\text{List.toArrayAux } \text{nil} \, acc).data = acc.data \, ++ \, \text{nil}\). For the inductive step, we assume that for any array \( acc \), \((\text{List.toArrayAux } \text{tail} \, acc).data = acc.data \, ++ \, \text{tail}\) and need to show that \((\text{List.toArrayAux } (\text{head} :: \text{tail}) \, acc).data = acc.data \, ++ \, (\text{head} :: \text{tail})\). We then simplify the goal using the definitions of `List.toArrayAux`, `Array.push`, the associativity of list append, and the property that concatenating an element to a list is equivalent to appending a singleton list. -/
  induction as generalizing acc <;> simp [*, List.toArrayAux, Array.push, List.append_assoc, List.concat_eq_append]","import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Fin.Basic
import Init.Data.UInt.Basic
import Init.Data.Repr
import Init.Data.ToString.Basic
import Init.GetElem
import Init.Data.Array.Basic

open Array
variable {α : Type u}
"
13914,Array.ext',theorem Array.ext' {as bs : Array α} (h : as.data = bs.data) : as = bs := by sorry,"Array Extensionality: $as.data = bs.data \to as = bs$ : For any type $\alpha$ and any two arrays $as$ and $bs$ of type `Array $\alpha$`, if the underlying lists of elements in $as$ and $bs$ are equal, i.e., $as.data = bs.data$, then the arrays $as$ and $bs$ are equal, i.e., $as = bs$.","theorem Array.ext' {as bs : Array α} (h : as.data = bs.data) : as = bs := by
  cases as; cases bs; simp at h; rw [h]","To prove that $as = bs$ given that $as.data = bs.data$, we start by considering the cases for the arrays $as$ and $bs$. Since both $as$ and $bs$ are constructed using the `Array.mk` function, we can write $as = \text{Array.mk}(as.data)$ and $bs = \text{Array.mk}(bs.data)$.

Given the hypothesis that $as.data = bs.data$, we can simplify this hypothesis to reflect the equality of the underlying lists. By substituting $as.data$ with $bs.data$ in the goal, we reduce the goal to showing that $\text{Array.mk}(as.data) = \text{Array.mk}(bs.data)$. Since $as.data = bs.data$, this equality is trivially true by the properties of equality. Therefore, we conclude that $as = bs$. This completes the proof. $\blacksquare$","theorem Array.ext' {as bs : Array α} (h : as.data = bs.data) : as = bs := by
/- We consider the cases for the arrays $as$ and $bs$. Since both $as$ and $bs$ are constructed using the `Array.mk` function, we can assume that $as = \text{Array.mk}(as.data)$ and $bs = \text{Array.mk}(bs.data)$. Using the fact that the underlying lists of elements in $as$ and $bs$ are equal, i.e., $as.data = bs.data$, we can simplify the hypothesis $h$ to reflect this equality. Then, by substituting $as.data$ with $bs.data$ in the goal, we reduce the goal to showing that $\text{Array.mk}(as.data) = \text{Array.mk}(bs.data)$. Since $as.data = bs.data$, this is trivially true by the properties of equality. -/
  cases as; cases bs; simp at h; rw [h]","import Init.WFTactics
import Init.Data.Nat.Basic
import Init.Data.Fin.Basic
import Init.Data.UInt.Basic
import Init.Data.Repr
import Init.Data.ToString.Basic
import Init.GetElem
import Init.Data.Array.Basic

open Array
variable {α : Type u}
"
15529,Nat.mod_mul_left_div_self,theorem Nat.mod_mul_left_div_self (m n k : Nat) : m % (k * n) / n = m / n % k := by sorry,"Modulo and Division Identity: \(\frac{m \mod (k \cdot n)}{n} = \left( \frac{m}{n} \right) \mod k\) : For any natural numbers \( m \), \( n \), and \( k \), the following identity holds:
\[ \frac{m \mod (k \cdot n)}{n} = \left( \frac{m}{n} \right) \mod k. \]","theorem Nat.mod_mul_left_div_self (m n k : Nat) : m % (k * n) / n = m / n % k := by
  rw [Nat.mul_comm k n, mod_mul_right_div_self]","To prove the identity \(\frac{m \mod (k \cdot n)}{n} = \left( \frac{m}{n} \right) \mod k\), we start by using the commutativity of multiplication. This allows us to rewrite \( k \cdot n \) as \( n \cdot k \). Therefore, the left-hand side of the identity becomes \(\frac{m \mod (n \cdot k)}{n}\).

Next, we apply the known identity \(\frac{m \mod (n \cdot k)}{n} = \left( \frac{m}{n} \right) \mod k\). This identity directly simplifies our goal to \(\left( \frac{m}{n} \right) \mod k\), which is exactly the right-hand side of the original identity.

Thus, we have shown that:
\[ \frac{m \mod (k \cdot n)}{n} = \left( \frac{m}{n} \right) \mod k. \]

This completes the proof.","theorem Nat.mod_mul_left_div_self (m n k : Nat) : m % (k * n) / n = m / n % k := by
/- First, we use the commutativity of multiplication to rewrite \( k \cdot n \) as \( n \cdot k \). Then, we apply the identity \(\frac{m \mod (n \cdot k)}{n} = \left( \frac{m}{n} \right) \mod k\) to the goal. This simplifies the goal to \(\frac{m \mod (n \cdot k)}{n} = \left( \frac{m}{n} \right) \mod k\), which is exactly what we need to prove. -/
  rw [Nat.mul_comm k n, mod_mul_right_div_self]","import Init.Omega
import Init.Data.Nat.Mod

open Nat

"
15530,Nat.mul_lt_mul_right,theorem Nat.mul_lt_mul_right (a0 : 0 < a) : b * a < c * a ↔ b < c := by sorry,"Multiplication Preserves Strict Inequality on the Right in Natural Numbers : For any natural numbers \( b \) and \( c \) and a nonzero natural number \( a \), the inequality \( b \cdot a < c \cdot a \) holds if and only if \( b < c \).","theorem Nat.mul_lt_mul_right (a0 : 0 < a) : b * a < c * a ↔ b < c := by
  rw [Nat.mul_comm b a, Nat.mul_comm c a, Nat.mul_lt_mul_left a0]","We start with the goal of proving that \( b \cdot a < c \cdot a \) if and only if \( b < c \) for any natural numbers \( b \) and \( c \) and a nonzero natural number \( a \).

1. **Rewriting the Goal:**
Using the commutativity of multiplication, we rewrite \( b \cdot a \) as \( a \cdot b \) and \( c \cdot a \) as \( a \cdot c \). This transforms the goal from \( b \cdot a < c \cdot a \leftrightarrow b < c \) to \( a \cdot b < a \cdot c \leftrightarrow b < c \).

2. **Applying the Theorem:**
We use the theorem that for any positive natural number \( a \), the inequality \( a \cdot b < a \cdot c \) holds if and only if \( b < c \). Since \( a \) is positive, this theorem allows us to conclude that \( a \cdot b < a \cdot c \leftrightarrow b < c \) is equivalent to \( b < c \leftrightarrow b < c \).

3. **Conclusion:**
The statement \( b < c \leftrightarrow b < c \) is trivially true. Therefore, we have shown that \( b \cdot a < c \cdot a \) if and only if \( b < c \).

This completes the proof. \(\blacksquare\)","theorem Nat.mul_lt_mul_right (a0 : 0 < a) : b * a < c * a ↔ b < c := by
/- First, we use the commutativity of multiplication to rewrite the goal. Specifically, we rewrite \( b * a \) as \( a * b \) and \( c * a \) as \( a * c \). This transforms the goal from \( b * a < c * a \leftrightarrow b < c \) to \( a * b < a * c \leftrightarrow b < c \). Then, we use the theorem that for any positive natural number \( a \), the inequality \( a * b < a * c \) holds if and only if \( b < c \). This theorem, combined with the fact that \( a \) is positive, allows us to conclude that \( a * b < a * c \leftrightarrow b < c \) is equivalent to \( b < c \leftrightarrow b < c \), which is trivially true. -/
  rw [Nat.mul_comm b a, Nat.mul_comm c a, Nat.mul_lt_mul_left a0]","import Init.Omega
import Init.Data.Nat.Mod

open Nat

"
15531,Nat.lt_of_mul_lt_mul_right,theorem Nat.lt_of_mul_lt_mul_right {a b c : Nat} (h : b * a < c * a) : b < c := by sorry,"Right Multiplication Cancellation in Natural Numbers: \(b \cdot a < c \cdot a \to b < c\) : For any natural numbers \(a\), \(b\), and \(c\), if \(a \neq 0\) and \(b \cdot a < c \cdot a\), then \(b < c\).","theorem Nat.lt_of_mul_lt_mul_right {a b c : Nat} (h : b * a < c * a) : b < c := by
  rw [Nat.mul_comm b a, Nat.mul_comm c a] at h
  exact Nat.lt_of_mul_lt_mul_left h","We start with the assumption that \( b \cdot a < c \cdot a \) and \( a \neq 0 \). By the commutativity of multiplication in natural numbers, we can rewrite the assumption as \( a \cdot b < a \cdot c \).

Next, we use the theorem that if \( a \cdot b < a \cdot c \) and \( a \geq 0 \), then \( b < c \). Since \( a \) is a natural number, it is nonnegative by definition. Therefore, we can directly conclude that \( b < c \).

This completes the proof.","theorem Nat.lt_of_mul_lt_mul_right {a b c : Nat} (h : b * a < c * a) : b < c := by
/- Since the commutativity of multiplication in natural numbers states that \( a * b = b * a \) and \( a * c = c * a \), we can rewrite the assumption \( b * a < c * a \) as \( a * b < a * c \). -/
  rw [Nat.mul_comm b a, Nat.mul_comm c a] at h
/- By the theorem that if \( a * b < a * c \) and \( a \geq 0 \), then \( b < c \), we can directly conclude that \( b < c \) from the assumption \( a * b < a * c \). Since \( a \) is a natural number, it is nonnegative by definition. -/
  exact Nat.lt_of_mul_lt_mul_left h","import Init.Omega
import Init.Data.Nat.Mod

open Nat

"
15535,Nat.mul_lt_mul_left,theorem Nat.mul_lt_mul_left (a0 : 0 < a) : a * b < a * c ↔ b < c := by sorry,"Multiplication Preserves Strict Inequality on the Left in Natural Numbers : For any natural numbers \(a\), \(b\), and \(c\) such that \(a > 0\), the inequality \(a \cdot b < a \cdot c\) holds if and only if \(b < c\).","theorem Nat.mul_lt_mul_left (a0 : 0 < a) : a * b < a * c ↔ b < c := by
  induction a with
  | zero => simp_all
  | succ a ih =>
    cases a
    · simp
    · simp_all [succ_eq_add_one, Nat.right_distrib]
      omega","We will prove the theorem by induction on \(a\).

**Base Case:**
For \(a = 0\), the assumption \(0 < 0\) is false. Therefore, the implication \(0 \cdot b < 0 \cdot c \leftrightarrow b < c\) is trivially true.

**Inductive Step:**
Assume \(a = n + 1\) and that the inductive hypothesis \(0 < n \rightarrow (n \cdot b < n \cdot c \leftrightarrow b < c)\) holds. We need to show that \((n + 1) \cdot b < (n + 1) \cdot c \leftrightarrow b < c\).

First, we use the definitions of successor and the right distributive property to simplify the goal:
\[
(n + 1) \cdot b = n \cdot b + b \quad \text{and} \quad (n + 1) \cdot c = n \cdot c + c
\]
Thus, the goal becomes:
\[
n \cdot b + b + b < n \cdot c + c + c \leftrightarrow b < c
\]

We use the inductive hypothesis \(n \cdot b < n \cdot c \leftrightarrow b < c\) and the fact that adding the same positive number to both sides of an inequality preserves the inequality. Therefore, the goal is trivially true by the properties of natural numbers and the inductive hypothesis.

By induction, the theorem holds for all natural numbers \(a > 0\). This completes the proof. \(\blacksquare\)","theorem Nat.mul_lt_mul_left (a0 : 0 < a) : a * b < a * c ↔ b < c := by
  induction a with
/- For the base case where \(a = 0\), we simplify the goal using the fact that \(0 < 0\) is false, and thus the implication \(0 \cdot b < 0 \cdot c \leftrightarrow b < c\) is trivially true. -/
  | zero => simp_all
/- We perform induction on \(a\). For the inductive step, assume \(a = n + 1\) and that the inductive hypothesis \(0 < n \rightarrow (n \cdot b < n \cdot c \leftrightarrow b < c)\) holds. We need to show that \((n + 1) \cdot b < (n + 1) \cdot c \leftrightarrow b < c\). -/
  | succ a ih =>
/- We consider the two cases for \(a\): \(a = 0\) and \(a = n + 1\). -/
    cases a
/- For the case \(a = 0\), we simplify the goal using the fact that \(0 < 0\) is false, and thus the implication \(0 \cdot b < 0 \cdot c \leftrightarrow b < c\) is trivially true. -/
    · simp
/- For the case \(a = n + 1\), we use the definitions of successor and the right distributive property to simplify the goal. This transforms the goal into \(n \cdot b + b + b < n \cdot c + c + c \leftrightarrow b < c\). -/
    · simp_all [succ_eq_add_one, Nat.right_distrib]
/- We use the omega tactic to automatically handle the arithmetic reasoning for the base case, which is trivial. -/
/- We use the omega tactic to automatically handle the arithmetic reasoning for the inductive step, which is trivial. -/
      omega","import Init.Omega
import Init.Data.Nat.Mod

open Nat

"
15537,Nat.lt_of_mul_lt_mul_left,theorem Nat.lt_of_mul_lt_mul_left {a b c : Nat} (h : a * b < a * c) : b < c := by sorry,"Left Multiplication Cancellation in Natural Numbers: \(a \cdot b < a \cdot c \to b < c\) : For any natural numbers \(a\), \(b\), and \(c\), if \(a \neq 0\) and \(a \cdot b < a \cdot c\), then \(b < c\).","theorem Nat.lt_of_mul_lt_mul_left {a b c : Nat} (h : a * b < a * c) : b < c := by
  cases a <;> simp_all","We need to show that if \(a \cdot b < a \cdot c\) for natural numbers \(a\), \(b\), and \(c\), and \(a \neq 0\), then \(b < c\).

1. **Case 1: \(a = 0\)**

If \(a = 0\), the hypothesis \(a \cdot b < a \cdot c\) becomes \(0 \cdot b < 0 \cdot c\), which simplifies to \(0 < 0\). This is a contradiction, so this case is impossible.

2. **Case 2: \(a \neq 0\)**

If \(a \neq 0\), we can write \(a\) as \(a = n + 1\) for some natural number \(n\). The hypothesis \(a \cdot b < a \cdot c\) becomes \((n + 1) \cdot b < (n + 1) \cdot c\). Since \(n + 1\) is a positive natural number, we can cancel it from both sides of the inequality, which gives us \(b < c\).

Therefore, in the only possible case where \(a \neq 0\), we have \(b < c\). This completes the proof. \(\blacksquare\)","theorem Nat.lt_of_mul_lt_mul_left {a b c : Nat} (h : a * b < a * c) : b < c := by
/- We will consider two cases for the natural number \(a\): \(a = 0\) and \(a \neq 0\).

1. **Case 1: \(a = 0\)**

If \(a = 0\), then the hypothesis \(a \cdot b < a \cdot c\) becomes \(0 \cdot b < 0 \cdot c\), which simplifies to \(0 < 0\). This is a contradiction, so this case is impossible.

2. **Case 2: \(a \neq 0\)**

If \(a \neq 0\), we can write \(a\) as \(a = n + 1\) for some natural number \(n\). The hypothesis \(a \cdot b < a \cdot c\) becomes \((n + 1) \cdot b < (n + 1) \cdot c\). Since \(n + 1\) is a positive natural number, we can cancel it from both sides of the inequality, which gives us \(b < c\). -/
  cases a <;> simp_all","import Init.Omega
import Init.Data.Nat.Mod

open Nat

"
15541,Nat.mod_mul,theorem Nat.mod_mul {a b x : Nat} : x % (a * b) = x % a + a * (x / a % b) := by sorry,"Modulo Identity: \(x \mod (a \cdot b) = x \mod a + a \cdot (x \div a \mod b)\) : For any natural numbers \(a\), \(b\), and \(x\), the modulo operation \(x \mod (a \cdot b)\) is equal to \(x \mod a + a \cdot (x \div a \mod b)\). In other words, the remainder when \(x\) is divided by \(a \cdot b\) can be expressed as the sum of the remainder when \(x\) is divided by \(a\) and the product of \(a\) and the remainder when \(x \div a\) is divided by \(b\).","theorem Nat.mod_mul {a b x : Nat} : x % (a * b) = x % a + a * (x / a % b) := by
  rw [Nat.add_comm, ← Nat.div_add_mod (x % (a*b)) a, Nat.mod_mul_right_mod,
    Nat.mod_mul_right_div_self]","We start by using the commutativity of addition to rewrite the goal:
\[ x \% (a \cdot b) = a \cdot (x / a \% b) + x \% a. \]
Next, we apply the division and modulo identity:
\[ a \cdot (x \% (a \cdot b) / a) + x \% (a \cdot b) \% a = a \cdot (x / a \% b) + x \% a. \]
Then, we use the modulo of product modulo right argument identity to simplify the modulo operation:
\[ a \cdot (x \% (a \cdot b) / a) + x \% a = a \cdot (x / a \% b) + x \% a. \]
Finally, we apply the modulo and division identity to simplify the division operation:
\[ a \cdot (x / a \% b) + x \% a = a \cdot (x / a \% b) + x \% a. \]
Since the left-hand side and the right-hand side are now identical, the goal is trivially true. This completes the proof.","theorem Nat.mod_mul {a b x : Nat} : x % (a * b) = x % a + a * (x / a % b) := by
/- First, we use the commutativity of addition to rewrite the goal as:
\[ x \% (a \cdot b) = a \cdot (x / a \% b) + x \% a. \]
Next, we apply the division and modulo identity to rewrite the left-hand side:
\[ a \cdot (x \% (a \cdot b) / a) + x \% (a \cdot b) \% a = a \cdot (x / a \% b) + x \% a. \]
Then, we use the modulo of product modulo right argument identity to simplify the modulo operation:
\[ a \cdot (x \% (a \cdot b) / a) + x \% a = a \cdot (x / a \% b) + x \% a. \]
Finally, we apply the modulo and division identity to simplify the division operation:
\[ a \cdot (x / a \% b) + x \% a = a \cdot (x / a \% b) + x \% a. \]
Since the left-hand side and the right-hand side are now identical, the goal is trivially true. -/
  rw [Nat.add_comm, ← Nat.div_add_mod (x % (a*b)) a, Nat.mod_mul_right_mod,
    Nat.mod_mul_right_div_self]","import Init.Omega
import Init.Data.Nat.Mod

open Nat

"
15549,Nat.mod_pow_succ,"theorem Nat.mod_pow_succ {x b k : Nat} :
    x % b ^ (k + 1) = x % b ^ k + b ^ k * ((x / b ^ k) % b) := by sorry","Modulo Identity: \(x \mod b^{k+1} = x \mod b^k + b^k \cdot (x \div b^k \mod b)\) : For any natural numbers \(x\), \(b\), and \(k\), the modulo operation \(x \mod b^{k+1}\) is equal to \(x \mod b^k + b^k \cdot (x \div b^k \mod b)\). In other words, the remainder when \(x\) is divided by \(b^{k+1}\) can be expressed as the sum of the remainder when \(x\) is divided by \(b^k\) and the product of \(b^k\) and the remainder when \(x \div b^k\) is divided by \(b\).","theorem Nat.mod_pow_succ {x b k : Nat} :
    x % b ^ (k + 1) = x % b ^ k + b ^ k * ((x / b ^ k) % b) := by
  rw [Nat.pow_succ, Nat.mod_mul]","We start with the goal of proving that \( x \mod b^{k+1} = x \mod b^k + b^k \cdot (x \div b^k \mod b) \).

1. **Step 1: Apply the power of successor identity.**
- We use the identity for the power of a successor, which states that \( b^{k+1} = b^k \cdot b \). This transforms our goal from \( x \mod b^{k+1} \) to \( x \mod (b^k \cdot b) \).

2. **Step 2: Apply the modulo identity.**
- Next, we apply the modulo identity \( x \mod (a \cdot b) = x \mod a + a \cdot (x \div a \mod b) \) with \( a = b^k \) and \( b = b \). This simplifies our goal to \( x \mod b^k + b^k \cdot (x \div b^k \mod b) \).

Since the goal is now exactly the expression we want to prove, the proof is complete.

\[
\boxed{x \mod b^{k+1} = x \mod b^k + b^k \cdot (x \div b^k \mod b)}
\]","theorem Nat.mod_pow_succ {x b k : Nat} :
    x % b ^ (k + 1) = x % b ^ k + b ^ k * ((x / b ^ k) % b) := by
/- First, we use the identity for the power of a successor, which states that \( b^{k+1} = b^k \cdot b \). This transforms our goal from \( x \mod b^{k+1} \) to \( x \mod (b^k \cdot b) \). Next, we apply the modulo identity \( x \mod (a \cdot b) = x \mod a + a \cdot (x \div a \mod b) \) with \( a = b^k \) and \( b = b \). This simplifies our goal to \( x \mod b^k + b^k \cdot (x \div b^k \mod b) \). -/
  rw [Nat.pow_succ, Nat.mod_mul]","import Init.Omega
import Init.Data.Nat.Mod

open Nat

"
15686,Thunk.sizeOf_eq,theorem Thunk.sizeOf_eq [SizeOf α] (a : Thunk α) : sizeOf a = 1 + sizeOf a.get := by sorry,"Size of Thunk is One Plus Size of Forced Value : For any type \( \alpha \) with a `SizeOf` instance, and for any thunk \( a \) of type \( \alpha \), the size of the thunk \( a \) is equal to one plus the size of the value obtained by forcing the thunk \( a \), i.e., \(\text{sizeOf}(a) = 1 + \text{sizeOf}(a.\text{get})\).","theorem Thunk.sizeOf_eq [SizeOf α] (a : Thunk α) : sizeOf a = 1 + sizeOf a.get := by
   cases a; rfl","To prove the theorem, we start by considering the structure of a thunk \( a \). A thunk is a delayed computation that, when forced, produces a value of type \( \alpha \). By the definition of the size of a thunk, the size of \( a \) is defined as one plus the size of the value obtained by forcing the thunk. Therefore, the size of the thunk \( a \) is \(\text{sizeOf}(a) = 1 + \text{sizeOf}(a.\text{get})\). This equality is a direct consequence of the definition of the size of a thunk. Hence, the theorem is proved.","theorem Thunk.sizeOf_eq [SizeOf α] (a : Thunk α) : sizeOf a = 1 + sizeOf a.get := by
/- We consider the definition of a thunk \( a \). A thunk is a delayed computation that can be forced to produce a value. By examining the structure of \( a \), we see that it consists of a function that, when called, returns a value of type \( \alpha \). Therefore, the size of the thunk \( a \) is defined as one plus the size of the value obtained by forcing the thunk. This is a direct consequence of the definition of the size of a thunk. Hence, the goal \(\text{sizeOf}(a) = 1 + \text{sizeOf}(a.\text{get})\) is trivially true by the definition of the size of a thunk. -/
   cases a; rfl","import Init.Prelude
import Init.SizeOf
import Init.Core

open Thunk

"
15688,heq_of_eqRec_eq,theorem heq_of_eqRec_eq {α β : Sort u} {a : α} {b : β} (h₁ : α = β) (h₂ : Eq.rec (motive := fun α _ => α) a h₁ = b) : HEq a b := by sorry,"Heterogeneous Equality from Equality and Recursion : For any types \( \alpha \) and \( \beta \), and for any elements \( a : \alpha \) and \( b : \beta \), if \( \alpha \) and \( \beta \) are equal (i.e., \( \alpha = \beta \)), and if the result of applying the `Eq.rec` function to \( a \) and the equality \( \alpha = \beta \) is equal to \( b \) (i.e., \( \text{Eq.rec}(a, \alpha = \beta) = b \)), then \( a \) and \( b \) are heterogeneously equal (i.e., \( \text{HEq}(a, b) \)).","theorem heq_of_eqRec_eq {α β : Sort u} {a : α} {b : β} (h₁ : α = β) (h₂ : Eq.rec (motive := fun α _ => α) a h₁ = b) : HEq a b := by
  subst h₁
  apply heq_of_eq
  exact h₂","We start with the assumption that \( \alpha = \beta \). Using this equality, we can substitute \( \beta \) with \( \alpha \) in the goal and the hypothesis. This simplifies the goal to showing \( \text{HEq} \, a \, b \) where \( b \) is now of type \( \alpha \).

Next, we use the theorem that if \( a \) and \( b \) are equal within the same type \( \alpha \), then they are also heterogeneously equal. Therefore, to prove \( \text{HEq} \, a \, b \), it suffices to show that \( a = b \).

Finally, the hypothesis \( \text{Eq.rec}(a, \alpha = \beta) = b \) directly proves that \( a = b \). Hence, \( a \) and \( b \) are heterogeneously equal. This completes the proof.","theorem heq_of_eqRec_eq {α β : Sort u} {a : α} {b : β} (h₁ : α = β) (h₂ : Eq.rec (motive := fun α _ => α) a h₁ = b) : HEq a b := by
/- Since \( \alpha = \beta \), we can substitute \( \beta \) with \( \alpha \) in the goal and the hypothesis. This simplifies the goal to showing \( \text{HEq} \, a \, b \) where \( b \) is now of type \( \alpha \). -/
  subst h₁
/- To prove \( \text{HEq} \, a \, b \), it suffices to show that \( a = b \) because if \( a \) and \( b \) are equal within the same type \( \alpha \), then they are also heterogeneously equal. -/
  apply heq_of_eq
/- The current goal \( a = b \) is exactly proved by the hypothesis \( \text{Eq.rec}(a, \alpha = \beta) = b \). This completes the proof. -/
  exact h₂","import Init.Prelude
import Init.SizeOf
import Init.Core


variable {α : Sort u}
variable {a b : α} {p : Prop}
variable {a b : α} {p : Prop}
variable {α β φ : Sort u} {a a' : α} {b b' : β} {c : φ}
"
15738,Nat.zero_testBit,theorem Nat.zero_testBit (i : Nat) : testBit 0 i = false := by sorry,"Test Bit of Zero is Always False : For any natural number \( i \), the \( i \)-th bit in the binary representation of 0 is false, i.e., \( \text{testBit}(0, i) = \text{false} \).","theorem Nat.zero_testBit (i : Nat) : testBit 0 i = false := by
  simp only [testBit, zero_shiftRight, and_zero, bne_self_eq_false]","To prove that the \( i \)-th bit in the binary representation of 0 is false for any natural number \( i \), we use the following properties and definitions:

1. **Right Shift of Zero is Zero:**
For any natural number \( n \), the right shift of zero by \( n \) positions is zero, i.e., \( 0 \>>> n = 0 \).

2. **Conjunction with Zero:**
For any natural number \( x \), the conjunction of \( x \) and \( 0 \) is equal to \( 0 \), i.e., \( x \&&& 0 = 0 \).

3. **Boolean Not-Equal Function Returns False for Equal Elements:**
For any type \( \alpha \) with a `BEq` instance and a `LawfulBEq` instance, and for any element \( a \in \alpha \), the boolean not-equal function \( a != a \) returns `false`.

Using these properties, we can simplify the expression \( \text{testBit}(0, i) \):

- The `testBit` function checks if the \( i \)-th bit of a number is 1. This is done by right-shifting the number by \( i \) positions and then performing a conjunction with 1.
- Since the right shift of zero by any natural number \( i \) is zero, we have \( 0 \>>> i = 0 \).
- The conjunction of zero with 1 is zero, i.e., \( 0 \&&& 1 = 0 \).
- The boolean not-equal function \( 0 != 0 \) returns `false`.

Therefore, \( \text{testBit}(0, i) = \text{false} \) for any natural number \( i \). This completes the proof.","theorem Nat.zero_testBit (i : Nat) : testBit 0 i = false := by
/- Using the definitions and properties of the `testBit` function, the right shift of zero, the conjunction with zero, and the boolean not-equal function, we can simplify the proposition we want to show. Specifically, we use the fact that the right shift of zero by any natural number \( n \) is zero, the conjunction of any natural number with zero is zero, and the boolean not-equal function returns `false` when applied to equal elements. Therefore, the \( i \)-th bit in the binary representation of 0 is `false` for any natural number \( i \). -/
  simp only [testBit, zero_shiftRight, and_zero, bne_self_eq_false]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15746,Nat.testBit_succ,theorem Nat.testBit_succ (x i : Nat) : testBit x (succ i) = testBit (x/2) i := by sorry,"Test Bit of Successor in Natural Number Representation Equals Test Bit of Half : For any natural numbers \( x \) and \( i \), the \((i+1)\)-th least significant bit in the binary representation of \( x \) is equal to the \(i\)-th least significant bit in the binary representation of \( x / 2 \). Formally, this is expressed as:
\[ x.\text{testBit}(i + 1) = (x / 2).\text{testBit}(i). \]","theorem Nat.testBit_succ (x i : Nat) : testBit x (succ i) = testBit (x/2) i := by
  unfold testBit
  simp [shiftRight_succ_inside]","We start by expanding the definition of the `testBit` function. The function `testBit m n` returns `true` if the \((n+1)\)-th least significant bit in the binary representation of the natural number \( m \) is 1, and `false` otherwise. Therefore, the goal becomes:
\[ (1 \&\&& x \>>> (i + 1) \neq 0) = (1 \&\&& (x / 2) \>>> i \neq 0). \]

Next, we use the property of right shift for natural numbers, which states that for any natural numbers \( m \) and \( n \), the right shift of \( m \) by \( n + 1 \) positions is equal to the right shift of \( m / 2 \) by \( n \) positions, i.e., \( m \>>> (n + 1) = (m / 2) \>>> n \). Applying this property, we simplify the goal to:
\[ (1 \&\&& (x / 2) \>>> i \neq 0) = (1 \&\&& (x / 2) \>>> i \neq 0). \]
This is trivially true, thus completing the proof. \(\blacksquare\)","theorem Nat.testBit_succ (x i : Nat) : testBit x (succ i) = testBit (x/2) i := by
/- First, we expand the definition of the `testBit` function. The function `testBit m n` returns `true` if the \((n+1)\)-th least significant bit in the binary representation of the natural number \( m \) is 1, and `false` otherwise. Therefore, the goal becomes:
\[ (1 \&\&& x \>>> (i + 1) \neq 0) = (1 \&\&& (x / 2) \>>> i \neq 0). \] -/
  unfold testBit
/- Next, we use the property of right shift for natural numbers, which states that for any natural numbers \( m \) and \( n \), the right shift of \( m \) by \( n + 1 \) positions is equal to the right shift of \( m / 2 \) by \( n \) positions, i.e., \( m \>>> (n + 1) = (m / 2) \>>> n \). Applying this property, we simplify the goal to:
\[ (1 \&\&& (x / 2) \>>> i \neq 0) = (1 \&\&& (x / 2) \>>> i \neq 0). \]
This is trivially true, thus completing the proof. -/
  simp [shiftRight_succ_inside]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15755,Nat.testBit_one_zero,theorem Nat.testBit_one_zero : testBit 1 0 = true := by sorry,"Least Significant Bit of One is True : The function `testBit` applied to the natural number 1 and the index 0 returns `true`. In other words, the least significant bit (0th bit) in the binary representation of the natural number 1 is 1.
\[
\text{testBit}(1, 0) = \text{true}
\]","theorem Nat.testBit_one_zero : testBit 1 0 = true := by
  trivial","The proof is straightforward. The least significant bit (0th bit) in the binary representation of the natural number 1 is 1, which is equivalent to `true`. Therefore, the function `testBit` applied to 1 and 0 returns `true`. This completes the proof.","theorem Nat.testBit_one_zero : testBit 1 0 = true := by
  trivial","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15758,Nat.and_zero,theorem Nat.and_zero (x : Nat) : x &&& 0 = 0 := by sorry,"Conjunction with Zero: \( x \&&& 0 = 0 \) : For any natural number \( x \), the conjunction of \( x \) and \( 0 \) is equal to \( 0 \), i.e., \( x \&&& 0 = 0 \).","theorem Nat.and_zero (x : Nat) : x &&& 0 = 0 := by
  simp only [HAnd.hAnd, AndOp.and, land]
  unfold bitwise
  simp","To prove that \( x \&&& 0 = 0 \) for any natural number \( x \), we start by simplifying the goal using the definitions of the bundled logical ""and"" operation, the homogeneous conjunction operation, and the bitwise ""and"" operation. This simplifies the goal to showing that the bitwise ""and"" of \( x \) and \( 0 \) is equal to \( 0 \).

Next, we expand the definition of the bitwise ""and"" operation. This reveals the recursive structure of the operation, which depends on the binary representations of \( x \) and \( 0 \). Specifically, the operation checks if \( x \) is zero, and if so, it returns \( 0 \) because the boolean ""and"" of `false` and `true` is `false`. If \( x \) is not zero, it checks if \( 0 \) is zero, and if so, it returns \( 0 \) because the boolean ""and"" of `true` and `false` is `false`. If both \( x \) and \( 0 \) are non-zero, it recursively applies the bitwise ""and"" to the halves of \( x \) and \( 0 \), and then adds 1 to the result if the least significant bits of \( x \) and \( 0 \) are both 1, otherwise it just returns the result of the recursive call.

Finally, we simplify the expanded goal. Since \( 0 \) is always zero, the conditions in the if-then-else statements simplify to \( 0 \) in all cases. Therefore, the entire expression simplifies to \( 0 \), which completes the proof.

\[
\boxed{x \&&& 0 = 0}
\]","theorem Nat.and_zero (x : Nat) : x &&& 0 = 0 := by
/- First, we simplify the goal using the definitions of the bundled logical ""and"" operation, the homogeneous conjunction operation, and the bitwise ""and"" operation. This simplifies the goal to showing that the bitwise ""and"" of \( x \) and \( 0 \) is equal to \( 0 \). -/
  simp only [HAnd.hAnd, AndOp.and, land]
/- Next, we expand the definition of the bitwise ""and"" operation. This reveals the recursive structure of the operation, which depends on the binary representations of \( x \) and \( 0 \). Specifically, the operation checks if \( x \) is zero, and if so, it returns \( 0 \) because the boolean ""and"" of `false` and `true` is `false`. If \( x \) is not zero, it checks if \( 0 \) is zero, and if so, it returns \( 0 \) because the boolean ""and"" of `true` and `false` is `false`. If both \( x \) and \( 0 \) are non-zero, it recursively applies the bitwise ""and"" to the halves of \( x \) and \( 0 \), and then adds 1 to the result if the least significant bits of \( x \) and \( 0 \) are both 1, otherwise it just returns the result of the recursive call. -/
  unfold bitwise
/- Finally, we simplify the expanded goal. Since \( 0 \) is always zero, the conditions in the if-then-else statements simplify to \( 0 \) in all cases. Therefore, the entire expression simplifies to \( 0 \), which completes the proof. -/
  simp","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15759,Nat.testBit_add_one,theorem Nat.testBit_add_one (x i : Nat) : testBit x (i + 1) = testBit (x/2) i := by sorry,"Bit Test of \( x \) at Position \( i + 1 \) Equals Bit Test of \( x / 2 \) at Position \( i \) : For any natural numbers \( x \) and \( i \), the \((i+1)\)-th least significant bit in the binary representation of \( x \) is equal to the \(i\)-th least significant bit in the binary representation of \( x / 2 \). Formally, \( x.\text{testBit}(i + 1) = (x / 2).\text{testBit}(i) \).","theorem Nat.testBit_add_one (x i : Nat) : testBit x (i + 1) = testBit (x/2) i := by
  unfold testBit
  simp [shiftRight_succ_inside]","We start by expanding the definition of the `testBit` function. The function `testBit m n` returns `true` if the \((n+1)\)-th least significant bit in the binary representation of the natural number \( m \) is 1, and `false` otherwise. Therefore, the goal \( x.\text{testBit}(i + 1) = (x / 2).\text{testBit}(i) \) is equivalent to \( (1 \&&& x \>>> (i + 1) \neq 0) = (1 \&&& (x / 2) \>>> i \neq 0) \).

Next, we use the property of right shift in natural numbers, which states that for any natural numbers \( m \) and \( n \), the right shift of \( m \) by \( n + 1 \) positions is equal to the right shift of \( m / 2 \) by \( n \) positions, i.e., \( m \>>> (n + 1) = (m / 2) \>>> n \). Applying this property, we can simplify the expression \( 1 \&&& x \>>> (i + 1) \neq 0 \) to \( 1 \&&& (x / 2) \>>> i \neq 0 \).

Thus, we have shown that \( x.\text{testBit}(i + 1) = (x / 2).\text{testBit}(i) \). This completes the proof. \(\blacksquare\)","theorem Nat.testBit_add_one (x i : Nat) : testBit x (i + 1) = testBit (x/2) i := by
/- First, we expand the definition of the `testBit` function. The function `testBit m n` returns `true` if the \((n+1)\)-th least significant bit in the binary representation of the natural number \( m \) is 1, and `false` otherwise. Therefore, the goal \( x.\text{testBit}(i + 1) = (x / 2).\text{testBit}(i) \) is equivalent to \( (1 \&&& x \>>> (i + 1) \neq 0) = (1 \&&& (x / 2) \>>> i \neq 0) \). -/
  unfold testBit
/- Next, we use the property of right shift in natural numbers, which states that for any natural numbers \( m \) and \( n \), the right shift of \( m \) by \( n + 1 \) positions is equal to the right shift of \( m / 2 \) by \( n \) positions, i.e., \( m \>>> (n + 1) = (m / 2) \>>> n \). Applying this property, we can simplify the expression \( 1 \&&& x \>>> (i + 1) \neq 0 \) to \( 1 \&&& (x / 2) \>>> i \neq 0 \). This completes the proof. -/
  simp [shiftRight_succ_inside]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15763,Nat.zero_and,theorem Nat.zero_and (x : Nat) : 0 &&& x = 0 := by sorry,"Conjunction with Zero: \( 0 \&&& x = 0 \) : For any natural number \( x \), the conjunction of \( 0 \) and \( x \) is equal to \( 0 \), i.e., \( 0 \&&& x = 0 \).","theorem Nat.zero_and (x : Nat) : 0 &&& x = 0 := by
  simp only [HAnd.hAnd, AndOp.and, land]
  unfold bitwise
  simp","To prove that \( 0 \&&& x = 0 \) for any natural number \( x \), we start by using the definitions of the bundled logical ""and"" function, the homogeneous conjunction operation, and the bitwise ""and"" operation. This simplifies our goal to showing that \( \text{bitwise and } 0 \, x = 0 \).

Next, we expand the definition of the bitwise operation on natural numbers. According to this definition:
- If \( n = 0 \), the result is \( 0 \) if \( f(\text{false}, \text{true}) \) is true, otherwise it is \( 0 \).
- If \( m = 0 \), the result is \( 0 \) if \( f(\text{true}, \text{false}) \) is true, otherwise it is \( 0 \).
- For both \( n \) and \( m \) non-zero, the function recursively applies the bitwise operation to the halves of \( n \) and \( m \), and adds 1 to the result if the least significant bits of \( n \) and \( m \) are both 1, otherwise it just returns the result of the recursive call.

In our case, \( n = 0 \). Therefore, the first condition \( \text{if } 0 = 0 \) evaluates to true. The inner condition \( \text{if } (\text{false} \, \text{and} \, \text{true}) = \text{true} \) is false, so the result is \( 0 \).

Thus, we have shown that \( \text{bitwise and } 0 \, x = 0 \), which completes the proof. Therefore, \( 0 \&&& x = 0 \) for any natural number \( x \). \(\blacksquare\)","theorem Nat.zero_and (x : Nat) : 0 &&& x = 0 := by
/- Using the definitions of the bundled logical ""and"" function, the homogeneous conjunction operation, and the bitwise ""and"" operation, we can simplify the proposition we want to show to \( \text{bitwise and } 0 \, x = 0 \). -/
  simp only [HAnd.hAnd, AndOp.and, land]
/- Expand the definition of the bitwise operation on natural numbers. This definition states that for \( n = 0 \), the result is \( 0 \) if \( f(\text{false}, \text{true}) \) is true, otherwise it is \( 0 \). For \( m = 0 \), the result is \( 0 \) if \( f(\text{true}, \text{false}) \) is true, otherwise it is \( 0 \). For both \( n \) and \( m \) non-zero, the function recursively applies the bitwise operation to the halves of \( n \) and \( m \), and adds 1 to the result if the least significant bits of \( n \) and \( m \) are both 1, otherwise it just returns the result of the recursive call. -/
  unfold bitwise
/- Using the properties of the boolean ""and"" operation and the if-then-else function, we can simplify the expanded definition. Specifically, since \( 0 = 0 \) is true, the first condition \( \text{if } 0 = 0 \) evaluates to true. The inner condition \( \text{if } (\text{false} \, \text{and} \, \text{true}) = \text{true} \) is false, so the result is \( 0 \). Therefore, the goal is simplified to \( 0 = 0 \), which is trivially true. -/
  simp","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15764,Nat.testBit_implies_ge,theorem Nat.testBit_implies_ge {x : Nat} (p : testBit x i = true) : x ≥ 2^i := by sorry,"Bit Test Implies \( x \ge 2^i \) in Natural Numbers : For any natural numbers \( i \) and \( x \), if the \( i \)-th bit of \( x \) is true, then \( x \) is greater than or equal to \( 2^i \), i.e., \( x \ge 2^i \).","theorem Nat.testBit_implies_ge {x : Nat} (p : testBit x i = true) : x ≥ 2^i := by
  simp only [testBit_to_div_mod] at p
  apply Decidable.by_contra
  intro not_ge
  have x_lt : x < 2^i := Nat.lt_of_not_le not_ge
  simp [div_eq_of_lt x_lt] at p","We start with the hypothesis that the \( i \)-th bit of \( x \) is true. Using the identity that the \( i \)-th bit of \( x \) is true if and only if the remainder when \( x \) is divided by \( 2^i \) and then divided by 2 is 1, we can rewrite the hypothesis as \( \text{decide}(x / 2^i \% 2 = 1) = \text{true} \).

To prove \( x \ge 2^i \), we assume the negation, i.e., \( x < 2^i \). From this assumption, we have \( x < 2^i \). Using the fact that if \( x < 2^i \), then \( x / 2^i = 0 \), we can simplify the hypothesis to \( \text{decide}(0 \% 2 = 1) = \text{true} \). Since \( 0 \% 2 = 0 \), this simplifies to \( \text{decide}(0 = 1) = \text{true} \), which is a contradiction.

Therefore, the assumption \( x < 2^i \) must be false, and thus \( x \ge 2^i \). This completes the proof. \(\blacksquare\)","theorem Nat.testBit_implies_ge {x : Nat} (p : testBit x i = true) : x ≥ 2^i := by
/- Using the identity that the \( i \)-th bit of \( x \) is true if and only if the remainder when \( x \) is divided by \( 2^i \) and then divided by 2 is 1, we can simplify the hypothesis \( p \) to \( \text{decide}(x / 2^i \% 2 = 1) = \text{true} \). -/
  simp only [testBit_to_div_mod] at p
/- To prove \( x \ge 2^i \), we assume the negation, i.e., \( x < 2^i \), and show that this leads to a contradiction. -/
  apply Decidable.by_contra
/- Let \( \text{not\_ge} \) be the assumption that \( x < 2^i \). -/
  intro not_ge
/- From the assumption \( \text{not\_ge} \), we have \( x < 2^i \). -/
  have x_lt : x < 2^i := Nat.lt_of_not_le not_ge
/- Using the fact that if \( x < 2^i \), then \( x / 2^i = 0 \), we can simplify the hypothesis \( p \) to \( \text{decide}(0 \% 2 = 1) = \text{true} \). Since \( 0 \% 2 = 0 \), this simplifies to \( \text{decide}(0 = 1) = \text{true} \), which is a contradiction. Therefore, the assumption \( x < 2^i \) must be false, and thus \( x \ge 2^i \). -/
  simp [div_eq_of_lt x_lt] at p","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15765,Nat.testBit_lt_two_pow,theorem Nat.testBit_lt_two_pow {x i : Nat} (lt : x < 2^i) : x.testBit i = false := by sorry,"Bit Test for Natural Numbers Less Than \( 2^i \) : For any natural numbers \( x \) and \( i \), if \( x \) is less than \( 2^i \), then the \( i \)-th bit of \( x \) in its binary representation is `false`.","theorem Nat.testBit_lt_two_pow {x i : Nat} (lt : x < 2^i) : x.testBit i = false := by
  match p : x.testBit i with
  | false => trivial
  | true =>
    exfalso
    exact Nat.not_le_of_gt lt (testBit_implies_ge p)","We need to show that for any natural numbers \( x \) and \( i \), if \( x < 2^i \), then \( x.testBit i = false \).

1. **Case 1: \( x.testBit i = false \)**
- If the \( i \)-th bit of \( x \) is `false`, then the statement \( x.testBit i = false \) is trivially true.

2. **Case 2: \( x.testBit i = true \)**
- Assume the \( i \)-th bit of \( x \) is `true`.
- By the property of the bit test, if the \( i \)-th bit of \( x \) is `true`, then \( x \ge 2^i \).
- However, we are given that \( x < 2^i \).
- This leads to a contradiction because \( x \) cannot be both less than \( 2^i \) and greater than or equal to \( 2^i \).
- Therefore, the assumption that the \( i \)-th bit of \( x \) is `true` must be false.

Since both cases lead to \( x.testBit i = false \), we conclude that if \( x < 2^i \), then \( x.testBit i = false \). This completes the proof.","theorem Nat.testBit_lt_two_pow {x i : Nat} (lt : x < 2^i) : x.testBit i = false := by
  match p : x.testBit i with
/- If the \( i \)-th bit of \( x \) is `false`, then the statement \( x.testBit i = false \) is trivially true. -/
  | false => trivial
/- Now consider the case where the \( i \)-th bit of \( x \) is `true`. -/
  | true =>
/- To prove \( true = false \), we will derive a contradiction. -/
    exfalso
/- Since \( x < 2^i \) (by assumption \( lt \)) and \( x \ge 2^i \) (by the property that if the \( i \)-th bit of \( x \) is `true`, then \( x \ge 2^i \)), we have a contradiction. Therefore, the assumption that the \( i \)-th bit of \( x \) is `true` must be false, and thus \( x.testBit i = false \). -/
    exact Nat.not_le_of_gt lt (testBit_implies_ge p)","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15766,Nat.toNat_testBit,"theorem Nat.toNat_testBit (x i : Nat) :
    (x.testBit i).toNat = x / 2 ^ i % 2 := by sorry","Bit Test and Division Modulo Identity in Natural Numbers : For any natural numbers \( x \) and \( i \), the natural number representation of the \( i \)-th bit of \( x \) is equal to the remainder when \( x \) is divided by \( 2^i \) and then divided by 2, i.e., \((x \text{.testBit } i).toNat = x / 2^i \% 2\).","theorem Nat.toNat_testBit (x i : Nat) :
    (x.testBit i).toNat = x / 2 ^ i % 2 := by
  rw [Nat.testBit_to_div_mod]
  rcases Nat.mod_two_eq_zero_or_one (x / 2^i) <;> simp_all","We start by using the identity that the \( i \)-th bit of \( x \) is equal to the boolean value `true` if and only if the remainder when \( x \) is divided by \( 2^i \) and then divided by 2 is 1. This transforms our goal into showing that \((\text{decide}(x / 2^i \% 2 = 1)).\text{toNat} = x / 2^i \% 2\).

We consider two cases based on the modulo two identity:

1. **Case 1: \( x / 2^i \% 2 = 0 \)**
- In this case, \(\text{decide}(x / 2^i \% 2 = 1)\) is `false`, and \(\text{false}.\text{toNat} = 0\). Therefore, the goal simplifies to \(0 = 0\), which is trivially true.

2. **Case 2: \( x / 2^i \% 2 = 1 \)**
- In this case, \(\text{decide}(x / 2^i \% 2 = 1)\) is `true`, and \(\text{true}.\text{toNat} = 1\). Therefore, the goal simplifies to \(1 = 1\), which is also trivially true.

In both cases, the goal is satisfied, thus completing the proof. \(\blacksquare\)","theorem Nat.toNat_testBit (x i : Nat) :
    (x.testBit i).toNat = x / 2 ^ i % 2 := by
/- First, we use the identity that the \( i \)-th bit of \( x \) is equal to the boolean value `true` if and only if the remainder when \( x \) is divided by \( 2^i \) and then divided by 2 is 1. This transforms our goal into showing that \((\text{decide}(x / 2^i \% 2 = 1)).\text{toNat} = x / 2^i \% 2\). -/
  rw [Nat.testBit_to_div_mod]
/- We consider two cases based on the modulo two identity: either \( x / 2^i \% 2 = 0 \) or \( x / 2^i \% 2 = 1 \).

1. **Case 1: \( x / 2^i \% 2 = 0 \)**
- In this case, \(\text{decide}(x / 2^i \% 2 = 1)\) is `false`, and \(\text{false}.\text{toNat} = 0\). Therefore, the goal simplifies to \(0 = 0\), which is trivially true.

2. **Case 2: \( x / 2^i \% 2 = 1 \)**
- In this case, \(\text{decide}(x / 2^i \% 2 = 1)\) is `true`, and \(\text{true}.\text{toNat} = 1\). Therefore, the goal simplifies to \(1 = 1\), which is also trivially true.

In both cases, the goal is satisfied, thus completing the proof. -/
  rcases Nat.mod_two_eq_zero_or_one (x / 2^i) <;> simp_all","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15767,Nat.testBit_zero,theorem Nat.testBit_zero (x : Nat) : testBit x 0 = decide (x % 2 = 1) := by sorry,"Least Significant Bit of Natural Number is 1 if and only if Number is Odd : For any natural number \( x \), the least significant bit (0th bit) of \( x \) in its binary representation is 1 if and only if \( x \) is odd, i.e., \( x \mod 2 = 1 \).","theorem Nat.testBit_zero (x : Nat) : testBit x 0 = decide (x % 2 = 1) := by
  cases mod_two_eq_zero_or_one x with | _ p => simp [testBit, p]","We need to show that for any natural number \( x \), the least significant bit of \( x \) (denoted as \( x \text{.testBit} 0 \)) is 1 if and only if \( x \) is odd, i.e., \( x \mod 2 = 1 \).

We will consider the two possible cases for the remainder when \( x \) is divided by 2, using the modulo two identity \( x \% 2 = 0 \lor x \% 2 = 1 \).

**Case 1: \( x \% 2 = 0 \)**
- By the definition of `testBit`, \( x \text{.testBit} 0 \) checks if the 0th bit of \( x \) is 1. Since \( x \% 2 = 0 \), the 0th bit of \( x \) is 0, so \( x \text{.testBit} 0 = \text{false} \).
- The decision \( \text{decide}(x \% 2 = 1) \) is `false` because \( x \% 2 = 0 \).
- Therefore, \( x \text{.testBit} 0 = \text{decide}(x \% 2 = 1) \) holds in this case.

**Case 2: \( x \% 2 = 1 \)**
- By the definition of `testBit`, \( x \text{.testBit} 0 \) checks if the 0th bit of \( x \) is 1. Since \( x \% 2 = 1 \), the 0th bit of \( x \) is 1, so \( x \text{.testBit} 0 = \text{true} \).
- The decision \( \text{decide}(x \% 2 = 1) \) is `true` because \( x \% 2 = 1 \).
- Therefore, \( x \text{.testBit} 0 = \text{decide}(x \% 2 = 1) \) holds in this case.

Since both cases are covered, we conclude that for any natural number \( x \), the least significant bit of \( x \) is 1 if and only if \( x \) is odd. This completes the proof. \(\blacksquare\)","theorem Nat.testBit_zero (x : Nat) : testBit x 0 = decide (x % 2 = 1) := by
/- We will consider the two possible cases for the remainder when \( x \) is divided by 2. By the modulo two identity, \( x \% 2 \) is either 0 or 1. We will handle each case separately. -/
/- **Case 1: \( x \% 2 = 0 \)**
Using the definition of `testBit` and the fact that \( x \% 2 = 0 \), we can simplify the expression \( x \text{.testBit} 0 \) to `false`. Since \( x \% 2 = 0 \), the decision \( \text{decide}(x \% 2 = 1) \) is `false`. Therefore, \( x \text{.testBit} 0 = \text{decide}(x \% 2 = 1) \) holds in this case. -/
/- **Case 2: \( x \% 2 = 1 \)**
Using the definition of `testBit` and the fact that \( x \% 2 = 1 \), we can simplify the expression \( x \text{.testBit} 0 \) to `true`. Since \( x \% 2 = 1 \), the decision \( \text{decide}(x \% 2 = 1) \) is `true`. Therefore, \( x \text{.testBit} 0 = \text{decide}(x \% 2 = 1) \) holds in this case. -/
  cases mod_two_eq_zero_or_one x with | _ p => simp [testBit, p]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15771,Nat.and_pow_two_identity,theorem Nat.and_pow_two_identity {x : Nat} (lt : x < 2^n) : x &&& 2^n-1 = x := by sorry,"Conjunction with \( 2^n - 1 \) is Identity for \( x < 2^n \) : For any natural numbers \( n \) and \( x \), if \( x < 2^n \), then the conjunction \( x \&&& (2^n - 1) \) is equal to \( x \), i.e., \( x \&&& (2^n - 1) = x \).","theorem Nat.and_pow_two_identity {x : Nat} (lt : x < 2^n) : x &&& 2^n-1 = x := by
  rw [and_pow_two_is_mod]
  apply Nat.mod_eq_of_lt lt","We start with the assumption that \( x < 2^n \). We need to show that \( x \&&& (2^n - 1) = x \).

First, we use the theorem that states the conjunction \( x \&&& (2^n - 1) \) is equivalent to the modulo operation \( x \mod 2^n \). Therefore, the goal \( x \&&& (2^n - 1) = x \) is equivalent to \( x \mod 2^n = x \).

Next, we use the theorem that for any natural numbers \( a \) and \( b \), if \( a < b \), then \( a \mod b = a \). Since we have the assumption \( x < 2^n \), it follows that \( x \mod 2^n = x \).

Thus, we have shown that \( x \&&& (2^n - 1) = x \). This completes the proof. \(\blacksquare\)","theorem Nat.and_pow_two_identity {x : Nat} (lt : x < 2^n) : x &&& 2^n-1 = x := by
/- Since the theorem states that the conjunction \( x \&&& (2^n - 1) \) is equivalent to the modulo operation \( x \mod 2^n \), we can replace the goal \( x \&&& (2^n - 1) = x \) with \( x \mod 2^n = x \). -/
  rw [and_pow_two_is_mod]
/- To prove \( x \mod 2^n = x \), we use the theorem that for any natural numbers \( a \) and \( b \), if \( a < b \), then \( a \mod b = a \). Since we have the assumption \( x < 2^n \), it suffices to show that \( x \mod 2^n = x \) holds. -/
  apply Nat.mod_eq_of_lt lt","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15772,Nat.eq_of_testBit_eq,"theorem Nat.eq_of_testBit_eq {x y : Nat} (pred : ∀i, testBit x i = testBit y i) : x = y := by sorry","Equality of Natural Numbers from Bitwise Equality: \( x = y \) if \( x \) and \( y \) have the same bits for all \( i \) : For any natural numbers \( x \) and \( y \), if for all natural numbers \( i \), the \( i \)-th bit of \( x \) is equal to the \( i \)-th bit of \( y \), then \( x \) is equal to \( y \). In other words, if \( x \) and \( y \) have the same bits at every position, then \( x = y \).","theorem Nat.eq_of_testBit_eq {x y : Nat} (pred : ∀i, testBit x i = testBit y i) : x = y := by
  if h : x = y then
    exact h
  else
    let ⟨i,eq⟩ := ne_implies_bit_diff h
    have p := pred i
    contradiction","To prove that \( x = y \) given that for all natural numbers \( i \), \( x.testBit i = y.testBit i \), we proceed by contradiction. Assume \( x \neq y \). By the theorem that if \( x \neq y \), then there exists a natural number \( i \) such that the \( i \)-th bit of \( x \) is different from the \( i \)-th bit of \( y \), we can find such an \( i \) and a corresponding bit difference \( x.testBit i \neq y.testBit i \). Let \( p \) be the predecessor of \( i \). This leads to a contradiction because we assumed that for all \( i \), \( x.testBit i = y.testBit i \). Therefore, our assumption \( x \neq y \) must be false, and thus \( x = y \). This completes the proof.","theorem Nat.eq_of_testBit_eq {x y : Nat} (pred : ∀i, testBit x i = testBit y i) : x = y := by
  if h : x = y then
    exact h
/- Assume for the sake of contradiction that \( x \neq y \). By the theorem that if \( x \neq y \), then there exists a natural number \( i \) such that the \( i \)-th bit of \( x \) is different from the \( i \)-th bit of \( y \), we can find such an \( i \) and a corresponding bit difference \( x.testBit i \neq y.testBit i \). Let \( p \) be the predecessor of \( i \). This leads to a contradiction because we assumed that for all \( i \), \( x.testBit i = y.testBit i \). Therefore, our assumption \( x \neq y \) must be false, and thus \( x = y \). -/
  else
    let ⟨i,eq⟩ := ne_implies_bit_diff h
    have p := pred i
    contradiction","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15773,Nat.testBit_and,theorem Nat.testBit_and (x y i : Nat) : (x &&& y).testBit i = (x.testBit i && y.testBit i) := by sorry,"Bitwise Conjunction Preserves Bitwise AND Operation in Natural Numbers : For any natural numbers \( x \), \( y \), and \( i \), the \( (i+1) \)-th least significant bit in the binary representation of the conjunction \( x \&&& y \) is equal to the logical ""and"" of the \( (i+1) \)-th least significant bits of \( x \) and \( y \). In other words, \((x \&&& y). \text{testBit}(i) = (x. \text{testBit}(i) \, \text{and} \, y. \text{testBit}(i))\).","theorem Nat.testBit_and (x y i : Nat) : (x &&& y).testBit i = (x.testBit i && y.testBit i) := by
  simp [HAnd.hAnd, AndOp.and, land, testBit_bitwise ]","To prove the theorem, we start by using the definitions and properties of the bitwise conjunction operation, the boolean ""and"" operation, and the bitwise test function. Specifically, we use the following properties:

1. The bitwise conjunction operation \( x \&&& y \) is defined such that the \( i \)-th bit of \( x \&&& y \) is the logical ""and"" of the \( i \)-th bits of \( x \) and \( y \).
2. The boolean ""and"" operation \( x \, \text{and} \, y \) returns `false` if either \( x \) or \( y \) is `false`, and returns `true` if both \( x \) and \( y \) are `true`.
3. The bitwise test function \( \text{testBit}(i) \) returns the \( i \)-th bit of a natural number.

Using these properties, we can simplify the expression \((x \&&& y). \text{testBit}(i)\) as follows:
\[
(x \&&& y). \text{testBit}(i) = (x. \text{testBit}(i) \, \text{and} \, y. \text{testBit}(i))
\]
This simplification shows that the \( i \)-th bit of the result of the bitwise operation \( x \&&& y \) is indeed the logical ""and"" of the \( i \)-th bits of \( x \) and \( y \). Therefore, the theorem is proved.","theorem Nat.testBit_and (x y i : Nat) : (x &&& y).testBit i = (x.testBit i && y.testBit i) := by
/- Using the definitions and properties of the bitwise conjunction operation, the boolean ""and"" operation, and the bitwise test function, we can simplify the proposition we want to show. Specifically, we use the fact that the \( i \)-th bit of the result of the bitwise operation \( x \&&& y \) is equal to the logical ""and"" of the \( i \)-th bits of \( x \) and \( y \). This simplification shows that \((x \&&& y). \text{testBit}(i) = (x. \text{testBit}(i) \, \text{and} \, y. \text{testBit}(i))\). -/
  simp [HAnd.hAnd, AndOp.and, land, testBit_bitwise ]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15774,Nat.testBit_shiftRight,theorem Nat.testBit_shiftRight (x : Nat) : testBit (x >>> i) j = testBit x (i+j) := by sorry,"Right Shift and Test Bit Relationship in Natural Numbers : For any natural numbers \( i \) and \( j \), and for any natural number \( x \), the \((j+1)\)-th least significant bit of the natural number \( x \) right-shifted by \( i \) positions is equal to the \((i + j + 1)\)-th least significant bit of \( x \). In other words, \((x >>> i).testBit(j) = x.testBit(i + j)\).","theorem Nat.testBit_shiftRight (x : Nat) : testBit (x >>> i) j = testBit x (i+j) := by
  simp [testBit, ←shiftRight_add]","To prove the theorem, we start by using the definition of the `testBit` function and the property of right-shifting. Specifically, we use the fact that right-shifting a number by \( i \) positions and then testing the \( j \)-th bit is equivalent to testing the \((i + j)\)-th bit of the original number. Formally, this means:

\[
(x >>> i).testBit(j) = x.testBit(i + j)
\]

By applying this property, we can directly simplify the left-hand side of the equation to the right-hand side. Therefore, the theorem holds true. This completes the proof. \(\blacksquare\)","theorem Nat.testBit_shiftRight (x : Nat) : testBit (x >>> i) j = testBit x (i+j) := by
/- Using the definition of the `testBit` function and the property that right-shifting a number by \( i \) positions and then testing the \( j \)-th bit is equivalent to testing the \((i + j)\)-th bit of the original number, we can simplify the goal. Specifically, the expression \((x >>> i).testBit(j)\) is equivalent to \(x.testBit(i + j)\). This completes the proof. -/
  simp [testBit, ←shiftRight_add]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15777,Nat.not_decide_mod_two_eq_one,"theorem Nat.not_decide_mod_two_eq_one (x : Nat)
    : (!decide (x % 2 = 1)) = decide (x % 2 = 0) := by sorry","Negation of Decide for Modulo Two Equals One is Decide for Modulo Two Equals Zero : For any natural number \( x \), the negation of the boolean value `decide (x \% 2 = 1)` is equal to the boolean value `decide (x \% 2 = 0)`. In other words, if \( x \) is not odd, then \( x \) is even, and vice versa. This can be expressed as:
\[
\text{not}(\text{decide}(x \% 2 = 1)) = \text{decide}(x \% 2 = 0)
\]","theorem Nat.not_decide_mod_two_eq_one (x : Nat)
    : (!decide (x % 2 = 1)) = decide (x % 2 = 0) := by
  cases Nat.mod_two_eq_zero_or_one x <;> (rename_i p; simp [p])","We start by considering the two possible cases for the remainder when \( x \) is divided by 2, using the modulo two identity:
\[
x \% 2 = 0 \lor x \% 2 = 1
\]

**Case 1: \( x \% 2 = 0 \)**
- Assume \( x \% 2 = 0 \). We rename this assumption to \( p \).
- We need to show that the negation of `decide (x \% 2 = 1)` is equal to `decide (x \% 2 = 0)`.
- Since \( x \% 2 = 0 \), `decide (x \% 2 = 1)` is `false`, and its negation is `true`.
- Therefore, the goal simplifies to `true = decide (x \% 2 = 0)`, which is true because `decide (x \% 2 = 0)` is `true` when \( x \% 2 = 0 \).

**Case 2: \( x \% 2 = 1 \)**
- Assume \( x \% 2 = 1 \). We rename this assumption to \( p \).
- We need to show that the negation of `decide (x \% 2 = 1)` is equal to `decide (x \% 2 = 0)`.
- Since \( x \% 2 = 1 \), `decide (x \% 2 = 1)` is `true`, and its negation is `false`.
- Therefore, the goal simplifies to `false = decide (x \% 2 = 0)`, which is true because `decide (x \% 2 = 0)` is `false` when \( x \% 2 = 1 \).

Since both cases are handled, the theorem is proved.","theorem Nat.not_decide_mod_two_eq_one (x : Nat)
    : (!decide (x % 2 = 1)) = decide (x % 2 = 0) := by
/- We will consider the two possible cases for the remainder when \( x \) is divided by 2. By the modulo two identity, \( x \% 2 \) is either 0 or 1. We will handle each case separately. -/
/- For the first case, assume \( x \% 2 = 0 \). We rename this assumption to \( p \). Using this assumption, we simplify the goal to show that the negation of `decide (x \% 2 = 1)` is equal to `decide (x \% 2 = 0)`. Since \( x \% 2 = 0 \), `decide (x \% 2 = 1)` is `false`, and its negation is `true`. Therefore, the goal simplifies to `true = decide (x \% 2 = 0)`, which is true because `decide (x \% 2 = 0)` is `true` when \( x \% 2 = 0 \). -/
/- For the second case, assume \( x \% 2 = 1 \). We rename this assumption to \( p \). Using this assumption, we simplify the goal to show that the negation of `decide (x \% 2 = 1)` is equal to `decide (x \% 2 = 0)`. Since \( x \% 2 = 1 \), `decide (x \% 2 = 1)` is `true`, and its negation is `false`. Therefore, the goal simplifies to `false = decide (x \% 2 = 0)`, which is true because `decide (x \% 2 = 0)` is `false` when \( x \% 2 = 1 \). -/
  cases Nat.mod_two_eq_zero_or_one x <;> (rename_i p; simp [p])","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15780,Nat.testBit_two_pow_sub_one,theorem Nat.testBit_two_pow_sub_one (n i : Nat) : testBit (2^n-1) i = decide (i < n) := by sorry,"Bit Representation of \( 2^n - 1 \) in Natural Numbers: \((2^n - 1).\text{testBit}(i) = \text{decide}(i < n)\) : For any natural numbers \( n \) and \( i \), the \((i+1)\)-th least significant bit in the binary representation of \( 2^n - 1 \) is equal to the boolean value \(\text{decide}(i < n)\). In other words, the \((i+1)\)-th bit of \( 2^n - 1 \) is 1 if and only if \( i < n \).","theorem Nat.testBit_two_pow_sub_one (n i : Nat) : testBit (2^n-1) i = decide (i < n) := by
  rw [testBit_two_pow_sub_succ]
  · simp
  · exact Nat.two_pow_pos _","To prove the theorem, we start by using the theorem that for any natural numbers \( x \) and \( n \) such that \( x < 2^n \), and for any natural number \( i \), the \((i+1)\)-th least significant bit in the binary representation of \( 2^n - (x + 1) \) is equal to the boolean value \(\text{decide}(i < n) \land \neg x.\text{testBit}(i)\). By setting \( x = 0 \), we can rewrite the goal \((2^n - 1).\text{testBit}(i) = \text{decide}(i < n)\) as \((\text{decide}(i < n) \land \neg 0.\text{testBit}(i)) = \text{decide}(i < n)\).

Next, we simplify the expression \((\text{decide}(i < n) \land \neg 0.\text{testBit}(i)) = \text{decide}(i < n)\). Since the \((i+1)\)-th bit of \(0\) is always \(0\), \(\neg 0.\text{testBit}(i)\) is always true. Therefore, the expression simplifies to \(\text{decide}(i < n) = \text{decide}(i < n)\), which is trivially true.

Finally, we need to show that \(0 < 2^n\). This is true because for any natural number \( n \), \(2^n\) is always greater than 0. This is a known property of the natural numbers and the power function.

Thus, we have shown that \((2^n - 1).\text{testBit}(i) = \text{decide}(i < n)\) for any natural numbers \( n \) and \( i \). This completes the proof. \(\blacksquare\)","theorem Nat.testBit_two_pow_sub_one (n i : Nat) : testBit (2^n-1) i = decide (i < n) := by
/- We use the theorem that for any natural numbers \( x \) and \( n \) such that \( x < 2^n \), and for any natural number \( i \), the \((i+1)\)-th least significant bit in the binary representation of \( 2^n - (x + 1) \) is equal to the boolean value \(\text{decide}(i < n) \land \neg x.\text{testBit}(i)\). By setting \( x = 0 \), we can rewrite the goal \((2^n - 1).\text{testBit}(i) = \text{decide}(i < n)\) as \((\text{decide}(i < n) \land \neg 0.\text{testBit}(i)) = \text{decide}(i < n)\). -/
  rw [testBit_two_pow_sub_succ]
/- We simplify the expression \((\text{decide}(i < n) \land \neg 0.\text{testBit}(i)) = \text{decide}(i < n)\). Since the \((i+1)\)-th bit of \(0\) is always \(0\), \(\neg 0.\text{testBit}(i)\) is always true. Therefore, the expression simplifies to \(\text{decide}(i < n) = \text{decide}(i < n)\), which is trivially true. -/
  · simp
/- We need to show that \(0 < 2^n\). This is true because for any natural number \( n \), \(2^n\) is always greater than 0. This is a known property of the natural numbers and the power function. -/
  · exact Nat.two_pow_pos _","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15782,Nat.zero_or,theorem Nat.zero_or (x : Nat) : 0 ||| x = x := by sorry,"Disjunction with Zero Equals the Number: \( 0 \ ||| \ x = x \) : For any natural number \( x \), the disjunction-like operation \( 0 \ ||| \ x \) is equal to \( x \), i.e., \( 0 \ ||| \ x = x \).","theorem Nat.zero_or (x : Nat) : 0 ||| x = x := by
  simp only [HOr.hOr, OrOp.or, lor]
  unfold bitwise
  simp [@eq_comm _ 0]","To prove that \( 0 \ ||| \ x = x \) for any natural number \( x \), we start by using the definitions of the homogeneous disjunction operation \( a \ ||| \ b \), the boolean or operation \( x \ || \ y \), and the bitwise or operation. This simplifies our goal to showing that \( \text{bitwise or } 0 \ x = x \).

Next, we expand the definition of the bitwise or operation. The bitwise or operation recursively applies the boolean or operation to the corresponding bits of the binary representations of the two natural numbers. Specifically:
- If the first number is zero, the result is the second number if the boolean or of `false` and `true` is true, otherwise it is zero.
- If the second number is zero, the result is the first number if the boolean or of `true` and `false` is true, otherwise it is zero.
- If both numbers are non-zero, the function computes the result of the bitwise or of the halves of the two numbers, and then adds 1 to the result if the boolean or of the least significant bits of the two numbers is true, otherwise it just returns the result of the recursive call.

In our case, since the first number is zero, the result is the second number \( x \) if the boolean or of `false` and `true` is true, which it is. Therefore, the result of the bitwise or operation on \( 0 \) and \( x \) is indeed \( x \).

Thus, we have shown that \( 0 \ ||| \ x = x \) for any natural number \( x \). This completes the proof. \(\blacksquare\)","theorem Nat.zero_or (x : Nat) : 0 ||| x = x := by
/- Using the definitions of the homogeneous disjunction operation \( a \ ||| \ b \), the boolean or operation \( x \ || \ y \), and the bitwise or operation, we can simplify the proposition we want to show to \( \text{bitwise or } 0 \ x = x \). -/
  simp only [HOr.hOr, OrOp.or, lor]
/- Expand the definition of the bitwise or operation. This operation recursively applies the boolean or operation to the corresponding bits of the binary representations of the two natural numbers. Specifically, if the first number is zero, the result is the second number if the boolean or of `false` and `true` is true, otherwise it is zero. If the second number is zero, the result is the first number if the boolean or of `true` and `false` is true, otherwise it is zero. If both numbers are non-zero, the function computes the result of the bitwise or of the halves of the two numbers, and then adds 1 to the result if the boolean or of the least significant bits of the two numbers is true, otherwise it just returns the result of the recursive call. -/
  unfold bitwise
/- Using the symmetry of equality, we can simplify the expression to show that the result of the bitwise or operation on \( 0 \) and \( x \) is indeed \( x \). This completes the proof. -/
  simp [@eq_comm _ 0]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15783,Nat.testBit_shiftLeft,"theorem Nat.testBit_shiftLeft (x : Nat) : testBit (x <<< i) j =
    (decide (j ≥ i) && testBit x (j-i)) := by sorry","Left Shift and Test Bit Relationship in Natural Numbers : For any natural numbers \( i \) and \( j \), and for any natural number \( x \), the \((j+1)\)-th least significant bit of the natural number \( x \) left-shifted by \( i \) positions is equal to the boolean value given by the expression \(\text{decide}(j \ge i) \land x.\text{testBit}(j - i)\). In other words, \((x <<< i).\text{testBit}(j) = \text{decide}(j \ge i) \land x.\text{testBit}(j - i)\).","theorem Nat.testBit_shiftLeft (x : Nat) : testBit (x <<< i) j =
    (decide (j ≥ i) && testBit x (j-i)) := by
  simp [shiftLeft_eq, Nat.mul_comm _ (2^_), testBit_mul_pow_two]","To prove the theorem, we start by using the definition of left shift. For any natural numbers \( x \) and \( i \), the left shift of \( x \) by \( i \) positions, denoted as \( x <<< i \), is equal to \( x \cdot 2^i \). This can be written as:
\[
x <<< i = x \cdot 2^i
\]

Next, we need to determine the \((j+1)\)-th least significant bit of \( x <<< i \). By the property of testing bits in a number multiplied by a power of two, we have:
\[
(x <<< i).\text{testBit}(j) = (2^i \cdot x).\text{testBit}(j)
\]

Using the property of testing bits in a number multiplied by a power of two, we know:
\[
(2^i \cdot x).\text{testBit}(j) = \text{decide}(j \ge i) \land x.\text{testBit}(j - i)
\]

This property states that if \( j \ge i \), then the \((j+1)\)-th bit of \( 2^i \cdot x \) is the same as the \((j - i + 1)\)-th bit of \( x \); otherwise, it is 0. Therefore, we have:
\[
(x <<< i).\text{testBit}(j) = \text{decide}(j \ge i) \land x.\text{testBit}(j - i)
\]

This completes the proof.","theorem Nat.testBit_shiftLeft (x : Nat) : testBit (x <<< i) j =
    (decide (j ≥ i) && testBit x (j-i)) := by
/- Using the fact that left-shifting a natural number \( x \) by \( i \) positions is equivalent to multiplying \( x \) by \( 2^i \), and the commutativity of multiplication, we can simplify the expression \((x <<< i).\text{testBit}(j)\) to \((2^i \cdot x).\text{testBit}(j)\). By the property of testing bits in a number multiplied by a power of two, this is equal to \(\text{decide}(j \ge i) \land x.\text{testBit}(j - i)\). -/
  simp [shiftLeft_eq, Nat.mul_comm _ (2^_), testBit_mul_pow_two]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15785,Nat.one_and_eq_mod_two,theorem Nat.one_and_eq_mod_two (n : Nat) : 1 &&& n = n % 2 := by sorry,"Conjunction with One is Modulo Two in Natural Numbers : For any natural number \( n \), the conjunction of 1 with \( n \), denoted as \( 1 \&&& n \), is equal to the remainder when \( n \) is divided by 2, i.e., \( 1 \&&& n = n \mod 2 \).","theorem Nat.one_and_eq_mod_two (n : Nat) : 1 &&& n = n % 2 := by
  if n0 : n = 0 then
    subst n0; decide
  else
    simp only [HAnd.hAnd, AndOp.and, land]
    cases mod_two_eq_zero_or_one n with | _ h => simp [bitwise, n0, h]","To prove that \( 1 \&&& n = n \mod 2 \) for any natural number \( n \), we start by simplifying the expression \( 1 \&&& n \) using the definitions of the bitwise AND operation for natural numbers. This simplification reduces the expression to a more manageable form.

Next, we consider the two possible cases for the remainder when \( n \) is divided by 2:
1. **Case 1: \( n \mod 2 = 0 \)**
- In this case, we use the property of bitwise AND for natural numbers, which states that \( a \&& b = (a \mod 2) \cdot (b \mod 2) \). Since \( 1 \mod 2 = 1 \) and \( n \mod 2 = 0 \), we have:
\[
1 \&&& n = (1 \mod 2) \cdot (n \mod 2) = 1 \cdot 0 = 0
\]
- Therefore, \( 1 \&&& n = 0 \), which is equal to \( n \mod 2 \).

2. **Case 2: \( n \mod 2 = 1 \)**
- In this case, we again use the property of bitwise AND for natural numbers. Since \( 1 \mod 2 = 1 \) and \( n \mod 2 = 1 \), we have:
\[
1 \&&& n = (1 \mod 2) \cdot (n \mod 2) = 1 \cdot 1 = 1
\]
- Therefore, \( 1 \&&& n = 1 \), which is equal to \( n \mod 2 \).

In both cases, we have shown that \( 1 \&&& n = n \mod 2 \). Hence, the theorem is proved.","theorem Nat.one_and_eq_mod_two (n : Nat) : 1 &&& n = n % 2 := by
  if n0 : n = 0 then
    subst n0; decide
/- First, we simplify the expression \( 1 \&&& n \) using the definitions of the bitwise AND operation for natural numbers. This simplification reduces the expression to a more manageable form. Then, we consider the two cases for the remainder when \( n \) is divided by 2, which are \( n \mod 2 = 0 \) and \( n \mod 2 = 1 \). For each case, we simplify the expression using the properties of bitwise AND and the hypothesis \( h \). -/
  else
    simp only [HAnd.hAnd, AndOp.and, land]
    cases mod_two_eq_zero_or_one n with | _ h => simp [bitwise, n0, h]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15788,Nat.testBit_two_pow_add_gt,"theorem Nat.testBit_two_pow_add_gt {i j : Nat} (j_lt_i : j < i) (x : Nat) :
    testBit (2^i + x) j = testBit x j := by sorry","Bit Test of Sum with Power of Two Equals Bit Test of Original Number : For any natural numbers \( i \) and \( j \) such that \( j < i \), and for any natural number \( x \), the \((j+1)\)-th least significant bit in the binary representation of \( 2^i + x \) is equal to the \((j+1)\)-th least significant bit in the binary representation of \( x \), i.e., \(\text{testBit}(2^i + x, j) = \text{testBit}(x, j)\).","theorem Nat.testBit_two_pow_add_gt {i j : Nat} (j_lt_i : j < i) (x : Nat) :
    testBit (2^i + x) j = testBit x j := by
  have i_def : i = j + (i-j) := (Nat.add_sub_cancel' (Nat.le_of_lt j_lt_i)).symm
  rw [i_def]
  simp only [testBit_to_div_mod, Nat.pow_add,
        Nat.add_comm x, Nat.mul_add_div (Nat.two_pow_pos _)]
  match i_sub_j_eq : i - j with
  | 0 =>
    exfalso
    rw [Nat.sub_eq_zero_iff_le] at i_sub_j_eq
    exact Nat.not_le_of_gt j_lt_i i_sub_j_eq
  | d+1 =>
    simp [Nat.pow_succ, Nat.mul_comm _ 2, Nat.mul_add_mod]","We start by constructing the lemma \( i = j + (i - j) \) using the fact that \( j < i \) implies \( j \le i \) and the property that \( a + b - a = b \) for any natural numbers \( a \) and \( b \). This lemma is obtained by symmetry of the equality.

Next, we use this lemma to replace \( i \) with \( j + (i - j) \) in the goal, simplifying it to \((2^{j + (i - j)} + x).\text{testBit}(j) = x.\text{testBit}(j)\).

We then simplify the goal using the following properties:
- The bit test \(\text{testBit}(x, i)\) is equivalent to \(\text{decide}(x / 2^i \% 2 = 1)\).
- The power of a sum \(2^{m + n} = 2^m \cdot 2^n\).
- The commutativity of addition \(a + b = b + a\).
- The division of a sum of multiples and a remainder \(\frac{m \cdot x + y}{m} = x + \frac{y}{m}\).

After simplification, the goal becomes \(\text{decide}((2^{i - j} + x / 2^j) \% 2 = 1) = \text{decide}(x / 2^j \% 2 = 1)\).

We consider two cases for \( i - j \):
1. **Case \( i - j = 0 \)**:
- We assume for contradiction that \( i - j = 0 \).
- Using the property that \( n - m = 0 \) if and only if \( n \le m \), we replace \( i - j = 0 \) with \( i \le j \).
- Since \( j < i \) implies \( j \not\le i \), we have a contradiction. Therefore, the assumption \( i - j = 0 \) is false.

2. **Case \( i - j = d + 1 \) for some natural number \( d \)**:
- We simplify the goal using the following properties:
- The power of a successor \(2^{d + 1} = 2^d \cdot 2\).
- The commutativity of multiplication \(a \cdot b = b \cdot a\).
- The modulo of a sum of multiples and a remainder \((m \cdot x + y) \% m = y \% m\).
- After simplification, the goal is trivially true.

Thus, in both cases, the goal is satisfied, and the theorem is proved. \(\blacksquare\)","theorem Nat.testBit_two_pow_add_gt {i j : Nat} (j_lt_i : j < i) (x : Nat) :
    testBit (2^i + x) j = testBit x j := by
/- First, we construct the lemma \( i = j + (i - j) \) by using the fact that \( j < i \) implies \( j \le i \), and the property that \( a + b - a = b \) for any natural numbers \( a \) and \( b \). This lemma is obtained by symmetry of the equality. -/
  have i_def : i = j + (i-j) := (Nat.add_sub_cancel' (Nat.le_of_lt j_lt_i)).symm
/- Using the lemma \( i = j + (i - j) \), we replace \( i \) with \( j + (i - j) \) in the goal. This simplifies the goal to \((2^{j + (i - j)} + x).\text{testBit}(j) = x.\text{testBit}(j)\). -/
  rw [i_def]
/- We simplify the goal using the following properties:
- The bit test \(\text{testBit}(x, i)\) is equivalent to \(\text{decide}(x / 2^i \% 2 = 1)\).
- The power of a sum \(2^{m + n} = 2^m \cdot 2^n\).
- The commutativity of addition \(a + b = b + a\).
- The division of a sum of multiples and a remainder \(\frac{m \cdot x + y}{m} = x + \frac{y}{m}\).

After simplification, the goal becomes \(\text{decide}((2^{i - j} + x / 2^j) \% 2 = 1) = \text{decide}(x / 2^j \% 2 = 1)\). -/
  simp only [testBit_to_div_mod, Nat.pow_add,
        Nat.add_comm x, Nat.mul_add_div (Nat.two_pow_pos _)]
  match i_sub_j_eq : i - j with
/- We consider the case where \( i - j = 0 \). -/
  | 0 =>
/- We assume for contradiction that \( i - j = 0 \). -/
    exfalso
/- Using the property that \( n - m = 0 \) if and only if \( n \le m \), we replace \( i - j = 0 \) with \( i \le j \). -/
    rw [Nat.sub_eq_zero_iff_le] at i_sub_j_eq
/- Since \( j < i \) implies \( j \not\le i \), we have a contradiction. Therefore, the assumption \( i - j = 0 \) is false. -/
    exact Nat.not_le_of_gt j_lt_i i_sub_j_eq
/- We consider the case where \( i - j = d + 1 \) for some natural number \( d \). -/
  | d+1 =>
/- We simplify the goal using the following properties:
- The power of a successor \(2^{d + 1} = 2^d \cdot 2\).
- The commutativity of multiplication \(a \cdot b = b \cdot a\).
- The modulo of a sum of multiples and a remainder \((m \cdot x + y) \% m = y \% m\).

After simplification, the goal is trivially true. -/
    simp [Nat.pow_succ, Nat.mul_comm _ 2, Nat.mul_add_mod]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15792,Nat.or_zero,theorem Nat.or_zero (x : Nat) : x ||| 0 = x := by sorry,"Disjunction with Zero Equals the Number: \( x \ ||| \ 0 = x \) : For any natural number \( x \), the disjunction-like operation \( x \ ||| \ 0 \) is equal to \( x \), i.e., \( x \ ||| \ 0 = x \).","theorem Nat.or_zero (x : Nat) : x ||| 0 = x := by
  simp only [HOr.hOr, OrOp.or, lor]
  unfold bitwise
  simp [@eq_comm _ 0]","To prove that \( x \ ||| \ 0 = x \) for any natural number \( x \), we start by using the definitions of the disjunction-like operation. Specifically, we simplify the proposition to show that \( \text{bitwise or } x \ 0 = x \).

Next, we expand the definition of the bitwise operation:
- If \( x = 0 \), the result is \( 0 \) if \( \text{false} \ || \ \text{true} \) is true, otherwise it is \( 0 \). Since \( \text{false} \ || \ \text{true} \) is true, the result is \( 0 \).
- If \( 0 = 0 \), the result is \( x \) if \( \text{true} \ || \ \text{false} \) is true, otherwise it is \( 0 \). Since \( \text{true} \ || \ \text{false} \) is true, the result is \( x \).
- If both \( x \) and \( 0 \) are non-zero, the function computes the result of \( \text{bitwise or } (x / 2) \ (0 / 2) \), and then adds 1 to the result if \( (x \% 2 = 1) \ || \ (0 \% 2 = 1) \) is true, otherwise it just returns the result of the recursive call. However, since \( 0 / 2 = 0 \), the recursive call simplifies to \( \text{bitwise or } (x / 2) \ 0 \), and the result is \( x / 2 \) if \( (x \% 2 = 1) \ || \ (0 \% 2 = 1) \) is true, otherwise it is \( x / 2 \).

Using the symmetry of equality, we can simplify the expression to show that the result of the bitwise operation is indeed \( x \). Therefore, we have \( x \ ||| \ 0 = x \).

This completes the proof.","theorem Nat.or_zero (x : Nat) : x ||| 0 = x := by
/- Using the definitions of the disjunction-like operation \( x \ ||| \ 0 \), we can simplify the proposition we want to show to \( \text{bitwise or } x \ 0 = x \). -/
  simp only [HOr.hOr, OrOp.or, lor]
/- Expand the definition of the bitwise operation, which is defined as follows:
- If \( x = 0 \), the result is \( 0 \) if \( \text{false} \ || \ \text{true} \) is true, otherwise it is \( 0 \).
- If \( 0 = 0 \), the result is \( x \) if \( \text{true} \ || \ \text{false} \) is true, otherwise it is \( 0 \).
- If both \( x \) and \( 0 \) are non-zero, the function computes the result of \( \text{bitwise or } (x / 2) \ (0 / 2) \), and then adds 1 to the result if \( (x \% 2 = 1) \ || \ (0 \% 2 = 1) \) is true, otherwise it just returns the result of the recursive call. -/
  unfold bitwise
/- Using the symmetry of equality, we can simplify the expression to show that the result of the bitwise operation is indeed \( x \). This completes the proof. -/
  simp [@eq_comm _ 0]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15798,Nat.and_lt_two_pow,theorem Nat.and_lt_two_pow (x : Nat) {y n : Nat} (right : y < 2^n) : (x &&& y) < 2^n := by sorry,"Conjunction with Natural Number Less Than \( 2^n \) is Less Than \( 2^n \) : For any natural numbers \( x \), \( y \), and \( n \), if \( y < 2^n \), then \( x \&&& y < 2^n \).","theorem Nat.and_lt_two_pow (x : Nat) {y n : Nat} (right : y < 2^n) : (x &&& y) < 2^n := by
  apply lt_pow_two_of_testBit
  intro i i_ge_n
  have yf : testBit y i = false := by
          apply Nat.testBit_lt_two_pow
          apply Nat.lt_of_lt_of_le right
          exact pow_le_pow_of_le_right Nat.zero_lt_two i_ge_n
  simp [testBit_and, yf]","To prove that \( x \&&& y < 2^n \), we use the theorem that if for all \( i \geq n \), the \( i \)-th bit of a number \( z \) is `false`, then \( z < 2^n \). Therefore, it suffices to show that for all \( i \geq n \), the \( i \)-th bit of \( x \&&& y \) is `false`.

Let \( i \) be an arbitrary natural number such that \( i \geq n \). We need to show that the \( i \)-th bit of \( x \&&& y \) is `false`.

First, we show that the \( i \)-th bit of \( y \) is `false`. Since \( y < 2^n \) and \( i \geq n \), we use the theorem that if \( y < 2^i \), then the \( i \)-th bit of \( y \) is `false`. To prove \( y < 2^i \), we use the transitivity of the less-than and less-than-or-equal relations: \( y < 2^n \) and \( 2^n \leq 2^i \) imply \( y < 2^i \). The inequality \( 2^n \leq 2^i \) holds because \( 2 > 0 \) and \( n \leq i \).

Using the property that the \( i \)-th bit of \( x \&&& y \) is the logical ""and"" of the \( i \)-th bits of \( x \) and \( y \), and the fact that the \( i \)-th bit of \( y \) is `false`, we conclude that the \( i \)-th bit of \( x \&&& y \) is `false`.

Thus, for all \( i \geq n \), the \( i \)-th bit of \( x \&&& y \) is `false`, which implies \( x \&&& y < 2^n \). This completes the proof. \(\blacksquare\)","theorem Nat.and_lt_two_pow (x : Nat) {y n : Nat} (right : y < 2^n) : (x &&& y) < 2^n := by
/- To prove that \( x \&&& y < 2^n \), using the theorem that if for all \( i \geq n \), the \( i \)-th bit of a number \( z \) is `false`, then \( z < 2^n \), it suffices to show that for all \( i \geq n \), the \( i \)-th bit of \( x \&&& y \) is `false`. -/
  apply lt_pow_two_of_testBit
/- Let \( i \) be an arbitrary natural number such that \( i \geq n \). We need to show that the \( i \)-th bit of \( x \&&& y \) is `false`. -/
  intro i i_ge_n
/- We first show that the \( i \)-th bit of \( y \) is `false`. Since \( y < 2^n \) and \( i \geq n \), we use the theorem that if \( y < 2^i \), then the \( i \)-th bit of \( y \) is `false`. To prove \( y < 2^i \), we use the transitivity of the less-than and less-than-or-equal relations: \( y < 2^n \) and \( 2^n \leq 2^i \) imply \( y < 2^i \). The inequality \( 2^n \leq 2^i \) holds because \( 2 > 0 \) and \( n \leq i \). -/
  have yf : testBit y i = false := by
          apply Nat.testBit_lt_two_pow
          apply Nat.lt_of_lt_of_le right
          exact pow_le_pow_of_le_right Nat.zero_lt_two i_ge_n
/- Using the property that the \( i \)-th bit of \( x \&&& y \) is the logical ""and"" of the \( i \)-th bits of \( x \) and \( y \), and the fact that the \( i \)-th bit of \( y \) is `false`, we conclude that the \( i \)-th bit of \( x \&&& y \) is `false`. -/
  simp [testBit_and, yf]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15805,Nat.testBit_mul_pow_two,"theorem Nat.testBit_mul_pow_two :
    testBit (2 ^ i * a) j = (decide (j ≥ i) && testBit a (j-i)) := by sorry","Bit Test for Multiplication by Power of Two in Natural Numbers: \((2^i \cdot a).\text{testBit}(j) = \text{decide}(j \ge i) \ \text{and} \ a.\text{testBit}(j - i)\) : For any natural numbers \( i \), \( a \), and \( j \), the \((j+1)\)-th least significant bit in the binary representation of \( 2^i \cdot a \) is equal to the result of the boolean expression \( \text{decide}(j \ge i) \ \text{and} \ a.\text{testBit}(j - i) \). Specifically, if \( j \ge i \), then the \((j+1)\)-th bit of \( 2^i \cdot a \) is the same as the \((j - i + 1)\)-th bit of \( a \); otherwise, it is 0.","theorem Nat.testBit_mul_pow_two :
    testBit (2 ^ i * a) j = (decide (j ≥ i) && testBit a (j-i)) := by
  have gen := testBit_mul_pow_two_add a (Nat.two_pow_pos i) j
  simp at gen
  rw [gen]
  cases Nat.lt_or_ge j i with
  | _ p => simp [p, Nat.not_le_of_lt, Nat.not_lt_of_le]","We start by constructing a lemma that states for any natural numbers \( a \), \( i \), and \( j \), the \((j+1)\)-th least significant bit in the binary representation of \( 2^i \cdot a + 0 \) is equal to:
- \( 0 \)’s \((j+1)\)-th least significant bit if \( j < i \),
- \( a \)’s \((j+1 - i)\)-th least significant bit if \( j \geq i \).

Using this lemma, we simplify the expression to get:
\[ (2^i \cdot a).testBit(j) = (\neg \text{decide}(j < i) \land a.testBit(j - i)) \]

We then replace the goal with:
\[ (\neg \text{decide}(j < i) \land a.testBit(j - i)) = (\text{decide}(j \ge i) \land a.testBit(j - i)) \]

We consider two cases for \( j \):
1. If \( j < i \), then \(\text{decide}(j < i)\) is true, and \(\neg \text{decide}(j < i)\) is false. Therefore, the left-hand side is false, and the right-hand side is also false because \(\text{decide}(j \ge i)\) is false.
2. If \( j \ge i \), then \(\text{decide}(j < i)\) is false, and \(\neg \text{decide}(j < i)\) is true. Therefore, the left-hand side is \(\text{true} \land a.testBit(j - i)\), and the right-hand side is also \(\text{true} \land a.testBit(j - i)\).

In both cases, the equality holds, thus completing the proof. \(\blacksquare\)","theorem Nat.testBit_mul_pow_two :
    testBit (2 ^ i * a) j = (decide (j ≥ i) && testBit a (j-i)) := by
/- First, we construct a lemma that states for any natural numbers \( a \), \( i \), and \( j \), the \((j+1)\)-th least significant bit in the binary representation of \( 2^i \cdot a + 0 \) is equal to:
- \( 0 \)’s \((j+1)\)-th least significant bit if \( j < i \),
- \( a \)’s \((j+1 - i)\)-th least significant bit if \( j \geq i \). -/
  have gen := testBit_mul_pow_two_add a (Nat.two_pow_pos i) j
/- Using the lemma we constructed, we simplify the expression to get:
\[ (2^i \cdot a).testBit(j) = (\neg \text{decide}(j < i) \land a.testBit(j - i)) \] -/
  simp at gen
/- Since the lemma we constructed shows that:
\[ (2^i \cdot a).testBit(j) = (\neg \text{decide}(j < i) \land a.testBit(j - i)) \]
we can replace the goal with:
\[ (\neg \text{decide}(j < i) \land a.testBit(j - i)) = (\text{decide}(j \ge i) \land a.testBit(j - i)) \] -/
  rw [gen]
  cases Nat.lt_or_ge j i with
/- We consider two cases for \( j \):
1. If \( j < i \), then \(\text{decide}(j < i)\) is true, and \(\neg \text{decide}(j < i)\) is false. Therefore, the left-hand side is false, and the right-hand side is also false because \(\text{decide}(j \ge i)\) is false.
2. If \( j \ge i \), then \(\text{decide}(j < i)\) is false, and \(\neg \text{decide}(j < i)\) is true. Therefore, the left-hand side is \(\text{true} \land a.testBit(j - i)\), and the right-hand side is also \(\text{true} \land a.testBit(j - i)\).

In both cases, the equality holds, thus completing the proof. -/
  | _ p => simp [p, Nat.not_le_of_lt, Nat.not_lt_of_le]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15809,Nat.and_pow_two_is_mod,theorem Nat.and_pow_two_is_mod (x n : Nat) : x &&& (2^n-1) = x % 2^n := by sorry,"Conjunction with \( 2^n - 1 \) is Equivalent to Modulo \( 2^n \) : For any natural numbers \( x \) and \( n \), the conjunction \( x \&&& (2^n - 1) \) is equal to the modulo operation \( x \mod 2^n \), i.e., \( x \&&& (2^n - 1) = x \mod 2^n \).","theorem Nat.and_pow_two_is_mod (x n : Nat) : x &&& (2^n-1) = x % 2^n := by
  apply eq_of_testBit_eq
  intro i
  simp only [testBit_and, testBit_mod_two_pow]
  cases testBit x i <;> simp","To prove that \( x \&&& (2^n - 1) = x \mod 2^n \), it suffices to show that for all natural numbers \( i \), the \( i \)-th bit of \( x \&&& (2^n - 1) \) is equal to the \( i \)-th bit of \( x \mod 2^n \).

Let \( i \) be an arbitrary natural number. We need to show:
\[
(x \text{ testBit } i \, \text{and} \, (2^n - 1) \text{ testBit } i) = (\text{decide}(i < n) \, \text{and} \, x \text{ testBit } i)
\]

We will discuss every possible case of \( x \text{ testBit } i \).

**Case 1:**
If \( x \text{ testBit } i = \text{false} \), we need to show:
\[
(\text{false} \, \text{and} \, (2^n - 1) \text{ testBit } i) = (\text{decide}(i < n) \, \text{and} \, \text{false})
\]
Simplifying both sides, we get:
\[
\text{false} = \text{false}
\]
Thus, the equality holds.

**Case 2:**
If \( x \text{ testBit } i = \text{true} \), we need to show:
\[
(\text{true} \, \text{and} \, (2^n - 1) \text{ testBit } i) = (\text{decide}(i < n) \, \text{and} \, \text{true})
\]
Simplifying both sides, we get:
\[
(2^n - 1) \text{ testBit } i = \text{decide}(i < n)
\]
Since \( 2^n - 1 \) is a number with all bits set to 1 up to the \( n \)-th bit, \( (2^n - 1) \text{ testBit } i \) is true if and only if \( i < n \). Therefore, both sides are equal, and the equality holds.

Since both cases are covered, we have shown that for all \( i \), the \( i \)-th bit of \( x \&&& (2^n - 1) \) is equal to the \( i \)-th bit of \( x \mod 2^n \). Therefore, \( x \&&& (2^n - 1) = x \mod 2^n \). This completes the proof.","theorem Nat.and_pow_two_is_mod (x n : Nat) : x &&& (2^n-1) = x % 2^n := by
/- To prove that \( x \&&& (2^n - 1) = x \mod 2^n \), it suffices to show that for all natural numbers \( i \), the \( i \)-th bit of \( x \&&& (2^n - 1) \) is equal to the \( i \)-th bit of \( x \mod 2^n \). -/
  apply eq_of_testBit_eq
/- Let \( i \) be an arbitrary natural number. We need to show that the \( i \)-th bit of \( x \&&& (2^n - 1) \) is equal to the \( i \)-th bit of \( x \mod 2^n \). -/
  intro i
/- Using the properties of bitwise AND and modulo operations, we can simplify the proposition we want to show to:
\[
(x \text{ testBit } i \, \text{and} \, (2^n - 1) \text{ testBit } i) = (\text{decide}(i < n) \, \text{and} \, x \text{ testBit } i)
\] -/
  simp only [testBit_and, testBit_mod_two_pow]
/- We will discuss every possible case of \( x \text{ testBit } i \).

**Case 1:**
If \( x \text{ testBit } i = \text{false} \), we need to show:
\[
(\text{false} \, \text{and} \, (2^n - 1) \text{ testBit } i) = (\text{decide}(i < n) \, \text{and} \, \text{false})
\]
Simplifying the left-hand side, we get:
\[
\text{false} \, \text{and} \, (2^n - 1) \text{ testBit } i = \text{false}
\]
Simplifying the right-hand side, we get:
\[
\text{decide}(i < n) \, \text{and} \, \text{false} = \text{false}
\]
Thus, both sides are equal to \(\text{false}\), and the equality holds.

**Case 2:**
If \( x \text{ testBit } i = \text{true} \), we need to show:
\[
(\text{true} \, \text{and} \, (2^n - 1) \text{ testBit } i) = (\text{decide}(i < n) \, \text{and} \, \text{true})
\]
Simplifying the left-hand side, we get:
\[
\text{true} \, \text{and} \, (2^n - 1) \text{ testBit } i = (2^n - 1) \text{ testBit } i
\]
Simplifying the right-hand side, we get:
\[
\text{decide}(i < n) \, \text{and} \, \text{true} = \text{decide}(i < n)
\]
Thus, we need to show:
\[
(2^n - 1) \text{ testBit } i = \text{decide}(i < n)
\]
Since \( 2^n - 1 \) is a number with all bits set to 1 up to the \( n \)-th bit, \( (2^n - 1) \text{ testBit } i \) is true if and only if \( i < n \). Therefore, both sides are equal, and the equality holds. -/
  cases testBit x i <;> simp","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
15835,Nat.testBit_mul_pow_two_add,"theorem Nat.testBit_mul_pow_two_add (a : Nat) {b i : Nat} (b_lt : b < 2^i) (j : Nat) :
    testBit (2 ^ i * a + b) j =
      if j < i then
        testBit b j
      else
        testBit a (j - i) := by sorry","Bitwise Representation of \( 2^i \cdot a + b \) in Natural Numbers : For any natural numbers \( a \), \( b \), and \( i \), if \( b < 2^i \), then for any natural number \( j \), the \((j+1)\)-th least significant bit in the binary representation of \( 2^i \cdot a + b \) is equal to:
- \( b \)’s \((j+1)\)-th least significant bit if \( j < i \),
- \( a \)’s \((j+1 - i)\)-th least significant bit if \( j \geq i \).","theorem Nat.testBit_mul_pow_two_add (a : Nat) {b i : Nat} (b_lt : b < 2^i) (j : Nat) :
    testBit (2 ^ i * a + b) j =
      if j < i then
        testBit b j
      else
        testBit a (j - i) := by
  cases Nat.lt_or_ge j i with
  | inl j_lt =>
    simp only [j_lt]
    have i_def : i = j + succ (pred (i-j)) := by
      rw [succ_pred_eq_of_pos] <;> omega
    rw [i_def]
    simp only [testBit_to_div_mod, Nat.pow_add, Nat.mul_assoc]
    simp only [Nat.mul_add_div (Nat.two_pow_pos _), Nat.mul_add_mod]
    simp [Nat.pow_succ, Nat.mul_comm _ 2, Nat.mul_assoc, Nat.mul_add_mod]
  | inr j_ge =>
    have j_def : j = i + (j-i) := (Nat.add_sub_cancel' j_ge).symm
    simp only [
        testBit_to_div_mod,
        Nat.not_lt_of_le,
        j_ge,
        ite_false]
    simp [congrArg (2^·) j_def, Nat.pow_add,
          ←Nat.div_div_eq_div_mul,
          Nat.mul_add_div,
          Nat.div_eq_of_lt b_lt,
          Nat.two_pow_pos i]","We need to show that for any natural numbers \( a \), \( b \), and \( i \), if \( b < 2^i \), then for any natural number \( j \), the \((j+1)\)-th least significant bit in the binary representation of \( 2^i \cdot a + b \) is equal to:
- \( b \)’s \((j+1)\)-th least significant bit if \( j < i \),
- \( a \)’s \((j+1 - i)\)-th least significant bit if \( j \geq i \).

We consider two cases based on the value of \( j \):

1. **Case \( j < i \):**
- We simplify the goal using the properties of the test bit, the power of a sum, and the division of a sum of multiples and a remainder.
- We show that \( (2^i \cdot a + b).testBit j = b.testBit j \).

2. **Case \( j \ge i \):**
- We introduce a lemma \( j = i + (j - i) \) and prove it using the property that \( a + b - a = b \) and the symmetry of equality.
- We simplify the goal using the properties of the test bit, the non-strict inequality, and the if-then-else function.
- We show that \( (2^i \cdot a + b).testBit j = a.testBit (j - i) \).

In both cases, the goal is simplified to the desired form, completing the proof.","theorem Nat.testBit_mul_pow_two_add (a : Nat) {b i : Nat} (b_lt : b < 2^i) (j : Nat) :
    testBit (2 ^ i * a + b) j =
      if j < i then
        testBit b j
      else
        testBit a (j - i) := by
  cases Nat.lt_or_ge j i with
/- We consider the case where \( j < i \). -/
  | inl j_lt =>
/- Since \( j < i \), we simplify the goal to:
\[ (2^i \cdot a + b).testBit j = b.testBit j \] -/
    simp only [j_lt]
/- We introduce a lemma \( i = j + \text{succ}(\text{pred}(i - j)) \) and prove it. -/
    have i_def : i = j + succ (pred (i-j)) := by
/- We use the property that the successor of the predecessor of a positive natural number is the number itself: \( \text{succ}(\text{pred}(n)) = n \) for \( n > 0 \). This simplifies \( i = j + (i - j) \) and \( 0 < i - j \). The `omega` tactic then automatically proves these equalities. -/
      rw [succ_pred_eq_of_pos] <;> omega
/- We substitute \( i = j + (i - j) \) into the goal, which simplifies the goal to:
\[ (2^{j + (i - j)} \cdot a + b).testBit j = b.testBit j \] -/
    rw [i_def]
/- We simplify the goal using the following properties:
- The test bit of a number \( x \) at position \( i \) is equivalent to the remainder of \( x / 2^i \% 2 \).
- The power of a sum is the product of the powers: \( 2^{j + (i - j)} = 2^j \cdot 2^{i - j} \).
- The associativity of multiplication: \( (2^j \cdot 2^{i - j} \cdot a + b) / 2^j \% 2 = (2^j \cdot (2^{i - j} \cdot a) + b) / 2^j \% 2 \).

This simplifies the goal to:
\[ \text{decide} \left( \frac{2^j \cdot (2^{i - j} \cdot a) + b}{2^j} \% 2 = 1 \right) = \text{decide} \left( b / 2^j \% 2 = 1 \right) \] -/
    simp only [testBit_to_div_mod, Nat.pow_add, Nat.mul_assoc]
/- We simplify the goal using the following properties:
- The division of a sum of multiples and a remainder: \( \frac{2^j \cdot (2^{i - j} \cdot a) + b}{2^j} = 2^{i - j} \cdot a + b / 2^j \).
- The modulo of a sum of multiples and a remainder: \( (2^j \cdot (2^{i - j} \cdot a) + b) \% 2^j = b \% 2^j \).

This simplifies the goal to:
\[ \text{decide} \left( (2^{i - j} \cdot a + b / 2^j) \% 2 = 1 \right) = \text{decide} \left( b / 2^j \% 2 = 1 \right) \] -/
    simp only [Nat.mul_add_div (Nat.two_pow_pos _), Nat.mul_add_mod]
/- We simplify the goal using the following properties:
- The power of a successor: \( 2^{i - j + 1} = 2^{i - j} \cdot 2 \).
- The commutativity of multiplication: \( 2 \cdot 2^{i - j} = 2^{i - j} \cdot 2 \).
- The associativity of multiplication: \( (2^{i - j} \cdot 2 \cdot a + b / 2^j) \% 2 = (2^{i - j} \cdot 2 \cdot a + b / 2^j) \% 2 \).
- The modulo of a sum of multiples and a remainder: \( (2^{i - j} \cdot 2 \cdot a + b / 2^j) \% 2 = b / 2^j \% 2 \).

This simplifies the goal to:
\[ \text{decide} \left( b / 2^j \% 2 = 1 \right) = \text{decide} \left( b / 2^j \% 2 = 1 \right) \] -/
    simp [Nat.pow_succ, Nat.mul_comm _ 2, Nat.mul_assoc, Nat.mul_add_mod]
/- We consider the case where \( j \ge i \). -/
  | inr j_ge =>
/- We introduce a lemma \( j = i + (j - i) \) and prove it using the property that \( a + b - a = b \) and the symmetry of equality. -/
    have j_def : j = i + (j-i) := (Nat.add_sub_cancel' j_ge).symm
/- We simplify the goal using the following properties:
- The test bit of a number \( x \) at position \( i \) is equivalent to the remainder of \( x / 2^i \% 2 \).
- The non-strict inequality \( j \ge i \) implies \( \neg (i < j) \).
- The if-then-else function returns the second argument when the condition is false: \( \text{ite}(\text{False}, a, b) = b \).

This simplifies the goal to:
\[ \text{decide} \left( (2^i \cdot a + b) / 2^j \% 2 = 1 \right) = \text{decide} \left( a / 2^{j - i} \% 2 = 1 \right) \] -/
    simp only [
        testBit_to_div_mod,
        Nat.not_lt_of_le,
        j_ge,
        ite_false]
/- First, we simplify the goal using the following properties:
- The function \( 2^{\cdot} \) is congruent, meaning if \( j = i + (j - i) \), then \( 2^j = 2^{i + (j - i)} \).
- The power of a sum is the product of the powers: \( 2^{i + (j - i)} = 2^i \cdot 2^{j - i} \).
- The division of a sum of multiples and a remainder: \( \frac{m \cdot x + y}{m} = x + \frac{y}{m} \).
- The division of a smaller natural number by a larger natural number is zero: \( b < 2^i \implies b / 2^i = 0 \).
- The power of 2 to any natural number is positive: \( 2^i > 0 \).

Using these properties, we simplify the goal to:
\[ \text{decide} \left( \frac{2^i \cdot a + b}{2^j} \% 2 = 1 \right) = \text{decide} \left( a / 2^{j - i} \% 2 = 1 \right) \] -/
    simp [congrArg (2^·) j_def, Nat.pow_add,
          ←Nat.div_div_eq_div_mul,
          Nat.mul_add_div,
          Nat.div_eq_of_lt b_lt,
/- We simplify the goal using the following properties:
- The function \( 2^{\cdot} \) is congruent, meaning if \( j = i + (j - i) \), then \( 2^j = 2^{i + (j - i)} \).
- The power of a sum is the product of the powers: \( 2^{i + (j - i)} = 2^i \cdot 2^{j - i} \).
- The division of a sum of multiples and a remainder: \( \frac{m \cdot x + y}{m} = x + \frac{y}{m} \).
- The division of a smaller natural number by a larger natural number is zero: \( b < 2^i \implies b / 2^i = 0 \).
- The power of 2 to any natural number is positive: \( 2^i > 0 \).

Using these properties, we simplify the goal to:
\[ \text{decide} \left( \frac{2^i \cdot a + b}{2^j} \% 2 = 1 \right) = \text{decide} \left( a / 2^{j - i} \% 2 = 1 \right) \] -/
          Nat.two_pow_pos i]","import Init.Data.Bool
import Init.Data.Int.Pow
import Init.Data.Nat.Bitwise.Basic
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Simproc
import Init.TacticsExtra
import Init.Omega
import Init.Data.Nat.Bitwise.Lemmas

open Nat

"
17172,List.foldlM_cons,"theorem List.foldlM_cons [Monad m] (f : β → α → m β) (b) (a) (l : List α) :
    (a :: l).foldlM f b = f b a >>= l.foldlM f := by sorry","Monadic Fold Over Cons List: \( \text{List.foldlM } f \, b \, (a :: l) = \text{do } \text{let } \text{init} \leftarrow f(b, a); \text{List.foldlM } f \, \text{init} \, l \) : For any monad \( m \), any function \( f : \beta \to \alpha \to m \beta \), any initial state \( b : \beta \), any element \( a : \alpha \), and any list \( l : \text{List } \alpha \), the monadic fold `List.foldlM f b (a :: l)` over a list with a head element \( a \) and a tail list \( l \) is equal to the following computation:
\[
\text{do} \quad
\begin{aligned}
  &\text{let } \text{init} \leftarrow f(b, a) \\
  &\text{List.foldlM } f \, \text{init} \, l
\end{aligned}
\]
In other words, the monadic fold over a list with a head element \( a \) and a tail list \( l \) is equivalent to first applying the function \( f \) to the initial state \( b \) and the head element \( a \), and then performing the monadic fold over the tail list \( l \) with the result of the first application as the new initial state.","theorem List.foldlM_cons [Monad m] (f : β → α → m β) (b) (a) (l : List α) :
    (a :: l).foldlM f b = f b a >>= l.foldlM f := by
  simp [List.foldlM]","To prove the theorem, we start by using the definition of the monadic fold `List.foldlM`. According to the definition, for a list with a head element \( a \) and a tail list \( l \), the monadic fold `List.foldlM f b (a :: l)` is defined as:
\[
\text{do} \quad
\begin{aligned}
&\text{let } \text{init} \leftarrow f(b, a) \\
&\text{List.foldlM } f \, \text{init} \, l
\end{aligned}
\]
This definition directly matches the goal we need to prove. Therefore, the proposition is true by the definition of `List.foldlM`. This completes the proof.","theorem List.foldlM_cons [Monad m] (f : β → α → m β) (b) (a) (l : List α) :
    (a :: l).foldlM f b = f b a >>= l.foldlM f := by
/- Using the definition of the monadic fold `List.foldlM`, we can simplify the proposition we want to show. The definition of `List.foldlM` states that for a list with a head element \( a \) and a tail list \( l \), the monadic fold `List.foldlM f b (a :: l)` is equivalent to:
\[
\text{do} \quad
\begin{aligned}
&\text{let } \text{init} \leftarrow f(b, a) \\
&\text{List.foldlM } f \, \text{init} \, l
\end{aligned}
\]
This simplification directly matches the goal we need to prove, thus the proof is complete. -/
  simp [List.foldlM]","import Init.Control.Basic
import Init.Data.List.Basic
import Init.Data.List.Control

open List

"
18471,BitVec.ofBool_true,theorem BitVec.ofBool_true : ofBool true  = 1 := by sorry,"Conversion of Boolean True to Bitvector One : The function `BitVec.ofBool` applied to the boolean value `true` results in the bitvector `1` of length 1, i.e., \(\text{BitVec.ofBool}(\text{true}) = 1\).","theorem BitVec.ofBool_true : ofBool true  = 1 := by
  trivial","The proof is straightforward. By the definition of the function `BitVec.ofBool`, we have that \(\text{BitVec.ofBool}(\text{true}) = 1\). Therefore, the equality \(\text{BitVec.ofBool}(\text{true}) = 1\) holds by definition. This completes the proof.","theorem BitVec.ofBool_true : ofBool true  = 1 := by
  trivial","import Init.Data.Fin.Basic
import Init.Data.Nat.Bitwise.Lemmas
import Init.Data.Nat.Power2
import Init.Data.Int.Bitwise
import Init.Data.BitVec.Basic

open BitVec

"
18474,BitVec.ofBool_false,theorem BitVec.ofBool_false : ofBool false = 0 := by sorry,"Conversion of Boolean False to Bitvector Zero : The function `BitVec.ofBool` applied to the boolean value `false` results in the bitvector `0` of length 1, i.e., \(\text{BitVec.ofBool}(\text{false}) = 0\).","theorem BitVec.ofBool_false : ofBool false = 0 := by
  trivial","The proof is straightforward. By the definition of the function `BitVec.ofBool`, applying it to the boolean value `false` yields the bitvector `0`. Therefore, the equality \(\text{BitVec.ofBool}(\text{false}) = 0\) holds by definition. This completes the proof.","theorem BitVec.ofBool_false : ofBool false = 0 := by
  trivial","import Init.Data.Fin.Basic
import Init.Data.Nat.Bitwise.Lemmas
import Init.Data.Nat.Power2
import Init.Data.Int.Bitwise
import Init.Data.BitVec.Basic

open BitVec

"
18730,Subarray.size_le_array_size,theorem Subarray.size_le_array_size {s : Subarray α} : s.size ≤ s.array.size := by sorry,"Subarray Size is Less Than or Equal to Array Size : For any subarray \( s \) of elements of type \( \alpha \), the size of the subarray \( s \) is less than or equal to the size of the original array \( s.array \). Formally, this is expressed as \( s.\text{size} \leq s.array.\text{size} \).","theorem Subarray.size_le_array_size {s : Subarray α} : s.size ≤ s.array.size := by
  let {array, start, stop, start_le_stop, stop_le_array_size} := s
  simp [size]
  apply Nat.le_trans (Nat.sub_le stop start)
  assumption","We start by deconstructing the subarray \( s \) into its components: the original array \( \text{array} \), the starting index \( \text{start} \), the stopping index \( \text{stop} \), the fact that the starting index is less than or equal to the stopping index \( \text{start} \leq \text{stop} \), and the fact that the stopping index is less than or equal to the size of the array \( \text{stop} \leq \text{array.size} \).

Next, we use the definition of the size of a subarray, which is the difference between the stopping index and the starting index, to simplify the goal to show that \( \text{stop} - \text{start} \leq \text{array.size} \).

To prove this, we use the transitivity of the less than or equal to relation. Specifically, we know that \( \text{stop} - \text{start} \leq \text{stop} \) (since the subtraction of a natural number from another natural number is less than or equal to the minuend). Therefore, it suffices to show that \( \text{stop} \leq \text{array.size} \).

The current goal \( \text{stop} \leq \text{array.size} \) has already been proved previously, as it is one of the components of the subarray \( s \). This completes the proof.","theorem Subarray.size_le_array_size {s : Subarray α} : s.size ≤ s.array.size := by
/- We start by deconstructing the subarray \( s \) into its components: the original array \( \text{array} \), the starting index \( \text{start} \), the stopping index \( \text{stop} \), the fact that the starting index is less than or equal to the stopping index \( \text{start} \leq \text{stop} \), and the fact that the stopping index is less than or equal to the size of the array \( \text{stop} \leq \text{array.size} \). -/
  let {array, start, stop, start_le_stop, stop_le_array_size} := s
/- Using the definition of the size of a subarray, which is the difference between the stopping index and the starting index, we simplify the goal to show that \( \text{stop} - \text{start} \leq \text{array.size} \). -/
  simp [size]
/- To prove that \( \text{stop} - \text{start} \leq \text{array.size} \), we use the transitivity of the less than or equal to relation. Specifically, we know that \( \text{stop} - \text{start} \leq \text{stop} \) (since the subtraction of a natural number from another natural number is less than or equal to the minuend). Therefore, it suffices to show that \( \text{stop} \leq \text{array.size} \). -/
  apply Nat.le_trans (Nat.sub_le stop start)
/- The current goal \( \text{stop} \leq \text{array.size} \) has already been proved previously, as it is one of the components of the subarray \( s \). -/
  assumption","import Init.Data.Array.Basic
import Init.Data.Array.Subarray

open Subarray

"
19612,Char.isValidUInt32,theorem Char.isValidUInt32 (n : Nat) (h : isValidCharNat n) : n < UInt32.size := by sorry,"Valid Unicode Scalar Value is Less Than \( 2^{32} \) : For any natural number \( n \), if \( n \) is a valid Unicode scalar value, then \( n \) is strictly less than \( 2^{32} \), i.e., \( n < 4294967296 \).","theorem Char.isValidUInt32 (n : Nat) (h : isValidCharNat n) : n < UInt32.size := by
  match h with
  | Or.inl h        =>
    apply Nat.lt_trans h
    decide
  | Or.inr ⟨_,  h₂⟩ =>
    apply Nat.lt_trans h₂
    decide","We need to show that for any natural number \( n \) that is a valid Unicode scalar value, \( n < 2^{32} \). A valid Unicode scalar value \( n \) satisfies one of the following conditions:
1. \( n < 55296 \)
2. \( 57343 < n \) and \( n < 1114112 \)

**Case 1: \( n < 55296 \)**
- We need to show that \( n < 2^{32} \).
- Since \( 55296 < 2^{32} \) (which is a straightforward computation), by the transitivity of the less-than relation, \( n < 55296 \) implies \( n < 2^{32} \).

**Case 2: \( 57343 < n \) and \( n < 1114112 \)**
- We need to show that \( n < 2^{32} \).
- Since \( 1114112 < 2^{32} \) (which is a straightforward computation), by the transitivity of the less-than relation, \( n < 1114112 \) implies \( n < 2^{32} \).

In both cases, we have shown that \( n < 2^{32} \). Therefore, for any valid Unicode scalar value \( n \), \( n < 2^{32} \). This completes the proof.","theorem Char.isValidUInt32 (n : Nat) (h : isValidCharNat n) : n < UInt32.size := by
  match h with
/- We consider the case where \( n < 55296 \). In this case, we need to show that \( n < 2^{32} \). -/
  | Or.inl h        =>
/- To prove \( n < 2^{32} \), we use the transitivity of the less-than relation. Since \( n < 55296 \) and \( 55296 < 2^{32} \), it follows that \( n < 2^{32} \). -/
    apply Nat.lt_trans h
/- We use the `decide` tactic to automatically verify that \( 1114112 < 2^{32} \). This is a straightforward computation, and the goal is immediately satisfied. -/
    decide
/- We consider the case where \( 57343 < n \) and \( n < 1114112 \). In this case, we need to show that \( n < 2^{32} \). -/
  | Or.inr ⟨_,  h₂⟩ =>
/- To prove \( n < 2^{32} \), we use the transitivity of the less-than relation. Since \( n < 1114112 \) and \( 1114112 < 2^{32} \), it follows that \( n < 2^{32} \). -/
    apply Nat.lt_trans h₂
/- We use the `decide` tactic to automatically verify that \( 55296 < 2^{32} \). This is a straightforward computation, and the goal is immediately satisfied. -/
/- We use the `decide` tactic to automatically verify that \( 1114112 < 2^{32} \). This is a straightforward computation, and the goal is immediately satisfied. -/
    decide","import Init.Data.UInt.Basic
import Init.Data.Char.Basic

open Char

"
19779,Nat.compare_def_lt,"theorem Nat.compare_def_lt (a b : Nat) :
    compare a b = if a < b then .lt else if b < a then .gt else .eq := by sorry","Comparison of Natural Numbers: \( \text{compare}(a, b) \) Based on Strict Inequality : For any natural numbers \( a \) and \( b \), the comparison \( \text{compare}(a, b) \) is defined as follows:
- If \( a < b \), then \( \text{compare}(a, b) = \text{Ordering.lt} \).
- If \( b < a \), then \( \text{compare}(a, b) = \text{Ordering.gt} \).
- If neither \( a < b \) nor \( b < a \), then \( \text{compare}(a, b) = \text{Ordering.eq} \).","theorem Nat.compare_def_lt (a b : Nat) :
    compare a b = if a < b then .lt else if b < a then .gt else .eq := by
  simp only [compare, compareOfLessAndEq]
  split
  · rfl
  · next h =>
    match Nat.lt_or_eq_of_le (Nat.not_lt.1 h) with
    | .inl h => simp [h, Nat.ne_of_gt h]
    | .inr rfl => simp","We start by using the definition of the comparison function for natural numbers to simplify the proposition we want to show:
\[
\text{if } a < b \text{ then } \text{Ordering.lt} \text{ else if } a = b \text{ then } \text{Ordering.eq} \text{ else } \text{Ordering.gt} = \text{if } a < b \text{ then } \text{Ordering.lt} \text{ else if } b < a \text{ then } \text{Ordering.gt} \text{ else } \text{Ordering.eq}
\]

We discuss by cases based on the condition \( a < b \):
1. **Case 1: \( a < b \)**
- The current goal is:
\[
\text{Ordering.lt} = \text{Ordering.lt}
\]
- This is trivially true due to the reflexive property of equality.

2. **Case 2: \( \neg (a < b) \)**
- We need to show:
\[
\text{if } a = b \text{ then } \text{Ordering.eq} \text{ else } \text{Ordering.gt} = \text{if } b < a \text{ then } \text{Ordering.gt} \text{ else } \text{Ordering.eq}
\]
- We further discuss by cases based on the condition \( a = b \):
- **Subcase 2.1: \( a = b \)**
- By substituting \( a = b \) into the expression, we get:
\[
\text{Ordering.eq} = \text{Ordering.eq}
\]
- This is trivially true due to the reflexive property of equality.
- **Subcase 2.2: \( a \neq b \)**
- Since \( a \neq b \) and \( \neg (a < b) \), it follows that \( b < a \).
- Thus, we need to show:
\[
\text{Ordering.gt} = \text{Ordering.gt}
\]
- This is trivially true due to the reflexive property of equality.

Therefore, the comparison function \( \text{compare}(a, b) \) is correctly defined as specified in the theorem. This completes the proof.","theorem Nat.compare_def_lt (a b : Nat) :
    compare a b = if a < b then .lt else if b < a then .gt else .eq := by
/- Using the definition of the comparison function for natural numbers, we can simplify the proposition we want to show to:
\[
\text{if } a < b \text{ then } \text{Ordering.lt} \text{ else if } a = b \text{ then } \text{Ordering.eq} \text{ else } \text{Ordering.gt} = \text{if } a < b \text{ then } \text{Ordering.lt} \text{ else if } b < a \text{ then } \text{Ordering.gt} \text{ else } \text{Ordering.eq}
\] -/
  simp only [compare, compareOfLessAndEq]
/- We discuss by cases based on the condition \( a < b \):
1. If \( a < b \), we need to show:
\[
\text{Ordering.lt} = \text{Ordering.lt}
\]
2. If \( \neg (a < b) \), we need to show:
\[
\text{if } a = b \text{ then } \text{Ordering.eq} \text{ else } \text{Ordering.gt} = \text{if } b < a \text{ then } \text{Ordering.gt} \text{ else } \text{Ordering.eq}
\] -/
  split
/- First, we show that if \( a < b \), then the current goal \( \text{Ordering.lt} = \text{Ordering.lt} \) is trivially true due to the reflexive property of equality. -/
  · rfl
/- Next, we consider the case where \( \neg (a < b) \). We need to show:
\[
\text{if } a = b \text{ then } \text{Ordering.eq} \text{ else } \text{Ordering.gt} = \text{if } b < a \text{ then } \text{Ordering.gt} \text{ else } \text{Ordering.eq}
\] -/
  · next h =>
    match Nat.lt_or_eq_of_le (Nat.not_lt.1 h) with
/- If \( a = b \), then by substituting \( a = b \) into the expression, we get:
\[
\text{Ordering.eq} = \text{Ordering.eq}
\]
This is trivially true due to the reflexive property of equality. -/
    | .inl h => simp [h, Nat.ne_of_gt h]
/- If \( a \neq b \), then by the property that \( a \neq b \) and \( \neg (a < b) \), it follows that \( b < a \). Thus, we need to show:
\[
\text{Ordering.gt} = \text{Ordering.gt}
\]
This is trivially true due to the reflexive property of equality. -/
    | .inr rfl => simp","import Init.Classical
import Init.Data.Ord
import Init.Data.Nat.Compare

open Nat

"
19780,Nat.compare_def_le,"theorem Nat.compare_def_le (a b : Nat) :
    compare a b = if a ≤ b then if b ≤ a then .eq else .lt else .gt := by sorry","Comparison of Natural Numbers: \( \text{compare}(a, b) \) Definition Using Less-Than-or-Equal Relation : For any natural numbers \( a \) and \( b \), the comparison \( \text{compare}(a, b) \) is defined as follows:
- If \( a \le b \) and \( b \le a \), then \( \text{compare}(a, b) = \text{Ordering.eq} \) (i.e., \( a = b \)).
- If \( a \le b \) and \( b \not\le a \), then \( \text{compare}(a, b) = \text{Ordering.lt} \) (i.e., \( a < b \)).
- If \( a \not\le b \), then \( \text{compare}(a, b) = \text{Ordering.gt} \) (i.e., \( a > b \)).","theorem Nat.compare_def_le (a b : Nat) :
    compare a b = if a ≤ b then if b ≤ a then .eq else .lt else .gt := by
  rw [compare_def_lt]
  split
  · next hlt => simp [Nat.le_of_lt hlt, Nat.not_le.2 hlt]
  · next hge =>
    split
    · next hgt => simp [Nat.le_of_lt hgt, Nat.not_le.2 hgt]
    · next hle => simp [Nat.not_lt.1 hge, Nat.not_lt.1 hle]","We start by noting that the assumption that the cardinality of $n$ is zero is equivalent to, and thus can be converted to, $n$ being empty. We need to prove that the determinant of $M$ is $1$.

First, we try to show that $M = 1$ (the identity matrix). To show this, we prove that for every $i \in n$, $M i = 1 i$. However, since $n$ is empty, $M i = 1 i$ holds for every $i \in n$ vacuously. Hence, $M = 1$.

Therefore, the determinant of $M$ is $\det M = \det 1 = 1$. This completes the proof.

---

### Line by Line Informal Proof for \( \text{compare}(a, b) \) Definition Using Less-Than-or-Equal Relation

#### Informal Step 1

**Formal proof line:**
rw [compare_def_lt]

**Informal translation:**
We use the definition of the comparison function based on strict inequality to rewrite the goal. Specifically, we replace the goal with the equivalent statement:
\[
\text{compare}(a, b) = \begin{cases}
\text{Ordering.lt} & \text{if } a < b \\
\text{Ordering.gt} & \text{if } b < a \\
\text{Ordering.eq} & \text{otherwise}
\end{cases}
\]

#### Informal Step 2

**Formal proof line:**
split

**Informal translation:**
We discuss by cases based on the condition \( a \le b \):
- Case 1: \( a < b \)
- Case 2: \( \neg (a < b) \)

#### Informal Step 3

**Formal proof line:**
· next hlt => simp [Nat.le_of_lt hlt, Nat.not_le.2 hlt]

**Informal translation:**
For the case where \( a < b \):
- Since \( a < b \) implies \( a \le b \), and \( \neg (b \le a) \) is equivalent to \( b < a \), we can simplify the goal to:
\[
\text{Ordering.lt} = \text{Ordering.lt}
\]
This is trivially true.

#### Informal Step 4

**Formal proof line:**
· next hge =>

**Informal translation:**
For the case where \( \neg (a < b) \):
- We further discuss by cases based on the condition \( b < a \):
- Case 1: \( b < a \)
- Case 2: \( \neg (b < a) \)

#### Informal Step 5

**Formal proof line:**
split

**Informal translation:**
We discuss by cases based on the condition \( b < a \):
- Case 1: \( b < a \)
- Case 2: \( \neg (b < a) \)

#### Informal Step 6

**Formal proof line:**
· next hgt => simp [Nat.le_of_lt hgt, Nat.not_le.2 hgt]

**Informal translation:**
For the case where \( b < a \):
- Since \( b < a \) implies \( b \le a \), and \( \neg (a \le b) \) is equivalent to \( a < b \), we can simplify the goal to:
\[
\text{Ordering.gt} = \text{Ordering.gt}
\]
This is trivially true.

#### Informal Step 7

**Formal proof line:**
· next hle => simp [Nat.not_lt.1 hge, Nat.not_lt.1 hle]

**Informal translation:**
For the case where \( \neg (b < a) \):
- Since \( \neg (a < b) \) is equivalent to \( b \le a \), and \( \neg (b < a) \) is equivalent to \( a \le b \), we can simplify the goal to:
\[
\text{Ordering.eq} = \text{Ordering.eq}
\]
This is trivially true.

### Whole Informal Proof

**Theorem:**
For any natural numbers \( a \) and \( b \), the comparison \( \text{compare}(a, b) \) is defined as follows:
- If \( a \le b \) and \( b \le a \), then \( \text{compare}(a, b) = \text{Ordering.eq} \) (i.e., \( a = b \)).
- If \( a \le b \) and \( b \not\le a \), then \( \text{compare}(a, b) = \text{Ordering.lt} \) (i.e., \( a < b \)).
- If \( a \not\le b \), then \( \text{compare}(a, b) = \text{Ordering.gt} \) (i.e., \( a > b \)).

**Proof:**
We start by using the definition of the comparison function based on strict inequality:
\[
\text{compare}(a, b) = \begin{cases}
\text{Ordering.lt} & \text{if } a < b \\
\text{Ordering.gt} & \text{if } b < a \\
\text{Ordering.eq} & \text{otherwise}
\end{cases}
\]

We then discuss by cases based on the condition \( a \le b \):

1. **Case 1: \( a < b \)**
- Since \( a < b \) implies \( a \le b \), and \( \neg (b \le a) \) is equivalent to \( b < a \), we have:
\[
\text{compare}(a, b) = \text{Ordering.lt}
\]
- The goal simplifies to:
\[
\text{Ordering.lt} = \text{Ordering.lt}
\]
- This is trivially true.

2. **Case 2: \( \neg (a < b) \)**
- We further discuss by cases based on the condition \( b < a \):

- **Subcase 1: \( b < a \)**
- Since \( b < a \) implies \( b \le a \), and \( \neg (a \le b) \) is equivalent to \( a < b \), we have:
\[
\text{compare}(a, b) = \text{Ordering.gt}
\]
- The goal simplifies to:
\[
\text{Ordering.gt} = \text{Ordering.gt}
\]
- This is trivially true.

- **Subcase 2: \( \neg (b < a) \)**
- Since \( \neg (a < b) \) is equivalent to \( b \le a \), and \( \neg (b < a) \) is equivalent to \( a \le b \), we have:
\[
\text{compare}(a, b) = \text{Ordering.eq}
\]
- The goal simplifies to:
\[
\text{Ordering.eq} = \text{Ordering.eq}
\]
- This is trivially true.

Thus, in all cases, the comparison function \( \text{compare}(a, b) \) is correctly defined as specified. This completes the proof.","theorem Nat.compare_def_le (a b : Nat) :
    compare a b = if a ≤ b then if b ≤ a then .eq else .lt else .gt := by
/- First, we use the equivalence that the cardinality of a finite type is $0$ if and only if this type is empty, to convert the assumption of cardinality of $n = 0$ into $n$ is empty. -/
/- It suffices to show that $M = 1$ (the identity matrix), because if this is true, by using this $M = 1$ and simplifying, we get the determinant of $M$ is $1$ automatically. -/
/- Using extensionality, to prove that $M = 1$, we only need to show that $M i = 1 i$ for every $i \in n$. -/
/- Since $n$ is empty, this $M i = 1 i$ holds for every $i \in n$ vacuously. This finishes the proof. -/
  rw [compare_def_lt]
  split
  · next hlt => simp [Nat.le_of_lt hlt, Nat.not_le.2 hlt]
  · next hge =>
    split
    · next hgt => simp [Nat.le_of_lt hgt, Nat.not_le.2 hgt]
    · next hle => simp [Nat.not_lt.1 hge, Nat.not_lt.1 hle]","import Init.Classical
import Init.Data.Ord
import Init.Data.Nat.Compare

open Nat

"
19781,Nat.compare_ne_lt,theorem Nat.compare_ne_lt {a b : Nat} : compare a b ≠ .lt ↔ b ≤ a := by sorry,"Comparison Not Less Than Implies \( b \leq a \) in Natural Numbers : For any natural numbers \( a \) and \( b \), if the comparison of \( a \) and \( b \) is not less than, i.e., \( \text{compare}(a, b) \neq \text{lt} \), then it holds that \( b \leq a \).","theorem Nat.compare_ne_lt {a b : Nat} : compare a b ≠ .lt ↔ b ≤ a := by
  rw [compare_def_le]; (repeat' split) <;> simp [Nat.le_of_not_le, *]","We start by using the definition of the comparison function for natural numbers, which states that \( \text{compare}(a, b) \) is less than if and only if \( a < b \). Therefore, the statement \( \text{compare}(a, b) \neq \text{lt} \) is equivalent to \( a < b \) being false. We need to show that \( a < b \) being false implies \( b \leq a \).

1. **Forward Direction:**
- Assume \( a < b \) is false.
- By the property of natural numbers, if \( a \) is not less than \( b \), then \( b \leq a \).
- Therefore, \( a < b \) being false implies \( b \leq a \).

2. **Backward Direction:**
- Assume \( b \leq a \).
- By the property of natural numbers, if \( b \leq a \), then \( a < b \) is false.
- Therefore, \( b \leq a \) implies \( a < b \) is false.

Combining these two directions, we have shown that \( \text{compare}(a, b) \neq \text{lt} \) if and only if \( b \leq a \). This completes the proof.","theorem Nat.compare_ne_lt {a b : Nat} : compare a b ≠ .lt ↔ b ≤ a := by
/- First, we use the definition of the comparison function for natural numbers, which states that \( \text{compare}(a, b) \) is less than if and only if \( a < b \). This transforms our goal into showing that \( a < b \) is false if and only if \( b \leq a \). We then split the goal into two cases: proving the forward direction and the backward direction. For the forward direction, we assume \( a < b \) is false and use the property that if \( a \) is not less than \( b \), then \( b \leq a \). For the backward direction, we assume \( b \leq a \) and show that \( a < b \) is false. After simplifying these expressions, we get the desired result. -/
  rw [compare_def_le]; (repeat' split) <;> simp [Nat.le_of_not_le, *]","import Init.Classical
import Init.Data.Ord
import Init.Data.Nat.Compare

open Nat

"
21280,List.filterMap_eq_filterMapTR,theorem List.filterMap_eq_filterMapTR : @List.filterMap = @filterMapTR := by sorry,"Equivalence of `filterMap` and `filterMapTR` Functions for Lists : For any types \( \alpha \) and \( \beta \), and for any function \( f : \alpha \to \text{Option} \, \beta \), the `filterMap` function applied to a list \( l \) of elements of type \( \alpha \) is equal to the `filterMapTR` function applied to the same list \( l \). In other words, the non-tail-recursive `filterMap` and the tail-recursive `filterMapTR` produce the same result when applied to the same list and function.","theorem List.filterMap_eq_filterMapTR : @List.filterMap = @filterMapTR := by
  funext α β f l
  let rec go : ∀ as acc, filterMapTR.go f as acc = acc.data ++ as.filterMap f
    | [], acc => by simp [filterMapTR.go, filterMap]
    | a::as, acc => by
      simp only [filterMapTR.go, go as, Array.push_data, append_assoc, singleton_append, filterMap]
      split <;> simp [*]
  exact (go l #[]).symm","By the principle of function extensionality, it suffices to show that for all types \( \alpha \) and \( \beta \), for any function \( f : \alpha \to \text{Option} \, \beta \), and for any list \( l \) of elements of type \( \alpha \), the functions `filterMap` and `filterMapTR` yield the same result when applied to \( l \) and \( f \).

Let us define a recursive function `go` such that for any list `as` and accumulator `acc`, `filterMapTR.go f as acc` is equal to the concatenation of `acc.data` and `as.filterMap f`. For the base case where `as` is empty, we simplify using the definitions of `filterMapTR.go` and `filterMap`. For the inductive case where `as` is of the form `a :: as`, we simplify using the recursive call `go as` and properties of list operations. We then handle the two cases of the `match` expression (where `f a` is either `none` or `some b`) and simplify using the properties of list concatenation.

The current goal, which is to show that `filterMap f l = filterMapTR f l`, is exactly proved by the symmetric form of the result of the recursive function `go` applied to `l` and an empty array `#[]`. This completes the proof.

Thus, we have shown that `filterMap` and `filterMapTR` are equivalent for any list and function, thereby establishing the theorem.","theorem List.filterMap_eq_filterMapTR : @List.filterMap = @filterMapTR := by
/- By the principle of function extensionality, it suffices to show that for all types \( \alpha \) and \( \beta \), for any function \( f : \alpha \to \text{Option} \, \beta \), and for any list \( l \) of elements of type \( \alpha \), the functions `filterMap` and `filterMapTR` yield the same result when applied to \( l \) and \( f \). -/
  funext α β f l
/- Let us define a recursive function `go` such that for any list `as` and accumulator `acc`, `filterMapTR.go f as acc` is equal to the concatenation of `acc.data` and `as.filterMap f`. For the base case where `as` is empty, we simplify using the definitions of `filterMapTR.go` and `filterMap`. For the inductive case where `as` is of the form `a :: as`, we simplify using the recursive call `go as` and properties of list operations. We then handle the two cases of the `match` expression (where `f a` is either `none` or `some b`) and simplify using the properties of list concatenation. -/
  let rec go : ∀ as acc, filterMapTR.go f as acc = acc.data ++ as.filterMap f
    | [], acc => by simp [filterMapTR.go, filterMap]
    | a::as, acc => by
      simp only [filterMapTR.go, go as, Array.push_data, append_assoc, singleton_append, filterMap]
      split <;> simp [*]
/- The current goal, which is to show that `filterMap f l = filterMapTR f l`, is exactly proved by the symmetric form of the result of the recursive function `go` applied to `l` and an empty array `#[]`. This completes the proof. -/
  exact (go l #[]).symm","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
21282,List.filterTR_loop_eq,"theorem List.filterTR_loop_eq (p : α → Bool) (as bs : List α) :
    filterTR.loop p as bs = bs.reverse ++ filter p as := by sorry","Tail-Recursive Filter Loop Equals Reverse Concatenation with Filtered List : For any type \( \alpha \), predicate \( p : \alpha \to \text{Bool} \), and lists \( \text{as}, \text{bs} : \text{List} \, \alpha \), the tail-recursive filter loop function `List.filterTR.loop` applied to \( p \), \( \text{as} \), and \( \text{bs} \) returns a list that is the reverse of \( \text{bs} \) concatenated with the list of elements from \( \text{as} \) that satisfy the predicate \( p \). In other words, \( \text{List.filterTR.loop} \, p \, \text{as} \, \text{bs} = \text{bs.reverse} \, ++ \, \text{List.filter} \, p \, \text{as} \).","theorem List.filterTR_loop_eq (p : α → Bool) (as bs : List α) :
    filterTR.loop p as bs = bs.reverse ++ filter p as := by
  induction as generalizing bs with
  | nil => simp [filterTR.loop, filter]
  | cons a as ih =>
    simp only [filterTR.loop, filter]
    split <;> simp_all","We proceed by induction on the structure of the list `as`.

1. **Base Case:**
When `as` is the empty list, we simplify the goal using the definitions of `filterTR.loop` and `filter`. This results in the expression `filterTR.loop p [] bs = bs.reverse ++ filter p []`, which simplifies to `bs.reverse = bs.reverse`, which is trivially true.

2. **Inductive Step:**
When `as` is of the form `a :: as`, we use the induction hypothesis `ih` which states that for any list `bs`, `filterTR.loop p as bs = bs.reverse ++ filter p as`.

We simplify the goal using the definitions of `filterTR.loop` and `filter`. This results in the expression:
\[
\text{match } p \, a \text{ with}
\begin{cases}
\text{true} & \Rightarrow \text{filterTR.loop } p \, \text{as} \, (a :: \text{bs}) \\
\text{false} & \Rightarrow \text{filterTR.loop } p \, \text{as} \, \text{bs}
\end{cases}
=
\text{bs.reverse} \, ++ \,
\begin{cases}
\text{true} & \Rightarrow a :: \text{filter } p \, \text{as} \\
\text{false} & \Rightarrow \text{filter } p \, \text{as}
\end{cases}
\]

We split the goal into two cases based on the value of `p a`:
1. If `p a` is `true`, we simplify the goal to `filterTR.loop p as (a :: bs) = bs.reverse ++ a :: filter p as`.
2. If `p a` is `false`, we simplify the goal to `filterTR.loop p as bs = bs.reverse ++ filter p as`.

For each case, we use the induction hypothesis `ih` to simplify the expressions, resulting in the goals being trivially true.

Thus, by induction, we have shown that `List.filterTR.loop p as bs = bs.reverse ++ List.filter p as` for any list `as` and `bs`.

This completes the proof.","theorem List.filterTR_loop_eq (p : α → Bool) (as bs : List α) :
    filterTR.loop p as bs = bs.reverse ++ filter p as := by
  induction as generalizing bs with
/- When `as` is the empty list, we simplify the goal using the definitions of `filterTR.loop` and `filter`. This results in the expression `filterTR.loop p [] bs = bs.reverse ++ filter p []`, which simplifies to `bs.reverse = bs.reverse`, which is trivially true. -/
  | nil => simp [filterTR.loop, filter]
/- When `as` is of the form `a :: as`, we use the induction hypothesis `ih` which states that for any list `bs`, `filterTR.loop p as bs = bs.reverse ++ filter p as`. -/
  | cons a as ih =>
/- We simplify the goal using the definitions of `filterTR.loop` and `filter`. This results in the expression:
\[
\text{match } p \, a \text{ with}
\begin{cases}
\text{true} & \Rightarrow \text{filterTR.loop } p \, \text{as} \, (a :: \text{bs}) \\
\text{false} & \Rightarrow \text{filterTR.loop } p \, \text{as} \, \text{bs}
\end{cases}
=
\text{bs.reverse} \, ++ \,
\begin{cases}
\text{true} & \Rightarrow a :: \text{filter } p \, \text{as} \\
\text{false} & \Rightarrow \text{filter } p \, \text{as}
\end{cases}
\] -/
    simp only [filterTR.loop, filter]
/- We consider the cases based on the structure of the list `as`. For each case, we simplify the goal using the definitions of `filterTR.loop` and `filter`. -/
/- We split the goal into two cases based on the value of `p a`:
1. If `p a` is `true`, we simplify the goal to `filterTR.loop p as (a :: bs) = bs.reverse ++ a :: filter p as`.
2. If `p a` is `false`, we simplify the goal to `filterTR.loop p as bs = bs.reverse ++ filter p as`.

For each case, we use the induction hypothesis `ih` to simplify the expressions, resulting in the goals being trivially true. -/
    split <;> simp_all","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
21284,List.intersperse_eq_intersperseTR,theorem List.intersperse_eq_intersperseTR : @intersperse = @intersperseTR := by sorry,"Equivalence of `intersperse` and `intersperseTR` Functions for Lists : For any type \( \alpha \), any element \( \text{sep} \) of type \( \alpha \), and any list \( \text{xs} \) of elements of type \( \alpha \), the function `List.intersperse` and the tail-recursive function `List.intersperseTR` produce the same result. Specifically, `List.intersperse sep xs` is equal to `List.intersperseTR sep xs`.","theorem List.intersperse_eq_intersperseTR : @intersperse = @intersperseTR := by
  funext α sep l; simp [intersperseTR]
  match l with
  | [] | [_] => rfl
  | x::y::xs => simp [intersperse]; induction xs generalizing y <;> simp [*]","By the principle of function extensionality, it suffices to show that for all types \( \alpha \), all elements \( \text{sep} \) of type \( \alpha \), and all lists \( \text{l} \) of elements of type \( \alpha \), the functions `List.intersperse` and `List.intersperseTR` yield the same result. We proceed by case analysis on the list `l`:

1. **Base Case: Empty List**
- If `l` is the empty list (`[]`), both `List.intersperse sep []` and `List.intersperseTR sep []` return the empty list. Thus, the equality holds trivially.

2. **Base Case: Single Element List**
- If `l` is a list with a single element (`[x]`), both `List.intersperse sep [x]` and `List.intersperseTR sep [x]` return the list `[x]`. Thus, the equality holds trivially.

3. **Inductive Case: At Least Two Elements**
- If `l` is of the form `x::y::xs` (i.e., it contains at least two elements), we simplify the expressions using the definitions of `List.intersperse` and `List.intersperseTR`. We then perform induction on the remaining list `xs`, generalizing the second element `y`. For each case in the induction, we simplify the expressions using the induction hypotheses and the definitions of the functions, ensuring that the results match.

By considering all these cases, we conclude that `List.intersperse sep l` is equal to `List.intersperseTR sep l` for any list `l`, thus proving the theorem.

$\square$","theorem List.intersperse_eq_intersperseTR : @intersperse = @intersperseTR := by
/- By the principle of function extensionality, it suffices to show that for all types \( \alpha \), all elements \( \text{sep} \) of type \( \alpha \), and all lists \( \text{l} \) of elements of type \( \alpha \), the functions `List.intersperse` and `List.intersperseTR` yield the same result. Using simplification with the definition of `List.intersperseTR`, we reduce the goal to showing that `List.intersperse sep l` equals the result of the pattern match on `l` using `List.intersperseTR`. -/
  funext α sep l; simp [intersperseTR]
  match l with
/- For the base cases where the list `l` is either empty (`[]`) or contains a single element (`[_]`), the result is straightforward. Both `List.intersperse` and `List.intersperseTR` return the list unchanged, so the equality is trivially true by reflexivity (`rfl`). -/
  | [] | [_] => rfl
/- For the inductive case where the list `l` is of the form `x::y::xs` (i.e., it contains at least two elements), we simplify the expression using the definition of `List.intersperse`. We then perform induction on the remaining list `xs`, generalizing the second element `y`. For each case in the induction, we simplify the expressions using the induction hypotheses and the definitions of the functions, ensuring that the results match. -/
  | x::y::xs => simp [intersperse]; induction xs generalizing y <;> simp [*]","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
21286,List.range'_eq_range'TR,theorem List.range'_eq_range'TR : @range' = @range'TR := by sorry,"Equality of `range'` and `range'TR` Functions in Natural Numbers : For any natural numbers \( \text{start} \), \( \text{len} \), and \( \text{step} \), the function `range'` that generates a list of natural numbers starting from `start` and incrementing by `step` for `len` times is equal to the tail-recursive function `range'TR` that generates the same list. Specifically, `range' start len step` returns the list \([ \text{start}, \text{start} + \text{step}, \ldots, \text{start} + (\text{len} - 1) \cdot \text{step} ]\), and this list is the same as the one returned by `range'TR start len step`.","theorem List.range'_eq_range'TR : @range' = @range'TR := by
  funext s n step
  let rec go (s) : ∀ n m,
    range'TR.go step n (s + step * n) (range' (s + step * n) m step) = range' s (n + m) step
  | 0, m => by simp [range'TR.go]
  | n+1, m => by
    simp [range'TR.go]
    rw [Nat.mul_succ, ← Nat.add_assoc, Nat.add_sub_cancel, Nat.add_right_comm n]
    exact go s n (m + 1)
  exact (go s n 0).symm","By the principle of function extensionality, it suffices to show that for all natural numbers \( s \), \( n \), and \( step \) (with \( step \) defaulting to 1), the functions `range'` and `range'TR` yield the same result, i.e., \( \text{range'} s n step = \text{range'TR} s n step \).

For the base case where \( n = 0 \) and any \( m \), simplifying using the definition of `range'TR.go` shows that both `range'` and `range'TR` return an empty list, thus they are equal.

For the inductive case where \( n = n + 1 \) and any \( m \), we proceed to show that the lists generated by `range'` and `range'TR` are equal. Using the definition of `range'TR.go`, we simplify the expressions involved in the lists generated by `range'` and `range'TR`. We rewrite the expressions using the properties of natural number arithmetic: the distributive property of multiplication over addition, associativity of addition, cancellation of subtraction, and right commutativity of addition. The current goal is exactly proved by applying the helper function `go` to \( s \), \( n \), and \( m + 1 \), which establishes the equality of the lists generated by `range'` and `range'TR`.

Thus, we have shown that \( \text{range'} s n step = \text{range'TR} s n step \) for all natural numbers \( s \), \( n \), and \( step \), completing the proof.","theorem List.range'_eq_range'TR : @range' = @range'TR := by
/- By the principle of function extensionality, it suffices to show that for all natural numbers \( s \), \( n \), and \( step \) (with \( step \) defaulting to 1), the functions `range'` and `range'TR` yield the same result, i.e., \( \text{range'} s n step = \text{range'TR} s n step \). -/
  funext s n step
  let rec go (s) : ∀ n m,
    range'TR.go step n (s + step * n) (range' (s + step * n) m step) = range' s (n + m) step
/- For the base case where \( n = 0 \) and any \( m \), simplifying using the definition of `range'TR.go` shows that both `range'` and `range'TR` return an empty list, thus they are equal. -/
  | 0, m => by simp [range'TR.go]
/- For the inductive case where \( n = n + 1 \) and any \( m \), we proceed to show that the lists generated by `range'` and `range'TR` are equal. -/
  | n+1, m => by
/- Using the definition of `range'TR.go`, we simplify the expressions involved in the lists generated by `range'` and `range'TR`. -/
    simp [range'TR.go]
/- We rewrite the expressions using the properties of natural number arithmetic: the distributive property of multiplication over addition, associativity of addition, cancellation of subtraction, and right commutativity of addition. -/
    rw [Nat.mul_succ, ← Nat.add_assoc, Nat.add_sub_cancel, Nat.add_right_comm n]
/- The current goal is exactly proved by applying the helper function `go` to \( s \), \( n \), and \( m + 1 \), which establishes the equality of the lists generated by `range'` and `range'TR`. -/
    exact go s n (m + 1)
/- The current goal \( \text{range'} s n step = \text{range'TR} s n step \) is exactly proved by the symmetry of the result of the helper function `go` applied to \( s \), \( n \), and \( 0 \). -/
  exact (go s n 0).symm","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
21983,String.ne_of_lt,theorem String.ne_of_lt {a b : String} (h : a < b) : a ≠ b := by sorry,"Irreflexivity of Strict Inequality: \( a < b \to a \neq b \) : For any strings \( a \) and \( b \), if \( a < b \), then \( a \neq b \).","theorem String.ne_of_lt {a b : String} (h : a < b) : a ≠ b := by
  have := String.lt_irrefl a
  intro h; subst h; contradiction","We start by noting that the irreflexivity of the less-than relation for strings implies that \( a < a \) is false. We denote this fact as \( \neg (a < a) \).

Assume, for the sake of contradiction, that \( a = b \). Substituting \( a \) for \( b \) in the assumption \( a < b \), we get \( a < a \). However, we already know that \( \neg (a < a) \) is true, which leads to a contradiction. Therefore, our assumption \( a = b \) must be false, and hence \( a \neq b \).

This completes the proof.","theorem String.ne_of_lt {a b : String} (h : a < b) : a ≠ b := by
/- First, we note that the irreflexivity of the less-than relation for strings implies that \( a < a \) is false. We denote this fact as \( \neg (a < a) \). -/
  have := String.lt_irrefl a
/- Assume, for the sake of contradiction, that \( a = b \). Substituting \( a \) for \( b \) in the assumption \( a < b \), we get \( a < a \). However, we already know that \( \neg (a < a) \) is true, which leads to a contradiction. Therefore, our assumption \( a = b \) must be false, and hence \( a \neq b \). -/
  intro h; subst h; contradiction","import Init.Data.Char.Lemmas
import Init.Data.String.Lemmas

open String

"
22004,List.mem_pmap,"theorem List.mem_pmap {p : α → Prop} {f : ∀ a, p a → β} {l H b} :
    b ∈ pmap f l H ↔ ∃ (a : _) (h : a ∈ l), f a (H a h) = b := by sorry","Membership in Partial Map of List: \( b \in \text{pmap } f \, l \, H \leftrightarrow \exists a \, h, f(a, h) = b \) : For any list \( l \) of elements of type \( \alpha \) and a predicate \( P : \alpha \to \text{Prop} \), if \( f : \Pi a, P a \to \beta \) is a partial function that can be applied to elements of \( l \) that satisfy \( P \), and \( H \) is a proof that all elements of \( l \) satisfy \( P \), then an element \( b \) of type \( \beta \) is in the list obtained by applying \( f \) to each element of \( l \) that satisfies \( P \) if and only if there exists an element \( a \) in \( l \) and a proof \( h \) that \( a \) satisfies \( P \) such that \( f(a, h) = b \).","theorem List.mem_pmap {p : α → Prop} {f : ∀ a, p a → β} {l H b} :
    b ∈ pmap f l H ↔ ∃ (a : _) (h : a ∈ l), f a (H a h) = b := by
  simp only [pmap_eq_map_attach, mem_map, mem_attach, true_and, Subtype.exists, eq_comm]","We start by simplifying the proposition we want to show using the following theorems and definitions:
1. The partial map of \( f \) over \( l \) using \( H \) is equal to the map of \( f \) over the attached list \( l.attach \):
\[
\text{pmap } f \, l \, H = \text{map } (fun \, x \, \Rightarrow \, f \, x.val) \, l.attach
\]
2. The membership of an element in a map of a list.
3. The membership of an element in the attached list.
4. The conjunction of the true proposition and any proposition \( p \) is equal to \( p \):
\[
\text{True} \land p = p
\]
5. The existential quantification over a subtype.
6. The symmetry of equality:
\[
a = b \leftrightarrow b = a
\]

After simplification, the proposition we want to show is equivalent to:
\[
b \in \text{map } (fun \, x \, \Rightarrow \, f \, x.val) \, l.attach \leftrightarrow \exists a \, h, f(a, h) = b
\]

This completes the proof.","theorem List.mem_pmap {p : α → Prop} {f : ∀ a, p a → β} {l H b} :
    b ∈ pmap f l H ↔ ∃ (a : _) (h : a ∈ l), f a (H a h) = b := by
/- We simplify the proposition we want to show using the following theorems and definitions:
- The partial map of \( f \) over \( l \) using \( H \) is equal to the map of \( f \) over the attached list \( l.attach \).
- The membership of an element in a map of a list.
- The membership of an element in the attached list.
- The conjunction of the true proposition and any proposition \( p \) is equal to \( p \).
- The existential quantification over a subtype.
- The symmetry of equality.

After simplification, the proposition we want to show is equivalent to:
\[
b \in \text{map } (fun \, x \, \Rightarrow \, f \, x.val) \, l.attach \leftrightarrow \exists a \, h, f(a, h) = b
\] -/
  simp only [pmap_eq_map_attach, mem_map, mem_attach, true_and, Subtype.exists, eq_comm]","import Init.Data.List.Count
import Init.Data.Subtype
import Init.Data.List.Attach

open List

"
22010,List.pmap_eq_nil,"theorem List.pmap_eq_nil {p : α → Prop} {f : ∀ a, p a → β} {l H} : pmap f l H = [] ↔ l = [] := by sorry","Partial Map on List is Empty if and only if List is Empty: \( \text{pmap } f \, l \, H = [] \leftrightarrow l = [] \) : For any types \( \alpha \) and \( \beta \), a predicate \( p : \alpha \to \text{Prop} \), a partial function \( f : \Pi a, p a \to \beta \), and a list \( l \) of elements of type \( \alpha \) such that all elements of \( l \) satisfy \( p \), the partial map `pmap f l H` is the empty list if and only if \( l \) is the empty list. Here, \( H \) is a proof that all elements of \( l \) satisfy \( p \).","theorem List.pmap_eq_nil {p : α → Prop} {f : ∀ a, p a → β} {l H} : pmap f l H = [] ↔ l = [] := by
  rw [← length_eq_zero, length_pmap, length_eq_zero]","To prove the theorem, we start by using the equivalence that a list is empty if and only if its length is zero. Specifically, we have:
\[
\text{pmap } f \, l \, H = [] \leftrightarrow (\text{pmap } f \, l \, H). \text{length} = 0
\]
Next, we use the fact that the length of the partial map of \( l \) is equal to the length of \( l \):
\[
(\text{pmap } f \, l \, H). \text{length} = l. \text{length}
\]
Thus, the goal reduces to:
\[
l. \text{length} = 0 \leftrightarrow l = []
\]
Finally, we use the equivalence again to show that the length of \( l \) is zero if and only if \( l \) is the empty list:
\[
l. \text{length} = 0 \leftrightarrow l = []
\]
Therefore, the original goal is equivalent to:
\[
\text{pmap } f \, l \, H = [] \leftrightarrow l = []
\]
This completes the proof. \(\blacksquare\)","theorem List.pmap_eq_nil {p : α → Prop} {f : ∀ a, p a → β} {l H} : pmap f l H = [] ↔ l = [] := by
/- First, we use the equivalence that a list is empty if and only if its length is zero. We rewrite the goal to show that the length of the partial map of \( l \) is zero if and only if the length of \( l \) is zero. Then, we use the fact that the length of the partial map of \( l \) is equal to the length of \( l \). Finally, we use the equivalence again to show that the length of \( l \) is zero if and only if \( l \) is the empty list. Therefore, the goal reduces to showing that \( l \) is the empty list if and only if \( l \) is the empty list, which is trivially true. -/
  rw [← length_eq_zero, length_pmap, length_eq_zero]","import Init.Data.List.Count
import Init.Data.Subtype
import Init.Data.List.Attach

open List

"
22011,List.pmap_eq_map_attach,"theorem List.pmap_eq_map_attach {p : α → Prop} (f : ∀ a, p a → β) (l H) :
    pmap f l H = l.attach.map fun x => f x.1 (H _ x.2) := by sorry","Partial Map Equals Map of Attached List: \(\text{pmap } f \, l \, H = \text{map } (fun \, x \, \Rightarrow \, f \, x.val) \, l.attach\) : For any type \( \alpha \) and a property \( p : \alpha \to \text{Prop} \), if \( f : \Pi a, p a \to \beta \) is a function that maps elements of \( \alpha \) satisfying \( p \) to elements of \( \beta \), and \( l \) is a list of elements of \( \alpha \) such that all elements in \( l \) satisfy \( p \) (i.e., \( H : \forall a \in l, p a \)), then the partial map of \( f \) over \( l \) using \( H \) is equal to the map of \( f \) over the attached list \( l.attach \). Formally, this can be written as:
\[
\text{pmap } f \, l \, H = \text{map } (fun \, x \, \Rightarrow \, f \, x.val) \, l.attach
\]","theorem List.pmap_eq_map_attach {p : α → Prop} (f : ∀ a, p a → β) (l H) :
    pmap f l H = l.attach.map fun x => f x.1 (H _ x.2) := by
  rw [attach, attachWith, map_pmap]; exact pmap_congr l fun _ _ _ _ => rfl","To prove the theorem, we start by using the definitions of `attach`, `attachWith`, and `map_pmap` to rewrite the goal. The `attach` function converts a list \( l \) into a list of pairs where each pair consists of an element of \( l \) and its index. The `attachWith` function is a variant of `attach` that uses a custom function to create the pairs. The `map_pmap` theorem states that the map of a function over a list of pairs is equivalent to the partial map of the function over the list.

By applying these definitions, the goal simplifies to showing that the partial map of \( f \) over \( l \) using \( H \) is equal to the map of \( f \) over the attached list \( l.attach \). This is equivalent to showing that for every element \( x \) in the list \( l \), the function \( f \) applied to \( x \) and its proof of property \( p \) is equal to the function \( f \) applied to the attached element \( x.val \).

This equality is trivially true by the reflexivity of equality, as the function \( f \) applied to \( x \) and its proof of property \( p \) is the same as the function \( f \) applied to \( x.val \). Therefore, by the congruence theorem for partial maps, `pmap_congr`, we conclude that:
\[
\text{pmap } f \, l \, H = \text{map } (fun \, x \, \Rightarrow \, f \, x.val) \, l.attach
\]
This completes the proof.","theorem List.pmap_eq_map_attach {p : α → Prop} (f : ∀ a, p a → β) (l H) :
    pmap f l H = l.attach.map fun x => f x.1 (H _ x.2) := by
/- First, we use the definitions of `attach`, `attachWith`, and `map_pmap` to rewrite the goal. This simplifies the goal to a form where we can apply the congruence theorem for partial maps, `pmap_congr`. Specifically, we need to show that for every element in the list, the function applied to the element and its proof of property is equal to the function applied to the attached element. This is trivially true by reflexivity. -/
  rw [attach, attachWith, map_pmap]; exact pmap_congr l fun _ _ _ _ => rfl","import Init.Data.List.Count
import Init.Data.Subtype
import Init.Data.List.Attach

open List

"
22018,List.length_pmap,"theorem List.length_pmap {p : α → Prop} {f : ∀ a, p a → β} {l H} : length (pmap f l H) = length l := by sorry","Length of Partial Map of List Equals Original List Length: \((\text{pmap } f \, l \, H). \text{length} = l. \text{length}\) : For any list \( l \) of elements of type \( \alpha \) and a predicate \( P : \alpha \to \text{Prop} \), if \( f : \Pi a, P a \to \beta \) is a partial function that can be applied to elements of \( l \) that satisfy \( P \), then the length of the list obtained by applying \( f \) to each element of \( l \) that satisfies \( P \) is equal to the length of \( l \). In other words, if \( l \) is a list and \( H \) is a proof that all elements of \( l \) satisfy \( P \), then the length of \( \text{pmap } f \, l \, H \) is the same as the length of \( l \).","theorem List.length_pmap {p : α → Prop} {f : ∀ a, p a → β} {l H} : length (pmap f l H) = length l := by
  induction l
  · rfl
  · simp only [*, pmap, length]","We perform induction on the list \( l \).

1. **Base Case:**
- If \( l \) is the empty list, we need to show that \((\text{pmap } f \, [] \, H). \text{length} = []. \text{length}\).
- By the definition of `pmap`, \(\text{pmap } f \, [] \, H\) is the empty list.
- Therefore, \((\text{pmap } f \, [] \, H). \text{length} = 0\) and \([]. \text{length} = 0\).
- Hence, the base case is trivially true.

2. **Inductive Step:**
- Assume \( l \) is a non-empty list of the form \( a :: l' \).
- We need to show that \((\text{pmap } f \, (a :: l') \, H). \text{length} = (a :: l'). \text{length}\).
- By the definition of `pmap`, \(\text{pmap } f \, (a :: l') \, H\) is the list \( f(a, H(a)) :: \text{pmap } f \, l' \, H' \), where \( H' \) is the proof that all elements of \( l' \) satisfy \( P \).
- By the definition of `length`, the length of \( f(a, H(a)) :: \text{pmap } f \, l' \, H' \) is \(1 + (\text{pmap } f \, l' \, H'). \text{length}\).
- By the inductive hypothesis, \((\text{pmap } f \, l' \, H'). \text{length} = l'. \text{length}\).
- Therefore, \(1 + (\text{pmap } f \, l' \, H'). \text{length} = 1 + l'. \text{length}\).
- Since \((a :: l'). \text{length} = 1 + l'. \text{length}\), the inductive step is proved.

By induction, the theorem holds for all lists \( l \). This completes the proof.","theorem List.length_pmap {p : α → Prop} {f : ∀ a, p a → β} {l H} : length (pmap f l H) = length l := by
/- We perform induction on the list \( l \). This breaks down the proof into two cases: the base case where \( l \) is the empty list, and the inductive step where \( l \) is a non-empty list of the form \( a :: l' \). -/
  induction l
/- For the base case, where \( l \) is the empty list, the goal is to show that \((\text{pmap } f \, [] \, H). \text{length} = []. \text{length}\). This is trivially true because both sides of the equation are \(0\). -/
  · rfl
/- For the inductive step, where \( l \) is a non-empty list of the form \( a :: l' \), we need to show that \((\text{pmap } f \, (a :: l') \, H). \text{length} = (a :: l'). \text{length}\). Using the definitions of `pmap` and `length`, we can simplify the left-hand side to \(1 + (\text{pmap } f \, l' \, H'). \text{length}\), where \(H'\) is the proof that all elements of \(l'\) satisfy the predicate \(P\). By the inductive hypothesis, \((\text{pmap } f \, l' \, H'). \text{length} = l'. \text{length}\). Therefore, the left-hand side simplifies to \(1 + l'. \text{length}\), which is equal to \((a :: l'). \text{length}\). This completes the inductive step. -/
  · simp only [*, pmap, length]","import Init.Data.List.Count
import Init.Data.Subtype
import Init.Data.List.Attach

open List

"
22019,List.map_pmap,"theorem List.map_pmap {p : α → Prop} (g : β → γ) (f : ∀ a, p a → β) (l H) :
    map g (pmap f l H) = pmap (fun a h => g (f a h)) l H := by sorry","Mapping a Function over a Partially Mapped List: \(\text{map } g \, (\text{pmap } f \, l \, H) = \text{pmap } (\lambda a h, g (f a h)) \, l \, H\) : For any types \( \alpha \), \( \beta \), and \( \gamma \), and a predicate \( p : \alpha \to \text{Prop} \), if \( g : \beta \to \gamma \) is a function and \( f : \Pi a, p a \to \beta \) is a partial function defined on elements of \( \alpha \) that satisfy \( p \), and \( l \) is a list of elements of type \( \alpha \) such that all elements of \( l \) satisfy \( p \) (i.e., \( H : \forall a \in l, p a \)), then the result of applying \( g \) to the list obtained by applying \( f \) to each element of \( l \) that satisfies \( p \) is the same as applying the partial function \( \lambda a h, g (f a h) \) to each element of \( l \) that satisfies \( p \). Formally, this is expressed as:
\[
\text{map } g \, (\text{pmap } f \, l \, H) = \text{pmap } (\lambda a h, g (f a h)) \, l \, H
\]","theorem List.map_pmap {p : α → Prop} (g : β → γ) (f : ∀ a, p a → β) (l H) :
    map g (pmap f l H) = pmap (fun a h => g (f a h)) l H := by
  induction l
  · rfl
  · simp only [*, pmap, map]","We perform induction on the list \( l \).

1. **Base Case:**
- If \( l \) is the empty list, then both sides of the equation \( \text{map } g \, (\text{pmap } f \, [] \, H) = \text{pmap } (\lambda a h, g (f a h)) \, [] \, H \) are the empty list. This is trivially true by the definitions of `pmap` and `map` on the empty list.

2. **Inductive Step:**
- Assume the inductive hypothesis that the equality holds for the tail of the list \( \text{tail} \). We need to show that the equality holds for the list \( \text{head} :: \text{tail} \).
- By the definitions of `pmap` and `map`, the left-hand side of the equation becomes:
\[
\text{map } g \, (\text{pmap } f \, (\text{head} :: \text{tail}) \, H) = g (f \, \text{head} \, H(\text{head})) :: \text{map } g \, (\text{pmap } f \, \text{tail} \, H)
\]
- The right-hand side of the equation becomes:
\[
\text{pmap } (\lambda a h, g (f a h)) \, (\text{head} :: \text{tail}) \, H = g (f \, \text{head} \, H(\text{head})) :: \text{pmap } (\lambda a h, g (f a h)) \, \text{tail} \, H
\]
- By the inductive hypothesis, we have:
\[
\text{map } g \, (\text{pmap } f \, \text{tail} \, H) = \text{pmap } (\lambda a h, g (f a h)) \, \text{tail} \, H
\]
- Therefore, the left-hand side and the right-hand side are equal, completing the inductive step.

By induction, the theorem holds for all lists \( l \). This completes the proof.","theorem List.map_pmap {p : α → Prop} (g : β → γ) (f : ∀ a, p a → β) (l H) :
    map g (pmap f l H) = pmap (fun a h => g (f a h)) l H := by
/- We perform induction on the list \( l \). This breaks down the proof into two cases: the base case where \( l \) is the empty list, and the inductive step where \( l \) is a non-empty list of the form \( \text{head} :: \text{tail} \). -/
  induction l
/- For the base case where \( l \) is the empty list, the equality \( \text{map } g \, (\text{pmap } f \, [] \, H) = \text{pmap } (\lambda a h, g (f a h)) \, [] \, H \) holds trivially because both sides are the empty list. This is due to the definition of `pmap` and `map` on the empty list. -/
  · rfl
/- For the inductive step, we assume the inductive hypothesis that the equality holds for the tail of the list \( \text{tail} \). We need to show that the equality holds for the list \( \text{head} :: \text{tail} \). Using the definitions of `pmap` and `map`, we can simplify the left-hand side and the right-hand side of the equation. The left-hand side becomes \( g (f \, \text{head} \, H(\text{head})) :: \text{map } g \, (\text{pmap } f \, \text{tail} \, H) \), and the right-hand side becomes \( g (f \, \text{head} \, H(\text{head})) :: \text{pmap } (\lambda a h, g (f a h)) \, \text{tail} \, H \). By the inductive hypothesis, these two expressions are equal, thus completing the proof. -/
  · simp only [*, pmap, map]","import Init.Data.List.Count
import Init.Data.Subtype
import Init.Data.List.Attach

open List

"
22020,List.pmap_eq_map,"theorem List.pmap_eq_map (p : α → Prop) (f : α → β) (l : List α) (H) :
    @pmap _ _ p (fun a _ => f a) l H = map f l := by sorry","Partial Map Equals Map for Elements Satisfying Predicate: \(\text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, l \, H = \text{map} \, f \, l\) : For any types \( \alpha \) and \( \beta \), a predicate \( p : \alpha \to \text{Prop} \), a function \( f : \alpha \to \beta \), a list \( l \) of elements of type \( \alpha \), and a proof \( H \) that all elements of \( l \) satisfy \( p \), the partial map `pmap` applied to \( f \) and \( l \) using \( H \) is equal to the map `map` applied to \( f \) and \( l \). Formally, if \( l = [a_1, a_2, \ldots, a_n] \) and \( H \) is a proof that \( p(a_i) \) holds for each \( a_i \in l \), then \( \text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, l \, H = \text{map} \, f \, l \).","theorem List.pmap_eq_map (p : α → Prop) (f : α → β) (l : List α) (H) :
    @pmap _ _ p (fun a _ => f a) l H = map f l := by
  induction l
  · rfl
  · simp only [*, pmap, map]","We perform induction on the list \( l \) to prove the theorem.

1. **Base Case:**
- If \( l \) is the empty list, then both \( \text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, [] \, H \) and \( \text{map} \, f \, [] \) are the empty list. Therefore, the equality \( \text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, [] \, H = \text{map} \, f \, [] \) holds trivially.

2. **Inductive Step:**
- Suppose \( l = a :: l' \), where \( a \) is the head of the list and \( l' \) is the tail. By the inductive hypothesis, we have \( \text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, l' \, H' = \text{map} \, f \, l' \) for some proof \( H' \) that all elements of \( l' \) satisfy \( p \).
- Using the definitions of `pmap` and `map`, we have:
\[
\text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, (a :: l') \, H = f(a) :: \text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, l' \, H'
\]
and
\[
\text{map} \, f \, (a :: l') = f(a) :: \text{map} \, f \, l'.
\]
- By the inductive hypothesis, \( \text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, l' \, H' = \text{map} \, f \, l' \). Therefore, we have:
\[
f(a) :: \text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, l' \, H' = f(a) :: \text{map} \, f \, l'.
\]
- This shows that \( \text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, (a :: l') \, H = \text{map} \, f \, (a :: l') \).

By induction, the theorem holds for all lists \( l \). This completes the proof.","theorem List.pmap_eq_map (p : α → Prop) (f : α → β) (l : List α) (H) :
    @pmap _ _ p (fun a _ => f a) l H = map f l := by
/- We perform induction on the list \( l \) to break down the proof into two cases: the base case where \( l \) is the empty list, and the inductive step where \( l \) is a non-empty list. -/
  induction l
/- For the base case, where \( l \) is the empty list, the equality \( \text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, [] \, H = \text{map} \, f \, [] \) holds trivially because both sides are the empty list. -/
  · rfl
/- For the inductive step, where \( l = a :: l' \) (i.e., \( l \) is a non-empty list with head \( a \) and tail \( l' \)), we use the definitions of `pmap` and `map` to simplify the goal. By the inductive hypothesis, we know that \( \text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, l' \, H' = \text{map} \, f \, l' \) for some proof \( H' \) that all elements of \( l' \) satisfy \( p \). Using this, we can show that \( \text{pmap} (fun \, a \, x \, \Rightarrow \, f \, a) \, (a :: l') \, H = \text{map} \, f \, (a :: l') \). -/
  · simp only [*, pmap, map]","import Init.Data.List.Count
import Init.Data.Subtype
import Init.Data.List.Attach

open List

"
22029,List.getLast_pmap,"theorem List.getLast_pmap (p : α → Prop) (f : ∀ a, p a → β) (l : List α)
    (hl₁ : ∀ a ∈ l, p a) (hl₂ : l ≠ []) :
    (l.pmap f hl₁).getLast (mt List.pmap_eq_nil.1 hl₂) =
      f (l.getLast hl₂) (hl₁ _ (List.getLast_mem hl₂)) := by sorry","Last Element of Partial Map is the Image of the Last Element: \((\text{pmap } f \, l \, hl_1).\text{getLast} = f (l.\text{getLast} \, hl_2)\) : For any types \( \alpha \) and \( \beta \), a predicate \( p : \alpha \to \text{Prop} \), a partial function \( f : \Pi a, p a \to \beta \), a non-empty list \( l \) of elements of type \( \alpha \) such that all elements of \( l \) satisfy \( p \), and proofs \( hl_1 \) and \( hl_2 \) that all elements of \( l \) satisfy \( p \) and that \( l \) is non-empty, respectively, the last element of the partial map of \( l \) under \( f \) and \( hl_1 \) is equal to the application of \( f \) to the last element of \( l \) and the proof \( hl_2 \). In other words, if \( l \neq [] \) and \( \forall a \in l, p a \), then \((\text{pmap } f \, l \, hl_1).\text{getLast} \, \cdots = f (l.\text{getLast} \, hl_2) \, \cdots\).","theorem List.getLast_pmap (p : α → Prop) (f : ∀ a, p a → β) (l : List α)
    (hl₁ : ∀ a ∈ l, p a) (hl₂ : l ≠ []) :
    (l.pmap f hl₁).getLast (mt List.pmap_eq_nil.1 hl₂) =
      f (l.getLast hl₂) (hl₁ _ (List.getLast_mem hl₂)) := by
  induction l with
  | nil => apply (hl₂ rfl).elim
  | cons l_hd l_tl l_ih =>
    by_cases hl_tl : l_tl = []
    · simp [hl_tl]
    · simp only [pmap]
      rw [getLast_cons, l_ih _ hl_tl]
      simp only [getLast_cons hl_tl]","We need to show that the last element of the partial map of a list \( l \) under a partial function \( f \) and a proof \( hl_1 \) is equal to the application of \( f \) to the last element of \( l \) and a proof \( hl_2 \).

1. **Base Case:**
- Consider the case where the list \( l \) is empty.
- Since \( l \) is non-empty by assumption, this case is impossible.
- Therefore, we can use the principle of explosion to conclude the goal trivially.

2. **Inductive Step:**
- Consider the case where the list \( l \) is non-empty and can be written as the head element \( l_{\text{hd}} \) followed by the tail \( l_{\text{tl}} \).
- We split the proof into two cases:
- **Case 1: The tail \( l_{\text{tl}} \) is empty.**
- Using the property that the last element of a list with a prepended element is the same as the last element of the original list, we simplify our goal to show that the last element of the partial map of the list is the application of the function to the head element of the list.
- Since the tail is empty, the list is just the head element, and the goal is trivially satisfied.
- **Case 2: The tail \( l_{\text{tl}} \) is non-empty.**
- Using the definition of the partial map, we simplify the goal to show that the last element of the partial map of the tail is the application of the function to the last element of the tail.
- We use the property that the last element of a list with a prepended element is the same as the last element of the original list, and the induction hypothesis to simplify the goal.
- This reduces our goal to showing that the last element of the partial map of the tail is the application of the function to the last element of the tail, which is exactly what the induction hypothesis states.
- Finally, we use the property that the last element of a list with a prepended element is the same as the last element of the original list to simplify the goal and complete the proof.

Thus, we have shown that the last element of the partial map of \( l \) under \( f \) and \( hl_1 \) is equal to the application of \( f \) to the last element of \( l \) and the proof \( hl_2 \). This completes the proof. \(\blacksquare\)","theorem List.getLast_pmap (p : α → Prop) (f : ∀ a, p a → β) (l : List α)
    (hl₁ : ∀ a ∈ l, p a) (hl₂ : l ≠ []) :
    (l.pmap f hl₁).getLast (mt List.pmap_eq_nil.1 hl₂) =
      f (l.getLast hl₂) (hl₁ _ (List.getLast_mem hl₂)) := by
  induction l with
/- Consider the case where the list is empty. Since the list is non-empty by assumption, this case is impossible. Therefore, we can use the principle of explosion to conclude the goal trivially. -/
  | nil => apply (hl₂ rfl).elim
/- Consider the case where the list is non-empty and can be written as the head element `l_hd` followed by the tail `l_tl`. We will proceed with this case. -/
  | cons l_hd l_tl l_ih =>
/- We split the proof into two cases: (1) the tail of the list is empty, and (2) the tail of the list is non-empty. -/
    by_cases hl_tl : l_tl = []
/- In the case where the tail of the list is empty, we use the property that the last element of a list with a prepended element is the same as the last element of the original list. This simplifies our goal to show that the last element of the partial map of the list is the application of the function to the head element of the list. Since the tail is empty, the list is just the head element, and the goal is trivially satisfied. -/
    · simp [hl_tl]
/- In the case where the tail of the list is non-empty, we use the definition of the partial map to simplify the goal. The partial map of a list with a head element and a non-empty tail is the head element followed by the partial map of the tail. This simplifies our goal to show that the last element of the partial map of the tail is the application of the function to the last element of the tail. -/
    · simp only [pmap]
/- We use the property that the last element of a list with a prepended element is the same as the last element of the original list, and the induction hypothesis to simplify the goal. This reduces our goal to showing that the last element of the partial map of the tail is the application of the function to the last element of the tail, which is exactly what the induction hypothesis states. -/
      rw [getLast_cons, l_ih _ hl_tl]
/- First, we use the property that the last element of a list with a prepended element is the same as the last element of the original list. This simplifies our goal to show that the last element of the partial map of the tail of the list is equal to the application of the function to the last element of the tail of the list. -/
/- Finally, we use the property that the last element of a list with a prepended element is the same as the last element of the original list to simplify the goal. This completes the proof. -/
      simp only [getLast_cons hl_tl]","import Init.Data.List.Count
import Init.Data.Subtype
import Init.Data.List.Attach

open List

"
22456,Bool.atLeastTwo_false_left,theorem Bool.atLeastTwo_false_left : atLeastTwo false b c = (b && c) := by sorry,"At Least Two of Three Booleans with Left False is Equivalent to AND of the Other Two: \( b \land c \) : For any boolean values \( b \) and \( c \), the function `atLeastTwo` returns `true` if at least two out of the three boolean values `false`, \( b \), and \( c \) are `true`. This is equivalent to the boolean value \( b \) and \( c \) being `true`, i.e., \( b \land c \).","theorem Bool.atLeastTwo_false_left : atLeastTwo false b c = (b && c) := by
  simp [atLeastTwo]","To prove that `false.atLeastTwo b c = (b && c)`, we use the definition of the `atLeastTwo` function. The function `atLeastTwo` checks if at least two out of the three boolean values are `true`. Given that the first value is `false`, the function simplifies to the boolean ""and"" operation between `b` and `c`. This is because for `atLeastTwo` to return `true`, both `b` and `c` must be `true`. Therefore, `false.atLeastTwo b c` is equivalent to `b && c`. Hence, the proposition `false.atLeastTwo b c = (b && c)` holds. This completes the proof.","theorem Bool.atLeastTwo_false_left : atLeastTwo false b c = (b && c) := by
  simp [atLeastTwo]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open Bool
open Nat Bool
"
22458,Bool.atLeastTwo_false_right,theorem Bool.atLeastTwo_false_right : atLeastTwo a b false = (a && b) := by sorry,"At Least Two with Right False Argument is Equivalent to Boolean And: \( \text{atLeastTwo}(a, b, \text{false}) = a \land b \) : For any boolean values \( a \) and \( b \), the function `atLeastTwo` returns `true` if at least two out of the three boolean values \( a, b, \text{false} \) are `true`. This is equivalent to the boolean value \( a \) and \( b \) being `true`, i.e., \( a \land b \).","theorem Bool.atLeastTwo_false_right : atLeastTwo a b false = (a && b) := by
  simp [atLeastTwo]","To prove that \( a.\text{atLeastTwo}(b, \text{false}) = (a \land b) \), we use the definition of the `atLeastTwo` function. The function `atLeastTwo` checks if at least two out of the three boolean values \( a, b, \text{false} \) are `true`. Since one of the values is `false`, the condition simplifies to checking if both \( a \) and \( b \) are `true`. This is exactly the boolean ""and"" operation \( a \land b \). Therefore, the proposition \( a.\text{atLeastTwo}(b, \text{false}) = (a \land b) \) is trivially true. This completes the proof.","theorem Bool.atLeastTwo_false_right : atLeastTwo a b false = (a && b) := by
  simp [atLeastTwo]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open Bool
open Nat Bool
"
22463,Bool.atLeastTwo_false_mid,theorem Bool.atLeastTwo_false_mid : atLeastTwo a false c = (a && c) := by sorry,"At Least Two of Three Booleans with Middle False is Equivalent to AND of the Other Two: \( a \text{ and } c \) : For any boolean values \( a \) and \( c \), the function `atLeastTwo` returns `true` if at least two out of the three boolean values \( a, \text{false}, c \) are `true`. This is equivalent to the boolean value \( a \) and \( c \) being `true`, i.e., \( a \text{ and } c \).","theorem Bool.atLeastTwo_false_mid : atLeastTwo a false c = (a && c) := by
  simp [atLeastTwo]","To prove that \( a.\text{atLeastTwo} \, \text{false} \, c = (a \land c) \), we use the definition of the `atLeastTwo` function. The function `atLeastTwo` checks if at least two out of the three boolean values are `true`. Given that the middle value is `false`, the function simplifies as follows:

1. The function `atLeastTwo` for the values \( a, \text{false}, c \) can be broken down into the following cases:
- If \( a \) is `false`, then the function returns `false` because there is only one `true` value (if \( c \) is `true`).
- If \( a \) is `true`, then the function returns the value of \( c \) because \( a \) and \( c \) are the two values being checked.

2. Therefore, \( a.\text{atLeastTwo} \, \text{false} \, c \) simplifies to \( a \land c \).

Thus, we have shown that \( a.\text{atLeastTwo} \, \text{false} \, c = (a \land c) \). This completes the proof.","theorem Bool.atLeastTwo_false_mid : atLeastTwo a false c = (a && c) := by
  simp [atLeastTwo]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open Bool
open Nat Bool
"
22467,BitVec.carry_width,"theorem BitVec.carry_width {x y : BitVec w} :
    carry w x y c = decide (x.toNat + y.toNat + c.toNat ≥ 2^w) := by sorry","Carry Bit at Width \( w \) is True if and Only if Sum of Natural Representations is at Least \( 2^w \) : For any natural number \( w \), boolean value \( c \), and bitvectors \( x \) and \( y \) of width \( w \), the carry bit at position \( w \) when computing the sum of \( x \) and \( y \) with an initial carry bit \( c \) is `true` if and only if the sum of the natural number representations of \( x \), \( y \), and \( c \) is at least \( 2^w \). Formally, this is expressed as:
\[
\text{carry}(w, x, y, c) = \text{true} \iff x_{\text{nat}} + y_{\text{nat}} + c_{\text{nat}} \ge 2^w
\]
where \( x_{\text{nat}} \), \( y_{\text{nat}} \), and \( c_{\text{nat}} \) are the natural number representations of \( x \), \( y \), and \( c \), respectively.","theorem BitVec.carry_width {x y : BitVec w} :
    carry w x y c = decide (x.toNat + y.toNat + c.toNat ≥ 2^w) := by
  simp [carry]","To prove the theorem, we start by using the definition of the carry bit. The carry bit at position \( w \) when computing the sum of \( x \) and \( y \) with an initial carry bit \( c \) is defined as:
\[
\text{carry}(w, x, y, c) = \text{decide}(x_{\text{nat}} + y_{\text{nat}} + c_{\text{nat}} \ge 2^w)
\]
Here, \(\text{decide}(P)\) is a function that returns `true` if the proposition \( P \) is true and `false` otherwise. Therefore, the carry bit is `true` if and only if the sum of the natural number representations of \( x \), \( y \), and \( c \) is at least \( 2^w \). This completes the proof.","theorem BitVec.carry_width {x y : BitVec w} :
    carry w x y c = decide (x.toNat + y.toNat + c.toNat ≥ 2^w) := by
/- Using the definition of the carry bit, we can simplify the proposition we want to show to the statement that the carry bit at position \( w \) when computing the sum of \( x \) and \( y \) with an initial carry bit \( c \) is `true` if and only if the sum of the natural number representations of \( x \), \( y \), and \( c \) is at least \( 2^w \). Formally, this is:
\[
\text{carry}(w, x, y, c) = \text{true} \iff x_{\text{nat}} + y_{\text{nat}} + c_{\text{nat}} \ge 2^w
\] -/
  simp [carry]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22469,BitVec.add_eq_adc,theorem BitVec.add_eq_adc (w : Nat) (x y : BitVec w) : x + y = (adc x y false).snd := by sorry,"Bitvector Addition Equals Second Component of Bitwise Addition with False Carry: \( x + y = \text{snd}(\text{adc}(x, y, \text{false})) \) : For any natural number \( w \) and any bitvectors \( x \) and \( y \) of width \( w \), the sum of \( x \) and \( y \) is equal to the second component of the result of the bitwise addition with carry operation `adc` applied to \( x \), \( y \), and the boolean value `false`. In other words, \( x + y = \text{snd}(\text{adc}(x, y, \text{false})) \).","theorem BitVec.add_eq_adc (w : Nat) (x y : BitVec w) : x + y = (adc x y false).snd := by
  simp [adc_spec]","To prove the theorem, we use the specification of the bitwise addition with carry operation \( \text{adc} \). According to the specification, for any natural number \( w \) and any bitvectors \( x \) and \( y \) of width \( w \), and for the boolean value `false`, the result of the bitwise addition with carry operation \( \text{adc}(x, y, \text{false}) \) is a pair consisting of the carry bit and the sum of the bitvectors. Specifically, we have:
\[
\text{adc}(x, y, \text{false}) = (\text{carry}(w, x, y, \text{false}), x + y + \text{zeroExtend}(w, \text{ofBool}(\text{false})))
\]
Since the boolean value `false` is converted to the bitvector `0` of length 1, and the zero extension of `0` to any width \( w \) is still `0`, we have:
\[
\text{zeroExtend}(w, \text{ofBool}(\text{false})) = 0
\]
Thus, the second component of \( \text{adc}(x, y, \text{false}) \) is:
\[
x + y + 0 = x + y
\]
Therefore, the proposition \( x + y = \text{snd}(\text{adc}(x, y, \text{false})) \) holds. This completes the proof. \(\blacksquare\)","theorem BitVec.add_eq_adc (w : Nat) (x y : BitVec w) : x + y = (adc x y false).snd := by
/- Using the specification of the bitwise addition with carry operation, we can simplify the proposition we want to show. Specifically, the specification states that for any natural number \( w \) and any bitvectors \( x \) and \( y \) of width \( w \), and for the boolean value `false`, the result of the bitwise addition with carry operation \( \text{adc}(x, y, \text{false}) \) is a pair consisting of the carry bit and the sum of the bitvectors. Since the boolean value `false` is converted to the bitvector `0` of length 1, and the zero extension of `0` to any width \( w \) is still `0`, the second component of \( \text{adc}(x, y, \text{false}) \) is \( x + y + 0 \), which simplifies to \( x + y \). Therefore, the proposition \( x + y = \text{snd}(\text{adc}(x, y, \text{false})) \) holds. -/
  simp [adc_spec]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22476,BitVec.ule_eq_not_ult,theorem BitVec.ule_eq_not_ult (x y : BitVec w) : x.ule y = !y.ult x := by sorry,"Unsigned Less-Than-or-Equal is Equivalent to Not Unsigned Less-Than for Bit Vectors : For any natural number \( w \) and any bit vectors \( x \) and \( y \) of length \( w \), the unsigned less-than-or-equal relation \( x \le y \) holds if and only if the unsigned less-than relation \( y < x \) does not hold. In other words, \( x \le y \) if and only if \( \neg (y < x) \).","theorem BitVec.ule_eq_not_ult (x y : BitVec w) : x.ule y = !y.ult x := by
  simp [BitVec.ule, BitVec.ult, ← decide_not]","To prove the theorem, we start by using the definitions of the unsigned less-than-or-equal relation \( x \le y \) and the unsigned less-than relation \( y < x \). We also use the property that the boolean value of the negation of a proposition is the negation of the boolean value of the proposition. Specifically, we have:

1. The unsigned less-than-or-equal relation \( x \le y \) is defined as a certain boolean expression.
2. The unsigned less-than relation \( y < x \) is defined as another boolean expression.
3. The property that the boolean value of the negation of a proposition is the negation of the boolean value of the proposition, i.e., \(\text{decide}(\neg p) = \text{not}(\text{decide} p)\).

Using these definitions and properties, we can simplify the goal to show that \( x \le y \) is equivalent to \( \neg (y < x) \). This simplification directly follows from the definitions and the property of negation. Therefore, we conclude that \( x \le y \) if and only if \( \neg (y < x) \). This completes the proof.","theorem BitVec.ule_eq_not_ult (x y : BitVec w) : x.ule y = !y.ult x := by
/- Using the definitions of the unsigned less-than-or-equal relation \( x \le y \) and the unsigned less-than relation \( y < x \), along with the property that the boolean value of the negation of a proposition is the negation of the boolean value of the proposition, we can simplify the goal to show that \( x \le y \) is equivalent to \( \neg (y < x) \). -/
  simp [BitVec.ule, BitVec.ult, ← decide_not]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22480,BitVec.sle_eq_not_slt,theorem BitVec.sle_eq_not_slt (x y : BitVec w) : x.sle y = !y.slt x := by sorry,"Signed Less Than or Equal To is Negation of Signed Less Than for Bit Vectors: \( x \leq y \leftrightarrow \neg (y < x) \) : For any natural number \( w \) and bit vectors \( x \) and \( y \) of length \( w \), the signed less than or equal to relation \( x \leq y \) is equivalent to the negation of the signed less than relation \( y < x \), i.e., \( x \leq y \) if and only if \( \neg (y < x) \).","theorem BitVec.sle_eq_not_slt (x y : BitVec w) : x.sle y = !y.slt x := by
  simp only [BitVec.sle, BitVec.slt, ← decide_not, decide_eq_decide]; omega","To prove the theorem, we start by simplifying the goal using the definitions of the signed less than or equal to (`sle`) and signed less than (`slt`) relations for bit vectors. Specifically, we use the following equivalences:
1. The negation of a decision is equivalent to the decision of the negation.
2. The equality of decisions is equivalent to the decision of equality.

After applying these simplifications, the goal reduces to a straightforward arithmetic statement. We then use the `omega` tactic to automatically discharge this arithmetic goal, which completes the proof.

Thus, we have shown that for any natural number \( w \) and bit vectors \( x \) and \( y \) of length \( w \), the signed less than or equal to relation \( x \leq y \) is indeed equivalent to the negation of the signed less than relation \( y < x \). This completes the proof. \(\blacksquare\)","theorem BitVec.sle_eq_not_slt (x y : BitVec w) : x.sle y = !y.slt x := by
/- We start by simplifying the goal using the definitions of the signed less than or equal to (`sle`) and signed less than (`slt`) relations for bit vectors. Specifically, we use the fact that the negation of a decision is equivalent to the decision of the negation, and that the equality of decisions is equivalent to the decision of equality. After simplifying, we use the `omega` tactic to automatically discharge the resulting goal, which is a straightforward arithmetic statement. -/
  simp only [BitVec.sle, BitVec.slt, ← decide_not, decide_eq_decide]; omega","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22481,BitVec.allOnes_sub_eq_not,theorem BitVec.allOnes_sub_eq_not (x : BitVec w) : allOnes w - x = ~~~x := by sorry,"Subtraction of Bitvector from All Ones Yields Complement: \( \text{allOnes}(w) - x = \sim x \) : For any natural number \( w \) and any bitvector \( x \) of width \( w \), subtracting \( x \) from the bitvector of all ones (i.e., \( \text{allOnes}(w) \)) is equivalent to taking the complement of \( x \), i.e., \( \text{allOnes}(w) - x = \sim x \).","theorem BitVec.allOnes_sub_eq_not (x : BitVec w) : allOnes w - x = ~~~x := by
  rw [← add_not_self x, BitVec.add_comm, add_sub_cancel]","To prove that \( \text{allOnes}(w) - x = \sim x \), we start by using the fact that the sum of a bitvector \( x \) and its complement \( \sim x \) is the all ones bitvector, i.e., \( x + \sim x = \text{allOnes}(w) \). This allows us to rewrite the goal as:
\[
\text{allOnes}(w) - x = \sim x \implies x + \sim x - x = \sim x
\]

Next, we use the commutativity of addition to rewrite the left-hand side:
\[
x + \sim x - x = \sim x + x - x
\]

Finally, we use the property that addition and subtraction cancel in an additive commutative group, i.e., \( a + (b - a) = b \), to simplify the expression:
\[
\sim x + x - x = \sim x
\]

Thus, we have shown that \( \text{allOnes}(w) - x = \sim x \). This completes the proof. \(\blacksquare\)","theorem BitVec.allOnes_sub_eq_not (x : BitVec w) : allOnes w - x = ~~~x := by
/- First, we use the fact that the sum of a bitvector \( x \) and its complement \( \sim x \) is the all ones bitvector, i.e., \( x + \sim x = \text{allOnes}(w) \). This allows us to rewrite the goal \( \text{allOnes}(w) - x = \sim x \) as \( x + \sim x - x = \sim x \). -/
/- Next, we use the commutativity of addition to rewrite \( x + \sim x - x \) as \( \sim x + x - x \). -/
/- Finally, we use the property that addition and subtraction cancel in an additive commutative group, i.e., \( a + (b - a) = b \), to simplify \( \sim x + x - x \) to \( \sim x \). This completes the proof. -/
  rw [← add_not_self x, BitVec.add_comm, add_sub_cancel]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22484,BitVec.carry_zero,theorem BitVec.carry_zero : carry 0 x y c = c := by sorry,"Carry Bit at Position Zero in Bitvector Addition : For any bitvector width \( w \), and for any bitvectors \( x \) and \( y \) of width \( w \), and any boolean carry bit \( c \), the carry bit at position \( 0 \) in the addition of \( x \) and \( y \) with initial carry \( c \) is equal to \( c \).","theorem BitVec.carry_zero : carry 0 x y c = c := by
  cases c <;> simp [carry, mod_one]","We will consider every possible case of the boolean carry bit \( c \). There are two cases: \( c = \text{false} \) and \( c = \text{true} \).

**Case 1: \( c = \text{false} \)**

Using the definition of the carry bit in bitvector addition, we need to show that \( \text{carry}(0, x, y, \text{false}) = \text{false} \). By the definition of the carry bit, this is equivalent to checking if the sum of the 0-th bits of \( x \) and \( y \), along with the initial carry bit \( \text{false} \), is at least \( 2^0 \). Since \( 2^0 = 1 \), and the sum of the 0-th bits of \( x \) and \( y \) (which are either 0 or 1) plus 0 (the initial carry bit) is less than 1, the carry bit is false. Therefore, \( \text{carry}(0, x, y, \text{false}) = \text{false} \).

**Case 2: \( c = \text{true} \)**

Using the definition of the carry bit in bitvector addition, we need to show that \( \text{carry}(0, x, y, \text{true}) = \text{true} \). By the definition of the carry bit, this is equivalent to checking if the sum of the 0-th bits of \( x \) and \( y \), along with the initial carry bit \( \text{true} \), is at least \( 2^0 \). Since \( 2^0 = 1 \), and the sum of the 0-th bits of \( x \) and \( y \) (which are either 0 or 1) plus 1 (the initial carry bit) is at least 1, the carry bit is true. Therefore, \( \text{carry}(0, x, y, \text{true}) = \text{true} \).

In both cases, the carry bit at position 0 is equal to the initial carry bit \( c \). This completes the proof.","theorem BitVec.carry_zero : carry 0 x y c = c := by
/- We will consider every possible case of the boolean carry bit \( c \). There are two cases: \( c = \text{false} \) and \( c = \text{true} \).

**Case 1: \( c = \text{false} \)**

Using the definition of the carry bit in bitvector addition, we need to show that \( \text{carry}(0, x, y, \text{false}) = \text{false} \). By the definition of the carry bit, this is equivalent to checking if the sum of the 0-th bits of \( x \) and \( y \), along with the initial carry bit \( \text{false} \), is at least \( 2^0 \). Since \( 2^0 = 1 \), and the sum of the 0-th bits of \( x \) and \( y \) (which are either 0 or 1) plus 0 (the initial carry bit) is less than 1, the carry bit is false. Therefore, \( \text{carry}(0, x, y, \text{false}) = \text{false} \).

**Case 2: \( c = \text{true} \)**

Using the definition of the carry bit in bitvector addition, we need to show that \( \text{carry}(0, x, y, \text{true}) = \text{true} \). By the definition of the carry bit, this is equivalent to checking if the sum of the 0-th bits of \( x \) and \( y \), along with the initial carry bit \( \text{true} \), is at least \( 2^0 \). Since \( 2^0 = 1 \), and the sum of the 0-th bits of \( x \) and \( y \) (which are either 0 or 1) plus 1 (the initial carry bit) is at least 1, the carry bit is true. Therefore, \( \text{carry}(0, x, y, \text{true}) = \text{true} \). -/
  cases c <;> simp [carry, mod_one]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22486,BitVec.ult_eq_not_carry,theorem BitVec.ult_eq_not_carry (x y : BitVec w) : x.ult y = !carry w x (~~~y) true := by sorry,"Unsigned Less-Than Relation for Bitvectors is Equivalent to No Carry in Complement Addition : For any natural number \( w \) and any bitvectors \( x \) and \( y \) of length \( w \), the unsigned less-than relation \( x < y \) holds if and only if the carry bit at position \( w \) is false when computing the sum of \( x \) and the complement of \( y \) with an initial carry bit of `true`. In other words, \( x < y \) if and only if \( \text{carry}(w, x, \sim y, \text{true}) = \text{false} \).","theorem BitVec.ult_eq_not_carry (x y : BitVec w) : x.ult y = !carry w x (~~~y) true := by
  simp only [BitVec.ult, carry, toNat_mod_cancel, toNat_not, toNat_true, ge_iff_le, ← decide_not,
    Nat.not_le, decide_eq_decide]
  rw [Nat.mod_eq_of_lt (by omega)]
  omega","We start by using the definitions and properties of bitvector operations to simplify the goal. Specifically, we use the definitions of the unsigned less-than relation for bitvectors, the carry bit in bitvector addition, the modulo cancellation property, the complement of a bitvector, the conversion of a bitvector to a natural number, the equivalence of greater-than-or-equal and less-than-or-equal relations, the negation of a decidable proposition, and the decidability equivalence. After simplification, the goal becomes:
\[ x.\text{toNat} < y.\text{toNat} \leftrightarrow x.\text{toNat} + (2^w - 1 - y.\text{toNat}) \mod 2^w + 1 < 2^w \]

Next, we use the modulo identity for natural numbers. Since \( 2^w - 1 - y.\text{toNat} < 2^w \) (which is true by the properties of natural numbers and the fact that \( y.\text{toNat} \) is a natural number less than \( 2^w \)), we can simplify the expression:
\[ x.\text{toNat} < y.\text{toNat} \leftrightarrow x.\text{toNat} + (2^w - 1 - y.\text{toNat}) + 1 < 2^w \]

Finally, we use the omega tactic to automatically verify the inequality. This completes the proof. \(\blacksquare\)","theorem BitVec.ult_eq_not_carry (x y : BitVec w) : x.ult y = !carry w x (~~~y) true := by
/- Using the definitions and properties of bitvector operations, we simplify the goal. Specifically, we use the definitions of the unsigned less-than relation for bitvectors, the carry bit in bitvector addition, the modulo cancellation property, the complement of a bitvector, the conversion of a bitvector to a natural number, the equivalence of greater-than-or-equal and less-than-or-equal relations, the negation of a decidable proposition, and the decidability equivalence. After simplification, the goal becomes:
\[ x.\text{toNat} < y.\text{toNat} \leftrightarrow x.\text{toNat} + (2^w - 1 - y.\text{toNat}) \mod 2^w + 1 < 2^w \] -/
  simp only [BitVec.ult, carry, toNat_mod_cancel, toNat_not, toNat_true, ge_iff_le, ← decide_not,
    Nat.not_le, decide_eq_decide]
/- Since \( 2^w - 1 - y.\text{toNat} < 2^w \) (which is true by the properties of natural numbers and the fact that \( y.\text{toNat} \) is a natural number less than \( 2^w \)), we can use the modulo identity for natural numbers to simplify the expression. This simplifies the goal to:
\[ x.\text{toNat} < y.\text{toNat} \leftrightarrow x.\text{toNat} + (2^w - 1 - y.\text{toNat}) + 1 < 2^w \] -/
  rw [Nat.mod_eq_of_lt (by omega)]
/- Finally, we use the omega tactic to automatically verify the inequality. This completes the proof. -/
  omega","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22488,BitVec.shiftLeftRec_zero,"theorem BitVec.shiftLeftRec_zero {x : BitVec w₁} {y : BitVec w₂} :
    shiftLeftRec x y 0 = x <<< (y &&& twoPow w₂ 0) := by sorry","Recursive Left Shift of Bitvectors with Zero Steps : For any natural numbers \( w_1 \) and \( w_2 \), and for any bitvectors \( x \) and \( y \) of widths \( w_1 \) and \( w_2 \) respectively, the recursive left shift operation `shiftLeftRec` applied to \( x \) and \( y \) with \( n = 0 \) is equal to the left shift of \( x \) by the value of the least significant bit of \( y \). Formally, this is expressed as:
\[ x.\text{shiftLeftRec}(y, 0) = x <<< (y \&&& \text{twoPow}(w_2, 0)) \]","theorem BitVec.shiftLeftRec_zero {x : BitVec w₁} {y : BitVec w₂} :
    shiftLeftRec x y 0 = x <<< (y &&& twoPow w₂ 0) := by
  simp [shiftLeftRec]","To prove the theorem, we start by using the definition of the `shiftLeftRec` function. The recursive left shift operation `shiftLeftRec` applied to \( x \) and \( y \) with \( n = 0 \) is defined such that it simplifies to the left shift of \( x \) by the value of the least significant bit of \( y \). Specifically, the least significant bit of \( y \) is given by \( y \&&& \text{twoPow}(w_2, 0) \).

Thus, we need to show that:
\[ x.\text{shiftLeftRec}(y, 0) = x <<< (y \&&& \text{twoPow}(w_2, 0)) \]

By the definition of `shiftLeftRec`, the left-hand side simplifies directly to the right-hand side. Therefore, the equality holds, and the theorem is proved.

\(\blacksquare\)","theorem BitVec.shiftLeftRec_zero {x : BitVec w₁} {y : BitVec w₂} :
    shiftLeftRec x y 0 = x <<< (y &&& twoPow w₂ 0) := by
/- Using the definition of the `shiftLeftRec` function, we simplify the proposition we want to show. The recursive left shift operation `shiftLeftRec` applied to \( x \) and \( y \) with \( n = 0 \) is equivalent to the left shift of \( x \) by the value of the least significant bit of \( y \). Therefore, the goal is to show that:
\[ x.\text{shiftLeftRec}(y, 0) = x <<< (y \&&& \text{twoPow}(w_2, 0)) \] -/
  simp [shiftLeftRec]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22489,BitVec.ule_eq_carry,theorem BitVec.ule_eq_carry (x y : BitVec w) : x.ule y = carry w y (~~~x) true := by sorry,"Unsigned Less-Than-or-Equal to Carry Bit Equivalence in Bitvectors : For any natural number \( w \) and any bitvectors \( x \) and \( y \) of width \( w \), the unsigned less-than-or-equal-to relation \( x \leq y \) is equivalent to the carry bit being true when computing the sum of \( y \) and the complement of \( x \) with an initial carry bit of `true`. Formally, this is expressed as:
\[ x \leq y \iff \text{carry}(w, y, \sim x, \text{true}) \]","theorem BitVec.ule_eq_carry (x y : BitVec w) : x.ule y = carry w y (~~~x) true := by
  simp [ule_eq_not_ult, ult_eq_not_carry]","To prove the theorem, we start by using the following two key equivalences:

1. The unsigned less-than-or-equal relation \( x \le y \) is equivalent to the negation of the unsigned less-than relation \( y < x \):
\[
x \le y \iff \neg (y < x)
\]

2. The unsigned less-than relation \( x < y \) is equivalent to the carry bit being false when computing the sum of \( x \) and the complement of \( y \) with an initial carry bit of `true`:
\[
x < y \iff \text{carry}(w, x, \sim y, \text{true}) = \text{false}
\]

Using these equivalences, we can rewrite the unsigned less-than-or-equal relation \( x \le y \) as:
\[
x \le y \iff \neg (y < x) \iff \neg (\text{carry}(w, y, \sim x, \text{true}) = \text{false})
\]

The negation of the carry bit being false is equivalent to the carry bit being true:
\[
\neg (\text{carry}(w, y, \sim x, \text{true}) = \text{false}) \iff \text{carry}(w, y, \sim x, \text{true}) = \text{true}
\]

Therefore, we have:
\[
x \le y \iff \text{carry}(w, y, \sim x, \text{true})
\]

This completes the proof.","theorem BitVec.ule_eq_carry (x y : BitVec w) : x.ule y = carry w y (~~~x) true := by
/- Using the fact that the unsigned less-than-or-equal relation \( x \le y \) is equivalent to the negation of the unsigned less-than relation \( y < x \), and the fact that the unsigned less-than relation \( x < y \) is equivalent to the carry bit being false when computing the sum of \( x \) and the complement of \( y \) with an initial carry bit of `true`, we can simplify the proposition we want to show. Specifically, we need to show that \( x \le y \) is equivalent to the carry bit being true when computing the sum of \( y \) and the complement of \( x \) with an initial carry bit of `true`. -/
  simp [ule_eq_not_ult, ult_eq_not_carry]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22491,BitVec.ult_eq_msb_of_msb_neq,"theorem BitVec.ult_eq_msb_of_msb_neq {x y : BitVec w} (h : x.msb ≠ y.msb) :
    x.ult y = y.msb := by sorry","Unsigned Less-Than Determined by MSB for Different MSBs: \( x <_{\text{u}} y = y.\text{msb} \) : For any bit vectors \( x \) and \( y \) of the same length \( w \), if the most significant bits (MSBs) of \( x \) and \( y \) are different, then the unsigned less-than comparison \( x <_{\text{u}} y \) is determined by the MSB of \( y \), i.e., \( x <_{\text{u}} y = y.\text{msb} \).","theorem BitVec.ult_eq_msb_of_msb_neq {x y : BitVec w} (h : x.msb ≠ y.msb) :
    x.ult y = y.msb := by
  simp only [BitVec.ult, msb_eq_decide, ne_eq, decide_eq_decide] at *
  omega","We start with the assumption that the most significant bits (MSBs) of \( x \) and \( y \) are different, i.e., \( x.\text{msb} \neq y.\text{msb} \). Using the definitions and properties of the unsigned less-than comparison for bit vectors, the most significant bit (MSB) of a bit vector, and the equivalence of not equal and negation of equality, we can simplify the goal and the hypothesis.

The hypothesis \( x.\text{msb} \neq y.\text{msb} \) is equivalent to \( \neg (2^{(w - 1)} \leq x.\text{toNat} \leftrightarrow 2^{(w - 1)} \leq y.\text{toNat}) \). This means that the conditions \( 2^{(w - 1)} \leq x.\text{toNat} \) and \( 2^{(w - 1)} \leq y.\text{toNat} \) are not equivalent.

The goal \( x <_{\text{u}} y = y.\text{msb} \) is equivalent to \( x.\text{toNat} < y.\text{toNat} \leftrightarrow 2^{(w - 1)} \leq y.\text{toNat} \).

Since the conditions \( 2^{(w - 1)} \leq x.\text{toNat} \) and \( 2^{(w - 1)} \leq y.\text{toNat} \) are not equivalent, the most significant bit (MSB) of \( y \) determines the unsigned less-than comparison when the MSBs of \( x \) and \( y \) are different. Therefore, \( x.\text{toNat} < y.\text{toNat} \) is equivalent to \( 2^{(w - 1)} \leq y.\text{toNat} \).

Thus, the goal is satisfied, and the theorem is proved. \(\blacksquare\)","theorem BitVec.ult_eq_msb_of_msb_neq {x y : BitVec w} (h : x.msb ≠ y.msb) :
    x.ult y = y.msb := by
/- Using the definitions and properties of the unsigned less-than comparison for bit vectors, the most significant bit (MSB) of a bit vector, and the equivalence of not equal and negation of equality, we can simplify the goal and the hypothesis. Specifically, the hypothesis \( x.\text{msb} \neq y.\text{msb} \) is equivalent to \( \neg (2^{(w - 1)} \leq x.\text{toNat} \leftrightarrow 2^{(w - 1)} \leq y.\text{toNat}) \), and the goal \( x <_{\text{u}} y = y.\text{msb} \) is equivalent to \( x.\text{toNat} < y.\text{toNat} \leftrightarrow 2^{(w - 1)} \leq y.\text{toNat} \). -/
  simp only [BitVec.ult, msb_eq_decide, ne_eq, decide_eq_decide] at *
/- Since the hypothesis \( \neg (2^{(w - 1)} \leq x.\text{toNat} \leftrightarrow 2^{(w - 1)} \leq y.\text{toNat}) \) states that the conditions \( 2^{(w - 1)} \leq x.\text{toNat} \) and \( 2^{(w - 1)} \leq y.\text{toNat} \) are not equivalent, we can conclude that \( x.\text{toNat} < y.\text{toNat} \) is equivalent to \( 2^{(w - 1)} \leq y.\text{toNat} \). This is because the most significant bit (MSB) of \( y \) determines the unsigned less-than comparison when the MSBs of \( x \) and \( y \) are different. Therefore, the goal is satisfied. -/
  omega","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22493,BitVec.toNat_add_of_and_eq_zero,"theorem BitVec.toNat_add_of_and_eq_zero {x y : BitVec w} (h : x &&& y = 0#w) :
    (x + y).toNat = x.toNat + y.toNat := by sorry","Bitwise AND Zero Implies Natural Number Sum of Bitvectors Equals Sum of Natural Number Representations : For any natural number \( w \) and any bitvectors \( x \) and \( y \) of width \( w \), if the bitwise AND of \( x \) and \( y \) is zero, i.e., \( x \& y = 0 \), then the natural number representation of the sum of \( x \) and \( y \) is equal to the sum of their natural number representations, i.e., \( (x + y).toNat = x.toNat + y.toNat \).","theorem BitVec.toNat_add_of_and_eq_zero {x y : BitVec w} (h : x &&& y = 0#w) :
    (x + y).toNat = x.toNat + y.toNat := by
  rw [toNat_add]
  apply Nat.mod_eq_of_lt
  suffices ¬ decide (x.toNat + y.toNat + false.toNat ≥ 2^w) by
    simp only [decide_eq_true_eq] at this
    omega
  rw [← carry_width]
  simp [not_eq_true, carry_of_and_eq_zero h]","We start by using the theorem that the natural number representation of the sum of two bitvectors \( x \) and \( y \) is equal to the sum of their natural number representations modulo \( 2^w \). This changes our goal to show that:
\[
(x.toNat + y.toNat) \mod 2^w = x.toNat + y.toNat
\]

To prove this, we use the theorem that if \( a < b \), then \( a \mod b = a \). Therefore, it suffices to show that:
\[
x.toNat + y.toNat < 2^w
\]

To prove \( x.toNat + y.toNat < 2^w \), it suffices to show that the boolean value of the decision \( x.toNat + y.toNat + false.toNat \ge 2^w \) is `false`. We simplify this using the theorem that the boolean value of a decision is `true` if and only if the proposition is true, which reduces our goal to showing that:
\[
x.toNat + y.toNat + false.toNat < 2^w
\]

We use the theorem that the carry bit at position \( w \) when adding \( x \) and \( y \) with an initial carry of `false` is `true` if and only if \( x.toNat + y.toNat + false.toNat \ge 2^w \). This changes our goal to show that the carry bit at position \( w \) is `false`.

We simplify the goal using the theorem that the carry bit at position \( w \) is `false` if the bitwise AND of \( x \) and \( y \) is zero. Since \( x \land y = 0 \) by our hypothesis, the carry bit at position \( w \) is indeed `false`. This completes the proof. \(\blacksquare\)","theorem BitVec.toNat_add_of_and_eq_zero {x y : BitVec w} (h : x &&& y = 0#w) :
    (x + y).toNat = x.toNat + y.toNat := by
/- First, we use the theorem that the natural number representation of the sum of two bitvectors \( x \) and \( y \) is equal to the sum of their natural number representations modulo \( 2^w \). This changes our goal to show that \((x.toNat + y.toNat) \mod 2^w = x.toNat + y.toNat\). -/
  rw [toNat_add]
/- To prove the current goal, we use the theorem that if \( a < b \), then \( a \mod b = a \). Therefore, it suffices to show that \( x.toNat + y.toNat < 2^w \). -/
  apply Nat.mod_eq_of_lt
/- To prove that \( x.toNat + y.toNat < 2^w \), it suffices to show that the boolean value of the decision \( x.toNat + y.toNat + false.toNat \ge 2^w \) is `false`. We simplify this using the theorem that the boolean value of a decision is `true` if and only if the proposition is true, which reduces our goal to showing that \( x.toNat + y.toNat + false.toNat < 2^w \). This is then trivially true by the `omega` tactic, which handles linear arithmetic. -/
  suffices ¬ decide (x.toNat + y.toNat + false.toNat ≥ 2^w) by
    simp only [decide_eq_true_eq] at this
    omega
/- We use the theorem that the carry bit at position \( w \) when adding \( x \) and \( y \) with an initial carry of `false` is `true` if and only if \( x.toNat + y.toNat + false.toNat \ge 2^w \). This changes our goal to show that the carry bit at position \( w \) is `false`. -/
  rw [← carry_width]
/- We simplify the goal using the theorem that the carry bit at position \( w \) is `false` if the bitwise AND of \( x \) and \( y \) is zero. Since \( x \land y = 0 \) by our hypothesis, the carry bit at position \( w \) is indeed `false`. This completes the proof. -/
  simp [not_eq_true, carry_of_and_eq_zero h]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22494,BitVec.ushiftRightRec_zero,"theorem BitVec.ushiftRightRec_zero (x : BitVec w₁) (y : BitVec w₂) :
    ushiftRightRec x y 0 = x >>> (y &&& twoPow w₂ 0) := by sorry","Logical Right Shift of Bitvector by Zero Bits : For any natural numbers \( w_1 \) and \( w_2 \), and any bitvectors \( x \) of width \( w_1 \) and \( y \) of width \( w_2 \), the logical right shift of \( x \) by the first 0 bits of \( y \) is equal to the logical right shift of \( x \) by the amount determined by the 0-th bit of \( y \). Mathematically, this can be expressed as:
\[ x.\text{ushiftRightRec}(y, 0) = x >>> (y \&&& \text{twoPow}(w_2, 0)) \]","theorem BitVec.ushiftRightRec_zero (x : BitVec w₁) (y : BitVec w₂) :
    ushiftRightRec x y 0 = x >>> (y &&& twoPow w₂ 0) := by
  simp [ushiftRightRec]","To prove the theorem, we start by using the definition of the logical right shift operation `ushiftRightRec`. By simplifying the expression using this definition, we directly obtain the desired equality:
\[ x.\text{ushiftRightRec}(y, 0) = x >>> (y \&&& \text{twoPow}(w_2, 0)) \]
This completes the proof.","theorem BitVec.ushiftRightRec_zero (x : BitVec w₁) (y : BitVec w₂) :
    ushiftRightRec x y 0 = x >>> (y &&& twoPow w₂ 0) := by
/- Using the definition of the logical right shift operation `ushiftRightRec`, we simplify the proposition we want to show. This simplification directly results in the equality \( x.\text{ushiftRightRec}(y, 0) = x >>> (y \&&& \text{twoPow}(w_2, 0)) \). -/
  simp [ushiftRightRec]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22495,Bool.atLeastTwo_true_right,theorem Bool.atLeastTwo_true_right : atLeastTwo a b true  = (a || b) := by sorry,"At Least Two of Three Booleans Including True is Equivalent to Boolean Or: \( a \text{ or } b \) : For any boolean values \( a \) and \( b \), the function `atLeastTwo` returns `true` if at least two out of the three boolean values \( a, b, \) and `true` are `true`. This is equivalent to the boolean ""or"" operation, i.e., \( a \text{ or } b \).","theorem Bool.atLeastTwo_true_right : atLeastTwo a b true  = (a || b) := by
  cases a <;> cases b <;> simp [atLeastTwo]","We need to show that for any boolean values \( a \) and \( b \), the function `atLeastTwo` applied to \( a, b, \) and `true` is equal to \( a \lor b \). We will consider every possible combination of \( a \) and \( b \).

1. **Case 1: \( a = \text{false} \) and \( b = \text{false} \)**
- Using the definition of `atLeastTwo`, we have:
\[
\text{false}.\text{atLeastTwo}(\text{false}, \text{true}) = \text{false}
\]
- The boolean ""or"" operation gives:
\[
\text{false} \lor \text{false} = \text{false}
\]
- Therefore, the goal is satisfied.

2. **Case 2: \( a = \text{false} \) and \( b = \text{true} \)**
- Using the definition of `atLeastTwo`, we have:
\[
\text{false}.\text{atLeastTwo}(\text{true}, \text{true}) = \text{true}
\]
- The boolean ""or"" operation gives:
\[
\text{false} \lor \text{true} = \text{true}
\]
- Therefore, the goal is satisfied.

3. **Case 3: \( a = \text{true} \) and \( b = \text{false} \)**
- Using the definition of `atLeastTwo`, we have:
\[
\text{true}.\text{atLeastTwo}(\text{false}, \text{true}) = \text{true}
\]
- The boolean ""or"" operation gives:
\[
\text{true} \lor \text{false} = \text{true}
\]
- Therefore, the goal is satisfied.

4. **Case 4: \( a = \text{true} \) and \( b = \text{true} \)**
- Using the definition of `atLeastTwo`, we have:
\[
\text{true}.\text{atLeastTwo}(\text{true}, \text{true}) = \text{true}
\]
- The boolean ""or"" operation gives:
\[
\text{true} \lor \text{true} = \text{true}
\]
- Therefore, the goal is satisfied.

Since all cases are satisfied, we conclude that for any boolean values \( a \) and \( b \), the function `atLeastTwo` applied to \( a, b, \) and `true` is equivalent to \( a \lor b \). This completes the proof.","theorem Bool.atLeastTwo_true_right : atLeastTwo a b true  = (a || b) := by
  cases a <;> cases b <;> simp [atLeastTwo]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open Bool
open Nat Bool
"
22496,BitVec.add_not_self,theorem BitVec.add_not_self (x : BitVec w) : x + ~~~x = allOnes w := by sorry,"Bitvector Addition of Complement Yields All Ones: \( x + \sim x = \text{allOnes}(w) \) : For any bitvector \( x \) of width \( w \), the sum of \( x \) and its complement \( \sim x \) is the bitvector of width \( w \) with all bits set to 1, i.e., \( x + \sim x = \text{allOnes}(w) \).","theorem BitVec.add_not_self (x : BitVec w) : x + ~~~x = allOnes w := by
  rw [add_eq_adc, adc, iunfoldr_replace (fun _ => false) (allOnes w)]
  · rfl
  · simp [adcb, atLeastTwo]","To prove that \( x + \sim x = \text{allOnes}(w) \), we start by using the equivalence that the sum of two bitvectors \( x \) and \( y \) is equal to the second component of the result of the bitwise addition with carry operation `adc` applied to \( x \), \( y \), and the boolean value `false`. This transforms our goal into showing that the second component of the result of `adc` applied to \( x \), \( \sim x \), and `false` is equal to the all-ones bitvector of width \( w \).

Next, we use the definition of `adc` to expand this into the iterative unfolding of the bitwise addition with carry operation. Specifically, we need to show that for each index \( i \) in \( \text{Fin } w \), the result of the bitwise addition of \( x \) and \( \sim x \) with carry `false` is `false` and the least significant bit of the all-ones bitvector is `true`.

We then use the `iunfoldr_replace` theorem to replace the iterative unfolding with the all-ones bitvector, reducing our goal to showing that the least significant bit of the all-ones bitvector is `true` for all indices \( i \) in \( \text{Fin } w \).

The current goal is to show that `false = false`, which is trivially true by the reflexive property of equality.

Finally, we simplify the remaining goal using the definitions of `adcb` and `atLeastTwo`. The function `adcb` computes the carry and result of a bitwise addition, and `atLeastTwo` checks if at least two of the inputs are `true`. By simplifying with these definitions, we show that for each index \( i \) in \( \text{Fin } w \), the result of the bitwise addition of \( x \) and \( \sim x \) with carry `false` is `false` and the least significant bit of the all-ones bitvector is `true`.

Thus, we have shown that \( x + \sim x = \text{allOnes}(w) \). This completes the proof. \(\blacksquare\)","theorem BitVec.add_not_self (x : BitVec w) : x + ~~~x = allOnes w := by
/- First, we use the equivalence that the sum of two bitvectors \( x \) and \( y \) is equal to the second component of the result of the bitwise addition with carry operation `adc` applied to \( x \), \( y \), and the boolean value `false`. This transforms our goal into showing that the second component of the result of `adc` applied to \( x \), \( \sim x \), and `false` is equal to the all-ones bitvector of width \( w \). We then use the definition of `adc` to expand this into the iterative unfolding of the bitwise addition with carry operation. Finally, we use the `iunfoldr_replace` theorem to replace the iterative unfolding with the all-ones bitvector, reducing our goal to showing that the least significant bit of the all-ones bitvector is `true` for all indices \( i \) in \( \text{Fin } w \). -/
  rw [add_eq_adc, adc, iunfoldr_replace (fun _ => false) (allOnes w)]
/- The current goal is to show that `false = false`, which is trivially true by the reflexive property of equality. -/
  · rfl
/- We simplify the remaining goal using the definitions of `adcb` and `atLeastTwo`. The function `adcb` computes the carry and result of a bitwise addition, and `atLeastTwo` checks if at least two of the inputs are `true`. By simplifying with these definitions, we show that for each index \( i \) in \( \text{Fin } w \), the result of the bitwise addition of \( x \) and \( \sim x \) with carry `false` is `false` and the least significant bit of the all-ones bitvector is `true`. -/
  · simp [adcb, atLeastTwo]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22499,BitVec.ushiftRightRec_succ,"theorem BitVec.ushiftRightRec_succ (x : BitVec w₁) (y : BitVec w₂) :
    ushiftRightRec x y (n + 1) = (ushiftRightRec x y n) >>> (y &&& twoPow w₂ (n + 1)) := by sorry","Logical Right Shift of Bitvector by Successive Bits : For any natural numbers \( w_1 \) and \( w_2 \), and any natural number \( n \), if \( x \) is a bitvector of width \( w_1 \) and \( y \) is a bitvector of width \( w_2 \), then the logical right shift of \( x \) by the first \( n + 1 \) bits of \( y \) is equal to the logical right shift of \( x \) by the first \( n \) bits of \( y \), followed by a logical right shift by the \( (n + 1) \)-th bit of \( y \). Mathematically, this can be expressed as:
\[ x.\text{ushiftRightRec}(y, n + 1) = x.\text{ushiftRightRec}(y, n) >>> (y \&&& \text{twoPow}(w_2, n + 1)) \]","theorem BitVec.ushiftRightRec_succ (x : BitVec w₁) (y : BitVec w₂) :
    ushiftRightRec x y (n + 1) = (ushiftRightRec x y n) >>> (y &&& twoPow w₂ (n + 1)) := by
  simp [ushiftRightRec]","To prove the theorem, we start by using the definition of the logical right shift function `ushiftRightRec`. The function `ushiftRightRec` shifts a bitvector `x` of width \( w_1 \) logically to the right by the first \( n \) bits of another bitvector `y` of width \( w_2 \). Specifically, for \( n + 1 \), it first shifts `x` by the first \( n \) bits of `y` and then performs another logical right shift by the amount \( y \&&& 2^{n+1} \).

Thus, the proposition we want to show is:
\[ x.\text{ushiftRightRec}(y, n + 1) = x.\text{ushiftRightRec}(y, n) >>> (y \&&& \text{twoPow}(w_2, n + 1)) \]

By the definition of `ushiftRightRec`, this simplifies directly to the desired equality. Therefore, the theorem is proved.

\(\blacksquare\)","theorem BitVec.ushiftRightRec_succ (x : BitVec w₁) (y : BitVec w₂) :
    ushiftRightRec x y (n + 1) = (ushiftRightRec x y n) >>> (y &&& twoPow w₂ (n + 1)) := by
/- Using the definition of the logical right shift function `ushiftRightRec`, we can simplify the proposition we want to show. The function `ushiftRightRec` shifts a bitvector `x` of width \( w_1 \) logically to the right by the first \( n \) bits of another bitvector `y` of width \( w_2 \). Specifically, for \( n + 1 \), it first shifts `x` by the first \( n \) bits of `y` and then performs another logical right shift by the amount \( y \&&& 2^{n+1} \). Therefore, the proposition simplifies to:
\[ x.\text{ushiftRightRec}(y, n + 1) = x.\text{ushiftRightRec}(y, n) >>> (y \&&& \text{twoPow}(w_2, n + 1)) \] -/
  simp [ushiftRightRec]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22501,Bool.atLeastTwo_true_mid,theorem Bool.atLeastTwo_true_mid : atLeastTwo a true c  = (a || c) := by sorry,"At Least Two with True Middle Argument is Equivalent to Boolean Or: \(\text{atLeastTwo}(a, \text{true}, c) = a \lor c\) : For any boolean values \( a \) and \( c \), the function `atLeastTwo` with the second argument `true` is equal to the boolean ""or"" operation of \( a \) and \( c \), i.e., \(\text{atLeastTwo}(a, \text{true}, c) = a \lor c\).","theorem Bool.atLeastTwo_true_mid : atLeastTwo a true c  = (a || c) := by
  cases a <;> cases c <;> simp [atLeastTwo]","To prove the theorem, we will consider every possible combination of the boolean values \( a \) and \( c \).

1. **Case 1: \( a = \text{false} \) and \( c = \text{false} \)**
- We need to show that \(\text{false}.\text{atLeastTwo}(\text{true}, \text{false}) = \text{false} \lor \text{false}\).
- Using the definition of the `atLeastTwo` function, \(\text{false}.\text{atLeastTwo}(\text{true}, \text{false})\) is `false` because at least two of the three booleans are not `true`.
- Therefore, \(\text{false} \lor \text{false} = \text{false}\).

2. **Case 2: \( a = \text{false} \) and \( c = \text{true} \)**
- We need to show that \(\text{false}.\text{atLeastTwo}(\text{true}, \text{true}) = \text{false} \lor \text{true}\).
- Using the definition of the `atLeastTwo` function, \(\text{false}.\text{atLeastTwo}(\text{true}, \text{true})\) is `true` because at least two of the three booleans are `true`.
- Therefore, \(\text{false} \lor \text{true} = \text{true}\).

3. **Case 3: \( a = \text{true} \) and \( c = \text{false} \)**
- We need to show that \(\text{true}.\text{atLeastTwo}(\text{true}, \text{false}) = \text{true} \lor \text{false}\).
- Using the definition of the `atLeastTwo` function, \(\text{true}.\text{atLeastTwo}(\text{true}, \text{false})\) is `true` because at least two of the three booleans are `true`.
- Therefore, \(\text{true} \lor \text{false} = \text{true}\).

4. **Case 4: \( a = \text{true} \) and \( c = \text{true} \)**
- We need to show that \(\text{true}.\text{atLeastTwo}(\text{true}, \text{true}) = \text{true} \lor \text{true}\).
- Using the definition of the `atLeastTwo` function, \(\text{true}.\text{atLeastTwo}(\text{true}, \text{true})\) is `true` because at least two of the three booleans are `true`.
- Therefore, \(\text{true} \lor \text{true} = \text{true}\).

Since all cases have been considered and the equality holds in each case, we conclude that for any boolean values \( a \) and \( c \), \(\text{atLeastTwo}(a, \text{true}, c) = a \lor c\). This completes the proof. \(\blacksquare\)","theorem Bool.atLeastTwo_true_mid : atLeastTwo a true c  = (a || c) := by
  cases a <;> cases c <;> simp [atLeastTwo]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open Bool
open Nat Bool
"
22503,BitVec.sle_eq_carry,"theorem BitVec.sle_eq_carry (x y : BitVec w) :
    x.sle y = !((x.msb == y.msb).xor (carry w y (~~~x) true)) := by sorry","Signed Less Than or Equal To in Bitvectors is Equivalent to Negation of XOR of MSB and Carry Bit : For any natural number \( w \) and any bitvectors \( x \) and \( y \) of width \( w \), the signed less than or equal to relation \( x \leq y \) (denoted as `x.sle y`) is equal to the negation of the exclusive or (XOR) of the most significant bits of \( x \) and \( y \) and the carry bit at position \( w \) when adding \( y \) and the complement of \( x \) with an initial carry bit of `true`. In other words, \( x \leq y \) if and only if \( \neg ((\text{msb}(x) = \text{msb}(y)) \oplus \text{carry}(w, y, \sim x, \text{true})) \).","theorem BitVec.sle_eq_carry (x y : BitVec w) :
    x.sle y = !((x.msb == y.msb).xor (carry w y (~~~x) true)) := by
  rw [sle_eq_not_slt, slt_eq_not_carry, beq_comm]","To prove the theorem, we start by using the equivalence that the signed less than or equal to relation \( x \leq y \) is the negation of the signed less than relation \( y < x \). This transforms our goal to show that:
\[ \neg (y < x) = \neg ((\text{msb}(x) = \text{msb}(y)) \oplus \text{carry}(w, y, \sim x, \text{true})) \]

Next, we use the equivalence that the signed less than relation \( y < x \) is the XOR of the most significant bits of \( y \) and \( x \) and the carry bit at position \( w \) when adding \( y \) and the complement of \( x \) with an initial carry bit of `true`. This further simplifies our goal to show that:
\[ \neg ((\text{msb}(y) = \text{msb}(x)) \oplus \text{carry}(w, y, \sim x, \text{true})) = \neg ((\text{msb}(x) = \text{msb}(y)) \oplus \text{carry}(w, y, \sim x, \text{true})) \]

Finally, we use the commutativity of boolean equality to conclude that:
\[ (\text{msb}(y) = \text{msb}(x)) = (\text{msb}(x) = \text{msb}(y)) \]

Thus, the two expressions are identical, and the goal is trivially true. Therefore, we have shown that:
\[ x \leq y \iff \neg ((\text{msb}(x) = \text{msb}(y)) \oplus \text{carry}(w, y, \sim x, \text{true})) \]

This completes the proof.","theorem BitVec.sle_eq_carry (x y : BitVec w) :
    x.sle y = !((x.msb == y.msb).xor (carry w y (~~~x) true)) := by
/- First, we use the equivalence that the signed less than or equal to relation \( x \leq y \) is the negation of the signed less than relation \( y < x \). This transforms our goal to show that \( \neg (y < x) \) is equal to the negation of the exclusive or (XOR) of the most significant bits of \( x \) and \( y \) and the carry bit at position \( w \) when adding \( y \) and the complement of \( x \) with an initial carry bit of `true`. Next, we use the equivalence that the signed less than relation \( y < x \) is the XOR of the most significant bits of \( y \) and \( x \) and the carry bit at position \( w \) when adding \( y \) and the complement of \( x \) with an initial carry bit of `true`. This further simplifies our goal to show that \( \neg ((y.\text{msb} = x.\text{msb}) \oplus \text{carry}(w, y, \sim x, \text{true})) \) is equal to \( \neg ((x.\text{msb} = y.\text{msb}) \oplus \text{carry}(w, y, \sim x, \text{true})) \). Finally, we use the commutativity of boolean equality to conclude that \( (y.\text{msb} = x.\text{msb}) \) is equivalent to \( (x.\text{msb} = y.\text{msb}) \), thus the two expressions are identical, and the goal is trivially true. -/
  rw [sle_eq_not_slt, slt_eq_not_carry, beq_comm]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22504,BitVec.shiftLeftRec_succ,"theorem BitVec.shiftLeftRec_succ {x : BitVec w₁} {y : BitVec w₂} :
    shiftLeftRec x y (n + 1) = (shiftLeftRec x y n) <<< (y &&& twoPow w₂ (n + 1)) := by sorry","Recursive Left Shift of Bitvectors with Successor Steps : For any natural numbers \( w_1 \) and \( w_2 \), and for any bitvectors \( x \) and \( y \) of widths \( w_1 \) and \( w_2 \) respectively, the recursive left shift operation `shiftLeftRec` applied to \( x \) and \( y \) with \( n + 1 \) steps is equal to the left shift of \( x \) by the value of the first \( n \) bits of \( y \) followed by the left shift of the result by the value of the \( (n + 1) \)-th bit of \( y \). Formally, this is expressed as:
\[ x.\text{shiftLeftRec}(y, n + 1) = (x.\text{shiftLeftRec}(y, n)) <<< (y \&&& \text{twoPow}(w_2, n + 1)) \]","theorem BitVec.shiftLeftRec_succ {x : BitVec w₁} {y : BitVec w₂} :
    shiftLeftRec x y (n + 1) = (shiftLeftRec x y n) <<< (y &&& twoPow w₂ (n + 1)) := by
  simp [shiftLeftRec]","To prove the theorem, we start by using the definition of the recursive left shift operation `shiftLeftRec`. According to the definition, the recursive left shift of \( x \) by \( y \) with \( n + 1 \) steps is given by:
\[ x.\text{shiftLeftRec}(y, n + 1) = (x.\text{shiftLeftRec}(y, n)) <<< (y \&&& \text{twoPow}(w_2, n + 1)) \]

This means that the left shift of \( x \) by \( y \) with \( n + 1 \) steps is equivalent to first performing the left shift of \( x \) by the value of the first \( n \) bits of \( y \), and then performing the left shift of the result by the value of the \( (n + 1) \)-th bit of \( y \).

By the definition of `shiftLeftRec`, the left shift of \( x \) by the value of the first \( n \) bits of \( y \) is \( x.\text{shiftLeftRec}(y, n) \). The value of the \( (n + 1) \)-th bit of \( y \) is given by \( y \&&& \text{twoPow}(w_2, n + 1) \).

Therefore, the left shift of \( x \) by \( y \) with \( n + 1 \) steps is:
\[ x.\text{shiftLeftRec}(y, n + 1) = (x.\text{shiftLeftRec}(y, n)) <<< (y \&&& \text{twoPow}(w_2, n + 1)) \]

This completes the proof.","theorem BitVec.shiftLeftRec_succ {x : BitVec w₁} {y : BitVec w₂} :
    shiftLeftRec x y (n + 1) = (shiftLeftRec x y n) <<< (y &&& twoPow w₂ (n + 1)) := by
/- Using the definition of the recursive left shift operation `shiftLeftRec`, we can simplify the proposition we want to show. Specifically, the recursive left shift of \( x \) by \( y \) with \( n + 1 \) steps is defined as the left shift of \( x \) by the value of the first \( n \) bits of \( y \) followed by the left shift of the result by the value of the \( (n + 1) \)-th bit of \( y \). Therefore, the goal is to show:
\[ x.\text{shiftLeftRec}(y, n + 1) = (x.\text{shiftLeftRec}(y, n)) <<< (y \&&& \text{twoPow}(w_2, n + 1)) \] -/
  simp [shiftLeftRec]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22510,BitVec.slt_eq_ult_of_msb_eq,"theorem BitVec.slt_eq_ult_of_msb_eq {x y : BitVec w} (h : x.msb = y.msb) :
    x.slt y = x.ult y := by sorry","Signed and Unsigned Less-Than Coincide if Most Significant Bits are Equal : For any natural number \( w \) and bit vectors \( x \) and \( y \) of length \( w \), if the most significant bit (msb) of \( x \) is equal to the most significant bit of \( y \), then the signed less-than comparison \( x <_{\text{signed}} y \) is equivalent to the unsigned less-than comparison \( x <_{\text{unsigned}} y \). In other words, if \( x.\text{msb} = y.\text{msb} \), then \( x <_{\text{signed}} y \) if and only if \( x <_{\text{unsigned}} y \).","theorem BitVec.slt_eq_ult_of_msb_eq {x y : BitVec w} (h : x.msb = y.msb) :
    x.slt y = x.ult y := by
  simp only [BitVec.slt, toInt_eq_msb_cond, BitVec.ult, decide_eq_decide, h]
  cases y.msb <;> simp","We start by simplifying the goal using the definitions of signed and unsigned less-than for bit vectors, the conversion of bit vectors to integers based on their most significant bit, and the fact that the most significant bits of \( x \) and \( y \) are equal. This simplification reduces the goal to showing that:
\[
((\text{if } y.\text{msb} = \text{true} \text{ then } x.\text{toNat} - 2^w \text{ else } x.\text{toNat}) < (\text{if } y.\text{msb} = \text{true} \text{ then } y.\text{toNat} - 2^w \text{ else } y.\text{toNat})) \leftrightarrow (x.\text{toNat} < y.\text{toNat})
\]

We consider two cases based on the value of \( y.\text{msb} \):

1. **Case 1: \( y.\text{msb} = \text{false} \)**
- In this case, the goal simplifies to:
\[
(x.\text{toNat} < y.\text{toNat}) \leftrightarrow (x.\text{toNat} < y.\text{toNat})
\]
- This is trivially true.

2. **Case 2: \( y.\text{msb} = \text{true} \)**
- In this case, the goal simplifies to:
\[
(x.\text{toNat} - 2^w < y.\text{toNat} - 2^w) \leftrightarrow (x.\text{toNat} < y.\text{toNat})
\]
- Since subtracting the same value from both sides of an inequality does not change the inequality, this is also true.

Thus, in both cases, the signed less-than comparison \( x <_{\text{signed}} y \) is equivalent to the unsigned less-than comparison \( x <_{\text{unsigned}} y \). This completes the proof. \(\blacksquare\)","theorem BitVec.slt_eq_ult_of_msb_eq {x y : BitVec w} (h : x.msb = y.msb) :
    x.slt y = x.ult y := by
/- First, we simplify the goal using the definitions of signed and unsigned less-than for bit vectors, the conversion of bit vectors to integers based on their most significant bit, and the fact that the most significant bits of \( x \) and \( y \) are equal. This simplification reduces the goal to showing that:
\[
((\text{if } y.\text{msb} = \text{true} \text{ then } x.\text{toNat} - 2^w \text{ else } x.\text{toNat}) < (\text{if } y.\text{msb} = \text{true} \text{ then } y.\text{toNat} - 2^w \text{ else } y.\text{toNat})) \leftrightarrow (x.\text{toNat} < y.\text{toNat})
\] -/
  simp only [BitVec.slt, toInt_eq_msb_cond, BitVec.ult, decide_eq_decide, h]
/- We consider two cases based on the value of \( y.\text{msb} \):

1. **Case 1: \( y.\text{msb} = \text{false} \)**
- In this case, the goal simplifies to:
\[
(x.\text{toNat} < y.\text{toNat}) \leftrightarrow (x.\text{toNat} < y.\text{toNat})
\]
- This is trivially true.

2. **Case 2: \( y.\text{msb} = \text{true} \)**
- In this case, the goal simplifies to:
\[
(x.\text{toNat} - 2^w < y.\text{toNat} - 2^w) \leftrightarrow (x.\text{toNat} < y.\text{toNat})
\]
- Since subtracting the same value from both sides of an inequality does not change the inequality, this is also true. -/
  cases y.msb <;> simp","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22511,BitVec.slt_eq_ult,"theorem BitVec.slt_eq_ult (x y : BitVec w) :
    x.slt y = (x.msb != y.msb).xor (x.ult y) := by sorry","Signed Less-Than Equals XOR of MSB Inequality and Unsigned Less-Than for Bit Vectors : For any bit vectors \( x \) and \( y \) of the same length \( w \), the signed less-than comparison \( x.\text{slt} y \) is equal to the exclusive or (XOR) of the inequality of their most significant bits (MSBs) and the unsigned less-than comparison \( x.\text{ult} y \). In other words, \( x.\text{slt} y = (x.\text{msb} \neq y.\text{msb}) \oplus (x.\text{ult} y) \).","theorem BitVec.slt_eq_ult (x y : BitVec w) :
    x.slt y = (x.msb != y.msb).xor (x.ult y) := by
  by_cases h : x.msb = y.msb
  · simp [h, slt_eq_ult_of_msb_eq]
  · have h' : x.msb != y.msb := by simp_all
    simp [slt_eq_not_ult_of_msb_neq h, h']","We consider two cases based on the equality of the most significant bits (MSBs) of \( x \) and \( y \).

1. **Case 1: \( x.\text{msb} = y.\text{msb} \)**
- If the most significant bits of \( x \) and \( y \) are equal, then the signed less-than comparison \( x.\text{slt} y \) is equivalent to the unsigned less-than comparison \( x.\text{ult} y \). Therefore, the expression \( x.\text{slt} y = (x.\text{msb} \neq y.\text{msb}) \oplus (x.\text{ult} y) \) simplifies to \( x.\text{ult} y = \text{false} \oplus (x.\text{ult} y) \), which is true. This completes the proof for the first case.

2. **Case 2: \( x.\text{msb} \neq y.\text{msb} \)**
- If the most significant bits of \( x \) and \( y \) are different, we construct a new hypothesis that \( x.\text{msb} \neq y.\text{msb} \) is true. Using the fact that if the most significant bits of \( x \) and \( y \) are different, then the signed less-than comparison \( x.\text{slt} y \) is equivalent to the negation of the unsigned less-than comparison \( x.\text{ult} y \), we simplify the expression \( x.\text{slt} y = (x.\text{msb} \neq y.\text{msb}) \oplus (x.\text{ult} y) \) to \( !x.\text{ult} y = \text{true} \oplus (x.\text{ult} y) \), which is true. This completes the proof for the second case.

Since both cases are covered, the theorem is proved.","theorem BitVec.slt_eq_ult (x y : BitVec w) :
    x.slt y = (x.msb != y.msb).xor (x.ult y) := by
/- Consider two cases: (1) Assume \( x.\text{msb} = y.\text{msb} \), and (2) Assume \( x.\text{msb} \neq y.\text{msb} \). -/
  by_cases h : x.msb = y.msb
/- In the first case, where \( x.\text{msb} = y.\text{msb} \), we use the fact that if the most significant bits of \( x \) and \( y \) are equal, then the signed less-than comparison \( x.\text{slt} y \) is equivalent to the unsigned less-than comparison \( x.\text{ult} y \). Therefore, the expression \( x.\text{slt} y = (x.\text{msb} \neq y.\text{msb}) \oplus (x.\text{ult} y) \) simplifies to \( x.\text{ult} y = \text{false} \oplus (x.\text{ult} y) \), which is true. This completes the proof for the first case. -/
  · simp [h, slt_eq_ult_of_msb_eq]
/- In the second case, where \( x.\text{msb} \neq y.\text{msb} \), we construct a new hypothesis \( h' \) that \( x.\text{msb} \neq y.\text{msb} \) is true. This is trivially true by the assumption \( x.\text{msb} \neq y.\text{msb} \). -/
  · have h' : x.msb != y.msb := by simp_all
/- Using the fact that if the most significant bits of \( x \) and \( y \) are different, then the signed less-than comparison \( x.\text{slt} y \) is equivalent to the negation of the unsigned less-than comparison \( x.\text{ult} y \), we simplify the expression \( x.\text{slt} y = (x.\text{msb} \neq y.\text{msb}) \oplus (x.\text{ult} y) \) to \( !x.\text{ult} y = \text{true} \oplus (x.\text{ult} y) \), which is true. This completes the proof for the second case. -/
    simp [slt_eq_not_ult_of_msb_neq h, h']","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22514,BitVec.slt_eq_not_carry,"theorem BitVec.slt_eq_not_carry (x y : BitVec w) :
    x.slt y = (x.msb == y.msb).xor (carry w x (~~~y) true) := by sorry","Signed Less-Than in Bitvectors Equals XOR of MSB and Carry Bit : For any natural number \( w \) and bitvectors \( x \) and \( y \) of length \( w \), the signed less-than operation \( x \, \text{sl} \, y \) is equal to the exclusive or (XOR) of the most significant bits of \( x \) and \( y \) and the carry bit at position \( w \) when computing the sum of \( x \) and the complement of \( y \) with an initial carry bit of `true`. Formally, this can be written as:
\[ x \, \text{sl} \, y = (x.\text{msb} \neq y.\text{msb}) \oplus \text{carry}(w, x, \sim y, \text{true}) \]","theorem BitVec.slt_eq_not_carry (x y : BitVec w) :
    x.slt y = (x.msb == y.msb).xor (carry w x (~~~y) true) := by
  simp only [slt_eq_ult, bne, ult_eq_not_carry]
  cases x.msb == y.msb <;> simp","To prove the theorem, we start by using the definitions and properties of signed less-than, boolean not-equal, and unsigned less-than to simplify the goal. Specifically, we use the fact that:
\[ x \, \text{sl} \, y = (x.\text{msb} \neq y.\text{msb}) \oplus (x < y) \]
and
\[ x < y = \text{not}(\text{carry}(w, x, \sim y, \text{true})) \]

This simplifies our goal to:
\[ (!(!x.\text{msb} == y.\text{msb}) == !\text{carry}(w, x, \sim y, \text{true})) = !(x.\text{msb} == y.\text{msb}) == \text{carry}(w, x, \sim y, \text{true}) \]

Next, we consider two cases based on whether the most significant bits of \( x \) and \( y \) are equal or not.

**Case 1: \( x.\text{msb} == y.\text{msb} \)**
- In this case, the goal simplifies to:
\[ (!(!\text{false}) == !\text{carry}(w, x, \sim y, \text{true})) = !\text{false} == \text{carry}(w, x, \sim y, \text{true}) \]
- Since the negation of `false` is `true`, this further simplifies to:
\[ (\text{true} == !\text{carry}(w, x, \sim y, \text{true})) = \text{true} == \text{carry}(w, x, \sim y, \text{true}) \]
- This is trivially true because both sides are equivalent.

**Case 2: \( x.\text{msb} \neq y.\text{msb} \)**
- In this case, the goal simplifies to:
\[ (!(!\text{true}) == !\text{carry}(w, x, \sim y, \text{true})) = !\text{true} == \text{carry}(w, x, \sim y, \text{true}) \]
- Since the negation of `true` is `false`, this further simplifies to:
\[ (\text{false} == !\text{carry}(w, x, \sim y, \text{true})) = \text{false} == \text{carry}(w, x, \sim y, \text{true}) \]
- This is trivially true because both sides are equivalent.

Since both cases are true, the original goal is proven. Therefore, the signed less-than operation \( x \, \text{sl} \, y \) is indeed equal to the exclusive or (XOR) of the most significant bits of \( x \) and \( y \) and the carry bit at position \( w \) when computing the sum of \( x \) and the complement of \( y \) with an initial carry bit of `true`. This completes the proof.","theorem BitVec.slt_eq_not_carry (x y : BitVec w) :
    x.slt y = (x.msb == y.msb).xor (carry w x (~~~y) true) := by
/- Using the definitions and properties of signed less-than, boolean not-equal, and unsigned less-than, we can simplify the goal to show that:
\[ (!(!x.\text{msb} == y.\text{msb}) == !\text{carry}(w, x, \sim y, \text{true})) = !(x.\text{msb} == y.\text{msb}) == \text{carry}(w, x, \sim y, \text{true}) \] -/
  simp only [slt_eq_ult, bne, ult_eq_not_carry]
/- We will consider two cases based on whether the most significant bits of \( x \) and \( y \) are equal or not.

**Case 1: \( x.\text{msb} == y.\text{msb} \)**
- In this case, the goal simplifies to:
\[ (!(!\text{false}) == !\text{carry}(w, x, \sim y, \text{true})) = !\text{false} == \text{carry}(w, x, \sim y, \text{true}) \]
- Since the negation of `false` is `true`, this further simplifies to:
\[ (\text{true} == !\text{carry}(w, x, \sim y, \text{true})) = \text{true} == \text{carry}(w, x, \sim y, \text{true}) \]
- This is trivially true because both sides are equivalent.

**Case 2: \( x.\text{msb} \neq y.\text{msb} \)**
- In this case, the goal simplifies to:
\[ (!(!\text{true}) == !\text{carry}(w, x, \sim y, \text{true})) = !\text{true} == \text{carry}(w, x, \sim y, \text{true}) \]
- Since the negation of `true` is `false`, this further simplifies to:
\[ (\text{false} == !\text{carry}(w, x, \sim y, \text{true})) = \text{false} == \text{carry}(w, x, \sim y, \text{true}) \]
- This is trivially true because both sides are equivalent. -/
  cases x.msb == y.msb <;> simp","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22519,BitVec.shiftLeft_eq_shiftLeftRec,"theorem BitVec.shiftLeft_eq_shiftLeftRec (x : BitVec w₁) (y : BitVec w₂) :
    x <<< y = shiftLeftRec x y (w₂ - 1) := by sorry","Left Shift of Bitvectors Equals Recursive Left Shift by \( w_2 - 1 \) Bits: \( x <<< y = x.\text{shiftLeftRec}(y, w_2 - 1) \) : For any natural numbers \( w_1 \) and \( w_2 \), and for any bitvectors \( x \) and \( y \) of widths \( w_1 \) and \( w_2 \) respectively, the left shift operation \( x <<< y \) is equal to the recursive left shift operation \( x.\text{shiftLeftRec}(y, w_2 - 1) \). Specifically, \( x <<< y = x.\text{shiftLeftRec}(y, w_2 - 1) \).","theorem BitVec.shiftLeft_eq_shiftLeftRec (x : BitVec w₁) (y : BitVec w₂) :
    x <<< y = shiftLeftRec x y (w₂ - 1) := by
  rcases w₂ with rfl | w₂
  · simp [of_length_zero]
  · simp [shiftLeftRec_eq]","We need to show that for any natural numbers \( w_1 \) and \( w_2 \), and for any bitvectors \( x \) and \( y \) of widths \( w_1 \) and \( w_2 \) respectively, the left shift operation \( x <<< y \) is equal to the recursive left shift operation \( x.\text{shiftLeftRec}(y, w_2 - 1) \).

We consider two cases:

1. **Case 1: \( w_2 = 0 \)**
- In this case, \( y \) is a bitvector of length 0, which is equal to the zero bitvector \( 0\#0 \).
- The left shift operation \( x <<< y \) is trivially equal to \( x \) because shifting by 0 bits does not change \( x \).
- The recursive left shift operation \( x.\text{shiftLeftRec}(y, 0 - 1) \) simplifies to \( x.\text{shiftLeftRec}(y, -1) \), which is also equal to \( x \) by definition.
- Therefore, \( x <<< y = x.\text{shiftLeftRec}(y, 0 - 1) \).

2. **Case 2: \( w_2 = w_2 + 1 \) for some natural number \( w_2 \)**
- In this case, we use the definition of the recursive left shift operation \( x.\text{shiftLeftRec}(y, n) \).
- Specifically, we use the theorem that states \( x.\text{shiftLeftRec}(y, n) = x <<< \text{BitVec.zeroExtend}(w_2, \text{BitVec.truncate}(n + 1, y)) \).
- Substituting \( n = w_2 \), we get \( x.\text{shiftLeftRec}(y, w_2) = x <<< \text{BitVec.zeroExtend}(w_2, \text{BitVec.truncate}(w_2 + 1, y)) \).
- Since \( \text{BitVec.zeroExtend}(w_2, \text{BitVec.truncate}(w_2 + 1, y)) \) is equal to \( y \), we have \( x.\text{shiftLeftRec}(y, w_2) = x <<< y \).
- Therefore, \( x <<< y = x.\text{shiftLeftRec}(y, w_2 - 1) \).

In both cases, we have shown that \( x <<< y = x.\text{shiftLeftRec}(y, w_2 - 1) \). This completes the proof.","theorem BitVec.shiftLeft_eq_shiftLeftRec (x : BitVec w₁) (y : BitVec w₂) :
    x <<< y = shiftLeftRec x y (w₂ - 1) := by
/- We consider two cases: when \( w_2 = 0 \) and when \( w_2 = w_2 + 1 \) for some natural number \( w_2 \). -/
  rcases w₂ with rfl | w₂
/- In the case where \( w_2 = 0 \), we use the fact that any bitvector of length 0 is equal to the zero bitvector \( 0\#0 \). This simplifies the goal to show that \( x <<< y = x.\text{shiftLeftRec}(y, 0 - 1) \). Since \( y \) is a bitvector of length 0, \( y = 0\#0 \), and the left shift of \( x \) by \( y \) is trivially equal to \( x \). Therefore, the goal is satisfied. -/
  · simp [of_length_zero]
/- In the case where \( w_2 = w_2 + 1 \), we use the definition of the recursive left shift operation \( x.\text{shiftLeftRec}(y, n) \). Specifically, we use the theorem that states \( x.\text{shiftLeftRec}(y, n) = x <<< \text{BitVec.zeroExtend}(w_2, \text{BitVec.truncate}(n + 1, y)) \). Substituting \( n = w_2 \), we get \( x.\text{shiftLeftRec}(y, w_2) = x <<< \text{BitVec.zeroExtend}(w_2, \text{BitVec.truncate}(w_2 + 1, y)) \). This simplifies to \( x <<< y \), which is exactly what we need to show. Therefore, the goal is satisfied. -/
  · simp [shiftLeftRec_eq]","import Init.Data.BitVec.Folds
import Init.Data.Nat.Mod
import Init.Data.BitVec.Bitblast

open BitVec
open Nat Bool
"
22737,WellFounded.fixFEq,theorem WellFounded.fixFEq (x : α) (acx : Acc r x) : fixF F x acx = F x (fun (y : α) (p : r y x) => fixF F y (Acc.inv acx p)) := by sorry,"Well-founded Fixpoint Function Equality: $\text{fixF}(F, x, \text{acx}) = F(x, \lambda y \, p. \, \text{fixF}(F, y, p))$ : For any type $\alpha$, a well-founded relation $r$ on $\alpha$, and a type family $C$ over $\alpha$, if $F$ is a function that, for each $x \in \alpha$, maps a function from $y \in \alpha$ and $r y x$ to $C y$ to an element of $C x$, and if $x \in \alpha$ is accessible under the relation $r$, then the value of the well-founded fixpoint function `fixF F x acx` is equal to $F(x, \lambda y \, p. \, \text{fixF}(F, y, p))$.","theorem WellFounded.fixFEq (x : α) (acx : Acc r x) : fixF F x acx = F x (fun (y : α) (p : r y x) => fixF F y (Acc.inv acx p)) := by
  induction acx with
  | intro x r _ => exact rfl","We perform induction on the accessibility predicate $\text{acx}$ for the element $x$. For the base case, we need to show that:
\[
\text{fixF}(F, x, \text{acx}) = F(x, \lambda y \, p. \, \text{fixF}(F, y, p))
\]
Since the goal is definitionally equal to itself, it is trivially true by the reflexivity of equality. This completes the proof. $\blacksquare$","theorem WellFounded.fixFEq (x : α) (acx : Acc r x) : fixF F x acx = F x (fun (y : α) (p : r y x) => fixF F y (Acc.inv acx p)) := by
  induction acx with
/- We perform induction on the accessibility predicate `acx` for the element `x`. For the base case, we need to show that `fixF F x acx = F x fun y p => fixF F y ⋯`. Since the goal is definitionally equal to itself, it is trivially true by the reflexivity of equality. -/
  | intro x r _ => exact rfl","import Init.SizeOf
import Init.Data.Nat.Basic
import Init.WF

open WellFounded
variable {α : Sort u} {r : α → α → Prop}
variable {α : Sort u} {r : α → α → Prop} (hwf : WellFounded r)
variable {C : α → Sort v}
variable (F : ∀ x, (∀ y, r y x → C y) → C x)
variable (F : ∀ x, (∀ y, r y x → C y) → C x)
"
22738,Prod.RProdSubLex,theorem Prod.RProdSubLex (a : α × β) (b : α × β) (h : RProd ra rb a b) : Prod.Lex ra rb a b := by sorry,"RProd Implies Lexicographic Order in Product Types : For any types \( \alpha \) and \( \beta \) and any relations \( r \) on \( \alpha \) and \( r' \) on \( \beta \), if \( (a_1, b_1) \) and \( (a_2, b_2) \) are elements of \( \alpha \times \beta \) such that \( (a_1, b_1) \) is less than \( (a_2, b_2) \) according to the relation \( \text{rprod} \), then \( (a_1, b_1) \) is also less than \( (a_2, b_2) \) according to the lexicographic order \( \text{lex} \).","theorem Prod.RProdSubLex (a : α × β) (b : α × β) (h : RProd ra rb a b) : Prod.Lex ra rb a b := by
  cases h with
  | intro h₁ h₂ => exact Prod.Lex.left _ _ h₁","We need to show that if \((a_1, b_1) < (a_2, b_2)\) in the product order \(\text{rprod}\), then \((a_1, b_1) < (a_2, b_2)\) in the lexicographic order \(\text{lex}\).

1. **Case 1: \(a_1 < a_2\) according to \(r_a\):**
- By the definition of the lexicographic order, if \(a_1 < a_2\), then \((a_1, b_1) < (a_2, b_2)\) regardless of the values of \(b_1\) and \(b_2\).
- Therefore, the current goal is exactly proved by the fact that \(a_1 < a_2\).

This completes the proof.","theorem Prod.RProdSubLex (a : α × β) (b : α × β) (h : RProd ra rb a b) : Prod.Lex ra rb a b := by
  cases h with
/- To prove that \((a_1, b_1) \) is less than \((a_2, b_2) \) in the lexicographic order, we consider the case where \(a_1\) is less than \(a_2\) according to the relation \(r_a\). By the definition of the lexicographic order, if \(a_1 < a_2\), then \((a_1, b_1) < (a_2, b_2)\) regardless of the values of \(b_1\) and \(b_2\). Therefore, the current goal is exactly proved by the fact that \(a_1 < a_2\). -/
  | intro h₁ h₂ => exact Prod.Lex.left _ _ h₁","import Init.SizeOf
import Init.Data.Nat.Basic
import Init.WF

open Prod
variable {α : Sort u} {r : α → α → Prop}
variable {α : Sort u} {r : α → α → Prop} (hwf : WellFounded r)
variable {C : α → Sort v}
variable (F : ∀ x, (∀ y, r y x → C y) → C x)
variable (F : ∀ x, (∀ y, r y x → C y) → C x)
variable {α : Sort u} {C : α → Sort v} {r : α → α → Prop}
open WellFounded
variable {α : Sort u} {r q : α → α → Prop}
variable {α : Sort u} {β : Sort v} {r : β → β → Prop}
open Relation
open WellFounded
variable {α : Type u} {β : Type v}
variable  (ra  : α → α → Prop)
variable  (rb  : β → β → Prop)
variable  (ra  : α → α → Prop)
variable  (rb  : β → β → Prop)
variable  (rb  : β → β → Prop)
variable {α : Type u} {β : Type v}
variable {ra  : α → α → Prop} {rb  : β → β → Prop}
variable {ra  : α → α → Prop} {rb  : β → β → Prop}
"
22754,Subrelation.accessible,theorem Subrelation.accessible {a : α} (h₁ : Subrelation q r) (ac : Acc r a) : Acc q a := by sorry,"Subrelation Accessibility: \( q \subseteq r \) and \( \text{Acc}(r, a) \) implies \( \text{Acc}(q, a) \) : For any type \( \alpha \) and relations \( q \) and \( r \) on \( \alpha \), if \( q \) is a subrelation of \( r \) and \( a \) is an accessible element with respect to \( r \), then \( a \) is also accessible with respect to \( q \). In other words, if \( q \subseteq r \) and \( \text{Acc}(r, a) \) holds, then \( \text{Acc}(q, a) \) also holds.","theorem Subrelation.accessible {a : α} (h₁ : Subrelation q r) (ac : Acc r a) : Acc q a := by
  induction ac with
  | intro x _ ih =>
    apply Acc.intro
    intro y h
    exact ih y (h₁ h)","We need to show that if \( q \subseteq r \) and \( a \) is accessible with respect to \( r \), then \( a \) is also accessible with respect to \( q \).

1. **Induction on Accessibility:**
Perform induction on the accessibility of \( r \) and consider the following cases. Let \( x \) be an arbitrary element in \( \alpha \) and assume that for all \( y \) such that \( r y x \), \( y \) is accessible with respect to \( r \). We need to show that \( x \) is accessible with respect to \( q \).

2. **Applying the Accessibility Predicate Constructor:**
To prove that \( x \) is accessible with respect to \( q \), it suffices to show that for all \( y \) such that \( q y x \), \( y \) is accessible with respect to \( q \).

3. **Introducing the Hypothesis:**
Let \( y \) be an arbitrary element in \( \alpha \) and assume that \( q y x \). We need to show that \( y \) is accessible with respect to \( q \).

4. **Using the Subrelation Property:**
Since \( q \subseteq r \), and \( q y x \), we can conclude that \( r y x \). Given that \( ih \) is a proof that for all \( y \) such that \( r y x \), \( y \) is accessible with respect to \( q \), we can conclude that \( y \) is accessible with respect to \( q \).

Therefore, \( a \) is accessible with respect to \( q \), and the proof is complete.","theorem Subrelation.accessible {a : α} (h₁ : Subrelation q r) (ac : Acc r a) : Acc q a := by
  induction ac with
/- Perform induction on the accessibility of \( r \) and consider the following cases. Let \( x \) be an arbitrary element in \( \alpha \) and assume that for all \( y \) such that \( r y x \), \( y \) is accessible with respect to \( r \). We need to show that \( x \) is accessible with respect to \( q \). -/
  | intro x _ ih =>
/- To prove that \( x \) is accessible with respect to \( q \), it suffices to show that for all \( y \) such that \( q y x \), \( y \) is accessible with respect to \( q \). -/
    apply Acc.intro
/- Let \( y \) be an arbitrary element in \( \alpha \) and assume that \( q y x \). We need to show that \( y \) is accessible with respect to \( q \). -/
    intro y h
/- Since \( h_1 \) states that \( q \subseteq r \), and \( h \) is a proof that \( q y x \), we can use \( h_1 \) to conclude that \( r y x \). Given that \( ih \) is a proof that for all \( y \) such that \( r y x \), \( y \) is accessible with respect to \( q \), we can conclude that \( y \) is accessible with respect to \( q \). Therefore, the current goal is exactly proved by \( ih y (h_1 h) \). -/
/- Since \( h_1 \) states that \( q \subseteq r \), and \( h \) is a proof that \( q y x \), we can use \( h_1 \) to conclude that \( r y x \). Given that \( ih \) is a proof that for all \( y \) such that \( r y x \), \( y \) is accessible with respect to \( q \), we can conclude that \( y \) is accessible with respect to \( q \). Therefore, the current goal is exactly proved by \( ih y (h_1 h) \). -/
    exact ih y (h₁ h)","import Init.SizeOf
import Init.Data.Nat.Basic
import Init.WF

open Subrelation
variable {α : Sort u} {r : α → α → Prop}
variable {α : Sort u} {r : α → α → Prop} (hwf : WellFounded r)
variable {C : α → Sort v}
variable (F : ∀ x, (∀ y, r y x → C y) → C x)
variable (F : ∀ x, (∀ y, r y x → C y) → C x)
variable {α : Sort u} {C : α → Sort v} {r : α → α → Prop}
open WellFounded
variable {α : Sort u} {r q : α → α → Prop}
"
22772,Acc.transGen,theorem Acc.transGen (h : Acc r a) : Acc (TransGen r) a := by sorry,"Accessibility of Transitive Closure: \( \text{Acc } r \, a \to \text{Acc } (\text{TransGen } r) \, a \) : For any type \( \alpha \) and a relation \( r \) on \( \alpha \), if \( a \) is accessible with respect to \( r \), then \( a \) is also accessible with respect to the transitive closure of \( r \). In other words, if there is no infinite sequence of elements in \( \alpha \) that are related to \( a \) by \( r \), then there is no infinite sequence of elements in \( \alpha \) that are related to \( a \) by the transitive closure of \( r \).","theorem Acc.transGen (h : Acc r a) : Acc (TransGen r) a := by
  induction h with
  | intro x _ H =>
    refine Acc.intro x fun y hy ↦ ?_
    cases hy with
    | single hyx =>
      exact H y hyx
    | tail hyz hzx =>
      exact (H _ hzx).inv hyz","We perform induction on the accessibility of \( a \) with respect to \( r \). Let \( x \) be an element in \( \alpha \) such that for every \( y \) in \( \alpha \) with \( r y x \), \( y \) is accessible with respect to \( r \). We need to show that \( x \) is accessible with respect to the transitive closure of \( r \).

To show this, we need to prove that for every \( y \) in \( \alpha \) such that \( \text{TransGen}(r) \, y \, x \) holds, \( y \) is accessible with respect to the transitive closure of \( r \).

1. **Single Step Case:**
- Suppose \( \text{TransGen}(r) \, y \, x \) is a single step, i.e., \( r y x \) holds.
- By the induction hypothesis, \( y \) is accessible with respect to \( r \).
- Therefore, \( y \) is also accessible with respect to the transitive closure of \( r \).

2. **Multi-Step Case:**
- Suppose \( \text{TransGen}(r) \, y \, x \) is a multi-step relation, i.e., there exists some \( z \) in \( \alpha \) such that \( \text{TransGen}(r) \, y \, z \) and \( r z x \) hold.
- By the induction hypothesis, \( z \) is accessible with respect to the transitive closure of \( r \).
- Since \( r z x \) holds, and accessibility is preserved by the relation \( r \), \( y \) is also accessible with respect to the transitive closure of \( r \).

Thus, in both cases, \( y \) is accessible with respect to the transitive closure of \( r \). Therefore, \( x \) is accessible with respect to the transitive closure of \( r \). This completes the proof. \(\blacksquare\)","theorem Acc.transGen (h : Acc r a) : Acc (TransGen r) a := by
  induction h with
/- Perform induction on the accessibility of \( a \) with respect to \( r \) and consider the following cases: For any \( x \) in \( \alpha \), if \( h \) states that for every \( y \) such that \( r y x \) holds, \( y \) is accessible with respect to \( r \), and \( H \) states that for every \( y \) such that \( r y x \) holds, \( y \) is accessible with respect to the transitive closure of \( r \), then we need to show that \( x \) is accessible with respect to the transitive closure of \( r \). -/
  | intro x _ H =>
/- To show that \( x \) is accessible with respect to the transitive closure of \( r \), we need to show that for every \( y \) such that \( \text{TransGen}(r) \, y \, x \) holds, \( y \) is accessible with respect to the transitive closure of \( r \). So now it suffices to show that for every \( y \) such that \( \text{TransGen}(r) \, y \, x \) holds, \( y \) is accessible with respect to the transitive closure of \( r \). -/
    refine Acc.intro x fun y hy ↦ ?_
    cases hy with
/- Consider the case where \( \text{TransGen}(r) \, y \, x \) is a single step, i.e., \( r y x \) holds. In this case, we need to show that \( y \) is accessible with respect to the transitive closure of \( r \). -/
    | single hyx =>
/- Since \( H \) states that for every \( y \) such that \( r y x \) holds, \( y \) is accessible with respect to the transitive closure of \( r \), and \( hyx \) states that \( r y x \) holds, the current goal is exactly proved by \( H \, y \, hyx \). -/
      exact H y hyx
/- Consider the case where \( \text{TransGen}(r) \, y \, x \) is a multi-step relation, i.e., there exists some \( z \) such that \( \text{TransGen}(r) \, y \, z \) and \( r z x \) hold. In this case, we need to show that \( y \) is accessible with respect to the transitive closure of \( r \). -/
    | tail hyz hzx =>
/- Since \( H \) states that for any \( y \) and \( z \) such that \( r y z \) holds, \( y \) is accessible with respect to the transitive closure of \( r \), and \( hzx \) states that \( r z x \) holds, we can use the fact that accessibility is preserved by the relation \( r \) to conclude that \( y \) is accessible with respect to the transitive closure of \( r \). Therefore, the current goal is exactly proved by \( (H \, z \, hzx).inv \, hyz \). -/
/- Since \( H \) states that for any \( y \) and \( z \) such that \( r y z \) holds, \( y \) is accessible with respect to the transitive closure of \( r \), and \( hzx \) states that \( r z x \) holds, we can use the fact that accessibility is preserved by the relation \( r \) to conclude that \( y \) is accessible with respect to the transitive closure of \( r \). Therefore, the current goal is exactly proved by \( (H \, z \, hzx).inv \, hyz \). -/
      exact (H _ hzx).inv hyz","import Init.SizeOf
import Init.Data.Nat.Basic
import Init.WF

open Acc
variable {α : Sort u} {r : α → α → Prop}
variable {α : Sort u} {r : α → α → Prop} (hwf : WellFounded r)
variable {C : α → Sort v}
variable (F : ∀ x, (∀ y, r y x → C y) → C x)
variable (F : ∀ x, (∀ y, r y x → C y) → C x)
variable {α : Sort u} {C : α → Sort v} {r : α → α → Prop}
open WellFounded
variable {α : Sort u} {r q : α → α → Prop}
variable {α : Sort u} {β : Sort v} {r : β → β → Prop}
open Relation
"
22780,PSigma.lexAccessible,"theorem PSigma.lexAccessible {a} (aca : Acc r a) (acb : (a : α) → WellFounded (s a)) (b : β a) : Acc (Lex r s) ⟨a, b⟩ := by sorry","Accessibility of Lexicographic Order on Dependent Pair Type: \(\text{Acc}(\text{Lex}(r, s)) \langle a, b \rangle\) : For any types \(\alpha\) and \(\beta\) where \(\beta\) is a family of types indexed by \(\alpha\), and for any relations \(r\) on \(\alpha\) and \(s\) on \(\beta a\) for each \(a \in \alpha\), if \(a\) is accessible under \(r\) and for every \(a \in \alpha\), the relation \(s a\) is well-founded, then for any \(b \in \beta a\), the dependent pair \(\langle a, b \rangle\) is accessible under the lexicographic order \(\text{Lex}(r, s)\).","theorem PSigma.lexAccessible {a} (aca : Acc r a) (acb : (a : α) → WellFounded (s a)) (b : β a) : Acc (Lex r s) ⟨a, b⟩ := by
  induction aca with
  | intro xa _ iha =>
    induction (WellFounded.apply (acb xa) b) with
    | intro xb _ ihb =>
      apply Acc.intro
      intro p lt
      cases lt with
      | left  => apply iha; assumption
      | right => apply ihb; assumption","We need to show that for any \(a \in \alpha\) and \(b \in \beta a\), the dependent pair \(\langle a, b \rangle\) is accessible under the lexicographic order \(\text{Lex}(r, s)\).

1. **Base Case:**
- We perform induction on the accessibility of \(a\) under the relation \(r\). For the base case, we introduce a new element \(xa\) and the induction hypothesis `iha` which states that for any \(y\) such that \(r y xa\), the dependent pair \(\langle y, b \rangle\) is accessible under the lexicographic order.
- We also perform induction on the well-foundedness of the relation \(s\) at \(xa\). For the base case, we introduce a new element \(xb\) and the induction hypothesis `ihb` which states that for any \(y\) such that \(s xa y xb\), the dependent pair \(\langle xa, y \rangle\) is accessible under the lexicographic order.

2. **Inductive Step:**
- To show that the dependent pair \(\langle xa, xb \rangle\) is accessible under the lexicographic order, we use the constructor `Acc.intro`. This means we need to show that for any pair \(\langle y, z \rangle\) such that \(\text{Lex}(r, s) \langle y, z \rangle \langle xa, xb \rangle\), the pair \(\langle y, z \rangle\) is accessible under the lexicographic order.
- We introduce a new pair \(p\) and the assumption `lt` that \(\text{Lex}(r, s) p \langle xa, xb \rangle\). We need to show that \(p\) is accessible under the lexicographic order.

3. **Case Analysis:**
- **Case 1: \(\text{Lex}(r, s) \langle y, z \rangle \langle xa, xb \rangle\) is determined by the first component:**
- We use the induction hypothesis `iha` to show that the dependent pair \(\langle y, b \rangle\) is accessible under the lexicographic order. Since the hypothesis `iha` already provides the necessary condition, this case is immediately resolved.
- **Case 2: \(\text{Lex}(r, s) \langle y, z \rangle \langle xa, xb \rangle\) is determined by the second component:**
- We use the induction hypothesis `ihb` to show that the dependent pair \(\langle xa, y \rangle\) is accessible under the lexicographic order. Since the hypothesis `ihb` already provides the necessary condition, this case is immediately resolved.

Thus, we have shown that for any \(a \in \alpha\) and \(b \in \beta a\), the dependent pair \(\langle a, b \rangle\) is accessible under the lexicographic order \(\text{Lex}(r, s)\). This completes the proof. \(\blacksquare\)","theorem PSigma.lexAccessible {a} (aca : Acc r a) (acb : (a : α) → WellFounded (s a)) (b : β a) : Acc (Lex r s) ⟨a, b⟩ := by
  induction aca with
/- We perform induction on the accessibility of \(a\) under the relation \(r\). For the base case, we introduce a new element \(xa\) and the induction hypothesis `iha` which states that for any \(y\) such that \(r y xa\), the dependent pair \(\langle y, b \rangle\) is accessible under the lexicographic order. -/
  | intro xa _ iha =>
    induction (WellFounded.apply (acb xa) b) with
/- We perform induction on the well-foundedness of the relation \(s\) at \(xa\). For the base case, we introduce a new element \(xb\) and the induction hypothesis `ihb` which states that for any \(y\) such that \(s xa y xb\), the dependent pair \(\langle xa, y \rangle\) is accessible under the lexicographic order. -/
    | intro xb _ ihb =>
/- To show that the dependent pair \(\langle xa, xb \rangle\) is accessible under the lexicographic order, we use the constructor `Acc.intro`. This means we need to show that for any pair \(\langle y, z \rangle\) such that \(\text{Lex}(r, s) \langle y, z \rangle \langle xa, xb \rangle\), the pair \(\langle y, z \rangle\) is accessible under the lexicographic order. -/
      apply Acc.intro
/- We introduce a new pair \(p\) and the assumption `lt` that \(\text{Lex}(r, s) p \langle xa, xb \rangle\). We need to show that \(p\) is accessible under the lexicographic order. -/
      intro p lt
      cases lt with
/- In the case where the lexicographic order is determined by the first component, we use the induction hypothesis `iha` to show that the dependent pair \(\langle y, b \rangle\) is accessible under the lexicographic order. Since the hypothesis `iha` already provides the necessary condition, this case is immediately resolved. -/
      | left  => apply iha; assumption
/- In the case where the lexicographic order is determined by the second component, we use the induction hypothesis `ihb` to show that the dependent pair \(\langle a, b \rangle\) is accessible under the lexicographic order. Since the hypothesis `ihb` already provides the necessary condition, this case is immediately resolved. -/
/- We perform induction on the well-foundedness of the relation \(s\) at \(xa\). For the base case, we introduce a new element \(xb\) and the induction hypothesis `ihb` which states that for any \(y\) such that \(s xa y xb\), the dependent pair \(\langle xa, y \rangle\) is accessible under the lexicographic order. -/
/- In the case where the lexicographic order is determined by the second component, we use the induction hypothesis `ihb` to show that the dependent pair \(\langle xa, y \rangle\) is accessible under the lexicographic order. Since the hypothesis `ihb` already provides the necessary condition, this case is immediately resolved. -/
      | right => apply ihb; assumption","import Init.SizeOf
import Init.Data.Nat.Basic
import Init.WF

open PSigma
variable {α : Sort u} {r : α → α → Prop}
variable {α : Sort u} {r : α → α → Prop} (hwf : WellFounded r)
variable {C : α → Sort v}
variable (F : ∀ x, (∀ y, r y x → C y) → C x)
variable (F : ∀ x, (∀ y, r y x → C y) → C x)
variable {α : Sort u} {C : α → Sort v} {r : α → α → Prop}
open WellFounded
variable {α : Sort u} {r q : α → α → Prop}
variable {α : Sort u} {β : Sort v} {r : β → β → Prop}
open Relation
open WellFounded
variable {α : Type u} {β : Type v}
variable  (ra  : α → α → Prop)
variable  (rb  : β → β → Prop)
variable  (ra  : α → α → Prop)
variable  (rb  : β → β → Prop)
variable  (rb  : β → β → Prop)
variable {α : Type u} {β : Type v}
variable {ra  : α → α → Prop} {rb  : β → β → Prop}
variable {ra  : α → α → Prop} {rb  : β → β → Prop}
variable {α : Sort u} {β : α → Sort v}
variable  (r  : α → α → Prop)
variable  (s  : ∀ a, β a → β a → Prop)
variable  (r  : α → α → Prop)
variable  (s  : ∀ a, β a → β a → Prop)
variable  (s  : ∀ a, β a → β a → Prop)
variable {α : Sort u} {β : α → Sort v}
variable {r  : α → α → Prop} {s : ∀ (a : α), β a → β a → Prop}
variable {r  : α → α → Prop} {s : ∀ (a : α), β a → β a → Prop}
"
24007,Nat.lcm_zero_left,theorem Nat.lcm_zero_left (m : Nat) : lcm 0 m = 0 := by sorry,"Least Common Multiple with Zero: \(\text{lcm}(0, m) = 0\) : For any natural number \( m \), the least common multiple (LCM) of \( 0 \) and \( m \) is \( 0 \), i.e., \(\text{lcm}(0, m) = 0\).","theorem Nat.lcm_zero_left (m : Nat) : lcm 0 m = 0 := by
  simp [lcm]","To prove that \(\text{lcm}(0, m) = 0\) for any natural number \( m \), we use the definition of the least common multiple (LCM). The LCM of two numbers \( a \) and \( b \) is the smallest positive integer that is a multiple of both \( a \) and \( b \). However, when one of the numbers is \( 0 \), the LCM is defined to be \( 0 \) because \( 0 \) is a multiple of any natural number. Therefore, by the definition of LCM, we have \(\text{lcm}(0, m) = 0\). This completes the proof. \(\blacksquare\)","theorem Nat.lcm_zero_left (m : Nat) : lcm 0 m = 0 := by
  simp [lcm]","import Init.Data.Nat.Gcd
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Lcm

open Nat

"
24008,Nat.lcm_zero_right,theorem Nat.lcm_zero_right (m : Nat) : lcm m 0 = 0 := by sorry,"Least Common Multiple with Zero: \(\text{lcm}(m, 0) = 0\) : For any natural number \( m \), the least common multiple (LCM) of \( m \) and \( 0 \) is \( 0 \), i.e., \(\text{lcm}(m, 0) = 0\).","theorem Nat.lcm_zero_right (m : Nat) : lcm m 0 = 0 := by
  simp [lcm]","To prove that \(\text{lcm}(m, 0) = 0\) for any natural number \( m \), we use the definition of the least common multiple (LCM). The LCM of two natural numbers \( m \) and \( n \) is the smallest natural number that is a multiple of both \( m \) and \( n \). When \( n = 0 \), the LCM of \( m \) and \( 0 \) is \( 0 \) because \( 0 \) is a multiple of any natural number. Therefore, \(\text{lcm}(m, 0) = 0\). This completes the proof.","theorem Nat.lcm_zero_right (m : Nat) : lcm m 0 = 0 := by
  simp [lcm]","import Init.Data.Nat.Gcd
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Lcm

open Nat

"
24011,Nat.lcm_one_left,theorem Nat.lcm_one_left (m : Nat) : lcm 1 m = m := by sorry,"LCM of One and Any Natural Number Equals the Number: \(\text{lcm}(1, m) = m\) : For any natural number \( m \), the least common multiple (LCM) of 1 and \( m \) is equal to \( m \), i.e., \(\text{lcm}(1, m) = m\).","theorem Nat.lcm_one_left (m : Nat) : lcm 1 m = m := by
  simp [lcm]","To prove that \(\text{lcm}(1, m) = m\) for any natural number \( m \), we start by using the definition of the least common multiple (LCM). The LCM of two natural numbers \(a\) and \(b\) is given by the formula:
\[
\text{lcm}(a, b) = \frac{a \cdot b}{\text{gcd}(a, b)}
\]
where \(\text{gcd}(a, b)\) is the greatest common divisor of \(a\) and \(b\).

In our case, we have \(a = 1\) and \(b = m\). The greatest common divisor of 1 and \(m\) is 1, i.e., \(\text{gcd}(1, m) = 1\). Substituting this into the LCM formula, we get:
\[
\text{lcm}(1, m) = \frac{1 \cdot m}{1} = m
\]
Thus, the least common multiple of 1 and \(m\) is indeed \(m\). Therefore, we have shown that \(\text{lcm}(1, m) = m\) for any natural number \(m\). This completes the proof. \(\blacksquare\)","theorem Nat.lcm_one_left (m : Nat) : lcm 1 m = m := by
  simp [lcm]","import Init.Data.Nat.Gcd
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Lcm

open Nat

"
24014,Nat.lcm_one_right,theorem Nat.lcm_one_right (m : Nat) : lcm m 1 = m := by sorry,"LCM Identity: \(\text{lcm}(m, 1) = m\) : For any natural number \( m \), the least common multiple (LCM) of \( m \) and 1 is equal to \( m \), i.e., \(\text{lcm}(m, 1) = m\).","theorem Nat.lcm_one_right (m : Nat) : lcm m 1 = m := by
  simp [lcm]","To prove that \(\text{lcm}(m, 1) = m\) for any natural number \( m \), we use the definition of the least common multiple (LCM). The LCM of two natural numbers \( a \) and \( b \) is the smallest natural number that is a multiple of both \( a \) and \( b \).

1. By the definition of LCM, \(\text{lcm}(m, 1)\) is the smallest natural number that is a multiple of both \( m \) and 1.
2. Since 1 is a divisor of every natural number, any multiple of \( m \) is also a multiple of 1.
3. Therefore, the smallest multiple of both \( m \) and 1 is \( m \) itself.
4. Hence, \(\text{lcm}(m, 1) = m\).

This completes the proof.","theorem Nat.lcm_one_right (m : Nat) : lcm m 1 = m := by
  simp [lcm]","import Init.Data.Nat.Gcd
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Lcm

open Nat

"
24021,Nat.lcm_self,theorem Nat.lcm_self (m : Nat) : lcm m m = m := by sorry,"LCM is Idempotent: \(\text{lcm}(m, m) = m\) : For any natural number \( m \), the least common multiple of \( m \) and itself is equal to \( m \), i.e., \(\text{lcm}(m, m) = m\).","theorem Nat.lcm_self (m : Nat) : lcm m m = m := by
  match eq_zero_or_pos m with
  | .inl h => rw [h, lcm_zero_left]
  | .inr h => simp [lcm, Nat.mul_div_cancel _ h]","We need to show that \(\text{lcm}(m, m) = m\) for any natural number \( m \).

1. **Case 1: \( m = 0 \)**
- By the definition of the least common multiple, \(\text{lcm}(0, m) = 0\) for any \( m \).
- Therefore, \(\text{lcm}(0, 0) = 0\).

2. **Case 2: \( m \neq 0 \)**
- By the definition of the least common multiple, \(\text{lcm}(m, m)\) is the smallest positive integer that is a multiple of both \( m \) and \( m \).
- Since \( m \) is a multiple of itself, \(\text{lcm}(m, m) = m\).
- This can be shown using the property that \( m \cdot \left(\frac{m}{m}\right) = m \), where \(\frac{m}{m} = 1\) because \( m \neq 0 \).

Thus, in both cases, we have \(\text{lcm}(m, m) = m\). This completes the proof.","theorem Nat.lcm_self (m : Nat) : lcm m m = m := by
  match eq_zero_or_pos m with
/- First, consider the case where \( m = 0 \). By the definition of the least common multiple, \(\text{lcm}(0, m) = 0\) for any \( m \). Therefore, \(\text{lcm}(0, 0) = 0\). -/
  | .inl h => rw [h, lcm_zero_left]
/- Next, consider the case where \( m \neq 0 \). By the definition of the least common multiple, \(\text{lcm}(m, m)\) is the smallest positive integer that is a multiple of both \( m \) and \( m \). Since \( m \) is a multiple of itself, \(\text{lcm}(m, m) = m\). This can be shown using the property that \( m \cdot \left(\frac{m}{m}\right) = m \), where \(\frac{m}{m} = 1\) because \( m \neq 0 \). -/
  | .inr h => simp [lcm, Nat.mul_div_cancel _ h]","import Init.Data.Nat.Gcd
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Lcm

open Nat

"
24022,Nat.lcm_comm,theorem Nat.lcm_comm (m n : Nat) : lcm m n = lcm n m := by sorry,"Commutativity of LCM: \(\text{lcm}(m, n) = \text{lcm}(n, m)\) : For any natural numbers \( m \) and \( n \), the least common multiple (LCM) of \( m \) and \( n \) is equal to the LCM of \( n \) and \( m \), i.e., \(\text{lcm}(m, n) = \text{lcm}(n, m)\).","theorem Nat.lcm_comm (m n : Nat) : lcm m n = lcm n m := by
  rw [lcm, lcm, Nat.mul_comm n m, gcd_comm n m]","To prove that \(\text{lcm}(m, n) = \text{lcm}(n, m)\), we start by using the definition of the least common multiple (LCM). The LCM of two natural numbers \( m \) and \( n \) is defined as:
\[
\text{lcm}(m, n) = \frac{m \cdot n}{\gcd(m, n)}
\]
Applying this definition to both sides of the equation, we get:
\[
\frac{m \cdot n}{\gcd(m, n)} = \frac{n \cdot m}{\gcd(n, m)}
\]
Next, we use the commutativity of multiplication, which states that \( m \cdot n = n \cdot m \), to rewrite the right-hand side:
\[
\frac{m \cdot n}{\gcd(m, n)} = \frac{m \cdot n}{\gcd(n, m)}
\]
Finally, we use the commutativity of the greatest common divisor (GCD), which states that \(\gcd(m, n) = \gcd(n, m)\), to rewrite the right-hand side again:
\[
\frac{m \cdot n}{\gcd(m, n)} = \frac{m \cdot n}{\gcd(m, n)}
\]
Since both sides of the equation are now identical, the equality holds. Therefore, we have shown that \(\text{lcm}(m, n) = \text{lcm}(n, m)\). This completes the proof. \(\blacksquare\)","theorem Nat.lcm_comm (m n : Nat) : lcm m n = lcm n m := by
/- First, we use the definition of the least common multiple (LCM) to rewrite the goal. The LCM of \( m \) and \( n \) is defined as \(\frac{m \cdot n}{\gcd(m, n)}\). Applying this definition to both sides of the equation, we get:
\[
m \cdot n / \gcd(m, n) = n \cdot m / \gcd(n, m)
\]
Next, we use the commutativity of multiplication, which states that \( m \cdot n = n \cdot m \), to rewrite the right-hand side:
\[
m \cdot n / \gcd(m, n) = m \cdot n / \gcd(n, m)
\]
Finally, we use the commutativity of the greatest common divisor (GCD), which states that \(\gcd(m, n) = \gcd(n, m)\), to rewrite the right-hand side again:
\[
m \cdot n / \gcd(m, n) = m \cdot n / \gcd(m, n)
\]
Since both sides of the equation are now identical, the goal is trivially true. -/
  rw [lcm, lcm, Nat.mul_comm n m, gcd_comm n m]","import Init.Data.Nat.Gcd
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Lcm

open Nat

"
24025,Nat.lcm_ne_zero,theorem Nat.lcm_ne_zero (hm : m ≠ 0) (hn : n ≠ 0) : lcm m n ≠ 0 := by sorry,"Nonzero LCM of Nonzero Natural Numbers : For any natural numbers \( m \) and \( n \) such that \( m \neq 0 \) and \( n \neq 0 \), their least common multiple (LCM) is also nonzero, i.e., \( \text{lcm}(m, n) \neq 0 \).","theorem Nat.lcm_ne_zero (hm : m ≠ 0) (hn : n ≠ 0) : lcm m n ≠ 0 := by
  intro h
  have h1 := gcd_mul_lcm m n
  rw [h, Nat.mul_zero] at h1
  match mul_eq_zero.1 h1.symm with
  | .inl hm1 => exact hm hm1
  | .inr hn1 => exact hn hn1","We start by assuming that \( \text{lcm}(m, n) = 0 \) and show that this leads to a contradiction.

1. Let \( h \) be the assumption that \( \text{lcm}(m, n) = 0 \). We need to show that this leads to a contradiction, i.e., \( \text{False} \).

2. We know from the property of the greatest common divisor (gcd) and the least common multiple (lcm) that \( \gcd(m, n) \cdot \text{lcm}(m, n) \) is associated with \( m \cdot n \). Let \( h1 \) be this property, i.e., \( \gcd(m, n) \cdot \text{lcm}(m, n) = m \cdot n \).

3. Since \( \text{lcm}(m, n) = 0 \) by assumption \( h \), we can substitute \( 0 \) for \( \text{lcm}(m, n) \) in \( h1 \). Using the property that any natural number multiplied by \( 0 \) is \( 0 \), we get \( 0 = m \cdot n \).

4. We now consider the equation \( 0 = m \cdot n \). If \( m \neq 0 \) (which is given by \( hm \)), then \( n \) must be \( 0 \) for the product to be \( 0 \). This contradicts the assumption \( n \neq 0 \) (given by \( hn \)).

5. Similarly, if \( n \neq 0 \) (which is given by \( hn \)), then \( m \) must be \( 0 \) for the product to be \( 0 \). This contradicts the assumption \( m \neq 0 \) (given by \( hm \)).

Since both cases lead to a contradiction, our assumption that \( \text{lcm}(m, n) = 0 \) must be false. Therefore, \( \text{lcm}(m, n) \neq 0 \). This completes the proof.","theorem Nat.lcm_ne_zero (hm : m ≠ 0) (hn : n ≠ 0) : lcm m n ≠ 0 := by
/- Let \( h \) be the assumption that \( \text{lcm}(m, n) = 0 \). We need to show that this leads to a contradiction, i.e., \( \text{False} \). -/
  intro h
/- We know from the property of the greatest common divisor (gcd) and the least common multiple (lcm) that \( \gcd(m, n) \cdot \text{lcm}(m, n) \) is associated with \( m \cdot n \). Let \( h1 \) be this property, i.e., \( \gcd(m, n) \cdot \text{lcm}(m, n) = m \cdot n \). -/
  have h1 := gcd_mul_lcm m n
/- Since \( \text{lcm}(m, n) = 0 \) by assumption \( h \), we can substitute \( 0 \) for \( \text{lcm}(m, n) \) in \( h1 \). Using the property that any natural number multiplied by \( 0 \) is \( 0 \), we get \( 0 = m \cdot n \). -/
  rw [h, Nat.mul_zero] at h1
  match mul_eq_zero.1 h1.symm with
/- We now consider the equation \( 0 = m \cdot n \). If \( m \neq 0 \) (which is given by \( hm \)), then \( n \) must be \( 0 \) for the product to be \( 0 \). This contradicts the assumption \( n \neq 0 \) (given by \( hn \)). -/
  | .inl hm1 => exact hm hm1
/- Similarly, if \( n \neq 0 \) (which is given by \( hn \)), then \( m \) must be \( 0 \) for the product to be \( 0 \). This contradicts the assumption \( m \neq 0 \) (given by \( hm \)). -/
  | .inr hn1 => exact hn hn1","import Init.Data.Nat.Gcd
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Lcm

open Nat

"
24026,Nat.gcd_mul_lcm,theorem Nat.gcd_mul_lcm (m n : Nat) : gcd m n * lcm m n = m * n := by sorry,"GCD and LCM Product Identity: \(\gcd(m, n) \cdot \text{lcm}(m, n) = m \cdot n\) : For any natural numbers \( m \) and \( n \), the product of their greatest common divisor (gcd) and their least common multiple (lcm) is equal to the product of the numbers themselves, i.e., \(\gcd(m, n) \cdot \text{lcm}(m, n) = m \cdot n\).","theorem Nat.gcd_mul_lcm (m n : Nat) : gcd m n * lcm m n = m * n := by
  rw [lcm, Nat.mul_div_cancel' (Nat.dvd_trans (gcd_dvd_left m n) (Nat.dvd_mul_right m n))]","To prove the identity \(\gcd(m, n) \cdot \text{lcm}(m, n) = m \cdot n\), we start by using the definition of the least common multiple (LCM). The LCM of \( m \) and \( n \) is defined as:
\[
\text{lcm}(m, n) = \frac{m \cdot n}{\gcd(m, n)}
\]
Substituting this into the left-hand side of the goal, we get:
\[
\gcd(m, n) \cdot \text{lcm}(m, n) = \gcd(m, n) \cdot \left( \frac{m \cdot n}{\gcd(m, n)} \right)
\]
Next, we use the fact that \(\gcd(m, n)\) divides \( m \) (i.e., \(\gcd(m, n) \mid m\)). By the transitivity of divisibility, since \(\gcd(m, n) \mid m\) and \( m \mid m \cdot n \), it follows that \(\gcd(m, n) \mid m \cdot n\). Therefore, we can apply the cancellation property of multiplication and division, which states that for any nonzero \( b \) and any \( a \), \( b \cdot \left( \frac{a}{b} \right) = a \). Here, \( b = \gcd(m, n) \) and \( a = m \cdot n \), so we have:
\[
\gcd(m, n) \cdot \left( \frac{m \cdot n}{\gcd(m, n)} \right) = m \cdot n
\]
Thus, the left-hand side simplifies to \( m \cdot n \), which is exactly the right-hand side of the goal. Therefore, we have:
\[
\gcd(m, n) \cdot \text{lcm}(m, n) = m \cdot n
\]
This completes the proof. \(\blacksquare\)","theorem Nat.gcd_mul_lcm (m n : Nat) : gcd m n * lcm m n = m * n := by
/- First, we use the definition of the least common multiple (LCM) to rewrite the goal. The LCM of \( m \) and \( n \) is defined as \(\frac{m \cdot n}{\gcd(m, n)}\). Therefore, the goal \( \gcd(m, n) \cdot \text{lcm}(m, n) = m \cdot n \) becomes \( \gcd(m, n) \cdot \left( \frac{m \cdot n}{\gcd(m, n)} \right) = m \cdot n \).

Next, we use the fact that \(\gcd(m, n)\) divides \( m \) (i.e., \(\gcd(m, n) \mid m\)) and the transitivity of divisibility to show that \(\gcd(m, n)\) divides \( m \cdot n \). Since \(\gcd(m, n)\) divides \( m \cdot n \), we can apply the cancellation property of multiplication and division, which states that for any nonzero \( b \) and any \( a \), \( b \cdot \left( \frac{a}{b} \right) = a \). Here, \( b = \gcd(m, n) \) and \( a = m \cdot n \), so we have \( \gcd(m, n) \cdot \left( \frac{m \cdot n}{\gcd(m, n)} \right) = m \cdot n \).

Thus, the goal is now \( m \cdot n = m \cdot n \), which is trivially true. -/
  rw [lcm, Nat.mul_div_cancel' (Nat.dvd_trans (gcd_dvd_left m n) (Nat.dvd_mul_right m n))]","import Init.Data.Nat.Gcd
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Lcm

open Nat

"
24044,Nat.lcm_dvd,theorem Nat.lcm_dvd {m n k : Nat} (H1 : m ∣ k) (H2 : n ∣ k) : lcm m n ∣ k := by sorry,"LCM Divides Common Multiple: \(\text{lcm}(m, n) \mid k\) if \( m \mid k \) and \( n \mid k \) : For any natural numbers \( m \), \( n \), and \( k \), if \( m \mid k \) and \( n \mid k \), then \( \text{lcm}(m, n) \mid k \).","theorem Nat.lcm_dvd {m n k : Nat} (H1 : m ∣ k) (H2 : n ∣ k) : lcm m n ∣ k := by
  match eq_zero_or_pos k with
  | .inl h => rw [h]; exact Nat.dvd_zero _
  | .inr kpos =>
    apply Nat.dvd_of_mul_dvd_mul_left (gcd_pos_of_pos_left n (pos_of_dvd_of_pos H1 kpos))
    rw [gcd_mul_lcm, ← gcd_mul_right, Nat.mul_comm n k]
    exact dvd_gcd (Nat.mul_dvd_mul_left _ H2) (Nat.mul_dvd_mul_right H1 _)","We need to show that if \( m \mid k \) and \( n \mid k \), then \( \text{lcm}(m, n) \mid k \).

1. **Case \( k = 0 \):**
- If \( k = 0 \), then \( \text{lcm}(m, n) \mid 0 \) is trivially true because any natural number divides 0.

2. **Case \( k > 0 \):**
- Assume \( k > 0 \). We need to show that \( \text{lcm}(m, n) \mid k \).
- Since \( m \mid k \) and \( k > 0 \), we have \( m > 0 \). Similarly, \( n > 0 \).
- We use the property that \( \gcd(m, n) \cdot \text{lcm}(m, n) = m \cdot n \).
- We also use the property that \( \gcd(m \cdot k, n \cdot k) = \gcd(m, n) \cdot k \).
- By the commutativity of multiplication, \( n \cdot k = k \cdot n \).
- Therefore, our goal is to show that \( m \cdot n \mid (m \cdot k) \gcd (k \cdot n) \).
- Since \( m \mid k \) and \( n \mid k \), we have \( m \cdot n \mid (m \cdot k) \) and \( n \cdot m \mid (k \cdot n) \).
- Thus, \( m \cdot n \) divides the greatest common divisor of \( m \cdot k \) and \( k \cdot n \), which is \( \gcd(m \cdot k, k \cdot n) \).
- Therefore, \( \text{lcm}(m, n) \mid k \).

This completes the proof. \(\blacksquare\)","theorem Nat.lcm_dvd {m n k : Nat} (H1 : m ∣ k) (H2 : n ∣ k) : lcm m n ∣ k := by
  match eq_zero_or_pos k with
/- If \( k = 0 \), then \( \text{lcm}(m, n) \mid 0 \) is trivially true because any natural number divides 0. -/
  | .inl h => rw [h]; exact Nat.dvd_zero _
/- Now, we consider the case where \( k > 0 \). -/
  | .inr kpos =>
/- To prove \( \text{lcm}(m, n) \mid k \), it suffices to show that \( \gcd(m, n) \cdot \text{lcm}(m, n) \mid \gcd(m, n) \cdot k \). Since \( m \mid k \) and \( k > 0 \), we have \( m > 0 \). Therefore, \( \gcd(m, n) > 0 \). Using the property that if \( k \cdot m \mid k \cdot n \) and \( k > 0 \), then \( m \mid n \), we can conclude that \( \text{lcm}(m, n) \mid k \). -/
    apply Nat.dvd_of_mul_dvd_mul_left (gcd_pos_of_pos_left n (pos_of_dvd_of_pos H1 kpos))
/- We use the properties of gcd and lcm to rewrite the goal. First, we use the fact that \( \gcd(m, n) \cdot \text{lcm}(m, n) = m \cdot n \). Then, we use the property that \( \gcd(m \cdot k, n \cdot k) = \gcd(m, n) \cdot k \). Finally, we use the commutativity of multiplication to rewrite \( n \cdot k \) as \( k \cdot n \). This simplifies our goal to \( m \cdot n \mid (m \cdot k) \gcd (k \cdot n) \). -/
    rw [gcd_mul_lcm, ← gcd_mul_right, Nat.mul_comm n k]
/- First, we use the fact that if \( m \mid k \) and \( n \mid k \), then \( m \cdot n \mid (m \cdot k) \gcd (k \cdot n) \). This is because \( m \mid k \) implies \( m \cdot n \mid k \cdot n \) and \( n \mid k \) implies \( n \cdot m \mid k \cdot m \). Therefore, \( m \cdot n \) divides the greatest common divisor of \( m \cdot k \) and \( k \cdot n \). -/
/- We conclude that \( m \cdot n \mid (m \cdot k) \gcd (k \cdot n) \) by using the fact that \( m \mid k \) and \( n \mid k \) imply \( m \cdot n \mid (m \cdot k) \) and \( n \cdot m \mid (k \cdot n) \). Therefore, \( m \cdot n \) divides the greatest common divisor of \( m \cdot k \) and \( k \cdot n \). -/
    exact dvd_gcd (Nat.mul_dvd_mul_left _ H2) (Nat.mul_dvd_mul_right H1 _)","import Init.Data.Nat.Gcd
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Lcm

open Nat

"
25185,Option.bind_some,theorem Option.bind_some (x : Option α) : x.bind some = x := by sorry,"Option Bind with Some Constructor Equals Original Option : For any type \( \alpha \) and any optional value \( x : \text{Option} \, \alpha \), if \( x \) is `some a` for some \( a : \alpha \), then \( x \) bound with the `some` constructor is equal to \( x \). In other words, if \( x \) is a valid optional value, then applying the `some` constructor to the value inside \( x \) results in \( x \) itself.","theorem Option.bind_some (x : Option α) : x.bind some = x := by
  cases x <;> rfl","We need to show that for any \( x : \text{Option} \, \alpha \), the equation \( x.bind \text{some} = x \) holds. We will consider the two possible cases for \( x \):

1. **Case 1: \( x = \text{none} \)**
- The `bind` operation on `none` with any function results in `none`. Therefore, \(\text{none.bind some} = \text{none}\). This is trivially true.

2. **Case 2: \( x = \text{some } a \) for some \( a : \alpha \)**
- The `bind` operation on `some a` with the `some` constructor results in `some a`. Therefore, \((\text{some } a).bind \text{some} = \text{some } a\). This is also trivially true.

Since both cases are trivially true, the theorem holds for any \( x : \text{Option} \, \alpha \). This completes the proof. \(\blacksquare\)","theorem Option.bind_some (x : Option α) : x.bind some = x := by
  cases x <;> rfl","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25187,Option.join_ne_none,"theorem Option.join_ne_none : x.join ≠ none ↔ ∃ z, x = some (some z) := by sorry","Join of Optional Type is Not None if and only if Original Value is Some Some: \( x.join \neq \text{none} \leftrightarrow \exists z, x = \text{some } (\text{some } z) \) : For any type \( \alpha \) and any `Option` of `Option` values \( x \), the join operation on \( x \) is not equal to `none` if and only if there exists an element \( z \in \alpha \) such that \( x \) is equal to `some (some z)`. In other words, \( x.join \neq \text{none} \) if and only if \( \exists z, x = \text{some } (\text{some } z) \).","theorem Option.join_ne_none : x.join ≠ none ↔ ∃ z, x = some (some z) := by
  simp only [ne_none_iff_exists', join_eq_some, iff_self]","We need to show that \( x.join \neq \text{none} \) if and only if there exists an element \( z \in \alpha \) such that \( x = \text{some } (\text{some } z) \).

1. **Simplification:**
- We use the equivalence that \( x \neq \text{none} \) is equivalent to the existence of some \( y \) such that \( x = \text{some } y \).
- We also use the fact that the join operation on \( x \) is equal to \( \text{some } z \) if and only if \( x = \text{some } (\text{some } z) \).
- Finally, we use the fact that the bi-implication \( p \leftrightarrow p \) is logically equivalent to the true proposition.

2. **Conclusion:**
- After simplification, the goal is reduced to showing that \( x \neq \text{none} \) if and only if there exists an element \( z \) such that \( x = \text{some } (\text{some } z) \).

Thus, we have shown that \( x.join \neq \text{none} \) if and only if \( \exists z, x = \text{some } (\text{some } z) \). This completes the proof.","theorem Option.join_ne_none : x.join ≠ none ↔ ∃ z, x = some (some z) := by
/- We simplify the proposition we want to show using the following lemmas:
- The statement \( x \neq \text{none} \) is equivalent to the existence of some \( y \) such that \( x = \text{some } y \).
- The join operation on \( x \) is equal to \( \text{some } z \) if and only if \( x = \text{some } (\text{some } z) \).
- The bi-implication \( p \leftrightarrow p \) is logically equivalent to the true proposition.

After simplification, the goal is reduced to showing that \( x \neq \text{none} \) if and only if there exists an element \( z \) such that \( x = \text{some } (\text{some } z) \). This completes the proof. -/
  simp only [ne_none_iff_exists', join_eq_some, iff_self]","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25188,Option.bind_eq_none',"theorem Option.bind_eq_none' {o : Option α} {f : α → Option β} :
    o.bind f = none ↔ ∀ b a, a ∈ o → b ∉ f a := by sorry","Option Bind Equals None if and only if Function Maps Members to None : For any types \( \alpha \) and \( \beta \), and for any optional value \( o : \text{Option} \, \alpha \) and function \( f : \alpha \to \text{Option} \, \beta \), the expression \( o \bind f \) is equal to `none` if and only if for every \( b : \beta \) and \( a : \alpha \), if \( a \in o \), then \( b \notin f(a) \).","theorem Option.bind_eq_none' {o : Option α} {f : α → Option β} :
    o.bind f = none ↔ ∀ b a, a ∈ o → b ∉ f a := by
  simp only [eq_none_iff_forall_not_mem, not_exists, not_and, mem_def, bind_eq_some]","We start by simplifying the proposition using the following theorems and definitions:
1. The equivalence that \( o \bind f = \text{none} \) if and only if for all \( b : \beta \) and \( a : \alpha \), if \( a \in o \), then \( b \notin f(a) \).
2. The equivalence that the non-existence of an element \( x \) in \( \alpha \) that satisfies \( p(x) \) is equivalent to the statement that for all elements \( x \) in \( \alpha \), \( p(x) \) does not hold.
3. The equivalence that the negation of the conjunction of two propositions \( a \) and \( b \) is equivalent to \( a \) implying the negation of \( b \).
4. The definition of membership in an `Option` type.
5. The definition of the `Option.bind` function.

Using these, we can rewrite the original statement as:
\[ o \bind f = \text{none} \leftrightarrow \forall (b : \beta) (a : \alpha), a \in o \to b \notin f(a) \]

This equivalence is trivially true by the definitions and theorems used. Therefore, the theorem is proved.","theorem Option.bind_eq_none' {o : Option α} {f : α → Option β} :
    o.bind f = none ↔ ∀ b a, a ∈ o → b ∉ f a := by
/- We simplify the proposition we want to show using the following theorems and definitions:
- The equivalence that \( o \bind f = \text{none} \) if and only if for all \( b : \beta \) and \( a : \alpha \), if \( a \in o \), then \( b \notin f(a) \).
- The equivalence that the non-existence of an element \( x \) in \( \alpha \) that satisfies \( p(x) \) is equivalent to the statement that for all elements \( x \) in \( \alpha \), \( p(x) \) does not hold.
- The equivalence that the negation of the conjunction of two propositions \( a \) and \( b \) is equivalent to \( a \) implying the negation of \( b \).
- The definition of membership in an `Option` type.
- The definition of the `Option.bind` function.

After simplification, the goal is trivially true. -/
  simp only [eq_none_iff_forall_not_mem, not_exists, not_and, mem_def, bind_eq_some]","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25190,Option.map_comp_map,"theorem Option.map_comp_map (f : α → β) (g : β → γ) :
    Option.map g ∘ Option.map f = Option.map (g ∘ f) := by sorry","Composition of `Option.map` Functions Equals `Option.map` of Composition : For any types \( \alpha \), \( \beta \), and \( \gamma \), and any functions \( f : \alpha \to \beta \) and \( g : \beta \to \gamma \), the composition of the `Option.map` functions applied to \( f \) and \( g \) is equal to the `Option.map` function applied to the composition of \( f \) and \( g \). Formally, for any \( x : \text{Option } \alpha \):
\[
\text{Option.map } g \circ \text{Option.map } f \, x = \text{Option.map } (g \circ f) \, x
\]","theorem Option.map_comp_map (f : α → β) (g : β → γ) :
    Option.map g ∘ Option.map f = Option.map (g ∘ f) := by
  funext x; simp","To prove the equality of the functions \(\text{Option.map } g \circ \text{Option.map } f\) and \(\text{Option.map } (g \circ f)\), we use the principle of function extensionality. This principle states that two functions are equal if they yield the same result for all possible arguments. Therefore, it suffices to show that for all \( x \in \text{Option } \alpha \), the following holds:
\[
(\text{Option.map } g \circ \text{Option.map } f) \, x = \text{Option.map } (g \circ f) \, x
\]

This completes the proof.","theorem Option.map_comp_map (f : α → β) (g : β → γ) :
    Option.map g ∘ Option.map f = Option.map (g ∘ f) := by
  funext x; simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25191,Option.not_isSome,theorem Option.not_isSome : isSome a = false ↔ a.isNone = true := by sorry,"Is Some False if and only if Is None True: \( a.\text{isSome} = \text{false} \leftrightarrow a.\text{isNone} = \text{true} \) : For any type \( \alpha \) and any `Option` value \( a \) of type \( \alpha \), the predicate \( a.\text{isSome} = \text{false} \) is equivalent to \( a.\text{isNone} = \text{true} \). In other words, \( a \) is not `Some` if and only if \( a \) is `None`.","theorem Option.not_isSome : isSome a = false ↔ a.isNone = true := by
  cases a <;> simp","To prove the equivalence \( a.\text{isSome} = \text{false} \leftrightarrow a.\text{isNone} = \text{true} \), we will consider every possible case of \( a \).

1. **Case 1: \( a = \text{none} \)**
- We need to show that \( \text{none.isSome} = \text{false} \leftrightarrow \text{none.isNone} = \text{true} \).
- By the definition of the `Option` type, \( \text{none.isSome} = \text{false} \) and \( \text{none.isNone} = \text{true} \).
- Therefore, \( \text{false} \leftrightarrow \text{true} \) is true.

2. **Case 2: \( a = \text{some } val \)**
- We need to show that \( (\text{some } val).isSome = \text{false} \leftrightarrow (\text{some } val).isNone = \text{true} \).
- By the definition of the `Option` type, \( (\text{some } val).isSome = \text{true} \) and \( (\text{some } val).isNone = \text{false} \).
- Therefore, \( \text{true} \leftrightarrow \text{false} \) is false.

Since both cases are covered and the simplifications are valid, we conclude that \( a.\text{isSome} = \text{false} \leftrightarrow a.\text{isNone} = \text{true} \). This completes the proof. \(\blacksquare\)","theorem Option.not_isSome : isSome a = false ↔ a.isNone = true := by
/- We will consider every possible case of \( a \). There are two cases to consider: \( a = \text{none} \) and \( a = \text{some } val \).

1. **Case 1: \( a = \text{none} \)**
- We need to show that \( \text{none.isSome} = \text{false} \leftrightarrow \text{none.isNone} = \text{true} \).
- Simplifying the proposition, we get \( \text{false} \leftrightarrow \text{true} \), which is true by the definition of the `Option` type.

2. **Case 2: \( a = \text{some } val \)**
- We need to show that \( (\text{some } val).isSome = \text{false} \leftrightarrow (\text{some } val).isNone = \text{true} \).
- Simplifying the proposition, we get \( \text{true} \leftrightarrow \text{false} \), which is false by the definition of the `Option` type.

Since both cases are covered and the simplifications are valid, the proof is complete. -/
  cases a <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25193,Option.bind_none,theorem Option.bind_none (x : Option α) : x.bind (fun _ => none (α := β)) = none := by sorry,"Option Bind with None Function Always Results in None : For any types \( \alpha \) and \( \beta \), and for any optional value \( x : \text{Option} \, \alpha \), the expression \( x \bind (\lambda a. \text{none}) \) is equal to `none`. In other words, if the function \( f \) always returns `none`, then the result of binding \( x \) with \( f \) is `none`.","theorem Option.bind_none (x : Option α) : x.bind (fun _ => none (α := β)) = none := by
  cases x <;> rfl","We need to show that for any \( x : \text{Option} \, \alpha \), the expression \( x \bind (\lambda a. \text{none}) \) is equal to `none`.

We will consider every possible case of \( x \):

**Case 1:**
If \( x = \text{none} \), then the expression \( x \bind (\lambda a. \text{none}) \) is \( \text{none} \bind (\lambda a. \text{none}) \). By the definition of the bind operation on `Option`, this is equal to `none`. Therefore, the goal \( \text{none} \bind (\lambda a. \text{none}) = \text{none} \) is trivially true due to the reflexive property.

**Case 2:**
If \( x = \text{some} \, val \) for some \( val \in \alpha \), then the expression \( x \bind (\lambda a. \text{none}) \) is \( \text{some} \, val \bind (\lambda a. \text{none}) \). By the definition of the bind operation on `Option`, this is equal to \( (\lambda a. \text{none}) \, val \), which is `none`. Therefore, the goal \( (\text{some} \, val) \bind (\lambda a. \text{none}) = \text{none} \) is trivially true due to the reflexive property.

Since both cases are covered, we conclude that for any \( x : \text{Option} \, \alpha \), the expression \( x \bind (\lambda a. \text{none}) \) is equal to `none`. This completes the proof.","theorem Option.bind_none (x : Option α) : x.bind (fun _ => none (α := β)) = none := by
/- We will consider every possible case of \( x \).

**Case 1:**
If \( x = \text{none} \), then the expression \( x \bind (\lambda a. \text{none}) \) is \( \text{none} \bind (\lambda a. \text{none}) \). By the definition of the bind operation on `Option`, this is equal to `none`. Therefore, the goal \( \text{none} \bind (\lambda a. \text{none}) = \text{none} \) is trivially true due to the reflexive property.

**Case 2:**
If \( x = \text{some} \, val \) for some \( val \in \alpha \), then the expression \( x \bind (\lambda a. \text{none}) \) is \( \text{some} \, val \bind (\lambda a. \text{none}) \). By the definition of the bind operation on `Option`, this is equal to \( (\lambda a. \text{none}) \, val \), which is `none`. Therefore, the goal \( (\text{some} \, val) \bind (\lambda a. \text{none}) = \text{none} \) is trivially true due to the reflexive property. -/
  cases x <;> rfl","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25194,Option.bind_eq_none,"theorem Option.bind_eq_none {o : Option α} {f : α → Option β} :
    o.bind f = none ↔ ∀ a, o = some a → f a = none := by sorry","Option Bind Equals None if and only if Function Maps Some to None : For any types \( \alpha \) and \( \beta \), and for any optional value \( o : \text{Option} \, \alpha \) and function \( f : \alpha \to \text{Option} \, \beta \), the expression \( o \bind f \) is equal to `none` if and only if for every \( a : \alpha \), if \( o = \text{some} \, a \), then \( f(a) = \text{none} \).","theorem Option.bind_eq_none {o : Option α} {f : α → Option β} :
    o.bind f = none ↔ ∀ a, o = some a → f a = none := by
  cases o <;> simp","We will consider every possible case of the optional value \( o \). There are two cases:

1. **Case 1: \( o = \text{none} \)**
- We need to show that \( \text{none} \bind f = \text{none} \) if and only if for every \( a : \alpha \), \( \text{none} = \text{some} \, a \) implies \( f(a) = \text{none} \).
- Since \( \text{none} = \text{some} \, a \) is always false, the right-hand side of the equivalence is trivially true. Therefore, the equivalence holds.

2. **Case 2: \( o = \text{some} \, a \)**
- We need to show that \( (\text{some} \, a) \bind f = \text{none} \) if and only if for every \( a' : \alpha \), \( \text{some} \, a = \text{some} \, a' \) implies \( f(a') = \text{none} \).
- Since \( \text{some} \, a = \text{some} \, a' \) implies \( a = a' \), the right-hand side of the equivalence simplifies to \( f(a) = \text{none} \). Therefore, the equivalence holds.

In both cases, the equivalence \( o \bind f = \text{none} \) if and only if for every \( a : \alpha \), if \( o = \text{some} \, a \), then \( f(a) = \text{none} \) is satisfied. This completes the proof.","theorem Option.bind_eq_none {o : Option α} {f : α → Option β} :
    o.bind f = none ↔ ∀ a, o = some a → f a = none := by
  cases o <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25195,Option.getD_of_ne_none,theorem Option.getD_of_ne_none {x : Option α} (hx : x ≠ none) (y : α) : some (x.getD y) = x := by sorry,"Optional Value with Default is Some if Not None: $\text{some} (x.\text{getD} \, y) = x$ if $x \neq \text{none}$ : For any type $\alpha$ and any optional value $x : \text{Option} \, \alpha$, if $x$ is not `none`, then for any value $y : \alpha$, the optional value `some (x.getD y)` is equal to $x$.","theorem Option.getD_of_ne_none {x : Option α} (hx : x ≠ none) (y : α) : some (x.getD y) = x := by
  cases x; {contradiction}; rw [getD_some]","We start by performing case analysis on the optional value $x$.

1. **Case 1: $x = \text{none}$**
- The assumption $x \neq \text{none}$ contradicts the case $x = \text{none}$. Therefore, this case is impossible.

2. **Case 2: $x = \text{some} \, a$ for some $a \in \alpha$**
- We need to show that `some (x.\text{getD} \, y) = x`.
- By the definition of `getD`, we have `some (some a).getD y = some a`.
- Since `some a` is equal to `x`, the goal is satisfied.

Thus, in both cases, the goal is satisfied, and the theorem is proved. $\blacksquare$","theorem Option.getD_of_ne_none {x : Option α} (hx : x ≠ none) (y : α) : some (x.getD y) = x := by
/- We perform case analysis on the optional value $x$. If $x$ is `none`, then the assumption $x \neq \text{none}$ leads to a contradiction, so this case is impossible. If $x$ is `some a` for some value $a \in \alpha$, we use the property that `getD` of `some a` with any default value $y$ is $a$. Therefore, the goal reduces to showing that `some (some a).getD y = some a`, which is true by the definition of `getD`. -/
  cases x; {contradiction}; rw [getD_some]","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25197,Option.ne_none_iff_isSome,theorem Option.ne_none_iff_isSome : o ≠ none ↔ o.isSome := by sorry,"Not Equal to None if and only if Is Some: $o \neq \text{none} \leftrightarrow \text{Option.isSome } o = \text{true}$ : For any type $\alpha$ and any element $o$ of the `Option` type over $\alpha$, the element $o$ is not equal to `none` if and only if `Option.isSome o` is `true`. In other words, $o \neq \text{none}$ if and only if $o$ is of the form `some x` for some $x \in \alpha$.","theorem Option.ne_none_iff_isSome : o ≠ none ↔ o.isSome := by
  cases o <;> simp","We will consider every possible case of $o$.

1. **Case 1: $o = \text{none}$**
- We need to show that $\text{none} \neq \text{none} \leftrightarrow \text{Option.isSome } \text{none} = \text{true}$.
- Simplifying the left-hand side, $\text{none} \neq \text{none}$ is false.
- Simplifying the right-hand side, $\text{Option.isSome } \text{none} = \text{false}$.
- Therefore, the equivalence $\text{none} \neq \text{none} \leftrightarrow \text{Option.isSome } \text{none} = \text{true}$ is true because both sides are false.

2. **Case 2: $o = \text{some } x$ for some $x \in \alpha$**
- We need to show that $\text{some } x \neq \text{none} \leftrightarrow \text{Option.isSome } (\text{some } x) = \text{true}$.
- Simplifying the left-hand side, $\text{some } x \neq \text{none}$ is true.
- Simplifying the right-hand side, $\text{Option.isSome } (\text{some } x) = \text{true}$.
- Therefore, the equivalence $\text{some } x \neq \text{none} \leftrightarrow \text{Option.isSome } (\text{some } x) = \text{true}$ is true because both sides are true.

Since both cases are true, the theorem is proved. $\blacksquare$","theorem Option.ne_none_iff_isSome : o ≠ none ↔ o.isSome := by
  cases o <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25200,Option.not_isSome_iff_eq_none,theorem Option.not_isSome_iff_eq_none : ¬o.isSome ↔ o = none := by sorry,"Option is None if and only if isSome is False : For any type \( \alpha \) and any option \( o \) of type `Option \alpha`, the option \( o \) is not `some` (i.e., \( o \) is `none`) if and only if \( o \) is equal to `none`. Formally, this can be stated as:
\[
\neg (o.\text{isSome} = \text{true}) \leftrightarrow o = \text{none}
\]","theorem Option.not_isSome_iff_eq_none : ¬o.isSome ↔ o = none := by
  cases o <;> simp","To prove the theorem, we will consider every possible case of the option \( o \). There are two cases: \( o \) is `none` or \( o \) is `some val` for some value \( val \).

1. **Case 1: \( o = \text{none} \)**
- We need to show that \( \neg (\text{none}.\text{isSome} = \text{true}) \leftrightarrow \text{none} = \text{none} \).
- By definition, `none.isSome` is `false`. Therefore, \( \neg (\text{false} = \text{true}) \) is true.
- The right-hand side is trivially true because \( \text{none} = \text{none} \).
- Thus, the equivalence holds in this case.

2. **Case 2: \( o = \text{some val} \)**
- We need to show that \( \neg (\text{some val}.\text{isSome} = \text{true}) \leftrightarrow \text{some val} = \text{none} \).
- By definition, `some val.isSome` is `true`. Therefore, \( \neg (\text{true} = \text{true}) \) is false.
- The right-hand side is false because \( \text{some val} \neq \text{none} \).
- Thus, the equivalence holds in this case as well.

Since the equivalence holds in both cases, the theorem is proven. Therefore, for any type \( \alpha \) and any option \( o \) of type `Option \alpha`, the option \( o \) is not `some` if and only if \( o \) is `none`. This completes the proof. \(\blacksquare\)","theorem Option.not_isSome_iff_eq_none : ¬o.isSome ↔ o = none := by
/- We will consider every possible case of the option \( o \). There are two cases: \( o \) is `none` or \( o \) is `some val` for some value \( val \).

1. **Case 1: \( o = \text{none} \)**
- We need to show that \( \neg (\text{none}.\text{isSome} = \text{true}) \leftrightarrow \text{none} = \text{none} \).
- Simplifying the left-hand side, we know that `none.isSome` is `false` by definition. Therefore, \( \neg (\text{false} = \text{true}) \) is true.
- The right-hand side is trivially true because \( \text{none} = \text{none} \).
- Thus, the equivalence holds in this case.

2. **Case 2: \( o = \text{some val} \)**
- We need to show that \( \neg (\text{some val}.\text{isSome} = \text{true}) \leftrightarrow \text{some val} = \text{none} \).
- Simplifying the left-hand side, we know that `some val.isSome` is `true` by definition. Therefore, \( \neg (\text{true} = \text{true}) \) is false.
- The right-hand side is false because \( \text{some val} \neq \text{none} \).
- Thus, the equivalence holds in this case as well. -/
  cases o <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25203,Option.eq_some_iff_get_eq,"theorem Option.eq_some_iff_get_eq : o = some a ↔ ∃ h : o.isSome, o.get h = a := by sorry","Option Equals Some if and only if Extracted Value Equals Given Value: \( o = \text{some } a \leftrightarrow \exists h, \text{Option.get } o \, h = a \) : For any type \( \alpha \) and any option \( o \) of type `Option \alpha`, and for any element \( a \) of type \( \alpha \), the option \( o \) is equal to `some a` if and only if there exists a proof \( h \) that \( o \) is non-empty such that the value extracted from \( o \) using \( h \) is equal to \( a \). In other words, \( o = \text{some } a \) if and only if \( \exists h, \text{Option.get } o \, h = a \).","theorem Option.eq_some_iff_get_eq : o = some a ↔ ∃ h : o.isSome, o.get h = a := by
  cases o <;> simp","We will consider every possible case of the option \( o \).

1. **Case 1: \( o = \text{none} \)**
- We need to show that \( \text{none} = \text{some } a \leftrightarrow \exists h, \text{none.get } h = a \).
- The left-hand side, \( \text{none} = \text{some } a \), is false because `none` and `some a` are different constructors.
- The right-hand side, \( \exists h, \text{none.get } h = a \), is also false because `none.get` is not defined.
- Therefore, both sides are false, and the equivalence holds.

2. **Case 2: \( o = \text{some } val \)**
- We need to show that \( \text{some } val = \text{some } a \leftrightarrow \exists h, (\text{some } val).get h = a \).
- The left-hand side, \( \text{some } val = \text{some } a \), is true if and only if \( val = a \).
- The right-hand side, \( \exists h, (\text{some } val).get h = a \), is true if and only if \( val = a \) because `(\text{some } val).get h` is defined and equals \( val \).
- Therefore, both sides are equivalent, and the equivalence holds.

Since both cases are covered, the theorem is proven.","theorem Option.eq_some_iff_get_eq : o = some a ↔ ∃ h : o.isSome, o.get h = a := by
/- We will consider every possible case of the option \( o \). There are two cases: \( o = \text{none} \) and \( o = \text{some } val \).

1. **Case 1: \( o = \text{none} \)**
- We need to show that \( \text{none} = \text{some } a \leftrightarrow \exists h, \text{none.get } h = a \).
- Simplifying the left-hand side, \( \text{none} = \text{some } a \) is false.
- Simplifying the right-hand side, \( \exists h, \text{none.get } h = a \) is also false because `none.get` is not defined.
- Therefore, both sides are false, and the equivalence holds.

2. **Case 2: \( o = \text{some } val \)**
- We need to show that \( \text{some } val = \text{some } a \leftrightarrow \exists h, (\text{some } val).get h = a \).
- Simplifying the left-hand side, \( \text{some } val = \text{some } a \) is true if and only if \( val = a \).
- Simplifying the right-hand side, \( \exists h, (\text{some } val).get h = a \) is true if and only if \( val = a \) because `(\text{some } val).get h` is defined and equals \( val \).
- Therefore, both sides are equivalent, and the equivalence holds. -/
  cases o <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25209,Option.ne_none_iff_exists,"theorem Option.ne_none_iff_exists : o ≠ none ↔ ∃ x, some x = o := by sorry","None Inequality and Existence of Some Element in Option Type : For any type \( \alpha \) and any optional value \( o : \text{Option} \, \alpha \), the statement \( o \neq \text{none} \) is equivalent to the existence of an element \( x \in \alpha \) such that \( o = \text{some} \, x \). In other words, \( o \neq \text{none} \) if and only if there exists \( x \) such that \( o = \text{some} \, x \).","theorem Option.ne_none_iff_exists : o ≠ none ↔ ∃ x, some x = o := by
  cases o <;> simp","We will consider every possible case of \( o \).

1. **Case 1: \( o = \text{none} \)**
- We need to show that \( \text{none} \neq \text{none} \leftrightarrow \exists x, \text{some} \, x = \text{none} \).
- Since \( \text{none} \neq \text{none} \) is false and there is no \( x \) such that \( \text{some} \, x = \text{none} \), the proposition simplifies to \( \text{False} \leftrightarrow \text{False} \), which is true.

2. **Case 2: \( o = \text{some} \, x \) for some \( x \in \alpha \)**
- We need to show that \( \text{some} \, x \neq \text{none} \leftrightarrow \exists y, \text{some} \, y = \text{some} \, x \).
- Since \( \text{some} \, x \neq \text{none} \) is true and there exists \( y = x \) such that \( \text{some} \, y = \text{some} \, x \), the proposition simplifies to \( \text{True} \leftrightarrow \text{True} \), which is true.

Since both cases are true, the original statement \( o \neq \text{none} \leftrightarrow \exists x, \text{some} \, x = o \) holds. This completes the proof.","theorem Option.ne_none_iff_exists : o ≠ none ↔ ∃ x, some x = o := by
  cases o <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25210,Option.liftOrGet_none_right,theorem Option.liftOrGet_none_right {f} {a : Option α} : liftOrGet f a none = a := by sorry,"Lift or Get with None on the Right: \( a \, \text{liftOrGet} \, \text{none} = a \) : For any type \( \alpha \) and a binary function \( f : \alpha \to \alpha \to \alpha \), and for any optional value \( a : \text{Option} \, \alpha \), the result of applying the `liftOrGet` function to \( a \) and `none` is \( a \). In other words, if one of the inputs to `liftOrGet` is `none`, the function returns the other input.","theorem Option.liftOrGet_none_right {f} {a : Option α} : liftOrGet f a none = a := by
  cases a <;> rfl","We need to show that for any optional value \( a \), the equation \( \text{liftOrGet} \, f \, a \, \text{none} = a \) holds. We will consider every possible case for \( a \).

1. **Case 1: \( a = \text{none} \)**
- The goal is to show that \( \text{liftOrGet} \, f \, \text{none} \, \text{none} = \text{none} \).
- This is trivially true because both sides of the equation are definitionally equal.

2. **Case 2: \( a = \text{some} \, x \) for some \( x \in \alpha \)**
- The goal is to show that \( \text{liftOrGet} \, f \, (\text{some} \, x) \, \text{none} = \text{some} \, x \).
- This is also trivially true because both sides of the equation are definitionally equal.

Since both cases are trivially true, the theorem is proved. Therefore, for any optional value \( a \), the result of applying the `liftOrGet` function to \( a \) and `none` is \( a \). This completes the proof.","theorem Option.liftOrGet_none_right {f} {a : Option α} : liftOrGet f a none = a := by
/- We will consider every possible case for the optional value \( a \). There are two cases: \( a = \text{none} \) and \( a = \text{some} \, x \) for some \( x \in \alpha \).

1. **Case 1: \( a = \text{none} \)**
- The goal is to show that \( \text{liftOrGet} \, f \, \text{none} \, \text{none} = \text{none} \).
- This is trivially true because both sides of the equation are definitionally equal.

2. **Case 2: \( a = \text{some} \, x \)**
- The goal is to show that \( \text{liftOrGet} \, f \, (\text{some} \, x) \, \text{none} = \text{some} \, x \).
- This is also trivially true because both sides of the equation are definitionally equal. -/
  cases a <;> rfl","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25211,Option.isSome_iff_exists,"theorem Option.isSome_iff_exists : isSome x ↔ ∃ a, x = some a := by sorry","Existence of Some Value in Option Type : For any type \( \alpha \) and any optional value \( x \) of type \( \text{Option } \alpha \), the condition that \( x \) is `some` (i.e., \( x.isSome = \text{true} \)) is equivalent to the existence of some element \( a \) of type \( \alpha \) such that \( x \) is equal to `some a` (i.e., \( \exists a, x = \text{some } a \)).","theorem Option.isSome_iff_exists : isSome x ↔ ∃ a, x = some a := by
  cases x <;> simp [isSome]","We will consider every possible case of \( x \).

1. **Case 1: \( x = \text{none} \)**
- We need to show that \( \text{none.isSome} = \text{true} \) is equivalent to \( \exists a, \text{none} = \text{some } a \).
- Simplifying the left-hand side using the definition of `isSome`, we get \( \text{none.isSome} = \text{false} \).
- Therefore, the left-hand side is \( \text{false} \).
- The right-hand side is \( \exists a, \text{none} = \text{some } a \), which is false because there is no \( a \) such that \( \text{none} = \text{some } a \).
- Hence, both sides are false, and the equivalence holds.

2. **Case 2: \( x = \text{some } val \) for some \( val \in \alpha \)**
- We need to show that \( (\text{some } val).isSome = \text{true} \) is equivalent to \( \exists a, \text{some } val = \text{some } a \).
- Simplifying the left-hand side using the definition of `isSome`, we get \( (\text{some } val).isSome = \text{true} \).
- Therefore, the left-hand side is \( \text{true} \).
- The right-hand side is \( \exists a, \text{some } val = \text{some } a \), which is true because we can choose \( a = val \).
- Hence, both sides are true, and the equivalence holds.

Since both cases are covered, the theorem is proved.","theorem Option.isSome_iff_exists : isSome x ↔ ∃ a, x = some a := by
  cases x <;> simp [isSome]","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25215,Option.bind_eq_some,"theorem Option.bind_eq_some : x.bind f = some b ↔ ∃ a, x = some a ∧ f a = some b := by sorry","Option Bind Equals Some if and only if Function Maps Some to Some : For any types \( \alpha \) and \( \beta \), and for any optional value \( x : \text{Option} \, \beta \) and function \( f : \beta \to \text{Option} \, \alpha \), the expression \( x \bind f \) is equal to `some b` if and only if there exists an element \( a : \beta \) such that \( x = \text{some} \, a \) and \( f(a) = \text{some} \, b \).","theorem Option.bind_eq_some : x.bind f = some b ↔ ∃ a, x = some a ∧ f a = some b := by
  cases x <;> simp","We will consider every possible case of \( x \).

1. **Case 1:** \( x = \text{none} \)
- We need to show that \( \text{none.bind} \, f = \text{some} \, b \) if and only if there exists an element \( a \) such that \( \text{none} = \text{some} \, a \) and \( f(a) = \text{some} \, b \).
- Simplifying the left-hand side, we get \( \text{none.bind} \, f = \text{none} \). Since \( \text{none} \neq \text{some} \, b \), the left-hand side is false.
- On the right-hand side, \( \text{none} = \text{some} \, a \) is false for any \( a \), so the entire right-hand side is false.
- Therefore, both sides are false, and the equivalence holds.

2. **Case 2:** \( x = \text{some} \, \text{val} \)
- We need to show that \( (\text{some} \, \text{val}).\bind f = \text{some} \, b \) if and only if there exists an element \( a \) such that \( \text{some} \, \text{val} = \text{some} \, a \) and \( f(a) = \text{some} \, b \).
- Simplifying the left-hand side, we get \( (\text{some} \, \text{val}).\bind f = f(\text{val}) \).
- On the right-hand side, \( \text{some} \, \text{val} = \text{some} \, a \) is true if and only if \( \text{val} = a \). Therefore, the right-hand side is true if and only if \( f(\text{val}) = \text{some} \, b \).
- Therefore, both sides are equivalent, and the equivalence holds.

Since both cases are covered, the theorem is proved. \(\blacksquare\)","theorem Option.bind_eq_some : x.bind f = some b ↔ ∃ a, x = some a ∧ f a = some b := by
/- We will consider every possible case of \( x \).

1. **Case 1:** \( x = \text{none} \)
- We need to show that \( \text{none.bind} \, f = \text{some} \, b \) if and only if there exists an element \( a \) such that \( \text{none} = \text{some} \, a \) and \( f(a) = \text{some} \, b \).
- Simplifying the left-hand side, we get \( \text{none.bind} \, f = \text{none} \). Since \( \text{none} \neq \text{some} \, b \), the left-hand side is false.
- On the right-hand side, \( \text{none} = \text{some} \, a \) is false for any \( a \), so the entire right-hand side is false.
- Therefore, both sides are false, and the equivalence holds.

2. **Case 2:** \( x = \text{some} \, \text{val} \)
- We need to show that \( (\text{some} \, \text{val}).\bind f = \text{some} \, b \) if and only if there exists an element \( a \) such that \( \text{some} \, \text{val} = \text{some} \, a \) and \( f(a) = \text{some} \, b \).
- Simplifying the left-hand side, we get \( (\text{some} \, \text{val}).\bind f = f(\text{val}) \).
- On the right-hand side, \( \text{some} \, \text{val} = \text{some} \, a \) is true if and only if \( \text{val} = a \). Therefore, the right-hand side is true if and only if \( f(\text{val}) = \text{some} \, b \).
- Therefore, both sides are equivalent, and the equivalence holds. -/
  cases x <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25216,Option.getD_eq_iff,theorem Option.getD_eq_iff {o : Option α} {a b} : o.getD a = b ↔ (o = some b ∨ o = none ∧ a = b) := by sorry,"Optional Value with Default Equals a Value if and only if it is Some of that Value or None with Default Equal to the Value: $o.\text{getD} \, a = b \leftrightarrow o = \text{some} \, b \lor (o = \text{none} \land a = b)$ : For any type $\alpha$ and any optional value $o : \text{Option} \, \alpha$, and for any values $a, b : \alpha$, the following holds:
\[
o.\text{getD} \, a = b \quad \text{if and only if} \quad o = \text{some} \, b \quad \text{or} \quad o = \text{none} \quad \text{and} \quad a = b.
\]","theorem Option.getD_eq_iff {o : Option α} {a b} : o.getD a = b ↔ (o = some b ∨ o = none ∧ a = b) := by
  cases o <;> simp","We will consider every possible case of the optional value $o$.

1. **Case 1: $o = \text{none}$**
- We need to show that $o.\text{getD} \, a = b$ if and only if $\text{none} = \text{some} \, b \lor (\text{none} = \text{none} \land a = b)$.
- Simplifying the left-hand side, we have $o.\text{getD} \, a = a$.
- Simplifying the right-hand side, we have $\text{none} = \text{some} \, b \lor (\text{none} = \text{none} \land a = b)$.
- Since $\text{none} = \text{some} \, b$ is false, the right-hand side simplifies to $\text{none} = \text{none} \land a = b$, which is equivalent to $a = b$.
- Therefore, $o.\text{getD} \, a = b$ is equivalent to $a = b$.

2. **Case 2: $o = \text{some} \, val$ for some value $val \in \alpha$**
- We need to show that $(\text{some} \, val).\text{getD} \, a = b$ if and only if $\text{some} \, val = \text{some} \, b \lor (\text{some} \, val = \text{none} \land a = b)$.
- Simplifying the left-hand side, we have $(\text{some} \, val).\text{getD} \, a = val$.
- Simplifying the right-hand side, we have $\text{some} \, val = \text{some} \, b \lor (\text{some} \, val = \text{none} \land a = b)$.
- Since $\text{some} \, val = \text{none}$ is false, the right-hand side simplifies to $\text{some} \, val = \text{some} \, b$, which is equivalent to $val = b$.
- Therefore, $(\text{some} \, val).\text{getD} \, a = b$ is equivalent to $val = b$.

In both cases, the proposition holds. Therefore, the theorem is proved. $\blacksquare$","theorem Option.getD_eq_iff {o : Option α} {a b} : o.getD a = b ↔ (o = some b ∨ o = none ∧ a = b) := by
/- We will consider every possible case of the optional value $o$. There are two cases: $o = \text{none}$ and $o = \text{some} \, val$ for some value $val \in \alpha$. For each case, we will simplify the proposition we want to show. -/
/- We will consider every possible case of the optional value $o$. The two cases are:
1. $o = \text{none}$
2. $o = \text{some} \, val$ for some value $val \in \alpha$ -/
/- For each of these cases, we will simplify the proposition we want to show. -/
/- For the case $o = \text{none}$, we simplify the proposition $o.\text{getD} \, a = b$ to $b = b$ and the right-hand side to $\text{none} = \text{some} \, b \lor (\text{none} = \text{none} \land a = b)$. Since $\text{none} = \text{some} \, b$ is false, the right-hand side simplifies to $\text{none} = \text{none} \land a = b$, which is equivalent to $a = b$. Therefore, the proposition $o.\text{getD} \, a = b$ is equivalent to $a = b$. -/
/- For the case $o = \text{some} \, val$, we simplify the proposition $(\text{some} \, val).\text{getD} \, a = b$ to $val = b$ and the right-hand side to $\text{some} \, val = \text{some} \, b \lor (\text{some} \, val = \text{none} \land a = b)$. Since $\text{some} \, val = \text{none}$ is false, the right-hand side simplifies to $\text{some} \, val = \text{some} \, b$, which is equivalent to $val = b$. Therefore, the proposition $(\text{some} \, val).\text{getD} \, a = b$ is equivalent to $val = b$. -/
  cases o <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25218,Option.bind_comm,"theorem Option.bind_comm {f : α → β → Option γ} (a : Option α) (b : Option β) :
    (a.bind fun x => b.bind (f x)) = b.bind fun y => a.bind fun x => f x y := by sorry","Commutativity of Option Bind Operation: $(a \bind (\lambda x, b \bind (f x))) = (b \bind (\lambda y, a \bind (\lambda x, f x y)))$ : For any types $\alpha$, $\beta$, and $\gamma$, and for any function $f : \alpha \to \beta \to \text{Option } \gamma$, and optional values $a : \text{Option } \alpha$ and $b : \text{Option } \beta$, the following equality holds:
\[
(a \bind (\lambda x, b \bind (f x))) = (b \bind (\lambda y, a \bind (\lambda x, f x y)))
\]
This theorem states that the bind operation on optional values is commutative with respect to the function $f$. In other words, the order in which the optional values $a$ and $b$ are bound to the function $f$ does not affect the result.","theorem Option.bind_comm {f : α → β → Option γ} (a : Option α) (b : Option β) :
    (a.bind fun x => b.bind (f x)) = b.bind fun y => a.bind fun x => f x y := by
  cases a <;> cases b <;> rfl","To prove the theorem, we will consider every possible case for the optional values $a$ and $b$ and show that the equality holds in each case.

1. **Case 1: $a = \text{none}$ and $b = \text{none}$**
- The left-hand side is $(\text{none} \bind (\lambda x, \text{none} \bind (f x))) = \text{none}$.
- The right-hand side is $(\text{none} \bind (\lambda y, \text{none} \bind (\lambda x, f x y))) = \text{none}$.
- Both sides are equal, so the equality holds.

2. **Case 2: $a = \text{none}$ and $b = \text{some } y$**
- The left-hand side is $(\text{none} \bind (\lambda x, \text{some } y \bind (f x))) = \text{none}$.
- The right-hand side is $(\text{some } y \bind (\lambda y, \text{none} \bind (\lambda x, f x y))) = \text{none}$.
- Both sides are equal, so the equality holds.

3. **Case 3: $a = \text{some } x$ and $b = \text{none}$**
- The left-hand side is $(\text{some } x \bind (\lambda x, \text{none} \bind (f x))) = \text{none}$.
- The right-hand side is $(\text{none} \bind (\lambda y, \text{some } x \bind (\lambda x, f x y))) = \text{none}$.
- Both sides are equal, so the equality holds.

4. **Case 4: $a = \text{some } x$ and $b = \text{some } y$**
- The left-hand side is $(\text{some } x \bind (\lambda x, \text{some } y \bind (f x))) = \text{some } y \bind (f x y)$.
- The right-hand side is $(\text{some } y \bind (\lambda y, \text{some } x \bind (\lambda x, f x y))) = \text{some } x \bind (\lambda x, f x y)$.
- Both sides are equal, so the equality holds.

In each case, the equality holds due to the definition of the bind operation on optional values. Therefore, the theorem is proved. $\blacksquare$","theorem Option.bind_comm {f : α → β → Option γ} (a : Option α) (b : Option β) :
    (a.bind fun x => b.bind (f x)) = b.bind fun y => a.bind fun x => f x y := by
/- We will consider every possible case for the optional values $a$ and $b$. For each case, we will show that the equality $(a \bind (\lambda x, b \bind (f x))) = (b \bind (\lambda y, a \bind (\lambda x, f x y)))$ holds.

1. **Case 1: $a = \text{none}$ and $b = \text{none}$**
- The left-hand side is $(\text{none} \bind (\lambda x, \text{none} \bind (f x))) = \text{none}$.
- The right-hand side is $(\text{none} \bind (\lambda y, \text{none} \bind (\lambda x, f x y))) = \text{none}$.
- Both sides are equal, so the equality holds.

2. **Case 2: $a = \text{none}$ and $b = \text{some } y$**
- The left-hand side is $(\text{none} \bind (\lambda x, \text{some } y \bind (f x))) = \text{none}$.
- The right-hand side is $(\text{some } y \bind (\lambda y, \text{none} \bind (\lambda x, f x y))) = \text{none}$.
- Both sides are equal, so the equality holds.

3. **Case 3: $a = \text{some } x$ and $b = \text{none}$**
- The left-hand side is $(\text{some } x \bind (\lambda x, \text{none} \bind (f x))) = \text{none}$.
- The right-hand side is $(\text{none} \bind (\lambda y, \text{some } x \bind (\lambda x, f x y))) = \text{none}$.
- Both sides are equal, so the equality holds.

4. **Case 4: $a = \text{some } x$ and $b = \text{some } y$**
- The left-hand side is $(\text{some } x \bind (\lambda x, \text{some } y \bind (f x))) = \text{some } y \bind (f x y)$.
- The right-hand side is $(\text{some } y \bind (\lambda y, \text{some } x \bind (\lambda x, f x y))) = \text{some } x \bind (\lambda x, f x y)$.
- Both sides are equal, so the equality holds.

In each case, the equality holds due to the definition of the bind operation on optional values. Therefore, the theorem is proved. -/
  cases a <;> cases b <;> rfl","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25220,Option.map_orElse,theorem Option.map_orElse {x y : Option α} : (x <|> y).map f = (x.map f <|> y.map f) := by sorry,"Map Preserves Or-Else Operation in Optional Types : For any types \( \alpha \) and \( \alpha_1 \), and any function \( f : \alpha \to \alpha_1 \), the following holds for any optional values \( x, y : \text{Option} \, \alpha \):
\[
\text{Option.map } f \, (x \, <|> \, y) = (x \, <|> \, y) \, \text{map } f
\]
In other words, applying the function \( f \) to the result of the or-else operation \( x \, <|> \, y \) is the same as performing the or-else operation on the results of applying \( f \) to \( x \) and \( y \) separately.","theorem Option.map_orElse {x y : Option α} : (x <|> y).map f = (x.map f <|> y.map f) := by
  cases x <;> simp","We will consider every possible case of \( x \).

1. **Case 1: \( x = \text{none} \)**
- We need to show:
\[
\text{Option.map } f \, (\text{none} \, <|> \, y) = (\text{none} \, <|> \, y) \, \text{map } f
\]
- By the definition of the or-else operation, \(\text{none} \, <|> \, y = y\).
- Therefore, the left-hand side becomes:
\[
\text{Option.map } f \, y
\]
- The right-hand side becomes:
\[
y \, \text{map } f
\]
- Since \(\text{Option.map } f \, y\) is the same as \(y \, \text{map } f\), the equality holds.

2. **Case 2: \( x = \text{some } val \)**
- We need to show:
\[
\text{Option.map } f \, (\text{some } val \, <|> \, y) = (\text{some } val \, <|> \, y) \, \text{map } f
\]
- By the definition of the or-else operation, \(\text{some } val \, <|> \, y = \text{some } val\).
- Therefore, the left-hand side becomes:
\[
\text{Option.map } f \, (\text{some } val) = \text{some } (f \, val)
\]
- The right-hand side becomes:
\[
\text{some } val \, \text{map } f = \text{some } (f \, val)
\]
- Since both sides are equal, the equality holds.

In both cases, the equality holds, thus proving the theorem. This completes the proof.","theorem Option.map_orElse {x y : Option α} : (x <|> y).map f = (x.map f <|> y.map f) := by
/- We will consider every possible case of \( x \). If \( x \) is `none`, we need to show:
\[
\text{Option.map } f \, (\text{none} \, <|> \, y) = (\text{none} \, <|> \, y) \, \text{map } f
\]
If \( x \) is `some val`, we need to show:
\[
\text{Option.map } f \, (\text{some } val \, <|> \, y) = (\text{some } val \, <|> \, y) \, \text{map } f
\]
In both cases, we simplify the expressions using the definitions and properties of the `Option` type and the `map` and `or-else` operations. -/
  cases x <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25223,Option.map_map,"theorem Option.map_map (h : β → γ) (g : α → β) (x : Option α) :
    (x.map g).map h = x.map (h ∘ g) := by sorry","Composition of Map Functions on Optional Values: \(\text{Option.map } h \, (\text{Option.map } g \, x) = \text{Option.map } (h \circ g) \, x\) : For any types \( \alpha \), \( \beta \), and \( \gamma \), and any functions \( g : \alpha \to \beta \) and \( h : \beta \to \gamma \), the following equality holds for any optional value \( x : \text{Option } \alpha \):
\[
\text{Option.map } h \, (\text{Option.map } g \, x) = \text{Option.map } (h \circ g) \, x
\]
This means that applying the function \( h \) to the result of applying \( g \) to the value inside \( x \) (if it is present) is the same as applying the composition \( h \circ g \) directly to the value inside \( x \).","theorem Option.map_map (h : β → γ) (g : α → β) (x : Option α) :
    (x.map g).map h = x.map (h ∘ g) := by
  cases x <;> simp only [map_none', map_some', ·∘·]","We will consider every possible case of the optional value \( x \).

1. **Case 1: \( x = \text{none} \)**
- We need to show:
\[
\text{Option.map } h \, (\text{Option.map } g \, \text{none}) = \text{Option.map } (h \circ g) \, \text{none}
\]
- By the definition of `Option.map` for `none`, we have:
\[
\text{Option.map } g \, \text{none} = \text{none}
\]
- Therefore:
\[
\text{Option.map } h \, (\text{Option.map } g \, \text{none}) = \text{Option.map } h \, \text{none} = \text{none}
\]
- Similarly:
\[
\text{Option.map } (h \circ g) \, \text{none} = \text{none}
\]
- Hence, the equality holds for \( x = \text{none} \).

2. **Case 2: \( x = \text{some } val \) for some value \( val \)**
- We need to show:
\[
\text{Option.map } h \, (\text{Option.map } g \, (\text{some } val)) = \text{Option.map } (h \circ g) \, (\text{some } val)
\]
- By the definition of `Option.map` for `some`, we have:
\[
\text{Option.map } g \, (\text{some } val) = \text{some } (g \, val)
\]
- Therefore:
\[
\text{Option.map } h \, (\text{Option.map } g \, (\text{some } val)) = \text{Option.map } h \, (\text{some } (g \, val)) = \text{some } (h \, (g \, val))
\]
- Similarly:
\[
\text{Option.map } (h \circ g) \, (\text{some } val) = \text{some } ((h \circ g) \, val) = \text{some } (h \, (g \, val))
\]
- Hence, the equality holds for \( x = \text{some } val \).

Since the equality holds in both cases, we conclude that:
\[
\text{Option.map } h \, (\text{Option.map } g \, x) = \text{Option.map } (h \circ g) \, x
\]
for any optional value \( x \). This completes the proof.","theorem Option.map_map (h : β → γ) (g : α → β) (x : Option α) :
    (x.map g).map h = x.map (h ∘ g) := by
/- We will consider every possible case of the optional value \( x \). If \( x \) is `none`, we need to show that:
\[
\text{Option.map } h \, (\text{Option.map } g \, \text{none}) = \text{Option.map } (h \circ g) \, \text{none}
\]
If \( x \) is `some val` for some value \( val \), we need to show that:
\[
\text{Option.map } h \, (\text{Option.map } g \, (\text{some } val)) = \text{Option.map } (h \circ g) \, (\text{some } val)
\]
We will simplify these expressions using the definitions of `Option.map` for `none` and `some` values, and the composition of functions. -/
  cases x <;> simp only [map_none', map_some', ·∘·]","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25225,Option.orElse_none,theorem Option.orElse_none (x : Option α) : (x <|> none) = x := by sorry,"Or-Else with None is Identity in Optional Types : For any type \( \alpha \) and any optional value \( x : \text{Option} \, \alpha \), the or-else operation \( x \, <|> \, \text{none} \) is equal to \( x \). In other words, if \( x \) is `some` value, the result is \( x \). If \( x \) is `none`, the result is `none`.","theorem Option.orElse_none (x : Option α) : (x <|> none) = x := by
  cases x <;> rfl","We will consider every possible case of \( x \). There are two cases:

1. **Case 1: \( x = \text{none} \)**
- In this case, the or-else operation \( \text{none} \, <|> \, \text{none} \) is defined to be `none`. Therefore, \( \text{none} \, <|> \, \text{none} = \text{none} \).

2. **Case 2: \( x = \text{some} \, v \) for some \( v \in \alpha \)**
- In this case, the or-else operation \( \text{some} \, v \, <|> \, \text{none} \) is defined to be `some` \( v \). Therefore, \( \text{some} \, v \, <|> \, \text{none} = \text{some} \, v \).

In both cases, the or-else operation \( x \, <|> \, \text{none} \) is equal to \( x \). This completes the proof.","theorem Option.orElse_none (x : Option α) : (x <|> none) = x := by
  cases x <;> rfl","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25227,Option.liftOrGet_none_left,theorem Option.liftOrGet_none_left {f} {b : Option α} : liftOrGet f none b = b := by sorry,"Lift or Get with None on the Left : For any type \( \alpha \) and a binary function \( f : \alpha \to \alpha \to \alpha \), and for any optional value \( b : \text{Option} \, \alpha \), the result of applying the `liftOrGet` function to `none` and \( b \) is \( b \). In other words, if one of the inputs to `liftOrGet` is `none`, the function returns the other input.","theorem Option.liftOrGet_none_left {f} {b : Option α} : liftOrGet f none b = b := by
  cases b <;> rfl","We need to show that for any \( b : \text{Option} \, \alpha \), \( \text{liftOrGet} \, f \, \text{none} \, b = b \).

We will consider every possible case for \( b \):

1. **Case 1: \( b = \text{none} \)**

In this case, we need to show that \( \text{liftOrGet} \, f \, \text{none} \, \text{none} = \text{none} \).

The current goal is trivially true due to the reflexive property, since both sides are definitionally equal.

2. **Case 2: \( b = \text{some} \, v \) for some \( v \in \alpha \)**

In this case, we need to show that \( \text{liftOrGet} \, f \, \text{none} \, (\text{some} \, v) = \text{some} \, v \).

The current goal is trivially true due to the reflexive property, since both sides are definitionally equal.

Since both cases are trivially true, we conclude that for any \( b : \text{Option} \, \alpha \), \( \text{liftOrGet} \, f \, \text{none} \, b = b \). This completes the proof.","theorem Option.liftOrGet_none_left {f} {b : Option α} : liftOrGet f none b = b := by
/- We will consider every possible case for \( b \). There are two cases: \( b = \text{none} \) and \( b = \text{some} \, v \) for some \( v \in \alpha \). -/
/- Case 1: \( b = \text{none} \). In this case, we need to show that \( \text{liftOrGet} \, f \, \text{none} \, \text{none} = \text{none} \). -/
/- The current goal \( \text{liftOrGet} \, f \, \text{none} \, \text{none} = \text{none} \) is trivially true due to the reflexive property, since both sides are definitionally equal. -/
/- Case 2: \( b = \text{some} \, v \). In this case, we need to show that \( \text{liftOrGet} \, f \, \text{none} \, (\text{some} \, v) = \text{some} \, v \).

The current goal \( \text{liftOrGet} \, f \, \text{none} \, (\text{some} \, v) = \text{some} \, v \) is trivially true due to the reflexive property, since both sides are definitionally equal. -/
  cases b <;> rfl","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25229,Option.isSome_map',theorem Option.isSome_map' {x : Option α} : (x.map f).isSome = x.isSome := by sorry,"Is Some Predicate is Preserved by Functorial Map in Option Type : For any types \( \alpha \) and \( \alpha_1 \), and any function \( f : \alpha \to \alpha_1 \), the predicate `isSome` applied to the result of mapping \( f \) over an `Option` value \( x \) is equal to the predicate `isSome` applied to \( x \). In other words, if \( x \) is `some a` for some \( a : \alpha \), then \( \text{Option.map } f \, x \) is also `some` (specifically, `some (f a)`), and if \( x \) is `none`, then \( \text{Option.map } f \, x \) is also `none`.","theorem Option.isSome_map' {x : Option α} : (x.map f).isSome = x.isSome := by
  cases x <;> simp","We will consider every possible case of \( x \).

1. **Case 1: \( x = \text{none} \)**
- We need to show that \((\text{Option.map } f \, \text{none}).\text{isSome} = \text{none}.\text{isSome}\).
- By the definition of `Option.map`, \(\text{Option.map } f \, \text{none} = \text{none}\).
- Therefore, \((\text{Option.map } f \, \text{none}).\text{isSome} = \text{none}.\text{isSome}\).
- This is trivially true since both sides are `false`.

2. **Case 2: \( x = \text{some } a \) for some \( a : \alpha \)**
- We need to show that \((\text{Option.map } f \, (\text{some } a)).\text{isSome} = (\text{some } a).\text{isSome}\).
- By the definition of `Option.map`, \(\text{Option.map } f \, (\text{some } a) = \text{some } (f a)\).
- Therefore, \((\text{Option.map } f \, (\text{some } a)).\text{isSome} = \text{some } (f a).\text{isSome}\).
- This is trivially true since both sides are `true`.

In both cases, the equality holds, thus proving the theorem.","theorem Option.isSome_map' {x : Option α} : (x.map f).isSome = x.isSome := by
/- We will consider every possible case of \( x \).

1. **Case 1: \( x = \text{none} \)**
- We need to show that \((\text{Option.map } f \, \text{none}).\text{isSome} = \text{none}.\text{isSome}\).
- Simplifying the left-hand side, \(\text{Option.map } f \, \text{none} = \text{none}\), so \((\text{Option.map } f \, \text{none}).\text{isSome} = \text{none}.\text{isSome}\).
- Therefore, the left-hand side is equal to the right-hand side, and the goal is trivially true.

2. **Case 2: \( x = \text{some } a \) for some \( a : \alpha \)**
- We need to show that \((\text{Option.map } f \, (\text{some } a)).\text{isSome} = (\text{some } a).\text{isSome}\).
- Simplifying the left-hand side, \(\text{Option.map } f \, (\text{some } a) = \text{some } (f a)\), so \((\text{Option.map } f \, (\text{some } a)).\text{isSome} = \text{some } (f a).\text{isSome}\).
- Therefore, the left-hand side is equal to the right-hand side, and the goal is trivially true. -/
  cases x <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25236,Option.join_map_eq_map_join,"theorem Option.join_map_eq_map_join {f : α → β} {x : Option (Option α)} :
    (x.map (Option.map f)).join = x.join.map f := by sorry","Commutativity of Join and Map Operations on Nested Optional Values : For any types \( \alpha \) and \( \beta \), and for any function \( f : \alpha \to \beta \) and any optional value \( x : \text{Option}(\text{Option} \, \alpha) \), the following equality holds:
\[
(\text{Option.map } (\text{Option.map } f) \, x).join = \text{Option.map } f \, x.join
\]
This theorem states that applying the `map` operation to the inner optional values and then flattening the result is equivalent to first flattening the optional value and then applying the `map` operation to the resulting value.","theorem Option.join_map_eq_map_join {f : α → β} {x : Option (Option α)} :
    (x.map (Option.map f)).join = x.join.map f := by
  cases x <;> simp","We will consider every possible case of \( x \). There are two cases: \( x = \text{none} \) and \( x = \text{some } val \).

**Case 1: \( x = \text{none} \)**
Using the definition of `Option.map` and `Option.join`, we simplify the expression \((\text{Option.map } (\text{Option.map } f) \, \text{none}).join\) to \(\text{none}\) and \(\text{Option.map } f \, \text{none.join}\) to \(\text{none}\). Therefore, the equality \((\text{Option.map } (\text{Option.map } f) \, \text{none}).join = \text{Option.map } f \, \text{none.join}\) holds.

**Case 2: \( x = \text{some } val \)**
Using the definition of `Option.map` and `Option.join`, we simplify the expression \((\text{Option.map } (\text{Option.map } f) \, \text{some } val).join\) to \(\text{Option.map } f \, val\) and \(\text{Option.map } f \, (\text{some } val).join\) to \(\text{Option.map } f \, val\). Therefore, the equality \((\text{Option.map } (\text{Option.map } f) \, \text{some } val).join = \text{Option.map } f \, (\text{some } val).join\) holds.

Since both cases are covered, the theorem is proven.","theorem Option.join_map_eq_map_join {f : α → β} {x : Option (Option α)} :
    (x.map (Option.map f)).join = x.join.map f := by
  cases x <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25237,Option.map_eq_some',"theorem Option.map_eq_some' : x.map f = some b ↔ ∃ a, x = some a ∧ f a = b := by sorry","Functor Map Equals Some if and Only if Existence of Some Element and Function Application : For any types \( \alpha \) and \( \alpha_1 \), any function \( f : \alpha_1 \to \alpha \), any optional value \( x : \text{Option} \, \alpha_1 \), and any element \( b : \alpha \), the following holds:
\[
\text{Option.map} \, f \, x = \text{some} \, b \quad \text{if and only if} \quad \exists a, \, x = \text{some} \, a \, \text{and} \, f \, a = b
\]
In other words, the function \( f \) applied to the optional value \( x \) results in \( \text{some} \, b \) if and only if there exists an element \( a \) such that \( x = \text{some} \, a \) and \( f \, a = b \).","theorem Option.map_eq_some' : x.map f = some b ↔ ∃ a, x = some a ∧ f a = b := by
  cases x <;> simp","We will consider every possible case of \( x \).

1. **Case 1: \( x = \text{none} \)**
- We need to show that \( \text{Option.map} \, f \, \text{none} = \text{some} \, b \) if and only if there exists an element \( a \) such that \( \text{none} = \text{some} \, a \) and \( f \, a = b \).
- Simplifying the left-hand side, we get \( \text{Option.map} \, f \, \text{none} = \text{none} \). Therefore, \( \text{none} = \text{some} \, b \) is false, and the right-hand side is also false because \( \text{none} = \text{some} \, a \) is false for any \( a \). Hence, both sides are equivalent to false, and the statement holds.

2. **Case 2: \( x = \text{some} \, a \)**
- We need to show that \( \text{Option.map} \, f \, (\text{some} \, a) = \text{some} \, b \) if and only if there exists an element \( a \) such that \( \text{some} \, a = \text{some} \, a \) and \( f \, a = b \).
- Simplifying the left-hand side, we get \( \text{Option.map} \, f \, (\text{some} \, a) = \text{some} \, (f \, a) \). Therefore, \( \text{some} \, (f \, a) = \text{some} \, b \) is true if and only if \( f \, a = b \). The right-hand side is true if and only if \( f \, a = b \). Hence, both sides are equivalent, and the statement holds.

Thus, the theorem is proven. \(\blacksquare\)","theorem Option.map_eq_some' : x.map f = some b ↔ ∃ a, x = some a ∧ f a = b := by
  cases x <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25239,Option.or_none,theorem Option.or_none : or o none = o := by sorry,"None is the Identity for Option or Function: \( o \text{ or } \text{none} = o \) : For any type \( \alpha \) and any `Option` value \( o \in \text{Option} \alpha \), the expression \( o \text{ or } \text{none} \) is equal to \( o \). In other words, the `none` element acts as the identity for the `or` function on `Option` values, i.e., \( o \text{ or } \text{none} = o \).","theorem Option.or_none : or o none = o := by
  cases o <;> rfl","To prove the theorem, we consider the two possible cases for \( o \):

1. **Case 1: \( o = \text{none} \)**
- We need to show that \( \text{none} \text{ or } \text{none} = \text{none} \).
- By the definition of the `or` function on `Option` values, \( \text{none} \text{ or } \text{none} = \text{none} \).
- Therefore, the equality holds in this case.

2. **Case 2: \( o = \text{some } val \)**
- We need to show that \( (\text{some } val) \text{ or } \text{none} = \text{some } val \).
- By the definition of the `or` function on `Option` values, \( (\text{some } val) \text{ or } \text{none} = \text{some } val \).
- Therefore, the equality holds in this case as well.

Since both cases are covered and the equality holds in each case, we conclude that for any `Option` value \( o \), \( o \text{ or } \text{none} = o \). This completes the proof.","theorem Option.or_none : or o none = o := by
/- We will consider every possible case of \( o \). There are two cases to consider: \( o = \text{none} \) and \( o = \text{some } val \).

1. **Case 1: \( o = \text{none} \)**
- The goal is to show that \( \text{none} \text{ or } \text{none} = \text{none} \).
- This is trivially true because the definition of the `or` function on `Option` values states that \( \text{none} \text{ or } \text{none} = \text{none} \).

2. **Case 2: \( o = \text{some } val \)**
- The goal is to show that \( (\text{some } val) \text{ or } \text{none} = \text{some } val \).
- This is also trivially true because the definition of the `or` function on `Option` values states that \( (\text{some } val) \text{ or } \text{none} = \text{some } val \). -/
  cases o <;> rfl","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25241,Option.getD_map,"theorem Option.getD_map (f : α → β) (x : α) (o : Option α) :
  (o.map f).getD (f x) = f (getD o x) := by sorry","Mapping and Getting with Default in Option Type: \((\text{Option.map } f \, o).getD (f \, x) = f (o.getD \, x)\) : For any types \( \alpha \) and \( \beta \), any function \( f : \alpha \to \beta \), any element \( x : \alpha \), and any optional value \( o : \text{Option } \alpha \), the following holds:
\[
(\text{Option.map } f \, o).getD (f \, x) = f (o.getD \, x)
\]
This means that applying the function \( f \) to the value obtained from the optional value \( o \) using the default value \( x \) is the same as first mapping \( f \) over \( o \) and then getting the value with the default \( f \, x \).","theorem Option.getD_map (f : α → β) (x : α) (o : Option α) :
  (o.map f).getD (f x) = f (getD o x) := by
  cases o <;> rfl","We will consider every possible case of the optional value \( o \). There are two cases: \( o \) is `none` or \( o \) is `some val` for some \( val \in \alpha \).

1. **Case 1: \( o = \text{none} \)**
- The goal is to show that \((\text{Option.map } f \, \text{none}).\text{getD} (f \, x) = f (\text{none}.\text{getD} \, x)\).
- Since \(\text{Option.map } f \, \text{none} = \text{none}\) and \(\text{none}.\text{getD} \, x = x\), the left-hand side becomes \(\text{none}.\text{getD} (f \, x) = f \, x\).
- The right-hand side is \(f (\text{none}.\text{getD} \, x) = f \, x\).
- Therefore, both sides are equal, and the goal is trivially true due to the reflexive property.

2. **Case 2: \( o = \text{some } val \)**
- The goal is to show that \((\text{Option.map } f \, (\text{some } val)).\text{getD} (f \, x) = f ((\text{some } val).\text{getD} \, x)\).
- Since \(\text{Option.map } f \, (\text{some } val) = \text{some } (f \, val)\) and \((\text{some } val).\text{getD} \, x = val\), the left-hand side becomes \((\text{some } (f \, val)).\text{getD} (f \, x) = f \, val\).
- The right-hand side is \(f ((\text{some } val).\text{getD} \, x) = f \, val\).
- Therefore, both sides are equal, and the goal is trivially true due to the reflexive property.

Thus, the theorem holds in both cases, and the proof is complete.","theorem Option.getD_map (f : α → β) (x : α) (o : Option α) :
  (o.map f).getD (f x) = f (getD o x) := by
  cases o <;> rfl","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25244,Option.map_congr,"theorem Option.map_congr {x : Option α} (h : ∀ a, a ∈ x → f a = g a) : x.map f = x.map g := by sorry","Congruence of Map Function on Optional Values: $\text{Option.map } f \, x = \text{Option.map } g \, x$ if $f(a) = g(a)$ for all $a \in x$ : For any types \( \alpha \) and \( \alpha_1 \), and any functions \( f, g : \alpha \to \alpha_1 \), if \( f \) and \( g \) are equal on all elements \( a \) that belong to the optional value \( x : \text{Option } \alpha \), then the map function applied to \( x \) with \( f \) is equal to the map function applied to \( x \) with \( g \). Formally, for any \( f, g : \alpha \to \alpha_1 \) and \( x : \text{Option } \alpha \):
\[
\forall a \in x, \, f(a) = g(a) \implies \text{Option.map } f \, x = \text{Option.map } g \, x
\]","theorem Option.map_congr {x : Option α} (h : ∀ a, a ∈ x → f a = g a) : x.map f = x.map g := by
  cases x <;> simp only [map_none', map_some', h, mem_def]","We will consider every possible case of the optional value \( x \).

1. **Case 1: \( x = \text{none} \)**
- We need to show that \(\text{Option.map } f \, \text{none} = \text{Option.map } g \, \text{none}\).
- By the definition of \(\text{Option.map}\) for \(\text{none}\), we have:
\[
\text{Option.map } f \, \text{none} = \text{none}
\]
and
\[
\text{Option.map } g \, \text{none} = \text{none}
\]
- Therefore, \(\text{Option.map } f \, \text{none} = \text{Option.map } g \, \text{none}\).

2. **Case 2: \( x = \text{some } a \)**
- We need to show that \(\text{Option.map } f \, (\text{some } a) = \text{Option.map } g \, (\text{some } a)\).
- By the definition of \(\text{Option.map}\) for \(\text{some } a\), we have:
\[
\text{Option.map } f \, (\text{some } a) = \text{some } (f a)
\]
and
\[
\text{Option.map } g \, (\text{some } a) = \text{some } (g a)
\]
- By the hypothesis \( h \), we know that \( f a = g a \) for all \( a \in x \).
- Therefore, \(\text{some } (f a) = \text{some } (g a)\), which implies:
\[
\text{Option.map } f \, (\text{some } a) = \text{Option.map } g \, (\text{some } a)
\]

Since both cases are covered, we conclude that:
\[
\forall a \in x, \, f(a) = g(a) \implies \text{Option.map } f \, x = \text{Option.map } g \, x
\]
This completes the proof.","theorem Option.map_congr {x : Option α} (h : ∀ a, a ∈ x → f a = g a) : x.map f = x.map g := by
/- We will consider every possible case of the optional value \( x \).

1. **Case 1: \( x = \text{none} \)**
- We need to show that \(\text{Option.map } f \, \text{none} = \text{Option.map } g \, \text{none}\).
- Using the definition of \(\text{Option.map}\) for \(\text{none}\), we have \(\text{Option.map } f \, \text{none} = \text{none}\) and \(\text{Option.map } g \, \text{none} = \text{none}\).
- Therefore, \(\text{Option.map } f \, \text{none} = \text{Option.map } g \, \text{none}\).

2. **Case 2: \( x = \text{some } a \)**
- We need to show that \(\text{Option.map } f \, (\text{some } a) = \text{Option.map } g \, (\text{some } a)\).
- Using the definition of \(\text{Option.map}\) for \(\text{some } a\), we have \(\text{Option.map } f \, (\text{some } a) = \text{some } (f a)\) and \(\text{Option.map } g \, (\text{some } a) = \text{some } (g a)\).
- By the hypothesis \( h \), we know that \( f a = g a \) for all \( a \in x \).
- Therefore, \(\text{some } (f a) = \text{some } (g a)\), which implies \(\text{Option.map } f \, (\text{some } a) = \text{Option.map } g \, (\text{some } a)\). -/
  cases x <;> simp only [map_none', map_some', h, mem_def]","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25247,Option.join_join,theorem Option.join_join {x : Option (Option (Option α))} : x.join.join = (x.map join).join := by sorry,"Double Join is Equivalent to Map Join and Join: \( x.\text{join}.\text{join} = (\text{Option.map } \text{join } x).\text{join} \) : For any type \( \alpha \) and any `Option` of `Option` of `Option` values \( x \), the double application of the `join` function is equivalent to applying the `join` function to the result of mapping the `join` function over \( x \). Formally, for any \( x : \text{Option}(\text{Option}(\text{Option} \alpha)) \):
\[
x.\text{join}.\text{join} = (\text{Option.map } \text{join } x).\text{join}
\]","theorem Option.join_join {x : Option (Option (Option α))} : x.join.join = (x.map join).join := by
  cases x <;> simp","We will consider every possible case of \( x \).

1. **Case 1: \( x = \text{none} \)**
- We need to show that \(\text{none}.\text{join}.\text{join} = (\text{Option.map } \text{join } \text{none}).\text{join}\).
- Simplifying the left-hand side, \(\text{none}.\text{join} = \text{none}\), and \(\text{none}.\text{join} = \text{none}\).
- Simplifying the right-hand side, \(\text{Option.map } \text{join } \text{none} = \text{none}\), and \(\text{none}.\text{join} = \text{none}\).
- Therefore, \(\text{none}.\text{join}.\text{join} = \text{none}\) and \((\text{Option.map } \text{join } \text{none}).\text{join} = \text{none}\), so the equality holds.

2. **Case 2: \( x = \text{some } y \)**
- We need to show that \((\text{some } y).\text{join}.\text{join} = (\text{Option.map } \text{join } (\text{some } y)).\text{join}\).
- Simplifying the left-hand side, \((\text{some } y).\text{join} = y.\text{join}\), and \(y.\text{join}.\text{join} = y.\text{join}.\text{join}\).
- Simplifying the right-hand side, \(\text{Option.map } \text{join } (\text{some } y) = \text{some } (y.\text{join})\), and \((\text{some } (y.\text{join})).\text{join} = y.\text{join}.\text{join}\).
- Therefore, \((\text{some } y).\text{join}.\text{join} = y.\text{join}.\text{join}\) and \((\text{Option.map } \text{join } (\text{some } y)).\text{join} = y.\text{join}.\text{join}\), so the equality holds.

Since both cases are covered, the theorem is proven. \(\blacksquare\)","theorem Option.join_join {x : Option (Option (Option α))} : x.join.join = (x.map join).join := by
/- We will consider every possible case of \( x \).

1. **Case 1: \( x = \text{none} \)**
- We need to show that \(\text{none}.\text{join}.\text{join} = (\text{Option.map } \text{join } \text{none}).\text{join}\).
- Simplifying the left-hand side, \(\text{none}.\text{join} = \text{none}\), and \(\text{none}.\text{join} = \text{none}\).
- Simplifying the right-hand side, \(\text{Option.map } \text{join } \text{none} = \text{none}\), and \(\text{none}.\text{join} = \text{none}\).
- Therefore, \(\text{none}.\text{join}.\text{join} = \text{none}\) and \((\text{Option.map } \text{join } \text{none}).\text{join} = \text{none}\), so the equality holds.

2. **Case 2: \( x = \text{some } y \)**
- We need to show that \((\text{some } y).\text{join}.\text{join} = (\text{Option.map } \text{join } (\text{some } y)).\text{join}\).
- Simplifying the left-hand side, \((\text{some } y).\text{join} = y.\text{join}\), and \(y.\text{join}.\text{join} = y.\text{join}.\text{join}\).
- Simplifying the right-hand side, \(\text{Option.map } \text{join } (\text{some } y) = \text{some } (y.\text{join})\), and \((\text{some } (y.\text{join})).\text{join} = y.\text{join}.\text{join}\).
- Therefore, \((\text{some } y).\text{join}.\text{join} = y.\text{join}.\text{join}\) and \((\text{Option.map } \text{join } (\text{some } y)).\text{join} = y.\text{join}.\text{join}\), so the equality holds. -/
  cases x <;> simp","import Init.Data.Option.BasicAux
import Init.Data.Option.Instances
import Init.Classical
import Init.Ext
import Init.Data.Option.Lemmas

open Option

"
25271,Bool.eq_false_or_eq_true,theorem Bool.eq_false_or_eq_true : (b : Bool) → b = true ∨ b = false := by sorry,"Boolean Value is True or False: \( b = \text{true} \lor b = \text{false} \) : For any boolean value \( b \), it holds that \( b = \text{true} \) or \( b = \text{false} \).","theorem Bool.eq_false_or_eq_true : (b : Bool) → b = true ∨ b = false := by
  decide","To prove that for any boolean value \( b \), \( b = \text{true} \) or \( b = \text{false} \), we use the fact that the boolean type is decidable. This means that for any boolean value \( b \), there are only two possible values: \( \text{true} \) and \( \text{false} \). Therefore, \( b \) must be either \( \text{true} \) or \( \text{false} \). This completes the proof. \(\blacksquare\)","theorem Bool.eq_false_or_eq_true : (b : Bool) → b = true ∨ b = false := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25274,Bool.eq_false_iff,theorem Bool.eq_false_iff : {b : Bool} → b = false ↔ b ≠ true := by sorry,"Boolean Value is False if and only if it is not True: \( b = \text{false} \leftrightarrow b \neq \text{true} \) : For any boolean value \( b \), \( b = \text{false} \) if and only if \( b \neq \text{true} \).","theorem Bool.eq_false_iff : {b : Bool} → b = false ↔ b ≠ true := by
  decide","We need to show that for any boolean value \( b \), the statement \( b = \text{false} \) is equivalent to \( b \neq \text{true} \).

1. **(\( \Rightarrow \) direction):** Assume \( b = \text{false} \). We need to show that \( b \neq \text{true} \). Since \( b = \text{false} \), it is clear that \( b \) cannot be equal to \(\text{true}\). Therefore, \( b \neq \text{true} \).

2. **(\( \Leftarrow \) direction):** Assume \( b \neq \text{true} \). We need to show that \( b = \text{false} \). Since \( b \) is a boolean value, it can only be either \(\text{true}\) or \(\text{false}\). Given that \( b \neq \text{true} \), the only remaining possibility is \( b = \text{false} \).

Thus, we have shown that \( b = \text{false} \) if and only if \( b \neq \text{true} \). This completes the proof.","theorem Bool.eq_false_iff : {b : Bool} → b = false ↔ b ≠ true := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25275,Bool.ne_false_iff,theorem Bool.ne_false_iff : {b : Bool} → b ≠ false ↔ b = true := by sorry,"Boolean Not Equal to False is Equivalent to True: \( b \neq \text{false} \leftrightarrow b = \text{true} \) : For any boolean value \( b \), \( b \neq \text{false} \) if and only if \( b = \text{true} \).","theorem Bool.ne_false_iff : {b : Bool} → b ≠ false ↔ b = true := by
  decide","We need to show that for any boolean value \( b \), the statement \( b \neq \text{false} \) is equivalent to \( b = \text{true} \).

1. **(\( \Rightarrow \)) Assume \( b \neq \text{false} \):**
- Since \( b \) is a boolean value, it can only be either \( \text{true} \) or \( \text{false} \).
- If \( b \neq \text{false} \), then \( b \) must be \( \text{true} \).

2. **(\( \Leftarrow \)) Assume \( b = \text{true} \):**
- If \( b = \text{true} \), then \( b \) is not equal to \( \text{false} \), i.e., \( b \neq \text{false} \).

Since both directions are proven, we conclude that for any boolean value \( b \), \( b \neq \text{false} \) if and only if \( b = \text{true} \). This completes the proof. \(\blacksquare\)","theorem Bool.ne_false_iff : {b : Bool} → b ≠ false ↔ b = true := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25276,Bool.and_self_left,"theorem Bool.and_self_left : ∀(a b : Bool), (a && (a && b)) = (a && b) := by sorry","Boolean AND Identity: $a \land (a \land b) = a \land b$ : For any boolean values $a$ and $b$, the expression $(a \land (a \land b))$ is equal to $(a \land b)$, i.e., $a \land (a \land b) = a \land b$.","theorem Bool.and_self_left : ∀(a b : Bool), (a && (a && b)) = (a && b) := by
  decide","To prove the statement for all boolean values $a$ and $b$, we use a decision procedure that automatically checks all possible cases for $a$ and $b$. Since there are only four possible combinations of $a$ and $b$ (both true, both false, $a$ true and $b$ false, $a$ false and $b$ true), the decision procedure verifies that the equation $(a \land (a \land b)) = (a \land b)$ holds in each case. This completes the proof.","theorem Bool.and_self_left : ∀(a b : Bool), (a && (a && b)) = (a && b) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25278,Bool.and_left_comm,"theorem Bool.and_left_comm : ∀ (x y z : Bool), (x && (y && z)) = (y && (x && z)) := by sorry","Left-Commutativity of Boolean AND Operation: $x \land (y \land z) = y \land (x \land z)$ : For any boolean values $x$, $y$, and $z$, the boolean ""and"" operation is left-commutative, i.e., $x \land (y \land z) = y \land (x \land z)$.","theorem Bool.and_left_comm : ∀ (x y z : Bool), (x && (y && z)) = (y && (x && z)) := by
  decide","To prove the left-commutativity of the boolean ""and"" operation, we need to show that for any boolean values $x$, $y$, and $z$, the equation $x \land (y \land z) = y \land (x \land z)$ holds. We use a decision procedure to check this equality for all possible combinations of $x$, $y$, and $z$. The decision procedure evaluates the expression for each combination and confirms that the equality holds in every case. Therefore, the left-commutativity of the boolean ""and"" operation is established. This completes the proof.","theorem Bool.and_left_comm : ∀ (x y z : Bool), (x && (y && z)) = (y && (x && z)) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25279,Bool.and_not_self,"theorem Bool.and_not_self : ∀ (x : Bool), (x && !x) = false := by sorry","Boolean AND with Negation is False: $x \land \neg x = \text{false}$ : For any boolean value $x$, the expression $x \land \neg x$ is equal to `false`, i.e., $x \land \neg x = \text{false}$.","theorem Bool.and_not_self : ∀ (x : Bool), (x && !x) = false := by
  decide","To prove that for any boolean value $x$, the expression $x \land \neg x$ is equal to `false`, we consider the two possible values of $x$:

1. **Case 1: $x = \text{true}$**
- If $x = \text{true}$, then $\neg x = \text{false}$.
- Therefore, $x \land \neg x = \text{true} \land \text{false} = \text{false}$.

2. **Case 2: $x = \text{false}$**
- If $x = \text{false}$, then $\neg x = \text{true}$.
- Therefore, $x \land \neg x = \text{false} \land \text{true} = \text{false}$.

In both cases, the expression $x \land \neg x$ evaluates to `false`. Hence, for any boolean value $x$, the expression $x \land \neg x$ is equal to `false`. This completes the proof.","theorem Bool.and_not_self : ∀ (x : Bool), (x && !x) = false := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25281,Bool.eq_false_and_eq_true_self,"theorem Bool.eq_false_and_eq_true_self : ∀(b : Bool), (b = false ∧ b = true) ↔ False := by sorry","Boolean Value Cannot be Both False and True: \( b = \text{false} \land b = \text{true} \leftrightarrow \text{False} \) : For any boolean value \( b \), if \( b \) is equal to `false` and \( b \) is equal to `true`, then the conjunction \( b = \text{false} \land b = \text{true} \) is equivalent to the false proposition, i.e., \( b = \text{false} \land b = \text{true} \leftrightarrow \text{False} \).","theorem Bool.eq_false_and_eq_true_self : ∀(b : Bool), (b = false ∧ b = true) ↔ False := by
  decide","We need to show that for any boolean value \( b \), the statement \( b = \text{false} \land b = \text{true} \) is equivalent to the false proposition.

Since \( b \) can only be either `false` or `true`, it is impossible for \( b \) to be both `false` and `true` at the same time. Therefore, the conjunction \( b = \text{false} \land b = \text{true} \) is always false. This means that the statement \( b = \text{false} \land b = \text{true} \) is equivalent to the false proposition, i.e., \( b = \text{false} \land b = \text{true} \leftrightarrow \text{False} \).

Thus, the theorem is proved.","theorem Bool.eq_false_and_eq_true_self : ∀(b : Bool), (b = false ∧ b = true) ↔ False := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25282,Bool.not_and_self,"theorem Bool.not_and_self : ∀ (x : Bool), (!x && x) = false := by sorry","Boolean Negation AND Identity: $\neg x \land x = \text{false}$ : For any boolean value $x$, the expression $\neg x \land x$ is equal to `false`, i.e., $\neg x \land x = \text{false}$.","theorem Bool.not_and_self : ∀ (x : Bool), (!x && x) = false := by
  decide","To prove that $\neg x \land x = \text{false}$ for any boolean value $x$, we consider the two possible values of $x$:
1. If $x = \text{true}$, then $\neg x = \text{false}$. Therefore, $\neg x \land x = \text{false} \land \text{true} = \text{false}$.
2. If $x = \text{false}$, then $\neg x = \text{true}$. Therefore, $\neg x \land x = \text{true} \land \text{false} = \text{false}$.

In both cases, the expression $\neg x \land x$ evaluates to `false`. Hence, the statement $\neg x \land x = \text{false}$ holds for all boolean values $x$. This completes the proof.","theorem Bool.not_and_self : ∀ (x : Bool), (!x && x) = false := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25283,Bool.decide_eq_false,theorem Bool.decide_eq_false {b : Bool} [Decidable (b = false)] : decide (b = false) = !b := by sorry,"Decide Equality to False is Boolean Negation: \(\text{decide}(b = \text{false}) = \neg b\) : For any boolean value \( b \), if the proposition \( b = \text{false} \) is decidable, then the function `decide` applied to \( b = \text{false} \) returns the negation of \( b \), i.e., \(\text{decide}(b = \text{false}) = \neg b\).","theorem Bool.decide_eq_false {b : Bool} [Decidable (b = false)] : decide (b = false) = !b := by
  cases b <;> simp","We need to show that for any boolean value \( b \), the function \(\text{decide}(b = \text{false})\) returns the negation of \( b \). We will consider every possible case of \( b \).

- **Case 1:** If \( b = \text{false} \), we need to show that \(\text{decide}(b = \text{false}) = \neg b\). Since \( b = \text{false} \), we have \(\text{decide}(\text{false} = \text{false}) = \neg \text{false}\). Simplifying, we get \(\text{decide}(\text{true}) = \text{true}\), which is true.
- **Case 2:** If \( b = \text{true} \), we need to show that \(\text{decide}(b = \text{false}) = \neg b\). Since \( b = \text{true} \), we have \(\text{decide}(\text{true} = \text{false}) = \neg \text{true}\). Simplifying, we get \(\text{decide}(\text{false}) = \text{false}\), which is true.

In both cases, the proposition holds. Therefore, for any boolean value \( b \), \(\text{decide}(b = \text{false}) = \neg b\). This completes the proof. \(\blacksquare\)","theorem Bool.decide_eq_false {b : Bool} [Decidable (b = false)] : decide (b = false) = !b := by
  cases b <;> simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25285,Bool.eq_false_or_eq_true_self,"theorem Bool.eq_false_or_eq_true_self : ∀(b : Bool), (b = false ∨ b = true) ↔ True := by sorry","Boolean Value is Either False or True : For any boolean value \( b \), the disjunction \( b = \text{false} \lor b = \text{true} \) is always true, i.e., \( b = \text{false} \lor b = \text{true} \leftrightarrow \text{True} \).","theorem Bool.eq_false_or_eq_true_self : ∀(b : Bool), (b = false ∨ b = true) ↔ True := by
  decide","We need to show that for any boolean value \( b \), the disjunction \( b = \text{false} \lor b = \text{true} \) is always true. Since a boolean value can only be either \(\text{false}\) or \(\text{true}\), the disjunction \( b = \text{false} \lor b = \text{true} \) is always true. Therefore, the statement \( b = \text{false} \lor b = \text{true} \leftrightarrow \text{True} \) holds. This completes the proof.","theorem Bool.eq_false_or_eq_true_self : ∀(b : Bool), (b = false ∨ b = true) ↔ True := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25286,Bool.iff_or_self,"theorem Bool.iff_or_self : ∀(a b : Bool), (b = (a || b)) ↔ (a → b) := by sorry","Boolean Identity: \( b = (a \lor b) \leftrightarrow (a = \text{true} \to b = \text{true}) \) : For any boolean values \( a \) and \( b \), \( b = (a \lor b) \) if and only if \( a = \text{true} \) implies \( b = \text{true} \).","theorem Bool.iff_or_self : ∀(a b : Bool), (b = (a || b)) ↔ (a → b) := by
  decide","To prove the boolean identity \( b = (a \lor b) \leftrightarrow (a = \text{true} \to b = \text{true}) \), we use the `decide` tactic. This tactic evaluates the boolean expressions and checks the equivalence directly. It confirms that for all boolean values \( a \) and \( b \), the statement holds true. Therefore, the theorem is proven.

\(\blacksquare\)","theorem Bool.iff_or_self : ∀(a b : Bool), (b = (a || b)) ↔ (a → b) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25287,Bool.not_or_self,"theorem Bool.not_or_self : ∀ (x : Bool), (!x || x) = true := by sorry","Negation or Self is True: $\neg x \lor x = \text{true}$ : For any boolean value $x$, the expression $\neg x \lor x$ is equal to `true`, i.e., $\neg x \lor x = \text{true}$.","theorem Bool.not_or_self : ∀ (x : Bool), (!x || x) = true := by
  decide","To prove that for any boolean value $x$, the expression $\neg x \lor x$ is equal to `true`, we consider the two possible values of $x$:

1. **Case 1: $x = \text{true}$**
- If $x = \text{true}$, then $\neg x = \text{false}$.
- Therefore, $\neg x \lor x = \text{false} \lor \text{true} = \text{true}$.

2. **Case 2: $x = \text{false}$**
- If $x = \text{false}$, then $\neg x = \text{true}$.
- Therefore, $\neg x \lor x = \text{true} \lor \text{false} = \text{true}$.

In both cases, the expression $\neg x \lor x$ evaluates to `true`. Hence, for any boolean value $x$, $\neg x \lor x = \text{true}$. This completes the proof.","theorem Bool.not_or_self : ∀ (x : Bool), (!x || x) = true := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25291,Bool.decide_eq_true,theorem Bool.decide_eq_true {b : Bool} [Decidable (b = true)]  : decide (b = true)  =  b := by sorry,"Decidability of True Bi-implication: \( \text{decide}(b = \text{true}) = b \) : For any boolean value \( b \), if \( b = \text{true} \) is decidable, then the function `decide (b = \text{true})` returns \( b \). In other words, \( \text{decide}(b = \text{true}) = b \).","theorem Bool.decide_eq_true {b : Bool} [Decidable (b = true)]  : decide (b = true)  =  b := by
  cases b <;> simp","We need to show that for any boolean value \( b \), the function \(\text{decide}(b = \text{true})\) returns \( b \). We will consider every possible case of \( b \).

1. **Case 1: \( b = \text{false} \)**
- We need to show that \(\text{decide}(\text{false} = \text{true}) = \text{false}\).
- Since \(\text{false} = \text{true}\) is false, \(\text{decide}(\text{false} = \text{true})\) is \(\text{false}\).
- Therefore, \(\text{decide}(\text{false} = \text{true}) = \text{false}\), which is true.

2. **Case 2: \( b = \text{true} \)**
- We need to show that \(\text{decide}(\text{true} = \text{true}) = \text{true}\).
- Since \(\text{true} = \text{true}\) is true, \(\text{decide}(\text{true} = \text{true})\) is \(\text{true}\).
- Therefore, \(\text{decide}(\text{true} = \text{true}) = \text{true}\), which is true.

Since both cases are true, we conclude that for any boolean value \( b \), \(\text{decide}(b = \text{true}) = b\). This completes the proof.","theorem Bool.decide_eq_true {b : Bool} [Decidable (b = true)]  : decide (b = true)  =  b := by
  cases b <;> simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25293,Bool.or_not_self,"theorem Bool.or_not_self : ∀ (x : Bool), (x || !x) = true := by sorry","Boolean Or with Negation is True: \( x \lor \neg x = \text{true} \) : For any boolean value \( x \), the expression \( x \lor \neg x \) is equal to `true`, i.e., \( x \lor \neg x = \text{true} \).","theorem Bool.or_not_self : ∀ (x : Bool), (x || !x) = true := by
  decide","To prove that \( x \lor \neg x = \text{true} \) for any boolean value \( x \), we consider the two possible values of \( x \):
1. If \( x = \text{true} \), then \( x \lor \neg x = \text{true} \lor \neg \text{true} = \text{true} \lor \text{false} = \text{true} \).
2. If \( x = \text{false} \), then \( x \lor \neg x = \text{false} \lor \neg \text{false} = \text{false} \lor \text{true} = \text{true} \).

In both cases, the expression \( x \lor \neg x \) evaluates to `true`. Therefore, the statement \( x \lor \neg x = \text{true} \) holds for all boolean values \( x \). This completes the proof.","theorem Bool.or_not_self : ∀ (x : Bool), (x || !x) = true := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25294,Bool.and_or_distrib_right,"theorem Bool.and_or_distrib_right : ∀ (x y z : Bool), ((x || y) && z) = (x && z || y && z) := by sorry","Distributivity of Boolean OR over AND: $(x \lor y) \land z = (x \land z) \lor (y \land z)$ : For any boolean values $x$, $y$, and $z$, the boolean expression $(x \lor y) \land z$ is equal to $(x \land z) \lor (y \land z)$, i.e., $(x \lor y) \land z = (x \land z) \lor (y \land z)$.","theorem Bool.and_or_distrib_right : ∀ (x y z : Bool), ((x || y) && z) = (x && z || y && z) := by
  decide","To prove the distributivity of Boolean OR over AND, we need to show that for any boolean values $x$, $y$, and $z$, the expression $(x \lor y) \land z$ is equal to $(x \land z) \lor (y \land z)$. We use a decision procedure to check the equality for all possible boolean values of $x$, $y$, and $z$. The decision procedure confirms that the equality holds for all combinations of $x$, $y$, and $z$. Therefore, the distributivity of Boolean OR over AND is established. This completes the proof.","theorem Bool.and_or_distrib_right : ∀ (x y z : Bool), ((x || y) && z) = (x && z || y && z) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25295,Bool.and_iff_left_iff_imp,"theorem Bool.and_iff_left_iff_imp : ∀(a b : Bool), ((a && b) = a) ↔ (a → b) := by sorry","Boolean AND Identity: \( (a \land b) = a \leftrightarrow (a = \text{true} \to b = \text{true}) \) : For any boolean values \( a \) and \( b \), the boolean ""and"" operation \( a \land b \) is equal to \( a \) if and only if \( a \) is `true` implies \( b \) is `true`.","theorem Bool.and_iff_left_iff_imp : ∀(a b : Bool), ((a && b) = a) ↔ (a → b) := by
  decide","To prove the statement \( (a \land b) = a \leftrightarrow (a = \text{true} \to b = \text{true}) \), we consider all possible boolean values for \( a \) and \( b \):

1. **Case 1: \( a = \text{true} \) and \( b = \text{true} \)**
- \( a \land b = \text{true} \land \text{true} = \text{true} \)
- \( a = \text{true} \)
- \( b = \text{true} \)
- Therefore, \( (a \land b) = a \) and \( a = \text{true} \to b = \text{true} \) both hold.

2. **Case 2: \( a = \text{true} \) and \( b = \text{false} \)**
- \( a \land b = \text{true} \land \text{false} = \text{false} \)
- \( a = \text{true} \)
- \( b = \text{false} \)
- Therefore, \( (a \land b) \neq a \) and \( a = \text{true} \to b = \text{true} \) does not hold.

3. **Case 3: \( a = \text{false} \) and \( b = \text{true} \)**
- \( a \land b = \text{false} \land \text{true} = \text{false} \)
- \( a = \text{false} \)
- \( b = \text{true} \)
- Therefore, \( (a \land b) = a \) and \( a = \text{true} \to b = \text{true} \) does not hold (since the antecedent \( a = \text{true} \) is false).

4. **Case 4: \( a = \text{false} \) and \( b = \text{false} \)**
- \( a \land b = \text{false} \land \text{false} = \text{false} \)
- \( a = \text{false} \)
- \( b = \text{false} \)
- Therefore, \( (a \land b) = a \) and \( a = \text{true} \to b = \text{true} \) does not hold (since the antecedent \( a = \text{true} \) is false).

In all cases, the statement \( (a \land b) = a \leftrightarrow (a = \text{true} \to b = \text{true}) \) holds true. This completes the proof.","theorem Bool.and_iff_left_iff_imp : ∀(a b : Bool), ((a && b) = a) ↔ (a → b) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25296,Bool.and_self_right,"theorem Bool.and_self_right : ∀(a b : Bool), ((a && b) && b) = (a && b) := by sorry","Boolean AND Identity: $a \land b \land b = a \land b$ : For any boolean values $a$ and $b$, the expression $(a \land b \land b)$ is equal to $(a \land b)$, i.e., $a \land b \land b = a \land b$.","theorem Bool.and_self_right : ∀(a b : Bool), ((a && b) && b) = (a && b) := by
  decide","To prove that for any boolean values $a$ and $b$, the expression $(a \land b \land b)$ is equal to $(a \land b)$, we can directly evaluate all possible cases for $a$ and $b$. Since there are only four possible combinations of $a$ and $b$ (both true, both false, $a$ true and $b$ false, $a$ false and $b$ true), we can check each case individually to verify the equality.

1. **Case 1: $a = \text{true}$ and $b = \text{true}$**
\[
(a \land b \land b) = (\text{true} \land \text{true} \land \text{true}) = \text{true}
\]
\[
(a \land b) = (\text{true} \land \text{true}) = \text{true}
\]
Thus, $(a \land b \land b) = (a \land b)$.

2. **Case 2: $a = \text{true}$ and $b = \text{false}$**
\[
(a \land b \land b) = (\text{true} \land \text{false} \land \text{false}) = \text{false}
\]
\[
(a \land b) = (\text{true} \land \text{false}) = \text{false}
\]
Thus, $(a \land b \land b) = (a \land b)$.

3. **Case 3: $a = \text{false}$ and $b = \text{true}$**
\[
(a \land b \land b) = (\text{false} \land \text{true} \land \text{true}) = \text{false}
\]
\[
(a \land b) = (\text{false} \land \text{true}) = \text{false}
\]
Thus, $(a \land b \land b) = (a \land b)$.

4. **Case 4: $a = \text{false}$ and $b = \text{false}$**
\[
(a \land b \land b) = (\text{false} \land \text{false} \land \text{false}) = \text{false}
\]
\[
(a \land b) = (\text{false} \land \text{false}) = \text{false}
\]
Thus, $(a \land b \land b) = (a \land b)$.

Since the equality holds for all possible values of $a$ and $b$, we conclude that for any boolean values $a$ and $b$, the expression $(a \land b \land b)$ is equal to $(a \land b)$. This completes the proof.","theorem Bool.and_self_right : ∀(a b : Bool), ((a && b) && b) = (a && b) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25297,Bool.and_comm,"theorem Bool.and_comm : ∀ (x y : Bool), (x && y) = (y && x) := by sorry","Boolean AND is Commutative: \( x \land y = y \land x \) : For any boolean values \( x \) and \( y \), the boolean ""and"" operation is commutative, i.e., \( x \land y = y \land x \).","theorem Bool.and_comm : ∀ (x y : Bool), (x && y) = (y && x) := by
  decide","To prove that the boolean ""and"" operation is commutative, we need to show that for any boolean values \( x \) and \( y \), the equality \( x \land y = y \land x \) holds. We can do this by checking all possible combinations of \( x \) and \( y \):

1. If \( x = \text{true} \) and \( y = \text{true} \), then \( x \land y = \text{true} \) and \( y \land x = \text{true} \), so \( x \land y = y \land x \).
2. If \( x = \text{true} \) and \( y = \text{false} \), then \( x \land y = \text{false} \) and \( y \land x = \text{false} \), so \( x \land y = y \land x \).
3. If \( x = \text{false} \) and \( y = \text{true} \), then \( x \land y = \text{false} \) and \( y \land x = \text{false} \), so \( x \land y = y \land x \).
4. If \( x = \text{false} \) and \( y = \text{false} \), then \( x \land y = \text{false} \) and \( y \land x = \text{false} \), so \( x \land y = y \land x \).

Since the equality \( x \land y = y \land x \) holds for all possible values of \( x \) and \( y \), we conclude that the boolean ""and"" operation is commutative. This completes the proof.","theorem Bool.and_comm : ∀ (x y : Bool), (x && y) = (y && x) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25298,Bool.decide_false_eq,theorem Bool.decide_false_eq {b : Bool} [Decidable (false = b)] : decide (false = b) = !b := by sorry,"Decide False Equality: $\text{decide}(\text{false} = b) = \neg b$ : For any boolean value $b$, if the proposition `false = b` is decidable, then the function `decide` applied to `false = b` returns the negation of $b$, i.e., $\text{decide}(\text{false} = b) = \neg b$.","theorem Bool.decide_false_eq {b : Bool} [Decidable (false = b)] : decide (false = b) = !b := by
  cases b <;> simp","We will consider every possible case of the boolean value $b$.

1. **Case 1: $b = \text{false}$**
- We need to show that $\text{decide}(\text{false} = \text{false}) = \neg \text{false}$.
- Since $\text{false} = \text{false}$ is true, $\text{decide}(\text{false} = \text{false})$ is true.
- Also, $\neg \text{false}$ is true.
- Therefore, $\text{decide}(\text{false} = \text{false}) = \text{true} = \neg \text{false}$, which is trivially true.

2. **Case 2: $b = \text{true}$**
- We need to show that $\text{decide}(\text{false} = \text{true}) = \neg \text{true}$.
- Since $\text{false} = \text{true}$ is false, $\text{decide}(\text{false} = \text{true})$ is false.
- Also, $\neg \text{true}$ is false.
- Therefore, $\text{decide}(\text{false} = \text{true}) = \text{false} = \neg \text{true}$, which is trivially true.

Since both cases are true, the theorem holds for any boolean value $b$. This completes the proof. $\blacksquare$","theorem Bool.decide_false_eq {b : Bool} [Decidable (false = b)] : decide (false = b) = !b := by
  cases b <;> simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25299,Bool.and_xor_distrib_right,"theorem Bool.and_xor_distrib_right : ∀ (x y z : Bool), (xor x y && z) = xor (x && z) (y && z) := by sorry","Distributivity of AND over XOR: $(x \oplus y) \land z = (x \land z) \oplus (y \land z)$ : For any boolean values $x$, $y$, and $z$, the conjunction of the exclusive or of $x$ and $y$ with $z$ is equal to the exclusive or of the conjunction of $x$ with $z$ and the conjunction of $y$ with $z$, i.e., $(x \oplus y) \land z = (x \land z) \oplus (y \land z)$.","theorem Bool.and_xor_distrib_right : ∀ (x y z : Bool), (xor x y && z) = xor (x && z) (y && z) := by
  decide","To prove the distributivity of the AND operation over the XOR operation, we need to show that for any boolean values $x$, $y$, and $z$, the equation $(x \oplus y) \land z = (x \land z) \oplus (y \land z)$ holds. We use the `decide` tactic to automatically verify this property. The `decide` tactic exhaustively checks all possible combinations of $x$, $y$, and $z$ to ensure that the equation holds in every case. Since the `decide` tactic confirms the equation for all possible boolean values, the distributivity property is established. Therefore, the theorem is proved.","theorem Bool.and_xor_distrib_right : ∀ (x y z : Bool), (xor x y && z) = xor (x && z) (y && z) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25300,Bool.eq_iff_iff,theorem Bool.eq_iff_iff {a b : Bool} : a = b ↔ (a ↔ b) := by sorry,"Boolean Equality is Equivalent to True Bi-implication: \( a = b \leftrightarrow (a = \text{true} \leftrightarrow b = \text{true}) \) : For any boolean values \( a \) and \( b \), \( a = b \) if and only if \( a = \text{true} \) if and only if \( b = \text{true} \).","theorem Bool.eq_iff_iff {a b : Bool} : a = b ↔ (a ↔ b) := by
  cases b <;> simp","We need to show that for any boolean values $a$ and $b$, the statement $a = b$ is equivalent to the statement $a = \text{true} \leftrightarrow b = \text{true}$. We will consider every possible case of the boolean value $b$.

1. **Case 1: $b = \text{false}$**
- We need to show that $a = \text{false} \leftrightarrow (a = \text{true} \leftrightarrow \text{false} = \text{true})$.
- Since $\text{false} = \text{true}$ is false, the right-hand side of the bi-implication is false.
- Therefore, the entire bi-implication simplifies to $a = \text{false} \leftrightarrow \text{false}$, which is true if and only if $a = \text{false}$.
- Hence, $a = \text{false} \leftrightarrow (a = \text{true} \leftrightarrow \text{false} = \text{true})$ is true.

2. **Case 2: $b = \text{true}$**
- We need to show that $a = \text{true} \leftrightarrow (a = \text{true} \leftrightarrow \text{true} = \text{true})$.
- Since $\text{true} = \text{true}$ is true, the right-hand side of the bi-implication is true.
- Therefore, the entire bi-implication simplifies to $a = \text{true} \leftrightarrow \text{true}$, which is true if and only if $a = \text{true}$.
- Hence, $a = \text{true} \leftrightarrow (a = \text{true} \leftrightarrow \text{true} = \text{true})$ is true.

Since both cases are true, we conclude that for any boolean values $a$ and $b$, $a = b$ if and only if $a = \text{true} \leftrightarrow b = \text{true}$. This completes the proof. $\blacksquare$","theorem Bool.eq_iff_iff {a b : Bool} : a = b ↔ (a ↔ b) := by
  cases b <;> simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25301,Bool.decide_true_eq,theorem Bool.decide_true_eq {b : Bool} [Decidable (true = b)]  : decide (true  = b) =  b := by sorry,"Decide True Equals Boolean Value: $\text{decide}(\text{true} = b) = b$ : For any boolean value \( b \), if the proposition \( \text{true} = b \) is decidable, then the function `decide` applied to \( \text{true} = b \) returns \( b \). In other words, \( \text{decide}(\text{true} = b) = b \).","theorem Bool.decide_true_eq {b : Bool} [Decidable (true = b)]  : decide (true  = b) =  b := by
  cases b <;> simp","We need to show that for any boolean value \( b \), the function `decide` applied to \( \text{true} = b \) returns \( b \). We will consider the two possible cases for \( b \).

1. **Case 1: \( b = \text{false} \)**
- We need to show that \( \text{decide}(\text{true} = \text{false}) = \text{false} \).
- Since \( \text{true} \neq \text{false} \), the function `decide` evaluates \( \text{true} = \text{false} \) to \(\text{false}\).
- Therefore, \( \text{decide}(\text{true} = \text{false}) = \text{false} \) is trivially true.

2. **Case 2: \( b = \text{true} \)**
- We need to show that \( \text{decide}(\text{true} = \text{true}) = \text{true} \).
- Since \( \text{true} = \text{true} \), the function `decide` evaluates \( \text{true} = \text{true} \) to \(\text{true}\).
- Therefore, \( \text{decide}(\text{true} = \text{true}) = \text{true} \) is trivially true.

Since both cases are true, we conclude that for any boolean value \( b \), \( \text{decide}(\text{true} = b) = b \). This completes the proof.","theorem Bool.decide_true_eq {b : Bool} [Decidable (true = b)]  : decide (true  = b) =  b := by
  cases b <;> simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25302,Bool.or_and_distrib_right,"theorem Bool.or_and_distrib_right : ∀ (x y z : Bool), (x && y || z) = ((x || z) && (y || z)) := by sorry","Right Distributive Property of AND over OR in Boolean Logic: $(x \land y) \lor z = (x \lor z) \land (y \lor z)$ : For any boolean values $x$, $y$, and $z$, the expression $(x \land y) \lor z$ is equal to $(x \lor z) \land (y \lor z)$. This theorem demonstrates the right distributive property of the boolean ""and"" operation over the boolean ""or"" operation.","theorem Bool.or_and_distrib_right : ∀ (x y z : Bool), (x && y || z) = ((x || z) && (y || z)) := by
  decide","To prove the right distributive property of the boolean ""and"" operation over the boolean ""or"" operation, we need to show that for any boolean values $x$, $y$, and $z$, the expression $(x \land y) \lor z$ is equal to $(x \lor z) \land (y \lor z)$. We use a decision procedure to verify this equality. The decision procedure checks all possible combinations of $x$, $y$, and $z$ and confirms that the equality holds in each case. Therefore, the right distributive property of the boolean ""and"" operation over the boolean ""or"" operation is established. This completes the proof.","theorem Bool.or_and_distrib_right : ∀ (x y z : Bool), (x && y || z) = ((x || z) && (y || z)) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25303,Bool.or_self_right,"theorem Bool.or_self_right : ∀(a b : Bool), ((a || b) || b) = (a || b) := by sorry","Right Self-Idempotence of Boolean Or Operation : For any boolean values $a$ and $b$, the expression $(a \lor b \lor b)$ is equal to $(a \lor b)$, i.e., $(a \lor b \lor b) = (a \lor b)$.","theorem Bool.or_self_right : ∀(a b : Bool), ((a || b) || b) = (a || b) := by
  decide","To prove that for any boolean values $a$ and $b$, the expression $(a \lor b \lor b)$ is equal to $(a \lor b)$, we can use the fact that the boolean values are finite and the operation $\lor$ (logical or) is well-defined. By evaluating all possible combinations of $a$ and $b$, we can verify that $(a \lor b \lor b) = (a \lor b)$ holds in every case. Specifically, we consider the following cases:

1. If $a = \text{true}$ and $b = \text{true}$, then $(a \lor b \lor b) = (\text{true} \lor \text{true} \lor \text{true}) = \text{true}$ and $(a \lor b) = (\text{true} \lor \text{true}) = \text{true}$.
2. If $a = \text{true}$ and $b = \text{false}$, then $(a \lor b \lor b) = (\text{true} \lor \text{false} \lor \text{false}) = \text{true}$ and $(a \lor b) = (\text{true} \lor \text{false}) = \text{true}$.
3. If $a = \text{false}$ and $b = \text{true}$, then $(a \lor b \lor b) = (\text{false} \lor \text{true} \lor \text{true}) = \text{true}$ and $(a \lor b) = (\text{false} \lor \text{true}) = \text{true}$.
4. If $a = \text{false}$ and $b = \text{false}$, then $(a \lor b \lor b) = (\text{false} \lor \text{false} \lor \text{false}) = \text{false}$ and $(a \lor b) = (\text{false} \lor \text{false}) = \text{false}$.

In all cases, we see that $(a \lor b \lor b) = (a \lor b)$. Therefore, the theorem is proved.","theorem Bool.or_self_right : ∀(a b : Bool), ((a || b) || b) = (a || b) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25304,Bool.false_eq_true,theorem Bool.false_eq_true : (false = true) = False := by sorry,"False is Not Equal to True in Boolean Type : The equality between the boolean values `false` and `true` is false, i.e., $\text{false} = \text{true}$ is equivalent to $\text{False}$.","theorem Bool.false_eq_true : (false = true) = False := by
  simp","We need to show that the equality $\text{false} = \text{true}$ is equivalent to the proposition $\text{False}$. By simplifying the expression $\text{false} = \text{true}$, we observe that this equality is a contradiction. Therefore, it simplifies directly to $\text{False}$. This completes the proof. $\blacksquare$","theorem Bool.false_eq_true : (false = true) = False := by
  simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25305,Bool.or_iff_right_iff_imp,"theorem Bool.or_iff_right_iff_imp : ∀(a b : Bool), ((a || b) = b) ↔ (a → b) := by sorry","Boolean Identity: \( (a \lor b) = b \leftrightarrow (a = \text{true} \to b = \text{true}) \) : For any boolean values \( a \) and \( b \), the boolean ""or"" operation \( a \lor b \) is equal to \( b \) if and only if \( a = \text{true} \) implies \( b = \text{true} \).","theorem Bool.or_iff_right_iff_imp : ∀(a b : Bool), ((a || b) = b) ↔ (a → b) := by
  decide","To prove the theorem, we need to show that for any boolean values \( a \) and \( b \), the following equivalence holds:
\[ (a \lor b) = b \leftrightarrow (a = \text{true} \to b = \text{true}) \]

We will consider all possible values of \( a \) and \( b \):

1. **Case 1: \( a = \text{false} \)**
- If \( a = \text{false} \), then \( a \lor b = b \) for any value of \( b \).
- Therefore, \( (a \lor b) = b \) is always true.
- The implication \( a = \text{true} \to b = \text{true} \) is vacuously true because the antecedent \( a = \text{true} \) is false.
- Hence, \( (a \lor b) = b \leftrightarrow (a = \text{true} \to b = \text{true}) \) holds.

2. **Case 2: \( a = \text{true} \)**
- If \( a = \text{true} \), then \( a \lor b = \text{true} \).
- For \( (a \lor b) = b \) to hold, we must have \( b = \text{true} \).
- The implication \( a = \text{true} \to b = \text{true} \) is true if and only if \( b = \text{true} \).
- Therefore, \( (a \lor b) = b \leftrightarrow (a = \text{true} \to b = \text{true}) \) holds.

Since the equivalence holds in both cases, the theorem is proven.

\(\blacksquare\)","theorem Bool.or_iff_right_iff_imp : ∀(a b : Bool), ((a || b) = b) ↔ (a → b) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25311,Bool.not_and,"theorem Bool.not_and : ∀ (x y : Bool), (!(x && y)) = (!x || !y) := by sorry","De Morgan's Law: $\neg (x \land y) = \neg x \lor \neg y$ : For any boolean values $x$ and $y$, the negation of their conjunction is equal to the disjunction of their negations, i.e., $\neg (x \land y) = \neg x \lor \neg y$.","theorem Bool.not_and : ∀ (x y : Bool), (!(x && y)) = (!x || !y) := by
  decide","To prove the statement $\neg (x \land y) = \neg x \lor \neg y$ for any boolean values $x$ and $y$, we can directly evaluate the truth values of both sides of the equation for all possible combinations of $x$ and $y$. We will use the truth table for boolean operations to verify this.

Consider the following truth table:

\[
\begin{array}{|c|c|c|c|c|}
\hline
x & y & x \land y & \neg (x \land y) & \neg x & \neg y & \neg x \lor \neg y \\
\hline
\text{true} & \text{true} & \text{true} & \text{false} & \text{false} & \text{false} & \text{false} \\
\text{true} & \text{false} & \text{false} & \text{true} & \text{false} & \text{true} & \text{true} \\
\text{false} & \text{true} & \text{false} & \text{true} & \text{true} & \text{false} & \text{true} \\
\text{false} & \text{false} & \text{false} & \text{true} & \text{true} & \text{true} & \text{true} \\
\hline
\end{array}
\]

From the truth table, we can see that for all combinations of $x$ and $y$, the value of $\neg (x \land y)$ is equal to the value of $\neg x \lor \neg y$. Therefore, the statement $\neg (x \land y) = \neg x \lor \neg y$ holds for any boolean values $x$ and $y$. This completes the proof.","theorem Bool.not_and : ∀ (x y : Bool), (!(x && y)) = (!x || !y) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25312,Bool.and_iff_right_iff_imp,"theorem Bool.and_iff_right_iff_imp : ∀(a b : Bool), ((a && b) = b) ↔ (b → a) := by sorry","Boolean AND Identity: \( (a \land b) = b \leftrightarrow (b = \text{true} \to a = \text{true}) \) : For any boolean values \( a \) and \( b \), the boolean ""and"" operation \( a \land b \) is equal to \( b \) if and only if \( b \) is `true` implies \( a \) is `true`.","theorem Bool.and_iff_right_iff_imp : ∀(a b : Bool), ((a && b) = b) ↔ (b → a) := by
  decide","To prove the theorem, we need to show that for any boolean values \( a \) and \( b \), the following equivalence holds:
\[ (a \land b) = b \leftrightarrow (b = \text{true} \to a = \text{true}) \]

We will consider all possible values of \( a \) and \( b \) and verify the equivalence directly.

1. **Case 1: \( a = \text{true} \) and \( b = \text{true} \)**
- \( (a \land b) = (\text{true} \land \text{true}) = \text{true} \)
- \( b = \text{true} \)
- \( b = \text{true} \to a = \text{true} \) is true because both \( b \) and \( a \) are true.
- Therefore, \( (a \land b) = b \) and \( b = \text{true} \to a = \text{true} \) are both true.

2. **Case 2: \( a = \text{true} \) and \( b = \text{false} \)**
- \( (a \land b) = (\text{true} \land \text{false}) = \text{false} \)
- \( b = \text{false} \)
- \( b = \text{true} \to a = \text{true} \) is vacuously true because \( b \) is false.
- Therefore, \( (a \land b) = b \) is false and \( b = \text{true} \to a = \text{true} \) is true, so the equivalence holds.

3. **Case 3: \( a = \text{false} \) and \( b = \text{true} \)**
- \( (a \land b) = (\text{false} \land \text{true}) = \text{false} \)
- \( b = \text{true} \)
- \( b = \text{true} \to a = \text{true} \) is false because \( b \) is true and \( a \) is false.
- Therefore, \( (a \land b) = b \) is false and \( b = \text{true} \to a = \text{true} \) is false, so the equivalence holds.

4. **Case 4: \( a = \text{false} \) and \( b = \text{false} \)**
- \( (a \land b) = (\text{false} \land \text{false}) = \text{false} \)
- \( b = \text{false} \)
- \( b = \text{true} \to a = \text{true} \) is vacuously true because \( b \) is false.
- Therefore, \( (a \land b) = b \) is false and \( b = \text{true} \to a = \text{true} \) is true, so the equivalence holds.

Since the equivalence holds in all possible cases, we conclude that for any boolean values \( a \) and \( b \),
\[ (a \land b) = b \leftrightarrow (b = \text{true} \to a = \text{true}) \]
This completes the proof.","theorem Bool.and_iff_right_iff_imp : ∀(a b : Bool), ((a && b) = b) ↔ (b → a) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25313,Bool.iff_self_and,"theorem Bool.iff_self_and : ∀(a b : Bool), (a = (a && b)) ↔ (a → b) := by sorry","Boolean AND Identity: \( a = (a \land b) \leftrightarrow (a = \text{true} \to b = \text{true}) \) : For any boolean values \( a \) and \( b \), the boolean ""and"" operation \( a \land b \) is equal to \( a \) if and only if \( a \) is `true` implies \( b \) is `true`.","theorem Bool.iff_self_and : ∀(a b : Bool), (a = (a && b)) ↔ (a → b) := by
  decide","To prove the statement, we need to show that for any boolean values \( a \) and \( b \), the following equivalence holds:
\[ a = (a \land b) \leftrightarrow (a = \text{true} \to b = \text{true}) \]

We will consider all possible values of \( a \) and \( b \):

1. **Case 1: \( a = \text{true} \) and \( b = \text{true} \)**
- \( a \land b = \text{true} \land \text{true} = \text{true} \)
- Therefore, \( a = (a \land b) \) is true.
- Since \( a = \text{true} \), the implication \( a = \text{true} \to b = \text{true} \) is also true.
- Hence, \( a = (a \land b) \leftrightarrow (a = \text{true} \to b = \text{true}) \) holds.

2. **Case 2: \( a = \text{true} \) and \( b = \text{false} \)**
- \( a \land b = \text{true} \land \text{false} = \text{false} \)
- Therefore, \( a = (a \land b) \) is false.
- Since \( a = \text{true} \), the implication \( a = \text{true} \to b = \text{true} \) is false.
- Hence, \( a = (a \land b) \leftrightarrow (a = \text{true} \to b = \text{true}) \) holds.

3. **Case 3: \( a = \text{false} \) and \( b = \text{true} \)**
- \( a \land b = \text{false} \land \text{true} = \text{false} \)
- Therefore, \( a = (a \land b) \) is true.
- Since \( a = \text{false} \), the implication \( a = \text{true} \to b = \text{true} \) is vacuously true.
- Hence, \( a = (a \land b) \leftrightarrow (a = \text{true} \to b = \text{true}) \) holds.

4. **Case 4: \( a = \text{false} \) and \( b = \text{false} \)**
- \( a \land b = \text{false} \land \text{false} = \text{false} \)
- Therefore, \( a = (a \land b) \) is true.
- Since \( a = \text{false} \), the implication \( a = \text{true} \to b = \text{true} \) is vacuously true.
- Hence, \( a = (a \land b) \leftrightarrow (a = \text{true} \to b = \text{true}) \) holds.

Since the equivalence holds in all possible cases, the theorem is proven. Therefore, for any boolean values \( a \) and \( b \), the boolean ""and"" operation \( a \land b \) is equal to \( a \) if and only if \( a \) is `true` implies \( b \) is `true`.","theorem Bool.iff_self_and : ∀(a b : Bool), (a = (a && b)) ↔ (a → b) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25315,Bool.or_eq_true_iff,"theorem Bool.or_eq_true_iff : ∀ (x y : Bool), (x || y) = true ↔ x = true ∨ y = true := by sorry","Boolean Or Identity: $(x \lor y) = \text{true} \leftrightarrow (x = \text{true} \lor y = \text{true})$ : For any boolean values \( x \) and \( y \), the boolean ""or"" operation \( x \lor y \) is equal to `true` if and only if \( x \) is `true` or \( y \) is `true`. In other words, \( (x \lor y) = \text{true} \) if and only if \( x = \text{true} \) or \( y = \text{true} \).","theorem Bool.or_eq_true_iff : ∀ (x y : Bool), (x || y) = true ↔ x = true ∨ y = true := by
  simp","To prove the equivalence \( (x \lor y) = \text{true} \leftrightarrow (x = \text{true} \lor y = \text{true}) \), we use the properties of boolean operations and the definition of disjunction. Specifically, we know that:

1. The boolean ""or"" operation \( x \lor y \) is defined such that \( x \lor y = \text{true} \) if and only if at least one of \( x \) or \( y \) is `true`.
2. This can be expressed as \( (x \lor y) = \text{true} \leftrightarrow (x = \text{true} \lor y = \text{true}) \).

By using these properties, we can directly conclude that the equivalence holds. Therefore, the theorem is proved.","theorem Bool.or_eq_true_iff : ∀ (x y : Bool), (x || y) = true ↔ x = true ∨ y = true := by
  simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25316,Bool.and_right_comm,"theorem Bool.and_right_comm : ∀ (x y z : Bool), ((x && y) && z) = ((x && z) && y) := by sorry","Right-Commutativity of Boolean AND Operation: $x \land y \land z = x \land z \land y$ : For any boolean values $x$, $y$, and $z$, the boolean ""and"" operation is right-commutative, i.e., $x \land y \land z = x \land z \land y$.","theorem Bool.and_right_comm : ∀ (x y z : Bool), ((x && y) && z) = ((x && z) && y) := by
  decide","To prove that for any boolean values $x$, $y$, and $z$, the boolean ""and"" operation is right-commutative, we need to show that $x \land y \land z = x \land z \land y$. Since there are only two possible boolean values (true and false), we can evaluate all possible combinations of $x$, $y$, and $z$ to verify the equality.

We consider the following cases:

1. **Case 1: $x = \text{true}$, $y = \text{true}$, $z = \text{true}$**
\[
\text{true} \land \text{true} \land \text{true} = \text{true} \land \text{true} \land \text{true}
\]
Both sides are true, so the equality holds.

2. **Case 2: $x = \text{true}$, $y = \text{true}$, $z = \text{false}$**
\[
\text{true} \land \text{true} \land \text{false} = \text{true} \land \text{false} \land \text{true}
\]
Both sides are false, so the equality holds.

3. **Case 3: $x = \text{true}$, $y = \text{false}$, $z = \text{true}$**
\[
\text{true} \land \text{false} \land \text{true} = \text{true} \land \text{true} \land \text{false}
\]
Both sides are false, so the equality holds.

4. **Case 4: $x = \text{true}$, $y = \text{false}$, $z = \text{false}$**
\[
\text{true} \land \text{false} \land \text{false} = \text{true} \land \text{false} \land \text{false}
\]
Both sides are false, so the equality holds.

5. **Case 5: $x = \text{false}$, $y = \text{true}$, $z = \text{true}$**
\[
\text{false} \land \text{true} \land \text{true} = \text{false} \land \text{true} \land \text{true}
\]
Both sides are false, so the equality holds.

6. **Case 6: $x = \text{false}$, $y = \text{true}$, $z = \text{false}$**
\[
\text{false} \land \text{true} \land \text{false} = \text{false} \land \text{false} \land \text{true}
\]
Both sides are false, so the equality holds.

7. **Case 7: $x = \text{false}$, $y = \text{false}$, $z = \text{true}$**
\[
\text{false} \land \text{false} \land \text{true} = \text{false} \land \text{true} \land \text{false}
\]
Both sides are false, so the equality holds.

8. **Case 8: $x = \text{false}$, $y = \text{false}$, $z = \text{false}$**
\[
\text{false} \land \text{false} \land \text{false} = \text{false} \land \text{false} \land \text{false}
\]
Both sides are false, so the equality holds.

Since the equality $x \land y \land z = x \land z \land y$ holds for all possible combinations of $x$, $y$, and $z$, the theorem is proved.","theorem Bool.and_right_comm : ∀ (x y z : Bool), ((x && y) && z) = ((x && z) && y) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25317,Bool.true_beq,"theorem Bool.true_beq : ∀b, (true  == b) =  b := by sorry","Boolean Equality with True: \(\text{true} == b = b\) : For any boolean value \( b \), the boolean equality \( \text{true} == b \) is equal to \( b \), i.e., \( \text{true} == b = b \).","theorem Bool.true_beq : ∀b, (true  == b) =  b := by
  decide","To prove the theorem, we consider the two possible values of \( b \):

1. **Case 1: \( b = \text{true} \)**
- We evaluate \(\text{true} == \text{true}\).
- By the definition of boolean equality, \(\text{true} == \text{true} = \text{true}\).
- Therefore, \(\text{true} == \text{true} = \text{true}\).

2. **Case 2: \( b = \text{false} \)**
- We evaluate \(\text{true} == \text{false}\).
- By the definition of boolean equality, \(\text{true} == \text{false} = \text{false}\).
- Therefore, \(\text{true} == \text{false} = \text{false}\).

Since both cases hold, we conclude that for any boolean value \( b \), \(\text{true} == b = b\). This completes the proof.","theorem Bool.true_beq : ∀b, (true  == b) =  b := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25320,Bool.false_beq,"theorem Bool.false_beq : ∀b, (false == b) = !b := by sorry","Boolean Identity: \(\text{false} == b = \neg b\) : For any boolean value \( b \), the boolean equality \( \text{false} == b \) is equal to the negation of \( b \), i.e., \( \text{false} == b = \neg b \).","theorem Bool.false_beq : ∀b, (false == b) = !b := by
  decide","To prove the theorem, we consider the two possible values of \( b \):

1. **Case \( b = \text{true} \):**
- \(\text{false} == \text{true}\) evaluates to \(\text{false}\).
- \(\neg \text{true}\) also evaluates to \(\text{false}\).
- Therefore, \(\text{false} == \text{true} = \neg \text{true}\).

2. **Case \( b = \text{false} \):**
- \(\text{false} == \text{false}\) evaluates to \(\text{true}\).
- \(\neg \text{false}\) also evaluates to \(\text{true}\).
- Therefore, \(\text{false} == \text{false} = \neg \text{false}\).

Since the equality \(\text{false} == b = \neg b\) holds for both possible values of \( b \), the theorem is proved.","theorem Bool.false_beq : ∀b, (false == b) = !b := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25321,Bool.false_bne,"theorem Bool.false_bne : ∀(b : Bool), (false != b) =  b := by sorry","Boolean Not-Equal Identity: \(\text{false} \neq b = b\) : For any boolean value \( b \), the boolean not-equal function `bne` applied to `false` and \( b \) returns \( b \). In other words, \(\text{false} \neq b\) is equivalent to \( b \).","theorem Bool.false_bne : ∀(b : Bool), (false != b) =  b := by
  decide","To prove the theorem, we need to show that for any boolean value \( b \), the expression \(\text{false} \neq b\) is equal to \( b \). We consider the two possible values of \( b \):

1. **Case 1: \( b = \text{true} \)**
- Evaluate \(\text{false} \neq \text{true}\):
- By the definition of the not-equal function, \(\text{false} \neq \text{true}\) is \(\text{true}\).
- Therefore, \(\text{false} \neq \text{true} = \text{true}\).

2. **Case 2: \( b = \text{false} \)**
- Evaluate \(\text{false} \neq \text{false}\):
- By the definition of the not-equal function, \(\text{false} \neq \text{false}\) is \(\text{false}\).
- Therefore, \(\text{false} \neq \text{false} = \text{false}\).

In both cases, we have shown that \(\text{false} \neq b = b\). Hence, the theorem is proved.","theorem Bool.false_bne : ∀(b : Bool), (false != b) =  b := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25323,Bool.beq_not_self,"theorem Bool.beq_not_self : ∀ (x : Bool), (x   == !x) = false := by sorry","Boolean Value is Not Equal to Its Negation: \( x == \neg x = \text{false} \) : For any boolean value \( x \), the boolean equality between \( x \) and its negation \(\neg x\) is `false`, i.e., \( x == \neg x = \text{false} \).","theorem Bool.beq_not_self : ∀ (x : Bool), (x   == !x) = false := by
  decide","To prove that for any boolean value \( x \), the equality \( x == \neg x \) is `false`, we consider the two possible values of \( x \):

1. **Case 1: \( x = \text{true} \)**
- The negation of \( x \) is \(\neg x = \text{false}\).
- Therefore, \( x == \neg x \) is \(\text{true} == \text{false}\), which is `false`.

2. **Case 2: \( x = \text{false} \)**
- The negation of \( x \) is \(\neg x = \text{true}\).
- Therefore, \( x == \neg x \) is \(\text{false} == \text{true}\), which is `false`.

Since both cases show that \( x == \neg x \) is `false`, we conclude that for any boolean value \( x \), the equality \( x == \neg x \) is `false`. This completes the proof.","theorem Bool.beq_not_self : ∀ (x : Bool), (x   == !x) = false := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25325,Bool.or_comm,"theorem Bool.or_comm : ∀ (x y : Bool), (x || y) = (y || x) := by sorry","Commutativity of Boolean Or: \( x \lor y = y \lor x \) : For any boolean values \( x \) and \( y \), the boolean ""or"" operation is commutative, i.e., \( x \lor y = y \lor x \).","theorem Bool.or_comm : ∀ (x y : Bool), (x || y) = (y || x) := by
  decide","To prove the commutativity of the boolean ""or"" operation, we need to show that for any boolean values \( x \) and \( y \), \( x \lor y = y \lor x \). We can do this by evaluating all possible combinations of \( x \) and \( y \):

1. **Case 1: \( x = \text{true} \) and \( y = \text{true} \)**
\[
x \lor y = \text{true} \lor \text{true} = \text{true}
\]
\[
y \lor x = \text{true} \lor \text{true} = \text{true}
\]
Thus, \( x \lor y = y \lor x \).

2. **Case 2: \( x = \text{true} \) and \( y = \text{false} \)**
\[
x \lor y = \text{true} \lor \text{false} = \text{true}
\]
\[
y \lor x = \text{false} \lor \text{true} = \text{true}
\]
Thus, \( x \lor y = y \lor x \).

3. **Case 3: \( x = \text{false} \) and \( y = \text{true} \)**
\[
x \lor y = \text{false} \lor \text{true} = \text{true}
\]
\[
y \lor x = \text{true} \lor \text{false} = \text{true}
\]
Thus, \( x \lor y = y \lor x \).

4. **Case 4: \( x = \text{false} \) and \( y = \text{false} \)**
\[
x \lor y = \text{false} \lor \text{false} = \text{false}
\]
\[
y \lor x = \text{false} \lor \text{false} = \text{false}
\]
Thus, \( x \lor y = y \lor x \).

Since all possible cases have been verified, we conclude that for any boolean values \( x \) and \( y \), the boolean ""or"" operation is commutative, i.e., \( x \lor y = y \lor x \). This completes the proof.","theorem Bool.or_comm : ∀ (x y : Bool), (x || y) = (y || x) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25326,Bool.bne_not_self,"theorem Bool.bne_not_self : ∀ (x : Bool), (x   != !x) = true := by sorry","Boolean Not-Equal Identity: \( x \neq \text{not}(x) \) is `true` : For any boolean value \( x \), the boolean not-equal function `bne` applied to \( x \) and its negation `not x` returns `true`, i.e., \( x \neq \text{not}(x) \) is `true`.","theorem Bool.bne_not_self : ∀ (x : Bool), (x   != !x) = true := by
  decide","To prove that for any boolean value \( x \), the statement \( x \neq \text{not}(x) \) is `true`, we use the `decide` tactic. This tactic evaluates the expression for all possible boolean values of \( x \) and confirms that the statement holds. Specifically, for \( x = \text{true} \), we have \( \text{true} \neq \text{not}(\text{true}) = \text{true} \neq \text{false} \), which is `true`. Similarly, for \( x = \text{false} \), we have \( \text{false} \neq \text{not}(\text{false}) = \text{false} \neq \text{true} \), which is also `true`. Therefore, the statement \( x \neq \text{not}(x) \) is `true` for all boolean values \( x \). This completes the proof.","theorem Bool.bne_not_self : ∀ (x : Bool), (x   != !x) = true := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25327,Bool.eq_not_self,"theorem Bool.eq_not_self : ∀(b : Bool), (b = (!b)) ↔ False := by sorry","Boolean Equality with Negation is False: \( b = \neg b \leftrightarrow \text{False} \) : For any boolean value \( b \), the equation \( b = \neg b \) is equivalent to the false proposition, i.e., \( b = \neg b \leftrightarrow \text{False} \).","theorem Bool.eq_not_self : ∀(b : Bool), (b = (!b)) ↔ False := by
  decide","To prove that for any boolean value \( b \), the equation \( b = \neg b \) is equivalent to the false proposition, we consider the possible values of \( b \):

1. If \( b = \text{true} \), then \( \neg b = \text{false} \). Clearly, \( \text{true} \neq \text{false} \), so \( b = \neg b \) is false.
2. If \( b = \text{false} \), then \( \neg b = \text{true} \). Clearly, \( \text{false} \neq \text{true} \), so \( b = \neg b \) is false.

Since \( b \) can only be either \( \text{true} \) or \( \text{false} \), and in both cases \( b = \neg b \) is false, we conclude that \( b = \neg b \) is equivalent to the false proposition. Therefore, \( b = \neg b \leftrightarrow \text{False} \). This completes the proof.","theorem Bool.eq_not_self : ∀(b : Bool), (b = (!b)) ↔ False := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25329,Bool.bne_assoc,"theorem Bool.bne_assoc : ∀ (x y z : Bool), ((x != y) != z) = (x != (y != z)) := by sorry","Associativity of Boolean Not-Equal Function: \((x \neq y) \neq z = x \neq (y \neq z)\) : For any boolean values \( x, y, z \in \text{Bool} \), the boolean not-equal function `!=` is associative, i.e., \((x \neq y) \neq z = x \neq (y \neq z)\).","theorem Bool.bne_assoc : ∀ (x y z : Bool), ((x != y) != z) = (x != (y != z)) := by
  decide","To prove the associativity of the boolean not-equal function, we need to show that for all boolean values \(x, y, z \in \text{Bool}\), the equality \((x \neq y) \neq z = x \neq (y \neq z)\) holds. We use a decision procedure to check this equality for all possible combinations of \(x, y, z\). The decision procedure confirms that the equality holds for all combinations of \(x, y, z\). Therefore, the boolean not-equal function is associative. This completes the proof.","theorem Bool.bne_assoc : ∀ (x y z : Bool), ((x != y) != z) = (x != (y != z)) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25330,Bool.false_eq,theorem Bool.false_eq (b : Bool) : (false = b) = (b = false) := by sorry,"Equivalence of False Equality in Boolean Type: $\text{false} = b \leftrightarrow b = \text{false}$ : For any boolean value $b$, the statement $\text{false} = b$ is equivalent to $b = \text{false}$, i.e., $\text{false} = b \leftrightarrow b = \text{false}$.","theorem Bool.false_eq (b : Bool) : (false = b) = (b = false) := by
  cases b <;> simp","To prove the equivalence $\text{false} = b \leftrightarrow b = \text{false}$ for any boolean value $b$, we will consider every possible case of $b$.

1. **Case 1: $b = \text{false}$**
- We need to show that $(\text{false} = \text{false}) = (\text{false} = \text{false})$.
- This is trivially true because both sides of the equality are the same.

2. **Case 2: $b = \text{true}$**
- We need to show that $(\text{false} = \text{true}) = (\text{true} = \text{false})$.
- Using the fact that $\text{true} \neq \text{false}$, both sides of the equality are false, so the proposition is true.

Since both cases are true, we have shown that $\text{false} = b \leftrightarrow b = \text{false}$ for any boolean value $b$. This completes the proof. $\blacksquare$","theorem Bool.false_eq (b : Bool) : (false = b) = (b = false) := by
/- We will consider every possible case of the boolean value $b$. There are two cases: $b = \text{false}$ and $b = \text{true}$. For each case, we will simplify the proposition we want to show. -/
/- We will consider every possible case of the boolean value $b$. There are two cases: $b = \text{false}$ and $b = \text{true}$. -/
/- First, we apply the case analysis to the current goal, which generates two subgoals. Then, for each of these new subgoals, we will simplify the proposition we want to show. -/
/- For the case $b = \text{false}$, we simplify the proposition $(\text{false} = \text{false}) = (\text{false} = \text{false})$. This is trivially true because both sides of the equality are the same. -/
/- For the case $b = \text{true}$, we simplify the proposition $(\text{false} = \text{true}) = (\text{true} = \text{false})$. Using the fact that $\text{true} \neq \text{false}$, both sides of the equality are false, so the proposition is true. -/
  cases b <;> simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25331,Bool.not_beq_self,"theorem Bool.not_beq_self : ∀ (x : Bool), ((!x) == x) = false := by sorry","Negation of Boolean Value is Not Equal to Itself: \((\neg x) == x = \text{false}\) : For any boolean value \( x \), the boolean equality between the negation of \( x \) and \( x \) itself is `false`, i.e., \((\neg x) == x = \text{false}\).","theorem Bool.not_beq_self : ∀ (x : Bool), ((!x) == x) = false := by
  decide","We need to show that for any boolean value \( x \), the boolean equality \((\neg x) == x\) is `false`. We consider the two possible values of \( x \):

1. **Case 1: \( x = \text{true} \)**
- The negation of \( x \) is \(\neg \text{true} = \text{false}\).
- Therefore, \((\neg \text{true}) == \text{true} = \text{false} == \text{true} = \text{false}\).

2. **Case 2: \( x = \text{false} \)**
- The negation of \( x \) is \(\neg \text{false} = \text{true}\).
- Therefore, \((\neg \text{false}) == \text{false} = \text{true} == \text{false} = \text{false}\).

In both cases, the boolean equality \((\neg x) == x\) is `false`. Hence, the statement \((\neg x) == x = \text{false}\) holds for all boolean values \( x \). This completes the proof.","theorem Bool.not_beq_self : ∀ (x : Bool), ((!x) == x) = false := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25332,Bool.and_eq_false_imp,"theorem Bool.and_eq_false_imp : ∀ (x y : Bool), (x && y) = false ↔ (x = true → y = false) := by sorry","Boolean AND Equals False if and only if True Implies False: $(x \land y) = \text{false} \leftrightarrow (x = \text{true} \to y = \text{false})$ : For any boolean values $x$ and $y$, the boolean ""and"" operation $(x \land y)$ is equal to `false` if and only if $x = \text{true}$ implies $y = \text{false}$.","theorem Bool.and_eq_false_imp : ∀ (x y : Bool), (x && y) = false ↔ (x = true → y = false) := by
  decide","To prove the statement, we need to show that for any boolean values $x$ and $y$, the boolean ""and"" operation $(x \land y)$ is equal to `false` if and only if $x = \text{true}$ implies $y = \text{false}$.

We consider all possible values of $x$ and $y$:

1. **Case 1: $x = \text{true}$ and $y = \text{true}$**
- $(x \land y) = (\text{true} \land \text{true}) = \text{true}$
- The right-hand side $x = \text{true} \to y = \text{false}$ is false.
- Therefore, $(x \land y) = \text{false}$ is false, and the implication holds.

2. **Case 2: $x = \text{true}$ and $y = \text{false}$**
- $(x \land y) = (\text{true} \land \text{false}) = \text{false}$
- The right-hand side $x = \text{true} \to y = \text{false}$ is true.
- Therefore, $(x \land y) = \text{false}$ is true, and the implication holds.

3. **Case 3: $x = \text{false}$ and $y = \text{true}$**
- $(x \land y) = (\text{false} \land \text{true}) = \text{false}$
- The right-hand side $x = \text{true} \to y = \text{false}$ is vacuously true (since the antecedent $x = \text{true}$ is false).
- Therefore, $(x \land y) = \text{false}$ is true, and the implication holds.

4. **Case 4: $x = \text{false}$ and $y = \text{false}$**
- $(x \land y) = (\text{false} \land \text{false}) = \text{false}$
- The right-hand side $x = \text{true} \to y = \text{false}$ is vacuously true (since the antecedent $x = \text{true}$ is false).
- Therefore, $(x \land y) = \text{false}$ is true, and the implication holds.

Since the statement holds for all possible values of $x$ and $y$, we conclude that for any boolean values $x$ and $y$, the boolean ""and"" operation $(x \land y)$ is equal to `false` if and only if $x = \text{true}$ implies $y = \text{false}$. This completes the proof.","theorem Bool.and_eq_false_imp : ∀ (x y : Bool), (x && y) = false ↔ (x = true → y = false) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25333,Bool.not_or,"theorem Bool.not_or : ∀ (x y : Bool), (!(x || y)) = (!x && !y) := by sorry","De Morgan's Law: \(\neg (x \lor y) = \neg x \land \neg y\) : For any boolean values \( x \) and \( y \), the negation of their disjunction is equal to the conjunction of their negations, i.e., \(\neg (x \lor y) = \neg x \land \neg y\).","theorem Bool.not_or : ∀ (x y : Bool), (!(x || y)) = (!x && !y) := by
  decide","To prove the theorem, we need to show that for any boolean values \( x \) and \( y \), the equation \(\neg (x \lor y) = \neg x \land \neg y\) holds. We can verify this by checking all possible combinations of \( x \) and \( y \):

1. **Case 1: \( x = \text{true} \) and \( y = \text{true} \)**
- \(\neg (x \lor y) = \neg (\text{true} \lor \text{true}) = \neg \text{true} = \text{false}\)
- \(\neg x \land \neg y = \neg \text{true} \land \neg \text{true} = \text{false} \land \text{false} = \text{false}\)
- Thus, \(\neg (x \lor y) = \neg x \land \neg y\).

2. **Case 2: \( x = \text{true} \) and \( y = \text{false} \)**
- \(\neg (x \lor y) = \neg (\text{true} \lor \text{false}) = \neg \text{true} = \text{false}\)
- \(\neg x \land \neg y = \neg \text{true} \land \neg \text{false} = \text{false} \land \text{true} = \text{false}\)
- Thus, \(\neg (x \lor y) = \neg x \land \neg y\).

3. **Case 3: \( x = \text{false} \) and \( y = \text{true} \)**
- \(\neg (x \lor y) = \neg (\text{false} \lor \text{true}) = \neg \text{true} = \text{false}\)
- \(\neg x \land \neg y = \neg \text{false} \land \neg \text{true} = \text{true} \land \text{false} = \text{false}\)
- Thus, \(\neg (x \lor y) = \neg x \land \neg y\).

4. **Case 4: \( x = \text{false} \) and \( y = \text{false} \)**
- \(\neg (x \lor y) = \neg (\text{false} \lor \text{false}) = \neg \text{false} = \text{true}\)
- \(\neg x \land \neg y = \neg \text{false} \land \neg \text{false} = \text{true} \land \text{true} = \text{true}\)
- Thus, \(\neg (x \lor y) = \neg x \land \neg y\).

Since the equation holds for all possible combinations of \( x \) and \( y \), we conclude that \(\neg (x \lor y) = \neg x \land \neg y\) for any boolean values \( x \) and \( y \). This completes the proof.","theorem Bool.not_or : ∀ (x y : Bool), (!(x || y)) = (!x && !y) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25334,Bool.not_eq_self,"theorem Bool.not_eq_self : ∀(b : Bool), ((!b) = b) ↔ False := by sorry","Negation of Boolean Value is Not Equal to Itself: \( \text{not}(b) \neq b \) : For any boolean value \( b \), the negation of \( b \) is equal to \( b \) if and only if the proposition `False` holds, i.e., \( \text{not}(b) = b \leftrightarrow \text{False} \).","theorem Bool.not_eq_self : ∀(b : Bool), ((!b) = b) ↔ False := by
  decide","To prove the statement, we consider the two possible boolean values: `true` and `false`.

1. **Case 1: \( b = \text{true} \)**
- The negation of `true` is `false`.
- Therefore, \( \text{not}(\text{true}) = \text{false} \).
- Clearly, \( \text{false} \neq \text{true} \).
- Hence, \( \text{not}(\text{true}) = \text{true} \) is false.

2. **Case 2: \( b = \text{false} \)**
- The negation of `false` is `true`.
- Therefore, \( \text{not}(\text{false}) = \text{true} \).
- Clearly, \( \text{true} \neq \text{false} \).
- Hence, \( \text{not}(\text{false}) = \text{false} \) is false.

In both cases, \( \text{not}(b) = b \) is false. Therefore, the statement \( \text{not}(b) = b \leftrightarrow \text{False} \) holds for all boolean values \( b \). This completes the proof.","theorem Bool.not_eq_self : ∀(b : Bool), ((!b) = b) ↔ False := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25335,Bool.eq_not_of_ne,"theorem Bool.eq_not_of_ne : ∀ {x y : Bool}, x ≠ y → x = !y := by sorry","Boolean Inequality Implies Negation: \( x \neq y \to x = \neg y \) : For any boolean values \( x \) and \( y \), if \( x \neq y \), then \( x = \text{not}(y) \), i.e., \( x = \neg y \).","theorem Bool.eq_not_of_ne : ∀ {x y : Bool}, x ≠ y → x = !y := by
  decide","We need to show that for any boolean values \( x \) and \( y \), if \( x \neq y \), then \( x = \neg y \).

Consider the boolean values \( x \) and \( y \). By the properties of boolean logic, there are only two possible values for \( x \) and \( y \): \( \text{true} \) and \( \text{false} \).

1. If \( x = \text{true} \) and \( y = \text{false} \), then \( x \neq y \) and \( x = \neg y \) because \( \neg \text{false} = \text{true} \).
2. If \( x = \text{false} \) and \( y = \text{true} \), then \( x \neq y \) and \( x = \neg y \) because \( \neg \text{true} = \text{false} \).

In both cases, if \( x \neq y \), then \( x = \neg y \). Therefore, the statement holds for all boolean values \( x \) and \( y \). This completes the proof.","theorem Bool.eq_not_of_ne : ∀ {x y : Bool}, x ≠ y → x = !y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25336,Bool.or_eq_false_iff,"theorem Bool.or_eq_false_iff : ∀ (x y : Bool), (x || y) = false ↔ x = false ∧ y = false := by sorry","Boolean Or Equals False if and only if Both Operands are False: \( (x \lor y) = \text{false} \leftrightarrow x = \text{false} \land y = \text{false} \) : For any boolean values \( x \) and \( y \), the boolean ""or"" operation \( x \lor y \) is equal to `false` if and only if both \( x \) and \( y \) are equal to `false`, i.e., \( (x \lor y) = \text{false} \leftrightarrow x = \text{false} \land y = \text{false} \).","theorem Bool.or_eq_false_iff : ∀ (x y : Bool), (x || y) = false ↔ x = false ∧ y = false := by
  decide","To prove the equivalence \( (x \lor y) = \text{false} \leftrightarrow x = \text{false} \land y = \text{false} \), we consider all possible values of \( x \) and \( y \):

1. **Case 1: \( x = \text{false} \) and \( y = \text{false} \)**
- Here, \( x \lor y = \text{false} \lor \text{false} = \text{false} \).
- Therefore, \( (x \lor y) = \text{false} \) holds, and \( x = \text{false} \land y = \text{false} \) also holds.

2. **Case 2: \( x = \text{false} \) and \( y = \text{true} \)**
- Here, \( x \lor y = \text{false} \lor \text{true} = \text{true} \).
- Therefore, \( (x \lor y) = \text{false} \) does not hold, and \( x = \text{false} \land y = \text{false} \) does not hold.

3. **Case 3: \( x = \text{true} \) and \( y = \text{false} \)**
- Here, \( x \lor y = \text{true} \lor \text{false} = \text{true} \).
- Therefore, \( (x \lor y) = \text{false} \) does not hold, and \( x = \text{false} \land y = \text{false} \) does not hold.

4. **Case 4: \( x = \text{true} \) and \( y = \text{true} \)**
- Here, \( x \lor y = \text{true} \lor \text{true} = \text{true} \).
- Therefore, \( (x \lor y) = \text{false} \) does not hold, and \( x = \text{false} \land y = \text{false} \) does not hold.

From these cases, we see that \( (x \lor y) = \text{false} \) if and only if \( x = \text{false} \) and \( y = \text{false} \). This completes the proof.","theorem Bool.or_eq_false_iff : ∀ (x y : Bool), (x || y) = false ↔ x = false ∧ y = false := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25339,Bool.true_eq,theorem Bool.true_eq (b : Bool) : (true = b) = (b = true) := by sorry,"Equivalence of True Equality in Boolean Type: $\text{true} = b \leftrightarrow b = \text{true}$ : For any boolean value $b$, the statement $\text{true} = b$ is equivalent to $b = \text{true}$, i.e., $\text{true} = b \leftrightarrow b = \text{true}$.","theorem Bool.true_eq (b : Bool) : (true = b) = (b = true) := by
  cases b <;> simp","To prove the equivalence $\text{true} = b \leftrightarrow b = \text{true}$ for any boolean value $b$, we will consider every possible case of $b$.

1. **Case 1: $b = \text{false}$**
- We need to show that $(\text{true} = \text{false}) = (\text{false} = \text{true})$.
- Since $\text{true} \neq \text{false}$, the left-hand side $\text{true} = \text{false}$ is false.
- Similarly, the right-hand side $\text{false} = \text{true}$ is also false.
- Therefore, $(\text{true} = \text{false}) = (\text{false} = \text{true})$ is equivalent to $\text{False} = \text{False}$, which is true.

2. **Case 2: $b = \text{true}$**
- We need to show that $(\text{true} = \text{true}) = (\text{true} = \text{true})$.
- Both sides of the equation are equal to $\text{true}$.
- Therefore, $(\text{true} = \text{true}) = (\text{true} = \text{true})$ is trivially true.

Since both cases are true, we conclude that for any boolean value $b$, the statement $\text{true} = b$ is equivalent to $b = \text{true}$. This completes the proof. $\blacksquare$","theorem Bool.true_eq (b : Bool) : (true = b) = (b = true) := by
/- We will consider every possible case of the boolean value $b$. There are two cases: $b = \text{true}$ and $b = \text{false}$. For each case, we will simplify the proposition we want to show. -/
/- We will consider every possible case of the boolean value $b$. There are two cases: $b = \text{true}$ and $b = \text{false}$. -/
/- First, we apply the case analysis to the current goal, which generates two subgoals. Then, for each of these subgoals, we will simplify the proposition we want to show. -/
/- For the case $b = \text{false}$, we simplify the proposition $(\text{true} = \text{false}) = (\text{false} = \text{true})$. Using the fact that $\text{true} \neq \text{false}$, we get $\text{False} = \text{False}$, which is true. -/
/- For the case $b = \text{true}$, we simplify the proposition $(\text{true} = \text{true}) = (\text{true} = \text{true})$. This is trivially true since both sides are equal to $\text{true}$. -/
  cases b <;> simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25340,Bool.beq_self_left,"theorem Bool.beq_self_left : ∀(a b : Bool), (a == (a == b)) = b := by sorry","Boolean Equality Reflexivity: \( a == (a == b) = b \) : For any boolean values \( a \) and \( b \), the boolean equality \( a == (a == b) \) is equal to \( b \), i.e., \( a == (a == b) = b \).","theorem Bool.beq_self_left : ∀(a b : Bool), (a == (a == b)) = b := by
  decide","To prove the theorem, we need to show that for any boolean values \( a \) and \( b \), the expression \( a == (a == b) \) is equal to \( b \). Since boolean values are decidable, we can evaluate the expression for all possible combinations of \( a \) and \( b \):

1. **Case 1: \( a = \text{true} \) and \( b = \text{true} \)**
\[
a == (a == b) = \text{true} == (\text{true} == \text{true}) = \text{true} == \text{true} = \text{true}
\]
Thus, \( a == (a == b) = b \).

2. **Case 2: \( a = \text{true} \) and \( b = \text{false} \)**
\[
a == (a == b) = \text{true} == (\text{true} == \text{false}) = \text{true} == \text{false} = \text{false}
\]
Thus, \( a == (a == b) = b \).

3. **Case 3: \( a = \text{false} \) and \( b = \text{true} \)**
\[
a == (a == b) = \text{false} == (\text{false} == \text{true}) = \text{false} == \text{false} = \text{true}
\]
Thus, \( a == (a == b) = b \).

4. **Case 4: \( a = \text{false} \) and \( b = \text{false} \)**
\[
a == (a == b) = \text{false} == (\text{false} == \text{false}) = \text{false} == \text{true} = \text{false}
\]
Thus, \( a == (a == b) = b \).

Since the equality holds for all possible values of \( a \) and \( b \), we conclude that for any boolean values \( a \) and \( b \), the boolean equality \( a == (a == b) \) is equal to \( b \). This completes the proof.","theorem Bool.beq_self_left : ∀(a b : Bool), (a == (a == b)) = b := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25341,Bool.le_refl,"theorem Bool.le_refl : ∀ (x : Bool), x ≤ x := by sorry","Reflexivity of Less Than or Equal To Relation on Boolean Values : For any boolean value \( x \in \text{Bool} \), it holds that \( x \le x \).","theorem Bool.le_refl : ∀ (x : Bool), x ≤ x := by
  decide","To prove that for any boolean value \( x \), \( x \le x \), we use the decidability of the boolean values. The boolean order relation \( \le \) is defined such that for any boolean value \( x \), \( x \le x \) is always true. This is a fundamental property of the boolean order relation. Therefore, the statement \( x \le x \) holds for all \( x \in \text{Bool} \). This completes the proof.","theorem Bool.le_refl : ∀ (x : Bool), x ≤ x := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25342,Bool.coe_false_iff_true,"theorem Bool.coe_false_iff_true : ∀(a b : Bool), (a = false ↔ b) ↔ (!a) = b := by sorry","Equivalence of \( a = \text{false} \leftrightarrow b = \text{true} \) and \( \neg a = b \) : For any boolean values \( a \) and \( b \), the statement \( a = \text{false} \leftrightarrow b = \text{true} \) is equivalent to \( \neg a = b \).","theorem Bool.coe_false_iff_true : ∀(a b : Bool), (a = false ↔ b) ↔ (!a) = b := by
  decide","We need to show that for any boolean values \( a \) and \( b \), the statement \( a = \text{false} \leftrightarrow b = \text{true} \) is equivalent to \( \neg a = b \).

To do this, we consider the truth table for boolean values:

- If \( a = \text{false} \):
- Then \( \neg a = \text{true} \).
- For \( a = \text{false} \leftrightarrow b = \text{true} \) to hold, \( b \) must be \( \text{true} \).
- Therefore, \( \neg a = b \) holds.

- If \( a = \text{true} \):
- Then \( \neg a = \text{false} \).
- For \( a = \text{false} \leftrightarrow b = \text{true} \) to hold, \( b \) must be \( \text{false} \).
- Therefore, \( \neg a = b \) holds.

Since both cases are covered, we conclude that \( a = \text{false} \leftrightarrow b = \text{true} \) is equivalent to \( \neg a = b \). This completes the proof.","theorem Bool.coe_false_iff_true : ∀(a b : Bool), (a = false ↔ b) ↔ (!a) = b := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25343,Bool.le_true,"theorem Bool.le_true : ∀ (x : Bool), x ≤ true := by sorry","Boolean Values are Less Than or Equal to True : For any boolean value \( x \), it holds that \( x \leq \text{true} \).","theorem Bool.le_true : ∀ (x : Bool), x ≤ true := by
  decide","To prove that for any boolean value \( x \), \( x \leq \text{true} \), we use the fact that the boolean lattice has `true` as its maximum element. In the boolean lattice, the value `true` is greater than or equal to both `true` and `false`. Therefore, for any boolean value \( x \), \( x \) is either `true` or `false`, and in both cases, \( x \leq \text{true} \) holds. This completes the proof.","theorem Bool.le_true : ∀ (x : Bool), x ≤ true := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25344,Bool.false_le,"theorem Bool.false_le : ∀ (x : Bool), false ≤ x := by sorry","False is Less Than or Equal to Any Boolean Value : For any boolean value \( x \), it holds that \( \text{false} \leq x \).","theorem Bool.false_le : ∀ (x : Bool), false ≤ x := by
  decide","We need to show that for any boolean value \( x \), \( \text{false} \leq x \). The boolean values are ordered such that \( \text{false} \leq \text{false} \) and \( \text{false} \leq \text{true} \). Since these are the only possible values for \( x \), the statement \( \text{false} \leq x \) holds for all \( x \). Therefore, the theorem is proved.","theorem Bool.false_le : ∀ (x : Bool), false ≤ x := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25345,Bool.bne_self_right,"theorem Bool.bne_self_right : ∀(a b : Bool), ((a != b) != b) = a := by sorry","Boolean Inequality Identity: \((a \neq b) \neq b = a\) : For any boolean values \( a \) and \( b \), the boolean expression \((a \neq b) \neq b\) is equal to \( a \), i.e., \((a \neq b) \neq b = a\).","theorem Bool.bne_self_right : ∀(a b : Bool), ((a != b) != b) = a := by
  decide","To prove the statement \((a \neq b) \neq b = a\) for any boolean values \(a\) and \(b\), we can directly evaluate all possible cases for \(a\) and \(b\):

1. **Case 1: \(a = \text{true}\) and \(b = \text{true}\)**
- \((a \neq b) = (\text{true} \neq \text{true}) = \text{false}\)
- \((a \neq b) \neq b = \text{false} \neq \text{true} = \text{true}\)
- Therefore, \((a \neq b) \neq b = \text{true} = a\)

2. **Case 2: \(a = \text{true}\) and \(b = \text{false}\)**
- \((a \neq b) = (\text{true} \neq \text{false}) = \text{true}\)
- \((a \neq b) \neq b = \text{true} \neq \text{false} = \text{true}\)
- Therefore, \((a \neq b) \neq b = \text{true} = a\)

3. **Case 3: \(a = \text{false}\) and \(b = \text{true}\)**
- \((a \neq b) = (\text{false} \neq \text{true}) = \text{true}\)
- \((a \neq b) \neq b = \text{true} \neq \text{true} = \text{false}\)
- Therefore, \((a \neq b) \neq b = \text{false} = a\)

4. **Case 4: \(a = \text{false}\) and \(b = \text{false}\)**
- \((a \neq b) = (\text{false} \neq \text{false}) = \text{false}\)
- \((a \neq b) \neq b = \text{false} \neq \text{false} = \text{false}\)
- Therefore, \((a \neq b) \neq b = \text{false} = a\)

In all cases, the equality \((a \neq b) \neq b = a\) holds. Therefore, the theorem is proved.","theorem Bool.bne_self_right : ∀(a b : Bool), ((a != b) != b) = a := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25346,Bool.xor_self,"theorem Bool.xor_self : ∀ (x : Bool), xor x x = false := by sorry","Exclusive Or of a Boolean with Itself is False : For any boolean value $x$, the exclusive or of $x$ with itself is `false`, i.e., $x \oplus x = \text{false}$.","theorem Bool.xor_self : ∀ (x : Bool), xor x x = false := by
  decide","To prove that for any boolean value $x$, the exclusive or of $x$ with itself is `false`, we consider all possible values of $x$. Since $x$ can only be `true` or `false`, we check both cases:
- If $x = \text{true}$, then $\text{xor}(\text{true}, \text{true}) = \text{false}$.
- If $x = \text{false}$, then $\text{xor}(\text{false}, \text{false}) = \text{false}$.
In both cases, the exclusive or of $x$ with itself is `false`. Therefore, the statement holds for all boolean values $x$. This completes the proof.","theorem Bool.xor_self : ∀ (x : Bool), xor x x = false := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25347,Bool.coe_true_iff_false,"theorem Bool.coe_true_iff_false : ∀(a b : Bool), (a ↔ b = false) ↔ a = (!b) := by sorry","Equivalence of \( a = \text{true} \leftrightarrow b = \text{false} \) and \( a = \neg b \) : For any boolean values \( a \) and \( b \), the statement \( a = \text{true} \leftrightarrow b = \text{false} \) is equivalent to \( a = \neg b \).","theorem Bool.coe_true_iff_false : ∀(a b : Bool), (a ↔ b = false) ↔ a = (!b) := by
  decide","We need to show that for any boolean values \( a \) and \( b \), the statement \( a = \text{true} \leftrightarrow b = \text{false} \) is equivalent to \( a = \neg b \).

To do this, we consider the truth values of \( a \) and \( b \):

1. **Case 1: \( a = \text{true} \)**
- If \( a = \text{true} \), then \( a = \text{true} \leftrightarrow b = \text{false} \) is true if and only if \( b = \text{false} \).
- This is equivalent to \( a = \neg b \) because \( \neg b = \text{true} \) when \( b = \text{false} \).

2. **Case 2: \( a = \text{false} \)**
- If \( a = \text{false} \), then \( a = \text{true} \leftrightarrow b = \text{false} \) is false for any value of \( b \).
- This is equivalent to \( a = \neg b \) because \( \neg b = \text{false} \) when \( b = \text{true} \).

In both cases, the statement \( a = \text{true} \leftrightarrow b = \text{false} \) is equivalent to \( a = \neg b \). Therefore, the theorem holds for all boolean values \( a \) and \( b \).

This completes the proof.","theorem Bool.coe_true_iff_false : ∀(a b : Bool), (a ↔ b = false) ↔ a = (!b) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25348,Bool.xor_left_comm,"theorem Bool.xor_left_comm : ∀ (x y z : Bool), xor x (xor y z) = xor y (xor x z) := by sorry","Left-Commutativity of Exclusive Or (XOR) in Boolean Values : For any boolean values $x$, $y$, and $z$, the expression $\text{xor}(x, \text{xor}(y, z))$ is equal to $\text{xor}(y, \text{xor}(x, z))$. This theorem demonstrates the left-commutativity property of the exclusive or (XOR) operation.","theorem Bool.xor_left_comm : ∀ (x y z : Bool), xor x (xor y z) = xor y (xor x z) := by
  decide","To prove the left-commutativity of the exclusive or (XOR) operation, we need to show that for any boolean values $x$, $y$, and $z$, the expression $\text{xor}(x, \text{xor}(y, z))$ is equal to $\text{xor}(y, \text{xor}(x, z))$. We use a decision procedure to verify this equality. This procedure exhaustively checks all possible combinations of $x$, $y$, and $z$ to ensure that the equality holds in every case. Since the decision procedure confirms the equality for all possible boolean values, the theorem is proven.

Thus, the left-commutativity of the XOR operation is established. $\blacksquare$","theorem Bool.xor_left_comm : ∀ (x y z : Bool), xor x (xor y z) = xor y (xor x z) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25349,Bool.bne_self_left,"theorem Bool.bne_self_left : ∀(a b : Bool), (a != (a != b)) = b := by sorry","Boolean Inequality Identity: \( a \neq (a \neq b) = b \) : For any boolean values \( a \) and \( b \), the boolean expression \( a \neq (a \neq b) \) is equal to \( b \), i.e., \( a \neq (a \neq b) = b \).","theorem Bool.bne_self_left : ∀(a b : Bool), (a != (a != b)) = b := by
  decide","To prove the statement \( \forall (a, b : \text{Bool}), (a \neq (a \neq b)) = b \), we evaluate the boolean expression for all possible values of \( a \) and \( b \). The boolean values \( a \) and \( b \) can each be either `true` or `false`. We check each combination:

1. **Case 1: \( a = \text{true} \) and \( b = \text{true} \)**
\[
a \neq (a \neq b) = \text{true} \neq (\text{true} \neq \text{true}) = \text{true} \neq \text{false} = \text{true}
\]
This matches \( b = \text{true} \).

2. **Case 2: \( a = \text{true} \) and \( b = \text{false} \)**
\[
a \neq (a \neq b) = \text{true} \neq (\text{true} \neq \text{false}) = \text{true} \neq \text{true} = \text{false}
\]
This matches \( b = \text{false} \).

3. **Case 3: \( a = \text{false} \) and \( b = \text{true} \)**
\[
a \neq (a \neq b) = \text{false} \neq (\text{false} \neq \text{true}) = \text{false} \neq \text{true} = \text{true}
\]
This matches \( b = \text{true} \).

4. **Case 4: \( a = \text{false} \) and \( b = \text{false} \)**
\[
a \neq (a \neq b) = \text{false} \neq (\text{false} \neq \text{false}) = \text{false} \neq \text{false} = \text{false}
\]
This matches \( b = \text{false} \).

Since the expression \( a \neq (a \neq b) \) equals \( b \) in all possible cases, the theorem is proven. Therefore, for any boolean values \( a \) and \( b \), the boolean expression \( a \neq (a \neq b) \) is equal to \( b \). This completes the proof.","theorem Bool.bne_self_left : ∀(a b : Bool), (a != (a != b)) = b := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25350,Bool.xor_right_comm,"theorem Bool.xor_right_comm : ∀ (x y z : Bool), xor (xor x y) z = xor (xor x z) y := by sorry","Right-Commutativity of Exclusive Or in Boolean Logic: $\text{xor}(\text{xor}(x, y), z) = \text{xor}(\text{xor}(x, z), y)$ : For any boolean values $x$, $y$, and $z$, the expression $\text{xor}(\text{xor}(x, y), z)$ is equal to $\text{xor}(\text{xor}(x, z), y)$. This theorem demonstrates the right-commutativity property of the exclusive or (XOR) operation.","theorem Bool.xor_right_comm : ∀ (x y z : Bool), xor (xor x y) z = xor (xor x z) y := by
  decide","To prove the right-commutativity of the exclusive or (XOR) operation, we use a decision procedure to check the equality for all possible boolean values of $x$, $y$, and $z$. This decision procedure exhaustively evaluates the expression $\text{xor}(\text{xor}(x, y), z) = \text{xor}(\text{xor}(x, z), y)$ for all combinations of $x, y, z \in \{\text{true}, \text{false}\}$ and confirms that the equality holds in every case. Therefore, the right-commutativity of the XOR operation is established. This completes the proof. $\blacksquare$","theorem Bool.xor_right_comm : ∀ (x y z : Bool), xor (xor x y) z = xor (xor x z) y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25351,Bool.or_right_comm,"theorem Bool.or_right_comm : ∀ (x y z : Bool), ((x || y) || z) = ((x || z) || y) := by sorry","Right-Commutativity of Boolean Or Operation: $x \lor y \lor z = x \lor z \lor y$ : For any boolean values $x$, $y$, and $z$, the boolean ""or"" operation is right-commutative, i.e., $x \lor y \lor z = x \lor z \lor y$.","theorem Bool.or_right_comm : ∀ (x y z : Bool), ((x || y) || z) = ((x || z) || y) := by
  decide","To prove that for any boolean values $x$, $y$, and $z$, the boolean ""or"" operation is right-commutative, we need to show that $x \lor y \lor z = x \lor z \lor y$. We can directly evaluate all possible combinations of $x$, $y$, and $z$ to verify the equality. Since there are only two boolean values (true and false), we can check each case individually.

Let's consider all possible combinations of $x$, $y$, and $z$:

1. If $x = \text{true}$, $y = \text{true}$, and $z = \text{true}$:
\[
x \lor y \lor z = \text{true} \lor \text{true} \lor \text{true} = \text{true}
\]
\[
x \lor z \lor y = \text{true} \lor \text{true} \lor \text{true} = \text{true}
\]
Thus, $x \lor y \lor z = x \lor z \lor y$.

2. If $x = \text{true}$, $y = \text{true}$, and $z = \text{false}$:
\[
x \lor y \lor z = \text{true} \lor \text{true} \lor \text{false} = \text{true}
\]
\[
x \lor z \lor y = \text{true} \lor \text{false} \lor \text{true} = \text{true}
\]
Thus, $x \lor y \lor z = x \lor z \lor y$.

3. If $x = \text{true}$, $y = \text{false}$, and $z = \text{true}$:
\[
x \lor y \lor z = \text{true} \lor \text{false} \lor \text{true} = \text{true}
\]
\[
x \lor z \lor y = \text{true} \lor \text{true} \lor \text{false} = \text{true}
\]
Thus, $x \lor y \lor z = x \lor z \lor y$.

4. If $x = \text{true}$, $y = \text{false}$, and $z = \text{false}$:
\[
x \lor y \lor z = \text{true} \lor \text{false} \lor \text{false} = \text{true}
\]
\[
x \lor z \lor y = \text{true} \lor \text{false} \lor \text{false} = \text{true}
\]
Thus, $x \lor y \lor z = x \lor z \lor y$.

5. If $x = \text{false}$, $y = \text{true}$, and $z = \text{true}$:
\[
x \lor y \lor z = \text{false} \lor \text{true} \lor \text{true} = \text{true}
\]
\[
x \lor z \lor y = \text{false} \lor \text{true} \lor \text{true} = \text{true}
\]
Thus, $x \lor y \lor z = x \lor z \lor y$.

6. If $x = \text{false}$, $y = \text{true}$, and $z = \text{false}$:
\[
x \lor y \lor z = \text{false} \lor \text{true} \lor \text{false} = \text{true}
\]
\[
x \lor z \lor y = \text{false} \lor \text{false} \lor \text{true} = \text{true}
\]
Thus, $x \lor y \lor z = x \lor z \lor y$.

7. If $x = \text{false}$, $y = \text{false}$, and $z = \text{true}$:
\[
x \lor y \lor z = \text{false} \lor \text{false} \lor \text{true} = \text{true}
\]
\[
x \lor z \lor y = \text{false} \lor \text{true} \lor \text{false} = \text{true}
\]
Thus, $x \lor y \lor z = x \lor z \lor y$.

8. If $x = \text{false}$, $y = \text{false}$, and $z = \text{false}$:
\[
x \lor y \lor z = \text{false} \lor \text{false} \lor \text{false} = \text{false}
\]
\[
x \lor z \lor y = \text{false} \lor \text{false} \lor \text{false} = \text{false}
\]
Thus, $x \lor y \lor z = x \lor z \lor y$.

Since the equality $x \lor y \lor z = x \lor z \lor y$ holds for all possible combinations of $x$, $y$, and $z$, we conclude that the boolean ""or"" operation is right-commutative. This completes the proof.","theorem Bool.or_right_comm : ∀ (x y z : Bool), ((x || y) || z) = ((x || z) || y) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25352,Bool.lt_trans,"theorem Bool.lt_trans : ∀ {x y z : Bool}, x < y → y < z → x < z := by sorry","Transitivity of the Less-Than Relation on Boolean Values: \( x < y \) and \( y < z \) implies \( x < z \) : For any boolean values \( x, y, z \), if \( x < y \) and \( y < z \), then \( x < z \).","theorem Bool.lt_trans : ∀ {x y z : Bool}, x < y → y < z → x < z := by
  decide","To prove the transitivity of the less-than relation on boolean values, we use the fact that the boolean values and the less-than relation are decidable. This means that for any boolean values \( x, y, z \), if \( x < y \) and \( y < z \), then \( x < z \) can be directly determined to be true. Therefore, the statement is true by decidability. This completes the proof.","theorem Bool.lt_trans : ∀ {x y z : Bool}, x < y → y < z → x < z := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25353,Bool.not_eq_not,"theorem Bool.not_eq_not : ∀ {a b : Bool}, ¬a = !b ↔ a = b := by sorry","Negation Identity: \( \neg a = \neg b \leftrightarrow a = b \) : For any boolean values \( a \) and \( b \), the negation of \( a \) is equal to the negation of \( b \) if and only if \( a \) is equal to \( b \), i.e., \( \neg a = \neg b \leftrightarrow a = b \).","theorem Bool.not_eq_not : ∀ {a b : Bool}, ¬a = !b ↔ a = b := by
  decide","To prove the statement \( \neg a = \neg b \leftrightarrow a = b \) for any boolean values \( a \) and \( b \), we can directly evaluate all possible cases for \( a \) and \( b \) since there are only two boolean values: `true` and `false`.

1. **Case 1: \( a = \text{true} \) and \( b = \text{true} \)**
- \( \neg a = \neg \text{true} = \text{false} \)
- \( \neg b = \neg \text{true} = \text{false} \)
- Therefore, \( \neg a = \neg b \) and \( a = b \).

2. **Case 2: \( a = \text{true} \) and \( b = \text{false} \)**
- \( \neg a = \neg \text{true} = \text{false} \)
- \( \neg b = \neg \text{false} = \text{true} \)
- Therefore, \( \neg a \neq \neg b \) and \( a \neq b \).

3. **Case 3: \( a = \text{false} \) and \( b = \text{true} \)**
- \( \neg a = \neg \text{false} = \text{true} \)
- \( \neg b = \neg \text{true} = \text{false} \)
- Therefore, \( \neg a \neq \neg b \) and \( a \neq b \).

4. **Case 4: \( a = \text{false} \) and \( b = \text{false} \)**
- \( \neg a = \neg \text{false} = \text{true} \)
- \( \neg b = \neg \text{false} = \text{true} \)
- Therefore, \( \neg a = \neg b \) and \( a = b \).

In all cases, we see that \( \neg a = \neg b \) if and only if \( a = b \). This completes the proof.","theorem Bool.not_eq_not : ∀ {a b : Bool}, ¬a = !b ↔ a = b := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25354,Bool.le_trans,"theorem Bool.le_trans : ∀ {x y z : Bool}, x ≤ y → y ≤ z → x ≤ z := by sorry","Transitivity of Boolean 'Less Than or Equal To' Relation: \( x \leq y \land y \leq z \to x \leq z \) : For any boolean values \( x, y, \) and \( z \), if \( x \leq y \) and \( y \leq z \), then \( x \leq z \).","theorem Bool.le_trans : ∀ {x y z : Bool}, x ≤ y → y ≤ z → x ≤ z := by
  decide","To prove the transitivity of the boolean 'less than or equal to' relation, we need to show that for any boolean values \( x, y, \) and \( z \), if \( x \leq y \) and \( y \leq z \), then \( x \leq z \).

We use the `decide` tactic, which automatically checks the truth of the statement for all possible boolean values \( x, y, \) and \( z \). Since the boolean values are finite and the relation \( \leq \) is well-defined, the `decide` tactic confirms that the statement holds for all cases. Therefore, the transitivity of the boolean 'less than or equal to' relation is established.

This completes the proof.","theorem Bool.le_trans : ∀ {x y z : Bool}, x ≤ y → y ≤ z → x ≤ z := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25355,Bool.lt_irrefl,"theorem Bool.lt_irrefl : ∀ (x : Bool), ¬ x < x := by sorry","Irreflexivity of Boolean 'Less Than' Relation: \( x < x \to \text{False} \) : For any boolean value \( x \in \text{Bool} \), it is not the case that \( x < x \). In other words, the less-than relation \( < \) on boolean values is irreflexive.","theorem Bool.lt_irrefl : ∀ (x : Bool), ¬ x < x := by
  decide","To prove that for any boolean value \( x \), it is not the case that \( x < x \), we consider the possible values of \( x \). The boolean values are either `true` or `false`.

1. If \( x = \text{true} \), then \( \text{true} < \text{true} \) is false.
2. If \( x = \text{false} \), then \( \text{false} < \text{false} \) is false.

Since neither \( \text{true} < \text{true} \) nor \( \text{false} < \text{false} \) holds, it follows that \( \neg (x < x) \) is true for all \( x \in \text{Bool} \). Therefore, the less-than relation \( < \) on boolean values is irreflexive. This completes the proof.","theorem Bool.lt_irrefl : ∀ (x : Bool), ¬ x < x := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25356,Bool.le_of_lt,"theorem Bool.le_of_lt : ∀ {x y : Bool}, x < y → x ≤ y := by sorry","Strict Inequality Implies Less Than or Equal To in Boolean Values: \( x < y \to x \leq y \) : For any boolean values \( x \) and \( y \), if \( x < y \), then \( x \leq y \).","theorem Bool.le_of_lt : ∀ {x y : Bool}, x < y → x ≤ y := by
  decide","To prove that for any boolean values \( x \) and \( y \), if \( x < y \), then \( x \leq y \), we use the decidability of boolean values and their order. Since the order on boolean values is decidable, we can directly conclude that if \( x < y \), then \( x \leq y \). This completes the proof. \(\blacksquare\)","theorem Bool.le_of_lt : ∀ {x y : Bool}, x < y → x ≤ y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25357,Bool.not_not_eq,"theorem Bool.not_not_eq : ∀ {a b : Bool}, ¬(!a) = b ↔ a = b := by sorry","Double Negation Identity: \( \neg(\neg a) = b \leftrightarrow a = b \) : For any boolean values \( a \) and \( b \), the negation of the negation of \( a \) is equal to \( b \) if and only if \( a \) is equal to \( b \), i.e., \( \neg(\neg a) = b \leftrightarrow a = b \).","theorem Bool.not_not_eq : ∀ {a b : Bool}, ¬(!a) = b ↔ a = b := by
  decide","To prove the statement \( \forall a, b : \text{Bool}, \neg(\neg a) = b \leftrightarrow a = b \), we use a decision procedure to automatically verify the equivalence. This decision procedure checks all possible boolean values for \( a \) and \( b \) and confirms that the equivalence holds in all cases. Specifically, we consider the following cases:

1. **Case 1: \( a = \text{true} \) and \( b = \text{true} \)**
- \( \neg(\neg \text{true}) = \neg(\text{false}) = \text{true} \)
- Since \( \text{true} = \text{true} \), the equivalence holds.

2. **Case 2: \( a = \text{true} \) and \( b = \text{false} \)**
- \( \neg(\neg \text{true}) = \neg(\text{false}) = \text{true} \)
- Since \( \text{true} \neq \text{false} \), the equivalence holds.

3. **Case 3: \( a = \text{false} \) and \( b = \text{true} \)**
- \( \neg(\neg \text{false}) = \neg(\text{true}) = \text{false} \)
- Since \( \text{false} \neq \text{true} \), the equivalence holds.

4. **Case 4: \( a = \text{false} \) and \( b = \text{false} \)**
- \( \neg(\neg \text{false}) = \neg(\text{true}) = \text{false} \)
- Since \( \text{false} = \text{false} \), the equivalence holds.

Since the equivalence \( \neg(\neg a) = b \leftrightarrow a = b \) holds in all possible cases, the theorem is proven.","theorem Bool.not_not_eq : ∀ {a b : Bool}, ¬(!a) = b ↔ a = b := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25358,Bool.not_bne_not,"theorem Bool.not_bne_not : ∀ (x y : Bool), ((!x) != (!y)) = (x != y) := by sorry","Boolean Not-Equal Function is Invariant under Negation: \((\text{not } x) \neq (\text{not } y) = x \neq y\) : For any boolean values \( x \) and \( y \), the boolean not-equal function `!=` satisfies the property that \((\text{not } x) \neq (\text{not } y) = x \neq y\).","theorem Bool.not_bne_not : ∀ (x y : Bool), ((!x) != (!y)) = (x != y) := by
  decide","To prove the theorem, we need to show that for any boolean values \( x \) and \( y \), the equality \((\text{not } x) \neq (\text{not } y) = x \neq y\) holds. We will consider all possible combinations of \( x \) and \( y \):

1. **Case 1: \( x = \text{true} \) and \( y = \text{true} \)**
- \((\text{not } \text{true}) \neq (\text{not } \text{true}) = \text{false} \neq \text{false} = \text{false}\)
- \( x \neq y = \text{true} \neq \text{true} = \text{false}\)
- Both sides are \(\text{false}\), so the equality holds.

2. **Case 2: \( x = \text{true} \) and \( y = \text{false} \)**
- \((\text{not } \text{true}) \neq (\text{not } \text{false}) = \text{false} \neq \text{true} = \text{true}\)
- \( x \neq y = \text{true} \neq \text{false} = \text{true}\)
- Both sides are \(\text{true}\), so the equality holds.

3. **Case 3: \( x = \text{false} \) and \( y = \text{true} \)**
- \((\text{not } \text{false}) \neq (\text{not } \text{true}) = \text{true} \neq \text{false} = \text{true}\)
- \( x \neq y = \text{false} \neq \text{true} = \text{true}\)
- Both sides are \(\text{true}\), so the equality holds.

4. **Case 4: \( x = \text{false} \) and \( y = \text{false} \)**
- \((\text{not } \text{false}) \neq (\text{not } \text{false}) = \text{true} \neq \text{true} = \text{false}\)
- \( x \neq y = \text{false} \neq \text{false} = \text{false}\)
- Both sides are \(\text{false}\), so the equality holds.

Since the equality \((\text{not } x) \neq (\text{not } y) = x \neq y\) holds for all possible combinations of \( x \) and \( y \), the theorem is proved.","theorem Bool.not_bne_not : ∀ (x y : Bool), ((!x) != (!y)) = (x != y) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25359,Bool.lt_of_le_of_ne,"theorem Bool.lt_of_le_of_ne : ∀ {x y : Bool}, x ≤ y → x ≠ y → x < y := by sorry","Strict Inequality from Non-Equality and Less-Than-or-Equal in Boolean Values: \( x \leq y \) and \( x \neq y \) implies \( x < y \) : For any boolean values \( x \) and \( y \), if \( x \leq y \) and \( x \neq y \), then \( x < y \).","theorem Bool.lt_of_le_of_ne : ∀ {x y : Bool}, x ≤ y → x ≠ y → x < y := by
  decide","We need to show that for any boolean values \( x \) and \( y \), if \( x \leq y \) and \( x \neq y \), then \( x < y \). Since the boolean values and the order relations on them are decidable, we can directly evaluate the conditions. Given \( x \leq y \) and \( x \neq y \), it follows that \( x < y \) must hold. This completes the proof.","theorem Bool.lt_of_le_of_ne : ∀ {x y : Bool}, x ≤ y → x ≠ y → x < y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25360,Bool.beq_eq_decide_eq,"theorem Bool.beq_eq_decide_eq [BEq α] [LawfulBEq α] [DecidableEq α] (a b : α) :
    (a == b) = decide (a = b) := by sorry","Boolean Equality Matches Decidable Equality: \(a == b = \text{decide}(a = b)\) : For any type \(\alpha\) with a `BEq` instance, a `LawfulBEq` instance, and a `DecidableEq` instance, and for any elements \(a, b \in \alpha\), the boolean equality \(a == b\) is equal to the boolean value obtained by deciding the proposition \(a = b\), i.e., \(a == b = \text{decide}(a = b)\).","theorem Bool.beq_eq_decide_eq [BEq α] [LawfulBEq α] [DecidableEq α] (a b : α) :
    (a == b) = decide (a = b) := by
  cases h : a == b
  · simp [ne_of_beq_false h]
  · simp [eq_of_beq h]","We will consider every possible case of the boolean equality \(a == b\).

1. **Case 1: \(a == b = \text{false}\)**
- Using the fact that \(a == b = \text{false}\) implies \(a \neq b\) (by the `ne_of_beq_false` theorem), we can simplify the proposition to \(\text{false} = \text{decide}(a \neq b)\).
- By the definition of the `decide` function, \(\text{decide}(a \neq b) = \text{false}\) when \(a \neq b\).
- Therefore, \(\text{false} = \text{decide}(a \neq b)\) is true.

2. **Case 2: \(a == b = \text{true}\)**
- Using the fact that \(a == b = \text{true}\) implies \(a = b\) (by the `eq_of_beq` theorem), we can simplify the proposition to \(\text{true} = \text{decide}(a = b)\).
- By the definition of the `decide` function, \(\text{decide}(a = b) = \text{true}\) when \(a = b\).
- Therefore, \(\text{true} = \text{decide}(a = b)\) is true.

Since both cases are true, we conclude that \(a == b = \text{decide}(a = b)\) for any elements \(a, b \in \alpha\). This completes the proof. \(\blacksquare\)","theorem Bool.beq_eq_decide_eq [BEq α] [LawfulBEq α] [DecidableEq α] (a b : α) :
    (a == b) = decide (a = b) := by
/- We will consider every possible case of the boolean equality \(a == b\). Case 1: \(a == b = \text{false}\). Case 2: \(a == b = \text{true}\). -/
  cases h : a == b
/- First, we show that if \(a == b = \text{false}\), then \(\text{false} = \text{decide}(a = b)\). Using the fact that \(a == b = \text{false}\) implies \(a \neq b\), we can simplify the proposition to \(\text{false} = \text{decide}(a \neq b)\), which is true by the definition of the `decide` function. -/
  · simp [ne_of_beq_false h]
/- Next, we show that if \(a == b = \text{true}\), then \(\text{true} = \text{decide}(a = b)\). Using the fact that \(a == b = \text{true}\) implies \(a = b\), we can simplify the proposition to \(\text{true} = \text{decide}(a = b)\), which is true by the definition of the `decide` function. -/
  · simp [eq_of_beq h]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25361,Bool.coe_iff_coe,"theorem Bool.coe_iff_coe : ∀(a b : Bool), (a ↔ b) ↔ a = b := by sorry","Boolean Equivalence: \( a = \text{true} \leftrightarrow b = \text{true} \) if and only if \( a = b \) : For any boolean values \( a \) and \( b \), the statement \( a = \text{true} \leftrightarrow b = \text{true} \) is equivalent to \( a = b \).","theorem Bool.coe_iff_coe : ∀(a b : Bool), (a ↔ b) ↔ a = b := by
  decide","We need to show that for any boolean values \( a \) and \( b \), the statement \( a = \text{true} \leftrightarrow b = \text{true} \) is equivalent to \( a = b \). We will consider all possible values of \( a \) and \( b \):

1. **Case 1: \( a = \text{true} \) and \( b = \text{true} \)**
- Here, \( a = \text{true} \leftrightarrow b = \text{true} \) is true because both \( a \) and \( b \) are true.
- Also, \( a = b \) is true because both \( a \) and \( b \) are true.
- Therefore, \( a = \text{true} \leftrightarrow b = \text{true} \) implies \( a = b \).

2. **Case 2: \( a = \text{true} \) and \( b = \text{false} \)**
- Here, \( a = \text{true} \leftrightarrow b = \text{true} \) is false because \( a \) is true and \( b \) is false.
- Also, \( a = b \) is false because \( a \) is true and \( b \) is false.
- Therefore, \( a = \text{true} \leftrightarrow b = \text{true} \) implies \( a = b \).

3. **Case 3: \( a = \text{false} \) and \( b = \text{true} \)**
- Here, \( a = \text{true} \leftrightarrow b = \text{true} \) is false because \( a \) is false and \( b \) is true.
- Also, \( a = b \) is false because \( a \) is false and \( b \) is true.
- Therefore, \( a = \text{true} \leftrightarrow b = \text{true} \) implies \( a = b \).

4. **Case 4: \( a = \text{false} \) and \( b = \text{false} \)**
- Here, \( a = \text{true} \leftrightarrow b = \text{true} \) is true because both \( a \) and \( b \) are false.
- Also, \( a = b \) is true because both \( a \) and \( b \) are false.
- Therefore, \( a = \text{true} \leftrightarrow b = \text{true} \) implies \( a = b \).

Since the statement \( a = \text{true} \leftrightarrow b = \text{true} \) is equivalent to \( a = b \) in all possible cases, the theorem is proved.","theorem Bool.coe_iff_coe : ∀(a b : Bool), (a ↔ b) ↔ a = b := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25362,Bool.lt_asymm,"theorem Bool.lt_asymm : ∀ {x y : Bool}, x < y → ¬ y < x := by sorry","Asymmetry of the Less-Than Relation on Boolean Values: \( x < y \) implies \( \neg (y < x) \) : For any boolean values \( x \) and \( y \), if \( x < y \), then it is not the case that \( y < x \). In other words, the less-than relation on boolean values is asymmetric.","theorem Bool.lt_asymm : ∀ {x y : Bool}, x < y → ¬ y < x := by
  decide","To prove the asymmetry of the less-than relation on boolean values, we need to show that for any boolean values \( x \) and \( y \), if \( x < y \), then \( \neg (y < x) \).

The less-than relation on boolean values is defined as follows:
- \( \text{false} < \text{true} \)
- No other comparisons hold.

Given \( x < y \), we have:
- \( x = \text{false} \) and \( y = \text{true} \).

Now, we need to check if \( y < x \):
- \( y = \text{true} \) and \( x = \text{false} \).

By the definition of the less-than relation, \( \text{true} < \text{false} \) is false. Therefore, \( y < x \) is false, which means \( \neg (y < x) \) is true.

Thus, if \( x < y \), then \( \neg (y < x) \) holds. This completes the proof.","theorem Bool.lt_asymm : ∀ {x y : Bool}, x < y → ¬ y < x := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25363,Bool.lt_of_lt_of_le,"theorem Bool.lt_of_lt_of_le : ∀ {x y z : Bool}, x < y → y ≤ z → x < z := by sorry","Transitivity of Less-Than and Less-Than-or-Equal in Boolean Type : For any boolean values \( x, y, z \), if \( x < y \) and \( y \le z \), then \( x < z \).","theorem Bool.lt_of_lt_of_le : ∀ {x y z : Bool}, x < y → y ≤ z → x < z := by
  decide","To prove the transitivity of the less-than and less-than-or-equal relations in the boolean type, we use the decidability of the boolean type. The boolean type has only two values: `true` and `false`. The relations \( < \) and \( \le \) are well-defined and decidable for these values. We need to show that if \( x < y \) and \( y \le z \), then \( x < z \).

We can verify this by checking all possible combinations of \( x, y, \) and \( z \):

1. If \( x = \text{false} \) and \( y = \text{true} \), then \( x < y \) is true.
2. If \( y = \text{true} \) and \( z = \text{true} \), then \( y \le z \) is true.
3. In this case, \( x = \text{false} \) and \( z = \text{true} \), so \( x < z \) is true.

Since the boolean type has only two values, and the relations \( < \) and \( \le \) are well-defined, the proposition holds for all possible combinations. Therefore, the statement \( x < y \) and \( y \le z \) implies \( x < z \) is true. This completes the proof.","theorem Bool.lt_of_lt_of_le : ∀ {x y z : Bool}, x < y → y ≤ z → x < z := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25364,Bool.xor_not,"theorem Bool.xor_not : ∀ (x y : Bool), xor x (!y) = !(xor x y) := by sorry","Exclusive Or with Negation: $x \oplus \neg y = \neg (x \oplus y)$ : For any boolean values $x$ and $y$, the exclusive or of $x$ and the negation of $y$ is equal to the negation of the exclusive or of $x$ and $y$, i.e., $x \oplus \neg y = \neg (x \oplus y)$.","theorem Bool.xor_not : ∀ (x y : Bool), xor x (!y) = !(xor x y) := by
  decide","To prove the theorem, we need to show that for any boolean values $x$ and $y$, the equation $x \oplus \neg y = \neg (x \oplus y)$ holds. We use the `decide` tactic to automatically verify this equality by checking all possible combinations of $x$ and $y$.

- **Case 1: $x = \text{true}$ and $y = \text{true}$**
- Left-hand side: $x \oplus \neg y = \text{true} \oplus \neg \text{true} = \text{true} \oplus \text{false} = \text{true}$
- Right-hand side: $\neg (x \oplus y) = \neg (\text{true} \oplus \text{true}) = \neg \text{false} = \text{true}$
- Both sides are equal.

- **Case 2: $x = \text{true}$ and $y = \text{false}$**
- Left-hand side: $x \oplus \neg y = \text{true} \oplus \neg \text{false} = \text{true} \oplus \text{true} = \text{false}$
- Right-hand side: $\neg (x \oplus y) = \neg (\text{true} \oplus \text{false}) = \neg \text{true} = \text{false}$
- Both sides are equal.

- **Case 3: $x = \text{false}$ and $y = \text{true}$**
- Left-hand side: $x \oplus \neg y = \text{false} \oplus \neg \text{true} = \text{false} \oplus \text{false} = \text{false}$
- Right-hand side: $\neg (x \oplus y) = \neg (\text{false} \oplus \text{true}) = \neg \text{true} = \text{false}$
- Both sides are equal.

- **Case 4: $x = \text{false}$ and $y = \text{false}$**
- Left-hand side: $x \oplus \neg y = \text{false} \oplus \neg \text{false} = \text{false} \oplus \text{true} = \text{true}$
- Right-hand side: $\neg (x \oplus y) = \neg (\text{false} \oplus \text{false}) = \neg \text{false} = \text{true}$
- Both sides are equal.

Since the equality holds for all possible combinations of $x$ and $y$, the theorem is proven. Therefore, for any boolean values $x$ and $y$, we have $x \oplus \neg y = \neg (x \oplus y)$. This completes the proof.","theorem Bool.xor_not : ∀ (x y : Bool), xor x (!y) = !(xor x y) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25365,Bool.bne_right_inj,"theorem Bool.bne_right_inj : ∀ (x y z : Bool), (x != z) = (y != z) ↔ x = y := by sorry","Right Injection of Boolean Not-Equal Function: \((x \neq z) = (y \neq z) \leftrightarrow x = y\) : For any boolean values \( x, y, z \in \text{Bool} \), the equation \((x \neq z) = (y \neq z)\) holds if and only if \( x = y \).","theorem Bool.bne_right_inj : ∀ (x y z : Bool), (x != z) = (y != z) ↔ x = y := by
  decide","To prove the statement, we use the decidability of boolean values. Since \( x, y, z \) can only be `true` or `false`, we can check all possible combinations of these values to verify the equivalence.

1. **Case 1: \( x = \text{true} \) and \( y = \text{true} \)**
- If \( z = \text{true} \), then \( (x \neq z) = \text{false} \) and \( (y \neq z) = \text{false} \). Thus, \((x \neq z) = (y \neq z)\) holds, and \( x = y \) is true.
- If \( z = \text{false} \), then \( (x \neq z) = \text{true} \) and \( (y \neq z) = \text{true} \). Thus, \((x \neq z) = (y \neq z)\) holds, and \( x = y \) is true.

2. **Case 2: \( x = \text{true} \) and \( y = \text{false} \)**
- If \( z = \text{true} \), then \( (x \neq z) = \text{false} \) and \( (y \neq z) = \text{true} \). Thus, \((x \neq z) \neq (y \neq z)\), and \( x \neq y \) is true.
- If \( z = \text{false} \), then \( (x \neq z) = \text{true} \) and \( (y \neq z) = \text{false} \). Thus, \((x \neq z) \neq (y \neq z)\), and \( x \neq y \) is true.

3. **Case 3: \( x = \text{false} \) and \( y = \text{true} \)**
- If \( z = \text{true} \), then \( (x \neq z) = \text{true} \) and \( (y \neq z) = \text{false} \). Thus, \((x \neq z) \neq (y \neq z)\), and \( x \neq y \) is true.
- If \( z = \text{false} \), then \( (x \neq z) = \text{false} \) and \( (y \neq z) = \text{true} \). Thus, \((x \neq z) \neq (y \neq z)\), and \( x \neq y \) is true.

4. **Case 4: \( x = \text{false} \) and \( y = \text{false} \)**
- If \( z = \text{true} \), then \( (x \neq z) = \text{true} \) and \( (y \neq z) = \text{true} \). Thus, \((x \neq z) = (y \neq z)\) holds, and \( x = y \) is true.
- If \( z = \text{false} \), then \( (x \neq z) = \text{false} \) and \( (y \neq z) = \text{false} \). Thus, \((x \neq z) = (y \neq z)\) holds, and \( x = y \) is true.

In all cases, we have shown that \((x \neq z) = (y \neq z)\) holds if and only if \( x = y \). Therefore, the theorem is proved. \(\blacksquare\)","theorem Bool.bne_right_inj : ∀ (x y z : Bool), (x != z) = (y != z) ↔ x = y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25366,Bool.eq_false_of_le_false,"theorem Bool.eq_false_of_le_false : ∀ {x : Bool}, x ≤ false → x = false := by sorry","Boolean Value Less Than or Equal to False is False: $x \leq \text{false} \implies x = \text{false}$ : For any boolean value $x$, if $x$ is less than or equal to `false`, then $x$ is equal to `false`, i.e., $x \leq \text{false} \implies x = \text{false}$.","theorem Bool.eq_false_of_le_false : ∀ {x : Bool}, x ≤ false → x = false := by
  decide","To prove that for any boolean value $x$, if $x \leq \text{false}$, then $x = \text{false}$, we consider the possible values of $x$. Since $x$ is a boolean value, it can only be either `true` or `false`.

1. If $x = \text{true}$, then $x \leq \text{false}$ would be false, which contradicts our assumption that $x \leq \text{false}$.
2. Therefore, the only possibility is $x = \text{false}$.

Thus, if $x \leq \text{false}$, it must be that $x = \text{false}$. This completes the proof.","theorem Bool.eq_false_of_le_false : ∀ {x : Bool}, x ≤ false → x = false := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25367,Bool.xor_comm,"theorem Bool.xor_comm : ∀ (x y : Bool), xor x y = xor y x := by sorry","Commutativity of Exclusive Or (XOR) in Boolean Values : For any boolean values $x$ and $y$, the exclusive or (XOR) operation is commutative, i.e., $\text{xor}(x, y) = \text{xor}(y, x)$.","theorem Bool.xor_comm : ∀ (x y : Bool), xor x y = xor y x := by
  decide","To prove that the exclusive or (XOR) operation is commutative for any boolean values $x$ and $y$, we can directly evaluate all possible cases for $x$ and $y$. Since there are only four possible combinations of boolean values, we check each case individually:

1. **Case 1: $x = \text{true}$ and $y = \text{true}$**
\[
\text{xor}(\text{true}, \text{true}) = \text{false} \quad \text{and} \quad \text{xor}(\text{true}, \text{true}) = \text{false}
\]
Thus, $\text{xor}(\text{true}, \text{true}) = \text{xor}(\text{true}, \text{true})$.

2. **Case 2: $x = \text{true}$ and $y = \text{false}$**
\[
\text{xor}(\text{true}, \text{false}) = \text{true} \quad \text{and} \quad \text{xor}(\text{false}, \text{true}) = \text{true}
\]
Thus, $\text{xor}(\text{true}, \text{false}) = \text{xor}(\text{false}, \text{true})$.

3. **Case 3: $x = \text{false}$ and $y = \text{true}$**
\[
\text{xor}(\text{false}, \text{true}) = \text{true} \quad \text{and} \quad \text{xor}(\text{true}, \text{false}) = \text{true}
\]
Thus, $\text{xor}(\text{false}, \text{true}) = \text{xor}(\text{true}, \text{false})$.

4. **Case 4: $x = \text{false}$ and $y = \text{false}$**
\[
\text{xor}(\text{false}, \text{false}) = \text{false} \quad \text{and} \quad \text{xor}(\text{false}, \text{false}) = \text{false}
\]
Thus, $\text{xor}(\text{false}, \text{false}) = \text{xor}(\text{false}, \text{false})$.

Since $\text{xor}(x, y) = \text{xor}(y, x)$ holds for all possible combinations of boolean values, the exclusive or (XOR) operation is commutative. This completes the proof.","theorem Bool.xor_comm : ∀ (x y : Bool), xor x y = xor y x := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25368,Bool.le_total,"theorem Bool.le_total : ∀ (x y : Bool), x ≤ y ∨ y ≤ x := by sorry","Total Order Property of Boolean 'Less Than or Equal To' Relation: \( x \leq y \lor y \leq x \) : For any boolean values \( x \) and \( y \), either \( x \leq y \) or \( y \leq x \) holds. This property is known as the total order property of the boolean 'less than or equal to' relation.","theorem Bool.le_total : ∀ (x y : Bool), x ≤ y ∨ y ≤ x := by
  decide","To prove that for any boolean values \( x \) and \( y \), either \( x \leq y \) or \( y \leq x \) holds, we can use the fact that the boolean type is decidable. This means that for any boolean values \( x \) and \( y \), we can determine whether \( x \leq y \) or \( y \leq x \) holds. Since the boolean type is finite and has only two values, \( \text{true} \) and \( \text{false} \), we can check all possible combinations of \( x \) and \( y \):

1. If \( x = \text{true} \) and \( y = \text{true} \), then \( x \leq y \) holds.
2. If \( x = \text{true} \) and \( y = \text{false} \), then \( y \leq x \) holds.
3. If \( x = \text{false} \) and \( y = \text{true} \), then \( x \leq y \) holds.
4. If \( x = \text{false} \) and \( y = \text{false} \), then \( x \leq y \) holds.

In all cases, either \( x \leq y \) or \( y \leq x \) holds. Therefore, the total order property of the boolean 'less than or equal to' relation is satisfied. This completes the proof.","theorem Bool.le_total : ∀ (x y : Bool), x ≤ y ∨ y ≤ x := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25369,Bool.le_of_eq,"theorem Bool.le_of_eq : ∀ {x y : Bool}, x = y → x ≤ y := by sorry","Equality Implies Less Than or Equal To in Boolean Values: \( x = y \to x \leq y \) : For any boolean values \( x \) and \( y \), if \( x = y \), then \( x \leq y \).","theorem Bool.le_of_eq : ∀ {x y : Bool}, x = y → x ≤ y := by
  decide","To prove that for any boolean values \( x \) and \( y \), if \( x = y \), then \( x \leq y \), we consider the possible values of \( x \) and \( y \). The boolean values are either `true` or `false`, and the order relation \( \leq \) on booleans is defined as follows:
- `false ≤ false`
- `false ≤ true`
- `true ≤ true`

Given \( x = y \), we have the following cases:
1. If \( x = \text{false} \) and \( y = \text{false} \), then \( \text{false} \leq \text{false} \) holds.
2. If \( x = \text{true} \) and \( y = \text{true} \), then \( \text{true} \leq \text{true} \) holds.

In both cases, \( x \leq y \) is true. Therefore, the statement \( x = y \to x \leq y \) holds for all boolean values \( x \) and \( y \). This completes the proof.","theorem Bool.le_of_eq : ∀ {x y : Bool}, x = y → x ≤ y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25370,Bool.not_xor,"theorem Bool.not_xor : ∀ (x y : Bool), xor (!x) y = !(xor x y) := by sorry","Negation of Exclusive Or: $\text{xor}(\neg x, y) = \neg \text{xor}(x, y)$ : For any boolean values $x$ and $y$, the exclusive or of the negation of $x$ and $y$ is equal to the negation of the exclusive or of $x$ and $y$, i.e., $\text{xor}(\neg x, y) = \neg \text{xor}(x, y)$.","theorem Bool.not_xor : ∀ (x y : Bool), xor (!x) y = !(xor x y) := by
  decide","To prove the theorem, we need to show that for any boolean values $x$ and $y$, the equality $\text{xor}(\neg x, y) = \neg \text{xor}(x, y)$ holds. We can verify this by checking all possible combinations of $x$ and $y$:

1. **Case 1: $x = 0$ and $y = 0$**
- $\text{xor}(\neg 0, 0) = \text{xor}(1, 0) = 1$
- $\neg \text{xor}(0, 0) = \neg 0 = 1$
- Thus, $\text{xor}(\neg 0, 0) = \neg \text{xor}(0, 0)$.

2. **Case 2: $x = 0$ and $y = 1$**
- $\text{xor}(\neg 0, 1) = \text{xor}(1, 1) = 0$
- $\neg \text{xor}(0, 1) = \neg 1 = 0$
- Thus, $\text{xor}(\neg 0, 1) = \neg \text{xor}(0, 1)$.

3. **Case 3: $x = 1$ and $y = 0$**
- $\text{xor}(\neg 1, 0) = \text{xor}(0, 0) = 0$
- $\neg \text{xor}(1, 0) = \neg 1 = 0$
- Thus, $\text{xor}(\neg 1, 0) = \neg \text{xor}(1, 0)$.

4. **Case 4: $x = 1$ and $y = 1$**
- $\text{xor}(\neg 1, 1) = \text{xor}(0, 1) = 1$
- $\neg \text{xor}(1, 1) = \neg 0 = 1$
- Thus, $\text{xor}(\neg 1, 1) = \neg \text{xor}(1, 1)$.

Since the equality holds for all possible combinations of $x$ and $y$, we conclude that for any boolean values $x$ and $y$, the exclusive or of the negation of $x$ and $y$ is equal to the negation of the exclusive or of $x$ and $y$, i.e., $\text{xor}(\neg x, y) = \neg \text{xor}(x, y)$. This completes the proof.","theorem Bool.not_xor : ∀ (x y : Bool), xor (!x) y = !(xor x y) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25371,Bool.and_xor_distrib_left,"theorem Bool.and_xor_distrib_left : ∀ (x y z : Bool), (x && xor y z) = xor (x && y) (x && z) := by sorry","Left Distributive Property of AND over XOR in Boolean Logic: $(x \land (y \oplus z)) = (x \land y) \oplus (x \land z)$ : For any boolean values $x$, $y$, and $z$, the expression $(x \land (y \oplus z))$ is equal to $(x \land y) \oplus (x \land z)$. This theorem demonstrates the left distributive property of the boolean ""and"" operation over the boolean ""exclusive or"" operation.","theorem Bool.and_xor_distrib_left : ∀ (x y z : Bool), (x && xor y z) = xor (x && y) (x && z) := by
  decide","To prove the distributive property of the boolean ""and"" operation over the boolean ""exclusive or"" operation, we consider all possible boolean values for $x$, $y$, and $z$. By evaluating the expression $(x \land (y \oplus z))$ and comparing it to $(x \land y) \oplus (x \land z)$ for each combination of $x$, $y$, and $z$, we verify that they are equal. This exhausts all cases and completes the proof.

\[
\begin{aligned}
&\text{Case 1: } x = \text{true}, y = \text{true}, z = \text{true} \\
&\quad (x \land (y \oplus z)) = (\text{true} \land (\text{true} \oplus \text{true})) = (\text{true} \land \text{false}) = \text{false} \\
&\quad (x \land y) \oplus (x \land z) = (\text{true} \land \text{true}) \oplus (\text{true} \land \text{true}) = \text{true} \oplus \text{true} = \text{false} \\
&\text{Case 2: } x = \text{true}, y = \text{true}, z = \text{false} \\
&\quad (x \land (y \oplus z)) = (\text{true} \land (\text{true} \oplus \text{false})) = (\text{true} \land \text{true}) = \text{true} \\
&\quad (x \land y) \oplus (x \land z) = (\text{true} \land \text{true}) \oplus (\text{true} \land \text{false}) = \text{true} \oplus \text{false} = \text{true} \\
&\text{Case 3: } x = \text{true}, y = \text{false}, z = \text{true} \\
&\quad (x \land (y \oplus z)) = (\text{true} \land (\text{false} \oplus \text{true})) = (\text{true} \land \text{true}) = \text{true} \\
&\quad (x \land y) \oplus (x \land z) = (\text{true} \land \text{false}) \oplus (\text{true} \land \text{true}) = \text{false} \oplus \text{true} = \text{true} \\
&\text{Case 4: } x = \text{true}, y = \text{false}, z = \text{false} \\
&\quad (x \land (y \oplus z)) = (\text{true} \land (\text{false} \oplus \text{false})) = (\text{true} \land \text{false}) = \text{false} \\
&\quad (x \land y) \oplus (x \land z) = (\text{true} \land \text{false}) \oplus (\text{true} \land \text{false}) = \text{false} \oplus \text{false} = \text{false} \\
&\text{Case 5: } x = \text{false}, y = \text{true}, z = \text{true} \\
&\quad (x \land (y \oplus z)) = (\text{false} \land (\text{true} \oplus \text{true})) = (\text{false} \land \text{false}) = \text{false} \\
&\quad (x \land y) \oplus (x \land z) = (\text{false} \land \text{true}) \oplus (\text{false} \land \text{true}) = \text{false} \oplus \text{false} = \text{false} \\
&\text{Case 6: } x = \text{false}, y = \text{true}, z = \text{false} \\
&\quad (x \land (y \oplus z)) = (\text{false} \land (\text{true} \oplus \text{false})) = (\text{false} \land \text{true}) = \text{false} \\
&\quad (x \land y) \oplus (x \land z) = (\text{false} \land \text{true}) \oplus (\text{false} \land \text{false}) = \text{false} \oplus \text{false} = \text{false} \\
&\text{Case 7: } x = \text{false}, y = \text{false}, z = \text{true} \\
&\quad (x \land (y \oplus z)) = (\text{false} \land (\text{false} \oplus \text{true})) = (\text{false} \land \text{true}) = \text{false} \\
&\quad (x \land y) \oplus (x \land z) = (\text{false} \land \text{false}) \oplus (\text{false} \land \text{true}) = \text{false} \oplus \text{false} = \text{false} \\
&\text{Case 8: } x = \text{false}, y = \text{false}, z = \text{false} \\
&\quad (x \land (y \oplus z)) = (\text{false} \land (\text{false} \oplus \text{false})) = (\text{false} \land \text{false}) = \text{false} \\
&\quad (x \land y) \oplus (x \land z) = (\text{false} \land \text{false}) \oplus (\text{false} \land \text{false}) = \text{false} \oplus \text{false} = \text{false}
\end{aligned}
\]

In all cases, we have shown that $(x \land (y \oplus z)) = (x \land y) \oplus (x \land z)$. Therefore, the left distributive property of the boolean ""and"" operation over the boolean ""exclusive or"" operation holds. This completes the proof.","theorem Bool.and_xor_distrib_left : ∀ (x y z : Bool), (x && xor y z) = xor (x && y) (x && z) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25372,Bool.ne_of_lt,"theorem Bool.ne_of_lt : ∀ {x y : Bool}, x < y → x ≠ y := by sorry","Strict Inequality Implies Inequality in Boolean Values: \( x < y \to x \neq y \) : For any boolean values \( x \) and \( y \), if \( x < y \), then \( x \neq y \).","theorem Bool.ne_of_lt : ∀ {x y : Bool}, x < y → x ≠ y := by
  decide","We need to show that for any boolean values \( x \) and \( y \), if \( x < y \), then \( x \neq y \). The boolean values are \( \text{true} \) and \( \text{false} \). We will consider all possible combinations of \( x \) and \( y \):

1. If \( x = \text{false} \) and \( y = \text{true} \), then \( x < y \) holds, and \( x \neq y \) is true.
2. If \( x = \text{false} \) and \( y = \text{false} \), then \( x < y \) does not hold.
3. If \( x = \text{true} \) and \( y = \text{true} \), then \( x < y \) does not hold.
4. If \( x = \text{true} \) and \( y = \text{false} \), then \( x < y \) does not hold.

In all cases where \( x < y \) holds, we have \( x \neq y \). Therefore, the statement \( x < y \to x \neq y \) is true for all boolean values \( x \) and \( y \). This completes the proof.","theorem Bool.ne_of_lt : ∀ {x y : Bool}, x < y → x ≠ y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25373,Bool.le_antisymm,"theorem Bool.le_antisymm : ∀ {x y : Bool}, x ≤ y → y ≤ x → x = y := by sorry","Antisymmetry of Boolean 'Less Than or Equal To' Relation: $x \leq y \land y \leq x \to x = y$ : For any boolean values $x$ and $y$, if $x \leq y$ and $y \leq x$, then $x = y$.","theorem Bool.le_antisymm : ∀ {x y : Bool}, x ≤ y → y ≤ x → x = y := by
  decide","To prove the antisymmetry of the boolean 'less than or equal to' relation, we need to show that for any boolean values $x$ and $y$, if $x \leq y$ and $y \leq x$, then $x = y$. Since the boolean values are finite and the relation $\leq$ is decidable, we can directly check all possible cases for $x$ and $y$.

1. **Case 1: $x = \text{false}$ and $y = \text{false}$**
- $x \leq y$ is true because $\text{false} \leq \text{false}$.
- $y \leq x$ is true because $\text{false} \leq \text{false}$.
- Therefore, $x = y$ is true because $\text{false} = \text{false}$.

2. **Case 2: $x = \text{false}$ and $y = \text{true}$**
- $x \leq y$ is true because $\text{false} \leq \text{true}$.
- $y \leq x$ is false because $\text{true} \leq \text{false}$ is false.
- This case does not satisfy the condition $y \leq x$, so it does not need to be considered.

3. **Case 3: $x = \text{true}$ and $y = \text{false}$**
- $x \leq y$ is false because $\text{true} \leq \text{false}$ is false.
- $y \leq x$ is true because $\text{false} \leq \text{true}$.
- This case does not satisfy the condition $x \leq y$, so it does not need to be considered.

4. **Case 4: $x = \text{true}$ and $y = \text{true}$**
- $x \leq y$ is true because $\text{true} \leq \text{true}$.
- $y \leq x$ is true because $\text{true} \leq \text{true}$.
- Therefore, $x = y$ is true because $\text{true} = \text{true}$.

In all valid cases, we have shown that if $x \leq y$ and $y \leq x$, then $x = y$. This completes the proof.","theorem Bool.le_antisymm : ∀ {x y : Bool}, x ≤ y → y ≤ x → x = y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25374,Bool.lt_iff_le_not_le,"theorem Bool.lt_iff_le_not_le : ∀ {x y : Bool}, x < y ↔ x ≤ y ∧ ¬ y ≤ x := by sorry","Boolean Less-Than Relation: \( x < y \leftrightarrow x \le y \land \neg (y \le x) \) : For any boolean values \( x \) and \( y \), the relation \( x < y \) holds if and only if \( x \le y \) and \( \neg (y \le x) \).","theorem Bool.lt_iff_le_not_le : ∀ {x y : Bool}, x < y ↔ x ≤ y ∧ ¬ y ≤ x := by
  decide","To prove the equivalence \( x < y \leftrightarrow x \le y \land \neg (y \le x) \) for any boolean values \( x \) and \( y \), we consider all possible values of \( x \) and \( y \). Since the boolean values are finite, we can use a decision procedure to check the truth of the statement for each combination of \( x \) and \( y \).

- If \( x = \text{false} \) and \( y = \text{true} \):
- \( x < y \) is true.
- \( x \le y \) is true.
- \( y \le x \) is false.
- Therefore, \( x < y \leftrightarrow x \le y \land \neg (y \le x) \) holds.

- If \( x = \text{false} \) and \( y = \text{false} \):
- \( x < y \) is false.
- \( x \le y \) is true.
- \( y \le x \) is true.
- Therefore, \( x < y \leftrightarrow x \le y \land \neg (y \le x) \) holds.

- If \( x = \text{true} \) and \( y = \text{true} \):
- \( x < y \) is false.
- \( x \le y \) is true.
- \( y \le x \) is true.
- Therefore, \( x < y \leftrightarrow x \le y \land \neg (y \le x) \) holds.

- If \( x = \text{true} \) and \( y = \text{false} \):
- \( x < y \) is false.
- \( x \le y \) is false.
- \( y \le x \) is true.
- Therefore, \( x < y \leftrightarrow x \le y \land \neg (y \le x) \) holds.

Since the equivalence holds for all possible values of \( x \) and \( y \), the theorem is proven.","theorem Bool.lt_iff_le_not_le : ∀ {x y : Bool}, x < y ↔ x ≤ y ∧ ¬ y ≤ x := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25375,Bool.eq_true_of_true_le,"theorem Bool.eq_true_of_true_le : ∀ {x : Bool}, true ≤ x → x = true := by sorry","Boolean Value Greater Than or Equal to True is True: $\text{true} \leq x \implies x = \text{true}$ : For any boolean value $x$, if `true` is less than or equal to $x$, then $x$ is equal to `true`, i.e., $\text{true} \leq x \implies x = \text{true}$.","theorem Bool.eq_true_of_true_le : ∀ {x : Bool}, true ≤ x → x = true := by
  decide","To prove that for any boolean value $x$, if $\text{true} \leq x$, then $x = \text{true}$, we consider the possible values of $x$. Since $x$ is a boolean value, it can only be either $\text{true}$ or $\text{false}$.

- If $x = \text{true}$, then $\text{true} \leq \text{true}$ is true, and $x = \text{true}$ holds.
- If $x = \text{false}$, then $\text{true} \leq \text{false}$ is false, which contradicts the assumption that $\text{true} \leq x$.

Therefore, the only possible value for $x$ that satisfies $\text{true} \leq x$ is $x = \text{true}$. This completes the proof.","theorem Bool.eq_true_of_true_le : ∀ {x : Bool}, true ≤ x → x = true := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25376,Bool.le_of_lt_or_eq,"theorem Bool.le_of_lt_or_eq : ∀ {x y : Bool}, x < y ∨ x = y → x ≤ y := by sorry","Boolean Less-Than or Equality Implies Less-Than-or-Equal: \( x < y \lor x = y \to x \leq y \) : For any boolean values \( x \) and \( y \), if \( x < y \) or \( x = y \), then \( x \leq y \).","theorem Bool.le_of_lt_or_eq : ∀ {x y : Bool}, x < y ∨ x = y → x ≤ y := by
  decide","We need to show that for any boolean values \( x \) and \( y \), if \( x < y \) or \( x = y \), then \( x \leq y \). Since \( x \) and \( y \) can only be `true` or `false`, we can check all possible cases:

1. **Case 1: \( x = \text{false} \) and \( y = \text{false} \)**
- \( x < y \) is false.
- \( x = y \) is true.
- Therefore, \( x \leq y \) is true.

2. **Case 2: \( x = \text{false} \) and \( y = \text{true} \)**
- \( x < y \) is true.
- \( x = y \) is false.
- Therefore, \( x \leq y \) is true.

3. **Case 3: \( x = \text{true} \) and \( y = \text{false} \)**
- \( x < y \) is false.
- \( x = y \) is false.
- This case does not satisfy the hypothesis \( x < y \lor x = y \).

4. **Case 4: \( x = \text{true} \) and \( y = \text{true} \)**
- \( x < y \) is false.
- \( x = y \) is true.
- Therefore, \( x \leq y \) is true.

In all valid cases, \( x \leq y \) holds. Hence, the statement is true. This completes the proof.","theorem Bool.le_of_lt_or_eq : ∀ {x y : Bool}, x < y ∨ x = y → x ≤ y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25377,Bool.coe_false_iff_false,"theorem Bool.coe_false_iff_false : ∀(a b : Bool), (a = false ↔ b = false) ↔ (!a) = (!b) := by sorry","Equivalence of \( a = \text{false} \leftrightarrow b = \text{false} \) and \( \neg a = \neg b \) : For any boolean values \( a \) and \( b \), the statement \( a = \text{false} \leftrightarrow b = \text{false} \) is equivalent to \( \neg a = \neg b \).","theorem Bool.coe_false_iff_false : ∀(a b : Bool), (a = false ↔ b = false) ↔ (!a) = (!b) := by
  decide","To prove the equivalence \( (a = \text{false} \leftrightarrow b = \text{false}) \leftrightarrow (\neg a = \neg b) \) for any boolean values \( a \) and \( b \), we consider all possible combinations of \( a \) and \( b \):

1. **Case 1: \( a = \text{true} \) and \( b = \text{true} \)**
- \( a = \text{false} \) is false.
- \( b = \text{false} \) is false.
- Therefore, \( a = \text{false} \leftrightarrow b = \text{false} \) is true.
- \( \neg a = \text{false} \) is false.
- \( \neg b = \text{false} \) is false.
- Therefore, \( \neg a = \neg b \) is true.
- Hence, \( (a = \text{false} \leftrightarrow b = \text{false}) \leftrightarrow (\neg a = \neg b) \) holds.

2. **Case 2: \( a = \text{true} \) and \( b = \text{false} \)**
- \( a = \text{false} \) is false.
- \( b = \text{false} \) is true.
- Therefore, \( a = \text{false} \leftrightarrow b = \text{false} \) is false.
- \( \neg a = \text{false} \) is false.
- \( \neg b = \text{false} \) is true.
- Therefore, \( \neg a = \neg b \) is false.
- Hence, \( (a = \text{false} \leftrightarrow b = \text{false}) \leftrightarrow (\neg a = \neg b) \) holds.

3. **Case 3: \( a = \text{false} \) and \( b = \text{true} \)**
- \( a = \text{false} \) is true.
- \( b = \text{false} \) is false.
- Therefore, \( a = \text{false} \leftrightarrow b = \text{false} \) is false.
- \( \neg a = \text{false} \) is true.
- \( \neg b = \text{false} \) is false.
- Therefore, \( \neg a = \neg b \) is false.
- Hence, \( (a = \text{false} \leftrightarrow b = \text{false}) \leftrightarrow (\neg a = \neg b) \) holds.

4. **Case 4: \( a = \text{false} \) and \( b = \text{false} \)**
- \( a = \text{false} \) is true.
- \( b = \text{false} \) is true.
- Therefore, \( a = \text{false} \leftrightarrow b = \text{false} \) is true.
- \( \neg a = \text{false} \) is true.
- \( \neg b = \text{false} \) is true.
- Therefore, \( \neg a = \neg b \) is true.
- Hence, \( (a = \text{false} \leftrightarrow b = \text{false}) \leftrightarrow (\neg a = \neg b) \) holds.

Since the equivalence holds in all possible cases, we conclude that for any boolean values \( a \) and \( b \), the statement \( a = \text{false} \leftrightarrow b = \text{false} \) is equivalent to \( \neg a = \neg b \). This completes the proof.","theorem Bool.coe_false_iff_false : ∀(a b : Bool), (a = false ↔ b = false) ↔ (!a) = (!b) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25378,Bool.bne_left_inj,"theorem Bool.bne_left_inj : ∀ (x y z : Bool), (x != y) = (x != z) ↔ y = z := by sorry","Left Injection of Boolean Not-Equal Function: \((x \neq y) = (x \neq z) \leftrightarrow y = z\) : For any boolean values \( x, y, z \in \text{Bool} \), the equation \((x \neq y) = (x \neq z)\) holds if and only if \( y = z \).","theorem Bool.bne_left_inj : ∀ (x y z : Bool), (x != y) = (x != z) ↔ y = z := by
  decide","We need to show that for any boolean values \( x, y, z \in \text{Bool} \), the equation \((x \neq y) = (x \neq z)\) holds if and only if \( y = z \).

To prove this, we consider the decidability of boolean values. The boolean values are either `true` or `false`, and the inequality \( x \neq y \) is a boolean value itself. Therefore, we can directly evaluate the truth of the equation \((x \neq y) = (x \neq z)\) for all possible values of \( x, y, \) and \( z \).

1. **Case 1: \( x = \text{true} \)**
- If \( y = \text{true} \) and \( z = \text{true} \), then \( (x \neq y) = \text{false} \) and \( (x \neq z) = \text{false} \), so \((x \neq y) = (x \neq z)\) is true, and \( y = z \) is true.
- If \( y = \text{true} \) and \( z = \text{false} \), then \( (x \neq y) = \text{false} \) and \( (x \neq z) = \text{true} \), so \((x \neq y) = (x \neq z)\) is false, and \( y = z \) is false.
- If \( y = \text{false} \) and \( z = \text{true} \), then \( (x \neq y) = \text{true} \) and \( (x \neq z) = \text{false} \), so \((x \neq y) = (x \neq z)\) is false, and \( y = z \) is false.
- If \( y = \text{false} \) and \( z = \text{false} \), then \( (x \neq y) = \text{true} \) and \( (x \neq z) = \text{true} \), so \((x \neq y) = (x \neq z)\) is true, and \( y = z \) is true.

2. **Case 2: \( x = \text{false} \)**
- If \( y = \text{true} \) and \( z = \text{true} \), then \( (x \neq y) = \text{true} \) and \( (x \neq z) = \text{true} \), so \((x \neq y) = (x \neq z)\) is true, and \( y = z \) is true.
- If \( y = \text{true} \) and \( z = \text{false} \), then \( (x \neq y) = \text{true} \) and \( (x \neq z) = \text{false} \), so \((x \neq y) = (x \neq z)\) is false, and \( y = z \) is false.
- If \( y = \text{false} \) and \( z = \text{true} \), then \( (x \neq y) = \text{false} \) and \( (x \neq z) = \text{true} \), so \((x \neq y) = (x \neq z)\) is false, and \( y = z \) is false.
- If \( y = \text{false} \) and \( z = \text{false} \), then \( (x \neq y) = \text{false} \) and \( (x \neq z) = \text{false} \), so \((x \neq y) = (x \neq z)\) is true, and \( y = z \) is true.

In all cases, we see that \((x \neq y) = (x \neq z)\) holds if and only if \( y = z \). Therefore, the theorem is proved.","theorem Bool.bne_left_inj : ∀ (x y z : Bool), (x != y) = (x != z) ↔ y = z := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25379,Bool.or_and_distrib_left,"theorem Bool.or_and_distrib_left : ∀ (x y z : Bool), (x || y && z) = ((x || y) && (x || z)) := by sorry","Left Distributive Property of OR over AND in Boolean Logic: $(x \lor y) \land z = (x \land z) \lor (y \land z)$ : For any boolean values $x$, $y$, and $z$, the expression $(x \lor y) \land z$ is equal to $(x \land z) \lor (y \land z)$. This theorem demonstrates the left distributive property of the boolean ""or"" operation over the boolean ""and"" operation.","theorem Bool.or_and_distrib_left : ∀ (x y z : Bool), (x || y && z) = ((x || y) && (x || z)) := by
  decide","To prove the distributive property, we consider all possible boolean values for $x$, $y$, and $z$. We evaluate the expression $(x \lor y) \land z$ and $(x \land z) \lor (y \land z)$ for each combination of $x$, $y$, and $z$:

1. **Case 1: $x = \text{true}$, $y = \text{true}$, $z = \text{true}$**
\[
(x \lor y) \land z = (\text{true} \lor \text{true}) \land \text{true} = \text{true} \land \text{true} = \text{true}
\]
\[
(x \land z) \lor (y \land z) = (\text{true} \land \text{true}) \lor (\text{true} \land \text{true}) = \text{true} \lor \text{true} = \text{true}
\]
Both expressions are equal.

2. **Case 2: $x = \text{true}$, $y = \text{true}$, $z = \text{false}$**
\[
(x \lor y) \land z = (\text{true} \lor \text{true}) \land \text{false} = \text{true} \land \text{false} = \text{false}
\]
\[
(x \land z) \lor (y \land z) = (\text{true} \land \text{false}) \lor (\text{true} \land \text{false}) = \text{false} \lor \text{false} = \text{false}
\]
Both expressions are equal.

3. **Case 3: $x = \text{true}$, $y = \text{false}$, $z = \text{true}$**
\[
(x \lor y) \land z = (\text{true} \lor \text{false}) \land \text{true} = \text{true} \land \text{true} = \text{true}
\]
\[
(x \land z) \lor (y \land z) = (\text{true} \land \text{true}) \lor (\text{false} \land \text{true}) = \text{true} \lor \text{false} = \text{true}
\]
Both expressions are equal.

4. **Case 4: $x = \text{true}$, $y = \text{false}$, $z = \text{false}$**
\[
(x \lor y) \land z = (\text{true} \lor \text{false}) \land \text{false} = \text{true} \land \text{false} = \text{false}
\]
\[
(x \land z) \lor (y \land z) = (\text{true} \land \text{false}) \lor (\text{false} \land \text{false}) = \text{false} \lor \text{false} = \text{false}
\]
Both expressions are equal.

5. **Case 5: $x = \text{false}$, $y = \text{true}$, $z = \text{true}$**
\[
(x \lor y) \land z = (\text{false} \lor \text{true}) \land \text{true} = \text{true} \land \text{true} = \text{true}
\]
\[
(x \land z) \lor (y \land z) = (\text{false} \land \text{true}) \lor (\text{true} \land \text{true}) = \text{false} \lor \text{true} = \text{true}
\]
Both expressions are equal.

6. **Case 6: $x = \text{false}$, $y = \text{true}$, $z = \text{false}$**
\[
(x \lor y) \land z = (\text{false} \lor \text{true}) \land \text{false} = \text{true} \land \text{false} = \text{false}
\]
\[
(x \land z) \lor (y \land z) = (\text{false} \land \text{false}) \lor (\text{true} \land \text{false}) = \text{false} \lor \text{false} = \text{false}
\]
Both expressions are equal.

7. **Case 7: $x = \text{false}$, $y = \text{false}$, $z = \text{true}$**
\[
(x \lor y) \land z = (\text{false} \lor \text{false}) \land \text{true} = \text{false} \land \text{true} = \text{false}
\]
\[
(x \land z) \lor (y \land z) = (\text{false} \land \text{true}) \lor (\text{false} \land \text{true}) = \text{false} \lor \text{false} = \text{false}
\]
Both expressions are equal.

8. **Case 8: $x = \text{false}$, $y = \text{false}$, $z = \text{false}$**
\[
(x \lor y) \land z = (\text{false} \lor \text{false}) \land \text{false} = \text{false} \land \text{false} = \text{false}
\]
\[
(x \land z) \lor (y \land z) = (\text{false} \land \text{false}) \lor (\text{false} \land \text{false}) = \text{false} \lor \text{false} = \text{false}
\]
Both expressions are equal.

Since the expressions $(x \lor y) \land z$ and $(x \land z) \lor (y \land z)$ are equal for all possible boolean values of $x$, $y$, and $z$, the distributive property holds. This completes the proof.","theorem Bool.or_and_distrib_left : ∀ (x y z : Bool), (x || y && z) = ((x || y) && (x || z)) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25380,Bool.lt_of_le_of_lt,"theorem Bool.lt_of_le_of_lt : ∀ {x y z : Bool}, x ≤ y → y < z → x < z := by sorry","Transitivity of Less-Than Relation in Boolean Type : For any boolean values \( x, y, z \), if \( x \leq y \) and \( y < z \), then \( x < z \).","theorem Bool.lt_of_le_of_lt : ∀ {x y z : Bool}, x ≤ y → y < z → x < z := by
  decide","To prove the transitivity of the less-than relation in the boolean type, we consider the decidability of the boolean values. The boolean type has only two values: `true` and `false`. The relations `≤` and `<` are defined as follows:
- \( x \leq y \) is true if \( x \) is `false` or \( y \) is `true`.
- \( x < y \) is true if \( x \) is `false` and \( y \) is `true`.

We need to show that for any boolean values \( x, y, z \), if \( x \leq y \) and \( y < z \), then \( x < z \).

We evaluate the statement for all possible combinations of \( x, y, \) and \( z \):

1. **Case 1: \( x = \text{false} \)**
- If \( y = \text{false} \), then \( x \leq y \) is true, but \( y < z \) is false for any \( z \), so this case does not apply.
- If \( y = \text{true} \), then \( x \leq y \) is true. For \( y < z \) to be true, \( z \) must be `true`. In this case, \( x < z \) is true because \( x = \text{false} \) and \( z = \text{true} \).

2. **Case 2: \( x = \text{true} \)**
- If \( y = \text{false} \), then \( x \leq y \) is false, so this case does not apply.
- If \( y = \text{true} \), then \( x \leq y \) is true. For \( y < z \) to be true, \( z \) must be `true`. However, \( x < z \) is false because \( x = \text{true} \) and \( z = \text{true} \), so this case does not apply.

From the above cases, we see that the only valid combination where both \( x \leq y \) and \( y < z \) are true is when \( x = \text{false} \), \( y = \text{true} \), and \( z = \text{true} \). In this case, \( x < z \) is true.

Therefore, the statement \( x \leq y \) and \( y < z \) implies \( x < z \) holds for all boolean values \( x, y, z \). This completes the proof.","theorem Bool.lt_of_le_of_lt : ∀ {x y z : Bool}, x ≤ y → y < z → x < z := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25382,Bool.not_inj_iff,"theorem Bool.not_inj_iff : ∀ {x y : Bool}, (!x) = (!y) ↔ x = y := by sorry","Negation is Injective in Boolean Values: $\neg x = \neg y \iff x = y$ : For any boolean values $x$ and $y$, the negation of $x$ is equal to the negation of $y$ if and only if $x$ is equal to $y$. In other words, $\neg x = \neg y \iff x = y$.","theorem Bool.not_inj_iff : ∀ {x y : Bool}, (!x) = (!y) ↔ x = y := by
  decide","To prove the statement, we consider all possible values of $x$ and $y$ in the boolean domain, which are $\{ \text{true}, \text{false} \}$. We will check the equivalence $\neg x = \neg y \iff x = y$ for each combination of $x$ and $y$.

1. **Case 1: $x = \text{true}$ and $y = \text{true}$**
- $\neg x = \neg \text{true} = \text{false}$
- $\neg y = \neg \text{true} = \text{false}$
- Therefore, $\neg x = \neg y$ and $x = y$.

2. **Case 2: $x = \text{true}$ and $y = \text{false}$**
- $\neg x = \neg \text{true} = \text{false}$
- $\neg y = \neg \text{false} = \text{true}$
- Therefore, $\neg x \neq \neg y$ and $x \neq y$.

3. **Case 3: $x = \text{false}$ and $y = \text{true}$**
- $\neg x = \neg \text{false} = \text{true}$
- $\neg y = \neg \text{true} = \text{false}$
- Therefore, $\neg x \neq \neg y$ and $x \neq y$.

4. **Case 4: $x = \text{false}$ and $y = \text{false}$**
- $\neg x = \neg \text{false} = \text{true}$
- $\neg y = \neg \text{false} = \text{true}$
- Therefore, $\neg x = \neg y$ and $x = y$.

In all cases, we have verified that $\neg x = \neg y$ if and only if $x = y$. This completes the proof.","theorem Bool.not_inj_iff : ∀ {x y : Bool}, (!x) = (!y) ↔ x = y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25383,Bool.eq_false_imp_eq_true,"theorem Bool.eq_false_imp_eq_true : ∀(b:Bool), (b = false → b = true) ↔ (b = true) := by sorry","Boolean False Implies True Identity: $b = \text{false} \to (b = \text{true} \leftrightarrow b = \text{true})$ : For any boolean value $b$, if $b = \text{false}$, then $b = \text{true}$ if and only if $b = \text{true}$.","theorem Bool.eq_false_imp_eq_true : ∀(b:Bool), (b = false → b = true) ↔ (b = true) := by
  decide","We need to show that for any boolean value $b$, if $b = \text{false}$, then the statement $b = \text{true} \leftrightarrow b = \text{true}$ holds.

Since the statement $b = \text{true} \leftrightarrow b = \text{true}$ is a tautology (it is always true regardless of the value of $b$), it holds trivially. Therefore, the implication $b = \text{false} \to (b = \text{true} \leftrightarrow b = \text{true})$ is also true. This completes the proof.","theorem Bool.eq_false_imp_eq_true : ∀(b:Bool), (b = false → b = true) ↔ (b = true) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25384,Bool.eq_true_imp_eq_false,"theorem Bool.eq_true_imp_eq_false : ∀(b:Bool), (b = true → b = false) ↔ (b = false) := by sorry","Boolean True Implies False Identity: $b = \text{true} \to (b = \text{false} \leftrightarrow b = \text{false})$ : For any boolean value $b$, if $b = \text{true}$, then $b = \text{false}$ if and only if $b = \text{false}$.","theorem Bool.eq_true_imp_eq_false : ∀(b:Bool), (b = true → b = false) ↔ (b = false) := by
  decide","We need to show that for any boolean value $b$, if $b = \text{true}$, then the statement $b = \text{false} \leftrightarrow b = \text{false}$ holds.

Since the statement $b = \text{false} \leftrightarrow b = \text{false}$ is a tautology (it is always true), it holds regardless of the value of $b$. Therefore, if $b = \text{true}$, the statement $b = \text{false} \leftrightarrow b = \text{false}$ is still true. This completes the proof.","theorem Bool.eq_true_imp_eq_false : ∀(b:Bool), (b = true → b = false) ↔ (b = false) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25385,Bool.and_or_inj_right_iff,"theorem Bool.and_or_inj_right_iff :
    ∀ {m x y : Bool}, (x && m) = (y && m) ∧ (x || m) = (y || m) ↔ x = y := by sorry","Injectivity of Conjunction and Disjunction on the Right: $(x \land m = y \land m) \land (x \lor m = y \lor m) \leftrightarrow x = y$ : For any boolean values $m$, $x$, and $y$, the following equivalence holds:
\[
(x \land m = y \land m) \land (x \lor m = y \lor m) \leftrightarrow x = y
\]
This means that if the conjunction and disjunction of $x$ and $m$ are equal to the conjunction and disjunction of $y$ and $m$, respectively, then $x$ is equal to $y$.","theorem Bool.and_or_inj_right_iff :
    ∀ {m x y : Bool}, (x && m) = (y && m) ∧ (x || m) = (y || m) ↔ x = y := by
  decide","To prove the equivalence, we need to show both directions of the biconditional statement.

1. **(⇒) If $x = y$, then $(x \land m = y \land m) \land (x \lor m = y \lor m)$:**
- Assume $x = y$.
- Then, $x \land m = y \land m$ and $x \lor m = y \lor m$ are trivially true because both sides of the equations are the same.

2. **(⇐) If $(x \land m = y \land m) \land (x \lor m = y \lor m)$, then $x = y$:**
- Assume $(x \land m = y \land m) \land (x \lor m = y \lor m)$.
- We need to show that $x = y$.
- Consider the possible values of $m$:
- If $m = \text{true}$:
- Then $x \land \text{true} = y \land \text{true}$ simplifies to $x = y$.
- Similarly, $x \lor \text{true} = y \lor \text{true}$ simplifies to $\text{true} = \text{true}$, which is always true.
- If $m = \text{false}$:
- Then $x \land \text{false} = y \land \text{false}$ simplifies to $\text{false} = \text{false}$, which is always true.
- Similarly, $x \lor \text{false} = y \lor \text{false}$ simplifies to $x = y$.
- In both cases, we conclude that $x = y$.

Since both directions of the biconditional statement are true, the equivalence holds. Therefore, the theorem is proved.","theorem Bool.and_or_inj_right_iff :
    ∀ {m x y : Bool}, (x && m) = (y && m) ∧ (x || m) = (y || m) ↔ x = y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25386,Bool.and_or_inj_left_iff,"theorem Bool.and_or_inj_left_iff :
    ∀ {m x y : Bool}, (m && x) = (m && y) ∧ (m || x) = (m || y) ↔ x = y := by sorry","Injectivity of Left Conjunction and Disjunction in Boolean Logic: \((m \land x) = (m \land y) \land (m \lor x) = (m \lor y) \leftrightarrow x = y\) : For any boolean values \( m \), \( x \), and \( y \), the conjunction \( (m \land x) = (m \land y) \) and the disjunction \( (m \lor x) = (m \lor y) \) hold if and only if \( x = y \).","theorem Bool.and_or_inj_left_iff :
    ∀ {m x y : Bool}, (m && x) = (m && y) ∧ (m || x) = (m || y) ↔ x = y := by
  decide","We need to show that for any boolean values \( m \), \( x \), and \( y \), the conjunction \( (m \land x) = (m \land y) \) and the disjunction \( (m \lor x) = (m \lor y) \) hold if and only if \( x = y \).

1. **(\(\Rightarrow\)) Assume \( (m \land x) = (m \land y) \) and \( (m \lor x) = (m \lor y) \).**
- If \( m = \text{true} \):
- Then \( (m \land x) = x \) and \( (m \land y) = y \). Since \( (m \land x) = (m \land y) \), we have \( x = y \).
- If \( m = \text{false} \):
- Then \( (m \land x) = \text{false} \) and \( (m \land y) = \text{false} \). The condition \( (m \land x) = (m \land y) \) is trivially satisfied.
- Also, \( (m \lor x) = x \) and \( (m \lor y) = y \). Since \( (m \lor x) = (m \lor y) \), we have \( x = y \).

2. **(\(\Leftarrow\)) Assume \( x = y \).**
- If \( x = y \), then \( (m \land x) = (m \land y) \) and \( (m \lor x) = (m \lor y) \) are trivially true because both sides of the equations are equal.

Thus, we have shown that \( (m \land x) = (m \land y) \) and \( (m \lor x) = (m \lor y) \) hold if and only if \( x = y \). This completes the proof.","theorem Bool.and_or_inj_left_iff :
    ∀ {m x y : Bool}, (m && x) = (m && y) ∧ (m || x) = (m || y) ↔ x = y := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25387,Bool.toNat_le,theorem Bool.toNat_le (c : Bool) : c.toNat ≤ 1 := by sorry,"Boolean to Natural Number Representation is Less Than or Equal to One : For any boolean value \( c \), the natural number representation of \( c \) (i.e., \( \text{Bool.toNat}(c) \)) is less than or equal to 1. Specifically, \(\text{Bool.toNat}(\text{false}) = 0\) and \(\text{Bool.toNat}(\text{true}) = 1\), so both values satisfy \( \text{Bool.toNat}(c) \leq 1 \).","theorem Bool.toNat_le (c : Bool) : c.toNat ≤ 1 := by
  cases c <;> trivial","We will consider every possible case of the boolean value \( c \). Specifically, we have two cases: \( c = \text{false} \) and \( c = \text{true} \).

1. **Case 1: \( c = \text{false} \)**
- We need to show that \( \text{Bool.toNat}(\text{false}) \leq 1 \).
- By definition, \( \text{Bool.toNat}(\text{false}) = 0 \).
- Since \( 0 \leq 1 \) is true, this case is straightforward.

2. **Case 2: \( c = \text{true} \)**
- We need to show that \( \text{Bool.toNat}(\text{true}) \leq 1 \).
- By definition, \( \text{Bool.toNat}(\text{true}) = 1 \).
- Since \( 1 \leq 1 \) is true, this case is also straightforward.

Since both cases are true, we conclude that for any boolean value \( c \), \( \text{Bool.toNat}(c) \leq 1 \). This completes the proof.","theorem Bool.toNat_le (c : Bool) : c.toNat ≤ 1 := by
/- We will consider every possible case of the boolean value \( c \). Specifically, we have two cases: \( c = \text{false} \) and \( c = \text{true} \). -/
/- Case 1: \( c = \text{false} \)
Case 2: \( c = \text{true} \) -/
/- For the case \( c = \text{false} \), we need to show that \( \text{Bool.toNat}(\text{false}) \leq 1 \). Since \( \text{Bool.toNat}(\text{false}) = 0 \) and \( 0 \leq 1 \) is true, this case is straightforward. -/
/- For the case \( c = \text{true} \), we need to show that \( \text{Bool.toNat}(\text{true}) \leq 1 \). Since \( \text{Bool.toNat}(\text{true}) = 1 \) and \( 1 \leq 1 \) is true, this case is also straightforward. -/
  cases c <;> trivial","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25388,Bool.and_or_inj_left,"theorem Bool.and_or_inj_left : ∀ {m x y : Bool}, (m && x) = (m && y) → (m || x) = (m || y) → x = y := by sorry","Injectivity of Left Conjunction and Disjunction in Boolean Logic : For any boolean values $m$, $x$, and $y$, if $(m \land x) = (m \land y)$ and $(m \lor x) = (m \lor y)$, then $x = y$.","theorem Bool.and_or_inj_left : ∀ {m x y : Bool}, (m && x) = (m && y) → (m || x) = (m || y) → x = y := by
  decide","We need to show that for any boolean values $m$, $x$, and $y$, if $(m \land x) = (m \land y)$ and $(m \lor x) = (m \lor y)$, then $x = y$. Since boolean values are decidable, we can check all possible cases for $m$, $x$, and $y$.

1. **Case 1: $m = \text{true}$**
- If $m = \text{true}$, then $(m \land x) = x$ and $(m \land y) = y$. Therefore, $(m \land x) = (m \land y)$ implies $x = y$.
- Similarly, $(m \lor x) = \text{true}$ and $(m \lor y) = \text{true}$. Therefore, $(m \lor x) = (m \lor y)$ is always true.
- Hence, if $m = \text{true}$, the conditions $(m \land x) = (m \land y)$ and $(m \lor x) = (m \lor y)$ imply $x = y$.

2. **Case 2: $m = \text{false}$**
- If $m = \text{false}$, then $(m \land x) = \text{false}$ and $(m \land y) = \text{false}$. Therefore, $(m \land x) = (m \land y)$ is always true.
- Similarly, $(m \lor x) = x$ and $(m \lor y) = y$. Therefore, $(m \lor x) = (m \lor y)$ implies $x = y$.
- Hence, if $m = \text{false}$, the conditions $(m \land x) = (m \land y)$ and $(m \lor x) = (m \lor y)$ imply $x = y$.

Since we have checked all possible cases for $m$, $x$, and $y$, we conclude that if $(m \land x) = (m \land y)$ and $(m \lor x) = (m \lor y)$, then $x = y$. This completes the proof.","theorem Bool.and_or_inj_left : ∀ {m x y : Bool}, (m && x) = (m && y) → (m || x) = (m || y) → x = y := by
/- We use the decidability of boolean values to directly conclude the proof. Since the boolean values are decidable, we can check all possible cases for $m$, $x$, and $y$ to verify that if $(m \land x) = (m \land y)$ and $(m \lor x) = (m \lor y)$, then $x = y$. -/
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25389,Bool.and_or_inj_right,"theorem Bool.and_or_inj_right : ∀ {m x y : Bool}, (x && m) = (y && m) → (x || m) = (y || m) → x = y := by sorry","Injectivity of Conjunction and Disjunction on the Right: $(x \land m) = (y \land m) \land (x \lor m) = (y \lor m) \to x = y$ : For any boolean values $m$, $x$, and $y$, if $(x \land m) = (y \land m)$ and $(x \lor m) = (y \lor m)$, then $x = y$.","theorem Bool.and_or_inj_right : ∀ {m x y : Bool}, (x && m) = (y && m) → (x || m) = (y || m) → x = y := by
  decide","We need to show that for any boolean values $m$, $x$, and $y$, if $(x \land m) = (y \land m)$ and $(x \lor m) = (y \lor m)$, then $x = y$. Since boolean values are decidable, we can check all possible combinations of $x$, $y$, and $m$:

1. **Case 1: $x = \text{true}$, $y = \text{true}$**
- $(x \land m) = (\text{true} \land m) = m$
- $(y \land m) = (\text{true} \land m) = m$
- $(x \lor m) = (\text{true} \lor m) = \text{true}$
- $(y \lor m) = (\text{true} \lor m) = \text{true}$
- Both conditions $(x \land m) = (y \land m)$ and $(x \lor m) = (y \lor m)$ are satisfied, and $x = y$.

2. **Case 2: $x = \text{true}$, $y = \text{false}$**
- $(x \land m) = (\text{true} \land m) = m$
- $(y \land m) = (\text{false} \land m) = \text{false}$
- $(x \lor m) = (\text{true} \lor m) = \text{true}$
- $(y \lor m) = (\text{false} \lor m) = m$
- The condition $(x \land m) = (y \land m)$ is not satisfied, so this case does not apply.

3. **Case 3: $x = \text{false}$, $y = \text{true}$**
- $(x \land m) = (\text{false} \land m) = \text{false}$
- $(y \land m) = (\text{true} \land m) = m$
- $(x \lor m) = (\text{false} \lor m) = m$
- $(y \lor m) = (\text{true} \lor m) = \text{true}$
- The condition $(x \lor m) = (y \lor m)$ is not satisfied, so this case does not apply.

4. **Case 4: $x = \text{false}$, $y = \text{false}$**
- $(x \land m) = (\text{false} \land m) = \text{false}$
- $(y \land m) = (\text{false} \land m) = \text{false}$
- $(x \lor m) = (\text{false} \lor m) = m$
- $(y \lor m) = (\text{false} \lor m) = m$
- Both conditions $(x \land m) = (y \land m)$ and $(x \lor m) = (y \lor m)$ are satisfied, and $x = y$.

In all valid cases, we have shown that if $(x \land m) = (y \land m)$ and $(x \lor m) = (y \lor m)$, then $x = y$. Therefore, the theorem is proved.","theorem Bool.and_or_inj_right : ∀ {m x y : Bool}, (x && m) = (y && m) → (x || m) = (y || m) → x = y := by
/- We use the decidability of boolean values to directly conclude the proof. Since the boolean values are decidable, we can check all possible cases for $x$, $y$, and $m$ to verify that if $(x \land m) = (y \land m)$ and $(x \lor m) = (y \lor m)$, then $x = y$. -/
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25392,Bool.if_true_right,"theorem Bool.if_true_right (p : Prop) [h : Decidable p] (t : Bool) :
    (ite p t true) = (!(p : Bool) || t) := by sorry","Distributive Property of If-then-else over True Boolean Value: \((\text{if } p \text{ then } t \text{ else } \text{true}) = (\text{not } (\text{decide } p)) \lor t\) : For any proposition \( p \) and boolean value \( t \), the if-then-else expression \((\text{if } p \text{ then } t \text{ else } \text{true})\) is equal to the boolean OR operation \((\text{not } (\text{decide } p)) \text{ or } t\). This can be written as:
\[
(\text{if } p \text{ then } t \text{ else } \text{true}) = (\text{not } (\text{decide } p)) \lor t
\]","theorem Bool.if_true_right (p : Prop) [h : Decidable p] (t : Bool) :
    (ite p t true) = (!(p : Bool) || t) := by
  cases h with | _ p => simp [p]","We will consider the two possible cases for the decidable proposition \( p \).

**Case 1: \( p \) is true.**
- The if-then-else expression \((\text{if } p \text{ then } t \text{ else } \text{true})\) simplifies to \( t \).
- The boolean OR operation \((\text{not } (\text{decide } p)) \lor t\) simplifies to \((\text{not } \text{true}) \lor t\), which is \(\text{false} \lor t\), and this is equal to \( t \).
- Therefore, \((\text{if } p \text{ then } t \text{ else } \text{true}) = t\) and \((\text{not } (\text{decide } p)) \lor t = t\), so the two expressions are equal.

**Case 2: \( p \) is false.**
- The if-then-else expression \((\text{if } p \text{ then } t \text{ else } \text{true})\) simplifies to \(\text{true}\).
- The boolean OR operation \((\text{not } (\text{decide } p)) \lor t\) simplifies to \((\text{not } \text{false}) \lor t\), which is \(\text{true} \lor t\), and this is equal to \(\text{true}\).
- Therefore, \((\text{if } p \text{ then } t \text{ else } \text{true}) = \text{true}\) and \((\text{not } (\text{decide } p)) \lor t = \text{true}\), so the two expressions are equal.

In both cases, the expressions are equal, thus proving the theorem.","theorem Bool.if_true_right (p : Prop) [h : Decidable p] (t : Bool) :
    (ite p t true) = (!(p : Bool) || t) := by
  cases h with | _ p => simp [p]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25393,Bool.cond_decide,"theorem Bool.cond_decide {α} (p : Prop) [Decidable p] (t e : α) :
    cond (decide p) t e = if p then t else e := by sorry","Conditional Expression with `decide` Equals If-then-else Expression: \((\text{if } \text{decide } p \text{ then } t \text{ else } e) = (\text{if } p \text{ then } t \text{ else } e)\) : For any decidable proposition \( p \) and any values \( t \) and \( e \) of type \( \alpha \), the expression `bif decide p then t else e` is equal to `if p then t else e`. In other words, if \( p \) is true, both expressions evaluate to \( t \); if \( p \) is false, both expressions evaluate to \( e \).","theorem Bool.cond_decide {α} (p : Prop) [Decidable p] (t e : α) :
    cond (decide p) t e = if p then t else e := by
  simp [cond_eq_ite]","We need to show that \((\text{if } \text{decide } p \text{ then } t \text{ else } e) = (\text{if } p \text{ then } t \text{ else } e)\).

Using the theorem that the conditional function `cond` (or `bif b then t else e`) is equivalent to the if-then-else function `ite` (or `if b = true then t else e`), we can simplify the proposition. Specifically, `decide p` is a boolean value that is `true` if \( p \) is true and `false` if \( p \) is false. Therefore, the conditional function `cond` with `decide p` is equivalent to the if-then-else function `ite` with \( p \).

Thus, \((\text{if } \text{decide } p \text{ then } t \text{ else } e) = (\text{if } p \text{ then } t \text{ else } e)\) is trivially true. This completes the proof.","theorem Bool.cond_decide {α} (p : Prop) [Decidable p] (t e : α) :
    cond (decide p) t e = if p then t else e := by
/- Using the theorem that the conditional function `cond` (or `bif b then t else e`) is equivalent to the if-then-else function `ite` (or `if b = true then t else e`), we can simplify the proposition we want to show. Specifically, we need to show that \((\text{if } \text{decide } p \text{ then } t \text{ else } e) = (\text{if } p \text{ then } t \text{ else } e)\). Since `decide p` is a boolean value that is `true` if \( p \) is true and `false` if \( p \) is false, the conditional function `cond` with `decide p` is equivalent to the if-then-else function `ite` with \( p \). Therefore, the proposition is trivially true. -/
  simp [cond_eq_ite]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25394,Bool.ite_eq_true_distrib,"theorem Bool.ite_eq_true_distrib (p : Prop) [h : Decidable p] (t f : Bool) :
    (ite p t f = true) = ite p (t = true) (f = true) := by sorry","Distributive Property of If-then-else over True Boolean Value: $(\text{if } p \text{ then } t \text{ else } f) = \text{true} \iff \text{if } p \text{ then } t = \text{true} \text{ else } f = \text{true}$ : For any proposition $p$ and boolean values $t$ and $f$, the if-then-else expression $(\text{if } p \text{ then } t \text{ else } f)$ is equal to `true` if and only if $p$ is true and $t$ is `true`, or $p$ is false and $f$ is `true`. This can be written as:
\[
(\text{if } p \text{ then } t \text{ else } f) = \text{true} \iff \text{if } p \text{ then } t = \text{true} \text{ else } f = \text{true}
\]","theorem Bool.ite_eq_true_distrib (p : Prop) [h : Decidable p] (t f : Bool) :
    (ite p t f = true) = ite p (t = true) (f = true) := by
  cases h with | _ p => simp [p]","We will consider every possible case of the decidable proposition $p$.

**Case 1: $p$ is true.**
- If $p$ is true, the expression $(\text{if } p \text{ then } t \text{ else } f)$ simplifies to $t$.
- Therefore, $(\text{if } p \text{ then } t \text{ else } f) = \text{true}$ is equivalent to $t = \text{true}$.
- Similarly, the right-hand side of the equivalence, $\text{if } p \text{ then } t = \text{true} \text{ else } f = \text{true}$, simplifies to $t = \text{true}$.
- Hence, the equivalence holds in this case.

**Case 2: $p$ is false.**
- If $p$ is false, the expression $(\text{if } p \text{ then } t \text{ else } f)$ simplifies to $f$.
- Therefore, $(\text{if } p \text{ then } t \text{ else } f) = \text{true}$ is equivalent to $f = \text{true}$.
- Similarly, the right-hand side of the equivalence, $\text{if } p \text{ then } t = \text{true} \text{ else } f = \text{true}$, simplifies to $f = \text{true}$.
- Hence, the equivalence holds in this case.

Since the equivalence holds in both cases, the theorem is proved.","theorem Bool.ite_eq_true_distrib (p : Prop) [h : Decidable p] (t f : Bool) :
    (ite p t f = true) = ite p (t = true) (f = true) := by
/- We will consider every possible case of the decidable proposition $p$.

**Case 1: $p$ is true.**
Using the fact that $p$ is true, we simplify the expression $(\text{if } p \text{ then } t \text{ else } f) = \text{true}$ to $t = \text{true}$. Similarly, the right-hand side of the equivalence, $\text{if } p \text{ then } t = \text{true} \text{ else } f = \text{true}$, simplifies to $t = \text{true}$. Therefore, the equivalence holds in this case.

**Case 2: $p$ is false.**
Using the fact that $p$ is false, we simplify the expression $(\text{if } p \text{ then } t \text{ else } f) = \text{true}$ to $f = \text{true}$. Similarly, the right-hand side of the equivalence, $\text{if } p \text{ then } t = \text{true} \text{ else } f = \text{true}$, simplifies to $f = \text{true}$. Therefore, the equivalence holds in this case. -/
  cases h with | _ p => simp [p]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25395,Bool.cond_eq_ite_iff,"theorem Bool.cond_eq_ite_iff (a : Bool) (p : Prop) [h : Decidable p] (x y u v : α) :
  (cond a x y = ite p u v) ↔ ite a x y = ite p u v := by sorry","Equivalence of Boolean Conditional and Propositional If-then-else: $(b \text{ if } a \text{ then } x \text{ else } y) = (\text{if } p \text{ then } u \text{ else } v) \leftrightarrow (\text{if } a = \text{true} \text{ then } x \text{ else } y) = (\text{if } p \text{ then } u \text{ else } v)$ : For any type $\alpha$, boolean value $a$, proposition $p$, and elements $x, y, u, v \in \alpha$, the following equivalence holds:
\[
(b \text{ if } a \text{ then } x \text{ else } y) = (\text{if } p \text{ then } u \text{ else } v) \quad \text{if and only if} \quad (\text{if } a = \text{true} \text{ then } x \text{ else } y) = (\text{if } p \text{ then } u \text{ else } v).
\]","theorem Bool.cond_eq_ite_iff (a : Bool) (p : Prop) [h : Decidable p] (x y u v : α) :
  (cond a x y = ite p u v) ↔ ite a x y = ite p u v := by
  simp [Bool.cond_eq_ite]","To prove the equivalence, we use the theorem that the boolean conditional function `cond` (or `bif b then t else e`) is equivalent to the if-then-else function `ite` (or `if b = true then t else e`). This theorem states that for any boolean value $a$ and elements $x, y \in \alpha$:
\[
(b \text{ if } a \text{ then } x \text{ else } y) = (\text{if } a = \text{true} \text{ then } x \text{ else } y).
\]
Using this equivalence, we can simplify the original proposition:
\[
(b \text{ if } a \text{ then } x \text{ else } y) = (\text{if } p \text{ then } u \text{ else } v) \quad \text{if and only if} \quad (\text{if } a = \text{true} \text{ then } x \text{ else } y) = (\text{if } p \text{ then } u \text{ else } v).
\]
Since the boolean conditional function and the if-then-else function are equivalent, the original proposition is true. This completes the proof.","theorem Bool.cond_eq_ite_iff (a : Bool) (p : Prop) [h : Decidable p] (x y u v : α) :
  (cond a x y = ite p u v) ↔ ite a x y = ite p u v := by
/- Using the theorem that the boolean conditional function `cond` (or `bif b then t else e`) is equivalent to the if-then-else function `ite` (or `if b = true then t else e`), we can simplify the proposition we want to show. Specifically, we need to prove that:
\[
(b \text{ if } a \text{ then } x \text{ else } y) = (\text{if } p \text{ then } u \text{ else } v) \quad \text{if and only if} \quad (\text{if } a = \text{true} \text{ then } x \text{ else } y) = (\text{if } p \text{ then } u \text{ else } v).
\]
This simplification is valid because the boolean conditional function and the if-then-else function are equivalent for boolean conditions. -/
  simp [Bool.cond_eq_ite]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25397,Bool.cond_true_left,"theorem Bool.cond_true_left : ∀(c f : Bool), cond c true f  = ( c || f) := by sorry","Conditional True Left Equals Boolean Or: $(\text{if } c \text{ then } \text{true} \text{ else } f) = (c \lor f)$ : For any boolean values $c$ and $f$, the expression `bif c then true else f` is equal to `c || f`, i.e., $(\text{if } c \text{ then } \text{true} \text{ else } f) = (c \lor f)$.","theorem Bool.cond_true_left : ∀(c f : Bool), cond c true f  = ( c || f) := by
  decide","To prove the theorem, we need to show that for any boolean values $c$ and $f$, the expression $(\text{if } c \text{ then } \text{true} \text{ else } f)$ is equal to $(c \lor f)$. We can verify this by considering all possible values of $c$ and $f$:

1. **Case 1: $c = \text{true}$**
- If $c = \text{true}$, then $(\text{if } c \text{ then } \text{true} \text{ else } f) = \text{true}$.
- Also, $(c \lor f) = (\text{true} \lor f) = \text{true}$.
- Therefore, $(\text{if } c \text{ then } \text{true} \text{ else } f) = (c \lor f)$.

2. **Case 2: $c = \text{false}$**
- If $c = \text{false}$, then $(\text{if } c \text{ then } \text{true} \text{ else } f) = f$.
- Also, $(c \lor f) = (\text{false} \lor f) = f$.
- Therefore, $(\text{if } c \text{ then } \text{true} \text{ else } f) = (c \lor f)$.

Since the equality holds in both cases, we conclude that for any boolean values $c$ and $f$, the expression $(\text{if } c \text{ then } \text{true} \text{ else } f)$ is equal to $(c \lor f)$. This completes the proof.","theorem Bool.cond_true_left : ∀(c f : Bool), cond c true f  = ( c || f) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25398,Bool.cond_eq_false_distrib,"theorem Bool.cond_eq_false_distrib : ∀(c t f : Bool),
    (cond c t f = false) = ite (c = true) (t = false) (f = false) := by sorry","Distributive Property of Conditional Function with False Outcome : For any boolean values $c$, $t$, and $f$, the equation $(\text{bif } c \text{ then } t \text{ else } f) = \text{false}$ holds if and only if $c = \text{true}$ implies $t = \text{false}$, and $c = \text{false}$ implies $f = \text{false}$.","theorem Bool.cond_eq_false_distrib : ∀(c t f : Bool),
    (cond c t f = false) = ite (c = true) (t = false) (f = false) := by
  decide","To prove the theorem, we need to show that the equation $(\text{bif } c \text{ then } t \text{ else } f) = \text{false}$ holds if and only if the following conditions are satisfied:
1. If $c = \text{true}$, then $t = \text{false}$.
2. If $c = \text{false}$, then $f = \text{false}$.

We will consider all possible values of $c$, $t$, and $f$ and verify the statement in each case.

1. **Case 1: $c = \text{true}$**
- If $c = \text{true}$, then $(\text{bif } c \text{ then } t \text{ else } f) = t$.
- Therefore, $(\text{bif } c \text{ then } t \text{ else } f) = \text{false}$ if and only if $t = \text{false}$.

2. **Case 2: $c = \text{false}$**
- If $c = \text{false}$, then $(\text{bif } c \text{ then } t \text{ else } f) = f$.
- Therefore, $(\text{bif } c \text{ then } t \text{ else } f) = \text{false}$ if and only if $f = \text{false}$.

Since the statement holds in both cases, we conclude that the equation $(\text{bif } c \text{ then } t \text{ else } f) = \text{false}$ is true if and only if $c = \text{true}$ implies $t = \text{false}$, and $c = \text{false}$ implies $f = \text{false}$. This completes the proof.","theorem Bool.cond_eq_false_distrib : ∀(c t f : Bool),
    (cond c t f = false) = ite (c = true) (t = false) (f = false) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25400,Bool.cond_neg,theorem Bool.cond_neg {b : Bool} {a a' : α} (h : b = false) : (bif b then a else a') = a' := by sorry,"Conditional Expression Evaluates to Second Argument if Condition is False: $(\text{if } b \text{ then } a \text{ else } a') = a'$ if $b = \text{false}$ : For any type $\alpha$ and any boolean condition $b$, if $b$ is false, then the conditional expression `bif b then a else a'` evaluates to $a'$, i.e., $(\text{if } b \text{ then } a \text{ else } a') = a'$.","theorem Bool.cond_neg {b : Bool} {a a' : α} (h : b = false) : (bif b then a else a') = a' := by
  rw [h, cond_false]","We start with the assumption that $b = \text{false}$. We need to show that the conditional expression $(\text{if } b \text{ then } a \text{ else } a')$ evaluates to $a'$. By substituting $b$ with $\text{false}$ in the conditional expression, we get $(\text{if } \text{false} \text{ then } a \text{ else } a')$. According to the property of the conditional function, $\text{cond}(\text{false}, a, a') = a'$, the expression simplifies to $a'$. Therefore, $(\text{if } b \text{ then } a \text{ else } a') = a'$, which is trivially true by the reflexivity of equality. This completes the proof.","theorem Bool.cond_neg {b : Bool} {a a' : α} (h : b = false) : (bif b then a else a') = a' := by
/- Since the hypothesis $h$ states that $b = \text{false}$, we can substitute $b$ with $\text{false}$ in the goal. This transforms the goal from $(\text{if } b \text{ then } a \text{ else } a') = a'$ to $(\text{if } \text{false} \text{ then } a \text{ else } a') = a'$. By the property of the conditional function, $\text{cond}(\text{false}, a, a') = a'$, the goal simplifies to $a' = a'$. This is trivially true by the reflexivity of equality. -/
  rw [h, cond_false]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25401,Bool.ite_eq_false_distrib,"theorem Bool.ite_eq_false_distrib (p : Prop) [h : Decidable p] (t f : Bool) :
    (ite p t f = false) = ite p (t = false) (f = false) := by sorry","Distributive Property of If-Then-Else over False Boolean Value: \((\text{if } p \text{ then } t \text{ else } f) = \text{false} \iff \text{if } p \text{ then } t = \text{false} \text{ else } f = \text{false}\) : For any proposition \( p \) and boolean values \( t \) and \( f \), the if-then-else expression \( \text{if } p \text{ then } t \text{ else } f \) is equal to `false` if and only if \( p \) is true and \( t \) is `false`, or \( p \) is false and \( f \) is `false`. This can be written as:
\[
(\text{if } p \text{ then } t \text{ else } f) = \text{false} \iff \text{if } p \text{ then } t = \text{false} \text{ else } f = \text{false}
\]","theorem Bool.ite_eq_false_distrib (p : Prop) [h : Decidable p] (t f : Bool) :
    (ite p t f = false) = ite p (t = false) (f = false) := by
  cases h with | _ p => simp [p]","We will consider the two possible cases for the proposition \( p \).

1. **Case 1: \( p \) is true.**
- In this case, the if-then-else expression \(\text{if } p \text{ then } t \text{ else } f\) simplifies to \( t \).
- Therefore, the goal \((\text{if } p \text{ then } t \text{ else } f) = \text{false}\) simplifies to \( t = \text{false} \).
- Similarly, the right-hand side of the equivalence \(\text{if } p \text{ then } t = \text{false} \text{ else } f = \text{false}\) simplifies to \( t = \text{false} \).
- Hence, the equivalence holds in this case.

2. **Case 2: \( p \) is false.**
- In this case, the if-then-else expression \(\text{if } p \text{ then } t \text{ else } f\) simplifies to \( f \).
- Therefore, the goal \((\text{if } p \text{ then } t \text{ else } f) = \text{false}\) simplifies to \( f = \text{false} \).
- Similarly, the right-hand side of the equivalence \(\text{if } p \text{ then } t = \text{false} \text{ else } f = \text{false}\) simplifies to \( f = \text{false} \).
- Hence, the equivalence holds in this case.

Since the equivalence holds in both cases, the proof is complete. \(\blacksquare\)","theorem Bool.ite_eq_false_distrib (p : Prop) [h : Decidable p] (t f : Bool) :
    (ite p t f = false) = ite p (t = false) (f = false) := by
/- We will consider the two possible cases for the proposition \( p \).

1. **Case 1: \( p \) is true.**
- In this case, the if-then-else expression \(\text{if } p \text{ then } t \text{ else } f\) simplifies to \( t \).
- Therefore, the goal \((\text{if } p \text{ then } t \text{ else } f) = \text{false}\) simplifies to \( t = \text{false} \).
- Similarly, the right-hand side of the equivalence \(\text{if } p \text{ then } t = \text{false} \text{ else } f = \text{false}\) simplifies to \( t = \text{false} \).
- Hence, the equivalence holds in this case.

2. **Case 2: \( p \) is false.**
- In this case, the if-then-else expression \(\text{if } p \text{ then } t \text{ else } f\) simplifies to \( f \).
- Therefore, the goal \((\text{if } p \text{ then } t \text{ else } f) = \text{false}\) simplifies to \( f = \text{false} \).
- Similarly, the right-hand side of the equivalence \(\text{if } p \text{ then } t = \text{false} \text{ else } f = \text{false}\) simplifies to \( f = \text{false} \).
- Hence, the equivalence holds in this case.

Since the equivalence holds in both cases, the proof is complete. -/
  cases h with | _ p => simp [p]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25402,Bool.cond_false_left,"theorem Bool.cond_false_left : ∀(c f : Bool), cond c false f = (!c && f) := by sorry","Conditional with False Left: \((\text{if } c \text{ then } \text{false} \text{ else } f) = (\neg c \land f)\) : For any boolean values \( c \) and \( f \), the expression \(\text{if } c \text{ then } \text{false} \text{ else } f\) is equal to \(\neg c \land f\), i.e., \((\text{if } c \text{ then } \text{false} \text{ else } f) = (\neg c \land f)\).","theorem Bool.cond_false_left : ∀(c f : Bool), cond c false f = (!c && f) := by
  decide","To prove the theorem, we need to show that for any boolean values \( c \) and \( f \), the expression \(\text{if } c \text{ then } \text{false} \text{ else } f\) is equal to \(\neg c \land f\). We will consider all possible values of \( c \) and \( f \):

1. **Case 1: \( c = \text{true} \)**
- If \( c = \text{true} \), then \(\text{if } c \text{ then } \text{false} \text{ else } f\) evaluates to \(\text{false}\).
- \(\neg c = \neg \text{true} = \text{false}\).
- Therefore, \(\neg c \land f = \text{false} \land f = \text{false}\).
- Hence, \(\text{if } c \text{ then } \text{false} \text{ else } f = \text{false} = \neg c \land f\).

2. **Case 2: \( c = \text{false} \)**
- If \( c = \text{false} \), then \(\text{if } c \text{ then } \text{false} \text{ else } f\) evaluates to \( f \).
- \(\neg c = \neg \text{false} = \text{true}\).
- Therefore, \(\neg c \land f = \text{true} \land f = f\).
- Hence, \(\text{if } c \text{ then } \text{false} \text{ else } f = f = \neg c \land f\).

Since the equality holds for all possible values of \( c \) and \( f \), the theorem is proven. Therefore, for any boolean values \( c \) and \( f \), \((\text{if } c \text{ then } \text{false} \text{ else } f) = (\neg c \land f)\). This completes the proof.","theorem Bool.cond_false_left : ∀(c f : Bool), cond c false f = (!c && f) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25403,Bool.cond_eq_true_distrib,"theorem Bool.cond_eq_true_distrib : ∀(c t f : Bool),
    (cond c t f = true) = ite (c = true) (t = true) (f = true) := by sorry","Distributive Property of Conditional Equality with True : For any boolean values \( c, t, f \), the expression \((\text{if } c \text{ then } t \text{ else } f) = \text{true}\) is equivalent to \(\text{if } c = \text{true} \text{ then } t = \text{true} \text{ else } f = \text{true}\).","theorem Bool.cond_eq_true_distrib : ∀(c t f : Bool),
    (cond c t f = true) = ite (c = true) (t = true) (f = true) := by
  decide","To prove the theorem, we need to show that for any boolean values \( c, t, \) and \( f \), the expression \((\text{if } c \text{ then } t \text{ else } f) = \text{true}\) is equivalent to \(\text{if } c = \text{true} \text{ then } t = \text{true} \text{ else } f = \text{true}\).

We consider the two cases for \( c \):

1. **Case 1: \( c = \text{true} \)**
- If \( c = \text{true} \), then the expression \((\text{if } c \text{ then } t \text{ else } f)\) simplifies to \( t \).
- Therefore, \((\text{if } c \text{ then } t \text{ else } f) = \text{true}\) is equivalent to \( t = \text{true} \).
- This matches the right-hand side of the equivalence, which is \(\text{if } c = \text{true} \text{ then } t = \text{true} \text{ else } f = \text{true}\).

2. **Case 2: \( c = \text{false} \)**
- If \( c = \text{false} \), then the expression \((\text{if } c \text{ then } t \text{ else } f)\) simplifies to \( f \).
- Therefore, \((\text{if } c \text{ then } t \text{ else } f) = \text{true}\) is equivalent to \( f = \text{true} \).
- This matches the right-hand side of the equivalence, which is \(\text{if } c = \text{true} \text{ then } t = \text{true} \text{ else } f = \text{true}\).

Since both cases hold, the equivalence is true for all boolean values \( c, t, \) and \( f \). This completes the proof.","theorem Bool.cond_eq_true_distrib : ∀(c t f : Bool),
    (cond c t f = true) = ite (c = true) (t = true) (f = true) := by
/- We use the `decide` tactic to automatically determine the truth of the given statement. This tactic evaluates the boolean expression and confirms that the statement holds for all possible values of \( c, t, \) and \( f \). -/
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25404,Bool.cond_self,theorem Bool.cond_self (c : Bool) (t : α) : cond c t t = t := by sorry,"Conditional Expression with Identical Branches Equals the Value : For any boolean condition $c$ and any value $t$ of type $\alpha$, the expression `bif c then t else t` is equal to $t$, i.e., $(\text{if } c \text{ then } t \text{ else } t) = t$.","theorem Bool.cond_self (c : Bool) (t : α) : cond c t t = t := by
  cases c <;> rfl","We need to show that for any boolean condition $c$ and any value $t$ of type $\alpha$, the expression $(\text{if } c \text{ then } t \text{ else } t)$ is equal to $t$. We will consider every possible case of the boolean condition $c$.

1. **Case 1: $c = \text{false}$**
- The expression $(\text{if } \text{false} \text{ then } t \text{ else } t)$ simplifies to $t$.
- This is trivially true because both sides of the equality are $t$.

2. **Case 2: $c = \text{true}$**
- The expression $(\text{if } \text{true} \text{ then } t \text{ else } t)$ simplifies to $t$.
- This is also trivially true because both sides of the equality are $t$.

Since both cases are trivially true, we conclude that for any boolean condition $c$ and any value $t$ of type $\alpha$, the expression $(\text{if } c \text{ then } t \text{ else } t)$ is equal to $t$. This completes the proof.","theorem Bool.cond_self (c : Bool) (t : α) : cond c t t = t := by
  cases c <;> rfl","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25405,Bool.toNat_eq_zero,theorem Bool.toNat_eq_zero (b : Bool) : b.toNat = 0 ↔ b = false := by sorry,"Boolean to Natural Conversion: \( \text{Bool.toNat}(b) = 0 \leftrightarrow b = \text{false} \) : For any boolean value \( b \), the conversion of \( b \) to a natural number using the function `Bool.toNat` is equal to \( 0 \) if and only if \( b \) is `false`. In other words, \( \text{Bool.toNat}(b) = 0 \) if and only if \( b = \text{false} \).","theorem Bool.toNat_eq_zero (b : Bool) : b.toNat = 0 ↔ b = false := by
  cases b <;> simp","We will consider every possible case of the boolean value \( b \). There are two cases: \( b = \text{false} \) and \( b = \text{true} \).

**Case 1: \( b = \text{false} \)**
- By the definition of `Bool.toNat`, we have \( \text{Bool.toNat}(\text{false}) = 0 \).
- Therefore, \( \text{Bool.toNat}(\text{false}) = 0 \) is true, and \( \text{false} = \text{false} \) is also true.
- Hence, \( \text{Bool.toNat}(\text{false}) = 0 \leftrightarrow \text{false} = \text{false} \) is true.

**Case 2: \( b = \text{true} \)**
- By the definition of `Bool.toNat`, we have \( \text{Bool.toNat}(\text{true}) = 1 \).
- Therefore, \( \text{Bool.toNat}(\text{true}) = 0 \) is false, and \( \text{true} = \text{false} \) is also false.
- Hence, \( \text{Bool.toNat}(\text{true}) = 0 \leftrightarrow \text{true} = \text{false} \) is true.

Since both cases are true, we conclude that for any boolean value \( b \), \( \text{Bool.toNat}(b) = 0 \) if and only if \( b = \text{false} \). This completes the proof.","theorem Bool.toNat_eq_zero (b : Bool) : b.toNat = 0 ↔ b = false := by
/- We will consider every possible case of the boolean value \( b \). There are two cases: \( b = \text{false} \) and \( b = \text{true} \). -/
/- Case 1: \( b = \text{false} \)
- We need to show that \( \text{Bool.toNat}(\text{false}) = 0 \leftrightarrow \text{false} = \text{false} \).

Case 2: \( b = \text{true} \)
- We need to show that \( \text{Bool.toNat}(\text{true}) = 0 \leftrightarrow \text{true} = \text{false} \). -/
/- For the case \( b = \text{false} \):
- By the definition of `Bool.toNat`, we have \( \text{Bool.toNat}(\text{false}) = 0 \).
- Therefore, \( \text{Bool.toNat}(\text{false}) = 0 \) is true, and \( \text{false} = \text{false} \) is also true.
- Hence, \( \text{Bool.toNat}(\text{false}) = 0 \leftrightarrow \text{false} = \text{false} \) is true. -/
/- For the case \( b = \text{true} \):
- By the definition of `Bool.toNat`, we have \( \text{Bool.toNat}(\text{true}) = 1 \).
- Therefore, \( \text{Bool.toNat}(\text{true}) = 0 \) is false, and \( \text{true} = \text{false} \) is also false.
- Hence, \( \text{Bool.toNat}(\text{true}) = 0 \leftrightarrow \text{true} = \text{false} \) is true. -/
  cases b <;> simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25406,Bool.cond_true_right,"theorem Bool.cond_true_right : ∀(c t : Bool), cond c t true  = (!c || t) := by sorry","Conditional with True Right: \((\text{if } c \text{ then } t \text{ else } \text{true}) = (\neg c \lor t)\) : For any boolean values \( c \) and \( t \), the expression \(\text{if } c \text{ then } t \text{ else } \text{true}\) is equal to \(\neg c \lor t\), i.e., \((\text{if } c \text{ then } t \text{ else } \text{true}) = (\neg c \lor t)\).","theorem Bool.cond_true_right : ∀(c t : Bool), cond c t true  = (!c || t) := by
  decide","To prove the theorem, we need to show that for any boolean values \( c \) and \( t \), the expression \(\text{if } c \text{ then } t \text{ else } \text{true}\) is equal to \(\neg c \lor t\). We will consider all possible values of \( c \) and \( t \):

1. **Case 1: \( c = \text{true} \)**
- If \( c = \text{true} \), then \(\text{if } c \text{ then } t \text{ else } \text{true} = t\).
- Also, \(\neg c = \neg \text{true} = \text{false}\), so \(\neg c \lor t = \text{false} \lor t = t\).
- Therefore, \(\text{if } c \text{ then } t \text{ else } \text{true} = t = \neg c \lor t\).

2. **Case 2: \( c = \text{false} \)**
- If \( c = \text{false} \), then \(\text{if } c \text{ then } t \text{ else } \text{true} = \text{true}\).
- Also, \(\neg c = \neg \text{false} = \text{true}\), so \(\neg c \lor t = \text{true} \lor t = \text{true}\).
- Therefore, \(\text{if } c \text{ then } t \text{ else } \text{true} = \text{true} = \neg c \lor t\).

Since the equality holds for all possible values of \( c \) and \( t \), we conclude that \((\text{if } c \text{ then } t \text{ else } \text{true}) = (\neg c \lor t)\). This completes the proof.","theorem Bool.cond_true_right : ∀(c t : Bool), cond c t true  = (!c || t) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25407,Bool.if_false_right,"theorem Bool.if_false_right (p : Prop) [h : Decidable p] (t : Bool) :
    (ite p t false) = (p && t) := by sorry","Distributive Property of If-then-else over False Boolean Value: \((\text{if } p \text{ then } t \text{ else } \text{false}) = (\text{decide } p) \land t\) : For any proposition \( p \) and boolean value \( t \), the if-then-else expression \((\text{if } p \text{ then } t \text{ else } \text{false})\) is equal to the boolean AND operation \((\text{decide } p) \text{ and } t\). This can be written as:
\[
(\text{if } p \text{ then } t \text{ else } \text{false}) = (\text{decide } p) \land t
\]","theorem Bool.if_false_right (p : Prop) [h : Decidable p] (t : Bool) :
    (ite p t false) = (p && t) := by
  cases h with | _ p => simp [p]","We will consider the two possible cases for the decidable proposition \( p \).

1. **Case 1: \( p \) is true.**
- In this case, the if-then-else expression \((\text{if } p \text{ then } t \text{ else } \text{false})\) simplifies to \( t \).
- The boolean AND operation \((\text{decide } p) \land t\) also simplifies to \( t \) because \(\text{decide } p\) is true.
- Therefore, \((\text{if } p \text{ then } t \text{ else } \text{false}) = t\) and \((\text{decide } p) \land t = t\), so the two expressions are equal.

2. **Case 2: \( p \) is false.**
- In this case, the if-then-else expression \((\text{if } p \text{ then } t \text{ else } \text{false})\) simplifies to \(\text{false}\).
- The boolean AND operation \((\text{decide } p) \land t\) also simplifies to \(\text{false}\) because \(\text{decide } p\) is false.
- Therefore, \((\text{if } p \text{ then } t \text{ else } \text{false}) = \text{false}\) and \((\text{decide } p) \land t = \text{false}\), so the two expressions are equal.

In both cases, the expressions are equal, thus proving the theorem. \(\blacksquare\)","theorem Bool.if_false_right (p : Prop) [h : Decidable p] (t : Bool) :
    (ite p t false) = (p && t) := by
  cases h with | _ p => simp [p]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25408,Bool.ite_eq_cond_iff,"theorem Bool.ite_eq_cond_iff (p : Prop) [h : Decidable p] (a : Bool) (x y u v : α) :
  (ite p x y = cond a u v) ↔ ite p x y = ite a u v := by sorry","Equivalence of If-then-else and Conditional Expressions: $(\text{if } p \text{ then } x \text{ else } y) = (\text{if } a \text{ then } u \text{ else } v) \leftrightarrow (\text{if } p \text{ then } x \text{ else } y) = (\text{if } a = \text{true} \text{ then } u \text{ else } v)$ : For any type $\alpha$, any proposition $p$ that is decidable, and any boolean value $a$, the following equivalence holds:
\[
(\text{if } p \text{ then } x \text{ else } y) = (\text{if } a \text{ then } u \text{ else } v) \leftrightarrow (\text{if } p \text{ then } x \text{ else } y) = (\text{if } a = \text{true} \text{ then } u \text{ else } v)
\]
where $x, y, u, v \in \alpha$.","theorem Bool.ite_eq_cond_iff (p : Prop) [h : Decidable p] (a : Bool) (x y u v : α) :
  (ite p x y = cond a u v) ↔ ite p x y = ite a u v := by
  simp [Bool.cond_eq_ite]","We need to show that the equivalence \((\text{if } p \text{ then } x \text{ else } y) = (\text{if } a \text{ then } u \text{ else } v)\) is equivalent to \((\text{if } p \text{ then } x \text{ else } y) = (\text{if } a = \text{true} \text{ then } u \text{ else } v)\).

To do this, we use the fact that the conditional function `cond` (or `bif b then t else e`) is equivalent to the if-then-else function `ite` (or `if b = true then t else e`). Specifically, for any boolean value $a$, the expression `bif a then u else v` is equivalent to `if a = true then u else v`.

Therefore, the original equivalence \((\text{if } p \text{ then } x \text{ else } y) = (\text{if } a \text{ then } u \text{ else } v)\) is equivalent to \((\text{if } p \text{ then } x \text{ else } y) = (\text{if } a = \text{true} \text{ then } u \text{ else } v)\).

This completes the proof.","theorem Bool.ite_eq_cond_iff (p : Prop) [h : Decidable p] (a : Bool) (x y u v : α) :
  (ite p x y = cond a u v) ↔ ite p x y = ite a u v := by
/- Using the fact that the conditional function `cond` (or `bif b then t else e`) is equivalent to the if-then-else function `ite` (or `if b = true then t else e`), we can simplify the proposition we want to show. Specifically, the expression `bif a then u else v` is equivalent to `if a = true then u else v`. Therefore, the original equivalence \((\text{if } p \text{ then } x \text{ else } y) = (\text{if } a \text{ then } u \text{ else } v)\) is equivalent to \((\text{if } p \text{ then } x \text{ else } y) = (\text{if } a = \text{true} \text{ then } u \text{ else } v)\). -/
  simp [Bool.cond_eq_ite]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25409,Bool.cond_not,theorem Bool.cond_not (b : Bool) (t e : α) : cond (!b) t e = cond b e t := by sorry,"Conditional Expression with Negated Condition Swaps Branches : For any boolean condition $b$ and any values $t, e$ of type $\alpha$, the expression `bif !b then t else e` is equal to `bif b then e else t`, i.e., $(\text{if } \neg b \text{ then } t \text{ else } e) = (\text{if } b \text{ then } e \text{ else } t)$.","theorem Bool.cond_not (b : Bool) (t e : α) : cond (!b) t e = cond b e t := by
  cases b <;> rfl","We will consider every possible case of the boolean value $b$.

**Case 1: $b = \text{false}$**
- The expression $(\text{if } \neg \text{false} \text{ then } t \text{ else } e)$ simplifies to $(\text{if } \text{true} \text{ then } t \text{ else } e)$, which is $t$.
- The expression $(\text{if } \text{false} \text{ then } e \text{ else } t)$ simplifies to $t$.
- Therefore, $(\text{if } \neg \text{false} \text{ then } t \text{ else } e) = (\text{if } \text{false} \text{ then } e \text{ else } t)$ holds.

**Case 2: $b = \text{true}$**
- The expression $(\text{if } \neg \text{true} \text{ then } t \text{ else } e)$ simplifies to $(\text{if } \text{false} \text{ then } t \text{ else } e)$, which is $e$.
- The expression $(\text{if } \text{true} \text{ then } e \text{ else } t)$ simplifies to $e$.
- Therefore, $(\text{if } \neg \text{true} \text{ then } t \text{ else } e) = (\text{if } \text{true} \text{ then } e \text{ else } t)$ holds.

In both cases, the equality holds trivially due to the reflexive property of equality. This completes the proof.","theorem Bool.cond_not (b : Bool) (t e : α) : cond (!b) t e = cond b e t := by
/- We will consider every possible case of the boolean value $b$.

**Case 1: $b = \text{false}$**
- The expression $(\text{if } \neg \text{false} \text{ then } t \text{ else } e)$ simplifies to $(\text{if } \text{true} \text{ then } t \text{ else } e)$, which is $t$.
- The expression $(\text{if } \text{false} \text{ then } e \text{ else } t)$ simplifies to $t$.
- Therefore, $(\text{if } \neg \text{false} \text{ then } t \text{ else } e) = (\text{if } \text{false} \text{ then } e \text{ else } t)$ holds.

**Case 2: $b = \text{true}$**
- The expression $(\text{if } \neg \text{true} \text{ then } t \text{ else } e)$ simplifies to $(\text{if } \text{false} \text{ then } t \text{ else } e)$, which is $e$.
- The expression $(\text{if } \text{true} \text{ then } e \text{ else } t)$ simplifies to $e$.
- Therefore, $(\text{if } \neg \text{true} \text{ then } t \text{ else } e) = (\text{if } \text{true} \text{ then } e \text{ else } t)$ holds.

In both cases, the equality holds trivially due to the reflexive property of equality. -/
  cases b <;> rfl","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25410,Bool.not_ite_eq_true_eq_false,"theorem Bool.not_ite_eq_true_eq_false (p : Prop) [h : Decidable p] (b c : Bool) :
  ¬(ite p (b = true) (c = false)) ↔ (ite p (b = false) (c = true)) := by sorry","Negation of If-Then-Else Expression: \(\neg (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{false}) \leftrightarrow \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{true}\) : For any proposition \( p \) and boolean values \( b \) and \( c \), the negation of the if-then-else expression \( \neg (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{false}) \) is equivalent to the if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{true} \).","theorem Bool.not_ite_eq_true_eq_false (p : Prop) [h : Decidable p] (b c : Bool) :
  ¬(ite p (b = true) (c = false)) ↔ (ite p (b = false) (c = true)) := by
  cases h with | _ p => simp [p]","We will consider the two possible cases for the proposition \( p \).

**Case 1: \( p \) is true.**
Using the fact that \( p \) is true, we simplify the expression \( \neg (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{false}) \) to \( \neg (b = \text{true}) \). By the property of boolean negation, \( \neg (b = \text{true}) \) is equivalent to \( b = \text{false} \). Similarly, we simplify \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{true} \) to \( b = \text{false} \). Therefore, in this case, the left-hand side and the right-hand side of the equivalence are both \( b = \text{false} \), which are clearly equivalent.

**Case 2: \( p \) is false.**
Using the fact that \( p \) is false, we simplify the expression \( \neg (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{false}) \) to \( \neg (c = \text{false}) \). By the property of boolean negation, \( \neg (c = \text{false}) \) is equivalent to \( c = \text{true} \). Similarly, we simplify \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{true} \) to \( c = \text{true} \). Therefore, in this case, the left-hand side and the right-hand side of the equivalence are both \( c = \text{true} \), which are clearly equivalent.

Since both cases have been considered and the equivalence holds in each case, the theorem is proved.","theorem Bool.not_ite_eq_true_eq_false (p : Prop) [h : Decidable p] (b c : Bool) :
  ¬(ite p (b = true) (c = false)) ↔ (ite p (b = false) (c = true)) := by
/- We will consider the two possible cases for the proposition \( p \). -/
/- **Case 1: \( p \) is true.**
Using the fact that \( p \) is true, we simplify the expression \( \neg (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{false}) \) to \( \neg (b = \text{true}) \). By the property of boolean negation, \( \neg (b = \text{true}) \) is equivalent to \( b = \text{false} \). Similarly, we simplify \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{true} \) to \( b = \text{false} \). Therefore, in this case, the left-hand side and the right-hand side of the equivalence are both \( b = \text{false} \), which are clearly equivalent. -/
/- **Case 2: \( p \) is false.**
Using the fact that \( p \) is false, we simplify the expression \( \neg (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{false}) \) to \( \neg (c = \text{false}) \). By the property of boolean negation, \( \neg (c = \text{false}) \) is equivalent to \( c = \text{true} \). Similarly, we simplify \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{true} \) to \( c = \text{true} \). Therefore, in this case, the left-hand side and the right-hand side of the equivalence are both \( c = \text{true} \), which are clearly equivalent. -/
  cases h with | _ p => simp [p]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25411,true_eq_decide_iff,theorem true_eq_decide_iff {p : Prop} [h : Decidable p] : true = decide p ↔ p := by sorry,"Boolean True Equals Decide if and only if Proposition is True: \(\text{true} = \text{decide}(p) \leftrightarrow p\) : For any decidable proposition \( p \), the boolean value `true` is equal to `decide p` if and only if \( p \) is true, i.e., \( \text{true} = \text{decide}(p) \leftrightarrow p \).","theorem true_eq_decide_iff {p : Prop} [h : Decidable p] : true = decide p ↔ p := by
  cases h with | _ q => simp [q]","We need to show that \(\text{true} = \text{decide}(p) \leftrightarrow p\) for any decidable proposition \( p \). We will consider the two possible cases for \( p \).

**Case 1: \( p \) is true.**
- Assume \( p \) is true.
- By the definition of \(\text{decide}\), \(\text{decide}(p) = \text{true}\).
- Therefore, \(\text{true} = \text{decide}(p)\) is true.
- Hence, \(\text{true} = \text{decide}(p) \leftrightarrow p\) is true because both sides are true.

**Case 2: \( p \) is false.**
- Assume \( p \) is false.
- By the definition of \(\text{decide}\), \(\text{decide}(p) = \text{false}\).
- Therefore, \(\text{true} = \text{decide}(p)\) is false.
- Hence, \(\text{true} = \text{decide}(p) \leftrightarrow p\) is false because the left side is true and the right side is false, which is consistent with \( p \) being false.

In both cases, the equivalence \(\text{true} = \text{decide}(p) \leftrightarrow p\) holds. Therefore, the theorem is proved. \(\blacksquare\)","theorem true_eq_decide_iff {p : Prop} [h : Decidable p] : true = decide p ↔ p := by
/- We will consider the two possible cases for the decidable proposition \( p \).

**Case 1: \( p \) is true.**
In this case, we have \( p \) as a hypothesis. Using this hypothesis, we simplify the goal \( \text{true} = \text{decide}(p) \leftrightarrow p \). Since \( p \) is true, \(\text{decide}(p)\) is also true. Therefore, the goal simplifies to \( \text{true} = \text{true} \leftrightarrow p \), which is trivially true because both sides are true.

**Case 2: \( p \) is false.**
In this case, we have \( \neg p \) as a hypothesis. Using this hypothesis, we simplify the goal \( \text{true} = \text{decide}(p) \leftrightarrow p \). Since \( p \) is false, \(\text{decide}(p)\) is false. Therefore, the goal simplifies to \( \text{true} = \text{false} \leftrightarrow p \), which is false because the left side is true and the right side is false. This is consistent with the fact that \( p \) is false. -/
  cases h with | _ q => simp [q]","import Init.BinderPredicates
import Init.Data.Bool



"
25413,Bool.cond_eq_ite,theorem Bool.cond_eq_ite {α} (b : Bool) (t e : α) : cond b t e = if b then t else e := by sorry,"Conditional Function Equals If-Then-Else Function for Boolean Conditions : For any type $\alpha$ and any boolean value $b$, the conditional function `cond` (or `bif b then t else e`) returns the same result as the if-then-else function `ite` (or `if b = true then t else e`). Specifically, if $b$ is `true`, both functions return $t$, and if $b$ is `false`, both functions return $e$.","theorem Bool.cond_eq_ite {α} (b : Bool) (t e : α) : cond b t e = if b then t else e := by
  cases b <;> simp","We need to show that for any boolean value $b$, the conditional function `cond` (or `bif b then t else e`) returns the same result as the if-then-else function `ite` (or `if b = true then t else e`).

We will consider the two possible cases for the boolean value $b$:

1. **Case 1: $b = \text{false}$**
- The expression `bif false then t else e` simplifies to $e$.
- The expression `if false = true then t else e` also simplifies to $e$ because `false` is not equal to `true`.
- Therefore, $(\text{bif false then } t \text{ else } e) = (\text{if false} = \text{true then } t \text{ else } e)$ holds.

2. **Case 2: $b = \text{true}$**
- The expression `bif true then t else e` simplifies to $t$.
- The expression `if true = true then t else e` also simplifies to $t$ because `true` is equal to `true`.
- Therefore, $(\text{bif true then } t \text{ else } e) = (\text{if true} = \text{true then } t \text{ else } e)$ holds.

Since both cases are covered, we conclude that for any boolean value $b$, the conditional function `cond` (or `bif b then t else e`) returns the same result as the if-then-else function `ite` (or `if b = true then t else e`). This completes the proof. $\blacksquare$","theorem Bool.cond_eq_ite {α} (b : Bool) (t e : α) : cond b t e = if b then t else e := by
/- We will consider the two possible cases for the boolean value $b$: $b = \text{true}$ and $b = \text{false}$. For each case, we will simplify the expression to show that the conditional function `cond` (or `bif b then t else e`) returns the same result as the if-then-else function `ite` (or `if b = true then t else e`). -/
/- We will discuss every possible case of $b$. Case 1: $b = \text{false}$. Case 2: $b = \text{true}$. -/
/- First, we apply the `cases` tactic to split the goal into two subgoals based on the value of $b$. Then, for each of these subgoals, we apply the `simp` tactic to simplify the expressions. -/
/- For the case where $b = \text{false}$, we simplify the expression $(\text{bif false then } t \text{ else } e) = (\text{if false} = \text{true then } t \text{ else } e)$. Since `false` is not equal to `true`, both sides of the equation simplify to $e$. Therefore, the equation holds. -/
/- For the case where $b = \text{true}$, we simplify the expression $(\text{bif true then } t \text{ else } e) = (\text{if true} = \text{true then } t \text{ else } e)$. Since `true` is equal to `true`, both sides of the equation simplify to $t$. Therefore, the equation holds. -/
  cases b <;> simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25414,Bool.cond_true_same,"theorem Bool.cond_true_same : ∀(c b : Bool), cond c c b = (c || b) := by sorry","Conditional Expression Evaluates to First Argument if True: $(\text{if } c \text{ then } c \text{ else } b) = (c \lor b)$ : For any boolean values $c$ and $b$, the conditional expression `bif c then c else b` is equal to the boolean OR operation `c || b`, i.e., $(\text{if } c \text{ then } c \text{ else } b) = (c \lor b)$.","theorem Bool.cond_true_same : ∀(c b : Bool), cond c c b = (c || b) := by
  decide","To prove the theorem, we need to show that for any boolean values $c$ and $b$, the conditional expression $(\text{if } c \text{ then } c \text{ else } b)$ is equal to the boolean OR operation $(c \lor b)$. We will consider all possible values of $c$ and $b$:

1. **Case 1: $c = \text{true}$ and $b = \text{true}$**
- The conditional expression $(\text{if } \text{true} \text{ then } \text{true} \text{ else } \text{true})$ evaluates to $\text{true}$.
- The boolean OR operation $(\text{true} \lor \text{true})$ also evaluates to $\text{true}$.
- Therefore, $(\text{if } \text{true} \text{ then } \text{true} \text{ else } \text{true}) = (\text{true} \lor \text{true})$.

2. **Case 2: $c = \text{true}$ and $b = \text{false}$**
- The conditional expression $(\text{if } \text{true} \text{ then } \text{true} \text{ else } \text{false})$ evaluates to $\text{true}$.
- The boolean OR operation $(\text{true} \lor \text{false})$ also evaluates to $\text{true}$.
- Therefore, $(\text{if } \text{true} \text{ then } \text{true} \text{ else } \text{false}) = (\text{true} \lor \text{false})$.

3. **Case 3: $c = \text{false}$ and $b = \text{true}$**
- The conditional expression $(\text{if } \text{false} \text{ then } \text{false} \text{ else } \text{true})$ evaluates to $\text{true}$.
- The boolean OR operation $(\text{false} \lor \text{true})$ also evaluates to $\text{true}$.
- Therefore, $(\text{if } \text{false} \text{ then } \text{false} \text{ else } \text{true}) = (\text{false} \lor \text{true})$.

4. **Case 4: $c = \text{false}$ and $b = \text{false}$**
- The conditional expression $(\text{if } \text{false} \text{ then } \text{false} \text{ else } \text{false})$ evaluates to $\text{false}$.
- The boolean OR operation $(\text{false} \lor \text{false})$ also evaluates to $\text{false}$.
- Therefore, $(\text{if } \text{false} \text{ then } \text{false} \text{ else } \text{false}) = (\text{false} \lor \text{false})$.

Since the equality holds in all possible cases, we conclude that for any boolean values $c$ and $b$, the conditional expression $(\text{if } c \text{ then } c \text{ else } b)$ is equal to the boolean OR operation $(c \lor b)$. This completes the proof.","theorem Bool.cond_true_same : ∀(c b : Bool), cond c c b = (c || b) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25416,Bool.cond_false_right,"theorem Bool.cond_false_right : ∀(c t : Bool), cond c t false = ( c && t) := by sorry","Conditional with False Right: \((\text{if } c \text{ then } t \text{ else } \text{false}) = (c \land t)\) : For any boolean values \( c \) and \( t \), the expression \(\text{if } c \text{ then } t \text{ else } \text{false}\) is equal to \( c \land t \), i.e., \((\text{if } c \text{ then } t \text{ else } \text{false}) = (c \land t)\).","theorem Bool.cond_false_right : ∀(c t : Bool), cond c t false = ( c && t) := by
  decide","To prove the theorem, we need to show that for any boolean values \( c \) and \( t \), the expression \(\text{if } c \text{ then } t \text{ else } \text{false}\) is equal to \( c \land t \).

We will consider all possible values of \( c \) and \( t \):

1. **Case 1: \( c = \text{true} \) and \( t = \text{true} \)**
- \(\text{if } \text{true} \text{ then } \text{true} \text{ else } \text{false} = \text{true}\)
- \( \text{true} \land \text{true} = \text{true} \)
- Therefore, \(\text{if } \text{true} \text{ then } \text{true} \text{ else } \text{false} = \text{true} \land \text{true}\).

2. **Case 2: \( c = \text{true} \) and \( t = \text{false} \)**
- \(\text{if } \text{true} \text{ then } \text{false} \text{ else } \text{false} = \text{false}\)
- \( \text{true} \land \text{false} = \text{false} \)
- Therefore, \(\text{if } \text{true} \text{ then } \text{false} \text{ else } \text{false} = \text{true} \land \text{false}\).

3. **Case 3: \( c = \text{false} \) and \( t = \text{true} \)**
- \(\text{if } \text{false} \text{ then } \text{true} \text{ else } \text{false} = \text{false}\)
- \( \text{false} \land \text{true} = \text{false} \)
- Therefore, \(\text{if } \text{false} \text{ then } \text{true} \text{ else } \text{false} = \text{false} \land \text{true}\).

4. **Case 4: \( c = \text{false} \) and \( t = \text{false} \)**
- \(\text{if } \text{false} \text{ then } \text{false} \text{ else } \text{false} = \text{false}\)
- \( \text{false} \land \text{false} = \text{false} \)
- Therefore, \(\text{if } \text{false} \text{ then } \text{false} \text{ else } \text{false} = \text{false} \land \text{false}\).

Since the equality holds in all possible cases, we conclude that for any boolean values \( c \) and \( t \), the expression \(\text{if } c \text{ then } t \text{ else } \text{false}\) is equal to \( c \land t \). This completes the proof.","theorem Bool.cond_false_right : ∀(c t : Bool), cond c t false = ( c && t) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25417,Bool.not_ite_eq_true_eq_true,"theorem Bool.not_ite_eq_true_eq_true (p : Prop) [h : Decidable p] (b c : Bool) :
  ¬(ite p (b = true) (c = true)) ↔ (ite p (b = false) (c = false)) := by sorry","Negation of If-Then-Else Equals True is Equivalent to If-Then-Else Equals False : For any proposition \( p \) and boolean values \( b \) and \( c \), the negation of the if-then-else expression \( \text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true} \) is logically equivalent to the if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \). In other words, \( \neg (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true}) \leftrightarrow (\text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false}) \).","theorem Bool.not_ite_eq_true_eq_true (p : Prop) [h : Decidable p] (b c : Bool) :
  ¬(ite p (b = true) (c = true)) ↔ (ite p (b = false) (c = false)) := by
  cases h with | _ p => simp [p]","We will consider every possible case of the decidable proposition \( p \).

1. **Case 1: \( p \) is true.**
- In this case, the if-then-else expression \( \text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true} \) simplifies to \( b = \text{true} \).
- The negation of this expression is \( \neg (b = \text{true}) \), which is equivalent to \( b = \text{false} \) by the property of boolean values.
- Therefore, the if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \) simplifies to \( b = \text{false} \).
- Hence, \( \neg (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true}) \) is equivalent to \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \).

2. **Case 2: \( p \) is false.**
- In this case, the if-then-else expression \( \text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true} \) simplifies to \( c = \text{true} \).
- The negation of this expression is \( \neg (c = \text{true}) \), which is equivalent to \( c = \text{false} \) by the property of boolean values.
- Therefore, the if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \) simplifies to \( c = \text{false} \).
- Hence, \( \neg (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true}) \) is equivalent to \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \).

Since both cases show that the negation of the if-then-else expression \( \text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true} \) is equivalent to the if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \), the theorem is proved.","theorem Bool.not_ite_eq_true_eq_true (p : Prop) [h : Decidable p] (b c : Bool) :
  ¬(ite p (b = true) (c = true)) ↔ (ite p (b = false) (c = false)) := by
/- We will consider every possible case of the decidable proposition \( p \). For each case, we will simplify the proposition we want to show using the assumption \( p \). -/
/- In the case where \( p \) is true, we simplify the proposition using the assumption \( p \). This simplification shows that the negation of the if-then-else expression \( \text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true} \) is equivalent to the if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \). -/
/- In the case where \( p \) is false, we simplify the proposition using the assumption \( \neg p \). This simplification shows that the negation of the if-then-else expression \( \text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true} \) is equivalent to the if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \). -/
  cases h with | _ p => simp [p]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25418,Bool.not_ite_eq_false_eq_false,"theorem Bool.not_ite_eq_false_eq_false (p : Prop) [h : Decidable p] (b c : Bool) :
  ¬(ite p (b = false) (c = false)) ↔ (ite p (b = true) (c = true)) := by sorry","Negation of If-Then-Else Equals False is Equivalent to If-Then-Else Equals True : For any proposition \( p \) and boolean values \( b \) and \( c \), the negation of the if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \) is logically equivalent to the if-then-else expression \( \text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true} \). In other words, \( \neg (\text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false}) \leftrightarrow (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true}) \).","theorem Bool.not_ite_eq_false_eq_false (p : Prop) [h : Decidable p] (b c : Bool) :
  ¬(ite p (b = false) (c = false)) ↔ (ite p (b = true) (c = true)) := by
  cases h with | _ p => simp [p]","We will consider the two possible cases for the decidable proposition \( p \).

1. **Case 1: \( p \) is true.**
- The if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \) simplifies to \( b = \text{false} \).
- The negation of \( b = \text{false} \) is \( b \neq \text{false} \), which is equivalent to \( b = \text{true} \).
- The right-hand side of the equivalence, \( \text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true} \), simplifies to \( b = \text{true} \).
- Therefore, the equivalence \( \neg (\text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false}) \leftrightarrow (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true}) \) holds in this case.

2. **Case 2: \( p \) is false.**
- The if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \) simplifies to \( c = \text{false} \).
- The negation of \( c = \text{false} \) is \( c \neq \text{false} \), which is equivalent to \( c = \text{true} \).
- The right-hand side of the equivalence, \( \text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true} \), simplifies to \( c = \text{true} \).
- Therefore, the equivalence \( \neg (\text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false}) \leftrightarrow (\text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true}) \) holds in this case.

Since the equivalence holds in both cases, the theorem is proved.","theorem Bool.not_ite_eq_false_eq_false (p : Prop) [h : Decidable p] (b c : Bool) :
  ¬(ite p (b = false) (c = false)) ↔ (ite p (b = true) (c = true)) := by
/- We will consider the two possible cases for the decidable proposition \( p \). -/
/- In the case where \( p \) is true, we simplify the expression using the fact that \( p \) is true. The if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \) simplifies to \( b = \text{false} \). The negation of this is \( b \neq \text{false} \), which is equivalent to \( b = \text{true} \). Therefore, the left-hand side of the equivalence becomes \( b = \text{true} \). The right-hand side of the equivalence, \( \text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true} \), simplifies to \( b = \text{true} \). Thus, the equivalence holds in this case. -/
/- In the case where \( p \) is false, we simplify the expression using the fact that \( p \) is false. The if-then-else expression \( \text{if } p \text{ then } b = \text{false} \text{ else } c = \text{false} \) simplifies to \( c = \text{false} \). The negation of this is \( c \neq \text{false} \), which is equivalent to \( c = \text{true} \). Therefore, the left-hand side of the equivalence becomes \( c = \text{true} \). The right-hand side of the equivalence, \( \text{if } p \text{ then } b = \text{true} \text{ else } c = \text{true} \), simplifies to \( c = \text{true} \). Thus, the equivalence holds in this case. -/
  cases h with | _ p => simp [p]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25419,Bool.decide_and,"theorem Bool.decide_and (p q : Prop) [dpq : Decidable (p ∧ q)] [dp : Decidable p] [dq : Decidable q] :
    decide (p ∧ q) = (p && q) := by sorry","Boolean Conjunction of Decidable Propositions: \(\text{decide}(p \land q) = \text{decide}(p) \land \text{decide}(q)\) : For any decidable propositions \( p \) and \( q \), the boolean value of the conjunction \( p \land q \) is equal to the boolean ""and"" operation of the boolean values of \( p \) and \( q \), i.e., \(\text{decide}(p \land q) = \text{decide}(p) \land \text{decide}(q)\).","theorem Bool.decide_and (p q : Prop) [dpq : Decidable (p ∧ q)] [dp : Decidable p] [dq : Decidable q] :
    decide (p ∧ q) = (p && q) := by
  cases dp with | _ p => simp [p]","We need to show that for any decidable propositions \( p \) and \( q \), the boolean value of \( p \land q \) is equal to the boolean ""and"" of the boolean values of \( p \) and \( q \).

We will consider the two possible cases for the decidable proposition \( p \):

1. **Case 1: \( p \) is true.**
- Since \( p \) is true, the boolean value of \( p \) is `true`.
- The boolean value of \( p \land q \) is the same as the boolean value of \( q \).
- Therefore, the goal is to show that the boolean value of \( q \) is equal to the boolean ""and"" of `true` and the boolean value of \( q \).
- This is trivially true because \(\text{true} \land q = q\).

2. **Case 2: \( p \) is false.**
- Since \( p \) is false, the boolean value of \( p \) is `false`.
- The boolean value of \( p \land q \) is `false` regardless of the boolean value of \( q \).
- Therefore, the goal is to show that `false` is equal to the boolean ""and"" of `false` and the boolean value of \( q \).
- This is trivially true because \(\text{false} \land q = \text{false}\).

In both cases, the goal is satisfied, thus proving the theorem. Therefore, \(\text{decide}(p \land q) = \text{decide}(p) \land \text{decide}(q)\). This completes the proof. \(\blacksquare\)","theorem Bool.decide_and (p q : Prop) [dpq : Decidable (p ∧ q)] [dp : Decidable p] [dq : Decidable q] :
    decide (p ∧ q) = (p && q) := by
/- We will consider the two possible cases for the decidable proposition \( p \):
1. \( p \) is true.
2. \( p \) is false. -/
/- **Case 1: \( p \) is true.**
Using the fact that \( p \) is true, we simplify the goal. Since \( p \) is true, the boolean value of \( p \) is `true`. Therefore, the boolean value of \( p \land q \) is the same as the boolean value of \( q \). This simplifies the goal to showing that the boolean value of \( q \) is equal to the boolean ""and"" of `true` and the boolean value of \( q \), which is trivially true. -/
/- **Case 2: \( p \) is false.**
Using the fact that \( p \) is false, we simplify the goal. Since \( p \) is false, the boolean value of \( p \) is `false`. Therefore, the boolean value of \( p \land q \) is `false` regardless of the boolean value of \( q \). This simplifies the goal to showing that `false` is equal to the boolean ""and"" of `false` and the boolean value of \( q \), which is trivially true. -/
  cases dp with | _ p => simp [p]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25420,Bool.decide_or,"theorem Bool.decide_or (p q : Prop) [dpq : Decidable (p ∨ q)] [dp : Decidable p] [dq : Decidable q] :
    decide (p ∨ q) = (p || q) := by sorry","Boolean Decision of Disjunction: $\text{decide}(p \lor q) = (\text{decide}(p) \lor \text{decide}(q))$ : For any propositions \( p \) and \( q \) that are decidable, the boolean value of the disjunction \( p \lor q \) is equal to the boolean ""or"" operation of the boolean values of \( p \) and \( q \). In other words, if \( p \) and \( q \) are decidable propositions, then \( \text{decide}(p \lor q) = (\text{decide}(p) \lor \text{decide}(q)) \).","theorem Bool.decide_or (p q : Prop) [dpq : Decidable (p ∨ q)] [dp : Decidable p] [dq : Decidable q] :
    decide (p ∨ q) = (p || q) := by
  cases dp with | _ p => simp [p]","We need to show that for any decidable propositions \( p \) and \( q \), the boolean value of \( p \lor q \) is equal to the boolean ""or"" operation of the boolean values of \( p \) and \( q \).

We will consider every possible case of the decidability of \( p \).

**Case 1: \( p \) is true.**
- Since \( p \) is true, the boolean value of \( p \) is `true`.
- Therefore, the boolean value of \( p \lor q \) is `true` (since `true` or anything is `true`).
- The boolean ""or"" operation of `true` with the boolean value of \( q \) is also `true`.
- Hence, the goal \( \text{decide}(p \lor q) = (\text{decide}(p) \lor \text{decide}(q)) \) simplifies to `true = true`, which is trivially true.

**Case 2: \( p \) is false.**
- Since \( p \) is false, the boolean value of \( p \) is `false`.
- Therefore, the boolean value of \( p \lor q \) is the same as the boolean value of \( q \) (since `false` or \( q \) is \( q \)).
- The boolean ""or"" operation of `false` with the boolean value of \( q \) is also the boolean value of \( q \).
- Hence, the goal \( \text{decide}(p \lor q) = (\text{decide}(p) \lor \text{decide}(q)) \) simplifies to the boolean value of \( q \) being equal to itself, which is trivially true.

In both cases, the goal is satisfied. Therefore, we have shown that for any decidable propositions \( p \) and \( q \), \( \text{decide}(p \lor q) = (\text{decide}(p) \lor \text{decide}(q)) \). This completes the proof.","theorem Bool.decide_or (p q : Prop) [dpq : Decidable (p ∨ q)] [dp : Decidable p] [dq : Decidable q] :
    decide (p ∨ q) = (p || q) := by
/- We will consider every possible case of the decidability of \( p \).

**Case 1: \( p \) is true.**
Using the fact that \( p \) is true, we simplify the goal. Since \( p \) is true, the boolean value of \( p \) is `true`. Therefore, the boolean value of \( p \lor q \) is also `true` (since `true` or anything is `true`). The boolean ""or"" operation of `true` with the boolean value of \( q \) is also `true`. Hence, the goal \( \text{decide}(p \lor q) = (\text{decide}(p) \lor \text{decide}(q)) \) simplifies to `true = true`, which is trivially true.

**Case 2: \( p \) is false.**
Using the fact that \( p \) is false, we simplify the goal. Since \( p \) is false, the boolean value of \( p \) is `false`. Therefore, the boolean value of \( p \lor q \) is the same as the boolean value of \( q \) (since `false` or \( q \) is \( q \)). The boolean ""or"" operation of `false` with the boolean value of \( q \) is also the boolean value of \( q \). Hence, the goal \( \text{decide}(p \lor q) = (\text{decide}(p) \lor \text{decide}(q)) \) simplifies to the boolean value of \( q \) being equal to itself, which is trivially true. -/
  cases dp with | _ p => simp [p]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25421,List.mapM_cons,"theorem List.mapM_cons [Monad m] [LawfulMonad m] (f : α → m β) :
    (a :: l).mapM f = (return (← f a) :: (← l.mapM f)) := by sorry","Monadic Map Over Cons List Equals Monadic Action on Head Followed by Monadic Map on Tail : For any monad \( m \) and any function \( f : \alpha \to m \beta \), and for any element \( a \) of type \( \alpha \) and any list \( l \) of elements of type \( \alpha \), the monadic map of \( f \) over the list \( a :: l \) (i.e., the list with \( a \) as the first element and \( l \) as the tail) is equal to the monadic action of \( f \) on \( a \) followed by the monadic map of \( f \) over \( l \), i.e.,
\[
\text{List.mapM } f \ (a :: l) = \text{do} \ \{ \text{let } \text{result}_1 \leftarrow f(a); \ \text{let } \text{result}_2 \leftarrow \text{List.mapM } f \ l; \ \text{pure } (\text{result}_1 :: \text{result}_2) \}
\]
where `::` denotes the cons operation, which adds an element to the front of a list.","theorem List.mapM_cons [Monad m] [LawfulMonad m] (f : α → m β) :
    (a :: l).mapM f = (return (← f a) :: (← l.mapM f)) := by
  simp [← mapM'_eq_mapM, mapM']","To prove the theorem, we start by using the equivalence that `List.mapM` is equal to `List.mapM'` and the definition of `List.mapM'`. The function `List.mapM'` is defined to handle the cons operation by applying the function \( f \) to the head of the list and then recursively applying the function to the tail of the list. Therefore, we can simplify the proposition we want to show as follows:

1. **Simplification:**
Using the equivalence \( \text{List.mapM } f \ (a :: l) = \text{List.mapM' } f \ (a :: l) \) and the definition of `List.mapM'`, we have:
\[
\text{List.mapM' } f \ (a :: l) = \text{do} \ \{ \text{let } \text{result}_1 \leftarrow f(a); \ \text{let } \text{result}_2 \leftarrow \text{List.mapM' } f \ l; \ \text{pure } (\text{result}_1 :: \text{result}_2) \}
\]

2. **Conclusion:**
Since `List.mapM'` is defined to handle the cons operation in this way, the monadic map of \( f \) over the list \( a :: l \) is indeed equal to the monadic action of \( f \) on \( a \) followed by the monadic map of \( f \) over \( l \). Therefore, we have:
\[
\text{List.mapM } f \ (a :: l) = \text{do} \ \{ \text{let } \text{result}_1 \leftarrow f(a); \ \text{let } \text{result}_2 \leftarrow \text{List.mapM } f \ l; \ \text{pure } (\text{result}_1 :: \text{result}_2) \}
\]

This completes the proof.","theorem List.mapM_cons [Monad m] [LawfulMonad m] (f : α → m β) :
    (a :: l).mapM f = (return (← f a) :: (← l.mapM f)) := by
  simp [← mapM'_eq_mapM, mapM']","import Init.Data.List.TakeDrop
import Init.Data.List.Monadic

open List
open Nat
"
25423,Bool.cond_false_same,"theorem Bool.cond_false_same : ∀(c b : Bool), cond c b c = (c && b) := by sorry","Conditional Expression Evaluates to Second Argument if False: $(\text{if } c \text{ then } b \text{ else } c) = (c \land b)$ : For any boolean values $c$ and $b$, the conditional expression `bif c then b else c` is equal to the boolean AND operation `c && b`, i.e., $(\text{if } c \text{ then } b \text{ else } c) = (c \land b)$.","theorem Bool.cond_false_same : ∀(c b : Bool), cond c b c = (c && b) := by
  decide","To prove the theorem, we need to show that for any boolean values $c$ and $b$, the expression $(\text{if } c \text{ then } b \text{ else } c)$ is equal to $(c \land b)$. We will consider all possible values of $c$ and $b$:

1. **Case 1: $c = \text{true}$ and $b = \text{true}$**
- The conditional expression $(\text{if } \text{true} \text{ then } \text{true} \text{ else } \text{true})$ evaluates to $\text{true}$.
- The boolean AND operation $(\text{true} \land \text{true})$ also evaluates to $\text{true}$.
- Therefore, $(\text{if } \text{true} \text{ then } \text{true} \text{ else } \text{true}) = (\text{true} \land \text{true})$.

2. **Case 2: $c = \text{true}$ and $b = \text{false}$**
- The conditional expression $(\text{if } \text{true} \text{ then } \text{false} \text{ else } \text{true})$ evaluates to $\text{false}$.
- The boolean AND operation $(\text{true} \land \text{false})$ also evaluates to $\text{false}$.
- Therefore, $(\text{if } \text{true} \text{ then } \text{false} \text{ else } \text{true}) = (\text{true} \land \text{false})$.

3. **Case 3: $c = \text{false}$ and $b = \text{true}$**
- The conditional expression $(\text{if } \text{false} \text{ then } \text{true} \text{ else } \text{false})$ evaluates to $\text{false}$.
- The boolean AND operation $(\text{false} \land \text{true})$ also evaluates to $\text{false}$.
- Therefore, $(\text{if } \text{false} \text{ then } \text{true} \text{ else } \text{false}) = (\text{false} \land \text{true})$.

4. **Case 4: $c = \text{false}$ and $b = \text{false}$**
- The conditional expression $(\text{if } \text{false} \text{ then } \text{false} \text{ else } \text{false})$ evaluates to $\text{false}$.
- The boolean AND operation $(\text{false} \land \text{false})$ also evaluates to $\text{false}$.
- Therefore, $(\text{if } \text{false} \text{ then } \text{false} \text{ else } \text{false}) = (\text{false} \land \text{false})$.

Since the equality holds in all possible cases, we conclude that for any boolean values $c$ and $b$, the conditional expression $(\text{if } c \text{ then } b \text{ else } c)$ is equal to the boolean AND operation $(c \land b)$. This completes the proof.","theorem Bool.cond_false_same : ∀(c b : Bool), cond c b c = (c && b) := by
  decide","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25424,false_eq_decide_iff,theorem false_eq_decide_iff {p : Prop} [h : Decidable p] : false = decide p ↔ ¬p := by sorry,"Boolean False Equals Decide if and only if Proposition is False: \(\text{false} = \text{decide}(p) \leftrightarrow \neg p\) : For any decidable proposition \( p \), the boolean value `false` is equal to `decide p` if and only if \( p \) is false, i.e., \( \text{false} = \text{decide}(p) \leftrightarrow \neg p \).","theorem false_eq_decide_iff {p : Prop} [h : Decidable p] : false = decide p ↔ ¬p := by
  cases h with | _ q => simp [q]","We will consider the two possible cases for the decidable proposition \( p \).

**Case 1: \( p \) is true.**
- In this case, \( \text{decide}(p) = \text{true} \).
- We need to show that \( \text{false} = \text{decide}(p) \leftrightarrow \neg p \).
- Since \( \text{decide}(p) = \text{true} \), the left-hand side of the equivalence \( \text{false} = \text{true} \) is false.
- Therefore, the equivalence \( \text{false} = \text{true} \leftrightarrow \neg p \) is true if and only if \( \neg p \) is false, which is true because \( p \) is true.
- Hence, the equivalence holds in this case.

**Case 2: \( p \) is false.**
- In this case, \( \text{decide}(p) = \text{false} \).
- We need to show that \( \text{false} = \text{decide}(p) \leftrightarrow \neg p \).
- Since \( \text{decide}(p) = \text{false} \), the left-hand side of the equivalence \( \text{false} = \text{false} \) is true.
- Therefore, the equivalence \( \text{false} = \text{false} \leftrightarrow \neg p \) is true if and only if \( \neg p \) is true, which is true because \( p \) is false.
- Hence, the equivalence holds in this case.

Since the equivalence holds in both cases, we conclude that for any decidable proposition \( p \), \( \text{false} = \text{decide}(p) \leftrightarrow \neg p \). This completes the proof.","theorem false_eq_decide_iff {p : Prop} [h : Decidable p] : false = decide p ↔ ¬p := by
/- We will consider the two possible cases for the decidable proposition \( p \).

**Case 1: \( p \) is true.**
- In this case, we have \( \text{decide}(p) = \text{true} \).
- We need to show that \( \text{false} = \text{decide}(p) \leftrightarrow \neg p \).
- Since \( \text{decide}(p) = \text{true} \), the left-hand side of the equivalence \( \text{false} = \text{true} \) is false.
- Therefore, the equivalence \( \text{false} = \text{true} \leftrightarrow \neg p \) is true if and only if \( \neg p \) is false, which is true because \( p \) is true.
- Hence, the equivalence holds in this case.

**Case 2: \( p \) is false.**
- In this case, we have \( \text{decide}(p) = \text{false} \).
- We need to show that \( \text{false} = \text{decide}(p) \leftrightarrow \neg p \).
- Since \( \text{decide}(p) = \text{false} \), the left-hand side of the equivalence \( \text{false} = \text{false} \) is true.
- Therefore, the equivalence \( \text{false} = \text{false} \leftrightarrow \neg p \) is true if and only if \( \neg p \) is true, which is true because \( p \) is false.
- Hence, the equivalence holds in this case. -/
  cases h with | _ q => simp [q]","import Init.BinderPredicates
import Init.Data.Bool



"
25427,Bool.apply_cond,"theorem Bool.apply_cond (f : α → β) {b : Bool} {a a' : α} :
    f (bif b then a else a') = bif b then f a else f a' := by sorry","Function Application Distributes Over Conditional Expressions : For any types $\alpha$ and $\beta$, and for any function $f : \alpha \to \beta$, if $b$ is a boolean value and $a, a' \in \alpha$, then the application of $f$ to the conditional expression `bif b then a else a'` is equal to the conditional expression `bif b then f a else f a'`. In other words, $f(\text{if } b \text{ then } a \text{ else } a') = \text{if } b \text{ then } f(a) \text{ else } f(a')$.","theorem Bool.apply_cond (f : α → β) {b : Bool} {a a' : α} :
    f (bif b then a else a') = bif b then f a else f a' := by
  cases b <;> simp","We will consider every possible case of the boolean value $b$.

1. **Case 1: $b = \text{false}$**
- We need to show that $f(\text{if } \text{false} \text{ then } a \text{ else } a') = \text{if } \text{false} \text{ then } f(a) \text{ else } f(a')$.
- Simplifying the left-hand side, we get $f(\text{if } \text{false} \text{ then } a \text{ else } a') = f(a')$.
- Simplifying the right-hand side, we get $\text{if } \text{false} \text{ then } f(a) \text{ else } f(a') = f(a')$.
- Therefore, $f(\text{if } \text{false} \text{ then } a \text{ else } a') = f(a') = \text{if } \text{false} \text{ then } f(a) \text{ else } f(a')$.

2. **Case 2: $b = \text{true}$**
- We need to show that $f(\text{if } \text{true} \text{ then } a \text{ else } a') = \text{if } \text{true} \text{ then } f(a) \text{ else } f(a')$.
- Simplifying the left-hand side, we get $f(\text{if } \text{true} \text{ then } a \text{ else } a') = f(a)$.
- Simplifying the right-hand side, we get $\text{if } \text{true} \text{ then } f(a) \text{ else } f(a') = f(a)$.
- Therefore, $f(\text{if } \text{true} \text{ then } a \text{ else } a') = f(a) = \text{if } \text{true} \text{ then } f(a) \text{ else } f(a')$.

Since both cases hold, we have shown that $f(\text{if } b \text{ then } a \text{ else } a') = \text{if } b \text{ then } f(a) \text{ else } f(a')$ for any boolean value $b$. This completes the proof.","theorem Bool.apply_cond (f : α → β) {b : Bool} {a a' : α} :
    f (bif b then a else a') = bif b then f a else f a' := by
/- We will consider every possible case of the boolean value $b$. There are two cases: $b = \text{true}$ and $b = \text{false}$. For each case, we will simplify the expression to show that the function $f$ applied to the conditional expression is equal to the conditional expression of the function applied to the values. -/
/- We will discuss every possible case of the boolean value $b$. Case 1: $b = \text{false}$. Case 2: $b = \text{true}$. -/
/- For each of these cases, we will simplify the expression to show the desired equality. -/
/- For the case $b = \text{false}$, we simplify the expression $f(\text{if } \text{false} \text{ then } a \text{ else } a')$ to $f(a')$ and the expression $\text{if } \text{false} \text{ then } f(a) \text{ else } f(a')$ to $f(a')$. Therefore, $f(\text{if } \text{false} \text{ then } a \text{ else } a') = \text{if } \text{false} \text{ then } f(a) \text{ else } f(a')$. -/
/- For the case $b = \text{true}$, we simplify the expression $f(\text{if } \text{true} \text{ then } a \text{ else } a')$ to $f(a)$ and the expression $\text{if } \text{true} \text{ then } f(a) \text{ else } f(a')$ to $f(a)$. Therefore, $f(\text{if } \text{true} \text{ then } a \text{ else } a') = \text{if } \text{true} \text{ then } f(a) \text{ else } f(a')$. -/
  cases b <;> simp","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
25433,List.forM_append,"theorem List.forM_append [Monad m] [LawfulMonad m] (l₁ l₂ : List α) (f : α → m PUnit) :
    (l₁ ++ l₂).forM f = (do l₁.forM f; l₂.forM f) := by sorry","Monadic Action on Concatenated Lists: $(l_1 \oplus l_2). \text{forM } f = \text{do} \{ l_1. \text{forM } f; l_2. \text{forM } f \}$ : For any monad `m` and any lists `l₁` and `l₂` of elements of type `α`, the monadic action `f` applied to the concatenation of `l₁` and `l₂` is equivalent to first applying `f` to `l₁` and then applying `f` to `l₂`. Formally, this is expressed as:
\[
(l_1 \oplus l_2). \text{forM } f = \text{do} \{ l_1. \text{forM } f; l_2. \text{forM } f \}
\]
where `⊕` denotes the list concatenation operation, and `do` is the monadic sequencing operation.","theorem List.forM_append [Monad m] [LawfulMonad m] (l₁ l₂ : List α) (f : α → m PUnit) :
    (l₁ ++ l₂).forM f = (do l₁.forM f; l₂.forM f) := by
  induction l₁ <;> simp [*]","We perform induction on the list `l₁` to break down the proof into two cases: the base case where `l₁` is the empty list, and the inductive step where `l₁` is a non-empty list of the form `head :: tail`.

**Base Case:**
For the base case, we need to show that:
\[
([] \oplus l_2). \text{forM } f = \text{do} \{ []. \text{forM } f; l_2. \text{forM } f \}
\]
Simplifying the left-hand side, we have:
\[
([] \oplus l_2). \text{forM } f = l_2. \text{forM } f
\]
Simplifying the right-hand side, we have:
\[
\text{do} \{ []. \text{forM } f; l_2. \text{forM } f \} = l_2. \text{forM } f
\]
Thus, the base case holds.

**Inductive Step:**
For the inductive step, assume that the property holds for a list `tail`, i.e.,
\[
(tail \oplus l_2). \text{forM } f = \text{do} \{ tail. \text{forM } f; l_2. \text{forM } f \}
\]
We need to show that the property holds for the list `head :: tail`, i.e.,
\[
((head :: tail) \oplus l_2). \text{forM } f = \text{do} \{ (head :: tail). \text{forM } f; l_2. \text{forM } f \}
\]
Simplifying the left-hand side, we have:
\[
((head :: tail) \oplus l_2). \text{forM } f = (head :: (tail \oplus l_2)). \text{forM } f
\]
By the definition of `forM` for a non-empty list, this is equivalent to:
\[
f(head) >>= \lambda \_. (tail \oplus l_2). \text{forM } f
\]
Using the inductive hypothesis, we get:
\[
f(head) >>= \lambda \_. \text{do} \{ tail. \text{forM } f; l_2. \text{forM } f \}
\]
By the monadic sequencing operation, this is equivalent to:
\[
\text{do} \{ f(head); tail. \text{forM } f; l_2. \text{forM } f \}
\]
Simplifying the right-hand side, we have:
\[
\text{do} \{ (head :: tail). \text{forM } f; l_2. \text{forM } f \} = \text{do} \{ f(head); tail. \text{forM } f; l_2. \text{forM } f \}
\]
Thus, the inductive step holds.

By induction, the theorem is proved.","theorem List.forM_append [Monad m] [LawfulMonad m] (l₁ l₂ : List α) (f : α → m PUnit) :
    (l₁ ++ l₂).forM f = (do l₁.forM f; l₂.forM f) := by
/- We perform induction on the list `l₁` to break down the proof into cases. For the base case, we need to show that the monadic action `f` applied to the concatenation of the empty list and `l₂` is equivalent to applying `f` to the empty list and then to `l₂`. For the inductive step, we assume that the property holds for a list `tail` and show that it also holds for the list `head :: tail`. -/
/- We perform induction on the list `l₁` to break down the proof into two cases: the base case where `l₁` is the empty list, and the inductive step where `l₁` is a non-empty list of the form `head :: tail`. -/
/- First, we handle the base case where `l₁` is the empty list. Then, we handle the inductive step where `l₁` is a non-empty list of the form `head :: tail`. -/
/- For the base case, we simplify the proposition we want to show using the known properties of the empty list and the monadic action `f`. This simplification shows that the monadic action `f` applied to the concatenation of the empty list and `l₂` is equivalent to applying `f` to the empty list and then to `l₂`. -/
/- For the inductive step, we simplify the proposition we want to show using the inductive hypothesis and the known properties of the monadic action `f`. This simplification shows that the monadic action `f` applied to the concatenation of `head :: tail` and `l₂` is equivalent to applying `f` to `head :: tail` and then to `l₂`. -/
  induction l₁ <;> simp [*]","import Init.Data.List.TakeDrop
import Init.Data.List.Monadic

open List
open Nat
"
25436,Bool.decide_iff_dist,"theorem Bool.decide_iff_dist (p q : Prop) [dpq : Decidable (p ↔ q)] [dp : Decidable p] [dq : Decidable q] :
    decide (p ↔ q) = (decide p == decide q) := by sorry","Boolean Decide of Bi-implication Equals Boolean Equality of Decides: \(\text{decide}(p \leftrightarrow q) = \text{decide}(p) == \text{decide}(q)\) : For any decidable propositions \( p \) and \( q \), the boolean value `decide (p \leftrightarrow q)` is equal to the boolean value `decide p == decide q`, i.e., \(\text{decide}(p \leftrightarrow q) = \text{decide}(p) == \text{decide}(q)\).","theorem Bool.decide_iff_dist (p q : Prop) [dpq : Decidable (p ↔ q)] [dp : Decidable p] [dq : Decidable q] :
    decide (p ↔ q) = (decide p == decide q) := by
  cases dp with | _ p => simp [p]","We will consider every possible case of the decidable proposition \( p \).

- **Case 1:** \( p \) is true.
- Using the fact that \( p \) is true, we simplify the proposition we want to show, which is \(\text{decide}(p \leftrightarrow q) = \text{decide}(p) == \text{decide}(q)\). Since \( p \) is true, \(\text{decide}(p) = \text{true}\). Therefore, the goal reduces to showing \(\text{decide}(p \leftrightarrow q) = \text{true} == \text{decide}(q)\). This is equivalent to showing \(\text{decide}(p \leftrightarrow q) = \text{decide}(q)\).
- By the definition of \(\text{decide}\), \(\text{decide}(p \leftrightarrow q)\) is true if and only if \( p \leftrightarrow q \) is true. Since \( p \) is true, \( p \leftrightarrow q \) is true if and only if \( q \) is true. Therefore, \(\text{decide}(p \leftrightarrow q) = \text{decide}(q)\).

- **Case 2:** \( p \) is false.
- Using the fact that \( p \) is false, we simplify the proposition we want to show, which is \(\text{decide}(p \leftrightarrow q) = \text{decide}(p) == \text{decide}(q)\). Since \( p \) is false, \(\text{decide}(p) = \text{false}\). Therefore, the goal reduces to showing \(\text{decide}(p \leftrightarrow q) = \text{false} == \text{decide}(q)\). This is equivalent to showing \(\text{decide}(p \leftrightarrow q) = \neg \text{decide}(q)\).
- By the definition of \(\text{decide}\), \(\text{decide}(p \leftrightarrow q)\) is true if and only if \( p \leftrightarrow q \) is true. Since \( p \) is false, \( p \leftrightarrow q \) is true if and only if \( q \) is false. Therefore, \(\text{decide}(p \leftrightarrow q) = \neg \text{decide}(q)\).

In both cases, we have shown that \(\text{decide}(p \leftrightarrow q) = \text{decide}(p) == \text{decide}(q)\). This completes the proof. \(\blacksquare\)","theorem Bool.decide_iff_dist (p q : Prop) [dpq : Decidable (p ↔ q)] [dp : Decidable p] [dq : Decidable q] :
    decide (p ↔ q) = (decide p == decide q) := by
/- We will consider every possible case of the decidable proposition \( p \).

- **Case 1:** \( p \) is true.
- Using the fact that \( p \) is true, we simplify the proposition we want to show, which is \(\text{decide}(p \leftrightarrow q) = \text{decide}(p) == \text{decide}(q)\). Since \( p \) is true, \(\text{decide}(p) = \text{true}\). Therefore, the goal reduces to showing \(\text{decide}(p \leftrightarrow q) = \text{true} == \text{decide}(q)\). This is equivalent to showing \(\text{decide}(p \leftrightarrow q) = \text{decide}(q)\).

- **Case 2:** \( p \) is false.
- Using the fact that \( p \) is false, we simplify the proposition we want to show, which is \(\text{decide}(p \leftrightarrow q) = \text{decide}(p) == \text{decide}(q)\). Since \( p \) is false, \(\text{decide}(p) = \text{false}\). Therefore, the goal reduces to showing \(\text{decide}(p \leftrightarrow q) = \text{false} == \text{decide}(q)\). This is equivalent to showing \(\text{decide}(p \leftrightarrow q) = \neg \text{decide}(q)\). -/
/- - **Case 1:** \( p \) is true.
- Since \( p \) is true, we simplify the proposition \(\text{decide}(p \leftrightarrow q) = \text{decide}(q)\). By the definition of \(\text{decide}\), \(\text{decide}(p \leftrightarrow q)\) is true if and only if \( p \leftrightarrow q \) is true. Since \( p \) is true, \( p \leftrightarrow q \) is true if and only if \( q \) is true. Therefore, \(\text{decide}(p \leftrightarrow q) = \text{decide}(q)\).

- **Case 2:** \( p \) is false.
- Since \( p \) is false, we simplify the proposition \(\text{decide}(p \leftrightarrow q) = \neg \text{decide}(q)\). By the definition of \(\text{decide}\), \(\text{decide}(p \leftrightarrow q)\) is true if and only if \( p \leftrightarrow q \) is true. Since \( p \) is false, \( p \leftrightarrow q \) is true if and only if \( q \) is false. Therefore, \(\text{decide}(p \leftrightarrow q) = \neg \text{decide}(q)\). -/
  cases dp with | _ p => simp [p]","import Init.BinderPredicates
import Init.Data.Bool

open Bool

"
26136,Nat.min_le_right,theorem Nat.min_le_right (a b : Nat) : min a b ≤ b := by sorry,"Minimum is Less Than or Equal to Right Argument in Natural Numbers : For any natural numbers \(a\) and \(b\), the minimum of \(a\) and \(b\) is less than or equal to \(b\), i.e., \(\min(a, b) \leq b\).","theorem Nat.min_le_right (a b : Nat) : min a b ≤ b := by
  by_cases (a <= b) <;> simp [Nat.min_def, *]","To prove that \(\min(a, b) \leq b\) for any natural numbers \(a\) and \(b\), we consider two cases based on the relationship between \(a\) and \(b\):

1. **Case 1: \(a \leq b\)**

By the definition of the minimum function, \(\min(a, b) = a\) if \(a \leq b\). Since we are assuming \(a \leq b\), it follows that \(\min(a, b) = a \leq b\). Therefore, \(\min(a, b) \leq b\) holds in this case.

2. **Case 2: \(a \not\leq b\)**

By the definition of the minimum function, \(\min(a, b) = b\) if \(a \not\leq b\). Since we are assuming \(a \not\leq b\), it follows that \(\min(a, b) = b\). Clearly, \(b \leq b\) is always true. Therefore, \(\min(a, b) \leq b\) holds in this case as well.

Since both cases cover all possible relationships between \(a\) and \(b\), we conclude that \(\min(a, b) \leq b\) for any natural numbers \(a\) and \(b\). This completes the proof. \(\blacksquare\)","theorem Nat.min_le_right (a b : Nat) : min a b ≤ b := by
/- Consider two cases: (1) Assume \( a \leq b \), and (2) Assume \( a \not\leq b \). -/
/- In the first case, where \( a \leq b \), we use the definition of the minimum function. The definition states that \(\min(a, b) = a\) if \( a \leq b \). Therefore, we need to show that \( a \leq b \), which is true by our assumption. Hence, \(\min(a, b) \leq b\). -/
/- In the second case, where \( a \not\leq b \), we again use the definition of the minimum function. The definition states that \(\min(a, b) = b\) if \( a \not\leq b \). Therefore, we need to show that \( b \leq b \), which is trivially true. Hence, \(\min(a, b) \leq b\). -/
  by_cases (a <= b) <;> simp [Nat.min_def, *]","import Init.ByCases
import Init.Data.Nat.MinMax

open Nat

"
26141,Nat.le_max_left,theorem Nat.le_max_left ( a b : Nat) : a ≤ max a b := by sorry,"Left Element is Less Than or Equal to Maximum in Natural Numbers : For any natural numbers \( a \) and \( b \), it holds that \( a \leq \max(a, b) \).","theorem Nat.le_max_left ( a b : Nat) : a ≤ max a b := by
  by_cases (a <= b) <;> simp [Nat.max_def, *]","To prove that \( a \leq \max(a, b) \) for any natural numbers \( a \) and \( b \), we consider two cases based on the relationship between \( a \) and \( b \).

1. **Case 1: \( a \leq b \)**
- By the definition of the maximum function, \(\max(a, b) = b\) if \( a \leq b \).
- Therefore, \( a \leq \max(a, b) \) simplifies to \( a \leq b \), which is true by our assumption.

2. **Case 2: \( a \not\leq b \)**
- By the definition of the maximum function, \(\max(a, b) = a\) if \( a \not\leq b \).
- Therefore, \( a \leq \max(a, b) \) simplifies to \( a \leq a \), which is always true by the reflexive property of the less than or equal to relation.

Since both cases cover all possible relationships between \( a \) and \( b \), we conclude that \( a \leq \max(a, b) \) holds for any natural numbers \( a \) and \( b \). This completes the proof.","theorem Nat.le_max_left ( a b : Nat) : a ≤ max a b := by
/- Consider two cases: (1) Assume \( a \leq b \), and (2) Assume \( a \not\leq b \). -/
/- In the first case, where \( a \leq b \), we use the definition of the maximum function, which states that \(\max(a, b) = b\) if \( a \leq b \). Therefore, \( a \leq \max(a, b) \) simplifies to \( a \leq b \), which is true by our assumption. -/
/- In the second case, where \( a \not\leq b \), we again use the definition of the maximum function, which states that \(\max(a, b) = a\) if \( a \not\leq b \). Therefore, \( a \leq \max(a, b) \) simplifies to \( a \leq a \), which is always true by the reflexive property of the less than or equal to relation. -/
  by_cases (a <= b) <;> simp [Nat.max_def, *]","import Init.ByCases
import Init.Data.Nat.MinMax

open Nat

"
26161,Nat.min_comm,theorem Nat.min_comm (a b : Nat) : min a b = min b a := by sorry,"Commutativity of Minimum on Natural Numbers: \(\min(a, b) = \min(b, a)\) : For any natural numbers \( a \) and \( b \), the minimum of \( a \) and \( b \) is equal to the minimum of \( b \) and \( a \), i.e., \(\min(a, b) = \min(b, a)\).","theorem Nat.min_comm (a b : Nat) : min a b = min b a := by
  match Nat.lt_trichotomy a b with
  | .inl h => simp [Nat.min_def, h, Nat.le_of_lt, Nat.not_le_of_lt]
  | .inr (.inl h) => simp [Nat.min_def, h]
  | .inr (.inr h) => simp [Nat.min_def, h, Nat.le_of_lt, Nat.not_le_of_lt]","To prove that \(\min(a, b) = \min(b, a)\) for any natural numbers \( a \) and \( b \), we consider the following cases:

1. **Case 1: \( a \leq b \) and \( b \leq a \)**
- If \( a \leq b \) and \( b \leq a \), then \( a = b \).
- By the definition of the minimum function, \(\min(a, b) = a\) and \(\min(b, a) = a\).
- Therefore, \(\min(a, b) = \min(b, a)\).

2. **Case 2: \( a \leq b \) and \( b \not\leq a \)**
- If \( a \leq b \) and \( b \not\leq a \), then \( a < b \).
- By the definition of the minimum function, \(\min(a, b) = a\) and \(\min(b, a) = a\).
- Therefore, \(\min(a, b) = \min(b, a)\).

3. **Case 3: \( a \not\leq b \) and \( b \leq a \)**
- If \( a \not\leq b \) and \( b \leq a \), then \( b < a \).
- By the definition of the minimum function, \(\min(a, b) = b\) and \(\min(b, a) = b\).
- Therefore, \(\min(a, b) = \min(b, a)\).

4. **Case 4: \( a \not\leq b \) and \( b \not\leq a \)**
- If \( a \not\leq b \) and \( b \not\leq a \), then \( a = b \).
- By the definition of the minimum function, \(\min(a, b) = a\) and \(\min(b, a) = a\).
- Therefore, \(\min(a, b) = \min(b, a)\).

In all cases, we have shown that \(\min(a, b) = \min(b, a)\). This completes the proof.","theorem Nat.min_comm (a b : Nat) : min a b = min b a := by
  match Nat.lt_trichotomy a b with
/- Consider the case where \( a \) is less than or equal to \( b \). Using the definition of the minimum function and the property that \( a \leq b \), we simplify the expression to show that \(\min(a, b) = a\) and \(\min(b, a) = a\), thus \(\min(a, b) = \min(b, a)\). -/
  | .inl h => simp [Nat.min_def, h, Nat.le_of_lt, Nat.not_le_of_lt]
/- Consider the case where \( a \) is not less than \( b \) but \( b \) is less than or equal to \( a \). Using the definition of the minimum function and the property that \( b \leq a \), we simplify the expression to show that \(\min(a, b) = b\) and \(\min(b, a) = b\), thus \(\min(a, b) = \min(b, a)\). -/
  | .inr (.inl h) => simp [Nat.min_def, h]
/- Consider the case where \( a \) and \( b \) are such that \( a \) is not less than \( b \) and \( b \) is not less than \( a \). Using the definition of the minimum function and the properties that \( a \leq b \) and \( b \leq a \) (which imply \( a = b \)), we simplify the expression to show that \(\min(a, b) = \min(b, a)\). -/
/- Consider the case where \( a \) and \( b \) are such that \( a \) is not less than \( b \) and \( b \) is not less than \( a \). Using the definition of the minimum function and the properties that \( a \leq b \) and \( b \leq a \) (which imply \( a = b \)), we simplify the expression to show that \(\min(a, b) = \min(b, a)\). -/
  | .inr (.inr h) => simp [Nat.min_def, h, Nat.le_of_lt, Nat.not_le_of_lt]","import Init.ByCases
import Init.Data.Nat.MinMax

open Nat

"
26168,Nat.max_comm,theorem Nat.max_comm (a b : Nat) : max a b = max b a := by sorry,"Commutativity of Maximum Operation in Natural Numbers: \(\max(a, b) = \max(b, a)\) : For any natural numbers \(a\) and \(b\), the maximum of \(a\) and \(b\) is equal to the maximum of \(b\) and \(a\), i.e., \(\max(a, b) = \max(b, a)\).","theorem Nat.max_comm (a b : Nat) : max a b = max b a := by
  simp only [Nat.max_def]
  by_cases h₁ : a ≤ b <;> by_cases h₂ : b ≤ a <;> simp [h₁, h₂]
  · exact Nat.le_antisymm h₂ h₁
  · cases not_or_intro h₁ h₂ <| Nat.le_total ..","We start by using the definition of the maximum function in a linear order. The maximum of \(a\) and \(b\) is defined as:
\[
\max(a, b) = \begin{cases}
b & \text{if } a \leq b \\
a & \text{if } a > b
\end{cases}
\]
Similarly, the maximum of \(b\) and \(a\) is:
\[
\max(b, a) = \begin{cases}
a & \text{if } b \leq a \\
b & \text{if } b > a
\end{cases}
\]
Thus, the goal \(\max(a, b) = \max(b, a)\) is equivalent to:
\[
(\text{if } a \leq b \text{ then } b \text{ else } a) = (\text{if } b \leq a \text{ then } a \text{ else } b)
\]

We consider two cases for \(a \leq b\) and \(b \leq a\):

1. **Case 1:** Assume \(a \leq b\).
- **Subcase 1.1:** Assume \(b \leq a\).
- Using the antisymmetry property of the less than or equal to relation, if \(a \leq b\) and \(b \leq a\), then \(a = b\). Therefore, the goal simplifies to \(b = a\), which is true.
- **Subcase 1.2:** Assume \(\neg (b \leq a)\).
- Since \(a \leq b\) and \(\neg (b \leq a)\), the goal simplifies to \(b = b\), which is trivially true.

2. **Case 2:** Assume \(\neg (a \leq b)\).
- **Subcase 2.1:** Assume \(b \leq a\).
- Since \(\neg (a \leq b)\) and \(b \leq a\), the goal simplifies to \(a = a\), which is trivially true.
- **Subcase 2.2:** Assume \(\neg (b \leq a)\).
- Since \(\neg (a \leq b)\) and \(\neg (b \leq a)\), we have a contradiction because the totality of the less than or equal to relation implies that either \(a \leq b\) or \(b \leq a\) must hold. Therefore, this subcase is impossible, and the goal simplifies to \(a = b\).

In all cases, the goal \(\max(a, b) = \max(b, a)\) is satisfied. Therefore, the theorem is proved. \(\blacksquare\)","theorem Nat.max_comm (a b : Nat) : max a b = max b a := by
/- First, we use the definition of the maximum function in a linear order to simplify the goal. The maximum of \(a\) and \(b\) is defined as \(b\) if \(a \leq b\), and \(a\) otherwise. Therefore, the goal \(\max(a, b) = \max(b, a)\) is equivalent to \((\text{if } a \leq b \text{ then } b \text{ else } a) = (\text{if } b \leq a \text{ then } a \text{ else } b)\). -/
  simp only [Nat.max_def]
/- We consider two cases for \(a \leq b\) and \(b \leq a\):

1. **Case 1:** Assume \(a \leq b\).
- We further consider two subcases for \(b \leq a\):
- **Subcase 1.1:** Assume \(b \leq a\).
- Using the assumptions \(a \leq b\) and \(b \leq a\), we simplify the goal to \(b = a\).
- **Subcase 1.2:** Assume \(\neg (b \leq a)\).
- Using the assumption \(a \leq b\) and \(\neg (b \leq a)\), we simplify the goal to \(b = b\), which is trivially true.

2. **Case 2:** Assume \(\neg (a \leq b)\).
- We further consider two subcases for \(b \leq a\):
- **Subcase 2.1:** Assume \(b \leq a\).
- Using the assumptions \(\neg (a \leq b)\) and \(b \leq a\), we simplify the goal to \(a = a\), which is trivially true.
- **Subcase 2.2:** Assume \(\neg (b \leq a)\).
- Using the assumptions \(\neg (a \leq b)\) and \(\neg (b \leq a)\), we simplify the goal to \(a = b\). -/
  by_cases h₁ : a ≤ b <;> by_cases h₂ : b ≤ a <;> simp [h₁, h₂]
/- In the subcase where \(a \leq b\) and \(b \leq a\), we use the antisymmetry property of the less than or equal to relation to conclude that \(b = a\). -/
  · exact Nat.le_antisymm h₂ h₁
/- In the subcase where \(\neg (a \leq b)\) and \(\neg (b \leq a)\), we use the totality of the less than or equal to relation to derive a contradiction. Since \(\neg (a \leq b)\) and \(\neg (b \leq a)\) imply that neither \(a \leq b\) nor \(b \leq a\) holds, this is a contradiction, and thus \(a = b\). -/
  · cases not_or_intro h₁ h₂ <| Nat.le_total ..","import Init.ByCases
import Init.Data.Nat.MinMax

open Nat

"
26282,Int.pow_succ',theorem Int.pow_succ' (b : Int) (e : Nat) : b ^ (e+1) = b * (b ^ e) := by sorry,"Power of Successor: \( b^{e + 1} = b \cdot b^e \) : For any integer \( b \) and any natural number \( e \), the power \( b^{e + 1} \) is equal to \( b \cdot b^e \), i.e., \( b^{e + 1} = b \cdot b^e \).","theorem Int.pow_succ' (b : Int) (e : Nat) : b ^ (e+1) = b * (b ^ e) := by
  rw [Int.mul_comm, Int.pow_succ]","We start with the goal of proving that \( b^{e + 1} = b \cdot b^e \) for any integer \( b \) and any natural number \( e \).

1. First, we use the commutativity of multiplication to rewrite the goal \( b \cdot b^e \) as \( b^e \cdot b \). This gives us the equivalent goal:
\[
b^{e + 1} = b^e \cdot b
\]

2. Next, we use the property of powers in monoids, which states that for any integer \( b \) and any natural number \( e \), \( b^{e + 1} = b^e \cdot b \). This property directly matches our current goal, so we have:
\[
b^{e + 1} = b^e \cdot b
\]

3. Since the goal \( b^e \cdot b = b^e \cdot b \) is trivially true by the properties of equality, the proof is complete.

Thus, we have shown that \( b^{e + 1} = b \cdot b^e \) for any integer \( b \) and any natural number \( e \). \(\blacksquare\)","theorem Int.pow_succ' (b : Int) (e : Nat) : b ^ (e+1) = b * (b ^ e) := by
/- First, we use the commutativity of multiplication to rewrite the goal \( b \cdot b^e \) as \( b^e \cdot b \). Then, we use the property of powers in monoids, which states that \( b^{e + 1} = b^e \cdot b \). Therefore, the goal \( b^{e + 1} = b \cdot b^e \) is equivalent to \( b^{e + 1} = b^e \cdot b \). -/
/- Next, we use the property of powers in monoids again, which states that \( b^{e + 1} = b^e \cdot b \). This directly matches our current goal, so the goal is now \( b^e \cdot b = b^e \cdot b \), which is trivially true by the properties of equality. -/
  rw [Int.mul_comm, Int.pow_succ]","import Init.Data.Int.Lemmas
import Init.Data.Int.Pow

open Int

"
26984,List.zip_map_left,"theorem List.zip_map_left (f : α → γ) (l₁ : List α) (l₂ : List β) :
    zip (l₁.map f) l₂ = (zip l₁ l₂).map (Prod.map f id) := by sorry","Left Mapping Preserves Zip Operation in Lists : For any types \( \alpha \), \( \beta \), and \( \gamma \), and for any function \( f : \alpha \to \gamma \), lists \( l_1 : \text{List } \alpha \) and \( l_2 : \text{List } \beta \), the following holds:
\[ (\text{map } f \, l_1) \text{.zip } l_2 = \text{map } (\text{Prod.map } f \, \text{id}) \, (l_1 \text{.zip } l_2) \]
In other words, zipping a list \( l_1 \) after applying \( f \) to each element of \( l_1 \) with a list \( l_2 \) is the same as applying the function \( \text{Prod.map } f \, \text{id} \) to each pair in the zipped list of \( l_1 \) and \( l_2 \).","theorem List.zip_map_left (f : α → γ) (l₁ : List α) (l₂ : List β) :
    zip (l₁.map f) l₂ = (zip l₁ l₂).map (Prod.map f id) := by
  rw [← zip_map, map_id]","To prove the theorem, we start by using the theorem that zipping the results of applying \( f \) to \( l_1 \) and the identity function to \( l_2 \) is the same as applying the function \( \text{Prod.map } f \, \text{id} \) to the pairs in the zipped list of \( l_1 \) and \( l_2 \). This theorem states:
\[
(\text{map } f \, l_1). \text{zip } (\text{map } \text{id} \, l_2) = \text{map } (\text{Prod.map } f \, \text{id}) \, (l_1. \text{zip } l_2).
\]
Since applying the identity function to \( l_2 \) results in \( l_2 \) itself, we have:
\[
(\text{map } f \, l_1). \text{zip } l_2 = (\text{map } f \, l_1). \text{zip } l_2.
\]
This is a trivial equality, and thus the proof is complete. Therefore, we have shown that:
\[
(\text{map } f \, l_1) \text{.zip } l_2 = \text{map } (\text{Prod.map } f \, \text{id}) \, (l_1 \text{.zip } l_2).
\]
\(\blacksquare\)","theorem List.zip_map_left (f : α → γ) (l₁ : List α) (l₂ : List β) :
    zip (l₁.map f) l₂ = (zip l₁ l₂).map (Prod.map f id) := by
  rw [← zip_map, map_id]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
26989,List.zip_map_right,"theorem List.zip_map_right (f : β → γ) (l₁ : List α) (l₂ : List β) :
    zip l₁ (l₂.map f) = (zip l₁ l₂).map (Prod.map id f) := by sorry","Right Mapping Preserves Zip Operation in Lists : For any types \( \alpha \), \( \beta \), and \( \gamma \), and for any function \( f : \beta \to \gamma \), lists \( l_1 : \text{List } \alpha \) and \( l_2 : \text{List } \beta \), the following holds:
\[ l_1 \text{.zip} (f \text{.map } l_2) = (f \text{.map } \text{Prod.map id } f) (l_1 \text{.zip } l_2) \]
In other words, zipping a list \( l_1 \) with the result of applying \( f \) to each element of \( l_2 \) is the same as applying the function \( \text{Prod.map id } f \) to each pair in the zipped list of \( l_1 \) and \( l_2 \).","theorem List.zip_map_right (f : β → γ) (l₁ : List α) (l₂ : List β) :
    zip l₁ (l₂.map f) = (zip l₁ l₂).map (Prod.map id f) := by
  rw [← zip_map, map_id]","To prove the theorem, we start with the goal:
\[
l_1. \text{zip } (f. \text{map } l_2) = (f. \text{map } \text{Prod.map id } f) (l_1. \text{zip } l_2).
\]
First, we use the theorem that zipping the results of applying a function to each element of two lists is the same as applying the function to the pairs in the zipped list. Specifically, for any types \( \alpha \), \( \beta \), \( \gamma \), and \( \delta \), and for any functions \( f : \alpha \to \gamma \) and \( g : \beta \to \delta \), and for any lists \( l_1 : \text{List } \alpha \) and \( l_2 : \text{List } \beta \), the following equality holds:
\[
(\text{map } f \, l_1). \text{zip } (\text{map } g \, l_2) = \text{map } (\text{Prod.map } f \, g) \, (l_1. \text{zip } l_2).
\]
Applying this theorem in the reverse direction to the left-hand side of our goal, we get:
\[
l_1. \text{zip } (\text{map } f \, l_2) = (\text{map } \text{id} \, l_1). \text{zip } (\text{map } f \, l_2).
\]
Next, we use the theorem that applying the identity function to each element of a list results in the same list. Specifically, for any list \( l \) of elements of type \( \alpha \), the following equality holds:
\[
\text{map } \text{id} \, l = l.
\]
Applying this theorem to the right-hand side of our goal, we get:
\[
l_1. \text{zip } (\text{map } f \, l_2) = l_1. \text{zip } (\text{map } f \, l_2).
\]
Since the left-hand side and the right-hand side are now identical, the goal is trivially true by the reflexive property of equality. This completes the proof.","theorem List.zip_map_right (f : β → γ) (l₁ : List α) (l₂ : List β) :
    zip l₁ (l₂.map f) = (zip l₁ l₂).map (Prod.map id f) := by
  rw [← zip_map, map_id]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
26991,List.zipWith_comm_of_comm,"theorem List.zipWith_comm_of_comm (f : α → α → β) (comm : ∀ x y : α, f x y = f y x) (l l' : List α) :
    zipWith f l l' = zipWith f l' l := by sorry","Commutativity of `zipWith` for Commutative Functions : For any types $\alpha$ and $\beta$, and a function $f : \alpha \to \alpha \to \beta$ that is commutative, i.e., $f(x, y) = f(y, x)$ for all $x, y \in \alpha$, and for any lists $l, l' : \text{List } \alpha$, the result of applying `zipWith` to $l$ and $l'$ using $f$ is the same as applying `zipWith` to $l'$ and $l$ using $f$. In other words, if $f$ is commutative, then:
\[ \text{zipWith } f \, l \, l' = \text{zipWith } f \, l' \, l \]","theorem List.zipWith_comm_of_comm (f : α → α → β) (comm : ∀ x y : α, f x y = f y x) (l l' : List α) :
    zipWith f l l' = zipWith f l' l := by
  rw [zipWith_comm]
  simp only [comm]","To prove the theorem, we start by using the commutativity property of `zipWith` for function swapping arguments. Specifically, since $f$ is commutative, we have:
\[ \text{zipWith } f \, l \, l' = \text{zipWith } (fun \, b \, a \, => \, f \, a \, b) \, l' \, l \]
This means it suffices to show that:
\[ \text{zipWith } (fun \, b \, a \, => \, f \, a \, b) \, l' \, l = \text{zipWith } f \, l' \, l \]

Since $f$ is commutative, for any $x, y \in \alpha$, we have $f(x, y) = f(y, x)$. Therefore, the function $(fun \, b \, a \, => \, f \, a \, b)$ is equivalent to $f$. Hence, the expression $\text{zipWith } (fun \, b \, a \, => \, f \, a \, b) \, l' \, l$ simplifies to $\text{zipWith } f \, l' \, l$. This completes the proof.","theorem List.zipWith_comm_of_comm (f : α → α → β) (comm : ∀ x y : α, f x y = f y x) (l l' : List α) :
    zipWith f l l' = zipWith f l' l := by
/- Using the theorem that states the commutativity of `zipWith` for function swapping arguments, we can rewrite the goal. Specifically, since the function $f$ is commutative, we have:
\[ \text{zipWith } f \, l \, l' = \text{zipWith } (fun \, b \, a \, => \, f \, a \, b) \, l' \, l \]
Thus, it suffices to show that:
\[ \text{zipWith } (fun \, b \, a \, => \, f \, a \, b) \, l' \, l = \text{zipWith } f \, l' \, l \] -/
  rw [zipWith_comm]
/- Since the function $f$ is commutative, we can simplify the expression $\text{zipWith } (fun \, b \, a \, => \, f \, a \, b) \, l' \, l$ to $\text{zipWith } f \, l' \, l$. This is because for any $x, y \in \alpha$, we have $f(x, y) = f(y, x)$. Therefore, the goal is trivially satisfied. -/
  simp only [comm]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
26995,List.map_prod_left_eq_zip,"theorem List.map_prod_left_eq_zip {l : List α} (f : α → β) :
    (l.map fun x => (x, f x)) = l.zip (l.map f) := by sorry","Mapping Function with Left Pairing Equals Zipping with Original List: \(\text{map } (\lambda x. (x, f(x))) \, l = l \, \text{zip} \, (\text{map } f \, l)\) : For any list \( l \) of elements of type \( \alpha \) and any function \( f : \alpha \to \beta \), the list obtained by mapping the function \( \lambda x. (x, f(x)) \) over \( l \) is equal to the list obtained by zipping \( l \) with the list \( \text{map } f \, l \). Formally, for a list \( l = [a_1, a_2, \ldots, a_n] \), the result of \( \text{map } (\lambda x. (x, f(x))) \, l \) is the list \( [(a_1, f(a_1)), (a_2, f(a_2)), \ldots, (a_n, f(a_n))] \), which is equal to the list obtained by zipping \( [a_1, a_2, \ldots, a_n] \) with \( [f(a_1), f(a_2), \ldots, f(a_n)] \).","theorem List.map_prod_left_eq_zip {l : List α} (f : α → β) :
    (l.map fun x => (x, f x)) = l.zip (l.map f) := by
  rw [← zip_map']
  congr
  exact map_id _","To prove the theorem, we start by using the theorem that zipping the result of applying a function \( f \) to each element of a list \( l \) with the result of applying another function \( g \) to each element of \( l \) is the same as mapping the function that pairs \( f(a) \) and \( g(a) \) to each element \( a \) of \( l \). This allows us to rewrite the goal from \( \text{map } (\lambda x. (x, f(x))) \, l = l \, \text{zip} \, (\text{map } f \, l) \) to \( (\text{map } (\lambda x. x) \, l) \, \text{zip} \, (\text{map } f \, l) = l \, \text{zip} \, (\text{map } f \, l) \).

Next, to establish the equality \( (\text{map } (\lambda x. x) \, l) \, \text{zip} \, (\text{map } f \, l) = l \, \text{zip} \, (\text{map } f \, l) \), we decompose it into proving that \( \text{map } (\lambda x. x) \, l = l \).

Finally, the current goal \( \text{map } (\lambda x. x) \, l = l \) is exactly proved by the theorem that the identity function preserves the list, i.e., \( \text{map } (\text{id}) \, l = l \).

Thus, we have shown that \( \text{map } (\lambda x. (x, f(x))) \, l = l \, \text{zip} \, (\text{map } f \, l) \), completing the proof.","theorem List.map_prod_left_eq_zip {l : List α} (f : α → β) :
    (l.map fun x => (x, f x)) = l.zip (l.map f) := by
/- First, we use the theorem that zipping the result of applying a function \( f \) to each element of a list \( l \) with the result of applying another function \( g \) to each element of \( l \) is the same as mapping the function that pairs \( f(a) \) and \( g(a) \) to each element \( a \) of \( l \). This allows us to rewrite the goal from \( \text{map } (\lambda x. (x, f(x))) \, l = l \, \text{zip} \, (\text{map } f \, l) \) to \( (\text{map } (\lambda x. x) \, l) \, \text{zip} \, (\text{map } f \, l) = l \, \text{zip} \, (\text{map } f \, l) \). -/
  rw [← zip_map']
/- To establish the equality \( (\text{map } (\lambda x. x) \, l) \, \text{zip} \, (\text{map } f \, l) = l \, \text{zip} \, (\text{map } f \, l) \), we can decompose it into proving that \( \text{map } (\lambda x. x) \, l = l \). -/
  congr
/- The current goal \( \text{map } (\lambda x. x) \, l = l \) is exactly proved by the theorem that the identity function preserves the list, i.e., \( \text{map } (\text{id}) \, l = l \). -/
  exact map_id _","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
26998,List.map_prod_right_eq_zip,"theorem List.map_prod_right_eq_zip {l : List α} (f : α → β) :
    (l.map fun x => (f x, x)) = (l.map f).zip l := by sorry","Mapping Function with Right Pairing Equals Zipping with Original List: \(\text{map } (\lambda x. (f(x), x)) \, l = (\text{map } f \, l) \, \text{zip} \, l\) : For any lists \( l \) of elements of type \( \alpha \) and any function \( f : \alpha \to \beta \), the list obtained by mapping the function \( \lambda x. (f(x), x) \) over \( l \) is equal to the list obtained by zipping the list \( \text{map } f \, l \) with \( l \). Formally, for a list \( l = [a_1, a_2, \ldots, a_n] \), the result of \( \text{map } (\lambda x. (f(x), x)) \, l \) is the list \( [(f(a_1), a_1), (f(a_2), a_2), \ldots, (f(a_n), a_n)] \), which is equal to the list obtained by zipping \( [f(a_1), f(a_2), \ldots, f(a_n)] \) with \( [a_1, a_2, \ldots, a_n] \).","theorem List.map_prod_right_eq_zip {l : List α} (f : α → β) :
    (l.map fun x => (f x, x)) = (l.map f).zip l := by
  rw [← zip_map']
  congr
  exact map_id _","We start by using the theorem that zipping the result of applying \( f \) to each element of \( l \) with the result of applying the identity function to each element of \( l \) is the same as mapping the function that pairs \( f(a) \) and \( a \) to each element \( a \) of \( l \). This transforms our goal from showing \( \text{map } (\lambda x. (f(x), x)) \, l = (\text{map } f \, l) \text{.zip} \, l \) to showing \( (\text{map } f \, l) \text{.zip} (\text{map } (\lambda x. x) \, l) = (\text{map } f \, l) \text{.zip} \, l \).

To establish the equality \( (\text{map } f \, l) \text{.zip} (\text{map } (\lambda x. x) \, l) = (\text{map } f \, l) \text{.zip} \, l \), we decompose it to prove that \( \text{map } (\lambda x. x) \, l = l \).

The current goal \( \text{map } (\lambda x. x) \, l = l \) is exactly proved by the theorem that the identity function preserves the list, which states that applying the identity function to each element of \( l \) results in the same list \( l \).

Thus, we have shown that \( \text{map } (\lambda x. (f(x), x)) \, l = (\text{map } f \, l) \text{.zip} \, l \). This completes the proof.","theorem List.map_prod_right_eq_zip {l : List α} (f : α → β) :
    (l.map fun x => (f x, x)) = (l.map f).zip l := by
/- First, we use the theorem that zipping the result of applying \( f \) to each element of \( l \) with the result of applying the identity function to each element of \( l \) is the same as mapping the function that pairs \( f(a) \) and \( a \) to each element \( a \) of \( l \). This transforms our goal from showing \( \text{map } (\lambda x. (f(x), x)) \, l = (\text{map } f \, l) \text{.zip} \, l \) to showing \( (\text{map } f \, l) \text{.zip} (\text{map } (\lambda x. x) \, l) = (\text{map } f \, l) \text{.zip} \, l \). -/
  rw [← zip_map']
/- To establish the equality \( (\text{map } f \, l) \text{.zip} (\text{map } (\lambda x. x) \, l) = (\text{map } f \, l) \text{.zip} \, l \), we can decompose it to prove that \( \text{map } (\lambda x. x) \, l = l \). -/
  congr
/- The current goal \( \text{map } (\lambda x. x) \, l = l \) is exactly proved by the theorem that the identity function preserves the list, which states that applying the identity function to each element of \( l \) results in the same list \( l \). -/
  exact map_id _","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27002,List.head_zipWith,"theorem List.head_zipWith {f : α → β → γ} (h):
    (List.zipWith f as bs).head h = f (as.head (by rintro rfl; simp_all)) (bs.head (by rintro rfl; simp_all)) := by sorry","Head of Zipped List is Function Applied to Heads of Input Lists: \(\text{head}(\text{zipWith } f \, \text{as} \, \text{bs}) = f(\text{head}(\text{as}), \text{head}(\text{bs}))\) : For any types \( \alpha \), \( \beta \), and \( \gamma \), and for any lists \( \text{as} : \text{List } \alpha \) and \( \text{bs} : \text{List } \beta \), and for any function \( f : \alpha \to \beta \to \gamma \), if the list obtained by applying \( f \) to corresponding elements of \( \text{as} \) and \( \text{bs} \) (i.e., \( \text{zipWith } f \, \text{as} \, \text{bs} \)) is non-empty, then the head of this zipped list is equal to \( f \) applied to the heads of \( \text{as} \) and \( \text{bs} \). Formally, if \( h : \text{zipWith } f \, \text{as} \, \text{bs} \neq [] \), then:
\[ \text{head}(\text{zipWith } f \, \text{as} \, \text{bs}) = f(\text{head}(\text{as}), \text{head}(\text{bs})) \]","theorem List.head_zipWith {f : α → β → γ} (h):
    (List.zipWith f as bs).head h = f (as.head (by rintro rfl; simp_all)) (bs.head (by rintro rfl; simp_all)) := by
  apply Option.some.inj
  rw [← head?_eq_head, head?_zipWith, head?_eq_head, head?_eq_head]","To prove the theorem, we start by using the injectivity of the `some` constructor in the `Option` type. This means that to show:
\[ \text{head}(\text{zipWith } f \, \text{as} \, \text{bs}) = f(\text{head}(\text{as}), \text{head}(\text{bs})) \]
it suffices to show:
\[ \text{some}(\text{head}(\text{zipWith } f \, \text{as} \, \text{bs})) = \text{some}(f(\text{head}(\text{as}), \text{head}(\text{bs}))) \]

Next, we use the equivalence that the optional head of a non-empty list is `some` of the first element. Specifically, we have:
\[ \text{head?}(\text{zipWith } f \, \text{as} \, \text{bs}) = \text{some}(\text{head}(\text{zipWith } f \, \text{as} \, \text{bs})) \]

We also use the definition of the head of the zipped list:
\[ \text{head?}(\text{zipWith } f \, \text{as} \, \text{bs}) = \text{some}(f(\text{head?}(\text{as}), \text{head?}(\text{bs}))) \]

Finally, we use the fact that the optional head of a non-empty list is `some` of the first element for both `as` and `bs`:
\[ \text{head?}(\text{as}) = \text{some}(\text{head}(\text{as})) \]
\[ \text{head?}(\text{bs}) = \text{some}(\text{head}(\text{bs})) \]

Combining these, we get:
\[ \text{head?}(\text{zipWith } f \, \text{as} \, \text{bs}) = \text{some}(f(\text{head}(\text{as}), \text{head}(\text{bs}))) \]

Thus, the goal is satisfied, and the theorem is proved.","theorem List.head_zipWith {f : α → β → γ} (h):
    (List.zipWith f as bs).head h = f (as.head (by rintro rfl; simp_all)) (bs.head (by rintro rfl; simp_all)) := by
/- To prove the current goal, using the injectivity of the `some` constructor in the `Option` type, it suffices to show that the optional values `some ((zipWith f as bs).head h)` and `some (f (as.head ⋯) (bs.head ⋯))` are equal. -/
  apply Option.some.inj
/- We use the equivalence that the optional head of a non-empty list is `some` of the first element, and the definition of the head of the zipped list, to simplify the goal. Specifically, we have:
1. \(\text{head?}(\text{zipWith } f \, \text{as} \, \text{bs}) = \text{some}(\text{head}(\text{zipWith } f \, \text{as} \, \text{bs}))\)
2. \(\text{head?}(\text{zipWith } f \, \text{as} \, \text{bs}) = \text{some}(f(\text{head?}(\text{as}), \text{head?}(\text{bs})))\)
3. \(\text{head?}(\text{as}) = \text{some}(\text{head}(\text{as}))\)
4. \(\text{head?}(\text{bs}) = \text{some}(\text{head}(\text{bs}))\)

Combining these, we get:
\[
\text{head?}(\text{zipWith } f \, \text{as} \, \text{bs}) = \text{some}(f(\text{head}(\text{as}), \text{head}(\text{bs})))
\]
Thus, the goal is satisfied. -/
  rw [← head?_eq_head, head?_zipWith, head?_eq_head, head?_eq_head]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27003,List.zip_replicate',"theorem List.zip_replicate' {a : α} {b : β} {n : Nat} :
    zip (replicate n a) (replicate n b) = replicate n (a, b) := by sorry","Zipping Replicated Lists Equals Replicated Pairs: \(\text{zip} \, (\text{replicate } n \, a) \, (\text{replicate } n \, b) = \text{replicate } n \, (a, b)\) : For any types $\alpha$ and $\beta$, and any elements $a \in \alpha$ and $b \in \beta$, and any natural number $n$, the list obtained by zipping the list containing $n$ copies of $a$ with the list containing $n$ copies of $b$ is equal to the list containing $n$ copies of the pair $(a, b)$. Formally, for any $n \in \mathbb{N}$:
\[ \text{zip} \, (\text{replicate } n \, a) \, (\text{replicate } n \, b) = \text{replicate } n \, (a, b) \]","theorem List.zip_replicate' {a : α} {b : β} {n : Nat} :
    zip (replicate n a) (replicate n b) = replicate n (a, b) := by
  induction n with
  | zero => rfl
  | succ n ih => simp [replicate_succ, ih]","We prove this by induction on $n$.

**Base Case:**
For $n = 0$, the list containing $0$ copies of $a$ is the empty list, and the list containing $0$ copies of $b$ is also the empty list. Therefore, zipping these two empty lists results in the empty list, which is the same as the list containing $0$ copies of the pair $(a, b)$. This is trivially true due to the reflexive property of equality.

**Inductive Step:**
Assume that the statement holds for some natural number $k$, i.e.,
\[
(\text{replicate } k \, a).zip (\text{replicate } k \, b) = \text{replicate } k \, (a, b)
\]

We need to show that the statement holds for $k + 1$, i.e.,
\[
(\text{replicate } (k + 1) \, a).zip (\text{replicate } (k + 1) \, b) = \text{replicate } (k + 1) \, (a, b)
\]

Using the definition of `replicate`, we have:
\[
\text{replicate } (k + 1) \, a = a :: (\text{replicate } k \, a)
\]
and
\[
\text{replicate } (k + 1) \, b = b :: (\text{replicate } k \, b)
\]

By the definition of `zip`, we get:
\[
(\text{replicate } (k + 1) \, a).zip (\text{replicate } (k + 1) \, b) = (a, b) :: ((\text{replicate } k \, a).zip (\text{replicate } k \, b))
\]

By the inductive hypothesis, we know:
\[
(\text{replicate } k \, a).zip (\text{replicate } k \, b) = \text{replicate } k \, (a, b)
\]

Therefore, we have:
\[
(a, b) :: ((\text{replicate } k \, a).zip (\text{replicate } k \, b)) = (a, b) :: (\text{replicate } k \, (a, b))
\]

By the definition of `replicate`, this is equal to:
\[
\text{replicate } (k + 1) \, (a, b)
\]

Thus, the inductive step is proved. By the principle of mathematical induction, the statement holds for all natural numbers $n$. This completes the proof. $\blacksquare$","theorem List.zip_replicate' {a : α} {b : β} {n : Nat} :
    zip (replicate n a) (replicate n b) = replicate n (a, b) := by
  induction n with
/- First, consider the base case where $n = 0$. In this case, the list containing $0$ copies of $a$ is the empty list, and the list containing $0$ copies of $b$ is also the empty list. Therefore, zipping these two empty lists results in the empty list, which is the same as the list containing $0$ copies of the pair $(a, b)$. This is trivially true due to the reflexive property of equality. -/
  | zero => rfl
/- Next, consider the inductive step where $n = k + 1$ for some natural number $k$. Assume that the statement holds for $k$, i.e., \((\text{replicate } k \, a).zip (\text{replicate } k \, b) = \text{replicate } k \, (a, b)\). We need to show that \((\text{replicate } (k + 1) \, a).zip (\text{replicate } (k + 1) \, b) = \text{replicate } (k + 1) \, (a, b)\).

Using the definition of `replicate`, we know that:
\[
\text{replicate } (k + 1) \, a = a :: (\text{replicate } k \, a)
\]
and
\[
\text{replicate } (k + 1) \, b = b :: (\text{replicate } k \, b)
\]

By the definition of `zip`, we have:
\[
(\text{replicate } (k + 1) \, a).zip (\text{replicate } (k + 1) \, b) = (a, b) :: ((\text{replicate } k \, a).zip (\text{replicate } k \, b))
\]

By the inductive hypothesis, we know that:
\[
(\text{replicate } k \, a).zip (\text{replicate } k \, b) = \text{replicate } k \, (a, b)
\]

Therefore, we have:
\[
(a, b) :: ((\text{replicate } k \, a).zip (\text{replicate } k \, b)) = (a, b) :: (\text{replicate } k \, (a, b))
\]

By the definition of `replicate`, this is equal to:
\[
\text{replicate } (k + 1) \, (a, b)
\]

Thus, the inductive step is proved. -/
  | succ n ih => simp [replicate_succ, ih]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27004,List.unzip_replicate,"theorem List.unzip_replicate {n : Nat} {a : α} {b : β} :
    unzip (replicate n (a, b)) = (replicate n a, replicate n b) := by sorry","Unzipping a List of Replicated Pairs : For any types $\alpha$ and $\beta$, and for any natural number $n$, the list of pairs `replicate n (a, b)` unzipped into two lists is equal to the pair of lists `(replicate n a, replicate n b)`. Formally, if we have a list of $n$ pairs, each pair being $(a, b)$, then unzipping this list results in two lists: one containing $n$ copies of $a$ and the other containing $n$ copies of $b$.","theorem List.unzip_replicate {n : Nat} {a : α} {b : β} :
    unzip (replicate n (a, b)) = (replicate n a, replicate n b) := by
  ext1 <;> simp","To prove the theorem, we start by applying a single extensionality lemma to the current goal. This splits the goal into two subgoals: proving that the first components of the unzipped lists are equal and proving that the second components of the unzipped lists are equal.

1. **First Subgoal:**
- We need to show that the first component of the unzipped list of `replicate n (a, b)` is equal to `replicate n a`.
- Simplifying the proposition, we find that the first component of the unzipped list of `replicate n (a, b)` is indeed `replicate n a`.

2. **Second Subgoal:**
- We need to show that the second component of the unzipped list of `replicate n (a, b)` is equal to `replicate n b`.
- Simplifying the proposition, we find that the second component of the unzipped list of `replicate n (a, b)` is indeed `replicate n b`.

Since both subgoals are satisfied, we conclude that the unzipped list of `replicate n (a, b)` is equal to the pair of lists `(replicate n a, replicate n b)`. This completes the proof. $\blacksquare$","theorem List.unzip_replicate {n : Nat} {a : α} {b : β} :
    unzip (replicate n (a, b)) = (replicate n a, replicate n b) := by
/- First, we apply a single extensionality lemma to the current goal, which splits the goal into two subgoals: proving that the first components of the unzipped lists are equal and proving that the second components of the unzipped lists are equal. Then, for each of these subgoals, we simplify the proposition we want to show. -/
/- For the first subgoal, we simplify the proposition that the first components of the unzipped lists are equal. This simplification shows that the first component of the unzipped list of `replicate n (a, b)` is indeed `replicate n a`. -/
/- For the second subgoal, we simplify the proposition that the second components of the unzipped lists are equal. This simplification shows that the second component of the unzipped list of `replicate n (a, b)` is indeed `replicate n b`. -/
  ext1 <;> simp","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27009,List.zipWith_foldl_eq_zip_foldl,"theorem List.zipWith_foldl_eq_zip_foldl {f : α → β → γ} (i : δ):
    (zipWith f l₁ l₂).foldl g i = (zip l₁ l₂).foldl (fun r p => g r (f p.1 p.2)) i := by sorry","Left Fold of ZipWith Equals Left Fold of Zip with Function Applied: \( \text{foldl } g \, i \, (\text{zipWith } f \, l_1 \, l_2) = \text{foldl } (\lambda r \, (a, b) \, \Rightarrow g \, r \, (f \, a \, b)) \, i \, (\text{zip } l_1 \, l_2) \) : For any types \(\alpha\), \(\beta\), \(\gamma\), and \(\delta\), and any lists \(l_1 : \text{List } \alpha\) and \(l_2 : \text{List } \beta\), and any functions \(f : \alpha \to \beta \to \gamma\) and \(g : \delta \to \gamma \to \delta\), the left fold of \(g\) over the list produced by `zipWith f l₁ l₂` starting with an initial value \(i : \delta\) is equal to the left fold of \(g\) over the list produced by `zip l₁ l₂` where \(g\) is applied to the result of \(f\) on each pair of elements. Formally, this can be written as:
\[ \text{foldl } g \, i \, (\text{zipWith } f \, l_1 \, l_2) = \text{foldl } (\lambda r \, (a, b) \, \Rightarrow g \, r \, (f \, a \, b)) \, i \, (\text{zip } l_1 \, l_2) \]","theorem List.zipWith_foldl_eq_zip_foldl {f : α → β → γ} (i : δ):
    (zipWith f l₁ l₂).foldl g i = (zip l₁ l₂).foldl (fun r p => g r (f p.1 p.2)) i := by
  induction l₁ generalizing i l₂ <;> cases l₂ <;> simp_all","We will prove the theorem by induction on the list \( l_1 \) while generalizing over the initial value \( i \) and the list \( l_2 \).

**Base Case: \( l_1 = [] \)**
1. **Case 1: \( l_2 = [] \)**
- We need to show:
\[
\text{foldl } g \, i \, (\text{zipWith } f \, [] \, []) = \text{foldl } (\lambda r \, (a, b) \, \Rightarrow g \, r \, (f \, a \, b)) \, i \, (\text{zip } [] \, [])
\]
- By the definition of `zipWith` and `zip`, both sides are equal to \( i \) because the lists are empty.
- Therefore, the base case holds.

2. **Case 2: \( l_2 = \text{head} \, \text{::} \, \text{tail} \)**
- We need to show:
\[
\text{foldl } g \, i \, (\text{zipWith } f \, [] \, (\text{head} \, \text{::} \, \text{tail})) = \text{foldl } (\lambda r \, (a, b) \, \Rightarrow g \, r \, (f \, a \, b)) \, i \, (\text{zip } [] \, (\text{head} \, \text{::} \, \text{tail}))
\]
- By the definition of `zipWith` and `zip`, both sides are equal to \( i \) because the first list is empty.
- Therefore, the base case holds.

**Inductive Step: \( l_1 = \text{head} \, \text{::} \, \text{tail} \)**
1. **Case 1: \( l_2 = [] \)**
- We need to show:
\[
\text{foldl } g \, i \, (\text{zipWith } f \, (\text{head} \, \text{::} \, \text{tail}) \, []) = \text{foldl } (\lambda r \, (a, b) \, \Rightarrow g \, r \, (f \, a \, b)) \, i \, (\text{zip } (\text{head} \, \text{::} \, \text{tail}) \, [])
\]
- By the definition of `zipWith` and `zip`, both sides are equal to \( i \) because the second list is empty.
- Therefore, the inductive step holds.

2. **Case 2: \( l_2 = \text{head} \, \text{::} \, \text{tail} \)**
- We need to show:
\[
\text{foldl } g \, i \, (\text{zipWith } f \, (\text{head} \, \text{::} \, \text{tail}) \, (\text{head} \, \text{::} \, \text{tail})) = \text{foldl } (\lambda r \, (a, b) \, \Rightarrow g \, r \, (f \, a \, b)) \, i \, (\text{zip } (\text{head} \, \text{::} \, \text{tail}) \, (\text{head} \, \text{::} \, \text{tail}))
\]
- By the definition of `zipWith` and `zip`, the left-hand side is:
\[
\text{foldl } g \, i \, (f \, \text{head} \, \text{head} \, \text{::} \, \text{zipWith } f \, \text{tail} \, \text{tail})
\]
- The right-hand side is:
\[
\text{foldl } (\lambda r \, (a, b) \, \Rightarrow g \, r \, (f \, a \, b)) \, i \, ((\text{head}, \text{head}) \, \text{::} \, \text{zip } \text{tail} \, \text{tail})
\]
- By the inductive hypothesis, we have:
\[
\text{foldl } g \, i \, (\text{zipWith } f \, \text{tail} \, \text{tail}) = \text{foldl } (\lambda r \, (a, b) \, \Rightarrow g \, r \, (f \, a \, b)) \, i \, (\text{zip } \text{tail} \, \text{tail})
\]
- Therefore, the inductive step holds.

By induction, the theorem is proved. \(\blacksquare\)","theorem List.zipWith_foldl_eq_zip_foldl {f : α → β → γ} (i : δ):
    (zipWith f l₁ l₂).foldl g i = (zip l₁ l₂).foldl (fun r p => g r (f p.1 p.2)) i := by
/- We perform induction on the list \( l_1 \) while generalizing over the initial value \( i \) and the list \( l_2 \). For each case of \( l_1 \), we further perform case analysis on \( l_2 \). Then, we simplify the resulting goals using the properties of list operations and the definitions of `zipWith` and `zip`. -/
/- We will discuss every possible case of \( l_2 \). Case 1: \( l_2 \) is the empty list. Case 2: \( l_2 \) is a non-empty list, i.e., \( l_2 = \text{head} \, \text{::} \, \text{tail} \). -/
/- Using the properties of list operations and the definitions of `zipWith` and `zip`, we can simplify the proposition to show that the left fold of \( g \) over the list produced by `zipWith f l₁ l₂` starting with an initial value \( i \) is equal to the left fold of \( g \) over the list produced by `zip l₁ l₂` where \( g \) is applied to the result of \( f \) on each pair of elements. -/
  induction l₁ generalizing i l₂ <;> cases l₂ <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27010,List.zipWith_eq_nil_iff,theorem List.zipWith_eq_nil_iff {f : α → β → γ} {l l'} : zipWith f l l' = [] ↔ l = [] ∨ l' = [] := by sorry,"ZipWith Produces Empty List if and only if One Input List is Empty: \( \text{zipWith } f \, l \, l' = [] \leftrightarrow l = [] \lor l' = [] \) : For any types \( \alpha \), \( \beta \), and \( \gamma \), and any function \( f : \alpha \to \beta \to \gamma \), the result of `zipWith f l l'` is the empty list if and only if at least one of the lists \( l \) or \( l' \) is the empty list. In other words, \( \text{zipWith } f \, l \, l' = [] \) if and only if \( l = [] \) or \( l' = [] \).","theorem List.zipWith_eq_nil_iff {f : α → β → γ} {l l'} : zipWith f l l' = [] ↔ l = [] ∨ l' = [] := by
  cases l <;> cases l' <;> simp","We will consider every possible case for the lists \( l \) and \( l' \).

1. **Case 1: Both \( l \) and \( l' \) are empty lists.**
- The `zipWith` function applied to two empty lists results in an empty list.
- Therefore, \( \text{zipWith } f \, [] \, [] = [] \).
- This is equivalent to \( [] = [] \lor [] = [] \), which is true.

2. **Case 2: \( l \) is the empty list and \( l' \) is a non-empty list.**
- The `zipWith` function applied to an empty list and a non-empty list results in an empty list.
- Therefore, \( \text{zipWith } f \, [] \, (head \, \text{::} \, tail) = [] \).
- This is equivalent to \( [] = [] \lor (head \, \text{::} \, tail) = [] \), which is true.

3. **Case 3: \( l \) is a non-empty list and \( l' \) is the empty list.**
- The `zipWith` function applied to a non-empty list and an empty list results in an empty list.
- Therefore, \( \text{zipWith } f \, (head \, \text{::} \, tail) \, [] = [] \).
- This is equivalent to \( (head \, \text{::} \, tail) = [] \lor [] = [] \), which is true.

4. **Case 4: Both \( l \) and \( l' \) are non-empty lists.**
- The `zipWith` function applied to two non-empty lists results in a non-empty list.
- Therefore, \( \text{zipWith } f \, (head_1 \, \text{::} \, tail_1) \, (head_2 \, \text{::} \, tail_2) \neq [] \).
- This is equivalent to \( (head_1 \, \text{::} \, tail_1) = [] \lor (head_2 \, \text{::} \, tail_2) = [] \), which is false.

In all cases, the result of `zipWith f l l'` is the empty list if and only if at least one of the lists \( l \) or \( l' \) is the empty list. This completes the proof. \(\blacksquare\)","theorem List.zipWith_eq_nil_iff {f : α → β → γ} {l l'} : zipWith f l l' = [] ↔ l = [] ∨ l' = [] := by
/- We will consider every possible case for the lists \( l \) and \( l' \). Specifically, we will consider the cases where \( l \) and \( l' \) are either empty or non-empty. For each case, we will simplify the goal using the properties of the `zipWith` function and the disjunction of propositions. -/
/- We will discuss every possible case of \( l \). Case 1: \( l \) is the empty list. Case 2: \( l \) is a non-empty list, i.e., \( l = \text{head} \, \text{::} \, \text{tail} \). -/
/- We will discuss every possible case of \( l' \). Case 1: \( l' \) is the empty list. Case 2: \( l' \) is a non-empty list, i.e., \( l' = \text{head} \, \text{::} \, \text{tail} \). -/
/- Using the properties of the `zipWith` function and the disjunction of propositions, we simplify the goal for the case where both \( l \) and \( l' \) are empty lists. The result is trivially true because the empty list is the only list that can be zipped with another empty list to produce an empty list. -/
/- Using the properties of the `zipWith` function and the disjunction of propositions, we simplify the goal for the case where \( l \) is the empty list and \( l' \) is a non-empty list. The result is trivially true because the empty list zipped with any non-empty list results in an empty list, which is equivalent to the disjunction \( l = [] \lor l' = [] \). -/
/- Using the properties of the `zipWith` function and the disjunction of propositions, we simplify the goal for the case where \( l \) is a non-empty list and \( l' \) is the empty list. The result is trivially true because a non-empty list zipped with the empty list results in an empty list, which is equivalent to the disjunction \( l = [] \lor l' = [] \). -/
/- Using the properties of the `zipWith` function and the disjunction of propositions, we simplify the goal for the case where both \( l \) and \( l' \) are non-empty lists. The result is trivially false because a non-empty list zipped with another non-empty list cannot produce an empty list, which is equivalent to the disjunction \( l = [] \lor l' = [] \). -/
  cases l <;> cases l' <;> simp","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27011,List.getElem?_zipWith,"theorem List.getElem?_zipWith {f : α → β → γ} {i : Nat} :
    (List.zipWith f as bs)[i]? = match as[i]?, bs[i]? with
      | some a, some b => some (f a b) | _, _ => none := by sorry","Element Retrieval in `zipWith` Lists: Optional Result Based on Index Validity : For any types \(\alpha\), \(\beta\), and \(\gamma\), given two lists \(as : \text{List } \alpha\) and \(bs : \text{List } \beta\), a function \(f : \alpha \to \beta \to \gamma\), and a natural number \(i\), the element at index \(i\) in the list resulting from `zipWith f as bs` is obtained as follows:
\[
(\text{zipWith } f \, as \, bs)[i]? =
\begin{cases}
\text{some } (f \, a \, b) & \text{if } as[i]? = \text{some } a \text{ and } bs[i]? = \text{some } b \\
\text{none} & \text{otherwise}
\end{cases}
\]","theorem List.getElem?_zipWith {f : α → β → γ} {i : Nat} :
    (List.zipWith f as bs)[i]? = match as[i]?, bs[i]? with
      | some a, some b => some (f a b) | _, _ => none := by
  induction as generalizing bs i with
  | nil => cases bs with
    | nil => simp
    | cons b bs => simp
  | cons a as aih => cases bs with
    | nil => simp
    | cons b bs => cases i <;> simp_all","We will prove the theorem by induction on the structure of the lists `as` and `bs`.

1. **Case 1: \(bs = []\)**

- **Subcase 1.1: \(as = []\)**

If both `as` and `bs` are empty, then the result of `zipWith f as bs` is an empty list. For any index \(i\), the element at index \(i\) in an empty list is `none`. Therefore, \((\text{zipWith } f \, [] \, [])[i]? = \text{none}\).

- **Subcase 1.2: \(as = a :: as'\)**

If `as` is non-empty and `bs` is empty, then the result of `zipWith f as bs` is an empty list. For any index \(i\), the element at index \(i\) in an empty list is `none`. Therefore, \((\text{zipWith } f \, (a :: as') \, [])[i]? = \text{none}\).

2. **Case 2: \(bs = b :: bs'\)**

- **Subcase 2.1: \(as = []\)**

If `as` is empty and `bs` is non-empty, then the result of `zipWith f as bs` is an empty list. For any index \(i\), the element at index \(i\) in an empty list is `none`. Therefore, \((\text{zipWith } f \, [] \, (b :: bs'))[i]? = \text{none}\).

- **Subcase 2.2: \(as = a :: as'\)**

If both `as` and `bs` are non-empty, we perform case analysis on the index \(i\):

- **Subcase 2.2.1: \(i = 0\)**

If \(i = 0\), then the element at index \(0\) in the result of `zipWith f as bs` is \(f(a, b)\). Therefore, \((\text{zipWith } f \, (a :: as') \, (b :: bs'))[0]? = \text{some } (f(a, b))\).

- **Subcase 2.2.2: \(i = n + 1\)**

If \(i = n + 1\), then the element at index \(i\) in the result of `zipWith f as bs` is the element at index \(n\) in the result of `zipWith f as' bs'`. By the induction hypothesis, \((\text{zipWith } f \, as' \, bs')[n]? = \text{some } (f(a', b'))\) if \(as'[n]? = \text{some } a'\) and \(bs'[n]? = \text{some } b'\), and \(\text{none}\) otherwise. Therefore, \((\text{zipWith } f \, (a :: as') \, (b :: bs'))[n + 1]? = \text{some } (f(a', b'))\) if \(as'[n]? = \text{some } a'\) and \(bs'[n]? = \text{some } b'\), and \(\text{none}\) otherwise.

This completes the proof.","theorem List.getElem?_zipWith {f : α → β → γ} {i : Nat} :
    (List.zipWith f as bs)[i]? = match as[i]?, bs[i]? with
      | some a, some b => some (f a b) | _, _ => none := by
  induction as generalizing bs i with
/- We consider the case where the list `bs` is empty, i.e., `bs = []`. We then perform case analysis on the list `bs`. -/
  | nil => cases bs with
/- In the case where both lists `as` and `bs` are empty, we simplify the goal using the properties of list element retrieval and the definition of `zipWith`. This simplification shows that the element at index `i` in the result of `zipWith f as bs` is `none` if either `as[i]?` or `bs[i]?` is `none`. -/
    | nil => simp
/- In the case where `bs` is non-empty, we simplify the goal using the properties of list element retrieval and the definition of `zipWith`. This simplification shows that the element at index `i` in the result of `zipWith f as bs` is `none` if `as[i]?` is `none`. -/
    | cons b bs => simp
/- We consider the case where the list `as` is non-empty, i.e., `as = a :: as`. We then perform case analysis on the list `bs`. -/
  | cons a as aih => cases bs with
/- In the case where `as` is non-empty and `bs` is empty, we simplify the goal using the properties of list element retrieval and the definition of `zipWith`. This simplification shows that the element at index `i` in the result of `zipWith f as bs` is `none` if `bs[i]?` is `none`. -/
    | nil => simp
/- We consider the case where the list `bs` is non-empty, i.e., `bs = b :: bs`. We then perform case analysis on the index `i`. For each case, we simplify the goal using the properties of list element retrieval and the definition of `zipWith`. -/
/- In the case where both `as` and `bs` are non-empty, we perform case analysis on the index `i`. For each case, we simplify the goal using the properties of list element retrieval and the definition of `zipWith`. This simplification shows that the element at index `i` in the result of `zipWith f as bs` is `some (f a b)` if both `as[i]?` and `bs[i]?` are `some a` and `some b`, respectively, and `none` otherwise. -/
    | cons b bs => cases i <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27013,List.unzip_snd,theorem List.unzip_snd : (unzip l).snd = l.map Prod.snd := by sorry,"Second Component of Unzipped List Equals Map of Second Components: \( l.\text{unzip}.2 = \text{map}(\text{snd}, l) \) : For any types \(\alpha\) and \(\beta\), and for any list \(l\) of pairs \((a, b)\) where \(a \in \alpha\) and \(b \in \beta\), the second component of the pair returned by the function `unzip` applied to \(l\) is equal to the list obtained by applying the function `Prod.snd` to each pair in \(l\). Formally, for a list of pairs \([(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)]\), the function `unzip` returns the pair of lists \([x_1, x_2, \ldots, x_n]\) and \([y_1, y_2, \ldots, y_n]\). The theorem states that the second list in this pair is equal to the list \([y_1, y_2, \ldots, y_n]\).","theorem List.unzip_snd : (unzip l).snd = l.map Prod.snd := by
  induction l <;> simp_all","We perform induction on the list \( l \).

1. **Base Case:**
- Consider the empty list \( l = [] \).
- The function `unzip` applied to the empty list returns the pair \(([], [])\).
- The second component of this pair is the empty list \( [] \).
- The list obtained by applying `Prod.snd` to the empty list is also \( [] \).
- Therefore, the second component of the pair returned by `unzip` applied to the empty list is equal to the list obtained by applying `Prod.snd` to the empty list.

2. **Inductive Step:**
- Assume the property holds for a list \( \text{tail} \), i.e., \(\text{tail}.unzip.snd = \text{map}(\text{Prod.snd}, \text{tail})\).
- Consider a non-empty list \( l = \text{head} :: \text{tail} \), where \(\text{head} = (a, b)\).
- The function `unzip` applied to \( \text{head} :: \text{tail} \) returns the pair \((\text{map}(\text{Prod.fst}, \text{head} :: \text{tail}), \text{map}(\text{Prod.snd}, \text{head} :: \text{tail}))\).
- The second component of this pair is \(\text{map}(\text{Prod.snd}, \text{head} :: \text{tail})\).
- By the definition of `map`, \(\text{map}(\text{Prod.snd}, \text{head} :: \text{tail}) = \text{Prod.snd}(\text{head}) :: \text{map}(\text{Prod.snd}, \text{tail})\).
- By the inductive hypothesis, \(\text{map}(\text{Prod.snd}, \text{tail}) = \text{tail}.unzip.snd\).
- Therefore, \(\text{map}(\text{Prod.snd}, \text{head} :: \text{tail}) = b :: \text{tail}.unzip.snd\).
- This is exactly the list obtained by applying `Prod.snd` to each pair in \( \text{head} :: \text{tail} \).

By induction, the theorem holds for all lists \( l \). This completes the proof. \(\blacksquare\)","theorem List.unzip_snd : (unzip l).snd = l.map Prod.snd := by
/- We perform induction on the list \( l \). This breaks down the proof into two cases: the base case where \( l \) is the empty list, and the inductive step where \( l \) is a non-empty list. -/
/- We perform induction on the list \( l \). For the base case, we need to show that the second component of the pair returned by `unzip` applied to the empty list is equal to the list obtained by applying `Prod.snd` to the empty list. For the inductive step, we assume that the property holds for a list \( \text{tail} \) and show that it also holds for a list \( \text{head} :: \text{tail} \). -/
/- First, we apply the induction tactic to the current goal, which generates two subgoals: one for the base case and one for the inductive step. Then, for each of these subgoals, we apply the `simp_all` tactic to simplify the propositions and hypotheses. -/
/- Using the properties of `unzip` and `map`, we can simplify the proposition to show that the second component of the pair returned by `unzip` applied to the empty list is indeed the empty list. This is trivially true. -/
/- Using the properties of `unzip` and `map`, we can simplify the proposition to show that the second component of the pair returned by `unzip` applied to a non-empty list \( \text{head} :: \text{tail} \) is equal to the list obtained by applying `Prod.snd` to each pair in \( \text{head} :: \text{tail} \). This is true by the inductive hypothesis and the definition of `unzip` and `map`. -/
  induction l <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27014,List.tail_zipWith,theorem List.tail_zipWith : (zipWith f l l').tail = zipWith f l.tail l'.tail := by sorry,"Tail of `zipWith` is `zipWith` of Tails : For any types $\alpha$, $\alpha_1$, and $\alpha_2$, and for any function $f : \alpha \to \alpha_1 \to \alpha_2$, and any lists $l : \text{List} \, \alpha$ and $l' : \text{List} \, \alpha_1$, the tail of the list obtained by applying `zipWith` to $l$ and $l'$ is equal to the list obtained by applying `zipWith` to the tails of $l$ and $l'$.","theorem List.tail_zipWith : (zipWith f l l').tail = zipWith f l.tail l'.tail := by
  rw [← drop_one]; simp [drop_zipWith]","To prove the theorem, we start by using the equivalence that the tail of a list is the same as dropping the first element of the list. This changes our goal from showing that the tail of $\text{zipWith} \, f \, l \, l'$ is equal to $\text{zipWith} \, f \, l.\text{tail} \, l'.\text{tail}$ to showing that dropping the first element of $\text{zipWith} \, f \, l \, l'$ is equal to $\text{zipWith} \, f \, (\text{drop} \, 1 \, l) \, (\text{drop} \, 1 \, l')$. We then simplify the goal using the property that dropping the first element of the result of `zipWith` is the same as applying `zipWith` to the lists with their first elements dropped. This completes the proof.","theorem List.tail_zipWith : (zipWith f l l').tail = zipWith f l.tail l'.tail := by
/- First, we use the equivalence that the tail of a list is the same as dropping the first element of the list. This changes our goal from showing that the tail of $\text{zipWith} \, f \, l \, l'$ is equal to $\text{zipWith} \, f \, l.\text{tail} \, l'.\text{tail}$ to showing that dropping the first element of $\text{zipWith} \, f \, l \, l'$ is equal to $\text{zipWith} \, f \, (\text{drop} \, 1 \, l) \, (\text{drop} \, 1 \, l')$. We then simplify the goal using the property that dropping the first element of the result of `zipWith` is the same as applying `zipWith` to the lists with their first elements dropped. This completes the proof. -/
  rw [← drop_one]; simp [drop_zipWith]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27015,List.unzip_fst,theorem List.unzip_fst : (unzip l).fst = l.map Prod.fst := by sorry,"First Component of Unzipped List Equals Map of First Components: \( l.\text{unzip}.1 = \text{map}(\text{fst}, l) \) : For any lists of pairs \( l \) with elements of types \( \alpha \) and \( \beta \), the first component of the result of `unzip` applied to \( l \) is equal to the result of applying `map` to \( l \) with the function `Prod.fst`. Formally, for a list of pairs \( l = [(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)] \), the first component of `unzip l` is the list \( [x_1, x_2, \ldots, x_n] \), which is the same as the list obtained by applying `map` to \( l \) with the function that extracts the first component of each pair.","theorem List.unzip_fst : (unzip l).fst = l.map Prod.fst := by
  induction l <;> simp_all","We perform induction on the list \( l \).

**Base Case:**
For the empty list \( l = [] \), we need to show that the first component of the result of `unzip` applied to the empty list is equal to the result of applying `map` to the empty list with the function `Prod.fst`. Formally, we need to show:
\[
[].\text{unzip}.1 = \text{map}(\text{fst}, [])
\]
By the definition of `unzip` and `map`, both sides are the empty list:
\[
[].\text{unzip}.1 = [] \quad \text{and} \quad \text{map}(\text{fst}, []) = []
\]
Thus, the base case holds.

**Inductive Step:**
Assume that for a list \( \text{tail} \) of pairs, the first component of the result of `unzip` applied to \( \text{tail} \) is equal to the result of applying `map` to \( \text{tail} \) with the function `Prod.fst`. Formally, we assume:
\[
\text{tail}.\text{unzip}.1 = \text{map}(\text{fst}, \text{tail})
\]
We need to show that for a list \( l = \text{head} :: \text{tail} \), the first component of the result of `unzip` applied to \( l \) is equal to the result of applying `map` to \( l \) with the function `Prod.fst`. Formally, we need to show:
\[
(\text{head} :: \text{tail}).\text{unzip}.1 = \text{map}(\text{fst}, \text{head} :: \text{tail})
\]
By the definition of `unzip`, the first component of the result of `unzip` applied to \( \text{head} :: \text{tail} \) is:
\[
(\text{head} :: \text{tail}).\text{unzip}.1 = \text{head}.1 :: \text{tail}.\text{unzip}.1
\]
By the inductive hypothesis, we have:
\[
\text{tail}.\text{unzip}.1 = \text{map}(\text{fst}, \text{tail})
\]
Thus:
\[
(\text{head} :: \text{tail}).\text{unzip}.1 = \text{head}.1 :: \text{map}(\text{fst}, \text{tail})
\]
By the definition of `map`, the result of applying `map` to \( \text{head} :: \text{tail} \) with the function `Prod.fst` is:
\[
\text{map}(\text{fst}, \text{head} :: \text{tail}) = \text{head}.1 :: \text{map}(\text{fst}, \text{tail})
\]
Therefore:
\[
(\text{head} :: \text{tail}).\text{unzip}.1 = \text{map}(\text{fst}, \text{head} :: \text{tail})
\]
This completes the inductive step.

By induction, the theorem holds for all lists \( l \). Thus, the first component of the result of `unzip` applied to \( l \) is equal to the result of applying `map` to \( l \) with the function `Prod.fst`. This completes the proof. \(\blacksquare\)","theorem List.unzip_fst : (unzip l).fst = l.map Prod.fst := by
/- We perform induction on the list \( l \) to break down the proof into cases. For the base case, we need to show that the first component of the result of `unzip` applied to the empty list is equal to the result of applying `map` to the empty list with the function `Prod.fst`. For the inductive step, we assume that the first component of the result of `unzip` applied to the tail of the list is equal to the result of applying `map` to the tail of the list with the function `Prod.fst`, and we need to show that the first component of the result of `unzip` applied to the list with a new head is equal to the result of applying `map` to the list with the new head. We then simplify the expressions in both cases to complete the proof. -/
  induction l <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27016,List.getElem?_zip_eq_some,"theorem List.getElem?_zip_eq_some (l₁ : List α) (l₂ : List β) (z : α × β) (i : Nat) :
    (zip l₁ l₂)[i]? = some z ↔ l₁[i]? = some z.1 ∧ l₂[i]? = some z.2 := by sorry","Element at Index in Zipped List is `some` if and only if Corresponding Elements are `some`: \((l_1 \text{ zip } l_2)[i]? = \text{some } z \leftrightarrow l_1[i]? = \text{some } z.1 \, \land \, l_2[i]? = \text{some } z.2\) : For any types \( \alpha \) and \( \beta \), and for any lists \( l_1 : \text{List } \alpha \) and \( l_2 : \text{List } \beta \), and for any pair \( z : \alpha \times \beta \), and for any natural number \( i \), the following holds:
\[
(l_1 \text{ zip } l_2)[i]? = \text{some } z \quad \text{if and only if} \quad l_1[i]? = \text{some } z.1 \, \land \, l_2[i]? = \text{some } z.2
\]
This means that the optional element at index \( i \) in the list obtained by zipping \( l_1 \) and \( l_2 \) is `some z` if and only if the optional elements at index \( i \) in \( l_1 \) and \( l_2 \) are `some z.1` and `some z.2`, respectively.","theorem List.getElem?_zip_eq_some (l₁ : List α) (l₂ : List β) (z : α × β) (i : Nat) :
    (zip l₁ l₂)[i]? = some z ↔ l₁[i]? = some z.1 ∧ l₂[i]? = some z.2 := by
  cases z
  rw [zip, getElem?_zipWith_eq_some]; constructor
  · rintro ⟨x, y, h₀, h₁, h₂⟩
    simpa [h₀, h₁] using h₂
  · rintro ⟨h₀, h₁⟩
    exact ⟨_, _, h₀, h₁, rfl⟩","We start by considering every possible case of the pair \( z \). Let \( z = (a, b) \) where \( a \in \alpha \) and \( b \in \beta \).

Using the definition of the `zip` function and the theorem that the optional element at index \( i \) in the `zipWith` list is `some z` if and only if the corresponding elements in the original lists are `some x` and `some y` and the function applied to them equals \( z \), we can rewrite the goal. This reduces our goal to proving:
\[
(\exists x y, l_1[i]? = \text{some } x \land l_2[i]? = \text{some } y \land (x, y) = (a, b)) \leftrightarrow l_1[i]? = \text{some } a \land l_2[i]? = \text{some } b
\]

We will prove this equivalence by constructing both directions of the implication.

1. **(\(\rightarrow\))**:
Let \( x \in \alpha \) and \( y \in \beta \) be such that \( l_1[i]? = \text{some } x \), \( l_2[i]? = \text{some } y \), and \( (x, y) = (a, b) \). We need to show that \( l_1[i]? = \text{some } a \) and \( l_2[i]? = \text{some } b \).

Using the hypotheses \( l_1[i]? = \text{some } x \) and \( l_2[i]? = \text{some } y \), and the fact that \( (x, y) = (a, b) \), we have \( x = a \) and \( y = b \). Therefore, \( l_1[i]? = \text{some } a \) and \( l_2[i]? = \text{some } b \) hold.

2. **(\(\leftarrow\))**:
Let \( l_1[i]? = \text{some } a \) and \( l_2[i]? = \text{some } b \). We need to show that there exist \( x \) and \( y \) such that \( l_1[i]? = \text{some } x \), \( l_2[i]? = \text{some } y \), and \( (x, y) = (a, b) \).

We can take \( x = a \) and \( y = b \). By the hypotheses \( l_1[i]? = \text{some } a \) and \( l_2[i]? = \text{some } b \), and the fact that \( (a, b) = (a, b) \) by reflexivity, the goal is exactly proved.

Thus, we have shown both directions of the equivalence, completing the proof. \(\blacksquare\)","theorem List.getElem?_zip_eq_some (l₁ : List α) (l₂ : List β) (z : α × β) (i : Nat) :
    (zip l₁ l₂)[i]? = some z ↔ l₁[i]? = some z.1 ∧ l₂[i]? = some z.2 := by
/- We will consider every possible case of the pair \( z \). Let \( z = (a, b) \) where \( a \in \alpha \) and \( b \in \beta \). -/
  cases z
/- Using the definition of the `zip` function and the theorem that the optional element at index \( i \) in the `zipWith` list is `some z` if and only if the corresponding elements in the original lists are `some x` and `some y` and the function applied to them equals \( z \), we can rewrite the goal. This reduces our goal to proving:
\[
(\exists x y, l_1[i]? = \text{some } x \land l_2[i]? = \text{some } y \land (x, y) = (a, b)) \leftrightarrow l_1[i]? = \text{some } a \land l_2[i]? = \text{some } b
\]
We will prove this equivalence by constructing both directions of the implication. -/
  rw [zip, getElem?_zipWith_eq_some]; constructor
/- Let \( x \in \alpha \) and \( y \in \beta \) be such that \( l_1[i]? = \text{some } x \), \( l_2[i]? = \text{some } y \), and \( (x, y) = (a, b) \). We need to show that \( l_1[i]? = \text{some } a \) and \( l_2[i]? = \text{some } b \). -/
  · rintro ⟨x, y, h₀, h₁, h₂⟩
/- Using the hypotheses \( h_0 \) and \( h_1 \), we can simplify the goal to show that \( l_1[i]? = \text{some } a \) and \( l_2[i]? = \text{some } b \). Since \( (x, y) = (a, b) \) by \( h_2 \), we have \( x = a \) and \( y = b \). Therefore, \( l_1[i]? = \text{some } a \) and \( l_2[i]? = \text{some } b \) hold, completing this direction of the proof. -/
    simpa [h₀, h₁] using h₂
/- Let \( h_0 \) be the hypothesis that \( l_1[i]? = \text{some } a \) and \( h_1 \) be the hypothesis that \( l_2[i]? = \text{some } b \). We need to show that there exist \( x \) and \( y \) such that \( l_1[i]? = \text{some } x \), \( l_2[i]? = \text{some } y \), and \( (x, y) = (a, b) \). -/
  · rintro ⟨h₀, h₁⟩
/- We can take \( x = a \) and \( y = b \). By the hypotheses \( h_0 \) and \( h_1 \), we have \( l_1[i]? = \text{some } a \) and \( l_2[i]? = \text{some } b \). Since \( (a, b) = (a, b) \) by reflexivity, the goal is exactly proved. -/
    exact ⟨_, _, h₀, h₁, rfl⟩","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27017,List.zipWithAll_map_left,"theorem List.zipWithAll_map_left (l₁ : List α) (l₂ : List β) (f : α → α') (g : Option α' → Option β → γ) :
    zipWithAll g (l₁.map f) l₂ = zipWithAll (fun a b => g (f <$> a) b) l₁ l₂ := by sorry","Left Mapping Preserves `zipWithAll` Operation in Lists : For any lists \( l_1 \) and \( l_2 \) of types \( \alpha \) and \( \beta \) respectively, and a function \( f : \alpha \to \alpha' \), and a function \( g : \text{Option} \, \alpha' \to \text{Option} \, \beta \to \gamma \), the following holds:
\[
\text{zipWithAll} \, g \, (\text{map} \, f \, l_1) \, l_2 = \text{zipWithAll} \, (\lambda a \, b, \, g \, (f \, a) \, b) \, l_1 \, l_2
\]
In other words, applying the function \( f \) to each element of \( l_1 \) and then zipping the result with \( l_2 \) using \( g \) is the same as zipping \( l_1 \) and \( l_2 \) using a modified version of \( g \) that applies \( f \) to the elements of \( l_1 \) before zipping.","theorem List.zipWithAll_map_left (l₁ : List α) (l₂ : List β) (f : α → α') (g : Option α' → Option β → γ) :
    zipWithAll g (l₁.map f) l₂ = zipWithAll (fun a b => g (f <$> a) b) l₁ l₂ := by
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","We perform induction on the list \( l_1 \) while generalizing over \( l_2 \).

**Base Case:**
1. **\( l_1 \) is the empty list:**
- **Sub-case 1: \( l_2 \) is the empty list:**
\[
\text{zipWithAll} \, g \, (\text{map} \, f \, []) \, [] = \text{zipWithAll} \, (\lambda a \, b, \, g \, (f \, a) \, b) \, [] \, []
\]
Both sides are trivially equal to the empty list.
- **Sub-case 2: \( l_2 \) is a non-empty list \( [b_1, b_2, \ldots, b_n] \):**
\[
\text{zipWithAll} \, g \, (\text{map} \, f \, []) \, [b_1, b_2, \ldots, b_n] = \text{zipWithAll} \, (\lambda a \, b, \, g \, (f \, a) \, b) \, [] \, [b_1, b_2, \ldots, b_n]
\]
Both sides are trivially equal to the list of results of applying \( g \) to `None` and each element of \( l_2 \).

**Inductive Step:**
2. **\( l_1 \) is a non-empty list \( [a_1, a_2, \ldots, a_m] \):**
- **Sub-case 1: \( l_2 \) is the empty list:**
\[
\text{zipWithAll} \, g \, (\text{map} \, f \, [a_1, a_2, \ldots, a_m]) \, [] = \text{zipWithAll} \, (\lambda a \, b, \, g \, (f \, a) \, b) \, [a_1, a_2, \ldots, a_m] \, []
\]
Both sides are trivially equal to the empty list.
- **Sub-case 2: \( l_2 \) is a non-empty list \( [b_1, b_2, \ldots, b_n] \):**
\[
\text{zipWithAll} \, g \, (\text{map} \, f \, [a_1, a_2, \ldots, a_m]) \, [b_1, b_2, \ldots, b_n] = \text{zipWithAll} \, (\lambda a \, b, \, g \, (f \, a) \, b) \, [a_1, a_2, \ldots, a_m] \, [b_1, b_2, \ldots, b_n]
\]
By the inductive hypothesis, we know that:
\[
\text{zipWithAll} \, g \, (\text{map} \, f \, [a_2, \ldots, a_m]) \, [b_2, \ldots, b_n] = \text{zipWithAll} \, (\lambda a \, b, \, g \, (f \, a) \, b) \, [a_2, \ldots, a_m] \, [b_2, \ldots, b_n]
\]
Therefore, the left-hand side and the right-hand side are equal by the definition of `zipWithAll` and the inductive hypothesis.

In all cases, the equality holds, thus completing the proof.","theorem List.zipWithAll_map_left (l₁ : List α) (l₂ : List β) (f : α → α') (g : Option α' → Option β → γ) :
    zipWithAll g (l₁.map f) l₂ = zipWithAll (fun a b => g (f <$> a) b) l₁ l₂ := by
/- We perform induction on the list \( l_1 \) while generalizing over \( l_2 \). For each case of \( l_1 \), we further perform case analysis on \( l_2 \). Then, we simplify the resulting goals using the simplification lemmas. -/
/- We perform induction on the list \( l_1 \) while generalizing over \( l_2 \). This means we consider two cases: the base case where \( l_1 \) is the empty list, and the inductive step where \( l_1 \) is a non-empty list. -/
/- For the base case of \( l_1 \) being the empty list, we perform case analysis on \( l_2 \). This means we consider two sub-cases: \( l_2 \) is the empty list and \( l_2 \) is a non-empty list. -/
/- For the inductive step of \( l_1 \) being a non-empty list, we perform case analysis on \( l_2 \). This means we consider two sub-cases: \( l_2 \) is the empty list and \( l_2 \) is a non-empty list. -/
/- We simplify the resulting goals using the simplification lemmas. This involves applying the transitivity and symmetry of equality, the identity function, and universal quantification congruence to reduce the goals to trivially true statements. -/
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27018,List.head_zipWithAll,"theorem List.head_zipWithAll {f : Option α → Option β → γ} (h) :
    (zipWithAll f as bs).head h = f as.head? bs.head? := by sorry","First Element of ZipWithAll Equals Function Applied to Optional Heads of Lists : For any types \( \alpha \), \( \beta \), and \( \gamma \), and any lists \( as : \text{List} \, \alpha \) and \( bs : \text{List} \, \beta \), and any function \( f : \text{Option} \, \alpha \to \text{Option} \, \beta \to \gamma \), if the list \( \text{zipWithAll} \, f \, as \, bs \) is non-empty, then the first element of \( \text{zipWithAll} \, f \, as \, bs \) is equal to \( f \, (\text{head?} \, as) \, (\text{head?} \, bs) \). In other words, if \( \text{zipWithAll} \, f \, as \, bs \neq [] \), then:
\[
(\text{zipWithAll} \, f \, as \, bs). \text{head} \, h = f \, (\text{head?} \, as) \, (\text{head?} \, bs)
\]
where \( h \) is a proof that \( \text{zipWithAll} \, f \, as \, bs \) is non-empty.","theorem List.head_zipWithAll {f : Option α → Option β → γ} (h) :
    (zipWithAll f as bs).head h = f as.head? bs.head? := by
  apply Option.some.inj
  rw [← head?_eq_head, head?_zipWithAll]
  split <;> simp_all","To prove the theorem, we start by using the injectivity of the `some` constructor in the `Option` type. This means that to show:
\[
(\text{zipWithAll} \, f \, as \, bs). \text{head} \, h = f \, (\text{head?} \, as) \, (\text{head?} \, bs)
\]
it suffices to show:
\[
\text{some}((\text{zipWithAll} \, f \, as \, bs). \text{head} \, h) = \text{some}(f \, (\text{head?} \, as) \, (\text{head?} \, bs))
\]

Next, we use the equivalence that the optional head of a non-empty list is `some` of the first element, and the definition of the first element of `zipWithAll`. This allows us to rewrite the goal to:
\[
\text{match } \text{head?} \, as, \text{head?} \, bs \text{ with} \\
\text{| none, none => none} \\
\text{| some } a, \text{ some } b => \text{ some } (f (\text{some } a) (\text{some } b))
\]
is equal to:
\[
\text{some} (f \, (\text{head?} \, as) \, (\text{head?} \, bs))
\]

We then discuss by cases based on the values of `head? as` and `head? bs`:
1. **Case 1:** If both `head? as` and `head? bs` are `none`, then the goal is:
\[
\text{none} = \text{some} (f \, \text{none} \, \text{none})
\]
This is a contradiction because `none` cannot be equal to `some` of any value. Therefore, this case is impossible.
2. **Case 2:** If both `head? as` and `head? bs` are `some a` and `some b` respectively, then the goal is:
\[
\text{some} (f \, (\text{some } a) \, (\text{some } b)) = \text{some} (f \, (\text{some } a) \, (\text{some } b))
\]
This is trivially true by the reflexivity of equality.

Since both cases are either impossible or trivially true, the theorem is proven. \(\blacksquare\)","theorem List.head_zipWithAll {f : Option α → Option β → γ} (h) :
    (zipWithAll f as bs).head h = f as.head? bs.head? := by
/- To prove the current goal, using the injectivity of the `some` constructor in the `Option` type, it suffices to show that:
\[
\text{some}((\text{zipWithAll} \, f \, as \, bs). \text{head} \, h) = \text{some}(f \, (\text{head?} \, as) \, (\text{head?} \, bs))
\] -/
  apply Option.some.inj
/- Using the equivalence that the optional head of a non-empty list is `some` of the first element, and the definition of the first element of `zipWithAll`, we can rewrite the goal to:
\[
\text{match } \text{head?} \, as, \text{head?} \, bs \text{ with} \\
\text{| none, none => none} \\
\text{| some } a, \text{ some } b => \text{ some } (f (\text{some } a) (\text{some } b))
\]
is equal to:
\[
\text{some} (f \, (\text{head?} \, as) \, (\text{head?} \, bs))
\] -/
  rw [← head?_eq_head, head?_zipWithAll]
/- We discuss by cases based on the values of `head? as` and `head? bs`:
1. **Case 1:** If both `head? as` and `head? bs` are `none`, then the goal is:
\[
\text{none} = \text{some} (f \, \text{none} \, \text{none})
\]
This is a contradiction because `none` cannot be equal to `some` of any value. Therefore, this case is impossible.
2. **Case 2:** If both `head? as` and `head? bs` are `some a` and `some b` respectively, then the goal is:
\[
\text{some} (f \, (\text{some } a) \, (\text{some } b)) = \text{some} (f \, (\text{some } a) \, (\text{some } b))
\]
This is trivially true by the reflexivity of equality. -/
  split <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27019,List.zip_of_prod,"theorem List.zip_of_prod {l : List α} {l' : List β} {lp : List (α × β)} (hl : lp.map Prod.fst = l)
    (hr : lp.map Prod.snd = l') : lp = l.zip l' := by sorry","List of Pairs Equals Zipped Lists if First and Second Components Match : For any lists $l$ and $l'$ of types $\alpha$ and $\beta$, respectively, and a list $lp$ of pairs $(\alpha \times \beta)$, if the first components of the pairs in $lp$ form the list $l$ and the second components of the pairs in $lp$ form the list $l'$, then $lp$ is equal to the list obtained by zipping $l$ and $l'$, i.e., $lp = l \text{.zip } l'$.","theorem List.zip_of_prod {l : List α} {l' : List β} {lp : List (α × β)} (hl : lp.map Prod.fst = l)
    (hr : lp.map Prod.snd = l') : lp = l.zip l' := by
  rw [← hl, ← hr, ← zip_unzip lp, ← unzip_fst, ← unzip_snd, zip_unzip, zip_unzip]","We need to show that \( lp = l \text{.zip } l' \) given the hypotheses \( \text{map}(\text{Prod.fst}, lp) = l \) and \( \text{map}(\text{Prod.snd}, lp) = l' \).

1. **Using the hypothesis \( \text{map}(\text{Prod.fst}, lp) = l \):**
- This means that the first components of the pairs in \( lp \) form the list \( l \).

2. **Using the hypothesis \( \text{map}(\text{Prod.snd}, lp) = l' \):**
- This means that the second components of the pairs in \( lp \) form the list \( l' \).

3. **Using the property of the `unzip` and `zip` operations:**
- The theorem \( (l. \text{unzip}. \text{fst}) \text{ zip } (l. \text{unzip}. \text{snd}) = l \) states that unzipping a list of pairs and then zipping the resulting lists of first and second components back together yields the original list.
- The theorem \( l. \text{unzip}. \text{fst} = \text{map}(\text{Prod.fst}, l) \) states that the first component of the unzipped list is equal to the list obtained by applying the function `Prod.fst` to each pair in \( l \).
- The theorem \( l. \text{unzip}. \text{snd} = \text{map}(\text{Prod.snd}, l) \) states that the second component of the unzipped list is equal to the list obtained by applying the function `Prod.snd` to each pair in \( l \).

4. **Combining these properties:**
- Since \( \text{map}(\text{Prod.fst}, lp) = l \) and \( \text{map}(\text{Prod.snd}, lp) = l' \), we have:
\[
lp = (lp. \text{unzip}. \text{fst}) \text{ zip } (lp. \text{unzip}. \text{snd})
\]
- By the properties of `unzip` and `zip`, this simplifies to:
\[
lp = l \text{.zip } l'
\]

Therefore, we have shown that \( lp = l \text{.zip } l' \), completing the proof.","theorem List.zip_of_prod {l : List α} {l' : List β} {lp : List (α × β)} (hl : lp.map Prod.fst = l)
    (hr : lp.map Prod.snd = l') : lp = l.zip l' := by
/- We start by using the given hypotheses \( \text{map}(\text{Prod.fst}, lp) = l \) and \( \text{map}(\text{Prod.snd}, lp) = l' \) to rewrite the goal. Specifically, we use the fact that the first components of \( lp \) form the list \( l \) and the second components form the list \( l' \). We then use the properties of the `unzip` and `zip` operations to show that \( lp \) is equal to the zipped list of \( l \) and \( l' \). Formally, we have:
1. \( \text{map}(\text{Prod.fst}, lp) = l \) implies \( lp = l \text{.zip } l' \) (using the hypothesis \( hl \)).
2. \( \text{map}(\text{Prod.snd}, lp) = l' \) implies \( lp = l \text{.zip } l' \) (using the hypothesis \( hr \)).
3. The property \( (l. \text{unzip}. \text{fst}) \text{ zip } (l. \text{unzip}. \text{snd}) = l \) (using the theorem `List.zip_unzip`).
4. The property \( l. \text{unzip}. \text{fst} = \text{map}(\text{Prod.fst}, l) \) (using the theorem `List.unzip_fst`).
5. The property \( l. \text{unzip}. \text{snd} = \text{map}(\text{Prod.snd}, l) \) (using the theorem `List.unzip_snd`).
6. Applying these properties, we conclude that \( lp = l \text{.zip } l' \). -/
  rw [← hl, ← hr, ← zip_unzip lp, ← unzip_fst, ← unzip_snd, zip_unzip, zip_unzip]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27020,List.zipWith_replicate',"theorem List.zipWith_replicate' {a : α} {b : β} {n : Nat} :
    zipWith f (replicate n a) (replicate n b) = replicate n (f a b) := by sorry","ZipWith of Replicated Elements : For any types `α`, `β`, and `α₁`, a function `f : α → β → α₁`, elements `a : α` and `b : β`, and a natural number `n`, the result of zipping two lists created by replicating `a` and `b` `n` times with the function `f` is equivalent to replicating the result of applying `f` to `a` and `b` `n` times. Specifically, `zipWith f (replicate n a) (replicate n b) = replicate n (f a b)`.","theorem List.zipWith_replicate' {a : α} {b : β} {n : Nat} :
    zipWith f (replicate n a) (replicate n b) = replicate n (f a b) := by
  induction n with
  | zero => rfl
  | succ n ih => simp [replicate_succ, ih]","We prove this by induction on \( n \).

**Base Case:**
For \( n = 0 \), we need to show:
\[ \text{zipWith } f \, (\text{replicate } 0 \, a) \, (\text{replicate } 0 \, b) = \text{replicate } 0 \, (f \, a \, b) \]
Since both sides of the equation are empty lists, the equality holds trivially by the reflexive property of equality.

**Inductive Step:**
Assume the inductive hypothesis that for some natural number \( k \):
\[ \text{zipWith } f \, (\text{replicate } k \, a) \, (\text{replicate } k \, b) = \text{replicate } k \, (f \, a \, b) \]
We need to show that:
\[ \text{zipWith } f \, (\text{replicate } (k + 1) \, a) \, (\text{replicate } (k + 1) \, b) = \text{replicate } (k + 1) \, (f \, a \, b) \]
Using the definition of `replicate`, we have:
\[ \text{replicate } (k + 1) \, a = a :: \text{replicate } k \, a \]
\[ \text{replicate } (k + 1) \, b = b :: \text{replicate } k \, b \]
Applying the definition of `zipWith`, we get:
\[ \text{zipWith } f \, (a :: \text{replicate } k \, a) \, (b :: \text{replicate } k \, b) = f \, a \, b :: \text{zipWith } f \, (\text{replicate } k \, a) \, (\text{replicate } k \, b) \]
By the inductive hypothesis, we know:
\[ \text{zipWith } f \, (\text{replicate } k \, a) \, (\text{replicate } k \, b) = \text{replicate } k \, (f \, a \, b) \]
Thus, we have:
\[ f \, a \, b :: \text{replicate } k \, (f \, a \, b) = \text{replicate } (k + 1) \, (f \, a \, b) \]
This completes the inductive step.

By induction, the theorem holds for all natural numbers \( n \). Therefore, the result is:
\[ \text{zipWith } f \, (\text{replicate } n \, a) \, (\text{replicate } n \, b) = \text{replicate } n \, (f \, a \, b) \]
This completes the proof.","theorem List.zipWith_replicate' {a : α} {b : β} {n : Nat} :
    zipWith f (replicate n a) (replicate n b) = replicate n (f a b) := by
  induction n with
/- First, consider the base case where \( n = 0 \). The goal is to show that:
\[ \text{zipWith } f \, (\text{replicate } 0 \, a) \, (\text{replicate } 0 \, b) = \text{replicate } 0 \, (f \, a \, b) \]
Since both sides of the equation are empty lists, the equality holds trivially by the reflexive property of equality. -/
  | zero => rfl
/- Next, consider the inductive step where \( n = k + 1 \) for some natural number \( k \). Assume the inductive hypothesis that:
\[ \text{zipWith } f \, (\text{replicate } k \, a) \, (\text{replicate } k \, b) = \text{replicate } k \, (f \, a \, b) \]
We need to show that:
\[ \text{zipWith } f \, (\text{replicate } (k + 1) \, a) \, (\text{replicate } (k + 1) \, b) = \text{replicate } (k + 1) \, (f \, a \, b) \]
Using the definition of `replicate`, we have:
\[ \text{replicate } (k + 1) \, a = a :: \text{replicate } k \, a \]
\[ \text{replicate } (k + 1) \, b = b :: \text{replicate } k \, b \]
Applying the definition of `zipWith`, we get:
\[ \text{zipWith } f \, (a :: \text{replicate } k \, a) \, (b :: \text{replicate } k \, b) = f \, a \, b :: \text{zipWith } f \, (\text{replicate } k \, a) \, (\text{replicate } k \, b) \]
By the inductive hypothesis, we know:
\[ \text{zipWith } f \, (\text{replicate } k \, a) \, (\text{replicate } k \, b) = \text{replicate } k \, (f \, a \, b) \]
Thus, we have:
\[ f \, a \, b :: \text{replicate } k \, (f \, a \, b) = \text{replicate } (k + 1) \, (f \, a \, b) \]
This completes the inductive step. -/
  | succ n ih => simp [replicate_succ, ih]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27021,List.take_zipWith,theorem List.take_zipWith : (zipWith f l l').take n = zipWith f (l.take n) (l'.take n) := by sorry,"Distributivity of `zipWith` over `take` : For any types $\alpha$, $\alpha_1$, and $\alpha_2$, and for any function $f : \alpha \to \alpha_1 \to \alpha_2$, and for any lists $l : \text{List } \alpha$ and $l' : \text{List } \alpha_1$, the first $n$ elements of the list obtained by applying `zipWith` to $l$ and $l'$ are equal to the list obtained by applying `zipWith` to the first $n$ elements of $l$ and the first $n$ elements of $l'$. In other words, for any natural number $n$:
\[ \text{take } n \, (\text{zipWith } f \, l \, l') = \text{zipWith } f \, (\text{take } n \, l) \, (\text{take } n \, l') \]","theorem List.take_zipWith : (zipWith f l l').take n = zipWith f (l.take n) (l'.take n) := by
  induction l generalizing l' n with
  | nil => simp
  | cons hd tl hl =>
    cases l'
    · simp
    · cases n
      · simp
      · simp [hl]","We proceed by induction on the list `l`.

1. **Base Case:**
- **Case 1: `l'` is empty.**
- We need to show that:
\[ \text{take } n \, (\text{zipWith } f \, (hd :: tl) \, []) = \text{zipWith } f \, (\text{take } n \, (hd :: tl)) \, (\text{take } n \, []) \]
- Since `zipWith` applied to any list and the empty list results in the empty list, and taking the first `n` elements of the empty list is the empty list, the goal simplifies to:
\[ \text{take } n \, [] = \text{zipWith } f \, (\text{take } n \, (hd :: tl)) \, [] \]
- This is trivially true because both sides are the empty list.

2. **Inductive Step:**
- **Case 2: `l'` is non-empty, specifically of the form `head :: tail`.**
- We need to show that:
\[ \text{take } n \, (\text{zipWith } f \, (hd :: tl) \, (head :: tail)) = \text{zipWith } f \, (\text{take } n \, (hd :: tl)) \, (\text{take } n \, (head :: tail)) \]
- We perform case analysis on the natural number `n`:
- **Subcase 1: `n` is zero.**
- We need to show that:
\[ \text{take } 0 \, (\text{zipWith } f \, (hd :: tl) \, (head :: tail)) = \text{zipWith } f \, (\text{take } 0 \, (hd :: tl)) \, (\text{take } 0 \, (head :: tail)) \]
- Since taking the first zero elements of any list results in the empty list, the goal simplifies to:
\[ \text{take } 0 \, [] = \text{zipWith } f \, [] \, [] \]
- This is trivially true because both sides are the empty list.
- **Subcase 2: `n` is a successor of some natural number `n'`.**
- We need to show that:
\[ \text{take } (n' + 1) \, (\text{zipWith } f \, (hd :: tl) \, (head :: tail)) = \text{zipWith } f \, (\text{take } (n' + 1) \, (hd :: tl)) \, (\text{take } (n' + 1) \, (head :: tail)) \]
- Using the inductive hypothesis `hl`, which states that for any list `l'` and natural number `n`, taking the first `n` elements of the list obtained by applying `zipWith` to `tl` and `l'` is equal to applying `zipWith` to the first `n` elements of `tl` and the first `n` elements of `l'`, we can simplify the goal to:
\[ \text{take } (n' + 1) \, (\text{zipWith } f \, (hd :: tl) \, (head :: tail)) = \text{zipWith } f \, (\text{take } (n' + 1) \, (hd :: tl)) \, (\text{take } (n' + 1) \, (head :: tail)) \]
- This is true by the definition of `zipWith` and the inductive hypothesis.

This completes the proof.","theorem List.take_zipWith : (zipWith f l l').take n = zipWith f (l.take n) (l'.take n) := by
  induction l generalizing l' n with
/- We consider the case where the list `l'` is empty. In this case, the goal simplifies to showing that taking the first `n` elements of the list obtained by applying `zipWith` to `hd :: tl` and the empty list is equal to applying `zipWith` to the first `n` elements of `hd :: tl` and the first `n` elements of the empty list. This is trivially true because `zipWith` applied to any list and the empty list results in the empty list, and taking the first `n` elements of the empty list is the empty list. -/
  | nil => simp
/- We consider the case where the list `l'` is non-empty, specifically of the form `head :: tail`. We need to show that taking the first `n` elements of the list obtained by applying `zipWith` to `hd :: tl` and `head :: tail` is equal to applying `zipWith` to the first `n` elements of `hd :: tl` and the first `n` elements of `head :: tail`. -/
  | cons hd tl hl =>
/- We perform case analysis on the list `l'`. We consider two cases: when `l'` is empty and when `l'` is non-empty. -/
    cases l'
/- We simplify the goal for the case where `l'` is empty. This simplification shows that the goal is trivially true because `zipWith` applied to any list and the empty list results in the empty list, and taking the first `n` elements of the empty list is the empty list. -/
    · simp
/- We perform case analysis on the natural number `n`. We consider two cases: when `n` is zero and when `n` is a successor of some natural number `n'`. -/
    · cases n
/- We simplify the goal for the case where `n` is zero. This simplification shows that the goal is trivially true because taking the first zero elements of any list results in the empty list, and `zipWith` applied to the empty list and any list results in the empty list. -/
      · simp
/- First, we simplify the goal using the hypothesis `hl`, which states that for any list `l'` and natural number `n`, taking the first `n` elements of the list obtained by applying `zipWith` to `tl` and `l'` is equal to applying `zipWith` to the first `n` elements of `tl` and the first `n` elements of `l'`. -/
/- We simplify the goal for the case where `n` is a successor of some natural number `n'`. Using the hypothesis `hl`, we show that taking the first `n + 1` elements of the list obtained by applying `zipWith` to `hd :: tl` and `head :: tail` is equal to applying `zipWith` to the first `n + 1` elements of `hd :: tl` and the first `n + 1` elements of `head :: tail`. -/
      · simp [hl]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27023,List.unzip_zip,"theorem List.unzip_zip {l₁ : List α} {l₂ : List β} (h : length l₁ = length l₂) :
    unzip (zip l₁ l₂) = (l₁, l₂) := by sorry","Unzip of Zipped Lists with Equal Lengths Returns Original Lists: \((l_1 \text{ zip } l_2). \text{unzip} = (l_1, l_2)\) when \( |l_1| = |l_2| \) : For any lists \( l_1 \) and \( l_2 \) of types \( \alpha \) and \( \beta \) respectively, if the lengths of \( l_1 \) and \( l_2 \) are equal, then the result of unzipping the zipped list \( l_1 \) and \( l_2 \) is the pair of lists \( (l_1, l_2) \). Formally, if \( |l_1| = |l_2| \), then \((l_1 \text{ zip } l_2). \text{unzip} = (l_1, l_2)\).","theorem List.unzip_zip {l₁ : List α} {l₂ : List β} (h : length l₁ = length l₂) :
    unzip (zip l₁ l₂) = (l₁, l₂) := by
  ext
  · rw [unzip_zip_left (Nat.le_of_eq h)]
  · rw [unzip_zip_right (Nat.le_of_eq h.symm)]","To prove that \((l_1 \text{ zip } l_2). \text{unzip} = (l_1, l_2)\), it suffices to show that for any natural number \( n \) and any element \( a \) of type \( \alpha \), \( a \in (l_1 \text{ zip } l_2). \text{unzip}. \text{fst}[n] \) if and only if \( a \in l_1[n] \), and for any element \( b \) of type \( \beta \), \( b \in (l_1 \text{ zip } l_2). \text{unzip}. \text{snd}[n] \) if and only if \( b \in l_2[n] \).

First, we show that for any element \( a \) of type \( \alpha \), \( a \in (l_1 \text{ zip } l_2). \text{unzip}. \text{fst}[n] \) if and only if \( a \in l_1[n] \). Since the lengths of \( l_1 \) and \( l_2 \) are equal, we have \( l_1.length \leq l_2.length \). By the theorem that the first component of the unzipped list of \( l_1 \) and \( l_2 \) is \( l_1 \) when \( l_1.length \leq l_2.length \), we can replace \((l_1 \text{ zip } l_2). \text{unzip}. \text{fst}\) with \( l_1 \). Therefore, \( a \in (l_1 \text{ zip } l_2). \text{unzip}. \text{fst}[n] \) is equivalent to \( a \in l_1[n] \).

Next, we show that for any element \( b \) of type \( \beta \), \( b \in (l_1 \text{ zip } l_2). \text{unzip}. \text{snd}[n] \) if and only if \( b \in l_2[n] \). Since the lengths of \( l_1 \) and \( l_2 \) are equal, we have \( l_2.length \leq l_1.length \) by symmetry. By the theorem that the second component of the unzipped list of \( l_1 \) and \( l_2 \) is \( l_2 \) when \( l_2.length \leq l_1.length \), we can replace \((l_1 \text{ zip } l_2). \text{unzip}. \text{snd}\) with \( l_2 \). Therefore, \( b \in (l_1 \text{ zip } l_2). \text{unzip}. \text{snd}[n] \) is equivalent to \( b \in l_2[n] \).

Thus, we have shown that \((l_1 \text{ zip } l_2). \text{unzip} = (l_1, l_2)\) when \( |l_1| = |l_2| \). This completes the proof. \(\blacksquare\)","theorem List.unzip_zip {l₁ : List α} {l₂ : List β} (h : length l₁ = length l₂) :
    unzip (zip l₁ l₂) = (l₁, l₂) := by
/- To prove that \((l_1 \text{ zip } l_2). \text{unzip} = (l_1, l_2)\), it suffices to show that for any natural number \( n \) and any element \( a \) of type \( \alpha \), \( a \in (l_1 \text{ zip } l_2). \text{unzip}. \text{fst}[n] \) if and only if \( a \in l_1[n] \), and for any element \( b \) of type \( \beta \), \( b \in (l_1 \text{ zip } l_2). \text{unzip}. \text{snd}[n] \) if and only if \( b \in l_2[n] \). -/
  ext
/- First, we show that for any element \( a \) of type \( \alpha \), \( a \in (l_1 \text{ zip } l_2). \text{unzip}. \text{fst}[n] \) if and only if \( a \in l_1[n] \). Since the lengths of \( l_1 \) and \( l_2 \) are equal, we have \( l_1.length \leq l_2.length \). By the theorem that the first component of the unzipped list of \( l_1 \) and \( l_2 \) is \( l_1 \) when \( l_1.length \leq l_2.length \), we can replace \((l_1 \text{ zip } l_2). \text{unzip}. \text{fst}\) with \( l_1 \). Therefore, \( a \in (l_1 \text{ zip } l_2). \text{unzip}. \text{fst}[n] \) is equivalent to \( a \in l_1[n] \). -/
  · rw [unzip_zip_left (Nat.le_of_eq h)]
/- Next, we show that for any element \( b \) of type \( \beta \), \( b \in (l_1 \text{ zip } l_2). \text{unzip}. \text{snd}[n] \) if and only if \( b \in l_2[n] \). Since the lengths of \( l_1 \) and \( l_2 \) are equal, we have \( l_2.length \leq l_1.length \) by symmetry. By the theorem that the second component of the unzipped list of \( l_1 \) and \( l_2 \) is \( l_2 \) when \( l_2.length \leq l_1.length \), we can replace \((l_1 \text{ zip } l_2). \text{unzip}. \text{snd}\) with \( l_2 \). Therefore, \( b \in (l_1 \text{ zip } l_2). \text{unzip}. \text{snd}[n] \) is equivalent to \( b \in l_2[n] \). -/
  · rw [unzip_zip_right (Nat.le_of_eq h.symm)]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27025,List.zipWith_append,"theorem List.zipWith_append (f : α → β → γ) (l la : List α) (l' lb : List β)
    (h : l.length = l'.length) :
    zipWith f (l ++ la) (l' ++ lb) = zipWith f l l' ++ zipWith f la lb := by sorry","ZipWith Distributes Over List Concatenation with Equal Lengths : For any types $\alpha$, $\beta$, and $\gamma$, and for any function $f : \alpha \to \beta \to \gamma$, and any lists $l, l_a : \text{List} \, \alpha$ and $l', l_b : \text{List} \, \beta$, if the lengths of $l$ and $l'$ are equal, then the list obtained by applying `zipWith` to the concatenation of $l$ and $l_a$ with the concatenation of $l'$ and $l_b$ is equal to the concatenation of the lists obtained by applying `zipWith` to $l$ and $l'$ and to $l_a$ and $l_b$. In other words, if $|l| = |l'|$, then:
\[ \text{zipWith } f \, (l \, ++ \, l_a) \, (l' \, ++ \, l_b) = (\text{zipWith } f \, l \, l') \, ++ \, (\text{zipWith } f \, l_a \, l_b) \]","theorem List.zipWith_append (f : α → β → γ) (l la : List α) (l' lb : List β)
    (h : l.length = l'.length) :
    zipWith f (l ++ la) (l' ++ lb) = zipWith f l l' ++ zipWith f la lb := by
  induction l generalizing l' with
  | nil =>
    have : l' = [] := eq_nil_of_length_eq_zero (by simpa using h.symm)
    simp [this]
  | cons hl tl ih =>
    cases l' with
    | nil => simp at h
    | cons head tail =>
      simp only [length_cons, Nat.succ.injEq] at h
      simp [ih _ h]","We prove this by induction on the list \(l\).

**Base Case:**
Consider the case where \(l\) is the empty list \([]\). We need to show:
\[ \text{zipWith } f \, ([] \, ++ \, l_a) \, (l' \, ++ \, l_b) = (\text{zipWith } f \, [] \, l') \, ++ \, (\text{zipWith } f \, l_a \, l_b) \]

Since the length of \(l\) is zero, the length of \(l'\) must also be zero. Therefore, \(l'\) is the empty list \([]\). Simplifying both sides, we get:
\[ \text{zipWith } f \, l_a \, (l_b) = \text{zipWith } f \, l_a \, l_b \]
which is trivially true.

**Inductive Step:**
Assume the statement holds for a list \(tl\) of length \(n\). We need to show it holds for a list \(hl :: tl\) of length \(n + 1\). Consider the list \(l = hl :: tl\). We need to show:
\[ \text{zipWith } f \, ((hl :: tl) \, ++ \, l_a) \, (l' \, ++ \, l_b) = (\text{zipWith } f \, (hl :: tl) \, l') \, ++ \, (\text{zipWith } f \, l_a \, l_b) \]

Since the lengths of \(l\) and \(l'\) are equal, \(l'\) must be of the form \(head :: tail\) where the lengths of \(tl\) and \(tail\) are equal. Using the induction hypothesis, we have:
\[ \text{zipWith } f \, (tl \, ++ \, l_a) \, (tail \, ++ \, l_b) = (\text{zipWith } f \, tl \, tail) \, ++ \, (\text{zipWith } f \, l_a \, l_b) \]

Simplifying the left-hand side, we get:
\[ \text{zipWith } f \, (hl :: (tl \, ++ \, l_a)) \, (head :: (tail \, ++ \, l_b)) = f(hl, head) :: (\text{zipWith } f \, (tl \, ++ \, l_a) \, (tail \, ++ \, l_b)) \]

Using the induction hypothesis, this becomes:
\[ f(hl, head) :: ((\text{zipWith } f \, tl \, tail) \, ++ \, (\text{zipWith } f \, l_a \, l_b)) \]

Simplifying the right-hand side, we get:
\[ (\text{zipWith } f \, (hl :: tl) \, (head :: tail)) \, ++ \, (\text{zipWith } f \, l_a \, l_b) = (f(hl, head) :: (\text{zipWith } f \, tl \, tail)) \, ++ \, (\text{zipWith } f \, l_a \, l_b) \]

Both sides are equal, thus completing the inductive step.

Therefore, by induction, the theorem holds for all lists \(l\) and \(l'\) of equal length. \(\blacksquare\)","theorem List.zipWith_append (f : α → β → γ) (l la : List α) (l' lb : List β)
    (h : l.length = l'.length) :
    zipWith f (l ++ la) (l' ++ lb) = zipWith f l l' ++ zipWith f la lb := by
  induction l generalizing l' with
/- Perform induction on the list `l` and consider the base case where `l` is the empty list `[]`. -/
  | nil =>
/- Since the length of `l'` is zero, we can conclude that `l'` is the empty list `[]` by using the fact that the length of the empty list is zero and the symmetry of equality. -/
    have : l' = [] := eq_nil_of_length_eq_zero (by simpa using h.symm)
/- Using the fact that `l'` is the empty list, we simplify the goal to show that the `zipWith` of the concatenated lists is equal to the concatenation of the `zipWith` results. -/
    simp [this]
/- Consider the inductive step where `l` is a non-empty list with head `hl` and tail `tl`. -/
  | cons hl tl ih =>
    cases l' with
/- Consider the case where `l'` is the empty list `[]` and simplify the assumption `h` to show that the lengths of the lists are equal. -/
    | nil => simp at h
/- Consider the case where `l'` is a non-empty list with head `head` and tail `tail`. -/
    | cons head tail =>
/- Using the properties of the length of a list and the injectivity of the successor function, we simplify the assumption `h` to show that the lengths of the tails `tl` and `tail` are equal. -/
      simp only [length_cons, Nat.succ.injEq] at h
/- Using the induction hypothesis `ih` and the assumption `h` that the lengths of `tl` and `tail` are equal, we simplify the goal to show that the `zipWith` of the concatenated lists is equal to the concatenation of the `zipWith` results. -/
/- Consider the inductive step where `l` is a non-empty list with head `hl` and tail `tl`. -/
/- Using the induction hypothesis `ih` and the assumption `h` that the lengths of `tl` and `tail` are equal, we simplify the goal to show that the `zipWith` of the concatenated lists is equal to the concatenation of the `zipWith` results. -/
      simp [ih _ h]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27026,List.zipWithAll_map_right,"theorem List.zipWithAll_map_right (l₁ : List α) (l₂ : List β) (f : β → β') (g : Option α → Option β' → γ) :
    zipWithAll g l₁ (l₂.map f) = zipWithAll (fun a b => g a (f <$> b)) l₁ l₂ := by sorry","Right Mapping Preserves `zipWithAll` Operation in Lists : For any lists \( l_1 \) and \( l_2 \) of types \( \alpha \) and \( \beta \) respectively, and a function \( f : \beta \to \beta' \), and a function \( g : \text{Option} \, \alpha \to \text{Option} \, \beta' \to \gamma \), the following holds:
\[
\text{zipWithAll} \, g \, l_1 \, (\text{map} \, f \, l_2) = \text{zipWithAll} \, (\lambda a \, b, \, g \, a \, (f \, b)) \, l_1 \, l_2
\]
In other words, applying the function \( f \) to each element of \( l_2 \) and then zipping the result with \( l_1 \) using \( g \) is the same as zipping \( l_1 \) and \( l_2 \) using a modified version of \( g \) that applies \( f \) to the elements of \( l_2 \) before zipping.","theorem List.zipWithAll_map_right (l₁ : List α) (l₂ : List β) (f : β → β') (g : Option α → Option β' → γ) :
    zipWithAll g l₁ (l₂.map f) = zipWithAll (fun a b => g a (f <$> b)) l₁ l₂ := by
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","We will prove the theorem by induction on the list \( l_1 \) and generalizing over \( l_2 \).

**Base Case:**
1. **\( l_1 \) is empty:**
- **Subcase 1: \( l_2 \) is empty:**
\[
\text{zipWithAll} \, g \, [] \, (\text{map} \, f \, []) = \text{zipWithAll} \, (\lambda a \, b, \, g \, a \, (f \, b)) \, [] \, []
\]
Both sides are empty lists, so the equality holds.
- **Subcase 2: \( l_2 \) is non-empty:**
\[
\text{zipWithAll} \, g \, [] \, (\text{map} \, f \, (b :: l_2')) = \text{zipWithAll} \, (\lambda a \, b, \, g \, a \, (f \, b)) \, [] \, (b :: l_2')
\]
Both sides are empty lists, so the equality holds.

**Inductive Step:**
2. **\( l_1 \) is non-empty:**
- **Subcase 1: \( l_2 \) is empty:**
\[
\text{zipWithAll} \, g \, (a :: l_1') \, (\text{map} \, f \, []) = \text{zipWithAll} \, (\lambda a \, b, \, g \, a \, (f \, b)) \, (a :: l_1') \, []
\]
Both sides are empty lists, so the equality holds.
- **Subcase 2: \( l_2 \) is non-empty:**
\[
\text{zipWithAll} \, g \, (a :: l_1') \, (\text{map} \, f \, (b :: l_2')) = \text{zipWithAll} \, (\lambda a \, b, \, g \, a \, (f \, b)) \, (a :: l_1') \, (b :: l_2')
\]
By the inductive hypothesis, we have:
\[
\text{zipWithAll} \, g \, l_1' \, (\text{map} \, f \, l_2') = \text{zipWithAll} \, (\lambda a \, b, \, g \, a \, (f \, b)) \, l_1' \, l_2'
\]
Using the definitions of `zipWithAll` and `map`, we can simplify the left-hand side and the right-hand side to show that they are equal.

Thus, by induction, the theorem holds for all lists \( l_1 \) and \( l_2 \). This completes the proof. \(\blacksquare\)","theorem List.zipWithAll_map_right (l₁ : List α) (l₂ : List β) (f : β → β') (g : Option α → Option β' → γ) :
    zipWithAll g l₁ (l₂.map f) = zipWithAll (fun a b => g a (f <$> b)) l₁ l₂ := by
/- We perform induction on the list \( l_1 \) and generalize over \( l_2 \). For each case of \( l_1 \), we further split \( l_2 \) into its possible cases (empty or non-empty). Then, we simplify the resulting goals using the properties of `zipWithAll` and `map`. -/
/- We perform induction on the list \( l_1 \) to break down the proof into cases. We generalize over \( l_2 \) to ensure that the induction hypothesis is strong enough to cover all possible cases of \( l_2 \). -/
/- First, we apply the induction tactic to the current goal, which may generate new subgoals. Then, for each of these new subgoals, we apply the `cases` tactic to further refine or solve them. -/
/- We will discuss every possible case of \( l_2 \). Case 1: \( l_2 \) is empty. Case 2: \( l_2 \) is non-empty. -/
/- We will discuss every possible case of \( l_2 \). Case 1: \( l_2 \) is empty. Case 2: \( l_2 \) is non-empty. -/
/- First, we apply the `cases` tactic to the current goal, which may generate new subgoals. Then, for each of these new subgoals, we apply the `simp_all` tactic to further refine or solve them. -/
/- Using the properties of `zipWithAll` and `map`, we can simplify the proposition to show that the left-hand side and the right-hand side are equal. This simplification is trivial and can be done using the definitions and properties of the functions involved. -/
/- Using the properties of `zipWithAll` and `map`, we can simplify the proposition to show that the left-hand side and the right-hand side are equal. This simplification is trivial and can be done using the definitions and properties of the functions involved. -/
/- Using the properties of `zipWithAll` and `map`, we can simplify the proposition to show that the left-hand side and the right-hand side are equal. This simplification is trivial and can be done using the definitions and properties of the functions involved. -/
/- Using the properties of `zipWithAll` and `map`, we can simplify the proposition to show that the left-hand side and the right-hand side are equal. This simplification is trivial and can be done using the definitions and properties of the functions involved. -/
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27027,List.zipWithAll_replicate,"theorem List.zipWithAll_replicate {a : α} {b : β} {n : Nat} :
    zipWithAll f (replicate n a) (replicate n b) = replicate n (f a b) := by sorry","ZipWithAll of Replicated Lists Equals Replicated Application of Function: \( \text{zipWithAll} \, f \, (\text{replicate} \, n \, a) \, (\text{replicate} \, n \, b) = \text{replicate} \, n \, (f \, (some \, a) \, (some \, b)) \) : For any types \( \alpha \), \( \beta \), and \( \alpha_1 \), and for any function \( f : \text{Option} \, \alpha \to \text{Option} \, \beta \to \alpha_1 \), elements \( a \in \alpha \) and \( b \in \beta \), and natural number \( n \), the list obtained by applying \( f \) to the corresponding elements of the lists `replicate n a` and `replicate n b` is equal to the list `replicate n (f (some a) (some b))`. Formally, if \( l_1 = [a, a, \ldots, a] \) and \( l_2 = [b, b, \ldots, b] \) are lists of length \( n \), then \( \text{zipWithAll} \, f \, l_1 \, l_2 = [f (some \, a) (some \, b), f (some \, a) (some \, b), \ldots, f (some \, a) (some \, b)] \).","theorem List.zipWithAll_replicate {a : α} {b : β} {n : Nat} :
    zipWithAll f (replicate n a) (replicate n b) = replicate n (f a b) := by
  induction n with
  | zero => rfl
  | succ n ih => simp [replicate_succ, ih]","We prove this by induction on \( n \).

**Base Case:**
For \( n = 0 \), we need to show:
\[
\text{zipWithAll} \, f \, (\text{replicate} \, 0 \, a) \, (\text{replicate} \, 0 \, b) = \text{replicate} \, 0 \, (f \, (some \, a) \, (some \, b))
\]
Since both `replicate 0 a` and `replicate 0 b` are empty lists, the left-hand side is the result of applying `zipWithAll` to two empty lists, which is an empty list. The right-hand side is also an empty list. Therefore, the equality holds trivially due to the reflexive property.

**Inductive Step:**
Assume the inductive hypothesis:
\[
\text{zipWithAll} \, f \, (\text{replicate} \, k \, a) \, (\text{replicate} \, k \, b) = \text{replicate} \, k \, (f \, (some \, a) \, (some \, b))
\]
We need to show:
\[
\text{zipWithAll} \, f \, (\text{replicate} \, (k + 1) \, a) \, (\text{replicate} \, (k + 1) \, b) = \text{replicate} \, (k + 1) \, (f \, (some \, a) \, (some \, b))
\]
Using the definition of `replicate`, we have:
\[
\text{replicate} \, (k + 1) \, a = a :: \text{replicate} \, k \, a
\]
\[
\text{replicate} \, (k + 1) \, b = b :: \text{replicate} \, k \, b
\]
Applying `zipWithAll` to these lists, we get:
\[
\text{zipWithAll} \, f \, (a :: \text{replicate} \, k \, a) \, (b :: \text{replicate} \, k \, b) = f \, (some \, a) \, (some \, b) :: \text{zipWithAll} \, f \, (\text{replicate} \, k \, a) \, (\text{replicate} \, k \, b)
\]
By the inductive hypothesis, we know:
\[
\text{zipWithAll} \, f \, (\text{replicate} \, k \, a) \, (\text{replicate} \, k \, b) = \text{replicate} \, k \, (f \, (some \, a) \, (some \, b))
\]
Thus, we have:
\[
f \, (some \, a) \, (some \, b) :: \text{replicate} \, k \, (f \, (some \, a) \, (some \, b)) = \text{replicate} \, (k + 1) \, (f \, (some \, a) \, (some \, b))
\]
This completes the inductive step.

By induction, the theorem holds for all natural numbers \( n \). Therefore, the proof is complete.","theorem List.zipWithAll_replicate {a : α} {b : β} {n : Nat} :
    zipWithAll f (replicate n a) (replicate n b) = replicate n (f a b) := by
  induction n with
/- First, consider the base case where \( n = 0 \). We need to show that:
\[
\text{zipWithAll} \, f \, (\text{replicate} \, 0 \, a) \, (\text{replicate} \, 0 \, b) = \text{replicate} \, 0 \, (f \, (some \, a) \, (some \, b))
\]
Since both `replicate 0 a` and `replicate 0 b` are empty lists, the left-hand side is the result of applying `zipWithAll` to two empty lists, which is an empty list. The right-hand side is also an empty list. Therefore, the equality holds trivially due to the reflexive property. -/
  | zero => rfl
/- Next, consider the inductive step where \( n = k + 1 \) for some natural number \( k \). Assume the inductive hypothesis:
\[
\text{zipWithAll} \, f \, (\text{replicate} \, k \, a) \, (\text{replicate} \, k \, b) = \text{replicate} \, k \, (f \, (some \, a) \, (some \, b))
\]
We need to show that:
\[
\text{zipWithAll} \, f \, (\text{replicate} \, (k + 1) \, a) \, (\text{replicate} \, (k + 1) \, b) = \text{replicate} \, (k + 1) \, (f \, (some \, a) \, (some \, b))
\]
Using the definition of `replicate`, we have:
\[
\text{replicate} \, (k + 1) \, a = a :: \text{replicate} \, k \, a
\]
\[
\text{replicate} \, (k + 1) \, b = b :: \text{replicate} \, k \, b
\]
Applying `zipWithAll` to these lists, we get:
\[
\text{zipWithAll} \, f \, (a :: \text{replicate} \, k \, a) \, (b :: \text{replicate} \, k \, b) = f \, (some \, a) \, (some \, b) :: \text{zipWithAll} \, f \, (\text{replicate} \, k \, a) \, (\text{replicate} \, k \, b)
\]
By the inductive hypothesis, we know:
\[
\text{zipWithAll} \, f \, (\text{replicate} \, k \, a) \, (\text{replicate} \, k \, b) = \text{replicate} \, k \, (f \, (some \, a) \, (some \, b))
\]
Thus, we have:
\[
f \, (some \, a) \, (some \, b) :: \text{replicate} \, k \, (f \, (some \, a) \, (some \, b)) = \text{replicate} \, (k + 1) \, (f \, (some \, a) \, (some \, b))
\]
This completes the inductive step. -/
  | succ n ih => simp [replicate_succ, ih]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27029,List.getElem?_zipWith',"theorem List.getElem?_zipWith' {f : α → β → γ} {i : Nat} :
    (zipWith f l₁ l₂)[i]? = (l₁[i]?.map f).bind fun g => l₂[i]?.map g := by sorry","Element at Index in `zipWith` List: Optional Result Using `Option.map` and `Option.bind` : For any types \(\alpha\), \(\beta\), and \(\gamma\), given two lists \(l_1 : \text{List } \alpha\) and \(l_2 : \text{List } \beta\), a function \(f : \alpha \to \beta \to \gamma\), and a natural number \(i\), the optional element at index \(i\) in the list resulting from \(\text{zipWith } f \, l_1 \, l_2\) is given by:
\[
(\text{zipWith } f \, l_1 \, l_2)[i]? = (\text{Option.map } f \, l_1[i]?).\text{bind } (\lambda g, \, \text{Option.map } g \, l_2[i]?)
\]
This means that if \(l_1[i]?\) is \(\text{some } a\) and \(l_2[i]?\) is \(\text{some } b\), then \((\text{zipWith } f \, l_1 \, l_2)[i]?\) is \(\text{some } (f \, a \, b)\). If either \(l_1[i]?\) or \(l_2[i]?\) is \(\text{none}\), then \((\text{zipWith } f \, l_1 \, l_2)[i]?\) is \(\text{none}\).","theorem List.getElem?_zipWith' {f : α → β → γ} {i : Nat} :
    (zipWith f l₁ l₂)[i]? = (l₁[i]?.map f).bind fun g => l₂[i]?.map g := by
  induction l₁ generalizing l₂ i with
  | nil => rw [zipWith] <;> simp
  | cons head tail =>
    cases l₂
    · simp
    · cases i <;> simp_all","We will prove the theorem by induction on the structure of the lists \( l_1 \) and \( l_2 \).

1. **Base Case: \( l_1 \) is the empty list.**
- If \( l_1 \) is the empty list, then for any list \( l_2 \) and any natural number \( i \), the list \(\text{zipWith } f \, [] \, l_2\) is the empty list. Therefore, \((\text{zipWith } f \, [] \, l_2)[i]?\) is \(\text{none}\).
- On the other hand, \(\text{Option.map } f \, [][i]?\) is \(\text{none}\) because \([i]?\) is \(\text{none}\) for any \( i \). Thus, \((\text{Option.map } f \, [][i]?).\text{bind } (\lambda g, \, \text{Option.map } g \, l_2[i]?)\) is also \(\text{none}\).
- Therefore, the base case holds.

2. **Inductive Step: \( l_1 \) is a non-empty list.**
- Let \( l_1 = \text{head} :: \text{tail} \) and \( l_2 = \text{head}^\prime :: \text{tail}^\prime \).
- We need to show that \((\text{zipWith } f \, (\text{head} :: \text{tail}) \, (\text{head}^\prime :: \text{tail}^\prime))[i]?\) is equal to \((\text{Option.map } f \, (\text{head} :: \text{tail})[i]?).\text{bind } (\lambda g, \, \text{Option.map } g \, (\text{head}^\prime :: \text{tail}^\prime)[i]?)\).

- **Case 1: \( i = 0 \)**
- \((\text{zipWith } f \, (\text{head} :: \text{tail}) \, (\text{head}^\prime :: \text{tail}^\prime))[0]?\) is \(\text{some } (f \, \text{head} \, \text{head}^\prime)\) because the first elements of the lists are paired.
- \((\text{Option.map } f \, (\text{head} :: \text{tail})[0]?).\text{bind } (\lambda g, \, \text{Option.map } g \, (\text{head}^\prime :: \text{tail}^\prime)[0]?)\) is \(\text{some } (f \, \text{head} \, \text{head}^\prime)\) because \((\text{head} :: \text{tail})[0]?\) is \(\text{some } \text{head}\) and \((\text{head}^\prime :: \text{tail}^\prime)[0]?\) is \(\text{some } \text{head}^\prime\).
- Therefore, the case \( i = 0 \) holds.

- **Case 2: \( i = n + 1 \) for some natural number \( n \)**
- \((\text{zipWith } f \, (\text{head} :: \text{tail}) \, (\text{head}^\prime :: \text{tail}^\prime))[n + 1]?\) is \((\text{zipWith } f \, \text{tail} \, \text{tail}^\prime)[n]?\) by the definition of `zipWith`.
- By the inductive hypothesis, \((\text{zipWith } f \, \text{tail} \, \text{tail}^\prime)[n]?\) is equal to \((\text{Option.map } f \, \text{tail}[n]?).\text{bind } (\lambda g, \, \text{Option.map } g \, \text{tail}^\prime[n]?)\).
- Therefore, \((\text{zipWith } f \, (\text{head} :: \text{tail}) \, (\text{head}^\prime :: \text{tail}^\prime))[n + 1]?\) is equal to \((\text{Option.map } f \, (\text{head} :: \text{tail})[n + 1]?).\text{bind } (\lambda g, \, \text{Option.map } g \, (\text{head}^\prime :: \text{tail}^\prime)[n + 1]?)\).

- **Case 3: \( l_2 \) is the empty list**
- If \( l_2 \) is the empty list, then \((\text{zipWith } f \, (\text{head} :: \text{tail}) \, [])[i]?\) is \(\text{none}\) for any \( i \).
- On the other hand, \((\text{Option.map } f \, (\text{head} :: \text{tail})[i]?).\text{bind } (\lambda g, \, \text{Option.map } g \, [][i]?)\) is \(\text{none}\) because \([][i]?\) is \(\text{none}\) for any \( i \).
- Therefore, the case where \( l_2 \) is the empty list holds.

Thus, by induction, the theorem holds for all lists \( l_1 \) and \( l_2 \) and all natural numbers \( i \). This completes the proof. \(\blacksquare\)","theorem List.getElem?_zipWith' {f : α → β → γ} {i : Nat} :
    (zipWith f l₁ l₂)[i]? = (l₁[i]?.map f).bind fun g => l₂[i]?.map g := by
  induction l₁ generalizing l₂ i with
/- For the case where \( l_2 \) is the empty list, we use the definition of `zipWith` to rewrite the goal. This simplifies the goal to a trivial equality, which is automatically resolved. -/
  | nil => rw [zipWith] <;> simp
/- For the case where \( l_2 \) is a non-empty list, we decompose \( l_2 \) into its head and tail. We then proceed to prove the goal for this case. -/
  | cons head tail =>
/- We will consider every possible case of the list \( l_2 \). Specifically, we consider the case where \( l_2 \) is the empty list and the case where \( l_2 \) is a non-empty list. -/
    cases l₂
/- For the case where \( l_2 \) is the empty list, we simplify the proposition using the properties of list operations and optional values. This simplification shows that the goal is trivially true. -/
    · simp
/- We will consider every possible case of the natural number \( i \). For each case, we simplify the proposition we want to show and the hypotheses using the properties of list operations and optional values. -/
/- For the case where \( l_2 \) is a non-empty list, we consider every possible case of the natural number \( i \). For each case, we simplify the proposition and the hypotheses using the properties of list operations and optional values. This simplification shows that the goal is true for each case. -/
    · cases i <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27030,List.drop_zipWith,theorem List.drop_zipWith : (zipWith f l l').drop n = zipWith f (l.drop n) (l'.drop n) := by sorry,"Distributivity of `zipWith` over `drop` : For any types $\alpha$, $\alpha_1$, and $\alpha_2$, and for any function $f : \alpha \to \alpha_1 \to \alpha_2$, and for any lists $l : \text{List } \alpha$ and $l' : \text{List } \alpha_1$, and for any natural number $n$, the result of dropping the first $n$ elements from the list obtained by applying `zipWith` to $l$ and $l'$ is equal to the list obtained by applying `zipWith` to the lists obtained by dropping the first $n$ elements from $l$ and $l'$.","theorem List.drop_zipWith : (zipWith f l l').drop n = zipWith f (l.drop n) (l'.drop n) := by
  induction l generalizing l' n with
  | nil => simp
  | cons hd tl hl =>
    · cases l'
      · simp
      · cases n
        · simp
        · simp [hl]","We proceed by induction on the list `l`.

1. **Base Case:**
- **Case 1: `l'` is empty.**
- We need to show that dropping the first `n` elements from the result of `zipWith f l []` is the same as applying `zipWith f` to the lists obtained by dropping the first `n` elements from `l` and `[]`.
- Since `zipWith f l []` is the empty list, and dropping elements from an empty list results in an empty list, the goal is trivially true.

2. **Inductive Step:**
- **Case 2: `l'` is non-empty, specifically of the form `head :: tail`.**
- We need to show that dropping the first `n` elements from the result of `zipWith f (hd :: tl) (head :: tail)` is the same as applying `zipWith f` to the lists obtained by dropping the first `n` elements from `hd :: tl` and `head :: tail`.
- We perform case analysis on the natural number `n`:
- **Subcase 1: `n` is `0`.**
- We need to show that dropping the first `0` elements from the result of `zipWith f (hd :: tl) (head :: tail)` is the same as applying `zipWith f` to the lists obtained by dropping the first `0` elements from `hd :: tl` and `head :: tail`.
- Since dropping `0` elements from a list does not change the list, the goal is trivially true.
- **Subcase 2: `n` is of the form `n' + 1`.**
- We need to show that dropping the first `n' + 1` elements from the result of `zipWith f (hd :: tl) (head :: tail)` is the same as applying `zipWith f` to the lists obtained by dropping the first `n' + 1` elements from `hd :: tl` and `head :: tail`.
- By the inductive hypothesis, we know that dropping the first `n'` elements from the result of `zipWith f tl tail` is the same as applying `zipWith f` to the lists obtained by dropping the first `n'` elements from `tl` and `tail`.
- Therefore, the goal is true by the inductive hypothesis.

This completes the proof.","theorem List.drop_zipWith : (zipWith f l l').drop n = zipWith f (l.drop n) (l'.drop n) := by
  induction l generalizing l' n with
/- We consider the case where the list `l'` is empty. In this case, the goal simplifies to showing that dropping the first `n` elements from the result of `zipWith f l []` is the same as applying `zipWith f` to the lists obtained by dropping the first `n` elements from `l` and `[]`. This is trivially true because `zipWith f l []` is the empty list, and dropping elements from an empty list results in an empty list. -/
  | nil => simp
/- We consider the case where the list `l'` is non-empty, specifically of the form `head :: tail`. We need to show that dropping the first `n` elements from the result of `zipWith f (hd :: tl) (head :: tail)` is the same as applying `zipWith f` to the lists obtained by dropping the first `n` elements from `hd :: tl` and `head :: tail`. -/
  | cons hd tl hl =>
/- We perform case analysis on the list `l'`. We consider two cases: when `l'` is empty and when `l'` is non-empty. -/
    · cases l'
/- In the case where `l'` is empty, we simplify the goal. The goal reduces to showing that dropping the first `n` elements from the result of `zipWith f (hd :: tl) []` is the same as applying `zipWith f` to the lists obtained by dropping the first `n` elements from `hd :: tl` and `[]`. This is trivially true because `zipWith f (hd :: tl) []` is the empty list, and dropping elements from an empty list results in an empty list. -/
      · simp
/- We perform case analysis on the natural number `n`. We consider two cases: when `n` is `0` and when `n` is of the form `n' + 1`. -/
      · cases n
/- In the case where `n` is `0`, we simplify the goal. The goal reduces to showing that dropping the first `0` elements from the result of `zipWith f (hd :: tl) (head :: tail)` is the same as applying `zipWith f` to the lists obtained by dropping the first `0` elements from `hd :: tl` and `head :: tail`. This is trivially true because dropping `0` elements from a list does not change the list. -/
        · simp
/- First, we simplify the goal using the hypothesis `hl`, which states that for any list `l'` and natural number `n`, dropping the first `n` elements from the result of `zipWith f tl l'` is the same as applying `zipWith f` to the lists obtained by dropping the first `n` elements from `tl` and `l'`. -/
/- In the case where `n` is of the form `n' + 1`, we simplify the goal using the hypothesis `hl`. The goal reduces to showing that dropping the first `n' + 1` elements from the result of `zipWith f (hd :: tl) (head :: tail)` is the same as applying `zipWith f` to the lists obtained by dropping the first `n' + 1` elements from `hd :: tl` and `head :: tail`. This is true by the inductive hypothesis `hl`. -/
        · simp [hl]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27033,List.map_zipWith,"theorem List.map_zipWith {δ : Type _} (f : α → β) (g : γ → δ → α) (l : List γ) (l' : List δ) :
    map f (zipWith g l l') = zipWith (fun x y => f (g x y)) l l' := by sorry","Mapping a Function over the Result of ZipWith: \( \text{map } f \, (\text{zipWith } g \, l \, l') = \text{zipWith } (\lambda x y, f(g(x, y))) \, l \, l' \) : For any types \( \alpha \), \( \beta \), \( \gamma \), and \( \delta \), and any functions \( f : \alpha \to \beta \) and \( g : \gamma \to \delta \to \alpha \), the result of applying `List.map f` to the list obtained by `List.zipWith g l l'` is equal to the list obtained by `List.zipWith` applied to the function \( \lambda x y, f(g(x, y)) \) and the lists \( l \) and \( l' \). Formally, for lists \( l : \text{List } \gamma \) and \( l' : \text{List } \delta \):
\[ \text{map } f \, (\text{zipWith } g \, l \, l') = \text{zipWith } (\lambda x y, f(g(x, y))) \, l \, l' \]","theorem List.map_zipWith {δ : Type _} (f : α → β) (g : γ → δ → α) (l : List γ) (l' : List δ) :
    map f (zipWith g l l') = zipWith (fun x y => f (g x y)) l l' := by
  induction l generalizing l' with
  | nil => simp
  | cons hd tl hl =>
    · cases l'
      · simp
      · simp [hl]","We will prove this by induction on the list \( l \).

**Base Case:**
Consider the case where \( l \) is the empty list. We need to show:
\[ \text{map } f \, (\text{zipWith } g \, [] \, l') = \text{zipWith } (\lambda x y, f(g(x, y))) \, [] \, l' \]
By the definition of `zipWith`, both sides are the empty list, so the base case is trivially true.

**Inductive Case:**
Assume the statement holds for a list \( tl \). We need to show that it holds for \( l = \text{hd} :: tl \). Specifically, we need to show:
\[ \text{map } f \, (\text{zipWith } g \, (hd :: tl) \, l') = \text{zipWith } (\lambda x y, f(g(x, y))) \, (hd :: tl) \, l' \]

We will consider two sub-cases for \( l' \):

1. **Sub-case 1: \( l' \) is the empty list.**
\[ \text{map } f \, (\text{zipWith } g \, (hd :: tl) \, []) = \text{zipWith } (\lambda x y, f(g(x, y))) \, (hd :: tl) \, [] \]
By the definition of `zipWith`, both sides are the empty list, so this sub-case is trivially true.

2. **Sub-case 2: \( l' = \text{head} :: \text{tail} \).**
\[ \text{map } f \, (\text{zipWith } g \, (hd :: tl) \, (\text{head} :: \text{tail})) = \text{zipWith } (\lambda x y, f(g(x, y))) \, (hd :: tl) \, (\text{head} :: \text{tail}) \]
By the definition of `zipWith`, the left-hand side becomes:
\[ \text{map } f \, (g(hd, \text{head}) :: \text{zipWith } g \, tl \, \text{tail}) \]
By the definition of `map`, this simplifies to:
\[ g(hd, \text{head}) :: \text{map } f \, (\text{zipWith } g \, tl \, \text{tail}) \]
By the induction hypothesis, we have:
\[ \text{map } f \, (\text{zipWith } g \, tl \, \text{tail}) = \text{zipWith } (\lambda x y, f(g(x, y))) \, tl \, \text{tail} \]
Therefore, the left-hand side becomes:
\[ g(hd, \text{head}) :: \text{zipWith } (\lambda x y, f(g(x, y))) \, tl \, \text{tail} \]
By the definition of `zipWith`, the right-hand side is:
\[ g(hd, \text{head}) :: \text{zipWith } (\lambda x y, f(g(x, y))) \, tl \, \text{tail} \]
Thus, the left-hand side and the right-hand side are equal, and the inductive case is proved.

By induction, the theorem holds for all lists \( l \) and \( l' \). This completes the proof.","theorem List.map_zipWith {δ : Type _} (f : α → β) (g : γ → δ → α) (l : List γ) (l' : List δ) :
    map f (zipWith g l l') = zipWith (fun x y => f (g x y)) l l' := by
  induction l generalizing l' with
/- We consider the base case where \( l' \) is the empty list. In this case, the goal simplifies to \( \text{map } f \, (\text{zipWith } g \, (hd :: tl) \, []) = \text{zipWith } (\lambda x y, f(g(x, y))) \, (hd :: tl) \, [] \). Since both sides are the empty list, the goal is trivially true. -/
  | nil => simp
/- We consider the inductive case where \( l' \) is a non-empty list, specifically \( l' = \text{head} :: \text{tail} \). We need to show that \( \text{map } f \, (\text{zipWith } g \, (hd :: tl) \, (\text{head} :: \text{tail})) = \text{zipWith } (\lambda x y, f(g(x, y))) \, (hd :: tl) \, (\text{head} :: \text{tail}) \). -/
  | cons hd tl hl =>
/- We will discuss every possible case of \( l' \). Case 1: \( l' \) is the empty list. Case 2: \( l' \) is a non-empty list, specifically \( l' = \text{head} :: \text{tail} \). -/
    · cases l'
/- For the base case where \( l' \) is the empty list, the goal simplifies to \( \text{map } f \, (\text{zipWith } g \, (hd :: tl) \, []) = \text{zipWith } (\lambda x y, f(g(x, y))) \, (hd :: tl) \, [] \). Since both sides are the empty list, the goal is trivially true. -/
      · simp
/- Using the induction hypothesis \( hl \), we simplify the goal to show that \( \text{map } f \, (\text{zipWith } g \, (hd :: tl) \, l') = \text{zipWith } (\lambda x y, f(g(x, y))) \, (hd :: tl) \, l' \). -/
/- For the inductive case where \( l' = \text{head} :: \text{tail} \), we use the induction hypothesis \( hl \) to simplify the goal. The goal simplifies to \( \text{map } f \, (\text{zipWith } g \, (hd :: tl) \, (\text{head} :: \text{tail})) = \text{zipWith } (\lambda x y, f(g(x, y))) \, (hd :: tl) \, (\text{head} :: \text{tail}) \). By the definition of `zipWith` and `map`, this reduces to:
\[ \text{map } f \, (g(hd, \text{head}) :: \text{zipWith } g \, tl \, \text{tail}) = g(hd, \text{head}) :: \text{zipWith } (\lambda x y, f(g(x, y))) \, tl \, \text{tail} \]
Using the induction hypothesis \( hl \), we have:
\[ \text{map } f \, (\text{zipWith } g \, tl \, \text{tail}) = \text{zipWith } (\lambda x y, f(g(x, y))) \, tl \, \text{tail} \]
Thus, the goal is satisfied. -/
      · simp [hl]","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27038,List.zipWith_map_right,"theorem List.zipWith_map_right (l₁ : List α) (l₂ : List β) (f : β → β') (g : α → β' → γ) :
    zipWith g l₁ (l₂.map f) = zipWith (fun a b => g a (f b)) l₁ l₂ := by sorry","ZipWith Preserves Mapping on Right List: \(\text{zipWith } g \, l_1 \, (\text{map } f \, l_2) = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, l_1 \, l_2\) : For any lists \( l_1 \) of type \( \alpha \) and \( l_2 \) of type \( \beta \), and for any functions \( f : \beta \to \beta' \) and \( g : \alpha \to \beta' \to \gamma \), the following equality holds:
\[ \text{zipWith } g \, l_1 \, (\text{map } f \, l_2) = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, l_1 \, l_2 \]","theorem List.zipWith_map_right (l₁ : List α) (l₂ : List β) (f : β → β') (g : α → β' → γ) :
    zipWith g l₁ (l₂.map f) = zipWith (fun a b => g a (f b)) l₁ l₂ := by
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","We will prove this theorem by induction on the list \( l_1 \) while generalizing over \( l_2 \).

**Base Case:**
Consider the case where \( l_1 \) is the empty list, i.e., \( l_1 = [] \).

- If \( l_2 \) is also the empty list, i.e., \( l_2 = [] \), then:
\[
\text{zipWith } g \, [] \, (\text{map } f \, []) = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, [] \, []
\]
This simplifies to:
\[
[] = []
\]
which is trivially true.

- If \( l_2 \) is a non-empty list, i.e., \( l_2 = [head \, :: \, tail] \), then:
\[
\text{zipWith } g \, [] \, (\text{map } f \, [head \, :: \, tail]) = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, [] \, [head \, :: \, tail]
\]
This simplifies to:
\[
[] = []
\]
which is trivially true.

**Inductive Step:**
Assume the theorem holds for a list \( l_1 = [head \, :: \, tail] \). We need to show that it holds for \( l_1 = [head \, :: \, tail] \).

- If \( l_2 \) is the empty list, i.e., \( l_2 = [] \), then:
\[
\text{zipWith } g \, [head \, :: \, tail] \, (\text{map } f \, []) = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, [head \, :: \, tail] \, []
\]
This simplifies to:
\[
[] = []
\]
which is trivially true.

- If \( l_2 \) is a non-empty list, i.e., \( l_2 = [head' \, :: \, tail'] \), then:
\[
\text{zipWith } g \, [head \, :: \, tail] \, (\text{map } f \, [head' \, :: \, tail']) = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, [head \, :: \, tail] \, [head' \, :: \, tail']
\]
This simplifies to:
\[
g \, head \, (f \, head') \, :: \, \text{zipWith } g \, tail \, (\text{map } f \, tail') = g \, head \, (f \, head') \, :: \, \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, tail \, tail'
\]
By the inductive hypothesis, we know that:
\[
\text{zipWith } g \, tail \, (\text{map } f \, tail') = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, tail \, tail'
\]
Thus, the equality holds.

Therefore, by induction, the theorem is true for all lists \( l_1 \) and \( l_2 \). This completes the proof.","theorem List.zipWith_map_right (l₁ : List α) (l₂ : List β) (f : β → β') (g : α → β' → γ) :
    zipWith g l₁ (l₂.map f) = zipWith (fun a b => g a (f b)) l₁ l₂ := by
/- We perform induction on the list \( l_1 \) while generalizing over \( l_2 \). For each case of \( l_1 \), we further perform case analysis on \( l_2 \). Then, we simplify the resulting goals using the properties of list operations and the definitions of `zipWith` and `map`. -/
/- We perform induction on the list \( l_1 \) while generalizing over \( l_2 \). This means we will consider two cases: the base case where \( l_1 \) is the empty list, and the inductive step where \( l_1 \) is a non-empty list. -/
/- We will discuss every possible case of \( l_2 \). Specifically, we consider two cases: \( l_2 \) is the empty list and \( l_2 \) is a non-empty list. -/
/- We will discuss every possible case of \( l_2 \). Specifically, we consider two cases: \( l_2 \) is the empty list and \( l_2 \) is a non-empty list. -/
/- Using the properties of list operations and the definitions of `zipWith` and `map`, we simplify the proposition to show that:
\[ \text{zipWith } g \, [] \, (\text{map } f \, []) = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, [] \, [] \]
This simplifies to:
\[ [] = [] \]
which is trivially true. -/
/- Using the properties of list operations and the definitions of `zipWith` and `map`, we simplify the proposition to show that:
\[ \text{zipWith } g \, [] \, (\text{map } f \, (head \, :: \, tail)) = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, [] \, (head \, :: \, tail) \]
This simplifies to:
\[ [] = [] \]
which is trivially true. -/
/- Using the properties of list operations and the definitions of `zipWith` and `map`, we simplify the proposition to show that:
\[ \text{zipWith } g \, (head \, :: \, tail) \, (\text{map } f \, []) = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, (head \, :: \, tail) \, [] \]
This simplifies to:
\[ [] = [] \]
which is trivially true. -/
/- Using the properties of list operations and the definitions of `zipWith` and `map`, we simplify the proposition to show that:
\[ \text{zipWith } g \, (head \, :: \, tail) \, (\text{map } f \, (head' \, :: \, tail')) = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, (head \, :: \, tail) \, (head' \, :: \, tail') \]
This simplifies to:
\[ g \, head \, (f \, head') \, :: \, \text{zipWith } g \, tail \, (\text{map } f \, tail') = g \, head \, (f \, head') \, :: \, \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, tail \, tail' \]
By the inductive hypothesis, we know that:
\[ \text{zipWith } g \, tail \, (\text{map } f \, tail') = \text{zipWith } (\lambda a \, b, \, g \, a \, (f \, b)) \, tail \, tail' \]
Thus, the equality holds. -/
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27039,List.zipWith_map_left,"theorem List.zipWith_map_left (l₁ : List α) (l₂ : List β) (f : α → α') (g : α' → β → γ) :
    zipWith g (l₁.map f) l₂ = zipWith (fun a b => g (f a) b) l₁ l₂ := by sorry","Left Mapping Preserves ZipWith Operation in Lists : For any lists \( l_1 \) and \( l_2 \) of types \( \alpha \) and \( \beta \) respectively, and for any functions \( f : \alpha \to \alpha' \) and \( g : \alpha' \to \beta \to \gamma \), the following equality holds:
\[ \text{zipWith } g \, (\text{map } f \, l_1) \, l_2 = \text{zipWith } (\lambda a \, b, \, g (f a) \, b) \, l_1 \, l_2 \]","theorem List.zipWith_map_left (l₁ : List α) (l₂ : List β) (f : α → α') (g : α' → β → γ) :
    zipWith g (l₁.map f) l₂ = zipWith (fun a b => g (f a) b) l₁ l₂ := by
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","We will prove the theorem by induction on the list \( l_1 \) while generalizing over \( l_2 \).

**Base Case:**
1. **Case 1: \( l_1 = [] \) and \( l_2 = [] \)**
- We need to show:
\[
\text{zipWith } g \, (\text{map } f \, []) \, [] = \text{zipWith } (\lambda a \, b, \, g (f a) \, b) \, [] \, []
\]
- By the definition of `map` and `zipWith`, both sides are the empty list:
\[
\text{zipWith } g \, [] \, [] = []
\]
\[
\text{zipWith } (\lambda a \, b, \, g (f a) \, b) \, [] \, [] = []
\]
- Therefore, the equality holds.

2. **Case 2: \( l_1 = [] \) and \( l_2 = y :: l_2' \)**
- We need to show:
\[
\text{zipWith } g \, (\text{map } f \, []) \, (y :: l_2') = \text{zipWith } (\lambda a \, b, \, g (f a) \, b) \, [] \, (y :: l_2')
\]
- By the definition of `map` and `zipWith`, both sides are the empty list:
\[
\text{zipWith } g \, [] \, (y :: l_2') = []
\]
\[
\text{zipWith } (\lambda a \, b, \, g (f a) \, b) \, [] \, (y :: l_2') = []
\]
- Therefore, the equality holds.

**Inductive Step:**
Assume the theorem holds for a list \( l_1' \) (inductive hypothesis). We need to show it holds for \( l_1 = x :: l_1' \).

1. **Case 1: \( l_1 = x :: l_1' \) and \( l_2 = [] \)**
- We need to show:
\[
\text{zipWith } g \, (\text{map } f \, (x :: l_1')) \, [] = \text{zipWith } (\lambda a \, b, \, g (f a) \, b) \, (x :: l_1') \, []
\]
- By the definition of `map` and `zipWith`, both sides are the empty list:
\[
\text{zipWith } g \, (f x :: \text{map } f \, l_1') \, [] = []
\]
\[
\text{zipWith } (\lambda a \, b, \, g (f a) \, b) \, (x :: l_1') \, [] = []
\]
- Therefore, the equality holds.

2. **Case 2: \( l_1 = x :: l_1' \) and \( l_2 = y :: l_2' \)**
- We need to show:
\[
\text{zipWith } g \, (\text{map } f \, (x :: l_1')) \, (y :: l_2') = \text{zipWith } (\lambda a \, b, \, g (f a) \, b) \, (x :: l_1') \, (y :: l_2')
\]
- By the definition of `map` and `zipWith`, we have:
\[
\text{zipWith } g \, (f x :: \text{map } f \, l_1') \, (y :: l_2') = g (f x) y :: \text{zipWith } g \, (\text{map } f \, l_1') \, l_2'
\]
\[
\text{zipWith } (\lambda a \, b, \, g (f a) \, b) \, (x :: l_1') \, (y :: l_2') = g (f x) y :: \text{zipWith } (\lambda a \, b, \, g (f a) \, b) \, l_1' \, l_2'
\]
- By the inductive hypothesis, we have:
\[
\text{zipWith } g \, (\text{map } f \, l_1') \, l_2' = \text{zipWith } (\lambda a \, b, \, g (f a) \, b) \, l_1' \, l_2'
\]
- Therefore, the equality holds.

By induction, the theorem is proved. \(\blacksquare\)","theorem List.zipWith_map_left (l₁ : List α) (l₂ : List β) (f : α → α') (g : α' → β → γ) :
    zipWith g (l₁.map f) l₂ = zipWith (fun a b => g (f a) b) l₁ l₂ := by
/- We perform induction on the list \( l_1 \) while generalizing over \( l_2 \). For each case of \( l_1 \), we further split \( l_2 \) into its possible cases (empty or non-empty). Then, we simplify the resulting goals using the properties of list operations and the definitions of `map` and `zipWith`. -/
/- We perform induction on the list \( l_1 \) while generalizing over \( l_2 \). This means we will consider two cases: the base case where \( l_1 \) is the empty list, and the inductive step where \( l_1 \) is a list with a head element and a tail. -/
/- We will discuss every possible case of \( l_2 \). Specifically, we consider two cases: \( l_2 \) is the empty list, and \( l_2 \) is a non-empty list with a head element and a tail. -/
/- We will discuss every possible case of \( l_2 \). Specifically, we consider two cases: \( l_2 \) is the empty list, and \( l_2 \) is a non-empty list with a head element and a tail. -/
/- Using the properties of list operations and the definitions of `map` and `zipWith`, we simplify the proposition to show that the equality holds. Specifically, we use the fact that `zipWith` applied to an empty list and any other list results in an empty list, and the definition of `map` on an empty list. -/
/- Using the properties of list operations and the definitions of `map` and `zipWith`, we simplify the proposition to show that the equality holds. Specifically, we use the fact that `zipWith` applied to an empty list and any other list results in an empty list, and the definition of `map` on an empty list. -/
/- Using the properties of list operations and the definitions of `map` and `zipWith`, we simplify the proposition to show that the equality holds. Specifically, we use the fact that `zipWith` applied to a non-empty list and an empty list results in an empty list, and the definition of `map` on a non-empty list. -/
/- Using the properties of list operations and the definitions of `map` and `zipWith`, we simplify the proposition to show that the equality holds. Specifically, we use the fact that `zipWith` applied to a non-empty list and an empty list results in an empty list, and the definition of `map` on a non-empty list. -/
/- Using the properties of list operations and the definitions of `map` and `zipWith`, we simplify the proposition to show that the equality holds. Specifically, we use the inductive hypothesis and the definition of `map` and `zipWith` to show that the equality holds for the inductive step. -/
/- Using the properties of list operations and the definitions of `map` and `zipWith`, we simplify the proposition to show that the equality holds. Specifically, we use the inductive hypothesis and the definition of `map` and `zipWith` to show that the equality holds for the inductive step. -/
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27046,List.zipWithAll_map,"theorem List.zipWithAll_map {μ} (f : Option γ → Option δ → μ) (g : α → γ) (h : β → δ) (l₁ : List α) (l₂ : List β) :
    zipWithAll f (l₁.map g) (l₂.map h) = zipWithAll (fun a b => f (g <$> a) (h <$> b)) l₁ l₂ := by sorry","ZipWithAll Distributes Over Map Operations : For any types \( \gamma \), \( \delta \), \( \alpha \), and \( \beta \), and any function \( f : \text{Option} \, \gamma \to \text{Option} \, \delta \to \mu \), the function \( g : \alpha \to \gamma \), and the function \( h : \beta \to \delta \), and for any lists \( l_1 : \text{List} \, \alpha \) and \( l_2 : \text{List} \, \beta \), the following equality holds:
\[
\text{zipWithAll} \, f \, (\text{map} \, g \, l_1) \, (\text{map} \, h \, l_2) = \text{zipWithAll} \, (\lambda a \, b, \, f \, (g \, a) \, (h \, b)) \, l_1 \, l_2
\]
This theorem states that applying `zipWithAll` to the results of mapping functions \( g \) and \( h \) over lists \( l_1 \) and \( l_2 \) respectively is equivalent to applying `zipWithAll` to the original lists \( l_1 \) and \( l_2 \) with a modified function that first applies \( g \) and \( h \) to the elements of the lists before applying \( f \).","theorem List.zipWithAll_map {μ} (f : Option γ → Option δ → μ) (g : α → γ) (h : β → δ) (l₁ : List α) (l₂ : List β) :
    zipWithAll f (l₁.map g) (l₂.map h) = zipWithAll (fun a b => f (g <$> a) (h <$> b)) l₁ l₂ := by
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","We will prove the theorem by induction on the list \( l_1 \) while generalizing over \( l_2 \).

1. **Base Case: \( l_1 = [] \)**
- We perform case analysis on \( l_2 \):
- **Case 1: \( l_2 = [] \)**
- We need to show:
\[
\text{zipWithAll} \, f \, (\text{map} \, g \, []) \, (\text{map} \, h \, []) = \text{zipWithAll} \, (\lambda a \, b, \, f \, (g \, a) \, (h \, b)) \, [] \, []
\]
- Simplifying both sides, we get:
\[
\text{zipWithAll} \, f \, [] \, [] = \text{zipWithAll} \, (\lambda a \, b, \, f \, (g \, a) \, (h \, b)) \, [] \, []
\]
- Both sides are the empty list, so the equality holds.
- **Case 2: \( l_2 = \text{head} \, :: \, \text{tail} \)**
- We need to show:
\[
\text{zipWithAll} \, f \, (\text{map} \, g \, []) \, (\text{map} \, h \, (\text{head} \, :: \, \text{tail})) = \text{zipWithAll} \, (\lambda a \, b, \, f \, (g \, a) \, (h \, b)) \, [] \, (\text{head} \, :: \, \text{tail})
\]
- Simplifying both sides, we get:
\[
\text{zipWithAll} \, f \, [] \, (\text{map} \, h \, (\text{head} \, :: \, \text{tail})) = \text{zipWithAll} \, (\lambda a \, b, \, f \, (g \, a) \, (h \, b)) \, [] \, (\text{head} \, :: \, \text{tail})
\]
- Both sides are the empty list, so the equality holds.

2. **Inductive Step: \( l_1 = \text{head} \, :: \, \text{tail} \)**
- We assume the inductive hypothesis:
\[
\forall \, l_2, \, \text{zipWithAll} \, f \, (\text{map} \, g \, \text{tail}) \, (\text{map} \, h \, l_2) = \text{zipWithAll} \, (\lambda a \, b, \, f \, (g \, a) \, (h \, b)) \, \text{tail} \, l_2
\]
- We perform case analysis on \( l_2 \):
- **Case 1: \( l_2 = [] \)**
- We need to show:
\[
\text{zipWithAll} \, f \, (\text{map} \, g \, (\text{head} \, :: \, \text{tail})) \, (\text{map} \, h \, []) = \text{zipWithAll} \, (\lambda a \, b, \, f \, (g \, a) \, (h \, b)) \, (\text{head} \, :: \, \text{tail}) \, []
\]
- Simplifying both sides, we get:
\[
\text{zipWithAll} \, f \, (\text{map} \, g \, (\text{head} \, :: \, \text{tail})) \, [] = \text{zipWithAll} \, (\lambda a \, b, \, f \, (g \, a) \, (h \, b)) \, (\text{head} \, :: \, \text{tail}) \, []
\]
- Both sides are the empty list, so the equality holds.
- **Case 2: \( l_2 = \text{head} \, :: \, \text{tail} \)**
- We need to show:
\[
\text{zipWithAll} \, f \, (\text{map} \, g \, (\text{head} \, :: \, \text{tail})) \, (\text{map} \, h \, (\text{head} \, :: \, \text{tail})) = \text{zipWithAll} \, (\lambda a \, b, \, f \, (g \, a) \, (h \, b)) \, (\text{head} \, :: \, \text{tail}) \, (\text{head} \, :: \, \text{tail})
\]
- Using the inductive hypothesis, we can simplify the left-hand side:
\[
\text{zipWithAll} \, f \, (\text{map} \, g \, (\text{head} \, :: \, \text{tail})) \, (\text{map} \, h \, (\text{head} \, :: \, \text{tail})) = f \, (g \, \text{head}) \, (h \, \text{head}) \, :: \, \text{zipWithAll} \, f \, (\text{map} \, g \, \text{tail}) \, (\text{map} \, h \, \text{tail})
\]
- Using the inductive hypothesis again, we get:
\[
f \, (g \, \text{head}) \, (h \, \text{head}) \, :: \, \text{zipWithAll} \, (\lambda a \, b, \, f \, (g \, a) \, (h \, b)) \, \text{tail} \, \text{tail}
\]
- This is equal to:
\[
\text{zipWithAll} \, (\lambda a \, b, \, f \, (g \, a) \, (h \, b)) \, (\text{head} \, :: \, \text{tail}) \, (\text{head} \, :: \, \text{tail})
\]
- Therefore, the equality holds.

By induction, the theorem is proved. \(\blacksquare\)","theorem List.zipWithAll_map {μ} (f : Option γ → Option δ → μ) (g : α → γ) (h : β → δ) (l₁ : List α) (l₂ : List β) :
    zipWithAll f (l₁.map g) (l₂.map h) = zipWithAll (fun a b => f (g <$> a) (h <$> b)) l₁ l₂ := by
/- We perform induction on the list \( l_1 \) while generalizing over \( l_2 \). For each case of \( l_1 \), we further perform case analysis on \( l_2 \). Then, we simplify the resulting goals using the simplification lemmas and hypotheses. -/
/- We perform induction on the list \( l_1 \) while generalizing over \( l_2 \). This means we will consider two cases: the base case where \( l_1 \) is the empty list, and the inductive step where \( l_1 \) is a non-empty list. -/
/- We perform case analysis on the list \( l_2 \). This means we will consider two cases: the base case where \( l_2 \) is the empty list, and the inductive step where \( l_2 \) is a non-empty list. -/
/- We simplify the resulting goals using the simplification lemmas and hypotheses. This step ensures that the goals are reduced to trivially true statements. -/
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27058,List.zipWith_foldr_eq_zip_foldr,"theorem List.zipWith_foldr_eq_zip_foldr {f : α → β → γ} (i : δ):
    (zipWith f l₁ l₂).foldr g i = (zip l₁ l₂).foldr (fun p r => g (f p.1 p.2) r) i := by sorry","Right Fold on ZipWith Equals Right Fold on Zip with Function Applied : For any types $\alpha$, $\beta$, $\gamma$, and $\delta$, and for any lists $l_1 : \text{List } \alpha$ and $l_2 : \text{List } \beta$, and for any functions $f : \alpha \to \beta \to \gamma$ and $g : \gamma \to \delta \to \delta$, and for any initial value $i : \delta$, the following equality holds:
\[ \text{foldr } g \, i \, (\text{zipWith } f \, l_1 \, l_2) = \text{foldr } (\lambda p \, r. \, g (f (p.1) (p.2)) \, r) \, i \, (l_1 \text{.zip } l_2) \]","theorem List.zipWith_foldr_eq_zip_foldr {f : α → β → γ} (i : δ):
    (zipWith f l₁ l₂).foldr g i = (zip l₁ l₂).foldr (fun p r => g (f p.1 p.2) r) i := by
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","We prove the theorem by induction on the list \( l_1 \) and generalize over \( l_2 \).

**Base Case:**
1. **Case 1: \( l_1 = [] \) and \( l_2 = [] \)**
- The left-hand side is:
\[ \text{foldr } g \, i \, (\text{zipWith } f \, [] \, []) = \text{foldr } g \, i \, [] = i \]
- The right-hand side is:
\[ \text{foldr } (\lambda p \, r. \, g (f (p.1) (p.2)) \, r) \, i \, ([].zip []) = \text{foldr } (\lambda p \, r. \, g (f (p.1) (p.2)) \, r) \, i \, [] = i \]
- Therefore, the base case holds.

2. **Case 2: \( l_1 = [] \) and \( l_2 = \text{head} \, l_2 :: \text{tail} \, l_2 \)**
- The left-hand side is:
\[ \text{foldr } g \, i \, (\text{zipWith } f \, [] \, (\text{head} \, l_2 :: \text{tail} \, l_2)) = \text{foldr } g \, i \, [] = i \]
- The right-hand side is:
\[ \text{foldr } (\lambda p \, r. \, g (f (p.1) (p.2)) \, r) \, i \, ([].zip (\text{head} \, l_2 :: \text{tail} \, l_2)) = \text{foldr } (\lambda p \, r. \, g (f (p.1) (p.2)) \, r) \, i \, [] = i \]
- Therefore, the base case holds.

**Inductive Step:**
Assume the property holds for the tails of the lists \( l_1 \) and \( l_2 \). We need to show that it holds for the lists \( l_1 = \text{head} \, l_1 :: \text{tail} \, l_1 \) and \( l_2 = \text{head} \, l_2 :: \text{tail} \, l_2 \).

1. **Case 1: \( l_1 = \text{head} \, l_1 :: \text{tail} \, l_1 \) and \( l_2 = [] \)**
- The left-hand side is:
\[ \text{foldr } g \, i \, (\text{zipWith } f \, (\text{head} \, l_1 :: \text{tail} \, l_1) \, []) = \text{foldr } g \, i \, [] = i \]
- The right-hand side is:
\[ \text{foldr } (\lambda p \, r. \, g (f (p.1) (p.2)) \, r) \, i \, ((\text{head} \, l_1 :: \text{tail} \, l_1).zip []) = \text{foldr } (\lambda p \, r. \, g (f (p.1) (p.2)) \, r) \, i \, [] = i \]
- Therefore, the inductive step holds.

2. **Case 2: \( l_1 = \text{head} \, l_1 :: \text{tail} \, l_1 \) and \( l_2 = \text{head} \, l_2 :: \text{tail} \, l_2 \)**
- The left-hand side is:
\[ \text{foldr } g \, i \, (\text{zipWith } f \, (\text{head} \, l_1 :: \text{tail} \, l_1) \, (\text{head} \, l_2 :: \text{tail} \, l_2)) = \text{foldr } g \, i \, (f (\text{head} \, l_1) (\text{head} \, l_2) :: \text{zipWith } f \, (\text{tail} \, l_1) \, (\text{tail} \, l_2)) \]
- By the inductive hypothesis:
\[ \text{foldr } g \, i \, (f (\text{head} \, l_1) (\text{head} \, l_2) :: \text{zipWith } f \, (\text{tail} \, l_1) \, (\text{tail} \, l_2)) = g (f (\text{head} \, l_1) (\text{head} \, l_2)) (\text{foldr } g \, i \, (\text{zipWith } f \, (\text{tail} \, l_1) \, (\text{tail} \, l_2))) \]
- The right-hand side is:
\[ \text{foldr } (\lambda p \, r. \, g (f (p.1) (p.2)) \, r) \, i \, ((\text{head} \, l_1 :: \text{tail} \, l_1).zip (\text{head} \, l_2 :: \text{tail} \, l_2)) = \text{foldr } (\lambda p \, r. \, g (f (p.1) (p.2)) \, r) \, i \, ((\text{head} \, l_1, \text{head} \, l_2) :: (\text{tail} \, l_1).zip (\text{tail} \, l_2)) \]
- By the inductive hypothesis:
\[ \text{foldr } (\lambda p \, r. \, g (f (p.1) (p.2)) \, r) \, i \, ((\text{head} \, l_1, \text{head} \, l_2) :: (\text{tail} \, l_1).zip (\text{tail} \, l_2)) = g (f (\text{head} \, l_1) (\text{head} \, l_2)) (\text{foldr } (\lambda p \, r. \, g (f (p.1) (p.2)) \, r) \, i \, ((\text{tail} \, l_1).zip (\text{tail} \, l_2))) \]
- Therefore, the inductive step holds.

By induction, the theorem is proved. \(\blacksquare\)","theorem List.zipWith_foldr_eq_zip_foldr {f : α → β → γ} (i : δ):
    (zipWith f l₁ l₂).foldr g i = (zip l₁ l₂).foldr (fun p r => g (f p.1 p.2) r) i := by
/- We perform induction on the list \( l_1 \) and generalize over \( l_2 \). For each case of \( l_1 \), we further perform case analysis on \( l_2 \). Then, we simplify the resulting goals using the properties of list operations and the definitions of `zipWith` and `foldr`. -/
/- We perform induction on the list \( l_1 \) and generalize over \( l_2 \). This means we will consider the base case where \( l_1 \) is the empty list and the inductive step where \( l_1 \) is a non-empty list. -/
/- For the base case where \( l_1 \) is the empty list, we perform case analysis on \( l_2 \). This means we consider two cases: \( l_2 \) is the empty list and \( l_2 \) is a non-empty list. -/
/- For the inductive step where \( l_1 \) is a non-empty list, we perform case analysis on \( l_2 \). This means we consider two cases: \( l_2 \) is the empty list and \( l_2 \) is a non-empty list. -/
/- For the base case where both \( l_1 \) and \( l_2 \) are empty lists, we simplify the goal using the properties of `zipWith` and `foldr`. Since both lists are empty, `zipWith f [] []` is the empty list, and `foldr g i []` is simply \( i \). Therefore, the left-hand side and the right-hand side of the equation are both \( i \), and the goal is trivially true. -/
/- For the base case where \( l_1 \) is the empty list and \( l_2 \) is a non-empty list, we simplify the goal using the properties of `zipWith` and `foldr`. Since \( l_1 \) is empty, `zipWith f [] (head :: tail)` is the empty list, and `foldr g i []` is simply \( i \). On the right-hand side, `[].zip (head :: tail)` is also the empty list, and `foldr (fun p r => g (f p.fst p.snd) r) i []` is \( i \). Therefore, the left-hand side and the right-hand side of the equation are both \( i \), and the goal is trivially true. -/
/- For the inductive step where \( l_1 \) is a non-empty list and \( l_2 \) is the empty list, we simplify the goal using the properties of `zipWith` and `foldr`. Since \( l_2 \) is empty, `zipWith f (head :: tail) []` is the empty list, and `foldr g i []` is simply \( i \). On the right-hand side, `(head :: tail).zip []` is also the empty list, and `foldr (fun p r => g (f p.fst p.snd) r) i []` is \( i \). Therefore, the left-hand side and the right-hand side of the equation are both \( i \), and the goal is trivially true. -/
/- For the inductive step where both \( l_1 \) and \( l_2 \) are non-empty lists, we simplify the goal using the properties of `zipWith` and `foldr`. We use the inductive hypothesis that the property holds for the tails of the lists. Specifically, we have:
\[ \text{foldr } g \, i \, (\text{zipWith } f \, (tail \, l_1) \, (tail \, l_2)) = \text{foldr } (fun p r => g (f p.fst p.snd) r) \, i \, ((tail \, l_1).zip (tail \, l_2)) \]
Using this, we can show that:
\[ \text{foldr } g \, i \, (\text{zipWith } f \, (head \, l_1 :: tail \, l_1) \, (head \, l_2 :: tail \, l_2)) = \text{foldr } (fun p r => g (f p.fst p.snd) r) \, i \, ((head \, l_1 :: tail \, l_1).zip (head \, l_2 :: tail \, l_2)) \]
This completes the proof for the inductive step. -/
  induction l₁ generalizing l₂ <;> cases l₂ <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27063,List.map_zipWithAll,"theorem List.map_zipWithAll {δ : Type _} (f : α → β) (g : Option γ → Option δ → α) (l : List γ) (l' : List δ) :
    map f (zipWithAll g l l') = zipWithAll (fun x y => f (g x y)) l l' := by sorry","Mapping Preserves `zipWithAll` Operation in Lists: \( \text{map} \, f \, (\text{zipWithAll} \, g \, l \, l') = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, l \, l' \) : For any types \( \alpha \), \( \beta \), \( \gamma \), and \( \delta \), and for any function \( f : \alpha \to \beta \) and a function \( g : \text{Option} \, \gamma \to \text{Option} \, \delta \to \alpha \), and lists \( l : \text{List} \, \gamma \) and \( l' : \text{List} \, \delta \), the following holds:
\[
\text{map} \, f \, (\text{zipWithAll} \, g \, l \, l') = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, l \, l'
\]
In other words, applying the function \( f \) to each element of the list obtained by zipping \( l \) and \( l' \) using \( g \) is the same as zipping \( l \) and \( l' \) using a modified version of \( g \) that applies \( f \) to the result of \( g \) before zipping.","theorem List.map_zipWithAll {δ : Type _} (f : α → β) (g : Option γ → Option δ → α) (l : List γ) (l' : List δ) :
    map f (zipWithAll g l l') = zipWithAll (fun x y => f (g x y)) l l' := by
  induction l generalizing l' with
  | nil => simp
  | cons hd tl hl =>
    cases l' <;> simp_all","We will prove this by induction on the list \( l \).

**Base Case:**
Consider the case where \( l \) is the empty list. We need to show that:
\[
\text{map} \, f \, (\text{zipWithAll} \, g \, [] \, l') = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, [] \, l'
\]
Using the properties of the `zipWithAll` and `map` functions, this simplifies to:
\[
\text{map} \, f \, [] = []
\]
which is trivially true.

**Inductive Step:**
Assume the statement holds for a list \( tl \), i.e., for any list \( l' \):
\[
\text{map} \, f \, (\text{zipWithAll} \, g \, tl \, l') = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, tl \, l'
\]
We need to show that the statement holds for the list \( l = \text{cons} \, \text{hd} \, \text{tl} \). We will consider two cases for \( l' \):

- **Case 1: \( l' \) is the empty list.**
Using the properties of the `zipWithAll` and `map` functions, we can simplify the proposition to show that:
\[
\text{map} \, f \, (\text{zipWithAll} \, g \, (hd :: tl) \, []) = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, (hd :: tl) \, []
\]
This simplifies to:
\[
\text{map} \, f \, [] = []
\]
which is trivially true.

- **Case 2: \( l' \) is a non-empty list, specifically \( l' = \text{cons} \, \text{head} \, \text{tail} \).**
Using the properties of the `zipWithAll` and `map` functions, we can simplify the proposition to show that:
\[
\text{map} \, f \, (\text{zipWithAll} \, g \, (hd :: tl) \, (head :: tail)) = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, (hd :: tl) \, (head :: tail)
\]
This simplifies to:
\[
\text{map} \, f \, (\text{cons} \, (g \, (\text{some} \, hd) \, (\text{some} \, head)) \, (\text{zipWithAll} \, g \, tl \, tail)) = \text{cons} \, (f \, (g \, (\text{some} \, hd) \, (\text{some} \, head))) \, (\text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, tl \, tail)
\]
By the induction hypothesis, we know that:
\[
\text{map} \, f \, (\text{zipWithAll} \, g \, tl \, tail) = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, tl \, tail
\]
Therefore, the left-hand side simplifies to:
\[
\text{cons} \, (f \, (g \, (\text{some} \, hd) \, (\text{some} \, head))) \, (\text{map} \, f \, (\text{zipWithAll} \, g \, tl \, tail))
\]
which is equal to the right-hand side:
\[
\text{cons} \, (f \, (g \, (\text{some} \, hd) \, (\text{some} \, head))) \, (\text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, tl \, tail)
\]
This completes the proof for this case.

By induction, the statement holds for all lists \( l \). Therefore, the theorem is proved. \(\blacksquare\)","theorem List.map_zipWithAll {δ : Type _} (f : α → β) (g : Option γ → Option δ → α) (l : List γ) (l' : List δ) :
    map f (zipWithAll g l l') = zipWithAll (fun x y => f (g x y)) l l' := by
  induction l generalizing l' with
/- First, consider the case where \( l' \) is the empty list. Using the properties of the `zipWithAll` and `map` functions, we can simplify the proposition to show that:
\[
\text{map} \, f \, (\text{zipWithAll} \, g \, l \, []) = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, l \, []
\]
This simplifies to:
\[
\text{map} \, f \, [] = []
\]
which is trivially true. -/
  | nil => simp
/- Next, consider the case where \( l' \) is a non-empty list, specifically \( l' = \text{cons} \, \text{hd} \, \text{tl} \). We will use the induction hypothesis \( \text{hl} \) which states that for any list \( l' \), the following holds:
\[
\text{map} \, f \, (\text{zipWithAll} \, g \, \text{tl} \, l') = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, \text{tl} \, l'
\] -/
  | cons hd tl hl =>
/- We will consider every possible case of the list \( l' \). For each case, we will simplify the proposition and the hypotheses using the properties of the `zipWithAll` and `map` functions. -/
/- We will consider every possible case of the list \( l' \) again. For each case, we will simplify the proposition and the hypotheses using the properties of the `zipWithAll` and `map` functions.

- **Case 1: \( l' \) is the empty list.**
Using the properties of the `zipWithAll` and `map` functions, we can simplify the proposition to show that:
\[
\text{map} \, f \, (\text{zipWithAll} \, g \, (hd :: tl) \, []) = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, (hd :: tl) \, []
\]
This simplifies to:
\[
\text{map} \, f \, [] = []
\]
which is trivially true.

- **Case 2: \( l' \) is a non-empty list, specifically \( l' = \text{cons} \, \text{head} \, \text{tail} \).**
Using the properties of the `zipWithAll` and `map` functions, we can simplify the proposition to show that:
\[
\text{map} \, f \, (\text{zipWithAll} \, g \, (hd :: tl) \, (head :: tail)) = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, (hd :: tl) \, (head :: tail)
\]
This simplifies to:
\[
\text{map} \, f \, (\text{cons} \, (g \, (\text{some} \, hd) \, (\text{some} \, head)) \, (\text{zipWithAll} \, g \, tl \, tail)) = \text{cons} \, (f \, (g \, (\text{some} \, hd) \, (\text{some} \, head))) \, (\text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, tl \, tail)
\]
By the induction hypothesis, we know that:
\[
\text{map} \, f \, (\text{zipWithAll} \, g \, tl \, tail) = \text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, tl \, tail
\]
Therefore, the left-hand side simplifies to:
\[
\text{cons} \, (f \, (g \, (\text{some} \, hd) \, (\text{some} \, head))) \, (\text{map} \, f \, (\text{zipWithAll} \, g \, tl \, tail))
\]
which is equal to the right-hand side:
\[
\text{cons} \, (f \, (g \, (\text{some} \, hd) \, (\text{some} \, head))) \, (\text{zipWithAll} \, (\lambda x \, y, \, f \, (g \, x \, y)) \, tl \, tail)
\]
This completes the proof for this case. -/
    cases l' <;> simp_all","import Init.Data.List.TakeDrop
import Init.Data.List.Zip

open List
open Nat
"
27166,List.leftpad_length,"theorem List.leftpad_length (n : Nat) (a : α) (l : List α) :
    (leftpad n a l).length = max n l.length := by sorry","Length of Left-Padded List Equals Maximum of Target Length and Original Length : For any type \(\alpha\), natural number \(n\), element \(a \in \alpha\), and list \(l\) of elements of type \(\alpha\), the length of the list returned by `List.leftpad n a l` is equal to the maximum of \(n\) and the length of \(l\), i.e., \(\text{length}(\text{leftpad}(n, a, l)) = \max(n, \text{length}(l))\).","theorem List.leftpad_length (n : Nat) (a : α) (l : List α) :
    (leftpad n a l).length = max n l.length := by
  simp only [leftpad, length_append, length_replicate, Nat.sub_add_eq_max]","To prove that the length of the list returned by \(\text{leftpad}(n, a, l)\) is \(\max(n, \text{length}(l))\), we use the following properties and definitions:
1. The length of a list \(l\) is denoted by \(\text{length}(l)\).
2. The length of a list created by replicating an element \(a\) \(n\) times is \(n\), i.e., \(\text{length}(\text{replicate}(n, a)) = n\).
3. The length of the concatenation of two lists \(as\) and \(bs\) is the sum of their lengths, i.e., \(\text{length}(as \oplus bs) = \text{length}(as) + \text{length}(bs)\).
4. For any natural numbers \(a\) and \(b\), the equation \(a - b + b = \max(a, b)\) holds.

By the definition of \(\text{leftpad}(n, a, l)\), the list is constructed by concatenating a list of \(n - \text{length}(l)\) copies of \(a\) (if \(n > \text{length}(l)\)) with the original list \(l\). Therefore, the length of the resulting list is:
\[
\text{length}(\text{leftpad}(n, a, l)) = \text{length}(\text{replicate}(n - \text{length}(l), a) \oplus l)
\]
Using the properties of the length of a replicated list and the length of a concatenated list, we get:
\[
\text{length}(\text{replicate}(n - \text{length}(l), a) \oplus l) = (n - \text{length}(l)) + \text{length}(l)
\]
Simplifying the right-hand side using the property \(a - b + b = \max(a, b)\), we obtain:
\[
(n - \text{length}(l)) + \text{length}(l) = \max(n, \text{length}(l))
\]
Thus, the length of the list returned by \(\text{leftpad}(n, a, l)\) is \(\max(n, \text{length}(l))\). This completes the proof.","theorem List.leftpad_length (n : Nat) (a : α) (l : List α) :
    (leftpad n a l).length = max n l.length := by
/- Using the definitions and properties of the length of a list, the length of a replicated list, and the length of a concatenated list, we can simplify the expression \((\text{leftpad}(n, a, l)).\text{length}\) to \(\max(n, \text{length}(l))\). Specifically, we use the following properties:
- The length of a list \(l\) is denoted by \(\text{length}(l)\).
- The length of a list created by replicating an element \(a\) \(n\) times is \(n\), i.e., \(\text{length}(\text{replicate}(n, a)) = n\).
- The length of the concatenation of two lists \(as\) and \(bs\) is the sum of their lengths, i.e., \(\text{length}(as \oplus bs) = \text{length}(as) + \text{length}(bs)\).
- For any natural numbers \(a\) and \(b\), the equation \(a - b + b = \max(a, b)\) holds.

Thus, the length of the list returned by \(\text{leftpad}(n, a, l)\) is \(\max(n, \text{length}(l))\). -/
  simp only [leftpad, length_append, length_replicate, Nat.sub_add_eq_max]","import Init.Data.List.Count
import Init.Data.List.MinMax
import Init.Data.Nat.Lemmas
import Init.Data.List.Nat.Basic

open List
open Nat
"
27932,List.getElem_cons_zero,theorem List.getElem_cons_zero (a : α) (as : List α) (h : 0 < (a :: as).length) : getElem (a :: as) 0 h = a := by sorry,"Element at Index 0 in a Cons List is the First Element: \( l[0] = a \) for \( l = a :: l' \) : For any type \( \alpha \), any element \( a \) of type \( \alpha \), and any list \( l \) of elements of type \( \alpha \), if the index \( 0 \) is less than the length of the list \( a :: l \), then the element at index \( 0 \) in the list \( a :: l \) is equal to \( a \).","theorem List.getElem_cons_zero (a : α) (as : List α) (h : 0 < (a :: as).length) : getElem (a :: as) 0 h = a := by
  rfl","We need to show that for any type \( \alpha \), any element \( a \) of type \( \alpha \), and any list \( l \) of elements of type \( \alpha \), if the index \( 0 \) is less than the length of the list \( a :: l \), then the element at index \( 0 \) in the list \( a :: l \) is equal to \( a \).

By the definition of the `getElem` function, the element at index \( 0 \) in the list \( a :: l \) is \( a \). This is a direct consequence of the construction of the list \( a :: l \), where \( a \) is the first element. Therefore, the equality \( \text{getElem}(a :: l, 0, h) = a \) holds trivially due to the reflexive property of equality.

This completes the proof.","theorem List.getElem_cons_zero (a : α) (as : List α) (h : 0 < (a :: as).length) : getElem (a :: as) 0 h = a := by
/- The current goal is trivially true due to the reflexive property. Specifically, the element at index \( 0 \) in the list \( a :: l \) is definitionally equal to \( a \). -/
  rfl","import Init.Util
import Init.GetElem

open List

"
27938,List.getElem_cons_succ,theorem List.getElem_cons_succ (a : α) (as : List α) (i : Nat) (h : i + 1 < (a :: as).length) : getElem (a :: as) (i+1) h = getElem as i (Nat.lt_of_succ_lt_succ h) := by sorry,"Element at Successor Index in Cons List : For any type \( \alpha \), any element \( a \in \alpha \), any list \( l \) of elements of type \( \alpha \), and any natural number \( i \), if \( i + 1 \) is less than the length of the list \( a :: l \), then the element at index \( i + 1 \) in the list \( a :: l \) is equal to the element at index \( i \) in the list \( l \).","theorem List.getElem_cons_succ (a : α) (as : List α) (i : Nat) (h : i + 1 < (a :: as).length) : getElem (a :: as) (i+1) h = getElem as i (Nat.lt_of_succ_lt_succ h) := by
  rfl","We need to show that for any type \( \alpha \), any element \( a \in \alpha \), any list \( l \) of elements of type \( \alpha \), and any natural number \( i \), if \( i + 1 \) is less than the length of the list \( a :: l \), then the element at index \( i + 1 \) in the list \( a :: l \) is equal to the element at index \( i \) in the list \( l \).

By the definition of the `getElem` function, the element at index \( i + 1 \) in the list \( a :: l \) is the same as the element at index \( i \) in the list \( l \). This is trivially true due to the reflexive property of equality. Therefore, the element at index \( i + 1 \) in the list \( a :: l \) is indeed equal to the element at index \( i \) in the list \( l \).

This completes the proof.","theorem List.getElem_cons_succ (a : α) (as : List α) (i : Nat) (h : i + 1 < (a :: as).length) : getElem (a :: as) (i+1) h = getElem as i (Nat.lt_of_succ_lt_succ h) := by
/- The current goal is trivially true due to the reflexive property. Specifically, the element at index \( i + 1 \) in the list \( a :: l \) is definitionally equal to the element at index \( i \) in the list \( l \). -/
  rfl","import Init.Util
import Init.GetElem

open List

"
27940,getElem_congr_coll,"theorem getElem_congr_coll [GetElem coll idx elem valid] {c d : coll} {i : idx} {h : valid c i}
    (h' : c = d) : c[i] = d[i]'(h' ▸ h) := by sorry","Element Retrieval is Congruent under Collection Equality: $\text{getElem}(c, i, h) = \text{getElem}(d, i, h)$ if $c = d$ : For any types `coll`, `idx`, and `elem`, and a validity predicate `valid : coll → idx → Prop`, if there is an instance of `GetElem coll idx elem valid`, and for any collections `c` and `d` of type `coll`, and an index `i` of type `idx`, and a proof `h` that `i` is a valid index for `c`, and a proof `h'` that `c` is equal to `d`, then the element retrieved from `c` at index `i` using the validity proof `h` is equal to the element retrieved from `d` at the same index `i` using the same validity proof `h`.

In mathematical notation, this can be expressed as:
For any collections $c, d \in \text{coll}$, index $i \in \text{idx}$, and a proof $h$ that $i$ is a valid index for $c$, if $c = d$, then $\text{getElem}(c, i, h) = \text{getElem}(d, i, h)$.","theorem getElem_congr_coll [GetElem coll idx elem valid] {c d : coll} {i : idx} {h : valid c i}
    (h' : c = d) : c[i] = d[i]'(h' ▸ h) := by
  cases h'; rfl","Given that $c$ and $d$ are collections of type $\text{coll}$, $i$ is an index of type $\text{idx}$, and $h$ is a proof that $i$ is a valid index for $c$, we need to show that if $c = d$, then $\text{getElem}(c, i, h) = \text{getElem}(d, i, h)$.

Since we have a proof $h'$ that $c = d$, we can use this equality to substitute $c$ with $d$ in the expression $\text{getElem}(c, i, h)$. By the properties of equality, this substitution shows that $\text{getElem}(c, i, h) = \text{getElem}(d, i, h)$. Therefore, the goal is trivially satisfied. This completes the proof. $\blacksquare$","theorem getElem_congr_coll [GetElem coll idx elem valid] {c d : coll} {i : idx} {h : valid c i}
    (h' : c = d) : c[i] = d[i]'(h' ▸ h) := by
/- Since we have a proof `h'` that `c` is equal to `d`, we can use this equality to substitute `c` with `d` in the goal. By the properties of equality, this substitution shows that the element retrieved from `c` at index `i` using the validity proof `h` is equal to the element retrieved from `d` at the same index `i` using the same validity proof `h`. Therefore, the goal is trivially satisfied. -/
  cases h'; rfl","import Init.Util
import Init.GetElem



"
27946,Fin.getElem?_fin,theorem Fin.getElem?_fin [h : GetElem? Cont Nat Elem Dom] (a : Cont) (i : Fin n) : a[i]? = a[i.1]? := by sorry,"Optional Element Getter for Finite Types is Equivalent to Natural Number Getter : For any type \( \text{Cont} \) and a type \( \text{Elem} \), and a validity predicate \( \text{Dom} : \text{Cont} \to \mathbb{N} \to \text{Prop} \), if there exists an optional element getter \( \text{GetElem?} \) for \( \text{Cont} \) and \( \mathbb{N} \) with respect to \( \text{Dom} \), then for any collection \( a : \text{Cont} \) and any index \( i \in \text{Fin } n \), the optional element getter \( \text{GetElem?} \) applied to \( a \) and \( i \) is equal to the optional element getter applied to \( a \) and the natural number value of \( i \), i.e., \( \text{GetElem? } a \, i = \text{GetElem? } a \, \text{val}(i) \).","theorem Fin.getElem?_fin [h : GetElem? Cont Nat Elem Dom] (a : Cont) (i : Fin n) : a[i]? = a[i.1]? := by
  rfl","We need to show that for any collection \( a : \text{Cont} \) and any index \( i \in \text{Fin } n \), the optional element getter \( \text{GetElem? } a \, i \) is equal to \( \text{GetElem? } a \, \text{val}(i) \). This equality holds trivially due to the reflexive property, as both sides of the equation are definitionally equal. Therefore, the theorem is proved.","theorem Fin.getElem?_fin [h : GetElem? Cont Nat Elem Dom] (a : Cont) (i : Fin n) : a[i]? = a[i.1]? := by
  rfl","import Init.Util
import Init.GetElem

open Fin

"
27949,getElem?_neg,"theorem getElem?_neg [GetElem? cont idx elem dom] [LawfulGetElem cont idx elem dom]
    (c : cont) (i : idx) (h : ¬dom c i) [Decidable (dom c i)] : c[i]? = none := by sorry","Invalid Index Returns None in Element Retrieval : For any collection `c` of type `cont`, any index `i` of type `idx`, and any element type `elem`, if the index `i` is not valid for the collection `c` (i.e., `¬dom c i` holds), and if the validity of the index is decidable (i.e., `Decidable (dom c i)` holds), then the function `getElem?` returns `none` when applied to `c` and `i`, i.e., `getElem? c i = none`.","theorem getElem?_neg [GetElem? cont idx elem dom] [LawfulGetElem cont idx elem dom]
    (c : cont) (i : idx) (h : ¬dom c i) [Decidable (dom c i)] : c[i]? = none := by
  rw [getElem?_def]
  exact dif_neg h","We start by using the definition of `getElem?`. According to this definition, `getElem? c i` is equivalent to the expression:
\[
\text{if } h : \text{dom} \, c \, i \text{ then } \text{some} \, (\text{getElem} \, c \, i \, h) \text{ else } \text{none}
\]
Given that \( \neg \text{dom} \, c \, i \) (i.e., the index \( i \) is not valid for the collection \( c \)), the condition `dom c i` is false. Therefore, the if-then-else construct evaluates to the else branch, which is `none`. Hence, we have:
\[
\text{getElem?} \, c \, i = \text{none}
\]
This completes the proof.","theorem getElem?_neg [GetElem? cont idx elem dom] [LawfulGetElem cont idx elem dom]
    (c : cont) (i : idx) (h : ¬dom c i) [Decidable (dom c i)] : c[i]? = none := by
/- We use the definition of `getElem?` to rewrite the goal. According to the definition, `getElem? c i` is equivalent to the expression `if h : dom c i then some (getElem c i h) else none`. Therefore, our goal is now to show that this expression is equal to `none`. -/
  rw [getElem?_def]
/- Since we have the assumption that \( \neg \text{dom} \, c \, i \) (i.e., the index \( i \) is not valid for the collection \( c \)), the dependent if-then-else construct `if h : dom c i then some (getElem c i h) else none` evaluates to `none`. This is because the condition `dom c i` is false, and the else branch of the if-then-else construct is `none`. Therefore, the goal is exactly proved by this fact. -/
  exact dif_neg h","import Init.Util
import Init.GetElem



"
27954,getElem?_pos,"theorem getElem?_pos [GetElem? cont idx elem dom] [LawfulGetElem cont idx elem dom]
    (c : cont) (i : idx) (h : dom c i) [Decidable (dom c i)] : c[i]? = some (c[i]'h) := by sorry","Valid Index Returns Some in Element Retrieval : For any collection \( c \) of type `cont`, any index \( i \) of type `idx`, and any element type `elem`, if the index \( i \) is valid for the collection \( c \) (i.e., \( \text{dom } c \, i \) holds), and if the validity of the index is decidable (i.e., \( \text{Decidable}(\text{dom } c \, i) \) holds), then the function `getElem?` returns `some (getElem c i h)` when applied to \( c \) and \( i \), where \( h \) is a proof of the validity of \( i \) in \( c \). In other words, if the index is valid, `getElem?` returns the element at that index wrapped in `some`.","theorem getElem?_pos [GetElem? cont idx elem dom] [LawfulGetElem cont idx elem dom]
    (c : cont) (i : idx) (h : dom c i) [Decidable (dom c i)] : c[i]? = some (c[i]'h) := by
  rw [getElem?_def]
  exact dif_pos h","To prove the theorem, we start by using the definition of `getElem?`. According to the definition, `getElem? c i` is defined as:
\[
\text{if } h : \text{dom } c \, i \text{ then } \text{some } (\text{getElem } c \, i \, h) \text{ else } \text{none}
\]
Given that \( h \) is a proof that \(\text{dom } c \, i\) holds, the if-then-else construct evaluates to the true branch:
\[
\text{if } h : \text{dom } c \, i \text{ then } \text{some } (\text{getElem } c \, i \, h) \text{ else } \text{none} = \text{some } (\text{getElem } c \, i \, h)
\]
Thus, the goal \(\text{getElem? } c \, i = \text{some } (\text{getElem } c \, i \, h)\) is exactly proved. This completes the proof.","theorem getElem?_pos [GetElem? cont idx elem dom] [LawfulGetElem cont idx elem dom]
    (c : cont) (i : idx) (h : dom c i) [Decidable (dom c i)] : c[i]? = some (c[i]'h) := by
/- Using the definition of `getElem?`, we can rewrite the goal to show that \((\text{if } h : \text{dom } c \, i \text{ then } \text{some } (\text{getElem } c \, i \, h) \text{ else } \text{none}) = \text{some } (\text{getElem } c \, i \, h)\). -/
  rw [getElem?_def]
/- Since \( h \) is a proof that \(\text{dom } c \, i\) holds, the dependent if-then-else construct \(\text{if } h : \text{dom } c \, i \text{ then } \text{some } (\text{getElem } c \, i \, h) \text{ else } \text{none}\) evaluates to \(\text{some } (\text{getElem } c \, i \, h)\). Therefore, the goal is exactly proved. -/
  exact dif_pos h","import Init.Util
import Init.GetElem



"
28657,Bool.sizeOf_eq_one,theorem Bool.sizeOf_eq_one (b : Bool) : sizeOf b = 1 := by sorry,"Size of Boolean Element is One: \(\text{sizeOf}(b) = 1\) : For any boolean value \( b \), the size of \( b \) is equal to 1, i.e., \(\text{sizeOf}(b) = 1\).","theorem Bool.sizeOf_eq_one (b : Bool) : sizeOf b = 1 := by
  cases b <;> rfl","To prove that \(\text{sizeOf}(b) = 1\) for any boolean value \( b \), we consider the two possible cases for \( b \):

1. **Case 1: \( b = \text{false} \)**
- By definition, \(\text{sizeOf}(\text{false}) = 1\). Therefore, the equality \(\text{sizeOf}(\text{false}) = 1\) holds.

2. **Case 2: \( b = \text{true} \)**
- By definition, \(\text{sizeOf}(\text{true}) = 1\). Therefore, the equality \(\text{sizeOf}(\text{true}) = 1\) holds.

Since both cases are covered and the equality holds in each case, we conclude that for any boolean value \( b \), \(\text{sizeOf}(b) = 1\). This completes the proof. \(\blacksquare\)","theorem Bool.sizeOf_eq_one (b : Bool) : sizeOf b = 1 := by
  cases b <;> rfl","import Init.Tactics
import Init.SizeOf

open Bool

"
30561,Fin.hIterate_eq,"theorem Fin.hIterate_eq {P : Nat → Sort _} (state : ∀(i : Nat), P i)
    {n : Nat} (f : ∀(i : Fin n), P i.val → P (i.val+1)) (s : P 0)
    (init : s = state 0)
    (step : ∀(i : Fin n), f i (state i) = state (i+1)) :
    hIterate P s f = state n := by sorry","Heterogeneous Iteration Equals State at Final Index: \( \text{hIterate}(P, s, f) = \text{state}(n) \) : For any type family \( P : \mathbb{N} \to \text{Sort} \) and any natural number \( n \), if \( s \) is an initial state of type \( P(0) \) and \( f \) is a function that takes an index \( i \) of type \( \text{Fin}(n) \) and a state \( \text{state}(i) \) of type \( P(i) \) to produce a new state \( \text{state}(i + 1) \) of type \( P(i + 1) \), then the result of applying the heterogeneous iteration function `hIterate` starting from \( s \) and using \( f \) is equal to \( \text{state}(n) \) if the following conditions hold:
1. \( s = \text{state}(0) \)
2. For all \( i \in \text{Fin}(n) \), \( f(i, \text{state}(i)) = \text{state}(i + 1) \).","theorem Fin.hIterate_eq {P : Nat → Sort _} (state : ∀(i : Nat), P i)
    {n : Nat} (f : ∀(i : Fin n), P i.val → P (i.val+1)) (s : P 0)
    (init : s = state 0)
    (step : ∀(i : Fin n), f i (state i) = state (i+1)) :
    hIterate P s f = state n := by
  apply hIterate_elim (fun i s => s = state i) f s init
  intro i s s_eq
  simp only [s_eq, step]","To prove that \( \text{hIterate}(P, s, f) = \text{state}(n) \), we use the heterogeneous iteration elimination principle. This principle states that if:
1. \( s = \text{state}(0) \), and
2. for all \( k \in \text{Fin}(n) \) and \( s \in P(k) \), if \( s = \text{state}(k) \), then \( f(k, s) = \text{state}(k + 1) \),
then \( \text{hIterate}(P, s, f) = \text{state}(n) \).

We need to show that for all \( k \in \text{Fin}(n) \) and \( s \in P(k) \), if \( s = \text{state}(k) \), then \( f(k, s) = \text{state}(k + 1) \).

Let \( i \) be an arbitrary element of \( \text{Fin}(n) \), \( s \) be an element of \( P(i) \), and assume \( s = \text{state}(i) \). Using the assumption \( s = \text{state}(i) \) and the step condition \( \forall (i : \text{Fin}(n)), f(i, \text{state}(i)) = \text{state}(i + 1) \), we can simplify the expression \( f(i, s) \) to \( \text{state}(i + 1) \). Therefore, \( f(i, s) = \text{state}(i + 1) \) holds.

By the heterogeneous iteration elimination principle, we conclude that \( \text{hIterate}(P, s, f) = \text{state}(n) \). This completes the proof.","theorem Fin.hIterate_eq {P : Nat → Sort _} (state : ∀(i : Nat), P i)
    {n : Nat} (f : ∀(i : Fin n), P i.val → P (i.val+1)) (s : P 0)
    (init : s = state 0)
    (step : ∀(i : Fin n), f i (state i) = state (i+1)) :
    hIterate P s f = state n := by
/- To prove that \( \text{hIterate}(P, s, f) = \text{state}(n) \), we use the heterogeneous iteration elimination principle. This principle states that if:
1. \( s = \text{state}(0) \), and
2. for all \( k \in \text{Fin}(n) \) and \( s \in P(k) \), if \( s = \text{state}(k) \), then \( f(k, s) = \text{state}(k + 1) \),
then \( \text{hIterate}(P, s, f) = \text{state}(n) \). Therefore, it suffices to show that for all \( k \in \text{Fin}(n) \) and \( s \in P(k) \), if \( s = \text{state}(k) \), then \( f(k, s) = \text{state}(k + 1) \). -/
  apply hIterate_elim (fun i s => s = state i) f s init
/- Let \( i \) be an arbitrary element of \( \text{Fin}(n) \), \( s \) be an element of \( P(i) \), and assume \( s = \text{state}(i) \). We need to show that \( f(i, s) = \text{state}(i + 1) \). -/
  intro i s s_eq
/- Using the assumption \( s = \text{state}(i) \) and the step condition \( \forall (i : \text{Fin}(n)), f(i, \text{state}(i)) = \text{state}(i + 1) \), we can simplify the expression \( f(i, s) \) to \( \text{state}(i + 1) \). Therefore, \( f(i, s) = \text{state}(i + 1) \) holds. -/
  simp only [s_eq, step]","import Init.PropLemmas
import Init.Data.Fin.Basic
import Init.Data.Fin.Iterate

open Fin

"
31187,Nat.not_beq_eq_true_eq,theorem Nat.not_beq_eq_true_eq (a b : Nat) : ((!(a == b)) = true) = ¬(a = b) := by sorry,"Boolean Negation of Equality Coincides with Logical Inequality in Natural Numbers : For any natural numbers \(a\) and \(b\), the boolean negation of the equality \(a == b\) is true if and only if the logical negation of the equality \(a = b\) holds. In other words, \((!a == b) = \text{true}\) if and only if \(a \neq b\).","theorem Nat.not_beq_eq_true_eq (a b : Nat) : ((!(a == b)) = true) = ¬(a = b) := by
  simp","We need to show that for any natural numbers \(a\) and \(b\), the boolean negation of the equality \(a == b\) being true is equivalent to the logical negation of the equality \(a = b\).

Using the properties of equality and logical negation, we can simplify the proposition \((!a == b) = \text{true} = \neg a = b\). The boolean negation of the equality \(a == b\) being true is equivalent to the logical negation of the equality \(a = b\). This is a direct consequence of the definition of logical negation and the properties of equality.

Thus, \((!a == b) = \text{true}\) if and only if \(a \neq b\). This completes the proof.","theorem Nat.not_beq_eq_true_eq (a b : Nat) : ((!(a == b)) = true) = ¬(a = b) := by
  simp","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31193,Nat.beq_eq_true_eq,theorem Nat.beq_eq_true_eq (a b : Nat) : ((a == b) = true) = (a = b) := by sorry,"Boolean Equality Coincides with Logical Equality in Natural Numbers : For any natural numbers \(a\) and \(b\), the boolean equality \(a == b\) is true if and only if the logical equality \(a = b\) holds. In other words, \(a == b = \text{true}\) if and only if \(a = b\).","theorem Nat.beq_eq_true_eq (a b : Nat) : ((a == b) = true) = (a = b) := by
  simp","To prove the theorem, we need to show that the boolean equality \(a == b\) is true if and only if the logical equality \(a = b\) holds. We start with the proposition \((a == b) = \text{true} = (a = b)\).

Using the properties of boolean and logical equality, we can simplify this proposition. Specifically, we use the fact that if \(a == b\) is true, then \(a = b\) must hold, and vice versa. This follows from the definitions and properties of equality in natural numbers. Therefore, the proposition \((a == b) = \text{true} = (a = b)\) is trivially true.

Hence, we have shown that \(a == b = \text{true}\) if and only if \(a = b\). This completes the proof. \(\blacksquare\)","theorem Nat.beq_eq_true_eq (a b : Nat) : ((a == b) = true) = (a = b) := by
  simp","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31200,Nat.add_left_comm,theorem Nat.add_left_comm (n m k : Nat) : n + (m + k) = m + (n + k) := by sorry,"Left Addition Commutativity in Natural Numbers: \( n + (m + k) = m + (n + k) \) : For any natural numbers \( n \), \( m \), and \( k \), the equation \( n + (m + k) = m + (n + k) \) holds. This theorem demonstrates the commutativity of addition when the first term is fixed and the other two terms are permuted.","theorem Nat.add_left_comm (n m k : Nat) : n + (m + k) = m + (n + k) := by
  rw [← Nat.add_assoc, Nat.add_comm n m, Nat.add_assoc]","To prove that \( n + (m + k) = m + (n + k) \) for any natural numbers \( n \), \( m \), and \( k \), we proceed as follows:

1. **Step 1: Use the associativity of addition.**
By the associativity of addition, we have:
\[
n + (m + k) = n + m + k
\]

2. **Step 2: Use the commutativity of addition.**
By the commutativity of addition, we can rewrite \( n + m + k \) as:
\[
n + m + k = m + n + k
\]

3. **Step 3: Use the associativity of addition again.**
By the associativity of addition, we can rewrite \( m + n + k \) as:
\[
m + n + k = m + (n + k)
\]

Combining these steps, we have:
\[
n + (m + k) = m + (n + k)
\]

Since the right-hand side of the equation is equal to itself, the equation \( n + (m + k) = m + (n + k) \) holds. This completes the proof. \(\blacksquare\)","theorem Nat.add_left_comm (n m k : Nat) : n + (m + k) = m + (n + k) := by
/- First, we use the associativity of addition to rewrite \( n + (m + k) \) as \( n + m + k \). Then, we use the commutativity of addition to rewrite \( n + m + k \) as \( m + n + k \). Finally, we use the associativity of addition again to rewrite \( m + n + k \) as \( m + (n + k) \). Thus, the goal \( n + (m + k) = m + (n + k) \) is equivalent to \( m + (n + k) = m + (n + k) \), which is trivially true by the reflexive property of equality. -/
  rw [← Nat.add_assoc, Nat.add_comm n m, Nat.add_assoc]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31201,Nat.add_right_cancel,theorem Nat.add_right_cancel {n m k : Nat} (h : n + m = k + m) : n = k := by sorry,"Right Addition Cancellation in Natural Numbers : For any natural numbers \( n \), \( m \), and \( k \), if \( n + m = k + m \), then \( n = k \).","theorem Nat.add_right_cancel {n m k : Nat} (h : n + m = k + m) : n = k := by
  rw [Nat.add_comm n m, Nat.add_comm k m] at h
  apply Nat.add_left_cancel h","We start with the assumption that \( n + m = k + m \). Using the commutativity of addition, we can rewrite this assumption as \( m + n = m + k \). This is because for any natural numbers \( a \) and \( b \), \( a + b = b + a \).

Next, we apply the left cancellation property of addition. This property states that if \( a + b = a + c \), then \( b = c \). Applying this property to our rewritten assumption \( m + n = m + k \), we conclude that \( n = k \).

Thus, we have shown that if \( n + m = k + m \), then \( n = k \). This completes the proof. \(\blacksquare\)","theorem Nat.add_right_cancel {n m k : Nat} (h : n + m = k + m) : n = k := by
/- Using the commutativity of addition, we can rewrite the assumption \( n + m = k + m \) as \( m + n = m + k \). This is because for any natural numbers \( a \) and \( b \), \( a + b = b + a \). -/
  rw [Nat.add_comm n m, Nat.add_comm k m] at h
/- To prove \( n = k \), we use the left cancellation property of addition. Since we have \( m + n = m + k \), it follows that \( n = k \) by the left cancellation property, which states that if \( a + b = a + c \), then \( b = c \). -/
  apply Nat.add_left_cancel h","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31204,Nat.add_right_comm,theorem Nat.add_right_comm (n m k : Nat) : (n + m) + k = (n + k) + m := by sorry,"Right Addition Commutativity in Natural Numbers: \( n + m + k = n + k + m \) : For any natural numbers \( n \), \( m \), and \( k \), the equation \( n + m + k = n + k + m \) holds. This theorem demonstrates the commutativity of addition when the first term is fixed and the other two terms are permuted.","theorem Nat.add_right_comm (n m k : Nat) : (n + m) + k = (n + k) + m := by
  rw [Nat.add_assoc, Nat.add_comm m k, ← Nat.add_assoc]","To prove that \( n + m + k = n + k + m \) for any natural numbers \( n \), \( m \), and \( k \), we proceed as follows:

1. **Step 1: Use Associativity of Addition**
By the associativity of addition, we can rewrite \( n + m + k \) as \( n + (m + k) \). Therefore, the goal \( n + m + k = n + k + m \) is equivalent to \( n + (m + k) = n + k + m \).

2. **Step 2: Use Commutativity of Addition**
By the commutativity of addition, we can rewrite \( m + k \) as \( k + m \). Therefore, the goal \( n + (m + k) = n + k + m \) is equivalent to \( n + (k + m) = n + k + m \).

3. **Step 3: Use Associativity of Addition Again**
By the associativity of addition, we can rewrite \( n + (k + m) \) as \( n + k + m \). Therefore, the goal \( n + (k + m) = n + k + m \) is equivalent to \( n + k + m = n + k + m \).

4. **Step 4: Reflexive Property of Equality**
The equation \( n + k + m = n + k + m \) is trivially true by the reflexive property of equality.

Thus, we have shown that \( n + m + k = n + k + m \) for any natural numbers \( n \), \( m \), and \( k \). This completes the proof. \(\blacksquare\)","theorem Nat.add_right_comm (n m k : Nat) : (n + m) + k = (n + k) + m := by
/- First, we use the associativity of addition to rewrite \( n + m + k \) as \( n + (m + k) \). Then, we use the commutativity of addition to rewrite \( m + k \) as \( k + m \). Finally, we use the associativity of addition again to rewrite \( n + (k + m) \) as \( n + k + m \). Thus, the goal \( n + m + k = n + k + m \) is equivalent to \( n + k + m = n + k + m \), which is trivially true by the reflexive property of equality. -/
  rw [Nat.add_assoc, Nat.add_comm m k, ← Nat.add_assoc]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31205,Nat.right_distrib,theorem Nat.right_distrib (n m k : Nat) : (n + m) * k = n * k + m * k := by sorry,"Distributive Property of Multiplication over Addition in Natural Numbers (Right) : For any natural numbers \( n \), \( m \), and \( k \), the following equality holds:
\[ (n + m) \cdot k = n \cdot k + m \cdot k. \]","theorem Nat.right_distrib (n m k : Nat) : (n + m) * k = n * k + m * k := by
  rw [Nat.mul_comm, Nat.left_distrib]; simp [Nat.mul_comm]","To prove the distributive property of multiplication over addition in natural numbers, we start with the expression \((n + m) \cdot k\). Using the commutative property of multiplication, we can rewrite this as:
\[ (n + m) \cdot k = k \cdot (n + m). \]

Next, we apply the left distributive property of multiplication over addition, which states that for any natural numbers \(a\), \(b\), and \(c\), \(a \cdot (b + c) = a \cdot b + a \cdot c\). Applying this property, we get:
\[ k \cdot (n + m) = k \cdot n + k \cdot m. \]

Finally, we use the commutative property of multiplication again to rewrite \(k \cdot n + k \cdot m\) as:
\[ k \cdot n + k \cdot m = n \cdot k + m \cdot k. \]

Thus, we have shown that:
\[ (n + m) \cdot k = n \cdot k + m \cdot k. \]

This completes the proof.","theorem Nat.right_distrib (n m k : Nat) : (n + m) * k = n * k + m * k := by
/- First, we use the commutative property of multiplication to rewrite the goal. Specifically, we rewrite \((n + m) \cdot k\) as \(k \cdot (n + m)\). Then, we use the left distributive property of multiplication over addition to rewrite \(k \cdot (n + m)\) as \(k \cdot n + k \cdot m\). Finally, we use the commutative property of multiplication again to rewrite \(k \cdot n + k \cdot m\) as \(n \cdot k + m \cdot k\). Thus, the goal is now to show that \(n \cdot k + m \cdot k = n \cdot k + m \cdot k\), which is trivially true by the properties of equality. -/
  rw [Nat.mul_comm, Nat.left_distrib]; simp [Nat.mul_comm]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31206,Nat.succ_ne_zero,theorem Nat.succ_ne_zero (n : Nat) : succ n ≠ 0 := by sorry,"Successor of a Natural Number is Not Zero: \( n + 1 \neq 0 \) : For any natural number \( n \), the successor of \( n \), denoted as \( n + 1 \), is not equal to zero, i.e., \( n + 1 \neq 0 \).","theorem Nat.succ_ne_zero (n : Nat) : succ n ≠ 0 := by
  simp","To prove that for any natural number \( n \), the successor of \( n \), denoted as \( n + 1 \), is not equal to zero, we start by considering the properties of natural numbers and the definition of the successor function. The successor function \( n + 1 \) is defined such that it always yields a positive number, which is greater than zero. Therefore, \( n + 1 \) cannot be zero. This is a fundamental property of natural numbers and the successor function. Hence, the statement \( n + 1 \neq 0 \) is trivially true for any natural number \( n \). This completes the proof.","theorem Nat.succ_ne_zero (n : Nat) : succ n ≠ 0 := by
  simp","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31207,Nat.mul_two,theorem Nat.mul_two (n) : n * 2 = n + n := by sorry,"Multiplication by Two Equals Double in Natural Numbers : For any natural number \( n \), the product of \( n \) and 2 is equal to the sum of \( n \) and \( n \), i.e., \( n \times 2 = n + n \).","theorem Nat.mul_two (n) : n * 2 = n + n := by
  rw [Nat.mul_succ, Nat.mul_one]","To prove that \( n \times 2 = n + n \) for any natural number \( n \), we start by using the property of multiplication by the successor in natural numbers. This property states that for any natural numbers \( n \) and \( m \), \( n \times (m + 1) = n \times m + n \). Applying this property with \( m = 1 \), we have:
\[
n \times 2 = n \times (1 + 1) = n \times 1 + n
\]
Next, we use the property of the multiplicative identity, which states that for any natural number \( n \), \( n \times 1 = n \). Substituting this into our equation, we get:
\[
n \times 2 = n + n
\]
Thus, we have shown that \( n \times 2 = n + n \) for any natural number \( n \). This completes the proof. \(\blacksquare\)","theorem Nat.mul_two (n) : n * 2 = n + n := by
  rw [Nat.mul_succ, Nat.mul_one]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31208,Nat.two_mul,theorem Nat.two_mul (n) : 2 * n = n + n := by sorry,"Multiplication by Two Equals Double in Natural Numbers : For any natural number \( n \), the product of 2 and \( n \) is equal to the sum of \( n \) and \( n \), i.e., \( 2 \cdot n = n + n \).","theorem Nat.two_mul (n) : 2 * n = n + n := by
  rw [Nat.succ_mul, Nat.one_mul]","To prove that \(2 \cdot n = n + n\) for any natural number \( n \), we start by using the identity for the successor of a natural number in multiplication. Specifically, we know that \((n + 1) \cdot m = n \cdot m + m\) for any natural numbers \( n \) and \( m \). Applying this identity with \(2 = 1 + 1\), we rewrite the goal \(2 \cdot n\) as \((1 + 1) \cdot n\), which simplifies to \(1 \cdot n + n\).

Next, we use the multiplicative identity property, which states that \(1 \cdot a = a\) for any natural number \(a\). Applying this property, we simplify \(1 \cdot n\) to \(n\). Therefore, the goal \(1 \cdot n + n\) becomes \(n + n\).

Thus, we have shown that \(2 \cdot n = n + n\). This completes the proof. \(\blacksquare\)","theorem Nat.two_mul (n) : 2 * n = n + n := by
  rw [Nat.succ_mul, Nat.one_mul]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31209,Nat.eq_of_mul_eq_mul_right,theorem Nat.eq_of_mul_eq_mul_right {n m k : Nat} (hm : 0 < m) (h : n * m = k * m) : n = k := by sorry,"Right Multiplication Cancellation in Natural Numbers : For any natural numbers \( n \), \( m \), and \( k \), if \( m \) is nonzero and \( n \cdot m = k \cdot m \), then \( n = k \).","theorem Nat.eq_of_mul_eq_mul_right {n m k : Nat} (hm : 0 < m) (h : n * m = k * m) : n = k := by
  rw [Nat.mul_comm n m, Nat.mul_comm k m] at h; exact Nat.eq_of_mul_eq_mul_left hm h","Given natural numbers \( n \), \( m \), and \( k \), and the assumption that \( m \) is nonzero, we start with the equation \( n \cdot m = k \cdot m \). By the commutativity of multiplication, we can rewrite this equation as \( m \cdot n = m \cdot k \). Since \( m \) is nonzero, we can apply the left cancellation property of multiplication, which states that if \( m \cdot n = m \cdot k \) and \( m \neq 0 \), then \( n = k \). Therefore, we conclude that \( n = k \). This completes the proof.","theorem Nat.eq_of_mul_eq_mul_right {n m k : Nat} (hm : 0 < m) (h : n * m = k * m) : n = k := by
/- First, we use the commutativity of multiplication to rewrite the equation \( n \cdot m = k \cdot m \) as \( m \cdot n = m \cdot k \). Then, since \( m \) is nonzero, we can apply the left cancellation property of multiplication to conclude that \( n = k \). -/
  rw [Nat.mul_comm n m, Nat.mul_comm k m] at h; exact Nat.eq_of_mul_eq_mul_left hm h","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31210,Nat.zero_lt_of_ne_zero,theorem Nat.zero_lt_of_ne_zero {a : Nat} (h : a ≠ 0) : 0 < a := by sorry,"Zero is Less Than Nonzero Natural Numbers : For any natural number \( a \), if \( a \neq 0 \), then \( 0 < a \).","theorem Nat.zero_lt_of_ne_zero {a : Nat} (h : a ≠ 0) : 0 < a := by
  match a with
  | 0 => contradiction
  | a+1 => apply Nat.zero_lt_succ","We need to show that for any natural number \( a \), if \( a \neq 0 \), then \( 0 < a \).

1. **Case 1: \( a = 0 \)**
- Assume \( a = 0 \).
- This contradicts our assumption that \( a \neq 0 \).
- Therefore, this case is impossible.

2. **Case 2: \( a = a' + 1 \) for some natural number \( a' \)**
- Assume \( a = a' + 1 \).
- We need to show that \( 0 < a \).
- By the properties of natural numbers, we know that \( 0 < a' + 1 \) for any natural number \( a' \).
- Therefore, \( 0 < a \).

Since the only possible case is \( a = a' + 1 \) and in this case \( 0 < a \), we conclude that for any natural number \( a \), if \( a \neq 0 \), then \( 0 < a \). This completes the proof.","theorem Nat.zero_lt_of_ne_zero {a : Nat} (h : a ≠ 0) : 0 < a := by
  match a with
/- We consider the case where \( a = 0 \). However, this contradicts our assumption that \( a \neq 0 \). Therefore, this case cannot occur. -/
  | 0 => contradiction
/- We consider the case where \( a = a' + 1 \) for some natural number \( a' \). To prove \( 0 < a \), we use the fact that \( 0 < a' + 1 \) for any natural number \( a' \). This is a known property of natural numbers, which states that the successor of any natural number is greater than zero. -/
  | a+1 => apply Nat.zero_lt_succ","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31211,Nat.add_le_add_right,theorem Nat.add_le_add_right {n m : Nat} (h : n ≤ m) (k : Nat) : n + k ≤ m + k := by sorry,"Right Addition Preserves Less-Than-or-Equal Relation in Natural Numbers : For any natural numbers \( n \) and \( m \) such that \( n \leq m \), and for any natural number \( k \), it holds that \( n + k \leq m + k \).","theorem Nat.add_le_add_right {n m : Nat} (h : n ≤ m) (k : Nat) : n + k ≤ m + k := by
  rw [Nat.add_comm n k, Nat.add_comm m k]
  apply Nat.add_le_add_left
  assumption","We start with the assumption that \( n \leq m \) and need to show that \( n + k \leq m + k \) for any natural number \( k \).

1. Using the commutativity of addition, we can rewrite the goal \( n + k \leq m + k \) as \( k + n \leq k + m \).
2. To prove \( k + n \leq k + m \), it suffices to show \( n \leq m \) because adding the same natural number \( k \) to both sides of an inequality preserves the inequality.
3. The current goal \( n \leq m \) has already been given as a hypothesis, so it is already proved.

Thus, we have shown that \( n + k \leq m + k \) for any natural number \( k \). This completes the proof. \(\blacksquare\)","theorem Nat.add_le_add_right {n m : Nat} (h : n ≤ m) (k : Nat) : n + k ≤ m + k := by
/- Using the commutativity of addition, we can rewrite the goal \( n + k \leq m + k \) as \( k + n \leq k + m \). -/
  rw [Nat.add_comm n k, Nat.add_comm m k]
/- To prove \( k + n \leq k + m \), it suffices to show \( n \leq m \) because adding the same natural number \( k \) to both sides of an inequality preserves the inequality. -/
  apply Nat.add_le_add_left
/- The current goal \( n \leq m \) has already been given as a hypothesis, so it is already proved. -/
  assumption","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31212,Nat.le_of_add_le_add_right,theorem Nat.le_of_add_le_add_right {a b c : Nat} : a + b ≤ c + b → a ≤ c := by sorry,"Right Addition Cancellation for Less Than or Equal in Natural Numbers : For any natural numbers \(a\), \(b\), and \(c\), if \(a + b \leq c + b\), then \(a \leq c\).","theorem Nat.le_of_add_le_add_right {a b c : Nat} : a + b ≤ c + b → a ≤ c := by
  rw [Nat.add_comm _ b, Nat.add_comm _ b]
  apply Nat.le_of_add_le_add_left","We start with the assumption that \(a + b \leq c + b\). Using the commutativity of addition, we can rewrite this as \(b + a \leq b + c\). To prove that \(a \leq c\), we use the theorem that states if \(a + b \leq a + c\), then \(b \leq c\). Applying this theorem to our rewritten assumption, we get that \(b + a \leq b + c\) implies \(a \leq c\). Therefore, the original assumption \(a + b \leq c + b\) implies \(a \leq c\). This completes the proof.","theorem Nat.le_of_add_le_add_right {a b c : Nat} : a + b ≤ c + b → a ≤ c := by
/- Using the commutativity of addition, we can rewrite the goal \(a + b \leq c + b\) as \(b + a \leq b + c\). Therefore, the goal is now to show that \(b + a \leq b + c \rightarrow a \leq c\). -/
  rw [Nat.add_comm _ b, Nat.add_comm _ b]
/- To prove \(b + a \leq b + c \rightarrow a \leq c\), we use the theorem that states if \(a + b \leq a + c\), then \(b \leq c\). Applying this theorem, it suffices to show that \(b + a \leq b + c\) implies \(a \leq c\). -/
  apply Nat.le_of_add_le_add_left","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31214,Nat.mul_left_comm,theorem Nat.mul_left_comm (n m k : Nat) : n * (m * k) = m * (n * k) := by sorry,"Left-Commutativity of Multiplication in Natural Numbers: \( n \cdot (m \cdot k) = m \cdot (n \cdot k) \) : For any natural numbers \( n, m, k \in \mathbb{N} \), the equation \( n \cdot (m \cdot k) = m \cdot (n \cdot k) \) holds. This property is known as the left-commutativity of multiplication in the natural numbers.","theorem Nat.mul_left_comm (n m k : Nat) : n * (m * k) = m * (n * k) := by
  rw [← Nat.mul_assoc, Nat.mul_comm n m, Nat.mul_assoc]","To prove the left-commutativity of multiplication in the natural numbers, we start with the equation \( n \cdot (m \cdot k) = m \cdot (n \cdot k) \).

1. **Step 1: Use the associativity of multiplication.**
By the associativity of multiplication, we can rewrite \( n \cdot (m \cdot k) \) as \( (n \cdot m) \cdot k \). Therefore, the goal becomes:
\[
(n \cdot m) \cdot k = m \cdot (n \cdot k)
\]

2. **Step 2: Use the commutativity of multiplication.**
By the commutativity of multiplication, we can rewrite \( (n \cdot m) \cdot k \) as \( (m \cdot n) \cdot k \). Therefore, the goal now is:
\[
(m \cdot n) \cdot k = m \cdot (n \cdot k)
\]

3. **Step 3: Use the associativity of multiplication again.**
By the associativity of multiplication, we can rewrite \( (m \cdot n) \cdot k \) as \( m \cdot (n \cdot k) \). Therefore, the goal is:
\[
m \cdot (n \cdot k) = m \cdot (n \cdot k)
\]

4. **Step 4: Conclude the proof.**
The equation \( m \cdot (n \cdot k) = m \cdot (n \cdot k) \) is trivially true by the reflexive property of equality. Hence, we have shown that \( n \cdot (m \cdot k) = m \cdot (n \cdot k) \).

This completes the proof. \(\blacksquare\)","theorem Nat.mul_left_comm (n m k : Nat) : n * (m * k) = m * (n * k) := by
/- First, we use the associativity of multiplication to rewrite \( n \cdot (m \cdot k) \) as \( (n \cdot m) \cdot k \). Then, we use the commutativity of multiplication to rewrite \( (n \cdot m) \cdot k \) as \( (m \cdot n) \cdot k \). Finally, we use the associativity of multiplication again to rewrite \( (m \cdot n) \cdot k \) as \( m \cdot (n \cdot k) \). Thus, the goal \( n \cdot (m \cdot k) = m \cdot (n \cdot k) \) is equivalent to \( m \cdot (n \cdot k) = m \cdot (n \cdot k) \), which is trivially true by the reflexive property of equality. -/
  rw [← Nat.mul_assoc, Nat.mul_comm n m, Nat.mul_assoc]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31215,Nat.add_sub_self_right,theorem Nat.add_sub_self_right (a b : Nat) : (a + b) - b = a := by sorry,"Right Addition and Subtraction Identity in Natural Numbers : For any natural numbers \(a\) and \(b\), the expression \(a + b - b\) is equal to \(a\), i.e., \(a + b - b = a\).","theorem Nat.add_sub_self_right (a b : Nat) : (a + b) - b = a := by
  rw [Nat.add_comm]; apply add_sub_self_left","To prove that \(a + b - b = a\) for any natural numbers \(a\) and \(b\), we start by using the commutativity of addition. The commutativity of addition states that \(a + b = b + a\). Therefore, we can rewrite the expression \(a + b - b\) as \(b + a - b\).

Next, we apply the theorem that for any natural numbers \(x\) and \(y\), \(x + y - y = x\). In our case, this theorem tells us that \(b + a - b = a\).

Thus, we have shown that \(a + b - b = a\), completing the proof.","theorem Nat.add_sub_self_right (a b : Nat) : (a + b) - b = a := by
/- First, we use the commutativity of addition in natural numbers, which states that \(a + b = b + a\). This allows us to rewrite the goal \(a + b - b = a\) as \(b + a - b = a\). Then, we apply the theorem that for any natural numbers \(x\) and \(y\), \(x + y - y = x\). This theorem directly gives us \(b + a - b = a\), which is exactly what we need to prove. -/
  rw [Nat.add_comm]; apply add_sub_self_left","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31216,Nat.sub_le,theorem Nat.sub_le (n m : Nat) : n - m ≤ n := by sorry,"Subtraction is Less Than or Equal to Minuend in Natural Numbers : For any natural numbers \( n \) and \( m \), the subtraction \( n - m \) is less than or equal to \( n \), i.e., \( n - m \leq n \).","theorem Nat.sub_le (n m : Nat) : n - m ≤ n := by
  induction m with
  | zero      => exact Nat.le_refl (n - 0)
  | succ m ih => apply Nat.le_trans (pred_le (n - m)) ih","We prove this by induction on \( m \).

1. **Base Case:**
- Consider \( m = 0 \). We need to show that \( n - 0 \leq n \).
- Since \( n - 0 = n \), this is equivalent to showing \( n \leq n \).
- This is true by the reflexivity of the less than or equal to relation.

2. **Inductive Step:**
- Assume the inductive hypothesis that for some \( m' \), \( n - m' \leq n \).
- We need to show that \( n - (m' + 1) \leq n \).
- By the definition of subtraction, \( n - (m' + 1) = \text{pred}(n - m') \).
- Using the fact that the predecessor of any natural number is less than or equal to the number itself, we have \( \text{pred}(n - m') \leq n - m' \).
- By the inductive hypothesis, \( n - m' \leq n \).
- Therefore, by the transitivity of the less than or equal to relation, we have \( \text{pred}(n - m') \leq n \).

By induction, the theorem holds for all natural numbers \( m \). Therefore, for any natural numbers \( n \) and \( m \), \( n - m \leq n \). This completes the proof. \(\blacksquare\)","theorem Nat.sub_le (n m : Nat) : n - m ≤ n := by
  induction m with
/- First, consider the base case where \( m = 0 \). We need to show that \( n - 0 \leq n \). Since \( n - 0 = n \), this is equivalent to showing \( n \leq n \), which is true by the reflexivity of the less than or equal to relation. -/
  | zero      => exact Nat.le_refl (n - 0)
/- Next, consider the inductive step where \( m = \text{succ}(m') \) for some \( m' \). Assume the inductive hypothesis that \( n - m' \leq n \). We need to show that \( n - (m' + 1) \leq n \). By the definition of subtraction, \( n - (m' + 1) = \text{pred}(n - m') \). Using the fact that the predecessor of any natural number is less than or equal to the number itself, we have \( \text{pred}(n - m') \leq n - m' \). By the inductive hypothesis, \( n - m' \leq n \). Therefore, by the transitivity of the less than or equal to relation, we have \( \text{pred}(n - m') \leq n \). This completes the inductive step. -/
  | succ m ih => apply Nat.le_trans (pred_le (n - m)) ih","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31217,Nat.succ_pred,theorem Nat.succ_pred {a : Nat} (h : a ≠ 0) : a.pred.succ = a := by sorry,"Successor of Predecessor Identity for Nonzero Natural Numbers: \( \text{succ}(\text{pred}(a)) = a \) for \( a \neq 0 \) : For any natural number \( a \) such that \( a \neq 0 \), the successor of the predecessor of \( a \) is equal to \( a \), i.e., \( \text{succ}(\text{pred}(a)) = a \).","theorem Nat.succ_pred {a : Nat} (h : a ≠ 0) : a.pred.succ = a := by
  induction a with
  | zero => contradiction
  | succ => rfl","We need to prove that for any natural number \( a \) such that \( a \neq 0 \), the successor of the predecessor of \( a \) is equal to \( a \). We consider two cases based on the structure of \( a \):

1. **Case 1: \( a = 0 \)**
- Since the assumption is \( a \neq 0 \), we get a direct contradiction. Therefore, this case is vacuously true.

2. **Case 2: \( a = n + 1 \) for some natural number \( n \)**
- In this case, we need to show that \( \text{succ}(\text{pred}(n + 1)) = n + 1 \).
- By the definition of the predecessor function, \( \text{pred}(n + 1) = n \).
- Therefore, \( \text{succ}(\text{pred}(n + 1)) = \text{succ}(n) = n + 1 \).
- This is trivially true due to the reflexive property, as both sides of the equation are definitionally equal.

Since both cases are covered, the theorem is proved. \(\blacksquare\)","theorem Nat.succ_pred {a : Nat} (h : a ≠ 0) : a.pred.succ = a := by
  induction a with
/- We consider the case where \( a = 0 \). Since the assumption is \( a \neq 0 \), we get a direct contradiction, and we can conclude the proof for this case. -/
  | zero => contradiction
/- We consider the case where \( a \) is a successor of some natural number \( n \), i.e., \( a = n + 1 \). In this case, the goal is to show that \( \text{succ}(\text{pred}(n + 1)) = n + 1 \). This is trivially true due to the reflexive property, as both sides of the equation are definitionally equal. -/
  | succ => rfl","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31218,Nat.le_of_add_le_add_left,theorem Nat.le_of_add_le_add_left {a b c : Nat} (h : a + b ≤ a + c) : b ≤ c := by sorry,"Left Addition Cancellation for Less Than or Equal in Natural Numbers : For any natural numbers \(a\), \(b\), and \(c\), if \(a + b \leq a + c\), then \(b \leq c\).","theorem Nat.le_of_add_le_add_left {a b c : Nat} (h : a + b ≤ a + c) : b ≤ c := by
  match le.dest h with
  | ⟨d, hd⟩ =>
    apply @le.intro _ _ d
    rw [Nat.add_assoc] at hd
    apply Nat.add_left_cancel hd","We start with the assumption that \(a + b \leq a + c\). To prove \(b \leq c\), we need to show that there exists a natural number \(d\) such that \(b + d = c\).

1. **Step 1:**
To prove \( b + d = c \), using the left addition cancellation property, it suffices to show that \( a + (b + d) = a + c \).

2. **Step 2:**
We introduce a natural number \( d \) and the hypothesis \( hd : a + b + d = a + c \). Our goal is to show that \( b \leq c \).

3. **Step 3:**
To prove \( b \leq c \), using the introduction rule for the less-than-or-equal relation, it suffices to show that \( b + d = c \).

4. **Step 4:**
Using the associativity of addition, we can rewrite the hypothesis \( hd : a + b + d = a + c \) as \( a + (b + d) = a + c \).

5. **Step 5:**
Using the left addition cancellation property, since \( a + (b + d) = a + c \), we conclude that \( b + d = c \).

Therefore, \( b \leq c \). This completes the proof. \(\blacksquare\)","theorem Nat.le_of_add_le_add_left {a b c : Nat} (h : a + b ≤ a + c) : b ≤ c := by
  match le.dest h with
/- We introduce a natural number \( d \) and the hypothesis \( hd : a + b + d = a + c \). Our goal is to show that \( b \leq c \). -/
  | ⟨d, hd⟩ =>
/- To prove \( b \leq c \), using the introduction rule for the less-than-or-equal relation, it suffices to show that \( b + d = c \). -/
    apply @le.intro _ _ d
/- Using the associativity of addition, we can rewrite the hypothesis \( hd : a + b + d = a + c \) as \( a + (b + d) = a + c \). -/
    rw [Nat.add_assoc] at hd
/- To prove \( b + d = c \), using the left addition cancellation property, it suffices to show that \( a + (b + d) = a + c \). -/
/- Using the left addition cancellation property, since \( a + (b + d) = a + c \), we conclude that \( b + d = c \). -/
    apply Nat.add_left_cancel hd","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31219,Nat.not_eq_zero_of_lt,theorem Nat.not_eq_zero_of_lt (h : b < a) : a ≠ 0 := by sorry,"Strict Inequality Implies Nonzero in Natural Numbers : For any natural numbers \( b \) and \( a \), if \( b < a \), then \( a \neq 0 \).","theorem Nat.not_eq_zero_of_lt (h : b < a) : a ≠ 0 := by
  cases a
  exact absurd h (Nat.not_lt_zero _)
  apply Nat.noConfusion","We need to show that if \( b < a \), then \( a \neq 0 \). We will consider every possible case for the natural number \( a \).

1. **Case 1: \( a = 0 \)**
- Assume \( b < 0 \). This is a contradiction because no natural number \( b \) can be less than \( 0 \). Therefore, the assumption \( b < 0 \) is false, and the goal \( 0 \neq 0 \) is vacuously true. This case is impossible.

2. **Case 2: \( a = n + 1 \) for some natural number \( n \)**
- We need to show that \( n + 1 \neq 0 \). By the property of natural numbers, no natural number can be equal to its successor. Therefore, \( n + 1 \neq 0 \).

Since both cases are covered, we conclude that if \( b < a \), then \( a \neq 0 \). This completes the proof. \(\blacksquare\)","theorem Nat.not_eq_zero_of_lt (h : b < a) : a ≠ 0 := by
/- We will consider every possible case for the natural number \( a \). Case 1: \( a = 0 \). Case 2: \( a = n + 1 \) for some natural number \( n \). -/
  cases a
/- In the case where \( a = 0 \), we have the assumption \( b < 0 \). However, this is a contradiction because no natural number \( b \) can be less than \( 0 \). Therefore, the goal \( 0 \neq 0 \) is vacuously true. This case is impossible. -/
  exact absurd h (Nat.not_lt_zero _)
/- In the case where \( a = n + 1 \), we need to show that \( n + 1 \neq 0 \). Using the property of natural numbers that no natural number can be equal to its successor, we conclude that \( n + 1 \neq 0 \). This completes the proof for this case. -/
  apply Nat.noConfusion","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31220,Nat.sub_add_cancel,theorem Nat.sub_add_cancel {n m : Nat} (h : m ≤ n) : n - m + m = n := by sorry,"Subtraction and Addition Cancellation in Natural Numbers: \( n - m + m = n \) : For any natural numbers \( n \) and \( m \) such that \( m \leq n \), the equation \( n - m + m = n \) holds.","theorem Nat.sub_add_cancel {n m : Nat} (h : m ≤ n) : n - m + m = n := by
  rw [Nat.add_comm, Nat.add_sub_of_le h]","We start with the goal of proving \( n - m + m = n \) for natural numbers \( n \) and \( m \) such that \( m \leq n \).

1. **Step 1:**
Using the commutativity of addition, we rewrite the goal \( n - m + m = n \) as \( m + (n - m) = n \).

2. **Step 2:**
By the property of natural numbers, for any \( a \) and \( b \) such that \( a \leq b \), the sum \( a + (b - a) \) is equal to \( b \). Since \( m \leq n \), we have \( m + (n - m) = n \).

3. **Step 3:**
Therefore, the goal is now \( n = n \), which is trivially true.

This completes the proof. \(\blacksquare\)","theorem Nat.sub_add_cancel {n m : Nat} (h : m ≤ n) : n - m + m = n := by
/- First, we use the commutativity of addition to rewrite the goal \( n - m + m = n \) as \( m + (n - m) = n \). Then, we use the property that for any natural numbers \( a \) and \( b \) such that \( a \leq b \), the sum \( a + (b - a) \) is equal to \( b \). Since \( m \leq n \), we have \( m + (n - m) = n \). Therefore, the goal is now \( n = n \), which is trivially true. -/
  rw [Nat.add_comm, Nat.add_sub_of_le h]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31221,Nat.sub_eq_of_eq_add,theorem Nat.sub_eq_of_eq_add {a b c : Nat} (h : a = c + b) : a - b = c := by sorry,"Subtraction Identity: \(a - b = c\) if \(a = c + b\) : For any natural numbers \(a\), \(b\), and \(c\), if \(a = c + b\), then \(a - b = c\).","theorem Nat.sub_eq_of_eq_add {a b c : Nat} (h : a = c + b) : a - b = c := by
  rw [h, Nat.add_sub_cancel]","We start with the given hypothesis \( a = c + b \). To prove that \( a - b = c \), we substitute \( a \) with \( c + b \) in the goal, which transforms the goal into \( (c + b) - b = c \). By the property of natural numbers, addition and subtraction cancel each other out, so \( c + (b - b) = c \). This simplifies to \( c = c \), which is trivially true. Therefore, we have shown that \( a - b = c \). This completes the proof. \(\blacksquare\)","theorem Nat.sub_eq_of_eq_add {a b c : Nat} (h : a = c + b) : a - b = c := by
/- First, we use the hypothesis \( h \) which states \( a = c + b \) to replace \( a \) with \( c + b \) in the goal. This transforms the goal \( a - b = c \) into \( (c + b) - b = c \). Next, we use the property of natural numbers that addition and subtraction cancel each other out, i.e., \( c + (b - b) = c \). This simplifies the goal to \( c = c \), which is trivially true. -/
  rw [h, Nat.add_sub_cancel]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31222,Nat.succ_sub_succ_eq_sub,theorem Nat.succ_sub_succ_eq_sub (n m : Nat) : succ n - succ m = n - m := by sorry,"Successor Subtraction Identity: \( (n + 1) - (m + 1) = n - m \) : For any natural numbers \( n \) and \( m \), the equation \( (n + 1) - (m + 1) = n - m \) holds.","theorem Nat.succ_sub_succ_eq_sub (n m : Nat) : succ n - succ m = n - m := by
  induction m with
  | zero      => exact rfl
  | succ m ih => apply congrArg pred ih","We prove this by induction on \( m \).

**Base Case:**
Consider \( m = 0 \). We need to show that \( (n + 1) - (0 + 1) = n - 0 \). This simplifies to \( n + 1 - 1 = n \), which is true by the definition of subtraction and the reflexivity of equality, i.e., \( n + 1 - 1 = n \) and \( n - 0 = n \).

**Inductive Step:**
Assume the inductive hypothesis that for some natural number \( k \), \( (n + 1) - (k + 1) = n - k \). We need to show that \( (n + 1) - ((k + 1) + 1) = n - (k + 1) \). By the inductive hypothesis, we have \( (n + 1) - (k + 1) = n - k \). Applying the predecessor function to both sides of this equation, we get \( \text{pred}((n + 1) - (k + 1)) = \text{pred}(n - k) \). Since the predecessor function is defined such that \(\text{pred}(a + 1) = a\), this simplifies to \( n - (k + 1) = n - (k + 1) \), which is true by the definition of subtraction and the reflexivity of equality.

By the principle of mathematical induction, the equation \( (n + 1) - (m + 1) = n - m \) holds for all natural numbers \( n \) and \( m \). This completes the proof.","theorem Nat.succ_sub_succ_eq_sub (n m : Nat) : succ n - succ m = n - m := by
  induction m with
/- First, consider the base case where \( m = 0 \). We need to show that \( n + 1 - 1 = n - 0 \). This is trivially true by the definition of subtraction and the reflexivity of equality, i.e., \( n + 1 - 1 = n \) and \( n - 0 = n \). -/
  | zero      => exact rfl
/- Next, consider the inductive step where \( m = k + 1 \) for some natural number \( k \). Assume the inductive hypothesis that \( n + 1 - (k + 1) = n - k \). We need to show that \( n + 1 - (k + 1 + 1) = n - (k + 1) \). By the inductive hypothesis, we have \( n + 1 - (k + 1) = n - k \). Applying the predecessor function to both sides of this equation, we get \( \text{pred}(n + 1 - (k + 1)) = \text{pred}(n - k) \). Since the predecessor function is defined such that \(\text{pred}(a + 1) = a\), this simplifies to \( n - (k + 1) = n - (k + 1) \), which is true by the definition of subtraction and the reflexivity of equality. -/
  | succ m ih => apply congrArg pred ih","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31223,Nat.sub_one_add_one,theorem Nat.sub_one_add_one {a : Nat} (h : a ≠ 0) : a - 1 + 1 = a := by sorry,"Subtraction and Addition Identity for Nonzero Natural Numbers: \( a - 1 + 1 = a \) for \( a \neq 0 \) : For any natural number \( a \) such that \( a \neq 0 \), the expression \( a - 1 + 1 \) is equal to \( a \), i.e., \( a - 1 + 1 = a \).","theorem Nat.sub_one_add_one {a : Nat} (h : a ≠ 0) : a - 1 + 1 = a := by
  induction a with
  | zero => contradiction
  | succ => rfl","We will prove the theorem by considering two cases based on the value of \( a \).

1. **Case 1: \( a = 0 \)**
- We have the assumption \( a \neq 0 \). Therefore, the case \( a = 0 \) leads to a direct contradiction. Hence, this case is not possible, and we can conclude the proof for this case.

2. **Case 2: \( a \) is a successor of some natural number**
- Let \( a = n + 1 \) for some natural number \( n \). We need to show that \( a - 1 + 1 = a \).
- By the definition of subtraction and addition, \( a - 1 + 1 = (n + 1) - 1 + 1 \).
- Simplifying the right-hand side, we get \( (n + 1) - 1 + 1 = n + 1 \).
- Since \( n + 1 = a \), the equality \( a - 1 + 1 = a \) holds trivially in this case.

Since both cases have been considered and the equality holds in each case, we conclude that for any natural number \( a \) such that \( a \neq 0 \), the expression \( a - 1 + 1 \) is equal to \( a \). This completes the proof.","theorem Nat.sub_one_add_one {a : Nat} (h : a ≠ 0) : a - 1 + 1 = a := by
  induction a with
/- First, consider the case where \( a = 0 \). Since we have the assumption \( a \neq 0 \), this case leads to a direct contradiction. Therefore, we can conclude the proof for this case. -/
  | zero => contradiction
/- Next, consider the case where \( a \) is a successor of some natural number, i.e., \( a = n + 1 \) for some \( n \). In this case, the expression \( a - 1 + 1 \) simplifies to \( (n + 1) - 1 + 1 \). By the definition of subtraction and addition, this is equal to \( n + 1 \), which is exactly \( a \). Therefore, the equality \( a - 1 + 1 = a \) holds trivially in this case. -/
  | succ => rfl","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31225,Nat.eq_add_of_sub_eq,theorem Nat.eq_add_of_sub_eq {a b c : Nat} (hle : b ≤ a) (h : a - b = c) : a = c + b := by sorry,"Subtraction Identity: \(a = c + b\) if \(a - b = c\) and \(b \leq a\) : For any natural numbers \(a\), \(b\), and \(c\), if \(b \leq a\) and \(a - b = c\), then \(a = c + b\).","theorem Nat.eq_add_of_sub_eq {a b c : Nat} (hle : b ≤ a) (h : a - b = c) : a = c + b := by
  rw [h.symm, Nat.sub_add_cancel hle]","We start with the given conditions: \(b \leq a\) and \(a - b = c\). We need to show that \(a = c + b\).

1. **Symmetry of Equality:**
Since \(a - b = c\), by the symmetry of equality, we can rewrite this as \(c = a - b\).

2. **Subtraction and Addition Cancel Each Other:**
Using the property of natural numbers, for any \(a\) and \(b\) where \(b \leq a\), the equation \(a - b + b = a\) holds. Therefore, we can rewrite \(a\) as:
\[
a = (a - b) + b
\]

3. **Substitute \(c\) for \(a - b\):**
From the symmetry of equality, we know \(c = a - b\). Substituting \(c\) for \(a - b\) in the equation \(a = (a - b) + b\), we get:
\[
a = c + b
\]

Thus, we have shown that \(a = c + b\). This completes the proof. \(\blacksquare\)","theorem Nat.eq_add_of_sub_eq {a b c : Nat} (hle : b ≤ a) (h : a - b = c) : a = c + b := by
/- First, we use the symmetry of the equality \(a - b = c\) to rewrite the goal. This gives us \(a = c + b\). Next, we use the property that for any natural numbers \(a\) and \(b\) where \(b \leq a\), the equation \(a - b + b = a\) holds. Therefore, we can rewrite \(a\) as \(a - b + b\). Combining these, we get \(a = c + b\). -/
  rw [h.symm, Nat.sub_add_cancel hle]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31226,Nat.eq_self_sub_one,theorem Nat.eq_self_sub_one (n : Nat) : n = n - 1 ↔ n = 0 := by sorry,"Natural Number Equals Its Predecessor if and Only if It is Zero: \( n = n - 1 \leftrightarrow n = 0 \) : For any natural number \( n \), it holds that \( n = n - 1 \) if and only if \( n = 0 \).","theorem Nat.eq_self_sub_one (n : Nat) : n = n - 1 ↔ n = 0 := by
  cases n <;> simp [add_one_ne]","We will consider every possible case of \( n \).

1. **Case 1: \( n = 0 \)**
- We need to show that \( 0 = 0 - 1 \leftrightarrow 0 = 0 \).
- Simplifying the left-hand side, we get \( 0 = 0 - 1 \), which is equivalent to \( 0 = 0 \) since \( 0 - 1 = 0 \) is false. Therefore, the left-hand side is false.
- The right-hand side is \( 0 = 0 \), which is true.
- Since both sides are equivalent to the same truth value (false on the left and true on the right), the equivalence holds.

2. **Case 2: \( n = k + 1 \) for some \( k \in \mathbb{N} \)**
- We need to show that \( k + 1 = (k + 1) - 1 \leftrightarrow k + 1 = 0 \).
- Simplifying the left-hand side, we get \( k + 1 = k \), which is false for any \( k \in \mathbb{N} \).
- The right-hand side is \( k + 1 = 0 \), which is also false for any \( k \in \mathbb{N} \).
- Since both sides are equivalent to the same truth value (false on both sides), the equivalence holds.

Therefore, for any natural number \( n \), \( n = n - 1 \) if and only if \( n = 0 \). This completes the proof.","theorem Nat.eq_self_sub_one (n : Nat) : n = n - 1 ↔ n = 0 := by
  cases n <;> simp [add_one_ne]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31227,Nat.add_sub_add_left,theorem Nat.add_sub_add_left (k n m : Nat) : (k + n) - (k + m) = n - m := by sorry,"Left Addition Cancellation in Subtraction of Natural Numbers: \( k + n - (k + m) = n - m \) : For any natural numbers \( k \), \( n \), and \( m \), the equation \( k + n - (k + m) = n - m \) holds.","theorem Nat.add_sub_add_left (k n m : Nat) : (k + n) - (k + m) = n - m := by
  rw [Nat.add_comm k n, Nat.add_comm k m, Nat.add_sub_add_right]","To prove the equation \( k + n - (k + m) = n - m \), we start by using the commutativity of addition. Specifically, we rewrite \( k + n \) as \( n + k \) and \( k + m \) as \( m + k \). This transforms the equation into:
\[
n + k - (m + k) = n - m
\]
Next, we apply the theorem that states for any natural numbers \( n \), \( k \), and \( m \), the equation \( n + k - (m + k) = n - m \) holds. This simplifies our goal to:
\[
n - m = n - m
\]
This is trivially true by the properties of equality. Therefore, the original equation \( k + n - (k + m) = n - m \) holds for any natural numbers \( k \), \( n \), and \( m \). This completes the proof. \(\blacksquare\)","theorem Nat.add_sub_add_left (k n m : Nat) : (k + n) - (k + m) = n - m := by
/- First, we use the commutativity of addition to rewrite \( k + n \) as \( n + k \) and \( k + m \) as \( m + k \). This transforms the goal \( k + n - (k + m) = n - m \) into \( n + k - (m + k) = n - m \). Then, we apply the theorem that states \( n + k - (m + k) = n - m \) for any natural numbers \( n \), \( k \), and \( m \). This simplifies our goal to \( n - m = n - m \), which is trivially true by the properties of equality. -/
  rw [Nat.add_comm k n, Nat.add_comm k m, Nat.add_sub_add_right]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31228,Nat.sub_one_eq_self,theorem Nat.sub_one_eq_self (n : Nat) : n - 1 = n ↔ n = 0 := by sorry,"Natural Number Equals Its Predecessor if and Only if It is Zero: \( n - 1 = n \leftrightarrow n = 0 \) : For any natural number \( n \), the equation \( n - 1 = n \) holds if and only if \( n = 0 \).","theorem Nat.sub_one_eq_self (n : Nat) : n - 1 = n ↔ n = 0 := by
  cases n <;> simp [ne_add_one]","We will consider every possible case of \( n \).

**Case 1: \( n = 0 \)**
- The goal is to show \( 0 - 1 = 0 \leftrightarrow 0 = 0 \).
- Simplifying the left-hand side, we get \( 0 - 1 = 0 \). Since \( 0 - 1 \) is defined as \( 0 \) (as \( 0 - 1 \) is not a valid natural number, it is treated as \( 0 \)), the left-hand side simplifies to \( 0 = 0 \), which is true.
- Therefore, \( 0 - 1 = 0 \leftrightarrow 0 = 0 \) is true.

**Case 2: \( n = k + 1 \) for some \( k \in \mathbb{N} \)**
- The goal is to show \( (k + 1) - 1 = k + 1 \leftrightarrow k + 1 = 0 \).
- Simplifying the left-hand side, we get \( (k + 1) - 1 = k \). Therefore, the left-hand side simplifies to \( k = k + 1 \).
- The equation \( k = k + 1 \) is false for any natural number \( k \), and the right-hand side \( k + 1 = 0 \) is also false for any natural number \( k \).
- Therefore, \( (k + 1) - 1 = k + 1 \leftrightarrow k + 1 = 0 \) is true because both sides are false.

Since both cases are true, we conclude that for any natural number \( n \), the equation \( n - 1 = n \) holds if and only if \( n = 0 \). This completes the proof. \(\blacksquare\)","theorem Nat.sub_one_eq_self (n : Nat) : n - 1 = n ↔ n = 0 := by
  cases n <;> simp [ne_add_one]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31229,Nat.zero_sub,theorem Nat.zero_sub (n : Nat) : 0 - n = 0 := by sorry,"Subtraction of Natural Number from Zero is Zero : For any natural number \( n \), the subtraction \( 0 - n \) is equal to \( 0 \), i.e., \( 0 - n = 0 \).","theorem Nat.zero_sub (n : Nat) : 0 - n = 0 := by
  induction n with
  | zero => rfl
  | succ n ih => simp only [ih, Nat.sub_succ]; decide","We prove this by induction on \( n \).

1. **Base Case:**
- Consider \( n = 0 \). The goal is to show that \( 0 - 0 = 0 \).
- This is trivially true by the reflexive property of equality, since both sides of the equation are definitionally equal.

2. **Inductive Step:**
- Assume the induction hypothesis that for some natural number \( k \), \( 0 - k = 0 \).
- We need to show that \( 0 - (\text{succ}(k)) = 0 \).
- Using the induction hypothesis and the definition of subtraction for natural numbers, we simplify the expression \( 0 - (\text{succ}(k)) \) to \( \text{pred}(0) \).
- Since the predecessor of \( 0 \) is \( 0 \), the goal is reduced to showing \( 0 = 0 \), which is trivially true.

By induction, the theorem holds for all natural numbers \( n \). Therefore, for any natural number \( n \), \( 0 - n = 0 \). This completes the proof.","theorem Nat.zero_sub (n : Nat) : 0 - n = 0 := by
  induction n with
/- First, consider the base case where \( n = 0 \). The goal is to show that \( 0 - 0 = 0 \). This is trivially true by the reflexive property of equality, since both sides of the equation are definitionally equal. -/
  | zero => rfl
/- Next, consider the inductive step where \( n = \text{succ}(k) \) for some natural number \( k \). We assume the induction hypothesis \( 0 - k = 0 \) and need to show that \( 0 - (\text{succ}(k)) = 0 \). Using the induction hypothesis and the definition of subtraction for natural numbers, we simplify the expression \( 0 - (\text{succ}(k)) \) to \( \text{pred}(0) \). Since the predecessor of \( 0 \) is \( 0 \), the goal is reduced to showing \( 0 = 0 \), which is trivially true. -/
  | succ n ih => simp only [ih, Nat.sub_succ]; decide","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31230,Nat.left_distrib,theorem Nat.left_distrib (n m k : Nat) : n * (m + k) = n * m + n * k := by sorry,"Left Distributive Property of Multiplication over Addition in Natural Numbers: \( n \cdot (m + k) = n \cdot m + n \cdot k \) : For any natural numbers \( n \), \( m \), and \( k \), the equation \( n \cdot (m + k) = n \cdot m + n \cdot k \) holds. This theorem demonstrates the left distributive property of multiplication over addition in the natural numbers.","theorem Nat.left_distrib (n m k : Nat) : n * (m + k) = n * m + n * k := by
  induction n with
  | zero      => repeat rw [Nat.zero_mul]
  | succ n ih => simp [succ_mul, ih]; rw [Nat.add_assoc, Nat.add_assoc (n*m)]; apply congrArg; apply Nat.add_left_comm","We prove the theorem by induction on \( n \).

**Base Case:**
Consider \( n = 0 \). Using the zero multiplication identity, which states that \( 0 \times m = 0 \) for any natural number \( m \), we have:
\[
0 \times (m + k) = 0
\]
and
\[
0 \times m + 0 \times k = 0 + 0 = 0
\]
Thus, the base case is proved.

**Inductive Step:**
Assume the inductive hypothesis that for some natural number \( n' \), the equation \( n' \times (m + k) = n' \times m + n' \times k \) holds. We need to show that the equation holds for \( n = n' + 1 \). Using the successor multiplication identity, which states that \((n' + 1) \times m = n' \times m + m\), we have:
\[
(n' + 1) \times (m + k) = (n' \times (m + k)) + (m + k)
\]
By the inductive hypothesis, we can replace \( n' \times (m + k) \) with \( n' \times m + n' \times k \), so the goal becomes:
\[
(n' \times m + n' \times k) + (m + k) = (n' \times m + m) + (n' \times k + k)
\]
Using the associativity of addition, we can rewrite the left-hand side as:
\[
n' \times m + (n' \times k + (m + k))
\]
and the right-hand side as:
\[
n' \times m + (m + (n' \times k + k))
\]
Since the left-hand side and the right-hand side are now in the same form, we can apply the function congruence theorem to show that they are equal. Finally, using the left-commutativity of addition, we can conclude that:
\[
n' \times k + (m + k) = m + (n' \times k + k)
\]
This completes the inductive step.

By the principle of mathematical induction, the theorem holds for all natural numbers \( n \). Therefore, the left distributive property of multiplication over addition in the natural numbers is proved. \(\blacksquare\)","theorem Nat.left_distrib (n m k : Nat) : n * (m + k) = n * m + n * k := by
  induction n with
/- First, we consider the base case where \( n = 0 \). Using the zero multiplication identity, which states that \( 0 \times m = 0 \) for any natural number \( m \), we can simplify the goal \( 0 \times (m + k) = 0 \times m + 0 \times k \) to \( 0 = 0 + 0 \). This is trivially true, so the base case is proved. -/
  | zero      => repeat rw [Nat.zero_mul]
/- Next, we consider the inductive step where \( n = n' + 1 \) for some natural number \( n' \). We assume the inductive hypothesis \( n' \times (m + k) = n' \times m + n' \times k \) and use the successor multiplication identity, which states that \((n' + 1) \times m = n' \times m + m\). Simplifying the goal using this identity, we get:
\[
(n' + 1) \times (m + k) = (n' \times (m + k)) + (m + k)
\]
By the inductive hypothesis, we can replace \( n' \times (m + k) \) with \( n' \times m + n' \times k \), so the goal becomes:
\[
(n' \times m + n' \times k) + (m + k) = (n' \times m + m) + (n' \times k + k)
\]
Using the associativity of addition, we can rewrite the left-hand side as:
\[
n' \times m + (n' \times k + (m + k))
\]
and the right-hand side as:
\[
n' \times m + (m + (n' \times k + k))
\]
Since the left-hand side and the right-hand side are now in the same form, we can apply the function congruence theorem to show that they are equal. Finally, using the left-commutativity of addition, we can conclude that:
\[
n' \times k + (m + k) = m + (n' \times k + k)
\]
This completes the inductive step. -/
  | succ n ih => simp [succ_mul, ih]; rw [Nat.add_assoc, Nat.add_assoc (n*m)]; apply congrArg; apply Nat.add_left_comm","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31231,Nat.add_sub_self_left,theorem Nat.add_sub_self_left (a b : Nat) : (a + b) - a = b := by sorry,"Left Addition and Subtraction Identity in Natural Numbers : For any natural numbers \(a\) and \(b\), the expression \(a + b - a\) is equal to \(b\), i.e., \(a + b - a = b\).","theorem Nat.add_sub_self_left (a b : Nat) : (a + b) - a = b := by
  induction a with
  | zero => simp
  | succ a ih =>
    rw [Nat.succ_add, Nat.succ_sub_succ]
    apply ih","We prove this by induction on \(a\).

1. **Base Case: \(a = 0\)**

We need to show that \(0 + b - 0 = b\). Simplifying the expression, we get:
\[
0 + b - 0 = b
\]
which is trivially true.

2. **Inductive Step:**

Assume that for some \(a\), the statement \(a + b - a = b\) holds. We need to show that \((a + 1) + b - (a + 1) = b\).

Using the properties of natural numbers:
- By the successor addition identity, \((a + 1) + b = (a + b) + 1\).
- By the subtraction of successors, \((a + b) + 1 - (a + 1) = a + b - a\).

Therefore, the goal simplifies to:
\[
a + b - a = b
\]
By the induction hypothesis, \(a + b - a = b\) is true. Hence, the inductive step is proved.

By induction, the statement \(a + b - a = b\) holds for all natural numbers \(a\) and \(b\). This completes the proof.","theorem Nat.add_sub_self_left (a b : Nat) : (a + b) - a = b := by
  induction a with
/- For the base case where \(a = 0\), we need to show that \(0 + b - 0 = b\). Simplifying the expression, we get \(b = b\), which is trivially true. -/
  | zero => simp
/- For the inductive step, assume \(a + b - a = b\) holds for some \(a\). We need to show that \((a + 1) + b - (a + 1) = b\). -/
  | succ a ih =>
/- Using the properties of natural numbers, we rewrite the goal \((a + 1) + b - (a + 1) = b\) as follows:
1. By the successor addition identity, \((a + 1) + b = (a + b) + 1\).
2. By the subtraction of successors, \((a + b) + 1 - (a + 1) = a + b - a\).
Thus, the goal simplifies to \(a + b - a = b\). -/
    rw [Nat.succ_add, Nat.succ_sub_succ]
/- To prove \(a + b - a = b\), we use the induction hypothesis \(a + b - a = b\), which directly gives us the desired result. -/
/- To prove \(a + b - a = b\), we use the induction hypothesis \(a + b - a = b\), which directly gives us the desired result. -/
    apply ih","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31232,Nat.sub_le_succ_sub,theorem Nat.sub_le_succ_sub (a i : Nat) : a - i ≤ a.succ - i := by sorry,"Subtraction Inequality with Successor in Natural Numbers : For any natural numbers \(a\) and \(i\), the inequality \(a - i \leq a + 1 - i\) holds.","theorem Nat.sub_le_succ_sub (a i : Nat) : a - i ≤ a.succ - i := by
  cases i with
  | zero => apply Nat.le_of_lt; apply Nat.lt_succ_self
  | succ i => rw [Nat.sub_succ, Nat.succ_sub_succ]; apply Nat.pred_le","We will prove the inequality \( a - i \leq a + 1 - i \) for any natural numbers \( a \) and \( i \) by considering two cases based on the value of \( i \).

1. **Case 1: \( i = 0 \)**
- To prove \( a - 0 \leq a + 1 - 0 \), it suffices to show \( a - 0 < a + 1 - 0 \).
- Since \( a - 0 = a \) and \( a + 1 - 0 = a + 1 \), this reduces to showing \( a < a + 1 \).
- By the property that any natural number is less than its successor, we have \( a < a + 1 \).
- Therefore, \( a - 0 \leq a + 1 - 0 \) holds.

2. **Case 2: \( i = i' + 1 \) for some natural number \( i' \)**
- We need to show \( a - (i' + 1) \leq a + 1 - (i' + 1) \).
- Using the properties of subtraction and successors, we can rewrite the goal as \( (a - i').\text{pred} \leq a - i' \).
- By the property that the predecessor of any natural number is less than or equal to the number itself, we have \( (a - i').\text{pred} \leq a - i' \).
- Therefore, \( a - (i' + 1) \leq a + 1 - (i' + 1) \) holds.

Since both cases are covered, the inequality \( a - i \leq a + 1 - i \) holds for any natural numbers \( a \) and \( i \). This completes the proof. \(\blacksquare\)","theorem Nat.sub_le_succ_sub (a i : Nat) : a - i ≤ a.succ - i := by
  cases i with
/- First, consider the case where \( i = 0 \). To prove \( a - 0 \leq a + 1 - 0 \), it suffices to show \( a - 0 < a + 1 - 0 \). Since \( a - 0 = a \) and \( a + 1 - 0 = a + 1 \), this reduces to showing \( a < a + 1 \). By the property that any natural number is less than its successor, we have \( a < a + 1 \). Therefore, \( a - 0 \leq a + 1 - 0 \) holds. -/
  | zero => apply Nat.le_of_lt; apply Nat.lt_succ_self
/- Next, consider the case where \( i = i' + 1 \) for some natural number \( i' \). We need to show \( a - (i' + 1) \leq a + 1 - (i' + 1) \). Using the properties of subtraction and successors, we can rewrite the goal as \( (a - i').\text{pred} \leq a - i' \). By the property that the predecessor of any natural number is less than or equal to the number itself, we have \( (a - i').\text{pred} \leq a - i' \). Therefore, \( a - (i' + 1) \leq a + 1 - (i' + 1) \) holds. -/
  | succ i => rw [Nat.sub_succ, Nat.succ_sub_succ]; apply Nat.pred_le","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31233,Nat.sub_succ_lt_self,theorem Nat.sub_succ_lt_self (a i : Nat) (h : i < a) : a - (i + 1) < a - i := by sorry,"Subtraction of Successor Preserves Strict Inequality in Natural Numbers : For any natural numbers \( a \) and \( i \) such that \( i < a \), it holds that \( a - (i + 1) < a - i \).","theorem Nat.sub_succ_lt_self (a i : Nat) (h : i < a) : a - (i + 1) < a - i := by
  rw [Nat.add_succ, Nat.sub_succ]
  apply Nat.pred_lt
  apply Nat.not_eq_zero_of_lt
  apply Nat.zero_lt_sub_of_lt
  assumption","We start with the goal of proving \( a - (i + 1) < a - i \). Using the properties of natural numbers, we know that adding the successor of a natural number is the same as adding one to the sum, and subtracting the successor of a natural number is the same as taking the predecessor of the result of the subtraction. Therefore, the goal \( a - (i + 1) < a - i \) can be rewritten as \( (a - i).pred < a - i \).

Next, we use the theorem that the predecessor of a natural number is strictly less than the number itself if the number is not zero. Thus, to prove \( (a - i).pred < a - i \), it suffices to show that \( a - i \neq 0 \).

To show \( a - i \neq 0 \), we use the theorem that if a natural number \( b \) is less than another natural number \( a \), then \( a \) is not zero. Therefore, it suffices to show that \( i < a \).

Finally, we use the theorem that if \( i < a \), then \( 0 < a - i \). Since \( i < a \) is given as a hypothesis, it is already proved. Therefore, \( 0 < a - i \) holds, and thus \( a - i \neq 0 \).

Since \( a - i \neq 0 \), we have \( (a - i).pred < a - i \), which completes the proof that \( a - (i + 1) < a - i \).","theorem Nat.sub_succ_lt_self (a i : Nat) (h : i < a) : a - (i + 1) < a - i := by
/- First, we use the fact that adding the successor of a natural number is the same as adding one to the sum, and the fact that subtracting the successor of a natural number is the same as taking the predecessor of the result of the subtraction. This transforms the goal \( a - (i + 1) < a - i \) into \( (a - i).pred < a - i \). -/
  rw [Nat.add_succ, Nat.sub_succ]
/- To prove \( (a - i).pred < a - i \), it suffices to show that \( a - i \neq 0 \), using the theorem that the predecessor of a natural number is strictly less than the number itself if the number is not zero. -/
  apply Nat.pred_lt
/- To show \( a - i \neq 0 \), it suffices to show that \( i < a \), using the theorem that if a natural number \( b \) is less than another natural number \( a \), then \( a \) is not zero. -/
  apply Nat.not_eq_zero_of_lt
/- To show \( i < a \), it suffices to show that \( 0 < a - i \), using the theorem that if \( i < a \), then \( 0 < a - i \). -/
  apply Nat.zero_lt_sub_of_lt
/- The current goal \( i < a \) has already been given as a hypothesis, so it is already proved. -/
  assumption","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31234,Nat.sub_eq_iff_eq_add',theorem Nat.sub_eq_iff_eq_add' {c : Nat} (h : b ≤ a) : a - b = c ↔ a = b + c := by sorry,"Subtraction and Addition Equivalence in Natural Numbers: \(a - b = c \leftrightarrow a = b + c\) : For any natural numbers \(a\), \(b\), and \(c\) such that \(b \leq a\), the equation \(a - b = c\) holds if and only if \(a = b + c\).","theorem Nat.sub_eq_iff_eq_add' {c : Nat} (h : b ≤ a) : a - b = c ↔ a = b + c := by
  rw [Nat.add_comm, Nat.sub_eq_iff_eq_add h]","We start with the goal of proving that for any natural numbers \(a\), \(b\), and \(c\) such that \(b \leq a\), the equation \(a - b = c\) holds if and only if \(a = b + c\).

1. **Step 1:**
We use the commutativity of addition, which states that for any natural numbers \(a\) and \(b\), \(a + b = b + a\). This allows us to rewrite the goal \(a - b = c \leftrightarrow a = b + c\) as \(a - b = c \leftrightarrow a = c + b\).

2. **Step 2:**
Next, we use the theorem that for any natural numbers \(a\), \(b\), and \(c\) such that \(b \leq a\), the equation \(a - b = c\) holds if and only if \(a = c + b\). This theorem directly simplifies our goal to \(a = c + b \leftrightarrow a = c + b\), which is trivially true.

Therefore, we have shown that \(a - b = c\) if and only if \(a = b + c\). This completes the proof. \(\blacksquare\)","theorem Nat.sub_eq_iff_eq_add' {c : Nat} (h : b ≤ a) : a - b = c ↔ a = b + c := by
/- First, we use the commutativity of addition to rewrite the goal \(a - b = c \leftrightarrow a = b + c\) as \(a - b = c \leftrightarrow a = c + b\). Then, we use the theorem that for any natural numbers \(a\), \(b\), and \(c\) such that \(b \leq a\), the equation \(a - b = c\) holds if and only if \(a = c + b\). This simplifies our goal to \(a = c + b \leftrightarrow a = c + b\), which is trivially true. -/
  rw [Nat.add_comm, Nat.sub_eq_iff_eq_add h]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31235,Nat.add_sub_add_right,theorem Nat.add_sub_add_right (n k m : Nat) : (n + k) - (m + k) = n - m := by sorry,"Right Addition Cancellation in Subtraction of Natural Numbers : For any natural numbers \( n \), \( k \), and \( m \), the equation \( n + k - (m + k) = n - m \) holds.","theorem Nat.add_sub_add_right (n k m : Nat) : (n + k) - (m + k) = n - m := by
  induction k with
  | zero => simp
  | succ k ih => simp [← Nat.add_assoc, succ_sub_succ_eq_sub, ih]","We will prove this by induction on \( k \).

**Base Case:**
Consider \( k = 0 \). We need to show that \( n + 0 - (m + 0) = n - m \). Simplifying the left-hand side, we get:
\[
n + 0 - m = n - m
\]
This is trivially true.

**Inductive Step:**
Assume the inductive hypothesis that for some natural number \( k' \), the equation \( n + k' - (m + k') = n - m \) holds. We need to show that \( n + (k' + 1) - (m + (k' + 1)) = n - m \).

Using the associativity of addition, we can rewrite the left-hand side as:
\[
n + (k' + 1) - (m + (k' + 1)) = (n + k' + 1) - (m + k' + 1)
\]
By the successor subtraction identity, this simplifies to:
\[
(n + k') - (m + k')
\]
By the inductive hypothesis, this is equal to:
\[
n - m
\]
Thus, the inductive step holds.

By the principle of mathematical induction, the equation \( n + k - (m + k) = n - m \) holds for all natural numbers \( n \), \( k \), and \( m \). This completes the proof.","theorem Nat.add_sub_add_right (n k m : Nat) : (n + k) - (m + k) = n - m := by
  induction k with
/- First, consider the base case where \( k = 0 \). We need to show that \( n + 0 - (m + 0) = n - m \). Simplifying the left-hand side, we get \( n + 0 - m = n - m \), which is trivially true. -/
  | zero => simp
/- Next, consider the inductive step where \( k = k' + 1 \) for some natural number \( k' \). We assume the inductive hypothesis that \( n + k' - (m + k') = n - m \). We need to show that \( n + (k' + 1) - (m + (k' + 1)) = n - m \). Using the associativity of addition, we can rewrite the left-hand side as \( (n + k' + 1) - (m + k' + 1) \). By the successor subtraction identity, this simplifies to \( (n + k') - (m + k') \). By the inductive hypothesis, this is equal to \( n - m \). Therefore, the inductive step holds. -/
  | succ k ih => simp [← Nat.add_assoc, succ_sub_succ_eq_sub, ih]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31237,Nat.succ_mul,theorem Nat.succ_mul (n m : Nat) : (succ n) * m = (n * m) + m := by sorry,"Successor Multiplication Identity: \((n + 1) \cdot m = n \cdot m + m\) : For any natural numbers \( n \) and \( m \), the successor of \( n \) multiplied by \( m \) is equal to \( n \) multiplied by \( m \) plus \( m \), i.e., \((n + 1) \cdot m = n \cdot m + m\).","theorem Nat.succ_mul (n m : Nat) : (succ n) * m = (n * m) + m := by
  induction m with
  | zero => rfl
  | succ m ih => rw [mul_succ, add_succ, ih, mul_succ, add_succ, Nat.add_right_comm]","We prove this by induction on \( m \).

1. **Base Case: \( m = 0 \)**
\[
n \cdot 0 = n \cdot 0 + 0
\]
This is trivially true because both sides are definitionally equal to \( 0 \).

2. **Inductive Step: \( m = m' + 1 \)**
Assume the inductive hypothesis:
\[
n \cdot m' = n \cdot m' + m'
\]
We need to show:
\[
n \cdot (m' + 1) = n \cdot m' + n + (m' + 1)
\]

- Using the definition of multiplication by successor:
\[
n \cdot (m' + 1) = n \cdot m' + n
\]
- Using the definition of addition by successor:
\[
n \cdot m' + n = (n \cdot m' + n) + 1
\]
- Applying the inductive hypothesis:
\[
(n \cdot m' + n) + 1 = (n \cdot m' + m') + n + 1
\]
- Using the definition of multiplication by successor again:
\[
(n \cdot m' + m') + n + 1 = n \cdot m' + n + (m' + 1)
\]
- Using the right commutativity of addition:
\[
n \cdot m' + n + (m' + 1) = n \cdot m' + (m' + 1) + n
\]
- Simplifying the expression:
\[
n \cdot m' + (m' + 1) + n = (n \cdot m' + m' + n) + 1
\]
- Using the inductive hypothesis again:
\[
(n \cdot m' + m' + n) + 1 = (n \cdot m' + n + m') + 1
\]
- Simplifying the final expression:
\[
(n \cdot m' + n + m') + 1 = (n \cdot m' + n + m') + 1
\]

Thus, the inductive step is complete, and by induction, the theorem holds for all natural numbers \( m \).

\(\blacksquare\)","theorem Nat.succ_mul (n m : Nat) : (succ n) * m = (n * m) + m := by
  induction m with
/- First, consider the base case where \( m = 0 \). The goal is to show that \( n \cdot 0 = n \cdot 0 + 0 \). This is trivially true because both sides are definitionally equal to \( 0 \). -/
  | zero => rfl
/- Next, consider the inductive step where \( m = m' + 1 \) for some \( m' \). We assume the inductive hypothesis \( n \cdot m' = n \cdot m' + m' \) and need to show that \( n \cdot (m' + 1) = n \cdot m' + n + (m' + 1) \).

1. **Using the definition of multiplication by successor:**
\[
n \cdot (m' + 1) = n \cdot m' + n
\]
2. **Using the definition of addition by successor:**
\[
n \cdot m' + n = (n \cdot m' + n) + 1
\]
3. **Applying the inductive hypothesis:**
\[
(n \cdot m' + n) + 1 = (n \cdot m' + m') + n + 1
\]
4. **Using the definition of multiplication by successor again:**
\[
(n \cdot m' + m') + n + 1 = n \cdot m' + n + (m' + 1)
\]
5. **Using the right commutativity of addition:**
\[
n \cdot m' + n + (m' + 1) = n \cdot m' + (m' + 1) + n
\]
6. **Simplifying the expression:**
\[
n \cdot m' + (m' + 1) + n = (n \cdot m' + m' + n) + 1
\]
7. **Using the inductive hypothesis again:**
\[
(n \cdot m' + m' + n) + 1 = (n \cdot m' + n + m') + 1
\]
8. **Simplifying the final expression:**
\[
(n \cdot m' + n + m') + 1 = (n \cdot m' + n + m') + 1
\]

Thus, the inductive step is complete. -/
  | succ m ih => rw [mul_succ, add_succ, ih, mul_succ, add_succ, Nat.add_right_comm]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31238,Nat.le_sub_of_add_le,theorem Nat.le_sub_of_add_le {a b c : Nat} (h : a + b ≤ c) : a ≤ c - b := by sorry,"Subtraction and Addition Inequality: \(a + b \leq c \to a \leq c - b\) : For any natural numbers \(a\), \(b\), and \(c\), if \(a + b \leq c\), then \(a \leq c - b\).","theorem Nat.le_sub_of_add_le {a b c : Nat} (h : a + b ≤ c) : a ≤ c - b := by
  match le.dest h with
  | ⟨d, hd⟩ =>
    apply @le.intro _ _ d
    have hd : a + d + b = c := by simp [← hd, Nat.add_comm, Nat.add_assoc, Nat.add_left_comm]
    have hd := Nat.sub_eq_of_eq_add hd.symm
    exact hd.symm","We start by assuming that \( a + b \leq c \). This means there exists a natural number \( d \) such that \( a + b + d = c \).

To prove that \( a \leq c - b \), we use the introduction rule for the less-than-or-equal relation. It suffices to show that \( a + d = c - b \).

We construct a new lemma that states \( a + d + b = c \) by simplifying the expression \( a + b + d = c \) using the commutativity and associativity of addition in natural numbers, as well as the left-commutativity of addition.

Next, we derive another lemma that states \( c - b = a + d \) by using the property that if \( a = c + b \), then \( a - b = c \).

Since we have shown that \( c - b = a + d \), by the symmetry of equality, we can conclude that \( a + d = c - b \).

Therefore, \( a \leq c - b \). This completes the proof. \(\blacksquare\)","theorem Nat.le_sub_of_add_le {a b c : Nat} (h : a + b ≤ c) : a ≤ c - b := by
  match le.dest h with
/- We assume that there exists a natural number \( d \) such that \( a + b + d = c \). This assumption will help us prove the main goal. -/
  | ⟨d, hd⟩ =>
/- To prove that \( a \leq c - b \), using the introduction rule for the less-than-or-equal relation, it suffices to show that \( a + d = c - b \). -/
    apply @le.intro _ _ d
/- We construct a new lemma \( hd \) that states \( a + d + b = c \). This is done by simplifying the expression \( a + b + d = c \) using the commutativity and associativity of addition in natural numbers, as well as the left-commutativity of addition. -/
    have hd : a + d + b = c := by simp [← hd, Nat.add_comm, Nat.add_assoc, Nat.add_left_comm]
/- We construct another lemma \( hd \) that states \( c - b = a + d \). This is derived from the fact that \( a + d + b = c \) by using the property that if \( a = c + b \), then \( a - b = c \). -/
    have hd := Nat.sub_eq_of_eq_add hd.symm
/- Since we have already shown that \( c - b = a + d \), by the symmetry of equality, we can conclude that \( a + d = c - b \). -/
/- Since we have shown that \( c - b = a + d \), by the symmetry of equality, we can conclude that \( a + d = c - b \). -/
    exact hd.symm","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31239,Nat.mul_sub_one,theorem Nat.mul_sub_one (n m : Nat) : n * (m - 1) = n * m - n := by sorry,"Multiplication by Predecessor on the Right: \( n \times (m - 1) = n \times m - n \) : For any natural numbers \( n \) and \( m \), the product \( n \times (m - 1) \) is equal to \( n \times m - n \).","theorem Nat.mul_sub_one (n m : Nat) : n * (m - 1) = n * m - n := by
  rw [Nat.mul_comm, Nat.sub_one_mul , Nat.mul_comm]","We start by using the commutativity of multiplication to rewrite the left-hand side of the equation:
\[
n \times (m - 1) = (m - 1) \times n
\]
Next, we apply the left distributive property of multiplication over subtraction:
\[
(m - 1) \times n = m \times n - n
\]
Finally, we use the commutativity of multiplication again to rewrite \( m \times n \) as \( n \times m \):
\[
m \times n - n = n \times m - n
\]
Thus, we have shown that:
\[
n \times (m - 1) = n \times m - n
\]
This completes the proof. \(\blacksquare\)","theorem Nat.mul_sub_one (n m : Nat) : n * (m - 1) = n * m - n := by
/- First, we use the commutativity of multiplication to rewrite \( n \times (m - 1) \) as \( (m - 1) \times n \). Then, we use the left distributive property of multiplication over subtraction to rewrite \( (m - 1) \times n \) as \( m \times n - n \). Finally, we use the commutativity of multiplication again to rewrite \( m \times n \) as \( n \times m \). Thus, our goal is to show that \( n \times m - n = n \times m - n \), which is trivially true by the properties of equality. -/
  rw [Nat.mul_comm, Nat.sub_one_mul , Nat.mul_comm]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31240,Nat.mul_pred,theorem Nat.mul_pred (n m : Nat) : n * pred m = n * m - n := by sorry,"Multiplication by Predecessor: \( n \cdot \text{pred}(m) = n \cdot m - n \) : For any natural numbers \( n \) and \( m \), the product of \( n \) and the predecessor of \( m \) is equal to the product of \( n \) and \( m \) minus \( n \). In other words, \( n \cdot \text{pred}(m) = n \cdot m - n \).","theorem Nat.mul_pred (n m : Nat) : n * pred m = n * m - n := by
  rw [Nat.mul_comm, pred_mul, Nat.mul_comm]","We start with the goal of proving that \( n \cdot \text{pred}(m) = n \cdot m - n \) for any natural numbers \( n \) and \( m \).

1. **Step 1:**
Using the commutativity of multiplication, we rewrite the goal:
\[
n \cdot \text{pred}(m) = n \cdot m - n
\]
as:
\[
\text{pred}(m) \cdot n = n \cdot m - n
\]

2. **Step 2:**
We use the theorem that the product of the predecessor of \( m \) and \( n \) is equal to the product of \( m \) and \( n \) minus \( n \):
\[
\text{pred}(m) \cdot n = m \cdot n - n
\]

3. **Step 3:**
Using the commutativity of multiplication again, we rewrite \( m \cdot n - n \) as:
\[
n \cdot m - n
\]

Thus, the goal is now:
\[
n \cdot m - n = n \cdot m - n
\]
which is trivially true by the properties of equality. Therefore, we have shown that \( n \cdot \text{pred}(m) = n \cdot m - n \). This completes the proof. \(\blacksquare\)","theorem Nat.mul_pred (n m : Nat) : n * pred m = n * m - n := by
/- First, we use the commutativity of multiplication to rewrite the goal \( n \cdot \text{pred}(m) = n \cdot m - n \) as \( \text{pred}(m) \cdot n = n \cdot m - n \). Next, we use the theorem that the product of the predecessor of \( m \) and \( n \) is equal to the product of \( m \) and \( n \) minus \( n \), i.e., \(\text{pred}(m) \cdot n = m \cdot n - n\). Finally, we use the commutativity of multiplication again to rewrite \( m \cdot n - n \) as \( n \cdot m - n \). Thus, the goal is now \( n \cdot m - n = n \cdot m - n \), which is trivially true by the properties of equality. -/
  rw [Nat.mul_comm, pred_mul, Nat.mul_comm]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31241,Nat.succ_sub,theorem Nat.succ_sub {m n : Nat} (h : n ≤ m) : succ m - n = succ (m - n) := by sorry,"Successor Subtraction Identity: \( (m + 1) - n = (m - n) + 1 \) for \( n \leq m \) : For any natural numbers \( m \) and \( n \) such that \( n \leq m \), the successor of \( m \) minus \( n \) is equal to the successor of \( m - n \), i.e., \( m + 1 - n = (m - n) + 1 \).","theorem Nat.succ_sub {m n : Nat} (h : n ≤ m) : succ m - n = succ (m - n) := by
  let ⟨k, hk⟩ := Nat.le.dest h
  rw [← hk, Nat.add_sub_cancel_left, ← add_succ, Nat.add_sub_cancel_left]","Given \( n \leq m \), there exists a natural number \( k \) such that \( n + k = m \). Let \( k \) be this natural number, and let \( hk \) denote the equation \( n + k = m \).

We need to show that \( m + 1 - n = (m - n) + 1 \). Using the equation \( n + k = m \), we can rewrite the goal as:
\[
(n + k) + 1 - n = (n + k - n) + 1
\]
By the property of left addition and subtraction canceling each other in additive commutative groups, we have:
\[
(n + k) + 1 - n = k + 1
\]
Using the property that the sum of a natural number and the successor of another natural number is the successor of their sum, we get:
\[
n + (k + 1) - n = k + 1
\]
Again, by the property of left addition and subtraction canceling each other, we have:
\[
k + 1 = k + 1
\]
This is trivially true, thus completing the proof. \(\blacksquare\)","theorem Nat.succ_sub {m n : Nat} (h : n ≤ m) : succ m - n = succ (m - n) := by
/- Since \( n \leq m \), there exists a natural number \( k \) such that \( n + k = m \). Let \( k \) be this natural number, and let \( hk \) denote the equation \( n + k = m \). -/
  let ⟨k, hk⟩ := Nat.le.dest h
/- We need to show that \( m + 1 - n = (m - n) + 1 \). Using the equation \( n + k = m \) (denoted by \( hk \)), we can rewrite the goal as:
\[
(n + k) + 1 - n = (n + k - n) + 1
\]
By the property of left addition and subtraction canceling each other in additive commutative groups, we have:
\[
(n + k) + 1 - n = k + 1
\]
Using the property that the sum of a natural number and the successor of another natural number is the successor of their sum, we get:
\[
n + (k + 1) - n = k + 1
\]
Again, by the property of left addition and subtraction canceling each other, we have:
\[
k + 1 = k + 1
\]
This is trivially true, thus completing the proof. -/
  rw [← hk, Nat.add_sub_cancel_left, ← add_succ, Nat.add_sub_cancel_left]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31242,Nat.le_add_of_sub_le,theorem Nat.le_add_of_sub_le {a b c : Nat} (h : a - b ≤ c) : a ≤ c + b := by sorry,"Subtraction Inequality Implies Addition Inequality: \(a - b \leq c \to a \leq c + b\) : For any natural numbers \(a\), \(b\), and \(c\), if \(a - b \leq c\), then \(a \leq c + b\).","theorem Nat.le_add_of_sub_le {a b c : Nat} (h : a - b ≤ c) : a ≤ c + b := by
  match le.dest h, Nat.le_total a b with
  | _, Or.inl hle =>
    exact Nat.le_trans hle (Nat.le_add_left ..)
  | ⟨d, hd⟩, Or.inr hge =>
    apply @le.intro _ _ d
    rw [Nat.add_comm, ← Nat.add_sub_assoc hge] at hd
    have hd := Nat.eq_add_of_sub_eq (Nat.le_trans hge (Nat.le_add_left ..)) hd
    rw [Nat.add_comm, hd]","We need to show that if \(a - b \leq c\), then \(a \leq c + b\). We consider two cases based on the relationship between \(a\) and \(b\).

1. **Case 1: \(a \leq b\)**

In this case, we need to show that \(a \leq c + b\). Since \(a \leq b\) and \(b \leq c + b\) (by the property that adding a non-negative number to another number preserves the inequality), we have \(a \leq c + b\) by the transitivity of the less-than-or-equal-to relation.

2. **Case 2: \(b \leq a\)**

In this case, we need to show that \(a \leq c + b\). We start by using the hypothesis \(a - b \leq c\). This implies that there exists a natural number \(d\) such that \(a - b + d = c\). We can rewrite this as \(d + a - b = c\).

Using the commutativity of addition and the associativity of addition and subtraction, we have:
\[
d + a - b = c \implies d + a = c + b
\]

Therefore, we have \(a + d = c + b\). Since \(a + d = c + b\), it follows that \(a \leq c + b\).

In both cases, we have shown that \(a \leq c + b\). Therefore, the theorem is proved. \(\blacksquare\)","theorem Nat.le_add_of_sub_le {a b c : Nat} (h : a - b ≤ c) : a ≤ c + b := by
  match le.dest h, Nat.le_total a b with
/- We consider the case where \(a \leq b\). In this case, we need to show that \(a \leq c + b\). -/
  | _, Or.inl hle =>
/- Since \(a \leq b\) and \(b \leq c + b\) (by the property that adding a non-negative number to another number preserves the inequality), we have \(a \leq c + b\) by the transitivity of the less-than-or-equal-to relation. -/
    exact Nat.le_trans hle (Nat.le_add_left ..)
/- We consider the case where \(b \leq a\). In this case, we need to show that \(a \leq c + b\). -/
  | ⟨d, hd⟩, Or.inr hge =>
/- To show \(a \leq c + b\), it suffices to show that \(a + d = c + b\). -/
    apply @le.intro _ _ d
/- We use the commutativity of addition and the associativity of addition and subtraction to rewrite the hypothesis \(d + a - b = c\) as \(d + a - b = c\). This simplifies to \(d + a - b = c\). -/
    rw [Nat.add_comm, ← Nat.add_sub_assoc hge] at hd
/- We construct a new hypothesis \(d + a = c + b\) by using the fact that \(b \leq a\) and \(a - b \leq c\). Since \(b \leq a\), we have \(a - b \leq c\), and by the property that adding a non-negative number to another number preserves the inequality, we have \(a - b \leq c\). Therefore, \(d + a = c + b\). -/
    have hd := Nat.eq_add_of_sub_eq (Nat.le_trans hge (Nat.le_add_left ..)) hd
/- First, we use the commutativity of addition to rewrite the goal \(a + d = c + b\) as \(d + a = c + b\). Then, we use the hypothesis \(d + a - b = c\) to rewrite the goal to \(d + a = c + b\). -/
/- We use the commutativity of addition to rewrite the goal \(a + d = c + b\) as \(d + a = c + b\). Since we have already shown that \(d + a = c + b\), the goal is satisfied. -/
    rw [Nat.add_comm, hd]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31243,Nat.add_sub_assoc,theorem Nat.add_sub_assoc {m k : Nat} (h : k ≤ m) (n : Nat) : n + m - k = n + (m - k) := by sorry,"Associativity of Addition and Subtraction in Natural Numbers: \( n + m - k = n + (m - k) \) : For any natural numbers \( m \) and \( k \) such that \( k \leq m \), and for any natural number \( n \), the expression \( n + m - k \) is equal to \( n + (m - k) \), i.e., \( n + m - k = n + (m - k) \).","theorem Nat.add_sub_assoc {m k : Nat} (h : k ≤ m) (n : Nat) : n + m - k = n + (m - k) := by
 cases Nat.le.dest h
 rename_i l hl
 rw [← hl, Nat.add_sub_cancel_left, Nat.add_comm k, ← Nat.add_assoc, Nat.add_sub_cancel]","We start by considering the case where \( k \leq m \). By the definition of the natural number inequality, there exists a natural number \( l \) such that \( k + l = m \).

To prove \( n + m - k = n + (m - k) \), we will simplify the left-hand side step by step:
1. Substitute \( m \) with \( k + l \) in the left-hand side:
\[
n + m - k = n + (k + l) - k
\]
2. By the property of left addition and subtraction cancellation in additive commutative groups, \( k + l - k = l \):
\[
n + (k + l) - k = n + l
\]
3. Using the commutativity of addition, \( k + l = l + k \):
\[
n + (l + k) - k = n + l
\]
4. By the associativity of addition, \( n + (l + k) = (n + l) + k \):
\[
(n + l) + k - k = n + l
\]
5. Finally, using the property of addition and subtraction cancellation, \( (n + l) + k - k = n + l \):
\[
n + l = n + l
\]
This is trivially true. Therefore, we have shown that \( n + m - k = n + (m - k) \).

Hence, the theorem is proved. \(\blacksquare\)","theorem Nat.add_sub_assoc {m k : Nat} (h : k ≤ m) (n : Nat) : n + m - k = n + (m - k) := by
/- We consider the case where \( k \leq m \). By the definition of the natural number inequality, there exists a natural number \( l \) such that \( k + l = m \). -/
 cases Nat.le.dest h
/- We rename the variable \( w \) to \( l \) and the hypothesis \( h \) to \( hl \) to make the proof more readable. Now we have \( k + l = m \). -/
 rename_i l hl
/- We will now simplify the goal \( n + m - k = n + (m - k) \) step by step:
1. Using the hypothesis \( k + l = m \), we substitute \( m \) with \( k + l \) in the goal, which gives us \( n + (k + l) - k = n + (k + l - k) \).
2. By the property of left addition and subtraction cancellation in additive commutative groups, \( k + l - k = l \), so the goal becomes \( n + (k + l) - k = n + l \).
3. Using the commutativity of addition, \( k + l = l + k \), the goal becomes \( n + (l + k) - k = n + l \).
4. By the associativity of addition, \( n + (l + k) = (n + l) + k \), the goal becomes \( (n + l) + k - k = n + l \).
5. Finally, using the property of addition and subtraction cancellation, \( (n + l) + k - k = n + l \), the goal simplifies to \( n + l = n + l \), which is trivially true. -/
 rw [← hl, Nat.add_sub_cancel_left, Nat.add_comm k, ← Nat.add_assoc, Nat.add_sub_cancel]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31244,Nat.zero_lt_sub_of_lt,theorem Nat.zero_lt_sub_of_lt (h : i < a) : 0 < a - i := by sorry,"Zero is Less Than the Difference of Two Natural Numbers if the First is Less Than the Second : For any natural numbers \( i \) and \( a \) such that \( i < a \), it holds that \( 0 < a - i \).","theorem Nat.zero_lt_sub_of_lt (h : i < a) : 0 < a - i := by
  induction a with
  | zero => contradiction
  | succ a ih =>
    match Nat.eq_or_lt_of_le h with
    | Or.inl h => injection h with h; subst h; rw [Nat.add_sub_self_left]; decide
    | Or.inr h =>
      have : 0 < a - i := ih (Nat.lt_of_succ_lt_succ h)
      exact Nat.lt_of_lt_of_le this (Nat.sub_le_succ_sub _ _)","We will prove this by induction on \( a \).

1. **Base Case: \( a = 0 \)**
- Consider the case where \( i = 0 \). We need to show that \( 0 < 0 - i \). However, this is a direct contradiction because \( i < 0 \) is impossible for natural numbers. Therefore, this case is vacuously true.

2. **Inductive Step:**
- Assume the statement holds for some \( a \), i.e., for any \( i < a \), \( 0 < a - i \). We need to show that for \( a + 1 \), if \( i < a + 1 \), then \( 0 < a + 1 - i \).

- **Case 1: \( i = a + 1 \)**
- This case is impossible because \( i < a + 1 \) and \( i = a + 1 \) cannot both be true.

- **Case 2: \( i < a + 1 \) and \( i \neq a + 1 \)**
- By the property of natural numbers, \( i < a + 1 \) implies \( i < a \) (since \( i \neq a + 1 \)).
- By the induction hypothesis, \( 0 < a - i \).
- We also know that \( a - i \leq a + 1 - i \) (by the property of subtraction with successor in natural numbers).
- By the transitivity of less-than and less-than-or-equal, \( 0 < a + 1 - i \).

Therefore, by induction, the statement holds for all natural numbers \( a \) and \( i \) such that \( i < a \). This completes the proof. \(\blacksquare\)","theorem Nat.zero_lt_sub_of_lt (h : i < a) : 0 < a - i := by
  induction a with
/- Consider the case where \(i = 0\). We need to show that \(0 < 0 - i\). However, this is a direct contradiction because \(i < 0\) is impossible for natural numbers. Therefore, this case is vacuously true. -/
  | zero => contradiction
/- Consider the case where \(i = a + 1\). We need to show that \(0 < a + 1 - i\). We will use induction on \(a\). -/
  | succ a ih =>
    match Nat.eq_or_lt_of_le h with
/- Consider the case where \(i = a + 1\) and \(i < a + 1\). By the property of natural numbers, this implies \(i = a\). Substituting \(i = a\) into the goal, we need to show that \(0 < a + 1 - a\). By the property of addition and subtraction, \(a + 1 - a = 1\), and since \(1 > 0\), the goal is satisfied. -/
    | Or.inl h => injection h with h; subst h; rw [Nat.add_sub_self_left]; decide
/- Consider the case where \(i < a + 1\) and \(i \neq a + 1\). We need to show that \(0 < a + 1 - i\). -/
    | Or.inr h =>
/- We construct a lemma that \(0 < a - i\) by using the induction hypothesis `ih` and the fact that \(i < a + 1\) implies \(i < a\) (by the property of successor in natural numbers). -/
      have : 0 < a - i := ih (Nat.lt_of_succ_lt_succ h)
/- We need to show that \(0 < a + 1 - i\). Since we have already established that \(0 < a - i\) (denoted as `this`), and we know that \(a - i \leq a + 1 - i\) (by the property of subtraction with successor in natural numbers), it follows by the transitivity of less-than and less-than-or-equal that \(0 < a + 1 - i\). -/
/- We need to show that \(0 < a + 1 - i\). Since we have already established that \(0 < a - i\) (denoted as `this`), and we know that \(a - i \leq a + 1 - i\) (by the property of subtraction with successor in natural numbers), it follows by the transitivity of less-than and less-than-or-equal that \(0 < a + 1 - i\). -/
      exact Nat.lt_of_lt_of_le this (Nat.sub_le_succ_sub _ _)","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31245,Nat.sub_lt_left_of_lt_add,theorem Nat.sub_lt_left_of_lt_add {n k m : Nat} (H : n ≤ k) (h : k < n + m) : k - n < m := by sorry,"Left Subtraction Preserves Strict Inequality in Natural Numbers : For any natural numbers \( n \), \( k \), and \( m \), if \( n \leq k \) and \( k < n + m \), then \( k - n < m \).","theorem Nat.sub_lt_left_of_lt_add {n k m : Nat} (H : n ≤ k) (h : k < n + m) : k - n < m := by
  have := Nat.sub_le_sub_right (succ_le_of_lt h) n
  rwa [Nat.add_sub_cancel_left, Nat.succ_sub H] at this","We start by noting the given conditions: \( n \leq k \) and \( k < n + m \). We need to show that \( k - n < m \).

1. **Construct a Lemma:**
First, we construct a lemma that states \( k + 1 - n \leq (n + m) - n \). This follows from the fact that if \( k < n + m \), then \( k + 1 \leq n + m \) (by the property that the successor of a number less than another number is less than or equal to that number), and by the property that subtraction preserves the less-than-or-equal-to relation in additive groups.

2. **Simplify the Lemma:**
Next, we simplify the lemma \( k + 1 - n \leq (n + m) - n \) using the properties of addition and subtraction. Specifically, we use the fact that \( a + b - a = b \) (left addition and subtraction cancel each other) to simplify \( (n + m) - n \) to \( m \). Additionally, we use the property that \( (k + 1) - n = (k - n) + 1 \) (successor subtraction identity) to rewrite \( k + 1 - n \) as \( (k - n) + 1 \). This simplifies our lemma to \( (k - n) + 1 \leq m \).

3. **Conclude the Proof:**
Since \( (k - n) + 1 \leq m \) is equivalent to \( k - n < m \), we have shown the desired inequality. Therefore, \( k - n < m \).

This completes the proof.","theorem Nat.sub_lt_left_of_lt_add {n k m : Nat} (H : n ≤ k) (h : k < n + m) : k - n < m := by
/- First, we construct a lemma that states \( k + 1 - n \leq (n + m) - n \). This follows from the fact that if \( k < n + m \), then \( k + 1 \leq n + m \) (by the property that the successor of a number less than another number is less than or equal to that number), and by the property that subtraction preserves the less-than-or-equal-to relation in additive groups. -/
  have := Nat.sub_le_sub_right (succ_le_of_lt h) n
/- Next, we simplify the lemma \( k + 1 - n \leq (n + m) - n \) using the properties of addition and subtraction. Specifically, we use the fact that \( a + b - a = b \) (left addition and subtraction cancel each other) to simplify \( (n + m) - n \) to \( m \). Additionally, we use the property that \( (k + 1) - n = (k - n) + 1 \) (successor subtraction identity) to rewrite \( k + 1 - n \) as \( (k - n) + 1 \). This simplifies our lemma to \( (k - n) + 1 \leq m \). Since \( (k - n) + 1 \leq m \) is equivalent to \( k - n < m \), we have shown the desired inequality. -/
  rwa [Nat.add_sub_cancel_left, Nat.succ_sub H] at this","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31247,Nat.mul_sub_left_distrib,theorem Nat.mul_sub_left_distrib (n m k : Nat) : n * (m - k) = n * m - n * k := by sorry,"Distributive Property of Multiplication over Subtraction in Natural Numbers : For any natural numbers \( n \), \( m \), and \( k \), the product of \( n \) with the difference \( m - k \) is equal to the difference between the product of \( n \) and \( m \) and the product of \( n \) and \( k \). In other words, \( n \times (m - k) = n \times m - n \times k \).","theorem Nat.mul_sub_left_distrib (n m k : Nat) : n * (m - k) = n * m - n * k := by
  rw [Nat.mul_comm, Nat.mul_sub_right_distrib, Nat.mul_comm m n, Nat.mul_comm n k]","To prove the distributive property of multiplication over subtraction in natural numbers, we start with the goal \( n \times (m - k) = n \times m - n \times k \).

1. **Step 1: Use Commutativity of Multiplication**
- By the commutativity of multiplication, we can rewrite \( n \times (m - k) \) as \( (m - k) \times n \). Thus, our goal becomes:
\[
(m - k) \times n = n \times m - n \times k
\]

2. **Step 2: Apply Right Distributive Property**
- Using the right distributive property of multiplication over subtraction, we have:
\[
(m - k) \times n = m \times n - k \times n
\]
- Therefore, our goal now is:
\[
m \times n - k \times n = n \times m - n \times k
\]

3. **Step 3: Use Commutativity of Multiplication Again**
- By the commutativity of multiplication, we can rewrite \( m \times n \) as \( n \times m \) and \( k \times n \) as \( n \times k \). Thus, our goal becomes:
\[
n \times m - n \times k = n \times m - n \times k
\]

4. **Step 4: Trivial Equality**
- The equation \( n \times m - n \times k = n \times m - n \times k \) is trivially true by the properties of equality.

Thus, we have shown that \( n \times (m - k) = n \times m - n \times k \), completing the proof.","theorem Nat.mul_sub_left_distrib (n m k : Nat) : n * (m - k) = n * m - n * k := by
/- First, we use the commutativity of multiplication to rewrite the goal. Specifically, we use the fact that \( n \times (m - k) = (m - k) \times n \). Then, we apply the right distributive property of multiplication over subtraction, which gives us \( (m - k) \times n = m \times n - k \times n \). Next, we use the commutativity of multiplication again to rewrite \( m \times n \) as \( n \times m \) and \( k \times n \) as \( n \times k \). This transforms our goal into \( n \times m - n \times k = n \times m - n \times k \), which is trivially true by the properties of equality. -/
  rw [Nat.mul_comm, Nat.mul_sub_right_distrib, Nat.mul_comm m n, Nat.mul_comm n k]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31248,Nat.sub.elim,"theorem Nat.sub.elim {motive : Nat → Prop}
    (x y : Nat)
    (h₁ : y ≤ x → (k : Nat) → x = y + k → motive k)
    (h₂ : x < y → motive 0)
    : motive (x - y) := by sorry","Subtraction Elimination for Natural Numbers: \( y \leq x \) and \( x = y + k \) Imply \( P(k) \) and \( x < y \) Imply \( P(0) \) : For any natural numbers \( x \) and \( y \), and any proposition \( P \) on natural numbers, if \( y \leq x \) and for any natural number \( k \) such that \( x = y + k \), \( P(k) \) holds, and if \( x < y \), \( P(0) \) holds, then \( P(x - y) \) holds.","theorem Nat.sub.elim {motive : Nat → Prop}
    (x y : Nat)
    (h₁ : y ≤ x → (k : Nat) → x = y + k → motive k)
    (h₂ : x < y → motive 0)
    : motive (x - y) := by
  cases Nat.lt_or_ge x y with
  | inl hlt => rw [Nat.sub_eq_zero_of_le (Nat.le_of_lt hlt)]; exact h₂ hlt
  | inr hle => exact h₁ hle (x - y) (Nat.add_sub_of_le hle).symm","We need to show that \( P(x - y) \) holds under the given conditions. We consider two cases based on the relationship between \( x \) and \( y \):

1. **Case 1: \( y \leq x \)**
- By the hypothesis \( h_1 \), if \( y \leq x \), then there exists a natural number \( k \) such that \( x = y + k \).
- Using the property of natural numbers, we have \( x = y + (x - y) \).
- Therefore, \( x - y = k \).
- By the hypothesis \( h_1 \), \( P(k) \) holds, which means \( P(x - y) \) holds.

2. **Case 2: \( x < y \)**
- By the property of natural numbers, if \( x < y \), then \( x \leq y \).
- Using the property that \( n \leq m \) implies \( n - m = 0 \), we get \( x - y = 0 \).
- By the hypothesis \( h_2 \), \( P(0) \) holds, which means \( P(x - y) \) holds.

In both cases, we have shown that \( P(x - y) \) holds. Therefore, the theorem is proved. \(\blacksquare\)","theorem Nat.sub.elim {motive : Nat → Prop}
    (x y : Nat)
    (h₁ : y ≤ x → (k : Nat) → x = y + k → motive k)
    (h₂ : x < y → motive 0)
    : motive (x - y) := by
  cases Nat.lt_or_ge x y with
/- If \( x < y \), then by the property that \( a < b \) implies \( a \leq b \), we have \( x \leq y \). Using the property that \( n \leq m \) implies \( n - m = 0 \), we get \( x - y = 0 \). Therefore, by the hypothesis \( h_2 \), \( P(0) \) holds, which means \( P(x - y) \) holds. -/
  | inl hlt => rw [Nat.sub_eq_zero_of_le (Nat.le_of_lt hlt)]; exact h₂ hlt
/- If \( y \leq x \), then by the hypothesis \( h_1 \), we have \( x = y + k \) for some natural number \( k \). Using the property that \( a + (b - a) = b \) for \( a \leq b \), we can rewrite \( x = y + (x - y) \). Therefore, \( x - y = k \), and by \( h_1 \), \( P(k) \) holds, which means \( P(x - y) \) holds. -/
  | inr hle => exact h₁ hle (x - y) (Nat.add_sub_of_le hle).symm","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat
open sub

"
31249,Nat.add_le_of_le_sub,theorem Nat.add_le_of_le_sub {a b c : Nat} (hle : b ≤ c) (h : a ≤ c - b) : a + b ≤ c := by sorry,"Addition and Subtraction Inequality: \(b \leq c \to a \leq c - b \to a + b \leq c\) : For any natural numbers \(a\), \(b\), and \(c\), if \(b \leq c\) and \(a \leq c - b\), then \(a + b \leq c\).","theorem Nat.add_le_of_le_sub {a b c : Nat} (hle : b ≤ c) (h : a ≤ c - b) : a + b ≤ c := by
  match le.dest h with
  | ⟨d, hd⟩ =>
    apply @le.intro _ _ d
    rw [Nat.eq_add_of_sub_eq hle hd.symm]
    simp [Nat.add_comm, Nat.add_assoc, Nat.add_left_comm]","We start with the given conditions \(b \leq c\) and \(a \leq c - b\). To prove \(a + b \leq c\), we will show that \(a + b + d = c\) for some \(d\) such that \(a + d = c - b\).

1. **Simplify the expression:**
Using the commutativity and associativity properties of addition in natural numbers, we simplify the expression \(a + b + d\) to \(a + d + b\).

2. **Introduce a new variable:**
We introduce a new variable \(d\) and the hypothesis \(a + d = c - b\). This allows us to reason about the expression involving \(d\).

3. **Apply the introduction rule:**
To prove \(a + b \leq c\), it suffices to show that \(a + b + d = c\), using the introduction rule for the less-than-or-equal relation in natural numbers.

4. **Rewrite the goal:**
Since \(b \leq c\) and \(a + d = c - b\), we can use the property that if \(a - c = b\), then \(a = b + c\). By symmetry, \(c - b = a + d\) implies \(c = a + d + b\). Therefore, the goal \(a + b + d = c\) is equivalent to \(a + b + d = a + d + b\).

5. **Simplify the final expression:**
Using the commutativity and associativity properties of addition in natural numbers, we simplify the expression \(a + b + d\) to \(a + d + b\), which is trivially true.

Thus, we have shown that \(a + b \leq c\). This completes the proof. \(\blacksquare\)","theorem Nat.add_le_of_le_sub {a b c : Nat} (hle : b ≤ c) (h : a ≤ c - b) : a + b ≤ c := by
  match le.dest h with
/- We introduce a new variable \(d\) and the hypothesis \(hd : a + d = c - b\). This allows us to reason about the expression involving \(d\). -/
  | ⟨d, hd⟩ =>
/- To prove \(a + b \leq c\), it suffices to show that \(a + b + d = c\), using the introduction rule for the less-than-or-equal relation in natural numbers. -/
    apply @le.intro _ _ d
/- Since \(b \leq c\) and \(a + d = c - b\), we can use the property that if \(a - c = b\), then \(a = b + c\). By symmetry, \(c - b = a + d\) implies \(c = a + d + b\). Therefore, the goal \(a + b + d = c\) is equivalent to \(a + b + d = a + d + b\). -/
    rw [Nat.eq_add_of_sub_eq hle hd.symm]
/- Using the commutativity and associativity properties of addition in natural numbers, we simplify the expression \(a + b + d\) to \(a + d + b\). -/
/- Using the commutativity and associativity properties of addition in natural numbers, we simplify the expression \(a + b + d\) to \(a + d + b\), which is trivially true. -/
    simp [Nat.add_comm, Nat.add_assoc, Nat.add_left_comm]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31253,Nat.mul_sub_right_distrib,theorem Nat.mul_sub_right_distrib (n m k : Nat) : (n - m) * k = n * k - m * k := by sorry,"Distributive Property of Multiplication over Subtraction in Natural Numbers: \((n - m) \times k = n \times k - m \times k\) : For any natural numbers \( n \), \( m \), and \( k \), the product of the difference \( n - m \) with \( k \) is equal to the difference between the product of \( n \) and \( k \) and the product of \( m \) and \( k \). In other words, \( (n - m) \times k = n \times k - m \times k \).","theorem Nat.mul_sub_right_distrib (n m k : Nat) : (n - m) * k = n * k - m * k := by
  induction m with
  | zero => simp
  | succ m ih => rw [Nat.sub_succ, Nat.pred_mul, ih, succ_mul, Nat.sub_sub]; done","We prove this by induction on \( m \).

**Base Case:**
Consider \( m = 0 \). We need to show that \((n - 0) \times k = n \times k - 0 \times k\). Simplifying the left-hand side, we get \( n \times k \), and the right-hand side simplifies to \( n \times k - 0 \). Since \( 0 \times k = 0 \), the equation holds trivially.

**Inductive Step:**
Assume the inductive hypothesis that for some \( m' \), \((n - m') \times k = n \times k - m' \times k\). We need to show that \((n - (m' + 1)) \times k = n \times k - (m' + 1) \times k\).

1. Using the property of subtraction, we have \( n - (m' + 1) = (n - m').\text{pred} \).
2. Using the property of multiplication of the predecessor, we have \((n - m').\text{pred} \times k = (n - m') \times k - k\).
3. By the inductive hypothesis, \((n - m') \times k = n \times k - m' \times k\).
4. Using the property of successor multiplication, we have \((m' + 1) \times k = m' \times k + k\).
5. Using the property of subtraction, we have \( n \times k - m' \times k - k = n \times k - (m' \times k + k) \).

Thus, the equation \((n - (m' + 1)) \times k = n \times k - (m' + 1) \times k\) holds, completing the inductive step.

By induction, the theorem holds for all natural numbers \( n \), \( m \), and \( k \). Therefore, \((n - m) \times k = n \times k - m \times k\). This completes the proof. \(\blacksquare\)","theorem Nat.mul_sub_right_distrib (n m k : Nat) : (n - m) * k = n * k - m * k := by
  induction m with
/- First, consider the base case where \( m = 0 \). We need to show that \((n - 0) \times k = n \times k - 0 \times k\). Simplifying the left-hand side, we get \( n \times k \), and the right-hand side simplifies to \( n \times k - 0 \). Since \( 0 \times k = 0 \), the equation holds trivially. -/
  | zero => simp
/- Next, consider the inductive step where \( m = m' + 1 \) for some \( m' \). We assume the inductive hypothesis that \((n - m') \times k = n \times k - m' \times k\). We need to show that \((n - (m' + 1)) \times k = n \times k - (m' + 1) \times k\).

1. Using the property of subtraction, we have \( n - (m' + 1) = (n - m').\text{pred} \).
2. Using the property of multiplication of the predecessor, we have \((n - m').\text{pred} \times k = (n - m') \times k - k\).
3. By the inductive hypothesis, \((n - m') \times k = n \times k - m' \times k\).
4. Using the property of successor multiplication, we have \((m' + 1) \times k = m' \times k + k\).
5. Using the property of subtraction, we have \( n \times k - m' \times k - k = n \times k - (m' \times k + k) \).

Thus, the equation \((n - (m' + 1)) \times k = n \times k - (m' + 1) \times k\) holds, completing the inductive step. -/
  | succ m ih => rw [Nat.sub_succ, Nat.pred_mul, ih, succ_mul, Nat.sub_sub]; done","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31255,Nat.add_lt_of_lt_sub,theorem Nat.add_lt_of_lt_sub {a b c : Nat} (h : a < c - b) : a + b < c := by sorry,"Addition and Subtraction Inequality: \(a < c - b \to a + b < c\) : For any natural numbers \(a\), \(b\), and \(c\), if \(a < c - b\), then \(a + b < c\).","theorem Nat.add_lt_of_lt_sub {a b c : Nat} (h : a < c - b) : a + b < c := by
  have hle : b ≤ c := by
    apply Nat.ge_of_not_lt
    intro hgt
    apply Nat.not_lt_zero a
    rw [Nat.sub_eq_zero_of_le (Nat.le_of_lt hgt)] at h
    exact h
  have : a.succ + b ≤ c := add_le_of_le_sub hle h
  simp [Nat.succ_add] at this
  exact this","We start by showing that \( b \leq c \). To do this, we use the theorem that if \( c \) is not less than \( b \), then \( b \leq c \). Therefore, it suffices to show that \( c \) is not less than \( b \).

Let \( hgt \) be an arbitrary hypothesis that \( c < b \). We need to show that this leads to a contradiction. To derive a contradiction, we use the theorem that no natural number is less than zero. Therefore, it suffices to show that \( a < 0 \).

Since \( c < b \) implies \( c \leq b \), we can use the theorem that \( c - b = 0 \). Substituting this into the hypothesis \( a < c - b \), we get \( a < 0 \). This is a contradiction because no natural number is less than zero. Therefore, \( c \) is not less than \( b \), and thus \( b \leq c \).

Next, we construct a new lemma that \( a + 1 + b \leq c \). This follows from the theorem that if \( b \leq c \) and \( a \leq c - b \), then \( a + b \leq c \). We use the hypothesis \( b \leq c \) and the fact that \( a < c - b \) implies \( a \leq c - b \).

Using the theorem that \( a + 1 + b = (a + b) + 1 \), we simplify the lemma to \( a + b + 1 \leq c \). This implies \( a + b < c \).

Therefore, we have shown that if \( a < c - b \), then \( a + b < c \). This completes the proof. \(\blacksquare\)","theorem Nat.add_lt_of_lt_sub {a b c : Nat} (h : a < c - b) : a + b < c := by
/- First, we need to show that \( b \leq c \). We will construct this inequality using the given hypothesis \( a < c - b \). -/
  have hle : b ≤ c := by
/- To prove \( b \leq c \), we use the theorem that if \( c \) is not less than \( b \), then \( b \leq c \). Therefore, it suffices to show that \( c \) is not less than \( b \). -/
    apply Nat.ge_of_not_lt
/- Let \( hgt \) be an arbitrary hypothesis that \( c < b \). We need to show that this leads to a contradiction. -/
    intro hgt
/- To derive a contradiction, we use the theorem that no natural number is less than zero. Therefore, it suffices to show that \( a < 0 \). -/
    apply Nat.not_lt_zero a
/- Since \( c < b \) implies \( c \leq b \), we can use the theorem that \( c - b = 0 \). Substituting this into the hypothesis \( a < c - b \), we get \( a < 0 \). -/
    rw [Nat.sub_eq_zero_of_le (Nat.le_of_lt hgt)] at h
/- The current goal \( a < 0 \) is exactly proved by the hypothesis \( h \). -/
    exact h
/- Now we construct a new lemma that \( a + 1 + b \leq c \). This follows from the theorem that if \( b \leq c \) and \( a \leq c - b \), then \( a + b \leq c \). We use the hypothesis \( b \leq c \) and the fact that \( a < c - b \) implies \( a \leq c - b \). -/
  have : a.succ + b ≤ c := add_le_of_le_sub hle h
/- Using the theorem that \( a + 1 + b = (a + b) + 1 \), we simplify the lemma to \( a + b + 1 \leq c \). -/
  simp [Nat.succ_add] at this
/- The current goal \( a + b < c \) is exactly proved by the lemma \( a + b + 1 \leq c \), which implies \( a + b < c \). -/
  exact this","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31256,Nat.pred_mul,theorem Nat.pred_mul (n m : Nat) : pred n * m = n * m - m := by sorry,"Multiplication of Predecessor with Natural Number: \((n - 1) \cdot m = n \cdot m - m\) : For any natural numbers \( n \) and \( m \), the product of the predecessor of \( n \) and \( m \) is equal to the product of \( n \) and \( m \) minus \( m \). In other words, \((n - 1) \cdot m = n \cdot m - m\).","theorem Nat.pred_mul (n m : Nat) : pred n * m = n * m - m := by
  cases n with
  | zero   => simp
  | succ n => rw [Nat.pred_succ, succ_mul, Nat.add_sub_cancel]","We will prove this by induction on \( n \).

**Base Case:**
Consider \( n = 0 \). We need to show that \(\text{pred}(0) \cdot m = 0 \cdot m - m\). Since \(\text{pred}(0) = 0\), the left-hand side is \(0 \cdot m\). The right-hand side is \(0 \cdot m - m\). Using the properties of natural numbers, we can simplify \(0 \cdot m - m\) to \(-m\), which is \(0 - m = -m\). Since \(0 \cdot m = 0\), the equation simplifies to \(0 = 0 - m\), which is trivially true. Therefore, the base case holds.

**Inductive Step:**
Assume the statement holds for some natural number \( k \), i.e., \(\text{pred}(k) \cdot m = k \cdot m - m\). We need to show that \(\text{pred}(k + 1) \cdot m = (k + 1) \cdot m - m\). By the definition of the predecessor, \(\text{pred}(k + 1) = k\). Therefore, the left-hand side is \(k \cdot m\). The right-hand side is \((k + 1) \cdot m - m\). Using the identity for the successor of a natural number, \((k + 1) \cdot m = k \cdot m + m\). Substituting this into the right-hand side, we get \(k \cdot m + m - m\). By the property of addition and subtraction in natural numbers, \(k \cdot m + m - m = k \cdot m\). Thus, the left-hand side and the right-hand side are equal, and the inductive step holds.

By the principle of mathematical induction, the statement \((n - 1) \cdot m = n \cdot m - m\) holds for all natural numbers \( n \) and \( m \). This completes the proof. \(\blacksquare\)","theorem Nat.pred_mul (n m : Nat) : pred n * m = n * m - m := by
  cases n with
/- First, consider the case when \( n = 0 \). We need to show that \(\text{pred}(0) \cdot m = 0 \cdot m - m\). Since \(\text{pred}(0) = 0\), the left-hand side is \(0 \cdot m\). The right-hand side is \(0 \cdot m - m\). Using the properties of natural numbers, we can simplify \(0 \cdot m - m\) to \(-m\), which is \(0 - m = -m\). Since \(0 \cdot m = 0\), the equation simplifies to \(0 = 0 - m\), which is trivially true. Therefore, the base case holds. -/
  | zero   => simp
/- Next, consider the case when \( n = k + 1 \) for some natural number \( k \). We need to show that \(\text{pred}(k + 1) \cdot m = (k + 1) \cdot m - m\). By the definition of the predecessor, \(\text{pred}(k + 1) = k\). Therefore, the left-hand side is \(k \cdot m\). The right-hand side is \((k + 1) \cdot m - m\). Using the identity for the successor of a natural number, \((k + 1) \cdot m = k \cdot m + m\). Substituting this into the right-hand side, we get \(k \cdot m + m - m\). By the property of addition and subtraction in natural numbers, \(k \cdot m + m - m = k \cdot m\). Thus, the left-hand side and the right-hand side are equal, and the inductive step holds. -/
  | succ n => rw [Nat.pred_succ, succ_mul, Nat.add_sub_cancel]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31257,Nat.sub_le_of_le_add,theorem Nat.sub_le_of_le_add {a b c : Nat} (h : a ≤ c + b) : a - b ≤ c := by sorry,"Subtraction and Addition Inequality: \(a \leq c + b \to a - b \leq c\) : For any natural numbers \(a\), \(b\), and \(c\), if \(a \leq c + b\), then \(a - b \leq c\).","theorem Nat.sub_le_of_le_add {a b c : Nat} (h : a ≤ c + b) : a - b ≤ c := by
  match le.dest h, Nat.le_total a b with
  | _, Or.inl hle =>
    rw [Nat.sub_eq_zero_of_le hle]
    apply Nat.zero_le
  | ⟨d, hd⟩, Or.inr hge =>
    apply @le.intro _ _ d
    have hd := Nat.sub_eq_of_eq_add hd
    rw [Nat.add_comm, ← Nat.add_sub_assoc hge, Nat.add_comm]
    exact hd","We need to show that for any natural numbers \(a\), \(b\), and \(c\), if \(a \leq c + b\), then \(a - b \leq c\).

1. **Case 1: \(a \leq b\)**

- Since \(a \leq b\), by the property of natural numbers, \(a - b = 0\).
- Therefore, our goal \(a - b \leq c\) is equivalent to \(0 \leq c\).
- We use the fact that \(0\) is less than or equal to any natural number \(c\). This completes the proof for the case \(a \leq b\).

2. **Case 2: \(b \leq a\)**

- There exists a natural number \(d\) such that \(a + d = c + b\).
- To prove \(a - b \leq c\), it suffices to show that \(a - b + d = c\).
- We construct a new hypothesis \(a + d - b = c\) from the given hypothesis \(a + d = c + b\) using the property that if \(a = c + b\), then \(a - b = c\).
- We simplify the goal \(a - b + d = c\) using the commutativity of addition and the associativity of addition and subtraction. Specifically, we use the commutativity of addition to rewrite \(a - b + d\) as \(d + (a - b)\), then use the associativity of addition and subtraction to rewrite \(d + (a - b)\) as \(d + a - b\), and finally use the commutativity of addition again to rewrite \(d + a - b\) as \(a + d - b\). Thus, our goal is equivalent to \(a + d - b = c\).
- The current goal \(a + d - b = c\) is exactly proved by the hypothesis \(a + d - b = c\).

This completes the proof. \(\blacksquare\)","theorem Nat.sub_le_of_le_add {a b c : Nat} (h : a ≤ c + b) : a - b ≤ c := by
  match le.dest h, Nat.le_total a b with
/- We consider the case where \(a \leq b\). In this case, we need to show that \(a - b \leq c\). -/
  | _, Or.inl hle =>
/- Since \(a \leq b\), by the property of natural numbers, \(a - b = 0\). Therefore, our goal \(a - b \leq c\) is equivalent to \(0 \leq c\). -/
    rw [Nat.sub_eq_zero_of_le hle]
/- To prove \(0 \leq c\), we use the fact that \(0\) is less than or equal to any natural number \(c\). This completes the proof for the case \(a \leq b\). -/
    apply Nat.zero_le
/- We consider the case where there exists a natural number \(d\) such that \(a + d = c + b\) and \(b \leq a\). In this case, we need to show that \(a - b \leq c\). -/
  | ⟨d, hd⟩, Or.inr hge =>
/- To prove \(a - b \leq c\), it suffices to show that \(a - b + d = c\). -/
    apply @le.intro _ _ d
/- We construct a new hypothesis \(hd : a + d - b = c\) from the given hypothesis \(hd : a + d = c + b\) using the property that if \(a = c + b\), then \(a - b = c\). -/
    have hd := Nat.sub_eq_of_eq_add hd
/- We simplify the goal \(a - b + d = c\) using the commutativity of addition and the associativity of addition and subtraction. Specifically, we use the commutativity of addition to rewrite \(a - b + d\) as \(d + (a - b)\), then use the associativity of addition and subtraction to rewrite \(d + (a - b)\) as \(d + a - b\), and finally use the commutativity of addition again to rewrite \(d + a - b\) as \(a + d - b\). Thus, our goal is equivalent to \(a + d - b = c\). -/
    rw [Nat.add_comm, ← Nat.add_sub_assoc hge, Nat.add_comm]
/- The current goal \(a + d - b = c\) is exactly proved by the hypothesis \(hd : a + d - b = c\). -/
/- The current goal \(a + d - b = c\) is exactly proved by the hypothesis \(hd : a + d - b = c\). -/
    exact hd","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
31260,Nat.add_sub_of_le,theorem Nat.add_sub_of_le {a b : Nat} (h : a ≤ b) : a + (b - a) = b := by sorry,"Addition and Subtraction Identity in Natural Numbers: \(a + (b - a) = b\) : For any natural numbers \(a\) and \(b\) such that \(a \leq b\), the sum of \(a\) and the difference \(b - a\) is equal to \(b\), i.e., \(a + (b - a) = b\).","theorem Nat.add_sub_of_le {a b : Nat} (h : a ≤ b) : a + (b - a) = b := by
  induction a with
  | zero => simp
  | succ a ih =>
    have hne : b - a ≠ 0 := Nat.sub_ne_zero_of_lt h
    have : a ≤ b := Nat.le_of_succ_le h
    rw [sub_succ, Nat.succ_add, ← Nat.add_succ, Nat.succ_pred hne, ih this]","We start by noting that the assumption that the cardinality of $n$ is zero is equivalent to, and thus can be converted to $n$ being empty. We need to prove that the determinant of $M$ is $1$. First, we try to show that $M = 1$ (the identity matrix). To show this, we prove that for every $i \in n$, $M i = 1 i$. However, since $n$ is empty, $M i = 1 i$ holds for every $i \in n$ vacuously. Hence, $M = 1$. Therefore, the determinant of $M$ is $\det M = \det 1 = 1$. This completes the proof.

---

### Line by Line Informal Proof

#### Informal Step 1

**Formal proof line:**
rw [sub_succ, Nat.succ_add, ← Nat.add_succ, Nat.succ_pred hne, ih this]

**Informal translation:**
We use the following identities to rewrite the goal:
1. \( b - (a + 1) = (b - a).pred \) (since \( b - (a + 1) \) is the predecessor of \( b - a \)).
2. \( a + 1 + (b - a).pred = (a + (b - a).pred).succ \) (since adding 1 to a number and then adding another number is the same as adding the number and then adding 1).
3. \( (a + (b - a).pred).succ = a + (b - a).pred.succ \) (since adding a number and then adding 1 is the same as adding 1 to the sum).
4. \( (b - a).pred.succ = b - a \) (since the successor of the predecessor of a nonzero number is the number itself).
5. \( a + (b - a) = b \) (by the induction hypothesis, since \( a \leq b \)).

Thus, the goal \( a + 1 + (b - (a + 1)) = b \) is equivalent to \( b = b \), which is trivially true.

#### Informal Step 2

**Formal proof line:**
| zero => simp

**Informal translation:**
For the base case where \( a = 0 \), we simplify the goal \( 0 + (b - 0) = b \) to \( b = b \), which is trivially true.

#### Informal Step 3

**Formal proof line:**
| succ a ih =>

**Informal translation:**
For the inductive step, assume \( a = k + 1 \) and the induction hypothesis \( k \leq b \to k + (b - k) = b \). We need to show \( k + 1 + (b - (k + 1)) = b \).

#### Informal Step 4

**Formal proof line:**
have hne : b - a ≠ 0 := Nat.sub_ne_zero_of_lt h

**Informal translation:**
We construct a lemma \( hne \) stating that \( b - a \neq 0 \) because \( a < b \) implies \( b - a \neq 0 \).

#### Informal Step 5

**Formal proof line:**
have : a ≤ b := Nat.le_of_succ_le h

**Informal translation:**
We construct a lemma stating that \( a \leq b \) because \( a + 1 \leq b \) implies \( a \leq b \).

#### Informal Step 6

**Formal proof line:**
rw [sub_succ, Nat.succ_add, ← Nat.add_succ, Nat.succ_pred hne, ih this]

**Informal translation:**
We use the following identities to rewrite the goal:
1. \( b - (a + 1) = (b - a).pred \) (since \( b - (a + 1) \) is the predecessor of \( b - a \)).
2. \( a + 1 + (b - a).pred = (a + (b - a).pred).succ \) (since adding 1 to a number and then adding another number is the same as adding the number and then adding 1).
3. \( (a + (b - a).pred).succ = a + (b - a).pred.succ \) (since adding a number and then adding 1 is the same as adding 1 to the sum).
4. \( (b - a).pred.succ = b - a \) (since the successor of the predecessor of a nonzero number is the number itself).
5. \( a + (b - a) = b \) (by the induction hypothesis, since \( a \leq b \)).

Thus, the goal \( a + 1 + (b - (a + 1)) = b \) is equivalent to \( b = b \), which is trivially true.

### Whole Informal Proof

**Theorem:**
For any natural numbers \(a\) and \(b\) such that \(a \leq b\), the sum of \(a\) and the difference \(b - a\) is equal to \(b\), i.e., \(a + (b - a) = b\).

**Proof:**
We prove this by induction on \(a\).

**Base Case:**
For \(a = 0\), we need to show \(0 + (b - 0) = b\). Simplifying, we get \(b = b\), which is trivially true.

**Inductive Step:**
Assume the statement holds for \(a = k\), i.e., \(k + (b - k) = b\). We need to show that \(k + 1 + (b - (k + 1)) = b\).

1. First, we note that \(b - (k + 1) = (b - k).pred\) because \(b - (k + 1)\) is the predecessor of \(b - k\).
2. Then, \(k + 1 + (b - (k + 1)) = k + 1 + (b - k).pred\).
3. By the properties of addition and the successor function, \(k + 1 + (b - k).pred = (k + (b - k).pred).succ\).
4. Using the property of the successor and predecessor, \((k + (b - k).pred).succ = k + (b - k)\).
5. By the induction hypothesis, \(k + (b - k) = b\).

Thus, \(k + 1 + (b - (k + 1)) = b\), completing the inductive step.

By induction, the statement \(a + (b - a) = b\) holds for all natural numbers \(a\) and \(b\) such that \(a \leq b\). This completes the proof.","theorem Nat.add_sub_of_le {a b : Nat} (h : a ≤ b) : a + (b - a) = b := by
/- First, we use the equivalence that the cardinality of a finite type is $0$ if and only if this type is empty, to convert the assumption of cardinality of $n = 0$ into $n$ is empty. -/
/- It suffices to show that $M = 1$, because if this is true, by using this $M = 1$ and simplifying, we get the determinant of $M$ is $1$ automatically. -/
/- Using extensionality, to prove that $M = 1$, we only need to show that $M i = 1 i$ for every $i \in n$. -/
/- Since $n$ is empty, this $M i = 1 i$ holds for every $i \in n$ vacuously. This finishes the proof. -/
  induction a with
  | zero => simp
  | succ a ih =>
    have hne : b - a ≠ 0 := Nat.sub_ne_zero_of_lt h
    have : a ≤ b := Nat.le_of_succ_le h
    rw [sub_succ, Nat.succ_add, ← Nat.add_succ, Nat.succ_pred hne, ih this]","import Init.SimpLemmas
import Init.Data.Nat.Basic

open Nat

"
32392,Nat.pos_of_lt_add_left,theorem Nat.pos_of_lt_add_left : n < k + n → 0 < k := by sorry,"Positive \( k \) from \( n < k + n \) in Natural Numbers : For any natural numbers \( n \) and \( k \), if \( n < k + n \), then \( 0 < k \).","theorem Nat.pos_of_lt_add_left : n < k + n → 0 < k := by
  rw [Nat.add_comm]; exact Nat.pos_of_lt_add_right","To prove the theorem, we start with the given inequality \( n < k + n \). By the commutativity of addition, we can rewrite this inequality as \( n < n + k \). We then use the known result that if \( n < n + k \), then \( 0 < k \). Therefore, we conclude that \( 0 < k \). This completes the proof.","theorem Nat.pos_of_lt_add_left : n < k + n → 0 < k := by
/- First, we use the commutativity of addition to rewrite the inequality \( n < k + n \) as \( n < n + k \). Then, we apply the theorem that states if \( n < n + k \), then \( 0 < k \). This completes the proof. -/
  rw [Nat.add_comm]; exact Nat.pos_of_lt_add_right","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32394,Nat.lt_of_add_lt_add_left,theorem Nat.lt_of_add_lt_add_left {n : Nat} : n + k < n + m → k < m := by sorry,"Left Addition Preserves Strict Inequality in Natural Numbers : For any natural numbers \( k \), \( m \), and \( n \), if \( n + k < n + m \), then \( k < m \).","theorem Nat.lt_of_add_lt_add_left {n : Nat} : n + k < n + m → k < m := by
  rw [Nat.add_comm n, Nat.add_comm n]; exact Nat.lt_of_add_lt_add_right","We start with the assumption that \( n + k < n + m \). Using the commutativity of addition, we can rewrite this as \( k + n < m + n \). By the property that if \( k + n < m + n \), then \( k < m \), we conclude that \( k < m \). This completes the proof.","theorem Nat.lt_of_add_lt_add_left {n : Nat} : n + k < n + m → k < m := by
/- We start with the assumption that \( n + k < n + m \). Using the commutativity of addition, we can rewrite \( n + k \) as \( k + n \) and \( n + m \) as \( m + n \). Therefore, the assumption \( n + k < n + m \) is equivalent to \( k + n < m + n \). By the property that if \( k + n < m + n \), then \( k < m \), we conclude that \( k < m \). -/
  rw [Nat.add_comm n, Nat.add_comm n]; exact Nat.lt_of_add_lt_add_right","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32395,Nat.lt_add_of_pos_left,theorem Nat.lt_add_of_pos_left : 0 < k → n < k + n := by sorry,"Positive Left Addition Preserves Strict Inequality in Natural Numbers : For any natural numbers \( k \) and \( n \), if \( k \) is strictly greater than 0, then \( n \) is strictly less than \( k + n \).","theorem Nat.lt_add_of_pos_left : 0 < k → n < k + n := by
  rw [Nat.add_comm]; exact Nat.lt_add_of_pos_right","To prove that for any natural numbers \( k \) and \( n \), if \( k > 0 \), then \( n < k + n \), we start by using the commutativity of addition. This allows us to rewrite the inequality \( n < k + n \) as \( n < n + k \).

Next, we apply the theorem that states if \( k > 0 \), then \( n < n + k \). This theorem is a known result in the properties of natural numbers, which asserts that adding a positive number to another number results in a strictly larger number.

Since \( k > 0 \), it follows that \( n < n + k \). Therefore, we have shown that \( n < k + n \), completing the proof. \(\blacksquare\)","theorem Nat.lt_add_of_pos_left : 0 < k → n < k + n := by
/- First, we use the commutativity of addition to rewrite the goal \( n < k + n \) as \( n < n + k \). Then, we apply the theorem that states if \( k \) is strictly greater than 0, then \( n \) is strictly less than \( n + k \). This completes the proof. -/
  rw [Nat.add_comm]; exact Nat.lt_add_of_pos_right","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32401,Nat.add_lt_of_lt_sub',theorem Nat.add_lt_of_lt_sub' {a b c : Nat} : b < c - a → a + b < c := by sorry,"Addition Preserves Strict Inequality: \( b < c - a \) Implies \( a + b < c \) : For any natural numbers \( a \), \( b \), and \( c \), if \( b < c - a \), then \( a + b < c \).","theorem Nat.add_lt_of_lt_sub' {a b c : Nat} : b < c - a → a + b < c := by
  rw [Nat.add_comm]; exact Nat.add_lt_of_lt_sub","To prove the theorem, we start with the given inequality \( b < c - a \). We need to show that \( a + b < c \).

1. By the commutativity of addition, we can rewrite \( a + b \) as \( b + a \). Thus, the goal is to show \( b + a < c \).
2. We use the theorem that states if \( b < c - a \), then \( b + a < c \). This theorem directly applies to our situation, and thus we have \( b + a < c \).

Therefore, we have shown that if \( b < c - a \), then \( a + b < c \). This completes the proof.","theorem Nat.add_lt_of_lt_sub' {a b c : Nat} : b < c - a → a + b < c := by
/- First, we use the commutativity of addition to rewrite the goal \( a + b < c \) as \( b + a < c \). Then, we apply the theorem that states if \( b < c - a \), then \( b + a < c \). This directly proves our goal. -/
  rw [Nat.add_comm]; exact Nat.add_lt_of_lt_sub","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32403,Nat.add_sub_cancel',theorem Nat.add_sub_cancel' {n m : Nat} (h : m ≤ n) : m + (n - m) = n := by sorry,"Addition and Subtraction Cancellation: \( m + (n - m) = n \) for \( m \leq n \) : For any natural numbers \( m \) and \( n \) such that \( m \leq n \), it holds that \( m + (n - m) = n \).","theorem Nat.add_sub_cancel' {n m : Nat} (h : m ≤ n) : m + (n - m) = n := by
  rw [Nat.add_comm, Nat.sub_add_cancel h]","We start with the goal of proving \( m + (n - m) = n \) under the assumption that \( m \leq n \).

1. **Step 1:**
We use the commutativity of addition to rewrite the goal:
\[
m + (n - m) = n \implies n - m + m = n
\]

2. **Step 2:**
Next, we use the property that subtraction and addition cancel each other in an additive group to simplify the left-hand side:
\[
n - m + m = n
\]
This simplification is valid because for any natural numbers \( a \) and \( b \) such that \( a \leq b \), the equation \( a - b + b = a \) holds.

3. **Step 3:**
The simplified goal \( n = n \) is trivially true.

Therefore, we have shown that \( m + (n - m) = n \) for any natural numbers \( m \) and \( n \) such that \( m \leq n \). This completes the proof. \(\blacksquare\)","theorem Nat.add_sub_cancel' {n m : Nat} (h : m ≤ n) : m + (n - m) = n := by
/- First, we use the commutativity of addition to rewrite the goal \( m + (n - m) = n \) as \( n - m + m = n \). Then, we use the property that subtraction and addition cancel each other in an additive group to simplify \( n - m + m \) to \( n \). Therefore, the goal \( n - m + m = n \) is equivalent to \( n = n \), which is trivially true. -/
  rw [Nat.add_comm, Nat.sub_add_cancel h]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32406,Nat.sub_add_lt_sub,theorem Nat.sub_add_lt_sub (h₁ : m + k ≤ n) (h₂ : 0 < k) : n - (m + k) < n - m := by sorry,"Subtraction of Sum Preserves Strict Inequality: \( n - (m + k) < n - m \) if \( m + k \leq n \) and \( 0 < k \) : For any natural numbers \( m \), \( k \), and \( n \), if \( m + k \leq n \) and \( 0 < k \), then \( n - (m + k) < n - m \).","theorem Nat.sub_add_lt_sub (h₁ : m + k ≤ n) (h₂ : 0 < k) : n - (m + k) < n - m := by
  rw [← Nat.sub_sub]; exact Nat.sub_lt_of_pos_le h₂ (Nat.le_sub_of_add_le' h₁)","We need to show that \( n - (m + k) < n - m \) given that \( m + k \leq n \) and \( 0 < k \).

1. First, we use the property of subtraction that \( n - (m + k) \) is equivalent to \( n - m - k \). This is because subtracting a sum is the same as subtracting each term individually.
2. Next, we need to show that \( n - m - k < n - m \).
3. Since \( 0 < k \), we know that \( k \) is a positive natural number.
4. Given \( m + k \leq n \), we can rewrite this as \( k \leq n - m \) by subtracting \( m \) from both sides.
5. Therefore, \( n - m - k < n - m \) because subtracting a positive number \( k \) from \( n - m \) results in a smaller number.
6. Hence, we have shown that \( n - (m + k) < n - m \).

This completes the proof.","theorem Nat.sub_add_lt_sub (h₁ : m + k ≤ n) (h₂ : 0 < k) : n - (m + k) < n - m := by
/- We start by using the property that \( n - (m + k) \) is equivalent to \( n - m - k \). Then, we need to show that \( n - m - k < n - m \). This follows from the fact that \( 0 < k \) and \( m + k \leq n \). Specifically, since \( 0 < k \) and \( m + k \leq n \), we have \( k \leq n - m \). Therefore, \( n - m - k < n - m \). -/
  rw [← Nat.sub_sub]; exact Nat.sub_lt_of_pos_le h₂ (Nat.le_sub_of_add_le' h₁)","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32409,Nat.min_self_assoc,theorem Nat.min_self_assoc {m n : Nat} : min m (min m n) = min m n := by sorry,"Associativity of Minimum with Self in Natural Numbers : For any natural numbers \( m \) and \( n \), the equation \(\min(m, \min(m, n)) = \min(m, n)\) holds.","theorem Nat.min_self_assoc {m n : Nat} : min m (min m n) = min m n := by
  rw [← Nat.min_assoc, Nat.min_self]","To prove the equation \(\min(m, \min(m, n)) = \min(m, n)\), we start by using the associativity of the minimum operation. The associativity property states that for any natural numbers \( a, b, \) and \( c \), \(\min(\min(a, b), c) = \min(a, \min(b, c))\). Applying this property, we can rewrite \(\min(m, \min(m, n))\) as \(\min(\min(m, m), n)\).

Next, we use the property that the minimum of an element with itself is the element itself, i.e., \(\min(a, a) = a\). Applying this property to \(\min(m, m)\), we get \(\min(m, m) = m\). Substituting this back into our expression, we have \(\min(\min(m, m), n) = \min(m, n)\).

Thus, we have shown that \(\min(m, \min(m, n)) = \min(m, n)\). This completes the proof. \(\blacksquare\)","theorem Nat.min_self_assoc {m n : Nat} : min m (min m n) = min m n := by
/- First, we use the associativity of the minimum operation, which states that \(\min(\min(a, b), c) = \min(a, \min(b, c))\), to rewrite the goal \(\min(m, \min(m, n))\) as \(\min(\min(m, m), n)\). Then, we use the property that the minimum of an element with itself is the element itself, i.e., \(\min(a, a) = a\), to simplify \(\min(m, m)\) to \(m\). Therefore, the goal \(\min(\min(m, m), n)\) simplifies to \(\min(m, n)\). This shows that \(\min(m, \min(m, n)) = \min(m, n)\). -/
  rw [← Nat.min_assoc, Nat.min_self]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32411,Nat.sub_right_comm,theorem Nat.sub_right_comm (m n k : Nat) : m - n - k = m - k - n := by sorry,"Subtraction Commutativity on Natural Numbers : For any natural numbers \( m \), \( n \), and \( k \), the expression \( m - n - k \) is equal to \( m - k - n \).","theorem Nat.sub_right_comm (m n k : Nat) : m - n - k = m - k - n := by
  rw [Nat.sub_sub, Nat.sub_sub, Nat.add_comm]","To prove that \( m - n - k = m - k - n \) for any natural numbers \( m \), \( n \), and \( k \), we use the following steps:

1. **Step 1: Apply the Subtraction Identity**
- We use the identity that for any natural numbers \( a, b, \) and \( c \), the expression \( a - b - c \) is equal to \( a - (b + c) \). Applying this identity twice, we get:
\[
m - n - k = m - (n + k)
\]
and
\[
m - k - n = m - (k + n)
\]

2. **Step 2: Use the Commutativity of Addition**
- We use the commutativity of addition, which states that for any natural numbers \( n \) and \( k \), \( n + k = k + n \). Therefore, we have:
\[
m - (n + k) = m - (k + n)
\]

3. **Step 3: Conclude the Proof**
- The original goal \( m - n - k = m - k - n \) is now equivalent to \( m - (k + n) = m - (k + n) \), which is trivially true by the reflexive property of equality.

Thus, we have shown that \( m - n - k = m - k - n \) for any natural numbers \( m \), \( n \), and \( k \). This completes the proof. \(\blacksquare\)","theorem Nat.sub_right_comm (m n k : Nat) : m - n - k = m - k - n := by
/- We start by using the identity that for any natural numbers \( a, b, \) and \( c \), the expression \( a - b - c \) is equal to \( a - (b + c) \). Applying this identity twice, we get:
\[ m - n - k = m - (n + k) \]
and
\[ m - k - n = m - (k + n) \]
Next, we use the commutativity of addition, which states that for any natural numbers \( n \) and \( k \), \( n + k = k + n \). Therefore, we have:
\[ m - (n + k) = m - (k + n) \]
Thus, the original goal \( m - n - k = m - k - n \) is equivalent to \( m - (k + n) = m - (k + n) \), which is trivially true by the reflexive property of equality. -/
  rw [Nat.sub_sub, Nat.sub_sub, Nat.add_comm]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32415,Nat.min_self_assoc',theorem Nat.min_self_assoc' {m n : Nat} : min n (min m n) = min n m := by sorry,"Associativity of Minimum with Self in Natural Numbers (Variant) : For any natural numbers \( m \) and \( n \), the equation \(\min(n, \min(m, n)) = \min(n, m)\) holds.","theorem Nat.min_self_assoc' {m n : Nat} : min n (min m n) = min n m := by
  rw [Nat.min_comm m n, ← Nat.min_assoc, Nat.min_self]","To prove the equation \(\min(n, \min(m, n)) = \min(n, m)\), we proceed as follows:

1. **Commutativity of Minimum:**
By the commutativity of the minimum operation, we have:
\[
\min(n, \min(m, n)) = \min(n, \min(n, m))
\]

2. **Associativity of Minimum:**
Using the associativity of the minimum operation, we can rewrite the right-hand side:
\[
\min(n, \min(n, m)) = \min(\min(n, n), m)
\]

3. **Minimum of an Element with Itself:**
Since the minimum of an element with itself is the element itself, we have:
\[
\min(\min(n, n), m) = \min(n, m)
\]

Combining these steps, we get:
\[
\min(n, \min(m, n)) = \min(n, m)
\]

Thus, the equation \(\min(n, \min(m, n)) = \min(n, m)\) holds for any natural numbers \( m \) and \( n \). This completes the proof. \(\blacksquare\)","theorem Nat.min_self_assoc' {m n : Nat} : min n (min m n) = min n m := by
/- We start by using the commutativity of the minimum operation, which states that \(\min(a, b) = \min(b, a)\). Applying this to \(\min(n, \min(m, n))\), we get \(\min(n, \min(n, m))\). Next, we use the associativity of the minimum operation, which states that \(\min(\min(a, b), c) = \min(a, \min(b, c))\). Applying this, we get \(\min(\min(n, n), m)\). Finally, we use the property that the minimum of an element with itself is the element itself, i.e., \(\min(a, a) = a\). Applying this, we get \(\min(n, m)\). Therefore, the goal \(\min(n, \min(m, n)) = \min(n, m)\) is equivalent to \(\min(n, m) = \min(n, m)\), which is trivially true. -/
  rw [Nat.min_comm m n, ← Nat.min_assoc, Nat.min_self]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32416,Nat.sub_add_min_cancel,theorem Nat.sub_add_min_cancel (n m : Nat) : n - m + min n m = n := by sorry,"Subtraction and Addition with Minimum Cancel Out in Natural Numbers : For any natural numbers \( n \) and \( m \), the expression \( n - m + \min(n, m) \) is equal to \( n \), i.e., \( n - m + \min(n, m) = n \).","theorem Nat.sub_add_min_cancel (n m : Nat) : n - m + min n m = n := by
  rw [Nat.sub_eq_sub_min, Nat.sub_add_cancel (Nat.min_le_left ..)]","We start by using the identity that for any natural numbers \( n \) and \( m \), \( n - m = n - \min(n, m) \). This allows us to rewrite the expression \( n - m + \min(n, m) \) as \( n - \min(n, m) + \min(n, m) \).

Next, we note that the minimum of \( n \) and \( m \) is less than or equal to \( n \), i.e., \(\min(n, m) \leq n\). By the property of subtraction and addition in additive groups, we have \( n - \min(n, m) + \min(n, m) = n \).

Thus, the expression \( n - m + \min(n, m) \) simplifies to \( n \). Therefore, we have shown that \( n - m + \min(n, m) = n \), completing the proof. \(\blacksquare\)","theorem Nat.sub_add_min_cancel (n m : Nat) : n - m + min n m = n := by
/- First, we use the identity that for any natural numbers \( n \) and \( m \), \( n - m = n - \min(n, m) \). This transforms our goal from \( n - m + \min(n, m) = n \) to \( n - \min(n, m) + \min(n, m) = n \). Next, we use the fact that the minimum of \( n \) and \( m \) is less than or equal to \( n \), i.e., \(\min(n, m) \leq n\). By the property of subtraction and addition in additive groups, \( n - \min(n, m) + \min(n, m) = n \). Therefore, the goal is now \( n = n \), which is trivially true. -/
  rw [Nat.sub_eq_sub_min, Nat.sub_add_cancel (Nat.min_le_left ..)]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32418,Nat.sub_min_sub_left,theorem Nat.sub_min_sub_left (a b c : Nat) : min (a - b) (a - c) = a - max b c := by sorry,"Minimum of Differences Equals Difference of Maximums in Natural Numbers : For any natural numbers \(a\), \(b\), and \(c\), the minimum of \(a - b\) and \(a - c\) is equal to \(a - \max(b, c)\), i.e., \(\min(a - b, a - c) = a - \max(b, c)\).","theorem Nat.sub_min_sub_left (a b c : Nat) : min (a - b) (a - c) = a - max b c := by
  omega","To prove the theorem, we need to show that for any natural numbers \(a\), \(b\), and \(c\), the equality \(\min(a - b, a - c) = a - \max(b, c)\) holds. We use the omega tactic, which is a powerful tool for handling arithmetic reasoning in natural numbers. This tactic automatically considers all possible cases and verifies the equality. Therefore, the theorem is true for all natural numbers \(a\), \(b\), and \(c\).

\[
\boxed{\min(a - b, a - c) = a - \max(b, c)}
\]","theorem Nat.sub_min_sub_left (a b c : Nat) : min (a - b) (a - c) = a - max b c := by
/- We use the omega tactic to automatically handle the arithmetic reasoning. This tactic simplifies the goal by considering all possible cases and verifying the equality \(\min(a - b, a - c) = a - \max(b, c)\) for any natural numbers \(a\), \(b\), and \(c\). -/
  omega","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32419,Nat.add_sub_sub_add_right,"theorem Nat.add_sub_sub_add_right (n m k l : Nat) :
    (n + l) - m - (k + l) = n - m - k := by sorry","Right Addition and Subtraction Identity: \( n + l - m - (k + l) = n - m - k \) : For any natural numbers \( n, m, k, \) and \( l \), the expression \( n + l - m - (k + l) \) is equal to \( n - m - k \).","theorem Nat.add_sub_sub_add_right (n m k l : Nat) :
    (n + l) - m - (k + l) = n - m - k := by
  rw [Nat.sub_sub, Nat.sub_sub, ←Nat.add_assoc, Nat.add_sub_add_right]","We need to show that \( n + l - m - (k + l) = n - m - k \). We will use the following properties of natural numbers:

1. **Subtraction Identity**: For any natural numbers \( a, b, \) and \( c \), the equation \( a - b - c = a - (b + c) \) holds.
2. **Associativity of Addition**: For any natural numbers \( a, b, \) and \( c \), the equation \( a + (b + c) = (a + b) + c \) holds.
3. **Right Addition Cancellation in Subtraction**: For any natural numbers \( n, k, \) and \( m \), the equation \( n + k - (m + k) = n - m \) holds.

Starting with the left-hand side of the equation:
\[
n + l - m - (k + l)
\]
Using the subtraction identity, we can rewrite this as:
\[
n + l - (m + (k + l))
\]
Applying the associativity of addition, we get:
\[
n + l - (m + k + l)
\]
Using the right addition cancellation in subtraction, we can simplify this to:
\[
n - (m + k)
\]
Thus, we have:
\[
n + l - m - (k + l) = n - (m + k)
\]
Since the right-hand side of the original equation is also \( n - (m + k) \), we have:
\[
n - (m + k) = n - (m + k)
\]
This is trivially true by the reflexive property of equality. Therefore, the original equation holds, and the proof is complete.","theorem Nat.add_sub_sub_add_right (n m k l : Nat) :
    (n + l) - m - (k + l) = n - m - k := by
/- We start by using the following properties of natural numbers:
1. The subtraction identity \( a - b - c = a - (b + c) \) to rewrite \( n + l - m - (k + l) \) as \( n + l - (m + (k + l)) \).
2. Applying the same subtraction identity again, we rewrite \( n + l - (m + (k + l)) \) as \( n + l - (m + k + l) \).
3. Using the associativity of addition \( a + (b + c) = (a + b) + c \), we rewrite \( m + (k + l) \) as \( m + k + l \).
4. Finally, using the right addition cancellation in subtraction \( n + k - (m + k) = n - m \), we rewrite \( n + l - (m + k + l) \) as \( n - (m + k) \).

Thus, the goal \( n + l - m - (k + l) = n - m - k \) is equivalent to \( n - (m + k) = n - (m + k) \), which is trivially true by the reflexive property of equality. -/
  rw [Nat.sub_sub, Nat.sub_sub, ←Nat.add_assoc, Nat.add_sub_add_right]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32420,Nat.sub_le_iff_le_add',theorem Nat.sub_le_iff_le_add' {a b c : Nat} : a - b ≤ c ↔ a ≤ b + c := by sorry,"Subtraction and Addition Inequality in Natural Numbers: \( a - b \leq c \leftrightarrow a \leq b + c \) : For any natural numbers \( a \), \( b \), and \( c \), the inequality \( a - b \leq c \) holds if and only if \( a \leq b + c \).","theorem Nat.sub_le_iff_le_add' {a b c : Nat} : a - b ≤ c ↔ a ≤ b + c := by
  rw [Nat.add_comm, Nat.sub_le_iff_le_add]","We start with the goal of proving the equivalence \( a - b \leq c \leftrightarrow a \leq b + c \).

1. **Step 1:**
We use the commutativity of addition, which states that for any natural numbers \( a \) and \( b \), \( a + b = b + a \). Applying this to our goal, we rewrite \( a - b \leq c \leftrightarrow a \leq b + c \) as \( a - b \leq c \leftrightarrow a \leq c + b \).

2. **Step 2:**
Next, we use the theorem that states for any natural numbers \( a \), \( b \), and \( c \), the inequality \( a - c \leq b \) holds if and only if \( a \leq b + c \). Applying this theorem, we rewrite the goal \( a - b \leq c \leftrightarrow a \leq c + b \) as \( a \leq c + b \leftrightarrow a \leq c + b \).

3. **Step 3:**
The resulting goal \( a \leq c + b \leftrightarrow a \leq c + b \) is trivially true because it is an equality of the same expression on both sides.

Thus, we have shown that \( a - b \leq c \leftrightarrow a \leq b + c \) holds for any natural numbers \( a \), \( b \), and \( c \). This completes the proof. \(\blacksquare\)","theorem Nat.sub_le_iff_le_add' {a b c : Nat} : a - b ≤ c ↔ a ≤ b + c := by
/- First, we use the commutativity of addition to rewrite the goal \( a - b \leq c \leftrightarrow a \leq b + c \) as \( a - b \leq c \leftrightarrow a \leq c + b \). Then, we use the theorem that states \( a - c \leq b \) if and only if \( a \leq b + c \) to rewrite the goal again, which simplifies to \( a \leq c + b \leftrightarrow a \leq c + b \). This is trivially true, thus completing the proof. -/
  rw [Nat.add_comm, Nat.sub_le_iff_le_add]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32421,Nat.sub_one_sub_lt,theorem Nat.sub_one_sub_lt (h : i < n) : n - 1 - i < n := by sorry,"Subtraction of One and Index Preserves Strict Inequality in Natural Numbers : For any natural numbers \( i \) and \( n \) such that \( i < n \), it holds that \( n - 1 - i < n \).","theorem Nat.sub_one_sub_lt (h : i < n) : n - 1 - i < n := by
  rw [Nat.sub_right_comm]; exact Nat.sub_one_lt_of_le (Nat.sub_pos_of_lt h) (Nat.sub_le ..)","We start with the assumption that \( i < n \). We need to show that \( n - 1 - i < n \).

First, we use the commutativity of subtraction to rewrite the expression \( n - 1 - i \) as \( n - i - 1 \). This gives us the goal of showing that \( n - i - 1 < n \).

Next, we observe that since \( i < n \), the difference \( n - i \) is a positive natural number. We use the property that subtracting one from a positive number results in a number that is still less than the original number. Specifically, we use the lemma that states if \( a \) is positive and \( a \leq b \), then \( a - 1 < b \). Here, \( a = n - i \) and \( b = n \).

Since \( n - i \) is positive and \( n - i \leq n \), it follows that \( n - i - 1 < n \).

Therefore, we have shown that \( n - 1 - i < n \), completing the proof.","theorem Nat.sub_one_sub_lt (h : i < n) : n - 1 - i < n := by
/- First, we use the commutativity of subtraction to rewrite the expression \( n - 1 - i \) as \( n - i - 1 \). Then, we need to show that \( n - i - 1 < n \). To do this, we use the fact that \( n - i \) is positive (since \( i < n \)) and that \( n - i - 1 \) is less than \( n \) by the property that subtracting one from a positive number results in a number that is still less than the original number. Specifically, we use the lemma that states if \( a \) is positive and \( a \leq b \), then \( a - 1 < b \). Here, \( a = n - i \) and \( b = n \). -/
  rw [Nat.sub_right_comm]; exact Nat.sub_one_lt_of_le (Nat.sub_pos_of_lt h) (Nat.sub_le ..)","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32422,Nat.sub_max_sub_left,theorem Nat.sub_max_sub_left (a b c : Nat) : max (a - b) (a - c) = a - min b c := by sorry,"Maximum of Differences Equals Difference of Minimums in Natural Numbers : For any natural numbers \(a\), \(b\), and \(c\), the maximum of \(a - b\) and \(a - c\) is equal to \(a - \min(b, c)\), i.e., \(\max(a - b, a - c) = a - \min(b, c)\).","theorem Nat.sub_max_sub_left (a b c : Nat) : max (a - b) (a - c) = a - min b c := by
  omega","To prove the theorem, we need to show that for any natural numbers \(a\), \(b\), and \(c\), the equality \(\max(a - b, a - c) = a - \min(b, c)\) holds. We use the omega tactic, which is a powerful tool for handling arithmetic reasoning in natural numbers. This tactic considers all possible cases and verifies the equality directly. Therefore, the theorem is established.

\[
\boxed{\max(a - b, a - c) = a - \min(b, c)}
\]","theorem Nat.sub_max_sub_left (a b c : Nat) : max (a - b) (a - c) = a - min b c := by
/- We use the omega tactic to automatically handle the arithmetic reasoning. This tactic simplifies the goal by considering all possible cases and verifying the equality \(\max(a - b, a - c) = a - \min(b, c)\) for natural numbers \(a\), \(b\), and \(c\). -/
  omega","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32423,Nat.sub_add_comm,theorem Nat.sub_add_comm {n m k : Nat} (h : k ≤ n) : n + m - k = n - k + m := by sorry,"Commutativity of Subtraction and Addition in Natural Numbers: \( n + m - k = n - k + m \) for \( k \leq n \) : For any natural numbers \( n \), \( m \), and \( k \) such that \( k \leq n \), the following equality holds: \( n + m - k = n - k + m \).","theorem Nat.sub_add_comm {n m k : Nat} (h : k ≤ n) : n + m - k = n - k + m := by
  rw [Nat.sub_eq_iff_eq_add (Nat.le_trans h (Nat.le_add_right ..))]
  rwa [Nat.add_right_comm, Nat.sub_add_cancel]","We start with the given condition \( k \leq n \). By the property that right addition preserves order, we have \( k \leq n + m \). Using the subtraction identity, the equation \( n + m - k = n - k + m \) is equivalent to \( n + m = n - k + m + k \).

Next, we use the right commutativity of addition to rewrite \( n - k + m + k \) as \( n - k + k + m \). By the property that subtraction and addition cancel each other, we have \( n - k + k = n \). Therefore, the equation \( n + m = n - k + k + m \) simplifies to \( n + m = n + m \), which is trivially true.

Thus, we have shown that \( n + m - k = n - k + m \) for any natural numbers \( n \), \( m \), and \( k \) such that \( k \leq n \). This completes the proof. \(\blacksquare\)","theorem Nat.sub_add_comm {n m k : Nat} (h : k ≤ n) : n + m - k = n - k + m := by
/- Since the theorem \( a - b = c \leftrightarrow a = c + b \) (subtraction identity) shows that \( n + m - k = n - k + m \) is equivalent to \( n + m = n - k + m + k \), and since \( k \leq n \) implies \( k \leq n + m \) by the property that right addition preserves order, it suffices to show that \( n + m = n - k + m + k \). -/
  rw [Nat.sub_eq_iff_eq_add (Nat.le_trans h (Nat.le_add_right ..))]
/- Using the right commutativity of addition, we can rewrite \( n - k + m + k \) as \( n - k + k + m \). Then, by the property that subtraction and addition cancel each other, \( n - k + k = n \). Therefore, the goal \( n + m = n - k + k + m \) simplifies to \( n + m = n + m \), which is trivially true. -/
  rwa [Nat.add_right_comm, Nat.sub_add_cancel]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32424,Nat.succ_sub_sub_succ,theorem Nat.succ_sub_sub_succ (n m k) : succ n - m - succ k = n - m - k := by sorry,"Successor Subtraction Identity: \( (n + 1) - m - (k + 1) = n - m - k \) : For any natural numbers \( n, m, \) and \( k \), the expression \( (n + 1) - m - (k + 1) \) is equal to \( n - m - k \).","theorem Nat.succ_sub_sub_succ (n m k) : succ n - m - succ k = n - m - k := by
  rw [Nat.sub_sub, Nat.sub_sub, add_succ, succ_sub_succ]","We start with the expression \( (n + 1) - m - (k + 1) \). Using the identity \( a - b - c = a - (b + c) \) twice, we can rewrite this as:
\[ (n + 1) - m - (k + 1) = (n + 1) - (m + (k + 1)) \]
Next, we use the identity \( n + (m + 1) = (n + m) + 1 \) to rewrite \( m + (k + 1) \) as \( (m + k) + 1 \):
\[ (n + 1) - (m + (k + 1)) = (n + 1) - ((m + k) + 1) \]
Finally, we use the identity \( (n + 1) - (m + 1) = n - m \) to rewrite \( (n + 1) - ((m + k) + 1) \) as \( n - (m + k) \):
\[ (n + 1) - ((m + k) + 1) = n - (m + k) \]
Thus, we have shown that:
\[ (n + 1) - m - (k + 1) = n - m - k \]
This completes the proof.","theorem Nat.succ_sub_sub_succ (n m k) : succ n - m - succ k = n - m - k := by
/- First, we use the identity \( a - b - c = a - (b + c) \) to rewrite the goal. Applying this identity twice, we get:
\[ n.succ - m - k.succ = n.succ - (m + k.succ) \]
Next, we use the identity \( n + (m + 1) = (n + m) + 1 \) to rewrite \( m + k.succ \) as \( (m + k).succ \):
\[ n.succ - (m + k.succ) = n.succ - (m + k).succ \]
Finally, we use the identity \( (n + 1) - (m + 1) = n - m \) to rewrite \( n.succ - (m + k).succ \) as \( n - (m + k) \):
\[ n.succ - (m + k).succ = n - (m + k) \]
Thus, the goal is now:
\[ n - (m + k) = n - (m + k) \]
This is trivially true by the properties of equality. -/
  rw [Nat.sub_sub, Nat.sub_sub, add_succ, succ_sub_succ]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32426,Nat.add_max_add_left,theorem Nat.add_max_add_left (a b c : Nat) : max (a + b) (a + c) = a + max b c := by sorry,"Maximum of Sums Equals Sum of Maximum in Natural Numbers : For any natural numbers \(a\), \(b\), and \(c\), the maximum of \(a + b\) and \(a + c\) is equal to \(a + \max(b, c)\), i.e., \(\max(a + b, a + c) = a + \max(b, c)\).","theorem Nat.add_max_add_left (a b c : Nat) : max (a + b) (a + c) = a + max b c := by
  repeat rw [Nat.add_comm a]
  exact Nat.add_max_add_right ..","We start by using the commutativity of addition to rewrite the goal. Specifically, we rewrite \(a + b\) as \(b + a\) and \(a + c\) as \(c + a\). This transforms the goal from \(\max(a + b, a + c) = a + \max(b, c)\) to \(\max(b + a, c + a) = a + \max(b, c)\).

Next, we use the distributive property of the maximum over addition in natural numbers, which states that \(\max(a + c, b + c) = \max(a, b) + c\). Applying this property, we see that \(\max(b + a, c + a) = \max(b, c) + a\).

Thus, the goal \(\max(b + a, c + a) = \max(b, c) + a\) is satisfied, and the proof is complete. \(\blacksquare\)","theorem Nat.add_max_add_left (a b c : Nat) : max (a + b) (a + c) = a + max b c := by
/- We repeatedly use the commutativity of addition to rewrite the goal. Specifically, we rewrite \(a + b\) as \(b + a\) and \(a + c\) as \(c + a\). This transforms the goal from \(\max(a + b, a + c) = a + \max(b, c)\) to \(\max(b + a, c + a) = a + \max(b, c)\). -/
  repeat rw [Nat.add_comm a]
/- The current goal \(\max(b + a, c + a) = \max(b, c) + a\) is exactly proved by the distributive property of the maximum over addition in natural numbers, which states that \(\max(a + c, b + c) = \max(a, b) + c\). Therefore, the goal is satisfied. -/
  exact Nat.add_max_add_right ..","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32428,Nat.sub_eq_sub_min,theorem Nat.sub_eq_sub_min (n m : Nat) : n - m = n - min n m := by sorry,"Subtraction Identity: \( n - m = n - \min(n, m) \) : For any natural numbers \( n \) and \( m \), the expression \( n - m \) is equal to \( n - \min(n, m) \), i.e., \( n - m = n - \min(n, m) \).","theorem Nat.sub_eq_sub_min (n m : Nat) : n - m = n - min n m := by
  cases Nat.le_total n m with
  | inl h => rw [Nat.min_eq_left h, Nat.sub_eq_zero_of_le h, Nat.sub_self]
  | inr h => rw [Nat.min_eq_right h]","We need to show that for any natural numbers \( n \) and \( m \), the equation \( n - m = n - \min(n, m) \) holds. We consider two cases based on the relationship between \( n \) and \( m \).

1. **Case 1: \( m \leq n \)**
- By the property of the minimum function, \(\min(n, m) = m\).
- Therefore, the goal \( n - m = n - \min(n, m) \) simplifies to \( n - m = n - m \), which is trivially true.

2. **Case 2: \( n \leq m \)**
- By the property of the minimum function, \(\min(n, m) = n\).
- Therefore, the goal \( n - m = n - \min(n, m) \) simplifies to \( n - m = n - n \).
- Since \( n \leq m \), we know that \( n - m = 0 \) by the property of subtraction in natural numbers.
- Also, \( n - n = 0 \) by the property that subtracting a number from itself gives zero.
- Thus, the goal \( n - m = n - n \) simplifies to \( 0 = 0 \), which is trivially true.

In both cases, the equation \( n - m = n - \min(n, m) \) holds. Therefore, the theorem is proved. \(\blacksquare\)","theorem Nat.sub_eq_sub_min (n m : Nat) : n - m = n - min n m := by
  cases Nat.le_total n m with
/- If \( n \leq m \), then by the property that the minimum of two numbers is the smaller one, we have \(\min(n, m) = n\). Therefore, the goal \( n - m = n - \min(n, m) \) simplifies to \( n - m = n - n \). Since \( n \leq m \), we know that \( n - m = 0 \) by the property of subtraction in natural numbers. Also, \( n - n = 0 \) by the property that subtracting a number from itself gives zero. Thus, the goal \( n - m = n - n \) simplifies to \( 0 = 0 \), which is trivially true. -/
  | inl h => rw [Nat.min_eq_left h, Nat.sub_eq_zero_of_le h, Nat.sub_self]
/- If \( m \leq n \), then by the property that the minimum of two numbers is the smaller one, we have \(\min(n, m) = m\). Therefore, the goal \( n - m = n - \min(n, m) \) simplifies to \( n - m = n - m \), which is trivially true. -/
  | inr h => rw [Nat.min_eq_right h]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32429,Nat.succ_max_succ,theorem Nat.succ_max_succ (x y) : max (succ x) (succ y) = succ (max x y) := by sorry,"Successor of Maximum is Maximum of Successors: \(\max(x + 1, y + 1) = \max(x, y) + 1\) : For any natural numbers \( x \) and \( y \), the maximum of their successors is equal to the successor of their maximum, i.e., \(\max(x + 1, y + 1) = \max(x, y) + 1\).","theorem Nat.succ_max_succ (x y) : max (succ x) (succ y) = succ (max x y) := by
  cases Nat.le_total x y with
  | inl h => rw [Nat.max_eq_right h, Nat.max_eq_right (Nat.succ_le_succ h)]
  | inr h => rw [Nat.max_eq_left h, Nat.max_eq_left (Nat.succ_le_succ h)]","We need to show that for any natural numbers \( x \) and \( y \), \(\max(x + 1, y + 1) = \max(x, y) + 1\).

Consider the following cases:

1. **Case 1: \( y \leq x \)**
- By the property of the maximum function, \(\max(x, y) = x\).
- Since the successor function preserves the less than or equal relation, we have \( y + 1 \leq x + 1 \).
- Therefore, \(\max(x + 1, y + 1) = x + 1\).
- Hence, \(\max(x + 1, y + 1) = \max(x, y) + 1\).

2. **Case 2: \( x \leq y \)**
- By the property of the maximum function, \(\max(x, y) = y\).
- Since the successor function preserves the less than or equal relation, we have \( x + 1 \leq y + 1 \).
- Therefore, \(\max(x + 1, y + 1) = y + 1\).
- Hence, \(\max(x + 1, y + 1) = \max(x, y) + 1\).

In both cases, we have shown that \(\max(x + 1, y + 1) = \max(x, y) + 1\). This completes the proof. \(\blacksquare\)","theorem Nat.succ_max_succ (x y) : max (succ x) (succ y) = succ (max x y) := by
  cases Nat.le_total x y with
/- If \( x \leq y \), then by the property that the maximum of two elements is the right element if the left is less than or equal to the right, we have \(\max(x, y) = y\). Similarly, since the successor function preserves the less than or equal relation, we have \(\max(x + 1, y + 1) = y + 1\). Therefore, \(\max(x + 1, y + 1) = \max(x, y) + 1\). -/
  | inl h => rw [Nat.max_eq_right h, Nat.max_eq_right (Nat.succ_le_succ h)]
/- If \( y \leq x \), then by the property that the maximum of two elements is the left element if the right is less than or equal to the left, we have \(\max(x, y) = x\). Similarly, since the successor function preserves the less than or equal relation, we have \(\max(x + 1, y + 1) = x + 1\). Therefore, \(\max(x + 1, y + 1) = \max(x, y) + 1\). -/
  | inr h => rw [Nat.max_eq_left h, Nat.max_eq_left (Nat.succ_le_succ h)]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32430,Nat.add_min_add_left,theorem Nat.add_min_add_left (a b c : Nat) : min (a + b) (a + c) = a + min b c := by sorry,"Minimum of Sums Equals Sum of Minimum in Natural Numbers : For any natural numbers \(a\), \(b\), and \(c\), the minimum of \(a + b\) and \(a + c\) is equal to \(a + \min(b, c)\), i.e., \(\min(a + b, a + c) = a + \min(b, c)\).","theorem Nat.add_min_add_left (a b c : Nat) : min (a + b) (a + c) = a + min b c := by
  repeat rw [Nat.add_comm a]
  exact Nat.add_min_add_right ..","We start by using the commutativity of addition to rewrite the goal. Specifically, we rewrite \(a + b\) as \(b + a\) and \(a + c\) as \(c + a\). This transforms the goal from \(\min(a + b, a + c) = a + \min(b, c)\) to \(\min(b + a, c + a) = a + \min(b, c)\).

Next, we use the distributive property of the minimum over addition in natural numbers, which states that \(\min(a + c, b + c) = \min(a, b) + c\). Applying this property, we see that \(\min(b + a, c + a) = \min(b, c) + a\).

Thus, the goal \(\min(b + a, c + a) = \min(b, c) + a\) is satisfied, and the proof is complete. \(\blacksquare\)","theorem Nat.add_min_add_left (a b c : Nat) : min (a + b) (a + c) = a + min b c := by
/- We repeatedly use the commutativity of addition to rewrite the goal. Specifically, we rewrite \(a + b\) as \(b + a\) and \(a + c\) as \(c + a\). This transforms the goal from \(\min(a + b, a + c) = a + \min(b, c)\) to \(\min(b + a, c + a) = a + \min(b, c)\). -/
  repeat rw [Nat.add_comm a]
/- The current goal \(\min(b + a, c + a) = \min(b, c) + a\) is exactly proved by the distributive property of the minimum over addition in natural numbers, which states that \(\min(a + c, b + c) = \min(a, b) + c\). Therefore, the goal is satisfied. -/
  exact Nat.add_min_add_right ..","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32431,Nat.sub_add_eq_max,theorem Nat.sub_add_eq_max (a b : Nat) : a - b + b = max a b := by sorry,"Subtraction and Addition Identity for Maximum in Natural Numbers : For any natural numbers \(a\) and \(b\), the equation \(a - b + b = \max(a, b)\) holds.","theorem Nat.sub_add_eq_max (a b : Nat) : a - b + b = max a b := by
  match Nat.le_total a b with
  | .inl hl => rw [Nat.max_eq_right hl, Nat.sub_eq_zero_iff_le.mpr hl, Nat.zero_add]
  | .inr hr => rw [Nat.max_eq_left hr, Nat.sub_add_cancel hr]","We need to show that for any natural numbers \(a\) and \(b\), the equation \(a - b + b = \max(a, b)\) holds. We consider two cases based on the relationship between \(a\) and \(b\).

1. **Case 1: \(a \leq b\)**

In this case, the maximum of \(a\) and \(b\) is \(b\). By the definition of the maximum function, we have \(\max(a, b) = b\). Additionally, since \(a \leq b\), the expression \(a - b\) is zero, and thus:
\[
a - b + b = 0 + b = b
\]
Therefore, \(a - b + b = \max(a, b)\).

2. **Case 2: \(a > b\)**

In this case, the maximum of \(a\) and \(b\) is \(a\). By the definition of the maximum function, we have \(\max(a, b) = a\). Additionally, since \(a > b\), the expression \(a - b\) is a positive natural number, and thus:
\[
a - b + b = (a - b) + b = a
\]
Therefore, \(a - b + b = \max(a, b)\).

In both cases, we have shown that \(a - b + b = \max(a, b)\). This completes the proof.","theorem Nat.sub_add_eq_max (a b : Nat) : a - b + b = max a b := by
  match Nat.le_total a b with
/- Consider the case where \(a > b\). In this case, the maximum of \(a\) and \(b\) is \(a\). By the definition of the maximum function, we have \(\max(a, b) = a\). Additionally, since \(a > b\), the expression \(a - b\) is a positive natural number, and thus \(a - b + b = (a - b) + b = a\). Therefore, \(a - b + b = \max(a, b)\). -/
  | .inl hl => rw [Nat.max_eq_right hl, Nat.sub_eq_zero_iff_le.mpr hl, Nat.zero_add]
/- Consider the case where \(a \leq b\). In this case, the maximum of \(a\) and \(b\) is \(b\). By the definition of the maximum function, we have \(\max(a, b) = b\). Additionally, since \(a \leq b\), the expression \(a - b\) is zero, and thus \(a - b + b = 0 + b = b\). Therefore, \(a - b + b = \max(a, b)\). -/
  | .inr hr => rw [Nat.max_eq_left hr, Nat.sub_add_cancel hr]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32432,Nat.max_lt,theorem Nat.max_lt {a b c : Nat} : max a b < c ↔ a < c ∧ b < c := by sorry,"Maximum of Two Natural Numbers is Less Than a Third if and Only if Both are Less Than the Third: \(\max(a, b) < c \leftrightarrow a < c \land b < c\) : For any natural numbers \(a\), \(b\), and \(c\), the maximum of \(a\) and \(b\) is strictly less than \(c\) if and only if both \(a\) and \(b\) are strictly less than \(c\). In other words, \(\max(a, b) < c \leftrightarrow a < c \land b < c\).","theorem Nat.max_lt {a b c : Nat} : max a b < c ↔ a < c ∧ b < c := by
  rw [← Nat.succ_le, ← Nat.succ_max_succ a b]; exact Nat.max_le","To prove the equivalence \(\max(a, b) < c \leftrightarrow a < c \land b < c\), we proceed as follows:

1. **(\(\Rightarrow\)) Assume \(\max(a, b) < c\):**
- By the definition of the maximum function, \(\max(a, b)\) is the larger of \(a\) and \(b\).
- Therefore, \(\max(a, b) < c\) implies that both \(a \leq \max(a, b)\) and \(b \leq \max(a, b)\).
- Since \(\max(a, b) < c\), it follows that \(a < c\) and \(b < c\).

2. **(\(\Leftarrow\)) Assume \(a < c\) and \(b < c\):**
- By the definition of the maximum function, \(\max(a, b)\) is the larger of \(a\) and \(b\).
- Since \(a < c\) and \(b < c\), it follows that \(\max(a, b) \leq c\).
- To show \(\max(a, b) < c\), we use the fact that \(\max(a, b) + 1 \leq c\).
- This is equivalent to \(\max(a + 1, b + 1) \leq c\), which is true because \(a + 1 \leq c\) and \(b + 1 \leq c\).

Thus, we have shown that \(\max(a, b) < c\) if and only if \(a < c\) and \(b < c\). This completes the proof. \(\blacksquare\)","theorem Nat.max_lt {a b c : Nat} : max a b < c ↔ a < c ∧ b < c := by
/- To prove that \(\max(a, b) < c\) if and only if \(a < c\) and \(b < c\), we use the following steps:
1. We use the equivalence that \(\max(a, b) < c\) is equivalent to \(\max(a, b) + 1 \leq c\).
2. We also use the equivalence that \(\max(a, b) + 1 = \max(a + 1, b + 1)\).
3. Therefore, the goal reduces to showing that \(\max(a + 1, b + 1) \leq c\) if and only if \(a + 1 \leq c\) and \(b + 1 \leq c\).
4. This is a known property of the maximum function, which states that \(\max(a + 1, b + 1) \leq c\) if and only if \(a + 1 \leq c\) and \(b + 1 \leq c\). -/
  rw [← Nat.succ_le, ← Nat.succ_max_succ a b]; exact Nat.max_le","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32433,Nat.succ_min_succ,theorem Nat.succ_min_succ (x y) : min (succ x) (succ y) = succ (min x y) := by sorry,"Successor of Minimum is Minimum of Successors: \(\min(x + 1, y + 1) = \min(x, y) + 1\) : For any natural numbers \( x \) and \( y \), the minimum of their successors is equal to the successor of their minimum, i.e., \(\min(x + 1, y + 1) = \min(x, y) + 1\).","theorem Nat.succ_min_succ (x y) : min (succ x) (succ y) = succ (min x y) := by
  cases Nat.le_total x y with
  | inl h => rw [Nat.min_eq_left h, Nat.min_eq_left (Nat.succ_le_succ h)]
  | inr h => rw [Nat.min_eq_right h, Nat.min_eq_right (Nat.succ_le_succ h)]","We need to show that for any natural numbers \( x \) and \( y \), \(\min(x + 1, y + 1) = \min(x, y) + 1\).

Consider the following cases:

1. **Case 1: \( y \leq x \)**
- By the property of the minimum function, \(\min(x, y) = y\).
- Since the successor function preserves the less than or equal relation, we have \( y + 1 \leq x + 1 \).
- Therefore, \(\min(x + 1, y + 1) = y + 1\).
- Hence, \(\min(x + 1, y + 1) = \min(x, y) + 1\) is equivalent to \( y + 1 = y + 1 \), which is trivially true.

2. **Case 2: \( x \leq y \)**
- By the property of the minimum function, \(\min(x, y) = x\).
- Since the successor function preserves the less than or equal relation, we have \( x + 1 \leq y + 1 \).
- Therefore, \(\min(x + 1, y + 1) = x + 1\).
- Hence, \(\min(x + 1, y + 1) = \min(x, y) + 1\) is equivalent to \( x + 1 = x + 1 \), which is trivially true.

In both cases, the goal is satisfied. Therefore, for any natural numbers \( x \) and \( y \), \(\min(x + 1, y + 1) = \min(x, y) + 1\). This completes the proof. \(\blacksquare\)","theorem Nat.succ_min_succ (x y) : min (succ x) (succ y) = succ (min x y) := by
  cases Nat.le_total x y with
/- Consider the case where \( x \leq y \). By the property that the minimum of two numbers is the smaller one, we have \(\min(x, y) = x\). Since the successor function preserves the less than or equal relation, we also have \(\min(x + 1, y + 1) = x + 1\). Therefore, the goal \(\min(x + 1, y + 1) = \min(x, y) + 1\) is equivalent to \(x + 1 = x + 1\), which is trivially true. -/
  | inl h => rw [Nat.min_eq_left h, Nat.min_eq_left (Nat.succ_le_succ h)]
/- Consider the case where \( y \leq x \). By the property that the minimum of two numbers is the smaller one, we have \(\min(x, y) = y\). Since the successor function preserves the less than or equal relation, we also have \(\min(x + 1, y + 1) = y + 1\). Therefore, the goal \(\min(x + 1, y + 1) = \min(x, y) + 1\) is equivalent to \(y + 1 = y + 1\), which is trivially true. -/
  | inr h => rw [Nat.min_eq_right h, Nat.min_eq_right (Nat.succ_le_succ h)]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32434,Nat.min_max_distrib_right,"theorem Nat.min_max_distrib_right (a b c : Nat) :
    min (max a b) c = max (min a c) (min b c) := by sorry","Distributive Property of Minimum over Maximum on the Right: \(\min(\max(a, b), c) = \max(\min(a, c), \min(b, c))\) : For any natural numbers \(a\), \(b\), and \(c\), the minimum of the maximum of \(a\) and \(b\) with \(c\) is equal to the maximum of the minimum of \(a\) and \(c\) with the minimum of \(b\) and \(c\). In other words, \(\min(\max(a, b), c) = \max(\min(a, c), \min(b, c))\).","theorem Nat.min_max_distrib_right (a b c : Nat) :
    min (max a b) c = max (min a c) (min b c) := by
  repeat rw [Nat.min_comm _ c]
  exact Nat.min_max_distrib_left ..","To prove the distributive property of the minimum over the maximum on the right, we start with the goal:
\[
\min(\max(a, b), c) = \max(\min(a, c), \min(b, c))
\]

First, we use the commutativity of the minimum operation, which states that for any natural numbers \(x\) and \(y\), \(\min(x, y) = \min(y, x)\). Applying this property, we rewrite the goal as:
\[
\min(c, \max(a, b)) = \max(\min(c, a), \min(c, b))
\]

Next, we use the distributive property of the minimum over the maximum on the left, which states that for any natural numbers \(a\), \(b\), and \(c\):
\[
\min(a, \max(b, c)) = \max(\min(a, b), \min(a, c))
\]

By substituting \(a = c\), \(b = a\), and \(c = b\) into this property, we get:
\[
\min(c, \max(a, b)) = \max(\min(c, a), \min(c, b))
\]

This exactly matches our rewritten goal, thus completing the proof. Therefore, we have:
\[
\min(\max(a, b), c) = \max(\min(a, c), \min(b, c))
\]

\(\blacksquare\)","theorem Nat.min_max_distrib_right (a b c : Nat) :
    min (max a b) c = max (min a c) (min b c) := by
/- We repeatedly use the commutativity of the minimum operation to rewrite the goal. Specifically, we use the fact that \(\min(a, b) = \min(b, a)\) to transform the goal \(\min(\max(a, b), c) = \max(\min(a, c), \min(b, c))\) into \(\min(c, \max(a, b)) = \max(\min(c, a), \min(c, b))\). -/
  repeat rw [Nat.min_comm _ c]
/- The current goal \(\min(c, \max(a, b)) = \max(\min(c, a), \min(c, b))\) is exactly proved by the distributive property of the minimum over the maximum on the left, which states that for any natural numbers \(a\), \(b\), and \(c\), \(\min(a, \max(b, c)) = \max(\min(a, b), \min(a, c))\). -/
  exact Nat.min_max_distrib_left ..","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32435,Nat.sub_eq_max_sub,theorem Nat.sub_eq_max_sub (n m : Nat) : n - m = max n m - m := by sorry,"Subtraction Identity: \( n - m = \max(n, m) - m \) : For any natural numbers \( n \) and \( m \), the subtraction \( n - m \) is equal to the maximum of \( n \) and \( m \) minus \( m \), i.e., \( n - m = \max(n, m) - m \).","theorem Nat.sub_eq_max_sub (n m : Nat) : n - m = max n m - m := by
  cases Nat.le_total m n with
  | inl h => rw [Nat.max_eq_left h]
  | inr h => rw [Nat.max_eq_right h, Nat.sub_eq_zero_of_le h, Nat.sub_self]","We need to prove that for any natural numbers \( n \) and \( m \), the equation \( n - m = \max(n, m) - m \) holds. We consider two cases based on the relationship between \( n \) and \( m \).

1. **Case 1: \( n \leq m \)**
- By the property of the maximum function, \(\max(n, m) = m\).
- Therefore, the goal \( n - m = \max(n, m) - m \) simplifies to \( n - m = m - m \).
- Since \( n \leq m \), we know that \( n - m = 0 \).
- Also, \( m - m = 0 \).
- Thus, the goal reduces to \( 0 = 0 \), which is trivially true.

2. **Case 2: \( m \leq n \)**
- By the property of the maximum function, \(\max(n, m) = n\).
- Therefore, the goal \( n - m = \max(n, m) - m \) simplifies to \( n - m = n - m \), which is trivially true.

Since both cases are covered, the theorem is proved. \(\blacksquare\)","theorem Nat.sub_eq_max_sub (n m : Nat) : n - m = max n m - m := by
  cases Nat.le_total m n with
/- Consider the case where \( m \leq n \). By the property of the maximum function, \(\max(n, m) = n\). Therefore, the goal \( n - m = \max(n, m) - m \) simplifies to \( n - m = n - m \), which is trivially true. -/
  | inl h => rw [Nat.max_eq_left h]
/- Consider the case where \( n \leq m \). By the property of the maximum function, \(\max(n, m) = m\). Therefore, the goal \( n - m = \max(n, m) - m \) simplifies to \( n - m = m - m \). Since \( n \leq m \), we know that \( n - m = 0 \). Also, \( m - m = 0 \). Thus, the goal reduces to \( 0 = 0 \), which is trivially true. -/
  | inr h => rw [Nat.max_eq_right h, Nat.sub_eq_zero_of_le h, Nat.sub_self]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32436,Nat.mul_right_cancel,theorem Nat.mul_right_cancel {n m k : Nat} (mp : 0 < m) (h : n * m = k * m) : n = k := by sorry,"Right Multiplication Cancellation in Natural Numbers : For any natural numbers \( n \), \( m \), and \( k \), if \( m \) is nonzero and \( n \cdot m = k \cdot m \), then \( n = k \).","theorem Nat.mul_right_cancel {n m k : Nat} (mp : 0 < m) (h : n * m = k * m) : n = k := by
  simp [Nat.mul_comm _ m] at h
  apply Nat.mul_left_cancel mp h","We start with the given conditions: \( m \) is a nonzero natural number, and \( n \cdot m = k \cdot m \).

First, we use the commutativity of multiplication to rewrite the equation \( n \cdot m = k \cdot m \) as \( m \cdot n = m \cdot k \).

Next, we apply the left multiplication cancellation property, which states that if \( m \cdot n = m \cdot k \) and \( m \) is nonzero, then \( n = k \). Since \( m \) is nonzero (given by \( 0 < m \)), and we have \( m \cdot n = m \cdot k \), it follows that \( n = k \).

Thus, we have shown that \( n = k \), completing the proof.","theorem Nat.mul_right_cancel {n m k : Nat} (mp : 0 < m) (h : n * m = k * m) : n = k := by
/- Using the commutativity of multiplication, we can rewrite the hypothesis \( n \cdot m = k \cdot m \) as \( m \cdot n = m \cdot k \). -/
  simp [Nat.mul_comm _ m] at h
/- To prove \( n = k \), we use the left multiplication cancellation property, which states that if \( m \cdot n = m \cdot k \) and \( m \) is nonzero, then \( n = k \). Since \( m \) is nonzero (given by \( 0 < m \)), and we have \( m \cdot n = m \cdot k \), it follows that \( n = k \). -/
  apply Nat.mul_left_cancel mp h","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32437,Nat.mul_right_comm,theorem Nat.mul_right_comm (n m k : Nat) : n * m * k = n * k * m := by sorry,"Right Commutativity of Multiplication in Natural Numbers: \( n \cdot m \cdot k = n \cdot k \cdot m \) : For any natural numbers \( n, m, k \), the equation \( n \cdot m \cdot k = n \cdot k \cdot m \) holds. This theorem demonstrates the commutativity of the middle term in a product of three natural numbers.","theorem Nat.mul_right_comm (n m k : Nat) : n * m * k = n * k * m := by
  rw [Nat.mul_assoc, Nat.mul_comm m, ← Nat.mul_assoc]","To prove \( n \cdot m \cdot k = n \cdot k \cdot m \), we start by using the associativity of multiplication. This allows us to rewrite the left-hand side as:
\[
n \cdot m \cdot k = n \cdot (m \cdot k)
\]
Next, we use the commutativity of multiplication to swap \( m \) and \( k \) in the product:
\[
n \cdot (m \cdot k) = n \cdot (k \cdot m)
\]
Finally, we use the associativity of multiplication again to rewrite the expression:
\[
n \cdot (k \cdot m) = n \cdot k \cdot m
\]
Thus, we have shown that:
\[
n \cdot m \cdot k = n \cdot k \cdot m
\]
This completes the proof. \(\blacksquare\)","theorem Nat.mul_right_comm (n m k : Nat) : n * m * k = n * k * m := by
/- To prove \( n \cdot m \cdot k = n \cdot k \cdot m \), we use the associativity of multiplication to rewrite the left-hand side as \( n \cdot (m \cdot k) \). Then, we use the commutativity of multiplication to swap \( m \) and \( k \) in the product, resulting in \( n \cdot (k \cdot m) \). Finally, we use the associativity of multiplication again to rewrite \( n \cdot (k \cdot m) \) as \( n \cdot k \cdot m \). Thus, the goal is now to show \( n \cdot k \cdot m = n \cdot k \cdot m \), which is trivially true by the reflexive property of equality. -/
  rw [Nat.mul_assoc, Nat.mul_comm m, ← Nat.mul_assoc]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32438,Nat.max_min_distrib_right,"theorem Nat.max_min_distrib_right (a b c : Nat) :
    max (min a b) c = min (max a c) (max b c) := by sorry","Distributive Property of Maximum over Minimum on the Right: \(\max(\min(a, b), c) = \min(\max(a, c), \max(b, c))\) : For any natural numbers \(a\), \(b\), and \(c\), the maximum of the minimum of \(a\) and \(b\) with \(c\) is equal to the minimum of the maximum of \(a\) and \(c\) with the maximum of \(b\) and \(c\). In other words, \(\max(\min(a, b), c) = \min(\max(a, c), \max(b, c))\).","theorem Nat.max_min_distrib_right (a b c : Nat) :
    max (min a b) c = min (max a c) (max b c) := by
  repeat rw [Nat.max_comm _ c]
  exact Nat.max_min_distrib_left ..","We start by using the commutativity of the maximum operation, which states that for any natural numbers \(a\) and \(b\), \(\max(a, b) = \max(b, a)\). Applying this property repeatedly, we can rewrite the goal \(\max(\min(a, b), c) = \min(\max(a, c), \max(b, c))\) as \(\max(c, \min(a, b)) = \min(\max(c, a), \max(c, b))\).

Next, we use the distributive property of the maximum over the minimum on the left, which states that for any natural numbers \(a\), \(b\), and \(c\), \(\max(a, \min(b, c)) = \min(\max(a, b), \max(a, c))\). This property directly proves our rewritten goal \(\max(c, \min(a, b)) = \min(\max(c, a), \max(c, b))\).

Thus, we have shown that \(\max(\min(a, b), c) = \min(\max(a, c), \max(b, c))\), completing the proof. \(\blacksquare\)","theorem Nat.max_min_distrib_right (a b c : Nat) :
    max (min a b) c = min (max a c) (max b c) := by
/- We repeatedly use the commutativity of the maximum operation, which states that for any natural numbers \(a\) and \(b\), \(\max(a, b) = \max(b, a)\). This allows us to rewrite the goal \(\max(\min(a, b), c) = \min(\max(a, c), \max(b, c))\) as \(\max(c, \min(a, b)) = \min(\max(c, a), \max(c, b))\). -/
  repeat rw [Nat.max_comm _ c]
/- The current goal \(\max(c, \min(a, b)) = \min(\max(c, a), \max(c, b))\) is exactly proved by the distributive property of the maximum over the minimum on the left, which states that for any natural numbers \(a\), \(b\), and \(c\), \(\max(a, \min(b, c)) = \min(\max(a, b), \max(a, c))\). This completes the proof. -/
  exact Nat.max_min_distrib_left ..","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32439,Nat.mul_max_mul_left,theorem Nat.mul_max_mul_left (a b c : Nat) : max (a * b) (a * c) = a * max b c := by sorry,"Maximum of Products Equals Product of Maximum in Natural Numbers : For any natural numbers \(a\), \(b\), and \(c\), the maximum of the products \(a \cdot b\) and \(a \cdot c\) is equal to the product of \(a\) and the maximum of \(b\) and \(c\), i.e., \(\max(a \cdot b, a \cdot c) = a \cdot \max(b, c)\).","theorem Nat.mul_max_mul_left (a b c : Nat) : max (a * b) (a * c) = a * max b c := by
  repeat rw [Nat.mul_comm a]
  exact Nat.mul_max_mul_right ..","To prove the theorem, we start with the goal \(\max(a \cdot b, a \cdot c) = a \cdot \max(b, c)\). We use the commutativity of multiplication, which states that for any natural numbers \(x\) and \(y\), \(x \cdot y = y \cdot x\). Applying this property, we rewrite the goal as follows:
\[
\max(a \cdot b, a \cdot c) = \max(b \cdot a, c \cdot a)
\]
Next, we need to show that \(\max(b \cdot a, c \cdot a) = \max(b, c) \cdot a\). This is exactly what the theorem \(\max(a \cdot c, b \cdot c) = \max(a, b) \cdot c\) states, which is a known result in the theory of natural numbers. Therefore, the goal is satisfied, and the proof is complete.

\(\blacksquare\)","theorem Nat.mul_max_mul_left (a b c : Nat) : max (a * b) (a * c) = a * max b c := by
/- We repeatedly use the commutativity of multiplication to rewrite the goal. Specifically, we rewrite \(a \cdot b\) as \(b \cdot a\) and \(a \cdot c\) as \(c \cdot a\). This transforms the goal from \(\max(a \cdot b, a \cdot c) = a \cdot \max(b, c)\) to \(\max(b \cdot a, c \cdot a) = \max(b, c) \cdot a\). -/
  repeat rw [Nat.mul_comm a]
/- The current goal \(\max(b \cdot a, c \cdot a) = \max(b, c) \cdot a\) is exactly proved by the theorem that states \(\max(a \cdot c, b \cdot c) = \max(a, b) \cdot c\). This theorem directly applies to our goal, thus completing the proof. -/
  exact Nat.mul_max_mul_right ..","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32440,Nat.max_le_of_le_of_le,theorem Nat.max_le_of_le_of_le {a b c : Nat} : a ≤ c → b ≤ c → max a b ≤ c := by sorry,"Maximum of Two Numbers Less Than or Equal to a Third Number : For any natural numbers \(a\), \(b\), and \(c\), if \(a \leq c\) and \(b \leq c\), then \(\max(a, b) \leq c\).","theorem Nat.max_le_of_le_of_le {a b c : Nat} : a ≤ c → b ≤ c → max a b ≤ c := by
  intros; cases Nat.le_total a b with
  | inl h => rw [Nat.max_eq_right h]; assumption
  | inr h => rw [Nat.max_eq_left h]; assumption","Let \(a\), \(b\), and \(c\) be natural numbers. Assume \(a \leq c\) and \(b \leq c\). We need to show that \(\max(a, b) \leq c\).

By the total order property of natural numbers, either \(a \leq b\) or \(b \leq a\). We will consider these two cases separately.

1. **Case 1: \(a \leq b\)**

By the property of the maximum function, \(\max(a, b) = b\) when \(a \leq b\). Therefore, the goal reduces to showing \(b \leq c\). Since \(b \leq c\) is already given as an assumption, this case is proved.

2. **Case 2: \(b \leq a\)**

By the property of the maximum function, \(\max(a, b) = a\) when \(b \leq a\). Therefore, the goal reduces to showing \(a \leq c\). Since \(a \leq c\) is already given as an assumption, this case is also proved.

Since both cases are proved, we conclude that \(\max(a, b) \leq c\). This completes the proof. \(\blacksquare\)","theorem Nat.max_le_of_le_of_le {a b c : Nat} : a ≤ c → b ≤ c → max a b ≤ c := by
/- Let \(a\), \(b\), and \(c\) be natural numbers. Assume \(a \leq c\) and \(b \leq c\). We need to show that \(\max(a, b) \leq c\). By the total order property of natural numbers, either \(a \leq b\) or \(b \leq a\). We will consider these two cases separately. -/
  intros; cases Nat.le_total a b with
/- First, consider the case where \(a \leq b\). By the property of the maximum function, \(\max(a, b) = b\) when \(a \leq b\). Therefore, the goal reduces to showing \(b \leq c\). Since \(b \leq c\) is already given as an assumption, this case is proved. -/
  | inl h => rw [Nat.max_eq_right h]; assumption
/- Next, consider the case where \(b \leq a\). By the property of the maximum function, \(\max(a, b) = a\) when \(b \leq a\). Therefore, the goal reduces to showing \(a \leq c\). Since \(a \leq c\) is already given as an assumption, this case is also proved. -/
  | inr h => rw [Nat.max_eq_left h]; assumption","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32441,Nat.mul_min_mul_left,theorem Nat.mul_min_mul_left (a b c : Nat) : min (a * b) (a * c) = a * min b c := by sorry,"Multiplication Distributes Over Minimum on the Left in Natural Numbers : For any natural numbers \(a\), \(b\), and \(c\), the minimum of \(a \cdot b\) and \(a \cdot c\) is equal to \(a\) times the minimum of \(b\) and \(c\), i.e., \(\min(a \cdot b, a \cdot c) = a \cdot \min(b, c)\).","theorem Nat.mul_min_mul_left (a b c : Nat) : min (a * b) (a * c) = a * min b c := by
  repeat rw [Nat.mul_comm a]
  exact Nat.mul_min_mul_right ..","We start with the goal of proving \(\min(a \cdot b, a \cdot c) = a \cdot \min(b, c)\). Using the commutativity of multiplication in natural numbers, which states that \(a \cdot b = b \cdot a\), we can rewrite the goal as \(\min(b \cdot a, c \cdot a) = \min(b, c) \cdot a\). This transformation is valid because the order of multiplication does not affect the result.

Next, we use the theorem that states \(\min(a \cdot c, b \cdot c) = \min(a, b) \cdot c\). This theorem directly applies to our transformed goal, \(\min(b \cdot a, c \cdot a) = \min(b, c) \cdot a\), thus proving the original statement. Therefore, we have shown that \(\min(a \cdot b, a \cdot c) = a \cdot \min(b, c)\).

This completes the proof. \(\blacksquare\)","theorem Nat.mul_min_mul_left (a b c : Nat) : min (a * b) (a * c) = a * min b c := by
/- Since the commutativity of multiplication in natural numbers states that \(a \cdot b = b \cdot a\), we can repeatedly replace \(a \cdot b\) with \(b \cdot a\) and \(a \cdot c\) with \(c \cdot a\) in the goal. This transforms the goal from \(\min(a \cdot b, a \cdot c) = a \cdot \min(b, c)\) to \(\min(b \cdot a, c \cdot a) = \min(b, c) \cdot a\). -/
  repeat rw [Nat.mul_comm a]
/- The current goal \(\min(b \cdot a, c \cdot a) = \min(b, c) \cdot a\) is exactly proved by the theorem that states \(\min(a \cdot c, b \cdot c) = \min(a, b) \cdot c\). This theorem directly applies to our goal, thus completing the proof. -/
  exact Nat.mul_min_mul_right ..","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32442,Nat.mul_mul_mul_comm,theorem Nat.mul_mul_mul_comm (a b c d : Nat) : (a * b) * (c * d) = (a * c) * (b * d) := by sorry,"Commutativity of Multiplication in Natural Numbers: \(a \times b \times (c \times d) = a \times c \times (b \times d)\) : For any natural numbers \(a\), \(b\), \(c\), and \(d\), the product \(a \times b \times (c \times d)\) is equal to \(a \times c \times (b \times d)\).","theorem Nat.mul_mul_mul_comm (a b c d : Nat) : (a * b) * (c * d) = (a * c) * (b * d) := by
  rw [Nat.mul_assoc, Nat.mul_assoc, Nat.mul_left_comm b]","We start with the expression \(a \times b \times (c \times d)\). Using the associativity of multiplication, we can rewrite this as:
\[
a \times (b \times (c \times d))
\]
Next, we use the associativity of multiplication again to rewrite \(b \times (c \times d)\) as:
\[
(b \times c) \times d
\]
Thus, the expression becomes:
\[
a \times ((b \times c) \times d)
\]
Using the left commutativity of multiplication, we can rewrite \(a \times ((b \times c) \times d)\) as:
\[
(b \times c) \times (a \times d)
\]
Finally, we use the associativity of multiplication to rewrite \((b \times c) \times (a \times d)\) as:
\[
a \times c \times (b \times d)
\]
Therefore, we have shown that:
\[
a \times b \times (c \times d) = a \times c \times (b \times d)
\]
This completes the proof. \(\blacksquare\)","theorem Nat.mul_mul_mul_comm (a b c d : Nat) : (a * b) * (c * d) = (a * c) * (b * d) := by
/- First, we use the associativity of multiplication to rewrite the left-hand side of the equation \(a \times b \times (c \times d)\) as \(a \times (b \times (c \times d))\). Then, we use the associativity of multiplication again to rewrite \(b \times (c \times d)\) as \((b \times c) \times d\). Finally, we use the left commutativity of multiplication to rewrite \(a \times ((b \times c) \times d)\) as \((b \times c) \times (a \times d)\). This simplifies the left-hand side to \(a \times (c \times (b \times d))\), which is equal to the right-hand side \(a \times c \times (b \times d)\). -/
  rw [Nat.mul_assoc, Nat.mul_assoc, Nat.mul_left_comm b]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32443,Nat.succ_mul_succ,theorem Nat.succ_mul_succ (a b) : succ a * succ b = a * b + a + b + 1 := by sorry,"Successor Multiplication Identity: \((a + 1) \cdot (b + 1) = a \cdot b + a + b + 1\) : For any natural numbers \( a \) and \( b \), the product of their successors is equal to the sum of their product, \( a \), \( b \), and 1, i.e., \((a + 1) \cdot (b + 1) = a \cdot b + a + b + 1\).","theorem Nat.succ_mul_succ (a b) : succ a * succ b = a * b + a + b + 1 := by
  rw [succ_mul, mul_succ]; rfl","To prove the identity \((a + 1) \cdot (b + 1) = a \cdot b + a + b + 1\), we start by using the properties of the successor function and multiplication. Specifically, we use the following properties:
1. \((a + 1) \cdot b = a \cdot b + b\)
2. \(a \cdot (b + 1) = a \cdot b + a\)

Applying these properties, we can rewrite the left-hand side of the equation:
\[
(a + 1) \cdot (b + 1) = (a + 1) \cdot b + (a + 1)
\]
Using the first property, we get:
\[
(a + 1) \cdot b = a \cdot b + b
\]
Substituting this back, we have:
\[
(a + 1) \cdot (b + 1) = (a \cdot b + b) + (a + 1)
\]
Simplifying the right-hand side, we get:
\[
(a \cdot b + b) + (a + 1) = a \cdot b + a + b + 1
\]
Thus, we have shown that:
\[
(a + 1) \cdot (b + 1) = a \cdot b + a + b + 1
\]
This completes the proof.","theorem Nat.succ_mul_succ (a b) : succ a * succ b = a * b + a + b + 1 := by
/- We use the properties of the successor function and multiplication to rewrite the goal. Specifically, we use the fact that \((a + 1) \cdot b = a \cdot b + b\) and \(a \cdot (b + 1) = a \cdot b + a\). After applying these properties, the goal simplifies to \(a \cdot b + a + b + 1\), which is exactly what we need to show. Therefore, the goal is trivially true by reflexivity. -/
  rw [succ_mul, mul_succ]; rfl","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32445,Nat.add_one_mul_add_one,theorem Nat.add_one_mul_add_one (a b : Nat) : (a + 1) * (b + 1) = a * b + a + b + 1 := by sorry,"Product of Successors Equals Sum of Products and Successors in Natural Numbers : For any natural numbers \(a\) and \(b\), the product of \(a + 1\) and \(b + 1\) is equal to \(a \cdot b + a + b + 1\), i.e., \((a + 1) \cdot (b + 1) = a \cdot b + a + b + 1\).","theorem Nat.add_one_mul_add_one (a b : Nat) : (a + 1) * (b + 1) = a * b + a + b + 1 := by
  rw [add_one_mul, mul_add_one]; rfl","To prove the theorem, we start with the left-hand side of the equation \((a + 1) \cdot (b + 1)\). Using the distributive properties of addition and multiplication, we can expand this expression as follows:
\[
(a + 1) \cdot (b + 1) = (a + 1) \cdot b + (a + 1) \cdot 1
\]
Next, we apply the distributive property again to each term:
\[
(a + 1) \cdot b = a \cdot b + 1 \cdot b = a \cdot b + b
\]
\[
(a + 1) \cdot 1 = a \cdot 1 + 1 \cdot 1 = a + 1
\]
Combining these results, we get:
\[
(a + 1) \cdot (b + 1) = (a \cdot b + b) + (a + 1) = a \cdot b + a + b + 1
\]
Thus, the left-hand side of the equation is equal to the right-hand side, and we have:
\[
(a + 1) \cdot (b + 1) = a \cdot b + a + b + 1
\]
This completes the proof.","theorem Nat.add_one_mul_add_one (a b : Nat) : (a + 1) * (b + 1) = a * b + a + b + 1 := by
/- We use the distributive properties of addition and multiplication to expand the left-hand side of the equation \((a + 1) \cdot (b + 1)\). Specifically, we use the fact that \((a + 1) \cdot (b + 1) = (a + 1) \cdot b + (a + 1) \cdot 1\) and \((a + 1) \cdot b = a \cdot b + 1 \cdot b\). After simplifying, we get \((a + 1) \cdot (b + 1) = a \cdot b + a + b + 1\). This matches the right-hand side of the equation, thus proving the equality. -/
  rw [add_one_mul, mul_add_one]; rfl","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32446,Nat.mul_ne_zero_iff,theorem Nat.mul_ne_zero_iff : n * m ≠ 0 ↔ n ≠ 0 ∧ m ≠ 0 := by sorry,"Product of Natural Numbers is Nonzero if and only if Both Factors are Nonzero: \( n \times m \neq 0 \leftrightarrow n \neq 0 \land m \neq 0 \) : For any natural numbers \( n \) and \( m \), the product \( n \times m \) is not equal to zero if and only if both \( n \) and \( m \) are not equal to zero, i.e., \( n \times m \neq 0 \leftrightarrow n \neq 0 \land m \neq 0 \).","theorem Nat.mul_ne_zero_iff : n * m ≠ 0 ↔ n ≠ 0 ∧ m ≠ 0 := by
  rw [ne_eq, mul_eq_zero, not_or]","To prove the theorem, we start with the goal \( n \times m \neq 0 \leftrightarrow n \neq 0 \land m \neq 0 \).

1. **Step 1:**
We use the equivalence that \( n \neq 0 \) is the same as \( \neg (n = 0) \). This transforms the goal into:
\[
\neg (n \times m = 0) \leftrightarrow \neg (n = 0) \land \neg (m = 0)
\]

2. **Step 2:**
Next, we use the fact that \( n \times m = 0 \) if and only if \( n = 0 \) or \( m = 0 \). This transforms the goal into:
\[
\neg (n = 0 \lor m = 0) \leftrightarrow \neg (n = 0) \land \neg (m = 0)
\]

3. **Step 3:**
Finally, we use the equivalence that the negation of a disjunction is the conjunction of the negations. This transforms the goal into:
\[
\neg (n = 0) \land \neg (m = 0) \leftrightarrow \neg (n = 0) \land \neg (m = 0)
\]
This is trivially true by the properties of logical equivalences.

Thus, we have shown that \( n \times m \neq 0 \leftrightarrow n \neq 0 \land m \neq 0 \). This completes the proof. \(\blacksquare\)","theorem Nat.mul_ne_zero_iff : n * m ≠ 0 ↔ n ≠ 0 ∧ m ≠ 0 := by
  rw [ne_eq, mul_eq_zero, not_or]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32447,Nat.pos_of_mul_pos_left,theorem Nat.pos_of_mul_pos_left {a b : Nat} (h : 0 < a * b) : 0 < b := by sorry,"Left Factor Positivity from Product Positivity in Natural Numbers : For any natural numbers \( a \) and \( b \), if the product \( a \times b \) is strictly greater than zero, then \( b \) is strictly greater than zero.","theorem Nat.pos_of_mul_pos_left {a b : Nat} (h : 0 < a * b) : 0 < b := by
  apply Decidable.by_contra
  intros
  simp_all","To prove that \( 0 < b \), we assume the negation, i.e., \( \neg (0 < b) \), and show that this leads to a contradiction. Let \( a \) and \( b \) be natural numbers, and assume \( 0 < a \times b \). Suppose, for the sake of contradiction, that \( \neg (0 < b) \). This means \( b \leq 0 \). Since \( b \) is a natural number, the only possibility is \( b = 0 \).

Now, consider the product \( a \times b \). Since \( b = 0 \), we have \( a \times b = a \times 0 = 0 \). This contradicts the assumption that \( 0 < a \times b \). Therefore, our assumption \( \neg (0 < b) \) must be false, and hence \( 0 < b \).

This completes the proof.","theorem Nat.pos_of_mul_pos_left {a b : Nat} (h : 0 < a * b) : 0 < b := by
/- To prove that \( 0 < b \), we assume the negation, i.e., \( \neg (0 < b) \), and show that this leads to a contradiction. Therefore, it suffices to show that \( \neg (0 < b) \) implies \( \text{False} \). -/
  apply Decidable.by_contra
/- Let \( a \) and \( b \) be natural numbers, and assume \( 0 < a \times b \). Suppose, for the sake of contradiction, that \( \neg (0 < b) \). We need to show that this assumption leads to a contradiction, i.e., \( \text{False} \). -/
  intros
/- Using the properties of natural numbers and the assumption \( \neg (0 < b) \), we can simplify the expression \( 0 < a \times b \) to a contradiction. Specifically, since \( b \) is not greater than zero, \( b \) must be zero. Therefore, \( a \times b = a \times 0 = 0 \), which contradicts the assumption \( 0 < a \times b \). Hence, we have derived \( \text{False} \). -/
  simp_all","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32448,Nat.mul_mod_mul_right,theorem Nat.mul_mod_mul_right (z x y : Nat) : (x * z) % (y * z) = (x % y) * z := by sorry,"Multiplication and Modulo Identity: \( (x \cdot z) \mod (y \cdot z) = (x \mod y) \cdot z \) : For any natural numbers \( z \), \( x \), and \( y \), the remainder of \( x \cdot z \) when divided by \( y \cdot z \) is equal to the product of the remainder of \( x \) when divided by \( y \) and \( z \). In other words, \( x \cdot z \mod (y \cdot z) = (x \mod y) \cdot z \).","theorem Nat.mul_mod_mul_right (z x y : Nat) : (x * z) % (y * z) = (x % y) * z := by
  rw [Nat.mul_comm x z, Nat.mul_comm y z, Nat.mul_comm (x % y) z]; apply mul_mod_mul_left","To prove the theorem, we start with the goal of showing that \( x \cdot z \mod (y \cdot z) = (x \mod y) \cdot z \).

1. **Rewriting the Goal:**
We use the commutativity of multiplication to rewrite the goal. Specifically, we rewrite \( x \cdot z \) as \( z \cdot x \), \( y \cdot z \) as \( z \cdot y \), and \( (x \mod y) \cdot z \) as \( z \cdot (x \mod y) \). This transforms the goal into showing that:
\[
z \cdot x \mod (z \cdot y) = z \cdot (x \mod y)
\]

2. **Applying the Modulo Theorem:**
We apply the theorem that states for any natural numbers \( a \), \( b \), and \( c \), the following holds:
\[
a \cdot b \mod (a \cdot c) = a \cdot (b \mod c)
\]
In our case, we set \( a = z \), \( b = x \), and \( c = y \). This theorem directly gives us:
\[
z \cdot x \mod (z \cdot y) = z \cdot (x \mod y)
\]

Thus, we have shown that \( x \cdot z \mod (y \cdot z) = (x \mod y) \cdot z \). This completes the proof.","theorem Nat.mul_mod_mul_right (z x y : Nat) : (x * z) % (y * z) = (x % y) * z := by
/- First, we use the commutativity of multiplication to rewrite the goal. Specifically, we rewrite \( x \cdot z \) as \( z \cdot x \), \( y \cdot z \) as \( z \cdot y \), and \( (x \mod y) \cdot z \) as \( z \cdot (x \mod y) \). This transforms the goal into showing that \( z \cdot x \mod (z \cdot y) = z \cdot (x \mod y) \). Then, we apply the theorem that states \( a \cdot b \mod (a \cdot c) = a \cdot (b \mod c) \) to conclude that \( z \cdot x \mod (z \cdot y) = z \cdot (x \mod y) \). -/
  rw [Nat.mul_comm x z, Nat.mul_comm y z, Nat.mul_comm (x % y) z]; apply mul_mod_mul_left","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32449,Nat.pos_of_mul_pos_right,theorem Nat.pos_of_mul_pos_right {a b : Nat} (h : 0 < a * b) : 0 < a := by sorry,"Right Factor Positivity from Product Positivity in Natural Numbers : For any natural numbers \( a \) and \( b \), if the product \( a \times b \) is strictly greater than zero, then \( a \) is strictly greater than zero.","theorem Nat.pos_of_mul_pos_right {a b : Nat} (h : 0 < a * b) : 0 < a := by
  apply Decidable.by_contra
  intros
  simp_all","To prove that \( 0 < a \) given \( 0 < a \times b \), we proceed by contradiction. Assume the negation, i.e., \( \neg (0 < a) \). This means \( a \leq 0 \). Since \( a \) is a natural number, the only possibility is \( a = 0 \).

Now, consider the product \( a \times b \). Since \( a = 0 \), we have \( a \times b = 0 \). This contradicts the given assumption that \( 0 < a \times b \). Therefore, our assumption \( \neg (0 < a) \) must be false, and hence \( 0 < a \).

This completes the proof.","theorem Nat.pos_of_mul_pos_right {a b : Nat} (h : 0 < a * b) : 0 < a := by
/- To prove that \( 0 < a \), we assume the negation, i.e., \( \neg (0 < a) \), and show that this leads to a contradiction. Therefore, it suffices to show that \( \neg (0 < a) \) implies \( \text{False} \). -/
  apply Decidable.by_contra
/- Let \( a \) and \( b \) be natural numbers, and assume \( 0 < a \times b \). Let \( \neg (0 < a) \) be our new hypothesis. It suffices to show that this assumption leads to a contradiction, i.e., \( \text{False} \). -/
  intros
/- Using the properties of natural numbers and the assumption \( \neg (0 < a) \), we can simplify the expression \( 0 < a \times b \) to a contradiction. Specifically, since \( a \) is not greater than zero, \( a \) must be zero. Therefore, \( a \times b = 0 \), which contradicts the assumption \( 0 < a \times b \). Hence, we have derived \( \text{False} \). -/
  simp_all","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32450,Nat.zero_pow,theorem Nat.zero_pow {n : Nat} (H : 0 < n) : 0 ^ n = 0 := by sorry,"Zero Raised to Any Positive Natural Number Equals Zero: \( 0^n = 0 \) : For any natural number \( n \) such that \( n > 0 \), the expression \( 0^n \) is equal to 0, i.e., \( 0^n = 0 \).","theorem Nat.zero_pow {n : Nat} (H : 0 < n) : 0 ^ n = 0 := by
  match n with
  | 0 => contradiction
  | n+1 => rw [Nat.pow_succ, Nat.mul_zero]","We will prove this by considering two cases: \( n = 0 \) and \( n = k + 1 \) for some natural number \( k \).

1. **Base Case: \( n = 0 \)**
- The assumption is \( 0 < n \). If \( n = 0 \), then \( 0 < 0 \), which is a contradiction. Therefore, this case is impossible.

2. **Inductive Step: \( n = k + 1 \)**
- Assume \( n = k + 1 \) for some natural number \( k \). By the definition of exponentiation, \( 0^{k+1} = 0^k \cdot 0 \).
- Since \( 0 \cdot 0 = 0 \), we have \( 0^{k+1} = 0 \).

By considering both cases, we conclude that for any natural number \( n \) such that \( n > 0 \), \( 0^n = 0 \). This completes the proof.","theorem Nat.zero_pow {n : Nat} (H : 0 < n) : 0 ^ n = 0 := by
  match n with
/- First, consider the base case where \( n = 0 \). Since the assumption is \( 0 < n \), this case leads to a contradiction because \( 0 \) is not greater than \( 0 \). Therefore, this case is impossible. -/
  | 0 => contradiction
/- Next, consider the case where \( n = k + 1 \) for some natural number \( k \). By the definition of exponentiation, \( 0^{k+1} \) is equal to \( 0^k \cdot 0 \). Since \( 0 \cdot 0 = 0 \), we have \( 0^{k+1} = 0 \). This completes the inductive step. -/
  | n+1 => rw [Nat.pow_succ, Nat.mul_zero]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32453,Nat.pow_add_one',theorem Nat.pow_add_one' {m n : Nat} : m ^ (n + 1) = m * m ^ n := by sorry,"Power of Successor: \( m^{n+1} = m \cdot m^n \) : For any natural numbers \( m \) and \( n \), the following identity holds:
\[
m^{n+1} = m \cdot m^n
\]
This theorem states that the power of a natural number \( m \) raised to \( n + 1 \) is equal to \( m \) times the power of \( m \) raised to \( n \).","theorem Nat.pow_add_one' {m n : Nat} : m ^ (n + 1) = m * m ^ n := by
  rw [Nat.pow_add_one, Nat.mul_comm]","To prove the identity \( m^{n+1} = m \cdot m^n \), we start by using the theorem that states \( m^{n+1} = m^n \cdot m \). This theorem tells us that the power of a natural number \( m \) raised to \( n + 1 \) is equal to \( m \) times the power of \( m \) raised to \( n \). Therefore, we can rewrite the goal as:
\[
m^{n+1} = m^n \cdot m
\]
Next, we use the commutativity of multiplication, which states that for any natural numbers \( a \) and \( b \), \( a \cdot b = b \cdot a \). Applying this property, we can rewrite \( m^n \cdot m \) as \( m \cdot m^n \). Thus, the goal becomes:
\[
m^{n+1} = m \cdot m^n
\]
Since the left-hand side and the right-hand side of the equation are now identical, the goal is trivially true by the properties of equality. Therefore, we have shown that:
\[
m^{n+1} = m \cdot m^n
\]
This completes the proof.","theorem Nat.pow_add_one' {m n : Nat} : m ^ (n + 1) = m * m ^ n := by
/- First, we use the theorem that states \( m^{n+1} = m^n \cdot m \) to rewrite the goal. This theorem tells us that the power of a natural number \( m \) raised to \( n + 1 \) is equal to \( m \) times the power of \( m \) raised to \( n \). After this, we use the commutativity of multiplication to rewrite \( m^n \cdot m \) as \( m \cdot m^n \). Thus, the goal \( m^{n+1} = m \cdot m^n \) is equivalent to \( m \cdot m^n = m \cdot m^n \), which is trivially true by the properties of equality. -/
  rw [Nat.pow_add_one, Nat.mul_comm]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32454,Nat.add_mod,theorem Nat.add_mod (a b n : Nat) : (a + b) % n = ((a % n) + (b % n)) % n := by sorry,"Modulo Distributes Over Addition in Natural Numbers: \((a + b) \mod n = (a \mod n + b \mod n) \mod n\) : For any natural numbers \(a\), \(b\), and \(n\), the following identity holds:
\[
(a + b) \mod n = (a \mod n + b \mod n) \mod n
\]
This theorem states that the modulo operation distributes over addition in the natural numbers.","theorem Nat.add_mod (a b n : Nat) : (a + b) % n = ((a % n) + (b % n)) % n := by
  rw [add_mod_mod, mod_add_mod]","To prove the identity \((a + b) \mod n = (a \mod n + b \mod n) \mod n\), we use the following steps:

1. **Rewrite the left-hand side:**
Using the identity \((m + n \% k) \% k = (m + n) \% k\), we rewrite \((a + b) \% n\) as \((a \% n + b) \% n\).

2. **Rewrite the right-hand side:**
Using the identity \((m \% n + k) \% n = (m + k) \% n\), we rewrite \((a \% n + b \% n) \% n\) as \((a + b) \% n\).

3. **Combine the results:**
Therefore, the goal \((a + b) \% n = (a \% n + b \% n) \% n\) is equivalent to \((a + b) \% n = (a + b) \% n\), which is trivially true by the properties of equality.

This completes the proof.","theorem Nat.add_mod (a b n : Nat) : (a + b) % n = ((a % n) + (b % n)) % n := by
/- We use the identity \((m + n \% k) \% k = (m + n) \% k\) to rewrite the left-hand side of the goal \((a + b) \% n\) as \((a \% n + b) \% n\). Then, we use the identity \((m \% n + k) \% n = (m + k) \% n\) to rewrite the right-hand side of the goal \((a \% n + b \% n) \% n\) as \((a + b) \% n\). Therefore, the goal \((a + b) \% n = (a \% n + b \% n) \% n\) is equivalent to \((a + b) \% n = (a + b) \% n\), which is trivially true by the properties of equality. -/
  rw [add_mod_mod, mod_add_mod]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32455,Nat.mul_left_cancel,theorem Nat.mul_left_cancel {n m k : Nat} (np : 0 < n) (h : n * m = n * k) : m = k := by sorry,"Left Multiplication Cancellation in Natural Numbers: \( n \cdot m = n \cdot k \to m = k \) for \( n \neq 0 \) : For any natural numbers \( n \), \( m \), and \( k \), if \( n \neq 0 \) and \( n \cdot m = n \cdot k \), then \( m = k \).","theorem Nat.mul_left_cancel {n m k : Nat} (np : 0 < n) (h : n * m = n * k) : m = k := by
  match Nat.lt_trichotomy m k with
  | Or.inl p =>
    have r : n * m < n * k := Nat.mul_lt_mul_of_pos_left p np
    simp [h] at r
  | Or.inr (Or.inl p) => exact p
  | Or.inr (Or.inr p) =>
    have r : n * k < n * m := Nat.mul_lt_mul_of_pos_left p np
    simp [h] at r","We start by assuming \( n \neq 0 \) and \( n \cdot m = n \cdot k \). We need to show that \( m = k \).

1. **Case 1: \( m < k \)**
- Assume \( m < k \).
- Since \( n > 0 \), by the property that left multiplication by a positive element preserves strict inequality, we have \( n \cdot m < n \cdot k \).
- However, we also have \( n \cdot m = n \cdot k \) by assumption.
- This leads to a contradiction, as \( n \cdot m < n \cdot m \) is false.
- Therefore, \( m < k \) cannot hold.

2. **Case 2: \( k < m \)**
- Assume \( k < m \).
- Since \( n > 0 \), by the property that left multiplication by a positive element preserves strict inequality, we have \( n \cdot k < n \cdot m \).
- However, we also have \( n \cdot m = n \cdot k \) by assumption.
- This leads to a contradiction, as \( n \cdot k < n \cdot k \) is false.
- Therefore, \( k < m \) cannot hold.

Since both \( m < k \) and \( k < m \) lead to contradictions, the only possibility left is \( m = k \).

Thus, we have shown that if \( n \neq 0 \) and \( n \cdot m = n \cdot k \), then \( m = k \). This completes the proof. \(\blacksquare\)","theorem Nat.mul_left_cancel {n m k : Nat} (np : 0 < n) (h : n * m = n * k) : m = k := by
  match Nat.lt_trichotomy m k with
/- Assume \( m < k \). We will derive a contradiction. -/
  | Or.inl p =>
/- Since \( m < k \) and \( n > 0 \), we have \( n \cdot m < n \cdot k \) by the property that left multiplication by a positive element preserves strict inequality. -/
    have r : n * m < n * k := Nat.mul_lt_mul_of_pos_left p np
/- Using the equality \( n \cdot m = n \cdot k \) (denoted by \( h \)), we simplify the hypothesis \( r \) to get \( n \cdot k < n \cdot m \). -/
    simp [h] at r
/- Assume \( k < m \). We will derive a contradiction. -/
  | Or.inr (Or.inl p) => exact p
/- Assume \( k < m \). We will derive a contradiction. -/
  | Or.inr (Or.inr p) =>
/- Since \( k < m \) and \( n > 0 \), we have \( n \cdot k < n \cdot m \) by the property that left multiplication by a positive element preserves strict inequality. -/
    have r : n * k < n * m := Nat.mul_lt_mul_of_pos_left p np
/- Using the equality \( n \cdot m = n \cdot k \) (denoted by \( h \)), we simplify the hypothesis \( r \) to get a contradiction, as \( n \cdot m < n \cdot m \) is false. -/
/- Using the equality \( n \cdot m = n \cdot k \) (denoted by \( h \)), we simplify the hypothesis \( r \) to get a contradiction, as \( n \cdot k < n \cdot k \) is false. -/
    simp [h] at r","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32457,Nat.mul_min_mul_right,theorem Nat.mul_min_mul_right (a b c : Nat) : min (a * c) (b * c) = min a b * c := by sorry,"Minimum of Products with a Common Factor in Natural Numbers: \(\min(a \cdot c, b \cdot c) = \min(a, b) \cdot c\) : For any natural numbers \(a\), \(b\), and \(c\), the minimum of the products \(a \cdot c\) and \(b \cdot c\) is equal to the product of the minimum of \(a\) and \(b\) with \(c\), i.e., \(\min(a \cdot c, b \cdot c) = \min(a, b) \cdot c\).","theorem Nat.mul_min_mul_right (a b c : Nat) : min (a * c) (b * c) = min a b * c := by
  induction a generalizing b with
  | zero => simp
  | succ i ind =>
    cases b <;> simp [succ_eq_add_one, Nat.succ_mul, Nat.add_min_add_right, ind]","We will prove the theorem by induction on \( b \).

**Base Case: \( b = 0 \)**
We need to show that \(\min(a \cdot c, 0 \cdot c) = \min(a, 0) \cdot c\).

Using the property that the minimum of any natural number and zero is zero, we have:
\[
\min(a \cdot c, 0 \cdot c) = \min(a \cdot c, 0) = 0
\]
and
\[
\min(a, 0) \cdot c = 0 \cdot c = 0
\]
Thus, the base case holds.

**Inductive Step: \( b = n + 1 \)**
Assume the statement holds for \( b = n \), i.e., \(\min(a \cdot c, n \cdot c) = \min(a, n) \cdot c\). We need to show that \(\min(a \cdot c, (n + 1) \cdot c) = \min(a, n + 1) \cdot c\).

Using the property of successor multiplication, we have:
\[
(n + 1) \cdot c = n \cdot c + c
\]
Thus, the goal becomes:
\[
\min(a \cdot c, n \cdot c + c) = \min(a, n + 1) \cdot c
\]

Using the distributive property of minimum over addition, we have:
\[
\min(a \cdot c, n \cdot c + c) = \min(a \cdot c, n \cdot c) + c
\]

By the induction hypothesis, we know:
\[
\min(a \cdot c, n \cdot c) = \min(a, n) \cdot c
\]

Substituting this into the equation, we get:
\[
\min(a \cdot c, n \cdot c + c) = \min(a, n) \cdot c + c
\]

Using the property of minimum, we have:
\[
\min(a, n + 1) = \min(a, n + 1)
\]

Thus:
\[
\min(a, n + 1) \cdot c = \min(a, n) \cdot c + c
\]

Therefore, the inductive step holds.

By induction, the theorem is true for all natural numbers \( b \). This completes the proof. \(\blacksquare\)","theorem Nat.mul_min_mul_right (a b c : Nat) : min (a * c) (b * c) = min a b * c := by
  induction a generalizing b with
/- In the case where \( b = 0 \), we simplify the goal using the property that the minimum of any natural number and zero is zero. This simplification shows that the goal holds trivially. -/
  | zero => simp
/- In the case where \( b = n + 1 \), we use the induction hypothesis that the statement holds for \( b = n \). We will then simplify the goal using the properties of successor, multiplication, and the distributive property of minimum over addition. -/
  | succ i ind =>
/- We will consider two cases for \( b \): \( b = 0 \) and \( b = n + 1 \) for some natural number \( n \). For each case, we will simplify the goal using the properties of successor, multiplication, and the distributive property of minimum over addition. -/
/- We will consider two cases for \( b \): \( b = 0 \) and \( b = n + 1 \) for some natural number \( n \). For each case, we will simplify the goal using the properties of successor, multiplication, and the distributive property of minimum over addition. -/
    cases b <;> simp [succ_eq_add_one, Nat.succ_mul, Nat.add_min_add_right, ind]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32459,Nat.one_shiftLeft,theorem Nat.one_shiftLeft (n : Nat) : 1 <<< n = 2 ^ n := by sorry,"Shift Left of One in Natural Numbers Equals Power of Two : For any natural number \( n \), shifting the number 1 to the left by \( n \) positions is equivalent to raising 2 to the power of \( n \), i.e., \( 1 \ll n = 2^n \).","theorem Nat.one_shiftLeft (n : Nat) : 1 <<< n = 2 ^ n := by
  rw [shiftLeft_eq, Nat.one_mul]","To prove that \( 1 \ll n = 2^n \) for any natural number \( n \), we start by using the theorem that the left shift of a natural number \( a \) by \( b \) positions is equivalent to multiplying \( a \) by \( 2^b \). Specifically, for \( a = 1 \) and \( b = n \), we have:
\[
1 \ll n = 1 \cdot 2^n
\]
Next, we use the property of the multiplicative identity, which states that \( 1 \cdot a = a \) for any natural number \( a \). Applying this property, we get:
\[
1 \cdot 2^n = 2^n
\]
Thus, our goal is to show that:
\[
2^n = 2^n
\]
This is trivially true by the reflexive property of equality. Therefore, we have shown that \( 1 \ll n = 2^n \) for any natural number \( n \). This completes the proof. \(\blacksquare\)","theorem Nat.one_shiftLeft (n : Nat) : 1 <<< n = 2 ^ n := by
  rw [shiftLeft_eq, Nat.one_mul]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32461,Nat.mul_self_sub_mul_self_eq,theorem Nat.mul_self_sub_mul_self_eq (a b : Nat) : a * a - b * b = (a + b) * (a - b) := by sorry,"Difference of Squares Identity in Natural Numbers : For any natural numbers \( a \) and \( b \), the difference between the squares of \( a \) and \( b \) is equal to the product of their sum and their difference, i.e., \( a^2 - b^2 = (a + b)(a - b) \).","theorem Nat.mul_self_sub_mul_self_eq (a b : Nat) : a * a - b * b = (a + b) * (a - b) := by
  rw [Nat.mul_sub_left_distrib, Nat.right_distrib, Nat.right_distrib, Nat.mul_comm b a,
    Nat.sub_add_eq, Nat.add_sub_cancel]","We start by using the left distributive property of multiplication over subtraction, the right distributive property of multiplication over addition, and the commutativity of multiplication to rewrite the goal. Specifically, we have:
\[
a \cdot a - b \cdot b = (a + b) \cdot (a - b)
\]
Using the left distributive property, we get:
\[
a \cdot a - b \cdot b = (a + b) \cdot a - (a + b) \cdot b
\]
Using the right distributive property twice, we get:
\[
a \cdot a - b \cdot b = a \cdot a + b \cdot a - (a \cdot b + b \cdot b)
\]
Using the commutativity of multiplication, we get:
\[
a \cdot a - b \cdot b = a \cdot a + a \cdot b - (a \cdot b + b \cdot b)
\]
Using the property of subtraction of sums, we get:
\[
a \cdot a - b \cdot b = a \cdot a + a \cdot b - a \cdot b - b \cdot b
\]
Finally, using the cancellation property of addition and subtraction, we get:
\[
a \cdot a - b \cdot b = a \cdot a - b \cdot b
\]
This completes the proof. \(\blacksquare\)","theorem Nat.mul_self_sub_mul_self_eq (a b : Nat) : a * a - b * b = (a + b) * (a - b) := by
/- We start by using the left distributive property of multiplication over subtraction, the right distributive property of multiplication over addition, and the commutativity of multiplication to rewrite the goal. Specifically, we have:
\[
a \cdot a - b \cdot b = (a + b) \cdot (a - b)
\]
Using the left distributive property, we get:
\[
a \cdot a - b \cdot b = (a + b) \cdot a - (a + b) \cdot b
\]
Using the right distributive property twice, we get:
\[
a \cdot a - b \cdot b = a \cdot a + b \cdot a - (a \cdot b + b \cdot b)
\]
Using the commutativity of multiplication, we get:
\[
a \cdot a - b \cdot b = a \cdot a + a \cdot b - (a \cdot b + b \cdot b)
\]
Using the property of subtraction of sums, we get:
\[
a \cdot a - b \cdot b = a \cdot a + a \cdot b - a \cdot b - b \cdot b
\]
Finally, using the cancellation property of addition and subtraction, we get:
\[
a \cdot a - b \cdot b = a \cdot a - b \cdot b
\]
This completes the proof. -/
  rw [Nat.mul_sub_left_distrib, Nat.right_distrib, Nat.right_distrib, Nat.mul_comm b a,
    Nat.sub_add_eq, Nat.add_sub_cancel]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32462,Nat.one_pow,theorem Nat.one_pow (n : Nat) : 1 ^ n = 1 := by sorry,"One Raised to Any Natural Number Equals One: \( 1^n = 1 \) : For any natural number \( n \), the expression \( 1^n \) is equal to 1, i.e., \( 1^n = 1 \).","theorem Nat.one_pow (n : Nat) : 1 ^ n = 1 := by
  induction n with
  | zero => rfl
  | succ _ ih => rw [Nat.pow_succ, Nat.mul_one, ih]","We will prove this by induction on \( n \).

1. **Base Case:**
- Consider \( n = 0 \). The goal is to show that \( 1^0 = 1 \). This is trivially true by the definition of exponentiation, as any number raised to the power of 0 is 1.

2. **Inductive Step:**
- Assume the inductive hypothesis that for some natural number \( k \), \( 1^k = 1 \). We need to show that \( 1^{k+1} = 1 \).
- By the definition of exponentiation, \( 1^{k+1} = 1^k \cdot 1 \).
- Using the inductive hypothesis \( 1^k = 1 \), we have \( 1^{k+1} = 1 \cdot 1 \).
- By the property of the multiplicative identity, \( 1 \cdot 1 = 1 \).
- Therefore, \( 1^{k+1} = 1 \).

By the principle of mathematical induction, the statement \( 1^n = 1 \) holds for all natural numbers \( n \). This completes the proof.","theorem Nat.one_pow (n : Nat) : 1 ^ n = 1 := by
  induction n with
/- First, consider the base case where \( n = 0 \). The goal is to show that \( 1^0 = 1 \). This is trivially true by the definition of exponentiation, as any number raised to the power of 0 is 1. -/
  | zero => rfl
/- Next, consider the inductive step where \( n = k + 1 \) for some natural number \( k \). Assume the inductive hypothesis that \( 1^k = 1 \). We need to show that \( 1^{k+1} = 1 \). By the definition of exponentiation, \( 1^{k+1} = 1^k \cdot 1 \). Using the inductive hypothesis \( 1^k = 1 \), we have \( 1^{k+1} = 1 \cdot 1 \). By the property of the multiplicative identity, \( 1 \cdot 1 = 1 \). Therefore, \( 1^{k+1} = 1 \). -/
  | succ _ ih => rw [Nat.pow_succ, Nat.mul_one, ih]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32463,Nat.pow_right_comm,theorem Nat.pow_right_comm (a m n : Nat) : (a ^ m) ^ n = (a ^ n) ^ m := by sorry,"Right-Commutativity of Exponentiation in Natural Numbers : For any natural numbers \( a \), \( m \), and \( n \), the power of a power is commutative with respect to the exponents, i.e., \((a^m)^n = (a^n)^m\).","theorem Nat.pow_right_comm (a m n : Nat) : (a ^ m) ^ n = (a ^ n) ^ m := by
  rw [← Nat.pow_mul, Nat.pow_mul']","To prove that \((a^m)^n = (a^n)^m\) for any natural numbers \( a \), \( m \), and \( n \), we start by using the properties of exponentiation in monoids. Specifically, we use the property that for any monoid \( M \) and any element \( a \in M \), and for any natural numbers \( m \) and \( n \), the following equalities hold:
1. \( a^{m \cdot n} = (a^m)^n \)
2. \( a^{m \cdot n} = (a^n)^m \)

Using the first property, we rewrite the left-hand side of the goal:
\[
(a^m)^n = a^{m \cdot n}
\]

Using the second property, we rewrite the right-hand side of the goal:
\[
(a^n)^m = a^{m \cdot n}
\]

Thus, the goal \((a^m)^n = (a^n)^m\) is equivalent to:
\[
a^{m \cdot n} = a^{m \cdot n}
\]

This is trivially true by the properties of equality. Therefore, we have shown that \((a^m)^n = (a^n)^m\), completing the proof. \(\blacksquare\)","theorem Nat.pow_right_comm (a m n : Nat) : (a ^ m) ^ n = (a ^ n) ^ m := by
/- First, we use the property of exponentiation in monoids that states \( a^{m \cdot n} = (a^m)^n \) to rewrite the left-hand side of the goal \((a^m)^n\) as \(a^{m \cdot n}\). Then, we use the property \( a^{m \cdot n} = (a^n)^m \) to rewrite the right-hand side of the goal \((a^n)^m\) as \(a^{m \cdot n}\). Therefore, the goal \((a^m)^n = (a^n)^m\) is equivalent to \(a^{m \cdot n} = a^{m \cdot n}\), which is trivially true by the properties of equality. -/
  rw [← Nat.pow_mul, Nat.pow_mul']","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32464,Nat.log2_zero,theorem Nat.log2_zero : Nat.log2 0 = 0 := by sorry,"Base 2 Logarithm of Zero is Zero: \(\log_2(0) = 0\) : The base 2 logarithm of the natural number 0 is 0, i.e., \(\log_2(0) = 0\).","theorem Nat.log2_zero : Nat.log2 0 = 0 := by
  simp [Nat.log2]","To prove that \(\log_2(0) = 0\), we use the definition of the base 2 logarithm function on natural numbers. The function \(\text{Nat.log2}\) is defined such that \(\text{Nat.log2}(0) = 0\). Therefore, the proposition \(\log_2(0) = 0\) is trivially true. This completes the proof. \(\blacksquare\)","theorem Nat.log2_zero : Nat.log2 0 = 0 := by
/- Using the definition of the base 2 logarithm function on natural numbers, we can simplify the proposition \(\log_2(0) = 0\) to a trivially true statement. The definition of \(\text{Nat.log2}\) states that \(\text{Nat.log2}(0) = 0\). Therefore, the proposition \(\log_2(0) = 0\) is true. -/
  simp [Nat.log2]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32466,Nat.pow_add',theorem Nat.pow_add' (a m n : Nat) : a ^ (m + n) = a ^ n * a ^ m := by sorry,"Power of Sum Equals Product of Powers in Natural Numbers : For any natural numbers \(a\), \(m\), and \(n\), the power of \(a\) raised to the sum of \(m\) and \(n\) is equal to the product of \(a\) raised to \(n\) and \(a\) raised to \(m\), i.e., \(a^{m + n} = a^n \cdot a^m\).","theorem Nat.pow_add' (a m n : Nat) : a ^ (m + n) = a ^ n * a ^ m := by
  rw [← Nat.pow_add, Nat.add_comm]","To prove that \(a^{m + n} = a^n \cdot a^m\) for any natural numbers \(a\), \(m\), and \(n\), we start by using the theorem that the power of a sum is equal to the product of the powers, but in the reverse direction. This theorem states that \(a^{m + n} = a^m \cdot a^n\). By applying this theorem, we rewrite the goal as \(a^{m + n} = a^{n + m}\).

Next, we use the commutativity of addition, which states that \(m + n = n + m\). This allows us to further simplify the goal to \(a^{n + m} = a^{n + m}\). Since the left-hand side and the right-hand side are identical, the goal is trivially true. Therefore, we have shown that \(a^{m + n} = a^n \cdot a^m\). This completes the proof. \(\blacksquare\)","theorem Nat.pow_add' (a m n : Nat) : a ^ (m + n) = a ^ n * a ^ m := by
/- First, we use the theorem that the power of a sum is equal to the product of the powers, i.e., \( a^{m + n} = a^m \cdot a^n \), but in the reverse direction, to rewrite the goal. This changes the goal from \( a^{m + n} = a^n \cdot a^m \) to \( a^{m + n} = a^{n + m} \). Next, we use the commutativity of addition, which states that \( m + n = n + m \), to further simplify the goal to \( a^{n + m} = a^{n + m} \). Since the left-hand side and the right-hand side are identical, the goal is trivially true. -/
  rw [← Nat.pow_add, Nat.add_comm]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32467,Nat.pow_mul',theorem Nat.pow_mul' (a m n : Nat) : a ^ (m * n) = (a ^ n) ^ m := by sorry,"Power of Product Equals Repeated Power in Natural Numbers : For any natural numbers \(a\), \(m\), and \(n\), the power of \(a\) raised to the product of \(m\) and \(n\) is equal to the power of \(a\) raised to \(n\) and then raised to \(m\). In other words, \(a^{m \cdot n} = (a^n)^m\).","theorem Nat.pow_mul' (a m n : Nat) : a ^ (m * n) = (a ^ n) ^ m := by
  rw [← Nat.pow_mul, Nat.mul_comm]","To prove the theorem, we start with the goal \( a^{m \cdot n} = (a^n)^m \).

1. **Step 1:**
We use the property of exponents in monoids, which states that for any natural numbers \(a\), \(m\), and \(n\), \( a^{m \cdot n} = (a^m)^n \). This allows us to rewrite the goal as:
\[
a^{m \cdot n} = a^{n \cdot m}
\]

2. **Step 2:**
Next, we use the commutativity of multiplication in natural numbers, which states that \( m \cdot n = n \cdot m \). This further simplifies the goal to:
\[
a^{n \cdot m} = a^{n \cdot m}
\]

3. **Step 3:**
The equation \( a^{n \cdot m} = a^{n \cdot m} \) is trivially true by the properties of equality.

Thus, we have shown that \( a^{m \cdot n} = (a^n)^m \). This completes the proof. \(\blacksquare\)","theorem Nat.pow_mul' (a m n : Nat) : a ^ (m * n) = (a ^ n) ^ m := by
/- First, we use the property of exponents in monoids, which states that \( a^{m \cdot n} = (a^m)^n \), to rewrite the goal. Then, we use the commutativity of multiplication in natural numbers, which states that \( m \cdot n = n \cdot m \), to further rewrite the goal. This transforms the goal \( a^{m \cdot n} = (a^n)^m \) into \( a^{n \cdot m} = a^{n \cdot m} \), which is trivially true by the properties of equality. -/
  rw [← Nat.pow_mul, Nat.mul_comm]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32468,Nat.dvd_of_pow_dvd,theorem Nat.dvd_of_pow_dvd {p k m : Nat} (hk : 1 ≤ k) (hpk : p ^ k ∣ m) : p ∣ m := by sorry,"Divisibility of Natural Number by a Power Implies Divisibility by the Base: \( p^k \mid m \to p \mid m \) for \( k \geq 1 \) : For any natural numbers \( p \), \( k \), and \( m \) such that \( k \geq 1 \) and \( p^k \mid m \), it holds that \( p \mid m \).","theorem Nat.dvd_of_pow_dvd {p k m : Nat} (hk : 1 ≤ k) (hpk : p ^ k ∣ m) : p ∣ m := by
  rw [← Nat.pow_one p]; exact pow_dvd_of_le_of_pow_dvd hk hpk","To prove that \( p \mid m \) given \( k \geq 1 \) and \( p^k \mid m \), we start by noting that \( p^1 = p \). Therefore, the statement \( p^1 \mid m \) is equivalent to \( p \mid m \). We then use the theorem that if \( k \geq 1 \) and \( p^k \mid m \), then \( p \mid m \). Since we have \( 1 \leq k \) and \( p^k \mid m \), this theorem directly implies that \( p \mid m \). This completes the proof.","theorem Nat.dvd_of_pow_dvd {p k m : Nat} (hk : 1 ≤ k) (hpk : p ^ k ∣ m) : p ∣ m := by
/- First, we use the fact that \( p^1 = p \) to rewrite the goal. This means we need to show that \( p \mid m \). We then apply the theorem that if \( k \geq 1 \) and \( p^k \mid m \), then \( p \mid m \). Since we have \( 1 \leq k \) and \( p^k \mid m \), the theorem directly gives us \( p \mid m \). -/
  rw [← Nat.pow_one p]; exact pow_dvd_of_le_of_pow_dvd hk hpk","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32469,Nat.mul_le_add_right,theorem Nat.mul_le_add_right (m k n : Nat) : k * m ≤ m + n ↔ (k-1) * m ≤ n := by sorry,"Multiplication Inequality Implies Subtraction Inequality in Natural Numbers : For any natural numbers \( m \), \( k \), and \( n \), the inequality \( k \cdot m \leq m + n \) holds if and only if the inequality \( (k - 1) \cdot m \leq n \) holds.","theorem Nat.mul_le_add_right (m k n : Nat) : k * m ≤ m + n ↔ (k-1) * m ≤ n := by
  match k with
  | 0 =>
    simp
  | succ k =>
    simp [succ_mul, Nat.add_comm _ m, Nat.add_le_add_iff_left]","We need to show that for any natural numbers \( m \), \( k \), and \( n \), the inequality \( k \cdot m \leq m + n \) holds if and only if the inequality \( (k - 1) \cdot m \leq n \) holds.

1. **Base Case: \( k = 0 \)**
- The goal is to show that \( 0 \cdot m \leq m + n \leftrightarrow (0 - 1) \cdot m \leq n \).
- Simplifying, we get \( 0 \leq m + n \leftrightarrow 0 \leq n \).
- Since \( 0 \leq m + n \) and \( 0 \leq n \) are always true for natural numbers, the base case is trivially true.

2. **Inductive Case: \( k = k' + 1 \)**
- The goal is to show that \((k' + 1) \cdot m \leq m + n \leftrightarrow (k' + 1 - 1) \cdot m \leq n\).
- Using the identity \((k' + 1) \cdot m = k' \cdot m + m\), the commutativity of addition \(a + b = b + a\), and the fact that adding the same number to both sides of an inequality preserves the inequality \(a + b \leq a + c \leftrightarrow b \leq c\), we simplify the goal to \(k' \cdot m + m \leq m + n \leftrightarrow k' \cdot m \leq n\).
- This simplifies to \(k' \cdot m \leq n\), which is exactly what we need to show.

By induction, the theorem holds for all natural numbers \( k \). Therefore, the inequality \( k \cdot m \leq m + n \) holds if and only if the inequality \( (k - 1) \cdot m \leq n \) holds. This completes the proof. \(\blacksquare\)","theorem Nat.mul_le_add_right (m k n : Nat) : k * m ≤ m + n ↔ (k-1) * m ≤ n := by
  match k with
/- We consider the base case where \(k = 0\). The goal is to show that \(0 \cdot m \leq m + n \leftrightarrow (0 - 1) \cdot m \leq n\). -/
  | 0 =>
/- Simplifying the base case, we note that \(0 \cdot m = 0\) and \(0 - 1 = 0\). Therefore, the goal reduces to \(0 \leq m + n \leftrightarrow 0 \leq n\). Since \(0 \leq m + n\) is always true for natural numbers, and \(0 \leq n\) is also always true, the base case is trivially true. -/
    simp
/- We consider the inductive case where \(k\) is the successor of some natural number, i.e., \(k = k' + 1\). The goal is to show that \((k' + 1) \cdot m \leq m + n \leftrightarrow (k' + 1 - 1) \cdot m \leq n\). -/
  | succ k =>
/- Using the properties of natural numbers, we simplify the goal. Specifically, we use the identity \((k + 1) \cdot m = k \cdot m + m\) (successor multiplication), the commutativity of addition \(a + b = b + a\), and the fact that adding the same number to both sides of an inequality preserves the inequality \(a + b \leq a + c \leftrightarrow b \leq c\). After simplification, the goal becomes \(k \cdot m + m \leq m + n \leftrightarrow k \cdot m \leq n\). -/
/- Using the same properties as in the first step, we simplify the inductive case. Specifically, we use the identity \((k' + 1) \cdot m = k' \cdot m + m\), the commutativity of addition \(a + b = b + a\), and the fact that adding the same number to both sides of an inequality preserves the inequality \(a + b \leq a + c \leftrightarrow b \leq c\). After simplification, the goal becomes \(k' \cdot m + m \leq m + n \leftrightarrow k' \cdot m \leq n\). -/
    simp [succ_mul, Nat.add_comm _ m, Nat.add_le_add_iff_left]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32470,Nat.pow_le_pow_of_le,theorem Nat.pow_le_pow_of_le {a n m : Nat} (h : 1 < a) (w : n ≤ m) : a ^ n ≤ a ^ m := by sorry,"Exponentiation Preserves Order in Natural Numbers: \(a^n \leq a^m\) if \(n \leq m\) : For any natural numbers \(a\), \(n\), and \(m\) such that \(1 < a\) and \(n \leq m\), it holds that \(a^n \leq a^m\).","theorem Nat.pow_le_pow_of_le {a n m : Nat} (h : 1 < a) (w : n ≤ m) : a ^ n ≤ a ^ m := by
  cases Nat.lt_or_eq_of_le w
  case inl lt =>
    exact Nat.le_of_lt (Nat.pow_lt_pow_of_lt h lt)
  case inr eq =>
    subst eq
    exact Nat.le_refl _","We start by considering the assumption \( n \leq m \). We will discuss every possible case of this inequality.

**Case 1: \( n < m \)**
In this case, we use the fact that if \( 1 < a \) and \( n < m \), then \( a^n < a^m \). Since \( a^n < a^m \) implies \( a^n \leq a^m \), we have \( a^n \leq a^m \).

**Case 2: \( n = m \)**
In this case, we substitute \( n \) with \( m \) in the goal, which simplifies the goal to \( a^n \leq a^n \). This is true by the reflexivity of the less than or equal to relation, i.e., \( a^n \leq a^n \) holds for any natural number \( a^n \).

Since both cases are covered, we conclude that for any natural numbers \(a\), \(n\), and \(m\) such that \(1 < a\) and \(n \leq m\), it holds that \(a^n \leq a^m\). This completes the proof. \(\blacksquare\)","theorem Nat.pow_le_pow_of_le {a n m : Nat} (h : 1 < a) (w : n ≤ m) : a ^ n ≤ a ^ m := by
/- We will discuss every possible case of \( n \leq m \). Case 1: \( n < m \). Case 2: \( n = m \). -/
  cases Nat.lt_or_eq_of_le w
/- For the case where \( n < m \), we use the fact that if \( 1 < a \) and \( n < m \), then \( a^n < a^m \). Since \( a^n < a^m \) implies \( a^n \leq a^m \), the current goal is exactly proved. -/
  case inl lt =>
    exact Nat.le_of_lt (Nat.pow_lt_pow_of_lt h lt)
/- For the case where \( n = m \), we substitute \( n \) with \( m \) in the goal, which simplifies the goal to \( a^n \leq a^n \). This is true by the reflexivity of the less than or equal to relation, i.e., \( a^n \leq a^n \) holds for any natural number \( a^n \). -/
  case inr eq =>
    subst eq
    exact Nat.le_refl _","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32471,Nat.div_eq_iff_eq_mul_left,"theorem Nat.div_eq_iff_eq_mul_left {a b c : Nat} (H : 0 < b) (H' : b ∣ a) :
    a / b = c ↔ a = c * b := by sorry","Equivalence of Division and Multiplication in Natural Numbers: \(\frac{a}{b} = c \leftrightarrow a = c \cdot b\) : For any natural numbers \(a\), \(b\), and \(c\) such that \(b > 0\) and \(b \mid a\), the following equivalence holds:
\[ \frac{a}{b} = c \quad \text{if and only if} \quad a = c \cdot b. \]","theorem Nat.div_eq_iff_eq_mul_left {a b c : Nat} (H : 0 < b) (H' : b ∣ a) :
    a / b = c ↔ a = c * b := by
  rw [Nat.mul_comm]; exact Nat.div_eq_iff_eq_mul_right H H'","We start with the given conditions that \(b > 0\) and \(b \mid a\). We need to show the equivalence \(\frac{a}{b} = c \leftrightarrow a = c \cdot b\).

First, we use the commutativity of multiplication to rewrite the goal. Specifically, we rewrite \(a = c \cdot b\) as \(a = b \cdot c\). This step is valid because multiplication is commutative in the natural numbers.

Next, we apply the theorem that states for any natural numbers \(a\), \(b\), and \(c\) such that \(b > 0\) and \(b \mid a\), the equivalence \(\frac{a}{b} = c\) holds if and only if \(a = b \cdot c\). This theorem directly gives us the desired equivalence \(\frac{a}{b} = c \leftrightarrow a = c \cdot b\).

Thus, we have shown that \(\frac{a}{b} = c\) if and only if \(a = c \cdot b\). This completes the proof.","theorem Nat.div_eq_iff_eq_mul_left {a b c : Nat} (H : 0 < b) (H' : b ∣ a) :
    a / b = c ↔ a = c * b := by
/- First, we use the commutativity of multiplication to rewrite the goal. Specifically, we rewrite \(a = c \cdot b\) as \(a = b \cdot c\). Then, we apply the theorem that states for any natural numbers \(a\), \(b\), and \(c\) such that \(b > 0\) and \(b \mid a\), the equivalence \(\frac{a}{b} = c\) holds if and only if \(a = b \cdot c\). This theorem directly gives us the desired equivalence \(\frac{a}{b} = c \leftrightarrow a = c \cdot b\). -/
  rw [Nat.mul_comm]; exact Nat.div_eq_iff_eq_mul_right H H'","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32472,Nat.mul_max_mul_right,theorem Nat.mul_max_mul_right (a b c : Nat) : max (a * c) (b * c) = max a b * c := by sorry,"Maximum of Products Equals Product of Maximum in Natural Numbers : For any natural numbers \(a\), \(b\), and \(c\), the maximum of \(a \cdot c\) and \(b \cdot c\) is equal to the product of the maximum of \(a\) and \(b\) with \(c\), i.e., \(\max(a \cdot c, b \cdot c) = \max(a, b) \cdot c\).","theorem Nat.mul_max_mul_right (a b c : Nat) : max (a * c) (b * c) = max a b * c := by
  induction a generalizing b with
  | zero => simp
  | succ i ind =>
    cases b <;> simp [succ_eq_add_one, Nat.succ_mul, Nat.add_max_add_right, ind]","We will prove this by induction on \( b \).

**Base Case: \( b = 0 \)**
We need to show that \(\max(a \cdot c, 0 \cdot c) = \max(a, 0) \cdot c\).
Using the property that \(\max(a, 0) = a\), we have:
\[
\max(a \cdot c, 0 \cdot c) = \max(a \cdot c, 0) = a \cdot c = \max(a, 0) \cdot c
\]
This is trivially true.

**Inductive Step: \( b = n + 1 \) for some natural number \( n \)**
Assume that for any natural number \( b \), \(\max(i \cdot c, b \cdot c) = \max(i, b) \cdot c\). We need to show that \(\max((i + 1) \cdot c, (n + 1) \cdot c) = \max(i + 1, n + 1) \cdot c\).

Using the property of successor multiplication, we have:
\[
(i + 1) \cdot c = i \cdot c + c
\]
and
\[
(n + 1) \cdot c = n \cdot c + c
\]
Thus, the goal becomes:
\[
\max(i \cdot c + c, n \cdot c + c) = \max(i + 1, n + 1) \cdot c
\]
Using the distributive property of maximum over addition, we have:
\[
\max(i \cdot c + c, n \cdot c + c) = \max(i \cdot c, n \cdot c) + c
\]
By the inductive hypothesis, we know:
\[
\max(i \cdot c, n \cdot c) = \max(i, n) \cdot c
\]
Thus:
\[
\max(i \cdot c + c, n \cdot c + c) = \max(i, n) \cdot c + c
\]
Since \(\max(i + 1, n + 1) = \max(i, n) + 1\), we have:
\[
\max(i + 1, n + 1) \cdot c = (\max(i, n) + 1) \cdot c = \max(i, n) \cdot c + c
\]
Therefore:
\[
\max(i \cdot c + c, n \cdot c + c) = \max(i + 1, n + 1) \cdot c
\]
This completes the inductive step.

By induction, the theorem holds for all natural numbers \( b \). Hence, for any natural numbers \(a\), \(b\), and \(c\), we have:
\[
\max(a \cdot c, b \cdot c) = \max(a, b) \cdot c
\]
\(\blacksquare\)","theorem Nat.mul_max_mul_right (a b c : Nat) : max (a * c) (b * c) = max a b * c := by
  induction a generalizing b with
/- In the case where \( b = 0 \), we simplify the goal using the property that the maximum of a natural number and zero is the natural number itself, i.e., \(\max(a, 0) = a\). This simplifies the goal to a trivial equality, which is automatically true. -/
  | zero => simp
/- In the case where \( b = n + 1 \) for some natural number \( n \), we use the inductive hypothesis that for any natural number \( b \), \(\max(i \cdot c, b \cdot c) = \max(i, b) \cdot c\). -/
  | succ i ind =>
/- We will consider two cases for \( b \): \( b = 0 \) and \( b = n + 1 \) for some natural number \( n \). For each case, we will simplify the goal using the properties of natural numbers and the inductive hypothesis. -/
/- We will consider two cases for \( b \): \( b = 0 \) and \( b = n + 1 \) for some natural number \( n \). For each case, we will simplify the goal using the properties of natural numbers and the inductive hypothesis. -/
    cases b <;> simp [succ_eq_add_one, Nat.succ_mul, Nat.add_max_add_right, ind]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32473,Nat.eq_mul_of_div_eq_right,"theorem Nat.eq_mul_of_div_eq_right {a b c : Nat} (H1 : b ∣ a) (H2 : a / b = c) :
    a = b * c := by sorry","Equivalence of Division and Multiplication in Natural Numbers: \( \frac{a}{b} = c \to a = b \cdot c \) : For any natural numbers \(a\), \(b\), and \(c\) such that \(b \mid a\) and \(\frac{a}{b} = c\), it holds that \(a = b \cdot c\).","theorem Nat.eq_mul_of_div_eq_right {a b c : Nat} (H1 : b ∣ a) (H2 : a / b = c) :
    a = b * c := by
  rw [← H2, Nat.mul_div_cancel' H1]","We start with the given hypotheses:
1. \( b \mid a \), which means there exists a natural number \( k \) such that \( a = b \cdot k \).
2. \( \frac{a}{b} = c \).

To prove \( a = b \cdot c \), we use the hypothesis \( \frac{a}{b} = c \) to rewrite the goal. Specifically, we substitute \( c \) with \( \frac{a}{b} \) in the equation \( a = b \cdot c \), which gives us:
\[ a = b \cdot \left( \frac{a}{b} \right). \]

Next, we use the theorem that for any natural number \( a \) and any nonzero natural number \( b \) such that \( b \mid a \), the equation \( b \cdot \left( \frac{a}{b} \right) = a \) holds. This theorem simplifies our goal to:
\[ a = a. \]

Since \( a = a \) is trivially true, we have completed the proof. Therefore, \( a = b \cdot c \).","theorem Nat.eq_mul_of_div_eq_right {a b c : Nat} (H1 : b ∣ a) (H2 : a / b = c) :
    a = b * c := by
/- First, we use the hypothesis \( H2 \) which states \( \frac{a}{b} = c \) to rewrite the goal \( a = b \cdot c \) as \( a = b \cdot \left( \frac{a}{b} \right) \). Then, we use the theorem that for any natural number \( a \) and any nonzero natural number \( b \) such that \( b \mid a \), the equation \( b \cdot \left( \frac{a}{b} \right) = a \) holds. This simplifies our goal to \( a = a \), which is trivially true. -/
  rw [← H2, Nat.mul_div_cancel' H1]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32474,Nat.pow_lt_pow_succ,theorem Nat.pow_lt_pow_succ (h : 1 < a) : a ^ n < a ^ (n + 1) := by sorry,"Exponentiation Preserves Strict Inequality in Natural Numbers: \( a^n < a^{n+1} \) for \( a > 1 \) : For any natural numbers \( a \) and \( n \) such that \( a > 1 \), it holds that \( a^n < a^{n+1} \).","theorem Nat.pow_lt_pow_succ (h : 1 < a) : a ^ n < a ^ (n + 1) := by
  rw [← Nat.mul_one (a^n), Nat.pow_succ]
  exact Nat.mul_lt_mul_of_le_of_lt (Nat.le_refl _) h (Nat.pow_pos (Nat.lt_trans Nat.zero_lt_one h))","We start by using the properties of exponentiation and the multiplicative identity. Specifically, we know that:
\[ a^n \cdot 1 = a^n \]
and
\[ a^{n+1} = a^n \cdot a. \]
Thus, the goal \( a^n < a^{n+1} \) can be rewritten as:
\[ a^n \cdot 1 < a^n \cdot a. \]

To prove this, we use the fact that multiplication preserves inequalities in ordered monoids. We need to show:
1. \( a^n \leq a^n \) (which is true by the reflexivity of the less than or equal to relation),
2. \( 1 < a \) (which is given by the hypothesis \( h \)),
3. \( 0 < a^n \) (which follows from the fact that \( 0 < 1 \) and \( 1 < a \) implies \( 0 < a \), and since \( a \) is positive, \( a^n \) is also positive).

Using these facts, we can conclude that:
\[ a^n \cdot 1 < a^n \cdot a. \]
Therefore, \( a^n < a^{n+1} \). This completes the proof. \(\blacksquare\)","theorem Nat.pow_lt_pow_succ (h : 1 < a) : a ^ n < a ^ (n + 1) := by
/- First, we use the multiplicative identity property \( a^n \cdot 1 = a^n \) and the property of exponentiation \( a^{n+1} = a^n \cdot a \) to rewrite the goal. This transforms the goal from \( a^n < a^{n+1} \) to \( a^n \cdot 1 < a^n \cdot a \). -/
  rw [← Nat.mul_one (a^n), Nat.pow_succ]
/- To prove \( a^n \cdot 1 < a^n \cdot a \), we use the fact that multiplication preserves inequalities in ordered monoids. Specifically, we need to show:
1. \( a^n \leq a^n \) (which is true by the reflexivity of the less than or equal to relation),
2. \( 1 < a \) (which is given by the hypothesis \( h \)),
3. \( 0 < a^n \) (which follows from the fact that \( 0 < 1 \) and \( 1 < a \) implies \( 0 < a \), and since \( a \) is positive, \( a^n \) is also positive).

Using these facts, we can conclude that \( a^n \cdot 1 < a^n \cdot a \). This completes the proof. -/
  exact Nat.mul_lt_mul_of_le_of_lt (Nat.le_refl _) h (Nat.pow_pos (Nat.lt_trans Nat.zero_lt_one h))","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32475,Nat.pow_dvd_pow,theorem Nat.pow_dvd_pow {m n : Nat} (a : Nat) (h : m ≤ n) : a ^ m ∣ a ^ n := by sorry,"Power Divisibility: \( a^m \mid a^n \) for \( m \leq n \) : For any natural numbers \( m \) and \( n \) such that \( m \leq n \), and for any natural number \( a \), it holds that \( a^m \) divides \( a^n \), i.e., \( a^m \mid a^n \).","theorem Nat.pow_dvd_pow {m n : Nat} (a : Nat) (h : m ≤ n) : a ^ m ∣ a ^ n := by
  cases Nat.exists_eq_add_of_le h
  case intro k p =>
    subst p
    rw [Nat.pow_add]
    apply Nat.dvd_mul_right","We start by considering the case where \( m \leq n \). By the property of natural numbers, there exists a natural number \( k \) such that \( n = m + k \).

We now focus on the specific case where \( n = m + k \). Substituting \( n = m + k \) into the goal, we need to show that \( a^m \mid a^{m + k} \). Using the property of exponents, we know that:
\[
a^{m + k} = a^m \cdot a^k
\]
Therefore, it suffices to show that \( a^m \mid a^m \cdot a^k \). By the property of divisibility in semigroups, \( a^m \) divides \( a^m \cdot a^k \). This completes the proof. \(\blacksquare\)","theorem Nat.pow_dvd_pow {m n : Nat} (a : Nat) (h : m ≤ n) : a ^ m ∣ a ^ n := by
/- We consider the case where \( m \leq n \). By the property of natural numbers, there exists a natural number \( k \) such that \( n = m + k \). -/
  cases Nat.exists_eq_add_of_le h
/- We now consider the specific case where \( n = m + k \) for some natural number \( k \). Substituting \( n = m + k \) into the goal, we need to show that \( a^m \mid a^{m + k} \). Using the property of exponents, we know that \( a^{m + k} = a^m \cdot a^k \). Therefore, it suffices to show that \( a^m \mid a^m \cdot a^k \). By the property of divisibility in semigroups, \( a^m \) divides \( a^m \cdot a^k \). This completes the proof. -/
  case intro k p =>
    subst p
    rw [Nat.pow_add]
    apply Nat.dvd_mul_right","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32477,Nat.shiftLeft_shiftRight,theorem Nat.shiftLeft_shiftRight (x n : Nat) : x <<< n >>> n = x := by sorry,"Left and Right Shift Operations Cancel Each Other in Natural Numbers : For any natural numbers \( x \) and \( n \), the left shift operation followed by the right shift operation of the same amount \( n \) returns the original number \( x \), i.e., \( (x <<< n) >>> n = x \).","theorem Nat.shiftLeft_shiftRight (x n : Nat) : x <<< n >>> n = x := by
  rw [Nat.shiftLeft_eq, Nat.shiftRight_eq_div_pow, Nat.mul_div_cancel _ (Nat.two_pow_pos _)]","To prove that \( (x \<<< n) \>>> n = x \) for any natural numbers \( x \) and \( n \), we proceed as follows:

1. **Left Shift Operation:**
By the definition of the left shift operation, we have:
\[
x \<<< n = x \cdot 2^n
\]

2. **Right Shift Operation:**
By the definition of the right shift operation, we have:
\[
(x \cdot 2^n) \>>> n = (x \cdot 2^n) / 2^n
\]

3. **Cancellation Property:**
Since \( 2^n \) is positive for any natural number \( n \), we can use the cancellation property of multiplication and division in a commutative group, which states that:
\[
a \cdot (b / a) = b
\]
Applying this property, we get:
\[
(x \cdot 2^n) / 2^n = x
\]

Therefore, we have shown that:
\[
(x \<<< n) \>>> n = x
\]

This completes the proof.","theorem Nat.shiftLeft_shiftRight (x n : Nat) : x <<< n >>> n = x := by
/- First, we use the fact that the left shift operation \( x \<<< n \) is equivalent to \( x \cdot 2^n \). Then, we use the fact that the right shift operation \( m \>>> n \) is equivalent to \( m / 2^n \). Therefore, the expression \( (x \<<< n) \>>> n \) can be rewritten as \( (x \cdot 2^n) / 2^n \). Since \( 2^n \) is positive for any natural number \( n \), we can apply the cancellation property of multiplication and division in a commutative group, which states that \( a \cdot (b / a) = b \). Thus, \( (x \cdot 2^n) / 2^n = x \). -/
  rw [Nat.shiftLeft_eq, Nat.shiftRight_eq_div_pow, Nat.mul_div_cancel _ (Nat.two_pow_pos _)]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32478,Nat.pow_mul,theorem Nat.pow_mul (a m n : Nat) : a ^ (m * n) = (a ^ m) ^ n := by sorry,"Power of Product Equals Power of Power in Natural Numbers : For any natural numbers \(a\), \(m\), and \(n\), the power of \(a\) raised to the product of \(m\) and \(n\) is equal to the power of \(a\) raised to \(m\) and then raised to \(n\), i.e., \(a^{m \cdot n} = (a^m)^n\).","theorem Nat.pow_mul (a m n : Nat) : a ^ (m * n) = (a ^ m) ^ n := by
  induction n with
  | zero => rw [Nat.mul_zero, Nat.pow_zero, Nat.pow_zero]
  | succ _ ih => rw [Nat.mul_succ, Nat.pow_add, Nat.pow_succ, ih]","We prove this by induction on \( n \).

**Base Case:**
Consider \( n = 0 \). We need to show that \( a^{m \cdot 0} = (a^m)^0 \). Using the properties of multiplication by zero and the power of zero, we have:
\[
a^{m \cdot 0} = a^0 = 1
\]
and
\[
(a^m)^0 = 1
\]
Thus, the base case holds.

**Inductive Step:**
Assume the inductive hypothesis that for some natural number \( k \), \( a^{m \cdot k} = (a^m)^k \). We need to show that \( a^{m \cdot (k + 1)} = (a^m)^{k + 1} \). Using the properties of multiplication by successor, the power of a sum, and the power of a successor, we have:
\[
a^{m \cdot (k + 1)} = a^{m \cdot k + m} = a^{m \cdot k} \cdot a^m
\]
By the inductive hypothesis, \( a^{m \cdot k} = (a^m)^k \), so:
\[
a^{m \cdot k} \cdot a^m = (a^m)^k \cdot a^m
\]
Using the property of the power of a successor, we get:
\[
(a^m)^k \cdot a^m = (a^m)^{k + 1}
\]
Thus, the inductive step holds.

By the principle of mathematical induction, the theorem is true for all natural numbers \( n \). Therefore, for any natural numbers \(a\), \(m\), and \(n\), we have:
\[
a^{m \cdot n} = (a^m)^n
\]
This completes the proof.","theorem Nat.pow_mul (a m n : Nat) : a ^ (m * n) = (a ^ m) ^ n := by
  induction n with
/- First, consider the base case where \( n = 0 \). We need to show that \( a^{m \cdot 0} = (a^m)^0 \). Using the properties of multiplication by zero and the power of zero, we have:
\[
a^{m \cdot 0} = a^0 = 1
\]
and
\[
(a^m)^0 = 1
\]
Thus, the base case holds. -/
  | zero => rw [Nat.mul_zero, Nat.pow_zero, Nat.pow_zero]
/- Next, consider the inductive step where \( n = k + 1 \) for some natural number \( k \). Assume the inductive hypothesis that \( a^{m \cdot k} = (a^m)^k \). We need to show that \( a^{m \cdot (k + 1)} = (a^m)^{k + 1} \). Using the properties of multiplication by successor, the power of a sum, and the power of a successor, we have:
\[
a^{m \cdot (k + 1)} = a^{m \cdot k + m} = a^{m \cdot k} \cdot a^m
\]
By the inductive hypothesis, \( a^{m \cdot k} = (a^m)^k \), so:
\[
a^{m \cdot k} \cdot a^m = (a^m)^k \cdot a^m
\]
Using the property of the power of a successor, we get:
\[
(a^m)^k \cdot a^m = (a^m)^{k + 1}
\]
Thus, the inductive step holds. -/
  | succ _ ih => rw [Nat.mul_succ, Nat.pow_add, Nat.pow_succ, ih]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32479,Nat.pow_dvd_pow_iff_le_right,theorem Nat.pow_dvd_pow_iff_le_right {x k l : Nat} (w : 1 < x) : x ^ k ∣ x ^ l ↔ k ≤ l := by sorry,"Divisibility of Powers of a Natural Number Greater than One Implies Inequality of Exponents: \( x^k \mid x^l \leftrightarrow k \leq l \) : For any natural numbers \( x \), \( k \), and \( l \) such that \( x > 1 \), the natural number \( x^k \) divides \( x^l \) if and only if \( k \leq l \).","theorem Nat.pow_dvd_pow_iff_le_right {x k l : Nat} (w : 1 < x) : x ^ k ∣ x ^ l ↔ k ≤ l := by
  rw [pow_dvd_pow_iff_pow_le_pow (lt_of_succ_lt w), Nat.pow_le_pow_iff_right w]","We start by noting that \( x > 1 \). We need to show that \( x^k \mid x^l \) if and only if \( k \leq l \).

1. **Step 1:**
We use the theorem that for any natural numbers \( k \), \( l \), and \( x \) such that \( x > 0 \), \( x^k \) divides \( x^l \) if and only if \( x^k \leq x^l \). Since \( x > 1 \), we can apply this theorem. This gives us:
\[
x^k \mid x^l \leftrightarrow x^k \leq x^l
\]

2. **Step 2:**
Next, we use the theorem that for any natural numbers \( n \) and \( m \) and any element \( a \) in a strict ordered semiring such that \( 1 < a \), \( a^n \leq a^m \) if and only if \( n \leq m \). Since \( x > 1 \), we can apply this theorem. This gives us:
\[
x^k \leq x^l \leftrightarrow k \leq l
\]

3. **Combining the results:**
Combining the results from steps 1 and 2, we get:
\[
x^k \mid x^l \leftrightarrow k \leq l
\]

Thus, we have shown that \( x^k \mid x^l \) if and only if \( k \leq l \). This completes the proof. \(\blacksquare\)","theorem Nat.pow_dvd_pow_iff_le_right {x k l : Nat} (w : 1 < x) : x ^ k ∣ x ^ l ↔ k ≤ l := by
/- First, we use the theorem that for any natural numbers \( k \), \( l \), and \( x \) such that \( x > 0 \), \( x^k \) divides \( x^l \) if and only if \( x^k \leq x^l \). Since \( x > 1 \), we can apply this theorem. Additionally, we use the theorem that for any natural numbers \( n \) and \( m \) and any element \( a \) in a strict ordered semiring such that \( 1 < a \), \( a^n \leq a^m \) if and only if \( n \leq m \). Combining these, we get that \( x^k \mid x^l \) if and only if \( k \leq l \). -/
  rw [pow_dvd_pow_iff_pow_le_pow (lt_of_succ_lt w), Nat.pow_le_pow_iff_right w]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32480,Nat.pow_lt_pow_of_lt,theorem Nat.pow_lt_pow_of_lt {a n m : Nat} (h : 1 < a) (w : n < m) : a ^ n < a ^ m := by sorry,"Exponentiation Preserves Strict Inequality in Natural Numbers: \(a^n < a^m\) if \(1 < a\) and \(n < m\) : For any natural numbers \(a\), \(n\), and \(m\) such that \(1 < a\) and \(n < m\), it holds that \(a^n < a^m\).","theorem Nat.pow_lt_pow_of_lt {a n m : Nat} (h : 1 < a) (w : n < m) : a ^ n < a ^ m := by
  have := Nat.exists_eq_add_of_lt w
  cases this
  case intro k p =>
  rw [Nat.add_right_comm] at p
  subst p
  rw [Nat.pow_add, ← Nat.mul_one (a^n)]
  have t : 0 < a ^ k := Nat.pow_pos (Nat.lt_trans Nat.zero_lt_one h)
  exact Nat.mul_lt_mul_of_lt_of_le (Nat.pow_lt_pow_succ h) t t","We start by noting that since \( n < m \), there exists a natural number \( k \) such that \( m = n + k + 1 \). We can rewrite this as \( m = n + 1 + k \) using the right commutativity of addition.

Next, we substitute \( m = n + 1 + k \) into the goal, so the goal becomes \( a^n < a^{n + 1 + k} \). Using the properties of exponents, we can rewrite \( a^{n + 1 + k} \) as \( a^n \cdot a \cdot a^k \). Therefore, the goal is to show \( a^n < a^n \cdot a \cdot a^k \).

We know that \( 1 < a \), so \( a^n < a^{n+1} \) by the property of exponents. Additionally, since \( 1 < a \), we have \( 0 < a \), and thus \( 0 < a^k \) for any natural number \( k \).

Using the fact that \( a^n < a^{n+1} \) and \( 0 < a^k \), we can apply the property of multiplication in ordered monoids to conclude that \( a^n \cdot 1 < a^{n+1} \cdot a^k \). This completes the proof. \(\blacksquare\)","theorem Nat.pow_lt_pow_of_lt {a n m : Nat} (h : 1 < a) (w : n < m) : a ^ n < a ^ m := by
/- First, we use the fact that for any natural numbers \( n \) and \( m \) such that \( n < m \), there exists a natural number \( k \) such that \( m = n + k + 1 \). We denote this \( k \) as \( w \). -/
  have := Nat.exists_eq_add_of_lt w
/- We consider the case where \( m = n + k + 1 \) for some natural number \( k \). -/
  cases this
  case intro k p =>
/- We use the right commutativity of addition to rewrite \( m = n + k + 1 \) as \( m = n + 1 + k \). -/
  rw [Nat.add_right_comm] at p
/- We substitute \( m = n + 1 + k \) into the goal, so the goal becomes \( a^n < a^{n + 1 + k} \). -/
  subst p
/- We use the property of exponents that \( a^{n + 1 + k} = a^n \cdot a^{1 + k} \) and the fact that \( a^n \cdot 1 = a^n \) to rewrite the goal as \( a^n \cdot 1 < a^n \cdot a \cdot a^k \). -/
  rw [Nat.pow_add, ← Nat.mul_one (a^n)]
/- We show that \( 0 < a^k \) by using the fact that \( 0 < 1 \) and \( 1 < a \) implies \( 0 < a \), and since \( a \) is positive, \( a^k \) is also positive. -/
  have t : 0 < a ^ k := Nat.pow_pos (Nat.lt_trans Nat.zero_lt_one h)
/- We use the fact that \( a^n < a^{n+1} \) (since \( 1 < a \)) and \( 0 < a^k \) to conclude that \( a^n \cdot 1 < a^{n+1} \cdot a^k \), which completes the proof. -/
  exact Nat.mul_lt_mul_of_lt_of_le (Nat.pow_lt_pow_succ h) t t","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32481,Nat.pow_sub_mul_pow,"theorem Nat.pow_sub_mul_pow (a : Nat) {m n : Nat} (h : m ≤ n) :
    a ^ (n - m) * a ^ m = a ^ n := by sorry","Power Subtraction and Multiplication Identity: \( a^{n - m} \cdot a^m = a^n \) : For any natural number \( a \) and any natural numbers \( m \) and \( n \) such that \( m \leq n \), it holds that \( a^{n - m} \cdot a^m = a^n \).","theorem Nat.pow_sub_mul_pow (a : Nat) {m n : Nat} (h : m ≤ n) :
    a ^ (n - m) * a ^ m = a ^ n := by
  rw [← Nat.pow_add, Nat.sub_add_cancel h]","To prove the identity \( a^{n - m} \cdot a^m = a^n \), we start by using the property of exponents that states the power of a sum of exponents is equal to the product of the powers of the individual exponents. Specifically, we have:
\[
a^{(n - m) + m} = a^{n - m} \cdot a^m
\]
By applying this property in reverse, we can rewrite the goal \( a^{n - m} \cdot a^m = a^n \) as:
\[
a^{(n - m) + m} = a^n
\]
Next, we use the property that subtraction and addition cancel each other out in additive groups. Since \( m \leq n \), we have:
\[
n - m + m = n
\]
Thus, the goal simplifies to:
\[
a^n = a^n
\]
This is trivially true. Therefore, we have shown that \( a^{n - m} \cdot a^m = a^n \). This completes the proof. \(\blacksquare\)","theorem Nat.pow_sub_mul_pow (a : Nat) {m n : Nat} (h : m ≤ n) :
    a ^ (n - m) * a ^ m = a ^ n := by
/- First, we use the property that the power of a sum of exponents is equal to the product of the powers of the individual exponents, i.e., \( a^{m + n} = a^m \cdot a^n \). By applying this property in reverse, we can rewrite the goal \( a^{n - m} \cdot a^m = a^n \) as \( a^{(n - m) + m} = a^n \). Next, we use the property that subtraction and addition cancel each other out in additive groups, i.e., \( a - b + b = a \). Since \( m \leq n \), we have \( n - m + m = n \). Therefore, the goal simplifies to \( a^n = a^n \), which is trivially true. -/
  rw [← Nat.pow_add, Nat.sub_add_cancel h]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32482,Nat.pow_div,theorem Nat.pow_div {x m n : Nat} (h : n ≤ m) (hx : 0 < x) : x ^ m / x ^ n = x ^ (m - n) := by sorry,"Power Division Identity: \( x^m / x^n = x^{m - n} \) for \( x > 0 \) and \( n \le m \) : For any natural numbers \( x \), \( m \), and \( n \) such that \( n \le m \) and \( x > 0 \), the division of \( x^m \) by \( x^n \) is equal to \( x^{m - n} \), i.e., \( x^m / x^n = x^{m - n} \).","theorem Nat.pow_div {x m n : Nat} (h : n ≤ m) (hx : 0 < x) : x ^ m / x ^ n = x ^ (m - n) := by
  rw [Nat.div_eq_iff_eq_mul_left (Nat.pow_pos hx) (Nat.pow_dvd_pow _ h), Nat.pow_sub_mul_pow _ h]","We start by noting that \( x^n \) is positive because \( x > 0 \) and \( x^n \) is a power of a positive number. Additionally, since \( n \le m \), \( x^n \) divides \( x^m \). Using the equivalence of division and multiplication in natural numbers, we have:
\[ \frac{x^m}{x^n} = x^{m - n} \quad \text{if and only if} \quad x^m = x^{m - n} \cdot x^n. \]
Next, we use the property of powers in monoids, which states that for any natural numbers \( m \) and \( n \) such that \( m \le n \), and for any element \( a \) in a monoid, it holds that:
\[ a^{n - m} \cdot a^m = a^n. \]
Applying this property to our specific case, we get:
\[ x^{m - n} \cdot x^n = x^m. \]
Thus, the equation \( x^m = x^{m - n} \cdot x^n \) is true, and therefore:
\[ \frac{x^m}{x^n} = x^{m - n}. \]
This completes the proof.","theorem Nat.pow_div {x m n : Nat} (h : n ≤ m) (hx : 0 < x) : x ^ m / x ^ n = x ^ (m - n) := by
/- First, we use the equivalence that for any natural numbers \(a\), \(b\), and \(c\) such that \(b > 0\) and \(b \mid a\), the following holds:
\[ \frac{a}{b} = c \quad \text{if and only if} \quad a = c \cdot b. \]
We apply this equivalence to our goal \( x^m / x^n = x^{m - n} \) by noting that \( x^n \) is positive (since \( x > 0 \) and \( x^n \) is a power of a positive number) and \( x^n \mid x^m \) (since \( n \le m \)). This transforms our goal into:
\[ x^m = x^{m - n} \cdot x^n. \] -/
/- Next, we use the property that for any monoid \( M \) and any natural numbers \( m \) and \( n \) such that \( m \le n \), and for any element \( a \in M \), it holds that:
\[ a^{n - m} \cdot a^m = a^n. \]
Applying this property to our current goal \( x^m = x^{m - n} \cdot x^n \), we get:
\[ x^m = x^m. \]
This is trivially true, and thus our goal is satisfied. -/
  rw [Nat.div_eq_iff_eq_mul_left (Nat.pow_pos hx) (Nat.pow_dvd_pow _ h), Nat.pow_sub_mul_pow _ h]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32484,Nat.mod_div_self,theorem Nat.mod_div_self (m n : Nat) : m % n / n = 0 := by sorry,"Remainder Divided by Divisor is Zero in Natural Numbers : For any natural numbers \( m \) and \( n \), the result of dividing the remainder of \( m \) divided by \( n \) by \( n \) is zero, i.e., \( m \% n / n = 0 \).","theorem Nat.mod_div_self (m n : Nat) : m % n / n = 0 := by
  cases n
  · exact (m % 0).div_zero
  · case succ n => exact Nat.div_eq_of_lt (m.mod_lt n.succ_pos)","We will consider two cases for \( n \).

1. **Case 1: \( n = 0 \)**
- We need to show that \( m \% 0 / 0 = 0 \).
- By the property of division by zero in a group with an adjoined zero element, \( a / 0 = 0 \) for any element \( a \).
- Therefore, \( m \% 0 / 0 = 0 \).

2. **Case 2: \( n = k + 1 \) where \( k \) is a natural number**
- We need to show that \( m \% (k + 1) / (k + 1) = 0 \).
- By the property of the modulo operation, \( m \% (k + 1) < k + 1 \).
- Since \( k + 1 > 0 \), we have \( m \% (k + 1) < k + 1 \).
- By the property of division of a smaller natural number by a larger natural number, \( a / b = 0 \) if \( a < b \).
- Therefore, \( m \% (k + 1) / (k + 1) = 0 \).

In both cases, we have shown that \( m \% n / n = 0 \). This completes the proof. \(\blacksquare\)","theorem Nat.mod_div_self (m n : Nat) : m % n / n = 0 := by
/- We will discuss every possible case of \( n \). Case 1: \( n = 0 \). -/
  cases n
/- For the case \( n = 0 \), we need to show that \( m \% 0 / 0 = 0 \). By the property of division by zero in a group with an adjoined zero element, \( a / 0 = 0 \) for any element \( a \). Therefore, \( m \% 0 / 0 = 0 \). -/
  · exact (m % 0).div_zero
/- For the case \( n = k + 1 \) where \( k \) is a natural number, we need to show that \( m \% (k + 1) / (k + 1) = 0 \). By the property of the modulo operation, \( m \% (k + 1) < k + 1 \). Since \( k + 1 > 0 \), we have \( m \% (k + 1) < k + 1 \). By the property of division of a smaller natural number by a larger natural number, \( a / b = 0 \) if \( a < b \). Therefore, \( m \% (k + 1) / (k + 1) = 0 \). -/
  · case succ n => exact Nat.div_eq_of_lt (m.mod_lt n.succ_pos)","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32486,Nat.pow_add,theorem Nat.pow_add (a m n : Nat) : a ^ (m + n) = a ^ m * a ^ n := by sorry,"Power of Sum Equals Product of Powers in Natural Numbers: \(a^{m + n} = a^m \cdot a^n\) : For any natural numbers \(a\), \(m\), and \(n\), the power of \(a\) raised to the sum of \(m\) and \(n\) is equal to the product of \(a\) raised to \(m\) and \(a\) raised to \(n\), i.e., \(a^{m + n} = a^m \cdot a^n\).","theorem Nat.pow_add (a m n : Nat) : a ^ (m + n) = a ^ m * a ^ n := by
  induction n with
  | zero => rw [Nat.add_zero, Nat.pow_zero, Nat.mul_one]
  | succ _ ih => rw [Nat.add_succ, Nat.pow_succ, Nat.pow_succ, ih, Nat.mul_assoc]","We prove this by induction on \( n \).

**Base Case:**
Consider \( n = 0 \). We need to show that \( a^{m + 0} = a^m \cdot a^0 \). Using the properties of addition and power:
1. \( m + 0 = m \) (since adding zero to any number \( m \) does not change it).
2. \( a^0 = 1 \) (since any number raised to the power of zero is 1).
3. \( a^m \cdot 1 = a^m \) (since multiplying any number \( a^m \) by 1 does not change it).

Thus, \( a^{m + 0} = a^m \cdot a^0 \) simplifies to \( a^m = a^m \), which is trivially true.

**Inductive Step:**
Assume the inductive hypothesis that \( a^{m + k} = a^m \cdot a^k \) for some natural number \( k \). We need to show that \( a^{m + (k + 1)} = a^m \cdot a^{k + 1} \). Using the properties of addition and power:
1. \( m + (k + 1) = (m + k) + 1 \) (since addition is associative).
2. \( a^{(m + k) + 1} = a^{m + k} \cdot a \) (since raising a number to the power of a successor is equivalent to multiplying the number raised to the original power by the number itself).
3. By the inductive hypothesis, \( a^{m + k} = a^m \cdot a^k \).
4. Substituting the inductive hypothesis, we get \( a^{(m + k) + 1} = (a^m \cdot a^k) \cdot a \).
5. Using the associativity of multiplication, \( (a^m \cdot a^k) \cdot a = a^m \cdot (a^k \cdot a) \).
6. Finally, \( a^m \cdot (a^k \cdot a) = a^m \cdot a^{k + 1} \) (since \( a^k \cdot a = a^{k + 1} \)).

Thus, \( a^{m + (k + 1)} = a^m \cdot a^{k + 1} \) is satisfied.

By the principle of mathematical induction, the theorem holds for all natural numbers \( n \). Therefore, for any natural numbers \( a \), \( m \), and \( n \), \( a^{m + n} = a^m \cdot a^n \). This completes the proof. \(\blacksquare\)","theorem Nat.pow_add (a m n : Nat) : a ^ (m + n) = a ^ m * a ^ n := by
  induction n with
/- First, consider the base case where \( n = 0 \). We need to show that \( a^{m + 0} = a^m \cdot a^0 \). Using the properties of addition and power, we have:
1. \( m + 0 = m \) (since adding zero to any number \( m \) does not change it).
2. \( a^0 = 1 \) (since any number raised to the power of zero is 1).
3. \( a^m \cdot 1 = a^m \) (since multiplying any number \( a^m \) by 1 does not change it).

Thus, the goal \( a^{m + 0} = a^m \cdot a^0 \) simplifies to \( a^m = a^m \), which is trivially true. -/
  | zero => rw [Nat.add_zero, Nat.pow_zero, Nat.mul_one]
/- Next, consider the inductive step where \( n = k + 1 \) for some natural number \( k \). We assume the inductive hypothesis \( a^{m + k} = a^m \cdot a^k \) and need to show that \( a^{m + (k + 1)} = a^m \cdot a^{k + 1} \). Using the properties of addition and power, we have:
1. \( m + (k + 1) = (m + k) + 1 \) (since addition is associative).
2. \( a^{(m + k) + 1} = a^{m + k} \cdot a \) (since raising a number to the power of a successor is equivalent to multiplying the number raised to the original power by the number itself).
3. By the inductive hypothesis, \( a^{m + k} = a^m \cdot a^k \).
4. Substituting the inductive hypothesis, we get \( a^{(m + k) + 1} = (a^m \cdot a^k) \cdot a \).
5. Using the associativity of multiplication, \( (a^m \cdot a^k) \cdot a = a^m \cdot (a^k \cdot a) \).
6. Finally, \( a^m \cdot (a^k \cdot a) = a^m \cdot a^{k + 1} \) (since \( a^k \cdot a = a^{k + 1} \)).

Thus, the goal \( a^{m + (k + 1)} = a^m \cdot a^{k + 1} \) is satisfied. -/
  | succ _ ih => rw [Nat.add_succ, Nat.pow_succ, Nat.pow_succ, ih, Nat.mul_assoc]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32490,Nat.log2_lt,theorem Nat.log2_lt (h : n ≠ 0) : n.log2 < k ↔ n < 2 ^ k := by sorry,"Base 2 Logarithm of a Nonzero Natural Number is Less Than \( k \) if and only if \( n < 2^k \) : For any natural numbers \( n \) and \( k \) such that \( n \neq 0 \), the base 2 logarithm of \( n \), denoted as \( \lfloor \log_2 n \rfloor \), is strictly less than \( k \) if and only if \( n \) is strictly less than \( 2^k \). Formally, \( \lfloor \log_2 n \rfloor < k \) if and only if \( n < 2^k \).","theorem Nat.log2_lt (h : n ≠ 0) : n.log2 < k ↔ n < 2 ^ k := by
  rw [← Nat.not_le, ← Nat.not_le, le_log2 h]","We start by noting that the negation of \( a \leq b \) is equivalent to \( b < a \). Therefore, we can rewrite the goal \( n.\log_2 < k \) as \( \neg (k \leq n.\log_2) \) and \( n < 2^k \) as \( \neg (2^k \leq n) \).

Next, we use the theorem that for any natural numbers \( n \) and \( k \) such that \( n \neq 0 \), \( k \leq \lfloor \log_2 n \rfloor \) if and only if \( 2^k \leq n \). This allows us to rewrite \( \neg (k \leq n.\log_2) \) as \( \neg (2^k \leq n) \).

Thus, our goal becomes \( \neg (2^k \leq n) \leftrightarrow \neg (2^k \leq n) \), which is trivially true. Therefore, we have shown that \( \lfloor \log_2 n \rfloor < k \) if and only if \( n < 2^k \).

This completes the proof. \(\blacksquare\)","theorem Nat.log2_lt (h : n ≠ 0) : n.log2 < k ↔ n < 2 ^ k := by
/- First, we use the equivalence that the negation of \( a \leq b \) is \( b < a \) to rewrite the goal. Specifically, we rewrite \( n.\log_2 < k \) as \( \neg (k \leq n.\log_2) \) and \( n < 2^k \) as \( \neg (2^k \leq n) \). Then, we use the theorem that for any natural numbers \( n \) and \( k \) such that \( n \neq 0 \), \( k \leq \lfloor \log_2 n \rfloor \) if and only if \( 2^k \leq n \). This transforms our goal into \( \neg (2^k \leq n) \leftrightarrow \neg (2^k \leq n) \), which is trivially true. -/
  rw [← Nat.not_le, ← Nat.not_le, le_log2 h]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32491,Nat.sub_mul_mod,theorem Nat.sub_mul_mod {x k n : Nat} (h₁ : n*k ≤ x) : (x - n*k) % n = x % n := by sorry,"Subtraction and Modulo Identity: \((x - n \cdot k) \% n = x \% n\) for \( n \cdot k \leq x \) : For any natural numbers \( x \), \( k \), and \( n \), if \( n \cdot k \leq x \), then the remainder of \( (x - n \cdot k) \) when divided by \( n \) is equal to the remainder of \( x \) when divided by \( n \). In other words, if \( n \cdot k \leq x \), then \((x - n \cdot k) \% n = x \% n\).","theorem Nat.sub_mul_mod {x k n : Nat} (h₁ : n*k ≤ x) : (x - n*k) % n = x % n := by
  match k with
  | 0 => rw [Nat.mul_zero, Nat.sub_zero]
  | succ k =>
    have h₂ : n * k ≤ x := Nat.le_trans (le_add_right _ n) h₁
    have h₄ : x - n * k ≥ n := by
      apply Nat.le_of_add_le_add_right (b := n * k)
      rw [Nat.sub_add_cancel h₂]
      simp [mul_succ, Nat.add_comm] at h₁; simp [h₁]
    rw [mul_succ, ← Nat.sub_sub, ← mod_eq_sub_mod h₄, sub_mul_mod h₂]","We proceed by induction on \( k \).

**Base Case:**
For \( k = 0 \):
1. \( n \times 0 = 0 \)
2. \( x - 0 = x \)
Thus, \((x - n \times 0) \% n = x \% n\) simplifies to \( x \% n = x \% n \), which is trivially true.

**Inductive Step:**
Assume the statement holds for \( k \), i.e., \((x - n \times k) \% n = x \% n\). We need to show that it holds for \( k + 1 \), i.e., \((x - n \times (k + 1)) \% n = x \% n\).

1. We construct a new lemma \( h₂ \) that \( n \times k \leq x \) by using the transitivity of the less than or equal to relation. Specifically, since \( n \times k \leq n \times k + n \) and \( n \times k + n \leq x \) (by the assumption \( n \times (k + 1) \leq x \)), it follows that \( n \times k \leq x \).
2. We construct a new lemma \( h₄ \) that \( x - n \times k \geq n \) by using the right addition cancellation property. Specifically, since \( n \times k \leq x \), it follows that \( x - n \times k \geq n \).
3. To prove \( x - n \times k \geq n \), it suffices to show that \( n + n \times k \leq x \) by using the right addition cancellation property. Specifically, if \( n + n \times k \leq x \), then \( x - n \times k \geq n \).
4. We use the identity \( a - b + b = a \) to rewrite the goal. Specifically, since \( n \times k \leq x \), it follows that \( n + n \times k \leq x \) simplifies to \( n + n \times k \leq x \).
5. We simplify the hypothesis \( h₁ \) using the commutativity of addition and the identity for multiplication by successor. Specifically, \( n \times (k + 1) = n \times k + n \) and \( n + n \times k = n \times k + n \). Thus, the hypothesis \( n \times (k + 1) \leq x \) simplifies to \( n + n \times k \leq x \), which is trivially true.

Therefore, by induction, the statement holds for all \( k \). This completes the proof. \(\blacksquare\)","theorem Nat.sub_mul_mod {x k n : Nat} (h₁ : n*k ≤ x) : (x - n*k) % n = x % n := by
  match k with
/- For the base case \( k = 0 \), we use the identities:
1. \( n \times 0 = 0 \)
2. \( x - 0 = x \)

Thus, the goal \((x - n \times 0) \% n = x \% n\) simplifies to \( x \% n = x \% n \), which is trivially true. -/
  | 0 => rw [Nat.mul_zero, Nat.sub_zero]
/- For the inductive step \( k = k + 1 \), we need to show that \((x - n \times (k + 1)) \% n = x \% n\). -/
  | succ k =>
/- We construct a new lemma \( h₂ \) that \( n \times k \leq x \) by using the transitivity of the less than or equal to relation. Specifically, since \( n \times k \leq n \times k + n \) and \( n \times k + n \leq x \) (by the assumption \( n \times (k + 1) \leq x \)), it follows that \( n \times k \leq x \). -/
    have h₂ : n * k ≤ x := Nat.le_trans (le_add_right _ n) h₁
/- We construct a new lemma \( h₄ \) that \( x - n \times k \geq n \) by using the right addition cancellation property. Specifically, since \( n \times k \leq x \), it follows that \( x - n \times k \geq n \). -/
    have h₄ : x - n * k ≥ n := by
/- To prove \( x - n \times k \geq n \), it suffices to show that \( n + n \times k \leq x \) by using the right addition cancellation property. Specifically, if \( n + n \times k \leq x \), then \( x - n \times k \geq n \). -/
      apply Nat.le_of_add_le_add_right (b := n * k)
/- We use the identity \( a - b + b = a \) to rewrite the goal. Specifically, since \( n \times k \leq x \), it follows that \( n + n \times k \leq x \) simplifies to \( n + n \times k \leq x \). -/
      rw [Nat.sub_add_cancel h₂]
/- We simplify the hypothesis \( h₁ \) using the commutativity of addition and the identity for multiplication by successor. Specifically, \( n \times (k + 1) = n \times k + n \) and \( n + n \times k = n \times k + n \). Thus, the hypothesis \( n \times (k + 1) \leq x \) simplifies to \( n + n \times k \leq x \), which is trivially true. -/
      simp [mul_succ, Nat.add_comm] at h₁; simp [h₁]
/- We use the following identities to rewrite the goal:
1. \( n \times (k + 1) = n \times k + n \)
2. \( x - n \times k - n = x - (n \times k + n) \)
3. \( (x - n \times k) \% n = x \% n \) (since \( x - n \times k \geq n \))
4. \( (x - n \times k) \% n = x \% n \) (since \( n \times k \leq x \))

Thus, the goal \((x - n \times k.succ) \% n = x \% n\) is equivalent to \( (x - (n \times k + n)) \% n = x \% n \), which simplifies to \((x - n \times k - n) \% n = x \% n\), and further to \((x - n \times k) \% n = x \% n\). -/
    rw [mul_succ, ← Nat.sub_sub, ← mod_eq_sub_mod h₄, sub_mul_mod h₂]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32494,Nat.mul_add_mod,theorem Nat.mul_add_mod (m x y : Nat) : (m * x + y) % m = y % m := by sorry,"Modulo of Sum of Multiples and Remainder in Natural Numbers: \((m \cdot x + y) \% m = y \% m\) : For any natural numbers \( m \), \( x \), and \( y \), the remainder of the sum \( m \cdot x + y \) when divided by \( m \) is equal to the remainder of \( y \) when divided by \( m \), i.e., \((m \cdot x + y) \% m = y \% m\).","theorem Nat.mul_add_mod (m x y : Nat) : (m * x + y) % m = y % m := by
  match x with
  | 0 => simp
  | x + 1 =>
    simp [Nat.mul_succ, Nat.add_assoc _ m, mul_add_mod _ x]","We will prove this by induction on \( x \).

**Base Case:**
Consider \( x = 0 \). We need to show that \((m \cdot 0 + y) \% m = y \% m\). Simplifying the left-hand side, we get:
\[
(m \cdot 0 + y) \% m = (0 + y) \% m = y \% m
\]
This is trivially true.

**Inductive Step:**
Assume the statement holds for some \( x = x' \), i.e., \((m \cdot x' + y) \% m = y \% m\). We need to show that it holds for \( x = x' + 1 \), i.e., \((m \cdot (x' + 1) + y) \% m = y \% m\).

Using the properties of multiplication and addition, we can rewrite the left-hand side as:
\[
(m \cdot (x' + 1) + y) \% m = (m \cdot x' + m + y) \% m
\]
By the associativity of addition, this can be further simplified to:
\[
(m \cdot x' + (m + y)) \% m
\]
Using the property of modulo, we know that \((a + b) \% m = (a \% m + b \% m) \% m\). Applying this property, we get:
\[
(m \cdot x' + (m + y)) \% m = (m \cdot x' \% m + (m + y) \% m) \% m
\]
Since \( m \cdot x' \% m = 0 \) (because \( m \cdot x' \) is a multiple of \( m \)), and \( (m + y) \% m = y \% m \) (because \( m \% m = 0 \)), we have:
\[
(0 + y \% m) \% m = y \% m
\]
Thus, the left-hand side simplifies to \( y \% m \), which is equal to the right-hand side. This completes the inductive step.

By the principle of mathematical induction, the statement holds for all natural numbers \( x \). Therefore, for any natural numbers \( m \), \( x \), and \( y \), we have:
\[
(m \cdot x + y) \% m = y \% m
\]
This completes the proof.","theorem Nat.mul_add_mod (m x y : Nat) : (m * x + y) % m = y % m := by
  match x with
/- First, consider the base case where \( x = 0 \). We need to show that \((m \cdot 0 + y) \% m = y \% m\). Simplifying the left-hand side, we get \((0 + y) \% m = y \% m\), which is trivially true. -/
  | 0 => simp
  | x + 1 =>
/- Next, consider the inductive step where \( x = x' + 1 \). We need to show that \((m \cdot (x' + 1) + y) \% m = y \% m\). Using the properties of multiplication and addition, we can rewrite the left-hand side as follows:
\[
(m \cdot (x' + 1) + y) \% m = (m \cdot x' + m + y) \% m
\]
By the associativity of addition, this can be further simplified to:
\[
(m \cdot x' + (m + y)) \% m
\]
Using the property of modulo, we know that \((a + b) \% m = (a \% m + b \% m) \% m\). Applying this property, we get:
\[
(m \cdot x' + (m + y)) \% m = (m \cdot x' \% m + (m + y) \% m) \% m
\]
Since \( m \cdot x' \% m = 0 \) (because \( m \cdot x' \) is a multiple of \( m \)), and \( (m + y) \% m = y \% m \) (because \( m \% m = 0 \)), we have:
\[
(0 + y \% m) \% m = y \% m
\]
Thus, the left-hand side simplifies to \( y \% m \), which is equal to the right-hand side. This completes the inductive step. -/
    simp [Nat.mul_succ, Nat.add_assoc _ m, mul_add_mod _ x]","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32514,Nat.le_log2,theorem Nat.le_log2 (h : n ≠ 0) : k ≤ n.log2 ↔ 2 ^ k ≤ n := by sorry,"Base 2 Logarithm of a Nonzero Natural Number is Greater Than or Equal to \( k \) if and only if \( 2^k \leq n \) : For any natural numbers \( n \) and \( k \) such that \( n \neq 0 \), it holds that \( k \leq \lfloor \log_2 n \rfloor \) if and only if \( 2^k \leq n \).","theorem Nat.le_log2 (h : n ≠ 0) : k ≤ n.log2 ↔ 2 ^ k ≤ n := by
  match k with
  | 0 => simp [show 1 ≤ n from Nat.pos_of_ne_zero h]
  | k+1 =>
    rw [log2]; split
    · have n0 : 0 < n / 2 := (Nat.le_div_iff_mul_le (by decide)).2 ‹_›
      simp only [Nat.add_le_add_iff_right, le_log2 (Nat.ne_of_gt n0), le_div_iff_mul_le,
        Nat.pow_succ]
      exact Nat.le_div_iff_mul_le (by decide)
    · simp only [le_zero_eq, succ_ne_zero, false_iff]
      refine mt (Nat.le_trans ?_) ‹_›
      exact Nat.pow_le_pow_of_le_right Nat.zero_lt_two (Nat.le_add_left 1 k)","We proceed by induction on \( k \).

**Base Case:**
For \( k = 0 \), we need to show that \( 0 \leq \lfloor \log_2 n \rfloor \) if and only if \( 2^0 \leq n \). Since \( n \neq 0 \), we have \( 1 \leq n \), which is equivalent to \( 2^0 \leq n \).

**Inductive Step:**
Assume the statement holds for \( k \). We need to show that \( k + 1 \leq \lfloor \log_2 n \rfloor \) if and only if \( 2^{k+1} \leq n \).

**Case 1: \( n \geq 2 \)**
We use the definition of \(\lfloor \log_2 n \rfloor\):
\[
\lfloor \log_2 n \rfloor = \lfloor \log_2 (n / 2) \rfloor + 1
\]
We need to show:
\[
k + 1 \leq \lfloor \log_2 (n / 2) \rfloor + 1 \iff 2^{k+1} \leq n
\]
This simplifies to:
\[
k \leq \lfloor \log_2 (n / 2) \rfloor \iff 2^k \leq n / 2
\]
By the inductive hypothesis, \( k \leq \lfloor \log_2 (n / 2) \rfloor \) if and only if \( 2^k \leq n / 2 \). Therefore, \( 2^k \leq n / 2 \) is equivalent to \( 2^k \cdot 2 \leq n \), which is \( 2^{k+1} \leq n \).

**Case 2: \( n < 2 \)**
We simplify the goal using the properties of natural numbers:
\[
k + 1 \leq 0 \iff 2^{k+1} \leq n
\]
Since \( k + 1 \leq 0 \) is false for any natural number \( k \), \( 2^{k+1} \leq n \) is also false.

Thus, the statement holds for all \( k \) and \( n \neq 0 \). This completes the proof. \(\blacksquare\)","theorem Nat.le_log2 (h : n ≠ 0) : k ≤ n.log2 ↔ 2 ^ k ≤ n := by
  match k with
/- For the base case where \(k = 0\), we need to show that \(0 \leq \lfloor \log_2 n \rfloor\) if and only if \(2^0 \leq n\). Since \(n \neq 0\), we have \(1 \leq n\), which is equivalent to \(2^0 \leq n\). -/
  | 0 => simp [show 1 ≤ n from Nat.pos_of_ne_zero h]
/- For the inductive step where \(k = k + 1\), we need to show that \(k + 1 \leq \lfloor \log_2 n \rfloor\) if and only if \(2^{k+1} \leq n\). -/
  | k+1 =>
/- We use the definition of \(\lfloor \log_2 n \rfloor\) to rewrite the goal. The definition states that \(\lfloor \log_2 n \rfloor = \lfloor \log_2 (n / 2) \rfloor + 1\) if \(n \geq 2\), and \(0\) otherwise. We then split the goal into two cases: \(n \geq 2\) and \(n < 2\). -/
    rw [log2]; split
/- In the case where \(n \geq 2\), we show that \(0 < n / 2\). This follows from the fact that \(n \geq 2\) implies \(n / 2 \geq 1\), and thus \(0 < n / 2\). -/
    · have n0 : 0 < n / 2 := (Nat.le_div_iff_mul_le (by decide)).2 ‹_›
/- We simplify the goal using the properties of addition, the inductive hypothesis, and the definition of exponentiation. Specifically, we use the fact that \(k + 1 \leq \lfloor \log_2 (n / 2) \rfloor + 1\) is equivalent to \(2^k \leq n / 2\), and \(2^k \leq n / 2\) is equivalent to \(2^k \cdot 2 \leq n\). -/
      simp only [Nat.add_le_add_iff_right, le_log2 (Nat.ne_of_gt n0), le_div_iff_mul_le,
        Nat.pow_succ]
/- We use the property that \(2^k \leq n / 2\) is equivalent to \(2^k \cdot 2 \leq n\), which completes the proof for the case \(n \geq 2\). -/
      exact Nat.le_div_iff_mul_le (by decide)
/- In the case where \(n < 2\), we simplify the goal using the properties of natural numbers. Specifically, \(k + 1 \leq 0\) is equivalent to \(k + 1 = 0\), which is false for any natural number \(k\). Therefore, \(2^{k+1} \leq n\) is also false. -/
    · simp only [le_zero_eq, succ_ne_zero, false_iff]
/- We use the property of transitivity of the less than or equal to relation to show that \(2 \leq 2^{k+1}\) implies \(2 \leq n\). This completes the proof for the case \(n < 2\). -/
      refine mt (Nat.le_trans ?_) ‹_›
/- First, we use the fact that \(2\) is greater than \(0\) and the property that adding \(1\) to \(k\) results in a number greater than or equal to \(1\). Therefore, \(2^1 \leq 2^{k+1}\), which simplifies to \(2 \leq 2^{k+1}\). -/
/- We use the fact that \(2\) is greater than \(0\) and the property that adding \(1\) to \(k\) results in a number greater than or equal to \(1\). Therefore, \(2^1 \leq 2^{k+1}\), which simplifies to \(2 \leq 2^{k+1}\). -/
      exact Nat.pow_le_pow_of_le_right Nat.zero_lt_two (Nat.le_add_left 1 k)","import Init.Data.Nat.MinMax
import Init.Data.Nat.Log2
import Init.Data.Nat.Power2
import Init.Omega
import Init.Data.Nat.Lemmas

open Nat

"
32554,not_true_eq_false,theorem not_true_eq_false : (¬ True) = False := by sorry,"Negation of True is False: $\neg \text{True} = \text{False}$ : The negation of the true proposition is equal to the false proposition, i.e., $\neg \text{True} = \text{False}$.","theorem not_true_eq_false : (¬ True) = False := by
  decide","We need to show that the negation of the true proposition is equal to the false proposition. By the decidability of the equality of propositions, we directly conclude that $\neg \text{True} = \text{False}$. This completes the proof. $\blacksquare$","theorem not_true_eq_false : (¬ True) = False := by
  decide","import Init.Core
import Init.SimpLemmas



"
32559,ite_cond_eq_true,theorem ite_cond_eq_true {α : Sort u} {c : Prop} {_ : Decidable c} (a b : α) (h : c = True) : (if c then a else b) = a := by sorry,"If-Then-Else Function Returns First Argument When Condition is True: $\text{ite}(c, a, b) = a$ if $c = \text{True}$ : For any type $\alpha$ and any proposition $c$, if $c$ is true, then the if-then-else function `ite` evaluated at $c$ with values $a$ and $b$ of type $\alpha$ returns $a$, i.e., $\text{ite}(c, a, b) = a$.","theorem ite_cond_eq_true {α : Sort u} {c : Prop} {_ : Decidable c} (a b : α) (h : c = True) : (if c then a else b) = a := by
  simp [h]","We start with the hypothesis that $c = \text{True}$. Using this hypothesis, we can simplify the expression $\text{ite}(c, a, b)$. By the definition of the if-then-else function, $\text{ite}(c, a, b)$ returns $a$ when $c$ is true. Therefore, $\text{ite}(c, a, b) = a$. This completes the proof. $\blacksquare$","theorem ite_cond_eq_true {α : Sort u} {c : Prop} {_ : Decidable c} (a b : α) (h : c = True) : (if c then a else b) = a := by
  simp [h]","import Init.Core
import Init.SimpLemmas



"
32562,dite_cond_eq_true,theorem dite_cond_eq_true {α : Sort u} {c : Prop} {_ : Decidable c} {t : c → α} {e : ¬ c → α} (h : c = True) : (dite c t e) = t (of_eq_true h) := by sorry,"Dependent If-Then-Else Evaluates to True Branch: $c = \text{True} \implies \text{dite}(c, t, e) = t(h)$ : For any type $\alpha$, proposition $c$, and decidable proof $x$ of $c$, if $c$ is true, then the dependent if-then-else construct `dite c t e` evaluates to the value $t(h)$, where $h$ is a proof of $c$. Formally, if $c = \text{True}$, then $\text{dite}(c, t, e) = t(h)$.","theorem dite_cond_eq_true {α : Sort u} {c : Prop} {_ : Decidable c} {t : c → α} {e : ¬ c → α} (h : c = True) : (dite c t e) = t (of_eq_true h) := by
  simp [h]","We start with the assumption that $c = \text{True}$. Using this assumption, we can simplify the expression $\text{dite}(c, t, e)$. By the definition of the dependent if-then-else construct, $\text{dite}(c, t, e)$ evaluates to $t(h)$ when $c$ is true, where $h$ is a proof of $c$. Therefore, we have $\text{dite}(c, t, e) = t(h)$. This completes the proof. $\blacksquare$","theorem dite_cond_eq_true {α : Sort u} {c : Prop} {_ : Decidable c} {t : c → α} {e : ¬ c → α} (h : c = True) : (dite c t e) = t (of_eq_true h) := by
  simp [h]","import Init.Core
import Init.SimpLemmas



"
32563,ite_cond_eq_false,theorem ite_cond_eq_false {α : Sort u} {c : Prop} {_ : Decidable c} (a b : α) (h : c = False) : (if c then a else b) = b := by sorry,"If-then-else Function Returns Second Argument if Condition is False: $\text{ite}(c, a, b) = b$ if $c = \text{False}$ : For any type $\alpha$ and any proposition $c$, if $c$ is false, then the if-then-else function `ite` returns the second argument $b$. Formally, for any elements $a, b \in \alpha$, if $c = \text{False}$, then $\text{ite}(c, a, b) = b$.","theorem ite_cond_eq_false {α : Sort u} {c : Prop} {_ : Decidable c} (a b : α) (h : c = False) : (if c then a else b) = b := by
  simp [h]","We start with the hypothesis that $c = \text{False}$. Using this hypothesis, we can simplify the expression $\text{ite}(c, a, b)$. By the definition of the if-then-else function, $\text{ite}(c, a, b)$ returns the second argument $b$ when the condition $c$ is false. Therefore, $\text{ite}(c, a, b) = b$ is trivially true. This completes the proof. $\blacksquare$","theorem ite_cond_eq_false {α : Sort u} {c : Prop} {_ : Decidable c} (a b : α) (h : c = False) : (if c then a else b) = b := by
  simp [h]","import Init.Core
import Init.SimpLemmas



"
32570,ite_self,theorem ite_self {α : Sort u} {c : Prop} {d : Decidable c} (a : α) : ite c a a = a := by sorry,"If-then-else with Identical Branches Equals the Branch Value: $\text{ite}(c, a, a) = a$ : For any type $\alpha$ and any proposition $c$, if $a \in \alpha$, then the if-then-else function `ite` evaluated with the same value $a$ for both the true and false branches is equal to $a$, i.e., $\text{ite}(c, a, a) = a$.","theorem ite_self {α : Sort u} {c : Prop} {d : Decidable c} (a : α) : ite c a a = a := by
  cases d <;> rfl","We need to show that $\text{ite}(c, a, a) = a$ for any type $\alpha$, any proposition $c$, and any element $a \in \alpha$. We will consider every possible case of the decidable proposition $c$.

1. **Case 1: $c$ is true.**
- In this case, $\text{ite}(c, a, a)$ evaluates to $a$ by the definition of the if-then-else function.
- Therefore, $\text{ite}(c, a, a) = a$ holds trivially.

2. **Case 2: $c$ is false.**
- In this case, $\text{ite}(c, a, a)$ also evaluates to $a$ by the definition of the if-then-else function.
- Therefore, $\text{ite}(c, a, a) = a$ holds trivially.

Since both cases lead to the same conclusion, we have shown that $\text{ite}(c, a, a) = a$ for any $a \in \alpha$. This completes the proof. $\blacksquare$","theorem ite_self {α : Sort u} {c : Prop} {d : Decidable c} (a : α) : ite c a a = a := by
  cases d <;> rfl","import Init.Core
import Init.SimpLemmas



"
32572,or_self_left,theorem or_self_left : a ∨ (a ∨ b) ↔ a ∨ b := by sorry,"Disjunction with Repeated Proposition is Equivalent to Simple Disjunction: \( a \lor a \lor b \leftrightarrow a \lor b \) : For any propositions \( a \) and \( b \), the disjunction \( a \lor a \lor b \) is logically equivalent to \( a \lor b \), i.e., \( a \lor a \lor b \leftrightarrow a \lor b \).","theorem or_self_left : a ∨ (a ∨ b) ↔ a ∨ b := by
  rw [←propext or_assoc, or_self]","To prove that \( a \lor a \lor b \leftrightarrow a \lor b \), we start by using the associativity of disjunction. The associativity of disjunction states that \((a \lor a) \lor b\) is logically equivalent to \(a \lor a \lor b\). Therefore, we can rewrite our goal as \((a \lor a) \lor b \leftrightarrow a \lor b\).

Next, we use the idempotence of disjunction, which states that \(a \lor a = a\). Applying this property, we simplify \((a \lor a) \lor b\) to \(a \lor b\). Thus, our goal reduces to \(a \lor b \leftrightarrow a \lor b\), which is trivially true by the properties of equality.

Therefore, we have shown that \( a \lor a \lor b \leftrightarrow a \lor b \). This completes the proof. \(\blacksquare\)","theorem or_self_left : a ∨ (a ∨ b) ↔ a ∨ b := by
  rw [←propext or_assoc, or_self]","import Init.Core
import Init.SimpLemmas



"
32574,and_self_left,theorem and_self_left : a ∧ (a ∧ b) ↔ a ∧ b := by sorry,"Left Conjunction with Self is Equivalent to Conjunction : For any propositions \( a \) and \( b \), the conjunction \( a \land a \land b \) is logically equivalent to \( a \land b \), i.e., \( a \land a \land b \leftrightarrow a \land b \).","theorem and_self_left : a ∧ (a ∧ b) ↔ a ∧ b := by
  rw [←propext and_assoc, and_self]","To prove that \( a \land a \land b \leftrightarrow a \land b \), we start by using the associativity of conjunction. The associativity of conjunction states that \((a \land a) \land b\) is logically equivalent to \(a \land a \land b\). Therefore, we can rewrite the goal as:
\[
(a \land a) \land b \leftrightarrow a \land b
\]
Next, we use the idempotence of conjunction, which states that \(a \land a\) is equal to \(a\). Applying this, we get:
\[
a \land b \leftrightarrow a \land b
\]
This is a trivially true statement, as it is an equality of the same expression on both sides. Therefore, we have shown that:
\[
a \land a \land b \leftrightarrow a \land b
\]
This completes the proof.","theorem and_self_left : a ∧ (a ∧ b) ↔ a ∧ b := by
  rw [←propext and_assoc, and_self]","import Init.Core
import Init.SimpLemmas



"
32575,or_self_right,theorem or_self_right : (a ∨ b) ∨ b ↔ a ∨ b := by sorry,"Disjunction with Self on the Right is Equivalent to Original Disjunction: \((a \lor b) \lor b \leftrightarrow a \lor b\) : For any propositions \( a \) and \( b \), the disjunction \((a \lor b) \lor b\) is logically equivalent to \( a \lor b \), i.e., \((a \lor b) \lor b \leftrightarrow a \lor b\).","theorem or_self_right : (a ∨ b) ∨ b ↔ a ∨ b := by
  rw [ propext or_assoc, or_self]","To prove that \((a \lor b) \lor b \leftrightarrow a \lor b\), we start by using the associativity of disjunction. The associativity of disjunction states that \((a \lor b) \lor c\) is logically equivalent to \(a \lor b \lor c\). Applying this to our goal, we can rewrite \((a \lor b) \lor b\) as \(a \lor b \lor b\).

Next, we use the idempotence of disjunction, which states that \(p \lor p\) is equal to \(p\). Applying this to our new goal, we can simplify \(a \lor b \lor b\) to \(a \lor b\). Therefore, the goal \((a \lor b) \lor b \leftrightarrow a \lor b\) is equivalent to \(a \lor b \leftrightarrow a \lor b\), which is trivially true by the properties of equality.

Thus, we have shown that \((a \lor b) \lor b \leftrightarrow a \lor b\). This completes the proof.","theorem or_self_right : (a ∨ b) ∨ b ↔ a ∨ b := by
  rw [ propext or_assoc, or_self]","import Init.Core
import Init.SimpLemmas



"
32578,iff_self_and,theorem iff_self_and : (p ↔ p ∧ q) ↔ (p → q) := by sorry,"Bi-implication with Conjunction: \( p \leftrightarrow p \land q \) if and only if \( p \to q \) : For any propositions \( p \) and \( q \), the bi-implication \( p \leftrightarrow p \land q \) holds if and only if \( p \) implies \( q \), i.e., \( p \leftrightarrow p \land q \) if and only if \( p \to q \).","theorem iff_self_and : (p ↔ p ∧ q) ↔ (p → q) := by
  rw [@Iff.comm p, and_iff_left_iff_imp]","To prove the theorem, we start with the goal \( (p \leftrightarrow p \land q) \leftrightarrow (p \to q) \).

1. **Step 1: Symmetry of Bi-implication**
- We use the symmetry of the bi-implication to rewrite \( p \leftrightarrow p \land q \) as \( p \land q \leftrightarrow p \). This is valid because the bi-implication is symmetric, i.e., \( p \leftrightarrow q \) is equivalent to \( q \leftrightarrow p \).

2. **Step 2: Conjunction Identity**
- Next, we use the equivalence that \( p \land q \leftrightarrow p \) holds if and only if \( p \to q \). This equivalence states that the bi-implication \( p \land q \leftrightarrow p \) is true if and only if \( p \) implies \( q \).

3. **Step 3: Simplification**
- Combining these two steps, the goal \( (p \leftrightarrow p \land q) \leftrightarrow (p \to q) \) is equivalent to \( (p \land q \leftrightarrow p) \leftrightarrow (p \to q) \), which simplifies to \( (p \to q) \leftrightarrow (p \to q) \).

4. **Step 4: Reflexivity**
- The statement \( (p \to q) \leftrightarrow (p \to q) \) is trivially true by the reflexivity of the bi-implication, which states that any proposition is equivalent to itself.

Therefore, we have shown that \( (p \leftrightarrow p \land q) \leftrightarrow (p \to q) \) is true, completing the proof.","theorem iff_self_and : (p ↔ p ∧ q) ↔ (p → q) := by
  rw [@Iff.comm p, and_iff_left_iff_imp]","import Init.Core
import Init.SimpLemmas



"
32579,Bool.not_false,theorem Bool.not_false : (!false) = true := by sorry,"Negation of False is True : The negation of the boolean value `false` is `true`, i.e., $\text{not}(\text{false}) = \text{true}$.","theorem Bool.not_false : (!false) = true := by
  decide","To prove that the negation of the boolean value `false` is `true`, we directly evaluate the expression $\text{not}(\text{false})$. By the definition of the negation operation on boolean values, $\text{not}(\text{false})$ is equal to $\text{true}$. Therefore, we have $\text{not}(\text{false}) = \text{true}$. This completes the proof. $\blacksquare$","theorem Bool.not_false : (!false) = true := by
  decide","import Init.Core
import Init.SimpLemmas

open Bool

"
32580,Bool.or_false,theorem Bool.or_false (b : Bool) : (b || false) = b := by sorry,"Boolean Or with False is Identity: $b \lor \text{false} = b$ : For any boolean value $b$, the boolean ""or"" operation between $b$ and `false` is equal to $b$, i.e., $b \lor \text{false} = b$.","theorem Bool.or_false (b : Bool) : (b || false) = b := by
  cases b <;> rfl","We will consider every possible case of the boolean value $b$.

1. **Case 1: $b = \text{false}$**
- We need to show that $(\text{false} \lor \text{false}) = \text{false}$.
- This equality holds trivially because both sides are definitionally equal.

2. **Case 2: $b = \text{true}$**
- We need to show that $(\text{true} \lor \text{false}) = \text{true}$.
- This equality holds trivially because both sides are definitionally equal.

Since both cases are covered and the equality holds in each case, we conclude that for any boolean value $b$, the boolean ""or"" operation between $b$ and `false` is equal to $b$. Therefore, $b \lor \text{false} = b$. This completes the proof.","theorem Bool.or_false (b : Bool) : (b || false) = b := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas

open Bool

"
32581,and_congr_left_iff,theorem and_congr_left_iff : (a ∧ c ↔ b ∧ c) ↔ c → (a ↔ b) := by sorry,"Conjunction Equivalence Implies Propositional Equivalence: \( (a \land c \leftrightarrow b \land c) \leftrightarrow (c \to (a \leftrightarrow b)) \) : For any propositions \( a \), \( b \), and \( c \), the conjunctions \( a \land c \) and \( b \land c \) are logically equivalent if and only if \( c \) implies that \( a \) and \( b \) are logically equivalent, i.e., \( a \land c \leftrightarrow b \land c \) if and only if \( c \to (a \leftrightarrow b) \).","theorem and_congr_left_iff : (a ∧ c ↔ b ∧ c) ↔ c → (a ↔ b) := by
  rw [@and_comm _ c, @and_comm _ c, ← and_congr_right_iff]","To prove the theorem, we start with the goal \( (a \land c \leftrightarrow b \land c) \leftrightarrow (c \to (a \leftrightarrow b)) \).

1. **Step 1:**
We use the commutativity of conjunction to rewrite the goal. Specifically, we apply the commutativity of conjunction to both sides of the bi-implication \( a \land c \leftrightarrow b \land c \), which transforms it into \( c \land a \leftrightarrow c \land b \). This step is justified by the theorem that states \( a \land b \leftrightarrow b \land a \) for any propositions \( a \) and \( b \).

2. **Step 2:**
Next, we use the theorem that states \( (a \land b) \leftrightarrow (a \land c) \) if and only if \( a \to (b \leftrightarrow c) \) to rewrite the goal again. This theorem allows us to transform the goal \( (c \land a \leftrightarrow c \land b) \) into \( c \to (a \leftrightarrow b) \).

3. **Step 3:**
After these transformations, the goal becomes \( (c \land a \leftrightarrow c \land b) \leftrightarrow (c \to (a \leftrightarrow b)) \). Since the left-hand side of the bi-implication is now the same as the right-hand side, the goal is trivially true by reflexivity.

Thus, we have shown that \( (a \land c \leftrightarrow b \land c) \leftrightarrow (c \to (a \leftrightarrow b)) \), completing the proof.","theorem and_congr_left_iff : (a ∧ c ↔ b ∧ c) ↔ c → (a ↔ b) := by
/- First, we use the commutativity of conjunction to rewrite the goal. Specifically, we apply the commutativity of conjunction to both sides of the bi-implication \( a \land c \leftrightarrow b \land c \), which transforms it into \( c \land a \leftrightarrow c \land b \). Then, we use the theorem that states \( (a \land b) \leftrightarrow (a \land c) \) if and only if \( a \to (b \leftrightarrow c) \) to rewrite the goal again. This results in the goal \( (c \land a \leftrightarrow c \land b) \leftrightarrow (c \to (a \leftrightarrow b)) \). Since the left-hand side of the bi-implication is now the same as the right-hand side, the goal is trivially true by reflexivity. -/
  rw [@and_comm _ c, @and_comm _ c, ← and_congr_right_iff]","import Init.Core
import Init.SimpLemmas



"
32582,Bool.true_or,theorem Bool.true_or (b : Bool) : (true || b) = true := by sorry,"Boolean Or with True is True: $\text{true} \lor b = \text{true}$ : For any boolean value $b$, the boolean ""or"" operation of `true` with $b$ is equal to `true`, i.e., $\text{true} \lor b = \text{true}$.","theorem Bool.true_or (b : Bool) : (true || b) = true := by
  cases b <;> rfl","To prove that $\text{true} \lor b = \text{true}$ for any boolean value $b$, we will consider the two possible cases for $b$.

1. **Case 1: $b = \text{false}$**
- In this case, the expression $\text{true} \lor \text{false}$ is definitionally equal to $\text{true}$. Therefore, $\text{true} \lor \text{false} = \text{true}$ is trivially true.

2. **Case 2: $b = \text{true}$**
- In this case, the expression $\text{true} \lor \text{true}$ is definitionally equal to $\text{true}$. Therefore, $\text{true} \lor \text{true} = \text{true}$ is trivially true.

Since both cases are covered and the equality holds in each case, we conclude that for any boolean value $b$, $\text{true} \lor b = \text{true}$. This completes the proof. $\blacksquare$","theorem Bool.true_or (b : Bool) : (true || b) = true := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas

open Bool

"
32583,Bool.true_and,theorem Bool.true_and (b : Bool) : (true && b) = b := by sorry,"True is the Identity for Boolean AND: $\text{true} \land b = b$ : For any boolean value $b$, the boolean AND operation between `true` and $b$ is equal to $b$, i.e., $\text{true} \land b = b$.","theorem Bool.true_and (b : Bool) : (true && b) = b := by
  cases b <;> rfl","To prove the theorem, we consider every possible value of $b$.

**Case 1: $b = \text{false}$**
- We need to show that $(\text{true} \land \text{false}) = \text{false}$.
- By the definition of the boolean AND operation, $\text{true} \land \text{false} = \text{false}$.
- Therefore, the equality holds.

**Case 2: $b = \text{true}$**
- We need to show that $(\text{true} \land \text{true}) = \text{true}$.
- By the definition of the boolean AND operation, $\text{true} \land \text{true} = \text{true}$.
- Therefore, the equality holds.

Since both cases are covered and the equality holds in each case, we conclude that for any boolean value $b$, $\text{true} \land b = b$. This completes the proof. $\blacksquare$","theorem Bool.true_and (b : Bool) : (true && b) = b := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas

open Bool

"
32584,Bool.and_self,theorem Bool.and_self (b : Bool) : (b && b) = b := by sorry,"Boolean AND is Idempotent: \( b \land b = b \) : For any boolean value \( b \), the boolean ""and"" operation \( b \text{ and } b \) is equal to \( b \), i.e., \( b \land b = b \).","theorem Bool.and_self (b : Bool) : (b && b) = b := by
  cases b <;> rfl","We will consider every possible case of the boolean value \( b \).

**Case 1: \( b = \text{false} \)**
- The goal is to show that \( \text{false} \land \text{false} = \text{false} \).
- This is trivially true because the boolean ""and"" operation of \(\text{false}\) with itself is \(\text{false}\).

**Case 2: \( b = \text{true} \)**
- The goal is to show that \( \text{true} \land \text{true} = \text{true} \).
- This is trivially true because the boolean ""and"" operation of \(\text{true}\) with itself is \(\text{true}\).

Since both cases are trivially true, we conclude that for any boolean value \( b \), \( b \land b = b \). This completes the proof.","theorem Bool.and_self (b : Bool) : (b && b) = b := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas

open Bool

"
32585,Bool.false_or,theorem Bool.false_or (b : Bool) : (false || b) = b := by sorry,"False is the Identity for Boolean Or: $\text{false} \lor b = b$ : For any boolean value $b$, the boolean ""or"" operation between `false` and $b$ is equal to $b$, i.e., $\text{false} \lor b = b$.","theorem Bool.false_or (b : Bool) : (false || b) = b := by
  cases b <;> rfl","We will consider every possible case of $b$.

**Case 1: $b = \text{false}$**
- We need to show that $(\text{false} \lor \text{false}) = \text{false}$.
- By the definition of the boolean ""or"" operation, $\text{false} \lor \text{false} = \text{false}$.
- Therefore, the equality holds.

**Case 2: $b = \text{true}$**
- We need to show that $(\text{false} \lor \text{true}) = \text{true}$.
- By the definition of the boolean ""or"" operation, $\text{false} \lor \text{true} = \text{true}$.
- Therefore, the equality holds.

Since both cases are true, we conclude that for any boolean value $b$, $\text{false} \lor b = b$. This completes the proof.","theorem Bool.false_or (b : Bool) : (false || b) = b := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas

open Bool

"
32588,or_iff_right_iff_imp,theorem or_iff_right_iff_imp : (a ∨ b ↔ b) ↔ (a → b) := by sorry,"Disjunction Equivalence to Right Proposition if and only if Implication: \( a \lor b \leftrightarrow b \leftrightarrow a \to b \) : For any propositions \( a \) and \( b \), the disjunction \( a \lor b \) is logically equivalent to \( b \) if and only if \( a \) implies \( b \), i.e., \( a \lor b \leftrightarrow b \) if and only if \( a \to b \).","theorem or_iff_right_iff_imp : (a ∨ b ↔ b) ↔ (a → b) := by
  rw [or_comm, or_iff_left_iff_imp]","To prove the theorem, we start with the goal \( (a \lor b \leftrightarrow b) \leftrightarrow a \to b \).

1. **Step 1: Use the commutativity of disjunction.**
- By the commutativity of disjunction, \( a \lor b \leftrightarrow b \lor a \).
- Therefore, the goal \( (a \lor b \leftrightarrow b) \leftrightarrow a \to b \) can be rewritten as \( (b \lor a \leftrightarrow b) \leftrightarrow a \to b \).

2. **Step 2: Use the equivalence \( (b \lor a \leftrightarrow b) \leftrightarrow a \to b \).**
- The equivalence \( (b \lor a \leftrightarrow b) \leftrightarrow a \to b \) states that the disjunction \( b \lor a \) is logically equivalent to \( b \) if and only if \( a \) implies \( b \).
- Therefore, the goal \( (b \lor a \leftrightarrow b) \leftrightarrow a \to b \) simplifies to \( a \to b \leftrightarrow a \to b \).

3. **Step 3: Conclude the proof.**
- The statement \( a \to b \leftrightarrow a \to b \) is trivially true, as it is a tautology.

Thus, we have shown that \( (a \lor b \leftrightarrow b) \leftrightarrow a \to b \). This completes the proof.","theorem or_iff_right_iff_imp : (a ∨ b ↔ b) ↔ (a → b) := by
  rw [or_comm, or_iff_left_iff_imp]","import Init.Core
import Init.SimpLemmas



"
32590,Bool.or_true,theorem Bool.or_true (b : Bool) : (b || true) = true := by sorry,"Boolean Or with True is True: $b \lor \text{true} = \text{true}$ : For any boolean value $b$, the boolean ""or"" operation between $b$ and `true` is equal to `true`, i.e., $b \lor \text{true} = \text{true}$.","theorem Bool.or_true (b : Bool) : (b || true) = true := by
  cases b <;> rfl","We will consider every possible case of the boolean value $b$.

1. **Case 1: $b = \text{false}$**
- In this case, the expression $(\text{false} \lor \text{true})$ is equal to $\text{true}$ by the definition of the boolean ""or"" operation. Therefore, the equality $(\text{false} \lor \text{true}) = \text{true}$ holds.

2. **Case 2: $b = \text{true}$**
- In this case, the expression $(\text{true} \lor \text{true})$ is equal to $\text{true}$ by the definition of the boolean ""or"" operation. Therefore, the equality $(\text{true} \lor \text{true}) = \text{true}$ holds.

Since both cases have been verified, we conclude that for any boolean value $b$, the boolean ""or"" operation between $b$ and $\text{true}$ is equal to $\text{true}$. This completes the proof.","theorem Bool.or_true (b : Bool) : (b || true) = true := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas

open Bool

"
32592,Bool.or_self,theorem Bool.or_self (b : Bool) : (b || b) = b := by sorry,"Boolean Or is Idempotent: $b \lor b = b$ : For any boolean value $b$, the boolean ""or"" operation of $b$ with itself is equal to $b$, i.e., $b \lor b = b$.","theorem Bool.or_self (b : Bool) : (b || b) = b := by
  cases b <;> rfl","We will consider every possible case of the boolean value $b$.

1. **Case 1: $b = \text{false}$**
- In this case, the expression $(\text{false} \lor \text{false})$ is equal to $\text{false}$ by the definition of the boolean ""or"" operation. Therefore, the equality $(\text{false} \lor \text{false}) = \text{false}$ holds trivially.

2. **Case 2: $b = \text{true}$**
- In this case, the expression $(\text{true} \lor \text{true})$ is equal to $\text{true}$ by the definition of the boolean ""or"" operation. Therefore, the equality $(\text{true} \lor \text{true}) = \text{true}$ holds trivially.

Since both cases have been verified, we conclude that for any boolean value $b$, the boolean ""or"" operation of $b$ with itself is equal to $b$, i.e., $b \lor b = b$. This completes the proof.","theorem Bool.or_self (b : Bool) : (b || b) = b := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas

open Bool

"
32593,Bool.and_false,theorem Bool.and_false (b : Bool) : (b && false) = false := by sorry,"Boolean AND with False Equals False : For any boolean value $b$, the boolean ""and"" operation between $b$ and `false` is equal to `false`, i.e., $b \land \text{false} = \text{false}$.","theorem Bool.and_false (b : Bool) : (b && false) = false := by
  cases b <;> rfl","We will consider every possible case of the boolean value $b$.

1. **Case 1: $b = \text{false}$**
- The expression $(\text{false} \land \text{false})$ is definitionally equal to $\text{false}$.
- Therefore, the equality $(\text{false} \land \text{false}) = \text{false}$ holds trivially.

2. **Case 2: $b = \text{true}$**
- The expression $(\text{true} \land \text{false})$ is definitionally equal to $\text{false}$.
- Therefore, the equality $(\text{true} \land \text{false}) = \text{false}$ holds trivially.

Since both cases have been verified, we conclude that for any boolean value $b$, the boolean ""and"" operation between $b$ and $\text{false}$ is equal to $\text{false}$. This completes the proof.","theorem Bool.and_false (b : Bool) : (b && false) = false := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas

open Bool

"
32594,beq_false,theorem beq_false (b : Bool) : (b == false) = !b := by sorry,"Boolean Equality with False is Equivalent to Negation: \( b == \text{false} \iff \text{not } b \) : For any boolean value \( b \), the boolean equality \( b == \text{false} \) is equal to the negation of \( b \), i.e., \( b == \text{false} \iff \text{not } b \).","theorem beq_false (b : Bool) : (b == false) = !b := by
  cases b <;> rfl","We will consider every possible case of the boolean value \( b \).

**Case 1: \( b = \text{false} \)**
- We need to show that \( (\text{false} == \text{false}) = \neg \text{false} \).
- Since \( \text{false} == \text{false} \) is true and \( \neg \text{false} \) is also true, the equality holds.

**Case 2: \( b = \text{true} \)**
- We need to show that \( (\text{true} == \text{false}) = \neg \text{true} \).
- Since \( \text{true} == \text{false} \) is false and \( \neg \text{true} \) is also false, the equality holds.

In both cases, the equality \( b == \text{false} = \neg b \) holds. Therefore, the theorem is proved.","theorem beq_false (b : Bool) : (b == false) = !b := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas



"
32595,ite_congr,"theorem ite_congr {x y u v : α} {s : Decidable b} [Decidable c]
    (h₁ : b = c) (h₂ : c → x = u) (h₃ : ¬ c → y = v) : ite b x y = ite c u v := by sorry","If-Then-Else Function Congruence: $\text{ite}(b, x, y) = \text{ite}(c, u, v)$ : For any type $\alpha$, propositions $b$ and $c$, and elements $x, y, u, v \in \alpha$, if $b$ is equal to $c$, and if $c$ implies $x = u$, and if the negation of $c$ implies $y = v$, then the if-then-else function `ite` evaluated at $b$ with $x$ and $y$ is equal to `ite` evaluated at $c$ with $u$ and $v$. In other words, if $b = c$, $c \to x = u$, and $\neg c \to y = v$, then $\text{ite}(b, x, y) = \text{ite}(c, u, v)$.","theorem ite_congr {x y u v : α} {s : Decidable b} [Decidable c]
    (h₁ : b = c) (h₂ : c → x = u) (h₃ : ¬ c → y = v) : ite b x y = ite c u v := by
  cases Decidable.em c with
  | inl h => rw [if_pos h]; subst b; rw [if_pos h]; exact h₂ h
  | inr h => rw [if_neg h]; subst b; rw [if_neg h]; exact h₃ h","We need to show that $\text{ite}(b, x, y) = \text{ite}(c, u, v)$ under the given conditions. We consider two cases based on the truth value of $c$.

1. **Case 1: $c$ is true.**
- By the property of the if-then-else function, $\text{ite}(c, u, v) = u$ when $c$ is true.
- Since $b = c$, we can substitute $b$ with $c$ in the goal. Thus, $\text{ite}(b, x, y) = \text{ite}(c, x, y) = x$.
- Therefore, the goal reduces to showing $x = u$.
- This is exactly proved by the hypothesis $h₂$, which states that if $c$ is true, then $x = u$.

2. **Case 2: $c$ is false.**
- By the property of the if-then-else function, $\text{ite}(c, u, v) = v$ when $c$ is false.
- Since $b = c$, we can substitute $b$ with $c$ in the goal. Thus, $\text{ite}(b, x, y) = \text{ite}(c, x, y) = y$.
- Therefore, the goal reduces to showing $y = v$.
- This is exactly proved by the hypothesis $h₃$, which states that if $c$ is false, then $y = v$.

In both cases, the goal is satisfied. Therefore, we have shown that $\text{ite}(b, x, y) = \text{ite}(c, u, v)$. This completes the proof. $\blacksquare$","theorem ite_congr {x y u v : α} {s : Decidable b} [Decidable c]
    (h₁ : b = c) (h₂ : c → x = u) (h₃ : ¬ c → y = v) : ite b x y = ite c u v := by
  cases Decidable.em c with
/- First, consider the case where $c$ is true. By the property of the if-then-else function, $\text{ite}(c, u, v) = u$ when $c$ is true. Since $b = c$, we can substitute $b$ with $c$ in the goal. Thus, $\text{ite}(b, x, y) = \text{ite}(c, x, y) = x$. Therefore, the goal reduces to showing $x = u$. This is exactly proved by the hypothesis $h₂$, which states that if $c$ is true, then $x = u$. -/
  | inl h => rw [if_pos h]; subst b; rw [if_pos h]; exact h₂ h
/- Next, consider the case where $c$ is false. By the property of the if-then-else function, $\text{ite}(c, u, v) = v$ when $c$ is false. Since $b = c$, we can substitute $b$ with $c$ in the goal. Thus, $\text{ite}(b, x, y) = \text{ite}(c, x, y) = y$. Therefore, the goal reduces to showing $y = v$. This is exactly proved by the hypothesis $h₃$, which states that if $c$ is false, then $y = v$. -/
  | inr h => rw [if_neg h]; subst b; rw [if_neg h]; exact h₃ h","import Init.Core
import Init.SimpLemmas



"
32596,beq_self_eq_true',theorem beq_self_eq_true' [DecidableEq α] (a : α) : (a == a) = true := by sorry,"Boolean Equality Function Returns True for Equal Elements: $a == a = \text{true}$ : For any type $\alpha$ with a decidable equality relation and for any element $a \in \alpha$, the boolean equality function `a == a` returns `true`. This means that the boolean expression `a == a` is always `true` for any element $a$ in the type $\alpha$.","theorem beq_self_eq_true' [DecidableEq α] (a : α) : (a == a) = true := by
  simp","We need to show that for any element $a \in \alpha$, the boolean equality function `a == a` returns `true`. Using the properties of equality and the fact that `a == a` is equivalent to `true` for any element $a$ in a type $\alpha$ with decidable equality, we can simplify the proposition to $(a == a) = \text{true}$. This is trivially true because the boolean equality function `a == a` always returns `true` for any element $a$. Therefore, the theorem holds. $\blacksquare$","theorem beq_self_eq_true' [DecidableEq α] (a : α) : (a == a) = true := by
  simp","import Init.Core
import Init.SimpLemmas



"
32598,Bool.false_and,theorem Bool.false_and (b : Bool) : (false && b) = false := by sorry,"False AND Identity: $\text{false} \land b = \text{false}$ : For any boolean value $b$, the boolean ""and"" operation between `false` and $b$ is equal to `false`, i.e., $\text{false} \land b = \text{false}$.","theorem Bool.false_and (b : Bool) : (false && b) = false := by
  cases b <;> rfl","To prove that $\text{false} \land b = \text{false}$ for any boolean value $b$, we will consider the two possible cases for $b$.

**Case 1: $b = \text{false}$**
We need to show that $\text{false} \land \text{false} = \text{false}$. By the definition of the boolean ""and"" operation, $\text{false} \land \text{false} = \text{false}$, which is trivially true.

**Case 2: $b = \text{true}$**
We need to show that $\text{false} \land \text{true} = \text{false}$. By the definition of the boolean ""and"" operation, $\text{false} \land \text{true} = \text{false}$, which is also trivially true.

Since both cases are true, we conclude that for any boolean value $b$, $\text{false} \land b = \text{false}$. This completes the proof. $\blacksquare$","theorem Bool.false_and (b : Bool) : (false && b) = false := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas

open Bool

"
32599,Bool.and_true,theorem Bool.and_true (b : Bool) : (b && true) = b := by sorry,"Boolean AND with True Equals the Original Boolean Value : For any boolean value $b$, the boolean ""and"" operation between $b$ and `true` is equal to $b$, i.e., $b \land \text{true} = b$.","theorem Bool.and_true (b : Bool) : (b && true) = b := by
  cases b <;> rfl","We will consider every possible case of the boolean value $b$.

1. **Case 1: $b = \text{false}$**
- We need to show that $(\text{false} \land \text{true}) = \text{false}$.
- The left-hand side $(\text{false} \land \text{true})$ is definitionally equal to $\text{false}$.
- Therefore, the equality $(\text{false} \land \text{true}) = \text{false}$ holds.

2. **Case 2: $b = \text{true}$**
- We need to show that $(\text{true} \land \text{true}) = \text{true}$.
- The left-hand side $(\text{true} \land \text{true})$ is definitionally equal to $\text{true}$.
- Therefore, the equality $(\text{true} \land \text{true}) = \text{true}$ holds.

Since both cases are covered and the equality holds in each case, we conclude that for any boolean value $b$, the boolean ""and"" operation between $b$ and `true` is equal to $b$. This completes the proof.","theorem Bool.and_true (b : Bool) : (b && true) = b := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas

open Bool

"
32600,beq_true,theorem beq_true (b : Bool) : (b == true)  =  b := by sorry,"Boolean Equality with True is Identity: \( b == \text{true} = b \) : For any boolean value \( b \), the boolean equality \( b == \text{true} \) is equal to \( b \). In other words, \( b == \text{true} \) returns `true` if \( b \) is `true`, and `false` if \( b \) is `false`.","theorem beq_true (b : Bool) : (b == true)  =  b := by
  cases b <;> rfl","We will consider every possible case of the boolean value \( b \).

1. **Case 1: \( b = \text{false} \)**
- We need to show that \( (\text{false} == \text{true}) = \text{false} \).
- The left-hand side \( \text{false} == \text{true} \) evaluates to `false` by the definition of boolean equality.
- Therefore, \( (\text{false} == \text{true}) = \text{false} \) holds trivially.

2. **Case 2: \( b = \text{true} \)**
- We need to show that \( (\text{true} == \text{true}) = \text{true} \).
- The left-hand side \( \text{true} == \text{true} \) evaluates to `true` by the definition of boolean equality.
- Therefore, \( (\text{true} == \text{true}) = \text{true} \) holds trivially.

Since both cases are satisfied, the theorem is proven.","theorem beq_true (b : Bool) : (b == true)  =  b := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas



"
32601,bne_self_eq_false',theorem bne_self_eq_false' [DecidableEq α] (a : α) : (a != a) = false := by sorry,"Boolean Not-Equal Function Returns False for Equal Elements: $a \neq a = \text{false}$ : For any type $\alpha$ with a decidable equality relation, and for any element $a \in \alpha$, the boolean not-equal function `a != a` returns `false`. In other words, for any element $a$ in the type $\alpha$, the boolean expression `a != a` is always `false`.","theorem bne_self_eq_false' [DecidableEq α] (a : α) : (a != a) = false := by
  simp","We need to show that for any element $a \in \alpha$, the boolean expression $(a \neq a) = \text{false}$ holds. Using the properties of decidable equality and the definition of the boolean not-equal function, we can simplify the proposition $(a \neq a) = \text{false}$. The boolean not-equal function `a != a` is defined such that it returns `false` when `a` is equal to `a`, which is always true by the definition of equality. Therefore, the proposition $(a \neq a) = \text{false}$ is trivially true. This completes the proof. $\blacksquare$","theorem bne_self_eq_false' [DecidableEq α] (a : α) : (a != a) = false := by
  simp","import Init.Core
import Init.SimpLemmas



"
32602,bne_self_eq_false,theorem bne_self_eq_false [BEq α] [LawfulBEq α] (a : α) : (a != a) = false := by sorry,"Boolean Not-Equal Function Returns False for Equal Elements: $a \neq a = \text{false}$ : For any type $\alpha$ with a `BEq` instance and a `LawfulBEq` instance, and for any element $a \in \alpha$, the boolean not-equal function `a != a` returns `false`. This means that the boolean expression `a != a` is always `false` for any element $a$ in the type $\alpha$.","theorem bne_self_eq_false [BEq α] [LawfulBEq α] (a : α) : (a != a) = false := by
  simp [bne]","To prove that \((a \neq a) = \text{false}\) for any element \(a \in \alpha\), we use the definition of the boolean not-equal function `bne`. The function `bne` is defined as the boolean negation of the equality function, i.e., \(a \neq a\) is equivalent to \(\text{not}(a == a)\). Since \(a == a\) is always `true` (by the reflexivity of equality), \(\text{not}(a == a)\) is \(\text{not}(\text{true})\), which is `false`. Therefore, \((a \neq a) = \text{false}\). This completes the proof. \(\blacksquare\)","theorem bne_self_eq_false [BEq α] [LawfulBEq α] (a : α) : (a != a) = false := by
  simp [bne]","import Init.Core
import Init.SimpLemmas



"
32603,dite_congr,"theorem dite_congr {_ : Decidable b} [Decidable c]
    {x : b → α} {u : c → α} {y : ¬b → α} {v : ¬c → α}
    (h₁ : b = c)
    (h₂ : (h : c)  → x (h₁.mpr_prop h) = u h)
    (h₃ : (h : ¬c) → y (h₁.mpr_not h)  = v h) :
    dite b x y = dite c u v := by sorry","Dependent If-Then-Else Construct Congruence: \( \text{dite}(b, x_1, y) = \text{dite}(c, u, v) \) if \( b = c \) and \( x_1 = u \) and \( y = v \) : For any propositions \( b \) and \( c \), and any type \( \alpha \), if \( b \) is decidable and \( c \) is decidable, and if there are functions \( x_1 : b \to \alpha \), \( u : c \to \alpha \), \( y : \neg b \to \alpha \), and \( v : \neg c \to \alpha \), then the following holds:
- If \( b = c \),
- and for all \( h : c \), \( x_1(h) = u(h) \),
- and for all \( h : \neg c \), \( y(h) = v(h) \),
then the dependent if-then-else construct \( \text{dite}(b, x_1, y) \) is equal to \( \text{dite}(c, u, v) \).","theorem dite_congr {_ : Decidable b} [Decidable c]
    {x : b → α} {u : c → α} {y : ¬b → α} {v : ¬c → α}
    (h₁ : b = c)
    (h₂ : (h : c)  → x (h₁.mpr_prop h) = u h)
    (h₃ : (h : ¬c) → y (h₁.mpr_not h)  = v h) :
    dite b x y = dite c u v := by
  cases Decidable.em c with
  | inl h => rw [dif_pos h]; subst b; rw [dif_pos h]; exact h₂ h
  | inr h => rw [dif_neg h]; subst b; rw [dif_neg h]; exact h₃ h","We need to show that \( \text{dite}(b, x_1, y) = \text{dite}(c, u, v) \) under the given conditions. We consider two cases based on the truth value of \( c \).

1. **Case 1: \( c \) is true.**
- By the property of the dependent if-then-else construct, if \( c \) is true, then \( \text{dite}(c, u, v) = u(h) \) for any proof \( h \) of \( c \).
- Since \( b = c \), we can substitute \( b \) with \( c \) in the goal. Therefore, \( \text{dite}(b, x_1, y) = \text{dite}(c, x_1, y) \).
- By the same property, \( \text{dite}(c, x_1, y) = x_1(h) \).
- By the hypothesis \( h_2 \), \( x_1(h) = u(h) \).
- Therefore, \( \text{dite}(b, x_1, y) = u(h) \), which is equal to \( \text{dite}(c, u, v) \).

2. **Case 2: \( c \) is false.**
- By the property of the dependent if-then-else construct, if \( c \) is false, then \( \text{dite}(c, u, v) = v(h) \) for any proof \( h \) of \( \neg c \).
- Since \( b = c \), we can substitute \( b \) with \( c \) in the goal. Therefore, \( \text{dite}(b, x_1, y) = \text{dite}(c, x_1, y) \).
- By the same property, \( \text{dite}(c, x_1, y) = y(h) \).
- By the hypothesis \( h_3 \), \( y(h) = v(h) \).
- Therefore, \( \text{dite}(b, x_1, y) = v(h) \), which is equal to \( \text{dite}(c, u, v) \).

In both cases, we have shown that \( \text{dite}(b, x_1, y) = \text{dite}(c, u, v) \). Therefore, the theorem is proved.","theorem dite_congr {_ : Decidable b} [Decidable c]
    {x : b → α} {u : c → α} {y : ¬b → α} {v : ¬c → α}
    (h₁ : b = c)
    (h₂ : (h : c)  → x (h₁.mpr_prop h) = u h)
    (h₃ : (h : ¬c) → y (h₁.mpr_not h)  = v h) :
    dite b x y = dite c u v := by
  cases Decidable.em c with
/- Consider the case where \( c \) is true, i.e., \( c \). By the property of the dependent if-then-else construct, if \( c \) is true, then \( \text{dite}(c, u, v) = u(h) \). Since \( b = c \), we can substitute \( b \) with \( c \) in the goal. Therefore, \( \text{dite}(b, x_1, y) = \text{dite}(c, u, v) \) simplifies to \( \text{dite}(c, x_1, y) = u(h) \). By the same property, \( \text{dite}(c, x_1, y) = x_1(h) \). Since \( x_1(h) = u(h) \) by the hypothesis \( h_2 \), the goal is satisfied. -/
  | inl h => rw [dif_pos h]; subst b; rw [dif_pos h]; exact h₂ h
/- Consider the case where \( c \) is false, i.e., \( \neg c \). By the property of the dependent if-then-else construct, if \( c \) is false, then \( \text{dite}(c, u, v) = v(h) \). Since \( b = c \), we can substitute \( b \) with \( c \) in the goal. Therefore, \( \text{dite}(b, x_1, y) = \text{dite}(c, u, v) \) simplifies to \( \text{dite}(c, x_1, y) = v(h) \). By the same property, \( \text{dite}(c, x_1, y) = y(h) \). Since \( y(h) = v(h) \) by the hypothesis \( h_3 \), the goal is satisfied. -/
  | inr h => rw [dif_neg h]; subst b; rw [dif_neg h]; exact h₃ h","import Init.Core
import Init.SimpLemmas



"
32604,Bool.not_eq_true,theorem Bool.not_eq_true (b : Bool) : (¬(b = true)) = (b = false) := by sorry,"Negation of Boolean Value Equals True if and only if Value is False: $\neg b = \text{true} \iff b = \text{false}$ : For any boolean value $b$, the negation of $b$ is equal to `true` if and only if $b$ is equal to `false`, i.e., $\neg b = \text{true} \iff b = \text{false}$.","theorem Bool.not_eq_true (b : Bool) : (¬(b = true)) = (b = false) := by
  cases b <;> decide","We will consider every possible case of the boolean value $b$.

1. **Case 1: $b = \text{false}$**
- We need to show that $(\neg \text{false} = \text{true}) = (\text{false} = \text{false})$.
- Since $\neg \text{false} = \text{true}$ and $\text{false} = \text{false}$, the equality holds.

2. **Case 2: $b = \text{true}$**
- We need to show that $(\neg \text{true} = \text{true}) = (\text{true} = \text{false})$.
- Since $\neg \text{true} = \text{false}$ and $\text{true} \neq \text{false}$, the equality holds.

In both cases, the equality $(\neg b = \text{true}) = (b = \text{false})$ is satisfied. Therefore, the theorem is proved. $\blacksquare$","theorem Bool.not_eq_true (b : Bool) : (¬(b = true)) = (b = false) := by
  cases b <;> decide","import Init.Core
import Init.SimpLemmas

open Bool

"
32605,Bool.beq_to_eq,theorem Bool.beq_to_eq (a b : Bool) : (a == b) = (a = b) := by sorry,"Boolean Equality Implies True if and only if Elements are Equal: \( (a == b) = \text{true} \leftrightarrow a = b \) : For any boolean values \( a \) and \( b \), the boolean equality \( a == b \) is true if and only if \( a \) is equal to \( b \), i.e., \( (a == b) = \text{true} \) if and only if \( a = b \).","theorem Bool.beq_to_eq (a b : Bool) : (a == b) = (a = b) := by
  simp","We need to show that for any boolean values \( a \) and \( b \), the boolean equality \( a == b \) is true if and only if \( a \) is equal to \( b \). This can be expressed as \((a == b) = \text{true} \leftrightarrow a = b\).

To prove this, we use the properties of boolean equality and the equivalence of true propositions. Specifically, we use the fact that if a proposition \( p \) is equal to `True`, then \( p \) holds. This is formalized by the theorem \( p = \text{True} \implies p \).

By applying these properties, we can simplify the proposition \((a == b) = \text{true} \leftrightarrow a = b\) to a trivially true statement. Therefore, the boolean equality \( a == b \) is true if and only if \( a \) is equal to \( b \).

This completes the proof. \(\blacksquare\)","theorem Bool.beq_to_eq (a b : Bool) : (a == b) = (a = b) := by
  simp","import Init.Core
import Init.SimpLemmas

open Bool

"
32606,Bool.not_eq_true',theorem Bool.not_eq_true' (b : Bool) : ((!b) = true) = (b = false) := by sorry,"Negation of Boolean Value Equals True if and only if Value is False: \(\text{not } b = \text{true} \iff b = \text{false}\) : For any boolean value \( b \), the negation of \( b \) is equal to `true` if and only if \( b \) is equal to `false`, i.e., \(\text{not } b = \text{true} \iff b = \text{false}\).","theorem Bool.not_eq_true' (b : Bool) : ((!b) = true) = (b = false) := by
  cases b <;> simp","We will consider every possible case of the boolean value $b$.

**Case 1: $b = \text{false}$**
We need to show that $(\text{not } \text{false}) = \text{true}$ is equivalent to $\text{false} = \text{false}$. Simplifying the left-hand side, we get $\text{true} = \text{true}$, which is trivially true. Therefore, the left-hand side is equivalent to the right-hand side, which is $\text{false} = \text{false}$, and this is also trivially true.

**Case 2: $b = \text{true}$**
We need to show that $(\text{not } \text{true}) = \text{true}$ is equivalent to $\text{true} = \text{false}$. Simplifying the left-hand side, we get $\text{false} = \text{true}$, which is false. Therefore, the left-hand side is equivalent to the right-hand side, which is $\text{true} = \text{false}$, and this is also false.

In both cases, the equivalence holds. Therefore, for any boolean value $b$, the negation of $b$ is equal to `true` if and only if $b$ is equal to `false`. This completes the proof. $\blacksquare$","theorem Bool.not_eq_true' (b : Bool) : ((!b) = true) = (b = false) := by
  cases b <;> simp","import Init.Core
import Init.SimpLemmas

open Bool

"
32609,Bool.not_beq_to_not_eq,theorem Bool.not_beq_to_not_eq (a b : Bool) : (!(a == b)) = ¬(a = b) := by sorry,"Boolean Negation and Equality: \((\text{not } a == b) = \text{true} \leftrightarrow \neg a = b\) : For any boolean values \( a \) and \( b \), the boolean equality \( \text{not } a \text{ equals } b \) is true if and only if the logical negation of \( a \) is equal to \( b \), i.e., \( (\text{not } a == b) = \text{true} \) if and only if \( \neg a = b \).","theorem Bool.not_beq_to_not_eq (a b : Bool) : (!(a == b)) = ¬(a = b) := by
  simp","We need to show that the boolean equality \((\text{not } a == b) = \text{true}\) is equivalent to the logical statement \(\neg a = b\).

1. **Simplify the Proposition:**
- The boolean equality \((\text{not } a == b) = \text{true}\) means that the boolean value \(\text{not } a\) is equal to the boolean value \(b\).
- By the definition of boolean equality, \((\text{not } a == b) = \text{true}\) is true if and only if \(\text{not } a\) and \(b\) are the same boolean value.
- The logical negation \(\neg a\) is defined such that \(\neg a\) is true if \(a\) is false, and \(\neg a\) is false if \(a\) is true.
- Therefore, \((\text{not } a == b) = \text{true}\) is equivalent to \(\neg a = b\).

Thus, we have shown that \((\text{not } a == b) = \text{true} \leftrightarrow \neg a = b\). This completes the proof.","theorem Bool.not_beq_to_not_eq (a b : Bool) : (!(a == b)) = ¬(a = b) := by
  simp","import Init.Core
import Init.SimpLemmas

open Bool

"
32610,forall_prop_domain_congr,"theorem forall_prop_domain_congr {p₁ p₂ : Prop} {q₁ : p₁ → Prop} {q₂ : p₂ → Prop}
    (h₁ : p₁ = p₂)
    (h₂ : ∀ a : p₂, q₁ (h₁.substr a) = q₂ a)
    : (∀ a : p₁, q₁ a) = (∀ a : p₂, q₂ a) := by sorry","Congruence of Universal Quantifiers over Propositional Domains : For any propositions $p_1$ and $p_2$, and any functions $q_1 : p_1 \to \text{Prop}$ and $q_2 : p_2 \to \text{Prop}$, if $p_1 = p_2$, and for all $a \in p_2$, $q_1(a) = q_2(a)$, then it holds that $\forall a \in p_1, q_1(a) = \forall a \in p_2, q_2(a)$.","theorem forall_prop_domain_congr {p₁ p₂ : Prop} {q₁ : p₁ → Prop} {q₂ : p₂ → Prop}
    (h₁ : p₁ = p₂)
    (h₂ : ∀ a : p₂, q₁ (h₁.substr a) = q₂ a)
    : (∀ a : p₁, q₁ a) = (∀ a : p₂, q₂ a) := by
  subst h₁; simp [← h₂]","We start with the assumption that $p_1 = p_2$. Using this equality, we can substitute $p_1$ with $p_2$ in the context and the goal. This simplifies our goal to showing that $\forall a \in p_2, q_1(a) = \forall a \in p_2, q_2(a)$.

Next, we use the pointwise equality of functions $q_1$ and $q_2$, which states that for all $a \in p_2$, $q_1(a) = q_2(a)$. This allows us to simplify the goal to $\forall a \in p_2, q_1(a) = \forall a \in p_2, q_2(a)$. Since the two universal quantifications are over the same domain and the functions are equal pointwise, this is trivially true.

Therefore, we have shown that $\forall a \in p_1, q_1(a) = \forall a \in p_2, q_2(a)$. This completes the proof.","theorem forall_prop_domain_congr {p₁ p₂ : Prop} {q₁ : p₁ → Prop} {q₂ : p₂ → Prop}
    (h₁ : p₁ = p₂)
    (h₂ : ∀ a : p₂, q₁ (h₁.substr a) = q₂ a)
    : (∀ a : p₁, q₁ a) = (∀ a : p₂, q₂ a) := by
/- Since we know that $p_1 = p_2$, we can substitute $p_1$ with $p_2$ in the context and the goal. This simplifies our goal to showing that $\forall a \in p_2, q_1(a) = \forall a \in p_2, q_2(a)$. Using the pointwise equality of functions $q_1$ and $q_2$, which states that for all $a \in p_2$, $q_1(a) = q_2(a)$, we can simplify the goal to $\forall a \in p_2, q_1(a) = \forall a \in p_2, q_2(a)$. This is trivially true because the two universal quantifications are over the same domain and the functions are equal pointwise. -/
  subst h₁; simp [← h₂]","import Init.Core
import Init.SimpLemmas



"
32612,Bool.not_not,theorem Bool.not_not (b : Bool) : (!!b) = b := by sorry,"Double Negation Identity: \(\text{not}(\text{not}(b)) = b\) : For any boolean value \( b \), the double negation of \( b \) is equal to \( b \), i.e., \(\text{not}(\text{not}(b)) = b\).","theorem Bool.not_not (b : Bool) : (!!b) = b := by
  cases b <;> rfl","We will consider every possible case of the boolean value \( b \).

1. **Case 1: \( b = \text{false} \)**
- We need to show that \(\text{not}(\text{not}(\text{false})) = \text{false}\).
- By the definition of the \(\text{not}\) function, \(\text{not}(\text{false}) = \text{true}\).
- Applying \(\text{not}\) again, \(\text{not}(\text{true}) = \text{false}\).
- Therefore, \(\text{not}(\text{not}(\text{false})) = \text{false}\).

2. **Case 2: \( b = \text{true} \)**
- We need to show that \(\text{not}(\text{not}(\text{true})) = \text{true}\).
- By the definition of the \(\text{not}\) function, \(\text{not}(\text{true}) = \text{false}\).
- Applying \(\text{not}\) again, \(\text{not}(\text{false}) = \text{true}\).
- Therefore, \(\text{not}(\text{not}(\text{true})) = \text{true}\).

Since both cases hold, we conclude that for any boolean value \( b \), \(\text{not}(\text{not}(b)) = b\). This completes the proof.","theorem Bool.not_not (b : Bool) : (!!b) = b := by
  cases b <;> rfl","import Init.Core
import Init.SimpLemmas

open Bool

"
32614,Bool.not_eq_false,theorem Bool.not_eq_false (b : Bool) : (¬(b = false)) = (b = true) := by sorry,"Negation of Boolean True is False: \(\neg \text{true} = \text{false}\) : For any boolean value \( b \), the negation of \( b \) is equal to `false` if and only if \( b \) is equal to `true`, i.e., \(\neg b = \text{false} \leftrightarrow b = \text{true}\).","theorem Bool.not_eq_false (b : Bool) : (¬(b = false)) = (b = true) := by
  cases b <;> decide","We will consider every possible case of the boolean value \( b \).

1. **Case 1: \( b = \text{false} \)**
- We need to show that \(\neg \text{false} = \text{false} \leftrightarrow \text{false} = \text{true}\).
- Since \(\neg \text{false} = \text{true}\) and \(\text{false} \neq \text{true}\), the left-hand side is \(\text{true} = \text{false}\), which is false, and the right-hand side is \(\text{false} = \text{true}\), which is also false.
- Therefore, both sides are equal, and the statement holds.

2. **Case 2: \( b = \text{true} \)**
- We need to show that \(\neg \text{true} = \text{false} \leftrightarrow \text{true} = \text{true}\).
- Since \(\neg \text{true} = \text{false}\) and \(\text{true} = \text{true}\), the left-hand side is \(\text{false} = \text{false}\), which is true, and the right-hand side is \(\text{true} = \text{true}\), which is also true.
- Therefore, both sides are equal, and the statement holds.

Since both cases are covered and the statement holds in each case, we conclude that for any boolean value \( b \), \(\neg b = \text{false} \leftrightarrow b = \text{true}\). This completes the proof.","theorem Bool.not_eq_false (b : Bool) : (¬(b = false)) = (b = true) := by
  cases b <;> decide","import Init.Core
import Init.SimpLemmas

open Bool

"
32615,Bool.and_eq_true,theorem Bool.and_eq_true (a b : Bool) : ((a && b) = true) = (a = true ∧ b = true) := by sorry,"Boolean AND Equals True if and only if Both Operands are True: \( a \text{ and } b = \text{true} \leftrightarrow a = \text{true} \land b = \text{true} \) : For any boolean values \( a \) and \( b \), the boolean ""and"" operation \( a \text{ and } b \) is equal to `true` if and only if both \( a \) and \( b \) are equal to `true`. In other words, \( a \text{ and } b = \text{true} \) if and only if \( a = \text{true} \) and \( b = \text{true} \).","theorem Bool.and_eq_true (a b : Bool) : ((a && b) = true) = (a = true ∧ b = true) := by
  cases a <;> cases b <;> decide","To prove the theorem, we will consider every possible combination of boolean values for \( a \) and \( b \) and show that the equality \( (a \text{ and } b) = \text{true} \) holds if and only if \( a = \text{true} \) and \( b = \text{true} \).

1. **Case 1: \( a = \text{false} \)**
- **Subcase 1.1: \( b = \text{false} \)**
- Evaluate \( (a \text{ and } b) = (false \text{ and } false) = \text{false} \).
- Evaluate \( (a = \text{true} \land b = \text{true}) = (false = \text{true} \land false = \text{true}) = \text{false} \).
- Therefore, \( (false \text{ and } false) = \text{false} \) and \( (false = \text{true} \land false = \text{true}) = \text{false} \), so the equality holds.
- **Subcase 1.2: \( b = \text{true} \)**
- Evaluate \( (a \text{ and } b) = (false \text{ and } true) = \text{false} \).
- Evaluate \( (a = \text{true} \land b = \text{true}) = (false = \text{true} \land true = \text{true}) = \text{false} \).
- Therefore, \( (false \text{ and } true) = \text{false} \) and \( (false = \text{true} \land true = \text{true}) = \text{false} \), so the equality holds.

2. **Case 2: \( a = \text{true} \)**
- **Subcase 2.1: \( b = \text{false} \)**
- Evaluate \( (a \text{ and } b) = (true \text{ and } false) = \text{false} \).
- Evaluate \( (a = \text{true} \land b = \text{true}) = (true = \text{true} \land false = \text{true}) = \text{false} \).
- Therefore, \( (true \text{ and } false) = \text{false} \) and \( (true = \text{true} \land false = \text{true}) = \text{false} \), so the equality holds.
- **Subcase 2.2: \( b = \text{true} \)**
- Evaluate \( (a \text{ and } b) = (true \text{ and } true) = \text{true} \).
- Evaluate \( (a = \text{true} \land b = \text{true}) = (true = \text{true} \land true = \text{true}) = \text{true} \).
- Therefore, \( (true \text{ and } true) = \text{true} \) and \( (true = \text{true} \land true = \text{true}) = \text{true} \), so the equality holds.

Since we have considered all possible cases and shown that the equality holds in each case, the theorem is proven. Therefore, for any boolean values \( a \) and \( b \), \( a \text{ and } b = \text{true} \) if and only if \( a = \text{true} \) and \( b = \text{true} \).","theorem Bool.and_eq_true (a b : Bool) : ((a && b) = true) = (a = true ∧ b = true) := by
/- We will consider every possible case for the boolean values \( a \) and \( b \). For each combination of \( a \) and \( b \), we will evaluate the expression \( (a \text{ and } b) = \text{true} \) and compare it to \( (a = \text{true} \land b = \text{true}) \). -/
/- We will discuss every possible case of \( a \). Case 1: \( a = \text{false} \). Case 2: \( a = \text{true} \). -/
/- For each case of \( a \), we will further discuss every possible case of \( b \). Case 1: \( b = \text{false} \). Case 2: \( b = \text{true} \). -/
/- We will evaluate the expression for each combination of \( a \) and \( b \) and show that the equality holds. -/
  cases a <;> cases b <;> decide","import Init.Core
import Init.SimpLemmas

open Bool

"
32616,Bool.not_eq_false',theorem Bool.not_eq_false' (b : Bool) : ((!b) = false) = (b = true) := by sorry,"Negation of Boolean Value Equals False if and only if Value is True: \(\text{not } b = \text{false} \iff b = \text{true}\) : For any boolean value \( b \), the negation of \( b \) is equal to `false` if and only if \( b \) is equal to `true`, i.e., \(\text{not } b = \text{false} \iff b = \text{true}\).","theorem Bool.not_eq_false' (b : Bool) : ((!b) = false) = (b = true) := by
  cases b <;> simp","We will consider every possible case of the boolean value \( b \). There are two cases:

1. **Case 1: \( b = \text{false} \)**
- We need to show that \((\text{not } \text{false}) = \text{false} \) is equivalent to \(\text{false} = \text{true} \).
- Simplify the expression \((\text{not } \text{false}) = \text{false} \). Since \(\text{not } \text{false} = \text{true} \), the expression becomes \(\text{true} = \text{false} \), which is false.
- Simplify the expression \(\text{false} = \text{true} \), which is also false.
- Therefore, \((\text{not } \text{false}) = \text{false} \) is equivalent to \(\text{false} = \text{true} \).

2. **Case 2: \( b = \text{true} \)**
- We need to show that \((\text{not } \text{true}) = \text{false} \) is equivalent to \(\text{true} = \text{true} \).
- Simplify the expression \((\text{not } \text{true}) = \text{false} \). Since \(\text{not } \text{true} = \text{false} \), the expression becomes \(\text{false} = \text{false} \), which is true.
- Simplify the expression \(\text{true} = \text{true} \), which is also true.
- Therefore, \((\text{not } \text{true}) = \text{false} \) is equivalent to \(\text{true} = \text{true} \).

Since both cases are true, we conclude that for any boolean value \( b \), \(\text{not } b = \text{false} \) if and only if \( b = \text{true} \). This completes the proof.","theorem Bool.not_eq_false' (b : Bool) : ((!b) = false) = (b = true) := by
  cases b <;> simp","import Init.Core
import Init.SimpLemmas

open Bool

"
32690,Bool.or_assoc,theorem Bool.or_assoc (a b c : Bool) : (a || b || c) = (a || (b || c)) := by sorry,"Associativity of Boolean OR: \((a \lor b) \lor c = a \lor (b \lor c)\) : For any boolean values \( a, b, c \), the boolean ""or"" operation is associative, i.e., \((a \lor b) \lor c = a \lor (b \lor c)\).","theorem Bool.or_assoc (a b c : Bool) : (a || b || c) = (a || (b || c)) := by
  cases a <;> cases b <;> cases c <;> decide","To prove the associativity of the boolean ""or"" operation, we will consider every possible combination of the boolean values of \(a\), \(b\), and \(c\). For each combination, we will show that \((a \lor b) \lor c = a \lor (b \lor c)\).

1. **Case 1: \(a = \text{false}, b = \text{false}, c = \text{false}\)**
\[
(\text{false} \lor \text{false}) \lor \text{false} = \text{false} \lor \text{false} = \text{false}
\]
\[
\text{false} \lor (\text{false} \lor \text{false}) = \text{false} \lor \text{false} = \text{false}
\]
Both sides are equal to \(\text{false}\).

2. **Case 2: \(a = \text{false}, b = \text{false}, c = \text{true}\)**
\[
(\text{false} \lor \text{false}) \lor \text{true} = \text{false} \lor \text{true} = \text{true}
\]
\[
\text{false} \lor (\text{false} \lor \text{true}) = \text{false} \lor \text{true} = \text{true}
\]
Both sides are equal to \(\text{true}\).

3. **Case 3: \(a = \text{false}, b = \text{true}, c = \text{false}\)**
\[
(\text{false} \lor \text{true}) \lor \text{false} = \text{true} \lor \text{false} = \text{true}
\]
\[
\text{false} \lor (\text{true} \lor \text{false}) = \text{false} \lor \text{true} = \text{true}
\]
Both sides are equal to \(\text{true}\).

4. **Case 4: \(a = \text{false}, b = \text{true}, c = \text{true}\)**
\[
(\text{false} \lor \text{true}) \lor \text{true} = \text{true} \lor \text{true} = \text{true}
\]
\[
\text{false} \lor (\text{true} \lor \text{true}) = \text{false} \lor \text{true} = \text{true}
\]
Both sides are equal to \(\text{true}\).

5. **Case 5: \(a = \text{true}, b = \text{false}, c = \text{false}\)**
\[
(\text{true} \lor \text{false}) \lor \text{false} = \text{true} \lor \text{false} = \text{true}
\]
\[
\text{true} \lor (\text{false} \lor \text{false}) = \text{true} \lor \text{false} = \text{true}
\]
Both sides are equal to \(\text{true}\).

6. **Case 6: \(a = \text{true}, b = \text{false}, c = \text{true}\)**
\[
(\text{true} \lor \text{false}) \lor \text{true} = \text{true} \lor \text{true} = \text{true}
\]
\[
\text{true} \lor (\text{false} \lor \text{true}) = \text{true} \lor \text{true} = \text{true}
\]
Both sides are equal to \(\text{true}\).

7. **Case 7: \(a = \text{true}, b = \text{true}, c = \text{false}\)**
\[
(\text{true} \lor \text{true}) \lor \text{false} = \text{true} \lor \text{false} = \text{true}
\]
\[
\text{true} \lor (\text{true} \lor \text{false}) = \text{true} \lor \text{true} = \text{true}
\]
Both sides are equal to \(\text{true}\).

8. **Case 8: \(a = \text{true}, b = \text{true}, c = \text{true}\)**
\[
(\text{true} \lor \text{true}) \lor \text{true} = \text{true} \lor \text{true} = \text{true}
\]
\[
\text{true} \lor (\text{true} \lor \text{true}) = \text{true} \lor \text{true} = \text{true}
\]
Both sides are equal to \(\text{true}\).

Since all possible cases have been considered and shown to satisfy the equation \((a \lor b) \lor c = a \lor (b \lor c)\), we conclude that the boolean ""or"" operation is associative. This completes the proof.","theorem Bool.or_assoc (a b c : Bool) : (a || b || c) = (a || (b || c)) := by
/- We will consider every possible combination of the boolean values of \(a\), \(b\), and \(c\). For each combination, we will show that \((a \lor b) \lor c = a \lor (b \lor c)\). -/
/- First, we consider every possible value of \(a\). For each value of \(a\), we then consider every possible value of \(b\). For each combination of \(a\) and \(b\), we consider every possible value of \(c\). This results in the following subgoals:
- \( (false \lor false \lor false) = (false \lor (false \lor false)) \)
- \( (false \lor false \lor true) = (false \lor (false \lor true)) \)
- \( (false \lor true \lor false) = (false \lor (true \lor false)) \)
- \( (false \lor true \lor true) = (false \lor (true \lor true)) \)
- \( (true \lor false \lor false) = (true \lor (false \lor false)) \)
- \( (true \lor false \lor true) = (true \lor (false \lor true)) \)
- \( (true \lor true \lor false) = (true \lor (true \lor false)) \)
- \( (true \lor true \lor true) = (true \lor (true \lor true)) \) -/
/- First, we consider every possible value of \(a\). For each value of \(a\), we then consider every possible value of \(b\). This results in the following subgoals:
- \( (false \lor false \lor c) = (false \lor (false \lor c)) \)
- \( (false \lor true \lor c) = (false \lor (true \lor c)) \)
- \( (true \lor false \lor c) = (true \lor (false \lor c)) \)
- \( (true \lor true \lor c) = (true \lor (true \lor c)) \) -/
/- We consider every possible value of \(a\). This results in the following subgoals:
- \( (false \lor b \lor c) = (false \lor (b \lor c)) \)
- \( (true \lor b \lor c) = (true \lor (b \lor c)) \) -/
/- We now consider each of the subgoals generated by the previous steps. -/
/- For each value of \(a\), we consider every possible value of \(b\). This results in the following subgoals:
- \( (false \lor false \lor c) = (false \lor (false \lor c)) \)
- \( (false \lor true \lor c) = (false \lor (true \lor c)) \) -/
/- For each value of \(a\), we consider every possible value of \(b\). This results in the following subgoals:
- \( (true \lor false \lor c) = (true \lor (false \lor c)) \)
- \( (true \lor true \lor c) = (true \lor (true \lor c)) \) -/
/- We now consider each of the subgoals generated by the previous steps. -/
/- For each combination of \(a\) and \(b\), we consider every possible value of \(c\). This results in the following subgoals:
- \( (false \lor false \lor false) = (false \lor (false \lor false)) \)
- \( (false \lor false \lor true) = (false \lor (false \lor true)) \) -/
/- For each combination of \(a\) and \(b\), we consider every possible value of \(c\). This results in the following subgoals:
- \( (false \lor true \lor false) = (false \lor (true \lor false)) \)
- \( (false \lor true \lor true) = (false \lor (true \lor true)) \) -/
/- For each combination of \(a\) and \(b\), we consider every possible value of \(c\). This results in the following subgoals:
- \( (true \lor false \lor false) = (true \lor (false \lor false)) \)
- \( (true \lor false \lor true) = (true \lor (false \lor true)) \) -/
/- For each combination of \(a\) and \(b\), we consider every possible value of \(c\). This results in the following subgoals:
- \( (true \lor true \lor false) = (true \lor (true \lor false)) \)
- \( (true \lor true \lor true) = (true \lor (true \lor true)) \) -/
/- We now consider each of the subgoals generated by the previous steps. -/
/- For the subgoal \( (false \lor false \lor false) = (false \lor (false \lor false)) \), we directly evaluate the boolean expressions and find that both sides are equal to \( \text{false} \). -/
/- For the subgoal \( (false \lor false \lor true) = (false \lor (false \lor true)) \), we directly evaluate the boolean expressions and find that both sides are equal to \( \text{true} \). -/
/- For the subgoal \( (false \lor true \lor false) = (false \lor (true \lor false)) \), we directly evaluate the boolean expressions and find that both sides are equal to \( \text{true} \). -/
/- For the subgoal \( (false \lor true \lor true) = (false \lor (true \lor true)) \), we directly evaluate the boolean expressions and find that both sides are equal to \( \text{true} \). -/
/- For the subgoal \( (true \lor false \lor false) = (true \lor (false \lor false)) \), we directly evaluate the boolean expressions and find that both sides are equal to \( \text{true} \). -/
/- For the subgoal \( (true \lor false \lor true) = (true \lor (false \lor true)) \), we directly evaluate the boolean expressions and find that both sides are equal to \( \text{true} \). -/
/- For the subgoal \( (true \lor true \lor false) = (true \lor (true \lor false)) \), we directly evaluate the boolean expressions and find that both sides are equal to \( \text{true} \). -/
/- For the subgoal \( (true \lor true \lor true) = (true \lor (true \lor true)) \), we directly evaluate the boolean expressions and find that both sides are equal to \( \text{true} \). -/
  cases a <;> cases b <;> cases c <;> decide","import Init.Core
import Init.SimpLemmas

open Bool

"
33614,List.eraseP_comm,"theorem List.eraseP_comm {l : List α} (h : ∀ a ∈ l, ¬ p a ∨ ¬ q a) :
    (l.eraseP p).eraseP q = (l.eraseP q).eraseP p := by sorry","Commutativity of `eraseP` for Disjoint Predicates: $\text{eraseP } q \circ \text{eraseP } p = \text{eraseP } p \circ \text{eraseP } q$ : For any type $\alpha$ and any two predicates $p, q : \alpha \to \text{Bool}$, if for every element $a \in l$, either $p(a)$ or $q(a)$ is false, then the list obtained by first removing the first element that satisfies $p$ and then removing the first element that satisfies $q$ is the same as the list obtained by first removing the first element that satisfies $q$ and then removing the first element that satisfies $p$. Formally, this is expressed as:
\[
\forall a \in l, \ (\neg p(a) \text{ or } \neg q(a)) \implies \text{eraseP } q (\text{eraseP } p \ l) = \text{eraseP } p (\text{eraseP } q \ l)
\]","theorem List.eraseP_comm {l : List α} (h : ∀ a ∈ l, ¬ p a ∨ ¬ q a) :
    (l.eraseP p).eraseP q = (l.eraseP q).eraseP p := by
  induction l with
  | nil => rfl
  | cons a l ih =>
    simp only [eraseP_cons]
    by_cases h₁ : p a
    · by_cases h₂ : q a
      · simp_all
      · simp [h₁, h₂, ih (fun b m => h b (mem_cons_of_mem _ m))]
    · by_cases h₂ : q a
      · simp [h₁, h₂, ih (fun b m => h b (mem_cons_of_mem _ m))]
      · simp [h₁, h₂, ih (fun b m => h b (mem_cons_of_mem _ m))]","We prove this by induction on the list \( l \).

**Base Case:**
For the base case where the list \( l \) is empty, the goal is trivially true by the reflexive property of equality. The empty list remains unchanged when elements are removed, so both sides of the equation are the same:
\[
\text{eraseP } q (\text{eraseP } p \ []) = \text{eraseP } p (\text{eraseP } q \ [])
\]

**Inductive Step:**
Assume the list \( l \) is of the form \( a :: l \) (i.e., \( a \) is the head of the list and \( l \) is the tail). We will use the induction hypothesis \( ih \) to prove the goal for this case.

We simplify the goal using the definition of `eraseP` for a list with a head and a tail. This simplification breaks down the goal into a more manageable form, specifically considering the cases where the head \( a \) satisfies the predicates \( p \) and \( q \).

**Case 1: \( p(a) \) holds**
- **Sub-case 1.1: \( q(a) \) holds**
- We simplify the goal using the properties of `eraseP` and the induction hypothesis. Since both \( p(a) \) and \( q(a) \) hold, the first element \( a \) is removed in both operations, and the remaining list is the same:
\[
\text{eraseP } q (\text{eraseP } p (a :: l)) = \text{eraseP } p (\text{eraseP } q (a :: l))
\]
- **Sub-case 1.2: \( q(a) \) does not hold**
- We simplify the goal using the hypotheses \( p(a) \) and \( \neg q(a) \), and the induction hypothesis. Since \( p(a) \) holds, the first element \( a \) is removed in the first operation, and the remaining list is the same:
\[
\text{eraseP } q (\text{eraseP } p (a :: l)) = \text{eraseP } p (\text{eraseP } q (a :: l))
\]

**Case 2: \( p(a) \) does not hold**
- **Sub-case 2.1: \( q(a) \) holds**
- We simplify the goal using the hypotheses \( \neg p(a) \) and \( q(a) \), and the induction hypothesis. Since \( q(a) \) holds, the first element \( a \) is removed in the first operation, and the remaining list is the same:
\[
\text{eraseP } q (\text{eraseP } p (a :: l)) = \text{eraseP } p (\text{eraseP } q (a :: l))
\]
- **Sub-case 2.2: \( q(a) \) does not hold**
- We simplify the goal using the hypotheses \( \neg p(a) \) and \( \neg q(a) \), and the induction hypothesis. Since neither \( p(a) \) nor \( q(a) \) holds, the first element \( a \) is not removed in either operation, and the remaining list is the same:
\[
\text{eraseP } q (\text{eraseP } p (a :: l)) = \text{eraseP } p (\text{eraseP } q (a :: l))
\]

By considering all cases, we have shown that the goal holds for the inductive step. Therefore, by induction, the theorem is true for all lists \( l \). This completes the proof.","theorem List.eraseP_comm {l : List α} (h : ∀ a ∈ l, ¬ p a ∨ ¬ q a) :
    (l.eraseP p).eraseP q = (l.eraseP q).eraseP p := by
  induction l with
/- For the base case where the list \( l \) is empty, the goal is trivially true by the reflexive property of equality. The empty list remains unchanged when elements are removed, so both sides of the equation are the same. -/
  | nil => rfl
/- For the inductive step, assume the list \( l \) is of the form \( a :: l \) (i.e., \( a \) is the head of the list and \( l \) is the tail). We will use the induction hypothesis \( ih \) to prove the goal for this case. -/
  | cons a l ih =>
/- We simplify the goal using the definition of `eraseP` for a list with a head and a tail. This simplification breaks down the goal into a more manageable form, specifically considering the cases where the head \( a \) satisfies the predicates \( p \) and \( q \). -/
    simp only [eraseP_cons]
/- Consider two cases: (1) Assume \( p(a) \) holds, and (2) Assume \( p(a) \) does not hold. -/
    by_cases h₁ : p a
/- For the case where \( p(a) \) holds, consider two sub-cases: (1) Assume \( q(a) \) holds, and (2) Assume \( q(a) \) does not hold. -/
    · by_cases h₂ : q a
/- For the sub-case where both \( p(a) \) and \( q(a) \) hold, we simplify the goal using the properties of `eraseP` and the induction hypothesis. This simplification shows that the goal holds. -/
      · simp_all
/- First, we simplify the goal using the hypotheses \( h_1 \) (which states \( \neg p(a) \)), \( h_2 \) (which states \( \neg q(a) \)), and the induction hypothesis \( ih \) (which states that for any element \( b \) in the list \( l \), if \( b \) satisfies \( p \) or \( q \), the result of removing elements that satisfy \( p \) and \( q \) is the same). This simplification shows that the goal holds. -/
      · simp [h₁, h₂, ih (fun b m => h b (mem_cons_of_mem _ m))]
/- For the case where \( p(a) \) does not hold, consider two sub-cases: (1) Assume \( q(a) \) holds, and (2) Assume \( q(a) \) does not hold. -/
    · by_cases h₂ : q a
/- For the sub-case where \( p(a) \) holds and \( q(a) \) does not hold, we simplify the goal using the hypotheses \( h_1 \) (which states \( p(a) \)), \( h_2 \) (which states \( \neg q(a) \)), and the induction hypothesis \( ih \). This simplification shows that the goal holds. -/
      · simp [h₁, h₂, ih (fun b m => h b (mem_cons_of_mem _ m))]
/- For the sub-case where \( p(a) \) does not hold and \( q(a) \) holds, we simplify the goal using the hypotheses \( h_1 \) (which states \( \neg p(a) \)), \( h_2 \) (which states \( q(a) \)), and the induction hypothesis \( ih \). This simplification shows that the goal holds. -/
/- For the sub-case where \( p(a) \) does not hold and \( q(a) \) does not hold, we simplify the goal using the hypotheses \( h_1 \) (which states \( \neg p(a) \)), \( h_2 \) (which states \( \neg q(a) \)), and the induction hypothesis \( ih \). This simplification shows that the goal holds. -/
      · simp [h₁, h₂, ih (fun b m => h b (mem_cons_of_mem _ m))]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open Nat
"
33615,List.IsPrefix.eraseIdx,"theorem List.IsPrefix.eraseIdx {l l' : List α} (h : l <+: l') (k : Nat) :
    eraseIdx l k <+: eraseIdx l' k := by sorry","Prefix Preservation under List Element Removal at Same Index : For any lists \( l \) and \( l' \) of elements of type \( \alpha \), if \( l \) is a prefix of \( l' \), then for any natural number \( k \), the list obtained by removing the element at index \( k \) from \( l \) is a prefix of the list obtained by removing the element at index \( k \) from \( l' \). In other words, if \( l \) is a prefix of \( l' \), then \( l \setminus \{l[k]\} \) is a prefix of \( l' \setminus \{l'[k]\} \).","theorem List.IsPrefix.eraseIdx {l l' : List α} (h : l <+: l') (k : Nat) :
    eraseIdx l k <+: eraseIdx l' k := by
  rcases h with ⟨t, rfl⟩
  if hkl : k < length l then
    simp [eraseIdx_append_of_lt_length hkl]
  else
    rw [Nat.not_lt] at hkl
    simp [eraseIdx_append_of_length_le hkl, eraseIdx_of_length_le hkl]","Given that \( l \) is a prefix of \( l' \), we can write \( l' \) as \( l \) concatenated with some list \( t \). Therefore, the goal is to show that removing the element at index \( k \) from \( l \) results in a list that is a prefix of the list obtained by removing the element at index \( k \) from \( l \) concatenated with \( t \).

Consider the following cases:

1. **Case 1: \( k \) is less than the length of \( l \):**
- In this case, removing the element at index \( k \) from \( l \) results in a list that is a prefix of the list obtained by removing the element at index \( k \) from \( l \) concatenated with \( t \). This is because the prefix relationship is preserved when removing elements at the same index from both lists.

2. **Case 2: \( k \) is greater than or equal to the length of \( l \):**
- Since \( k \) is not less than the length of \( l \), it follows that \( k \) is greater than or equal to the length of \( l \). Using this, we can simplify the goal by noting that removing the element at index \( k \) from \( l \) results in \( l \) itself, and removing the element at index \( k \) from \( l \) concatenated with \( t \) results in \( l \) concatenated with the list obtained by removing the element at index \( k - \text{length}(l) \) from \( t \). Therefore, the goal is to show that \( l \) is a prefix of \( l \) concatenated with the list obtained by removing the element at index \( k - \text{length}(l) \) from \( t \), which is trivially true.

In both cases, the goal is satisfied, and thus the theorem is proved.","theorem List.IsPrefix.eraseIdx {l l' : List α} (h : l <+: l') (k : Nat) :
    eraseIdx l k <+: eraseIdx l' k := by
  rcases h with ⟨t, rfl⟩
  if hkl : k < length l then
    simp [eraseIdx_append_of_lt_length hkl]
  else
    rw [Nat.not_lt] at hkl
    simp [eraseIdx_append_of_length_le hkl, eraseIdx_of_length_le hkl]","import Init.Data.List.Pairwise
import Init.Data.List.Erase

open List
open IsPrefix
open Nat
variable [BEq α]
"
33655,List.mk_mem_enumFrom_iff_le_and_getElem?_sub,"theorem List.mk_mem_enumFrom_iff_le_and_getElem?_sub {n i : Nat} {x : α} {l : List α} :
    (i, x) ∈ enumFrom n l ↔ n ≤ i ∧ l[i - n]? = x := by sorry","Membership in Enumerated List: \(i \geq n\) and Element at Index \(i - n\) : For any type \(\alpha\), any natural numbers \(n\) and \(i\), any element \(x\) of type \(\alpha\), and any list \(l\) of elements of type \(\alpha\), the pair \((i, x)\) is a member of the list `List.enumFrom n l` if and only if \(n \leq i\) and the element at index \(i - n\) in \(l\) is \(x\).","theorem List.mk_mem_enumFrom_iff_le_and_getElem?_sub {n i : Nat} {x : α} {l : List α} :
    (i, x) ∈ enumFrom n l ↔ n ≤ i ∧ l[i - n]? = x := by
  if h : n ≤ i then
    rcases Nat.exists_eq_add_of_le h with ⟨i, rfl⟩
    simp [mk_add_mem_enumFrom_iff_getElem?, Nat.add_sub_cancel_left]
  else
    have : ∀ k, n + k ≠ i := by rintro k rfl; simp at h
    simp [h, mem_iff_get?, this]","We need to prove the equivalence \((i, x) \in \text{List.enumFrom } n \, l \leftrightarrow n \leq i \land l[i - n]? = \text{some } x\).

1. **(\(\rightarrow\))** Assume \((i, x) \in \text{List.enumFrom } n \, l\). By the definition of \(\text{List.enumFrom } n \, l\), this means there exists some \(k\) such that \(i = n + k\) and \(l[k]? = \text{some } x\). Therefore, \(n \leq i\) and \(l[i - n]? = \text{some } x\).

2. **(\(\leftarrow\))** Assume \(n \leq i\) and \(l[i - n]? = \text{some } x\). Let \(k = i - n\). Then \(i = n + k\) and \(l[k]? = \text{some } x\). By the definition of \(\text{List.enumFrom } n \, l\), \((i, x) \in \text{List.enumFrom } n \, l\).

To handle the case where \(n > i\), we show that \((i, x) \notin \text{List.enumFrom } n \, l\). We first prove that for all natural numbers \(k\), \(n + k \neq i\). This is true because if \(n + k = i\), then \(n \leq i\), which contradicts our assumption \(n > i\). Using this new hypothesis and the fact that \(n > i\), we simplify the goal using the lemma that states \((i, x) \in l\) if and only if the element at index \(i\) in \(l\) is \(x\). This simplification shows that \((i, x) \notin \text{List.enumFrom } n \, l\).

Thus, we have shown both directions of the equivalence, completing the proof.","theorem List.mk_mem_enumFrom_iff_le_and_getElem?_sub {n i : Nat} {x : α} {l : List α} :
    (i, x) ∈ enumFrom n l ↔ n ≤ i ∧ l[i - n]? = x := by
  if h : n ≤ i then
    rcases Nat.exists_eq_add_of_le h with ⟨i, rfl⟩
    simp [mk_add_mem_enumFrom_iff_getElem?, Nat.add_sub_cancel_left]
/- We consider the case where \(n > i\). We first show that for all natural numbers \(k\), \(n + k \neq i\). This is true because if \(n + k = i\), then \(n \leq i\), which contradicts our assumption \(n > i\). Using this new hypothesis and the fact that \(n > i\), we simplify the goal using the lemma that states \((i, x) \in l\) if and only if the element at index \(i\) in \(l\) is \(x\). This simplification shows that \((i, x) \notin \text{List.enumFrom } n \, l\). -/
  else
    have : ∀ k, n + k ≠ i := by rintro k rfl; simp at h
    simp [h, mem_iff_get?, this]","import Init.Data.List.Nat.TakeDrop
import Init.Data.List.Pairwise
import Init.Data.List.Nat.Range

open List
open Nat
"
34209,Char.lt_irrefl,theorem Char.lt_irrefl (a : Char) : ¬ a < a := by sorry,"Irreflexivity of Less-Than Relation on Characters: \( \neg (a < a) \) : For any character \( a \) in the Unicode character type `Char`, it is not the case that \( a < a \). In other words, the less-than relation on characters is irreflexive, i.e., \( \neg (a < a) \).","theorem Char.lt_irrefl (a : Char) : ¬ a < a := by
  simp","To prove that for any character \( a \), \( \neg (a < a) \), we use the properties of the less-than relation on characters. The less-than relation on characters is defined such that \( a < b \) if and only if the integer value of \( a \) is less than the integer value of \( b \).

By the definition of the less-than relation, \( a < a \) would imply that the integer value of \( a \) is less than itself, which is a contradiction. Therefore, \( a < a \) is false. This means that \( \neg (a < a) \) holds for any character \( a \). Hence, the less-than relation on characters is irreflexive. This completes the proof.","theorem Char.lt_irrefl (a : Char) : ¬ a < a := by
  simp","import Init.Data.Char.Basic
import Init.Data.UInt.Lemmas
import Init.Data.Char.Lemmas

open Char

"
34238,Char.ofNat_toNat,theorem Char.ofNat_toNat (c : Char) : Char.ofNat c.toNat = c := by sorry,"Character Conversion: $\text{Char.ofNat}(c.\text{toNat}) = c$ : For any Unicode character \( c \), the conversion from the natural number representation of \( c \) back to a character using the function `Char.ofNat` results in the original character \( c \). Formally, \( \text{Char.ofNat}(c.\text{toNat}) = c \).","theorem Char.ofNat_toNat (c : Char) : Char.ofNat c.toNat = c := by
  rw [Char.ofNat, dif_pos]
  rfl","To prove that for any Unicode character \( c \), the conversion from the natural number representation of \( c \) back to a character using the function `Char.ofNat` results in the original character \( c \), we start by using the definition of `Char.ofNat`.

The function `Char.ofNat` is defined such that for a natural number \( n \), if \( n \) is a valid Unicode scalar value, then `Char.ofNat n` is `Char.ofNatAux n h`, where \( h \) is a proof that \( n \) is valid. Otherwise, it returns the null character `'\0'`.

Given a character \( c \), we know that \( c.toNat \) is a valid Unicode scalar value. Therefore, the expression `Char.ofNat c.toNat` simplifies to `Char.ofNatAux c.toNat h`, where \( h \) is a proof that \( c.toNat \) is valid.

By the definition of `Char.ofNatAux`, we have that `Char.ofNatAux c.toNat h` is definitionally equal to \( c \). Hence, the equality \( \text{Char.ofNat}(c.\text{toNat}) = c \) holds by definition.

This completes the proof.","theorem Char.ofNat_toNat (c : Char) : Char.ofNat c.toNat = c := by
/- First, we use the definition of `Char.ofNat` and the property of dependent if-then-else to simplify the goal. The definition of `Char.ofNat` states that for a natural number \( n \), if \( n \) is a valid Unicode scalar value, then `Char.ofNat n` is `Char.ofNatAux n h`, where \( h \) is a proof that \( n \) is valid. Otherwise, it returns the null character `'\0'`. Since we are dealing with a character \( c \), we know that \( c.toNat \) is a valid Unicode scalar value. Therefore, the goal simplifies to showing that `Char.ofNatAux c.toNat h = c`, where \( h \) is a proof that \( c.toNat \) is valid. -/
  rw [Char.ofNat, dif_pos]
/- The current goal is trivially true due to the reflexive property. Since `Char.ofNatAux c.toNat h` is definitionally equal to \( c \) when \( c.toNat \) is valid, the equality `Char.ofNatAux c.toNat h = c` holds by definition. -/
  rfl","import Init.Data.Char.Basic
import Init.Data.UInt.Lemmas
import Init.Data.Char.Lemmas

open Char

"
34411,List.pairwise_singleton,theorem List.pairwise_singleton (R) (a : α) : Pairwise R [a] := by sorry,"Pairwise Relation on a Singleton List: \([a]\) is Pairwise \( R \) : For any type \( \alpha \) and any binary relation \( R \) on \( \alpha \), the list \([a]\) consisting of a single element \( a \) satisfies the pairwise relation \( R \). In other words, the list \([a]\) is pairwise \( R \)-related.","theorem List.pairwise_singleton (R) (a : α) : Pairwise R [a] := by
  simp","To prove that the list \([a]\) is pairwise \( R \)-related, we need to show that for any two distinct elements \( x \) and \( y \) in the list, \( R(x, y) \) holds. However, the list \([a]\) contains only one element \( a \), and there are no pairs of distinct elements to check. Therefore, the pairwise relation \( R \) is trivially satisfied. Hence, the list \([a]\) is pairwise \( R \)-related. This completes the proof.","theorem List.pairwise_singleton (R) (a : α) : Pairwise R [a] := by
  simp","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Nat
"
34415,List.pairwise_pair,"theorem List.pairwise_pair {a b : α} : Pairwise R [a, b] ↔ R a b := by sorry","Pairwise Relation on a Two-Element List: \([a, b]\) is Pairwise \( R \) if and only if \( R(a, b) \) : For any type \( \alpha \) and any binary relation \( R \) on \( \alpha \), the list \([a, b]\) satisfies the pairwise relation \( R \) if and only if \( R(a, b) \) holds. In other words, the list \([a, b]\) is pairwise \( R \) if and only if \( a \) and \( b \) are related by \( R \).","theorem List.pairwise_pair {a b : α} : Pairwise R [a, b] ↔ R a b := by
  simp","To prove the theorem, we need to show that the list \([a, b]\) satisfies the pairwise relation \( R \) if and only if \( R(a, b) \) holds.

1. **Simplification:**
Using the simplification rules for the pairwise relation on lists, we can simplify the proposition we want to show. Specifically, the pairwise relation on the list \([a, b]\) is equivalent to the relation \( R(a, b) \). Therefore, the goal is to show that \( \text{Pairwise } R [a, b] \) is equivalent to \( R(a, b) \).

2. **Conclusion:**
Since the simplification rules directly give us the equivalence, we conclude that the list \([a, b]\) satisfies the pairwise relation \( R \) if and only if \( R(a, b) \) holds.

This completes the proof.","theorem List.pairwise_pair {a b : α} : Pairwise R [a, b] ↔ R a b := by
  simp","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Nat
"
34430,List.pairwise_of_forall,"theorem List.pairwise_of_forall {l : List α} (H : ∀ x y, R x y) : Pairwise R l := by sorry","Pairwise Relation Holds for All Elements in a List : For any type \( \alpha \) and any relation \( R : \alpha \to \alpha \to \text{Prop} \), if \( R \) holds for all pairs of elements \( x, y \in \alpha \), then the list \( l \) of elements of type \( \alpha \) satisfies the pairwise relation \( \text{Pairwise } R \, l \).","theorem List.pairwise_of_forall {l : List α} (H : ∀ x y, R x y) : Pairwise R l := by
  induction l <;> simp [*]","We perform induction on the list \( l \).

1. **Base Case:**
- When \( l \) is the empty list, we need to show that \( \text{Pairwise } R \, [] \).
- By the definition of \( \text{Pairwise } R \), the empty list trivially satisfies the pairwise relation because there are no pairs to check.
- Therefore, \( \text{Pairwise } R \, [] \) holds.

2. **Inductive Step:**
- Assume \( l = \text{head} :: \text{tail} \) and that \( \text{Pairwise } R \, \text{tail} \) holds.
- We need to show that \( \text{Pairwise } R \, (\text{head} :: \text{tail}) \).
- By the definition of \( \text{Pairwise } R \), we need to show that \( R \) holds for all pairs of elements in \( \text{head} :: \text{tail} \).
- Since \( R \) holds for all pairs of elements \( x, y \in \alpha \) by the hypothesis \( H \), it follows that \( R \) holds for the head and any element in the tail, and \( R \) holds for all pairs in the tail by the inductive hypothesis.
- Therefore, \( \text{Pairwise } R \, (\text{head} :: \text{tail}) \) holds.

By induction, we have shown that for any list \( l \) of elements of type \( \alpha \), if \( R \) holds for all pairs of elements \( x, y \in \alpha \), then \( \text{Pairwise } R \, l \) holds. This completes the proof. \(\blacksquare\)","theorem List.pairwise_of_forall {l : List α} (H : ∀ x y, R x y) : Pairwise R l := by
/- We perform induction on the list \( l \). For the base case, when \( l \) is the empty list, we need to show that \( \text{Pairwise } R \, [] \). For the inductive step, assume \( l = \text{head} :: \text{tail} \) and that \( \text{Pairwise } R \, \text{tail} \) holds. We need to show that \( \text{Pairwise } R \, (\text{head} :: \text{tail}) \). In both cases, we simplify the goal using the hypothesis \( H \) that \( R \) holds for all pairs of elements. -/
  induction l <;> simp [*]","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Nat
"
34432,List.nodup_replicate,"theorem List.nodup_replicate {n : Nat} {a : α} :
    (replicate n a).Nodup ↔ n ≤ 1 := by sorry","List with No Duplicates if and only if \( n \leq 1 \) in `replicate` Function : For any type \( \alpha \) and any natural number \( n \), the list `replicate n a` has no duplicate elements if and only if \( n \leq 1 \). In other words, the list containing \( n \) copies of the element \( a \) has no duplicates if and only if \( n \) is less than or equal to 1.","theorem List.nodup_replicate {n : Nat} {a : α} :
    (replicate n a).Nodup ↔ n ≤ 1 := by
  simp [Nodup]","To prove the theorem, we need to show that the list `replicate n a` has no duplicate elements if and only if \( n \leq 1 \).

1. **Simplification:**
Using the definition of `Nodup`, we simplify the proposition we want to show. The list `replicate n a` has no duplicate elements if and only if \( n \leq 1 \).

2. **Case Analysis:**
- **Case 1: \( n = 0 \)**
- If \( n = 0 \), the list `replicate 0 a` is the empty list `[]`.
- The empty list has no duplicate elements by definition.
- Therefore, `replicate 0 a` has no duplicate elements, and \( 0 \leq 1 \) is true.
- **Case 2: \( n = 1 \)**
- If \( n = 1 \), the list `replicate 1 a` is the list `[a]`.
- The list `[a]` has no duplicate elements because it contains only one element.
- Therefore, `replicate 1 a` has no duplicate elements, and \( 1 \leq 1 \) is true.
- **Case 3: \( n > 1 \)**
- If \( n > 1 \), the list `replicate n a` contains at least two elements, all of which are \( a \).
- Since the list contains at least two identical elements, it has duplicate elements.
- Therefore, `replicate n a` has duplicate elements, and \( n \leq 1 \) is false.

3. **Conclusion:**
From the above cases, we see that the list `replicate n a` has no duplicate elements if and only if \( n \leq 1 \).

Thus, the theorem is proved. \(\blacksquare\)","theorem List.nodup_replicate {n : Nat} {a : α} :
    (replicate n a).Nodup ↔ n ≤ 1 := by
  simp [Nodup]","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Nat
"
34435,List.get?_take,theorem List.get?_take {l : List α} {n m : Nat} (h : m < n) : (l.take n).get? m = l.get? m := by sorry,"Element at Index in Sublist Equals Element at Same Index in Original List : For any type $\alpha$, any list $l$ of elements of type $\alpha$, and any natural numbers $m$ and $n$ such that $m < n$, the $m$-th element of the list obtained by taking the first $n$ elements of $l$ is equal to the $m$-th element of $l$ itself, i.e., $(\text{take } n \, l).get? \, m = l.get? \, m$.","theorem List.get?_take {l : List α} {n m : Nat} (h : m < n) : (l.take n).get? m = l.get? m := by
  simp [getElem?_take, h]","We need to show that for any type \(\alpha\), any list \(l\) of elements of type \(\alpha\), and any natural numbers \(m\) and \(n\) such that \(m < n\), the \(m\)-th element of the list obtained by taking the first \(n\) elements of \(l\) is equal to the \(m\)-th element of \(l\) itself.

Using the theorem that the \(m\)-th element of the list obtained by taking the first \(n\) elements of \(l\) is equal to the \(m\)-th element of \(l\) itself, and the hypothesis that \(m < n\), we can simplify the proposition we want to show to \((\text{take } n \, l).get? \, m = l.get? \, m\). This simplification directly proves the goal.

Thus, the theorem is proved. \(\blacksquare\)","theorem List.get?_take {l : List α} {n m : Nat} (h : m < n) : (l.take n).get? m = l.get? m := by
/- Using the theorem that the \(m\)-th element of the list obtained by taking the first \(n\) elements of \(l\) is equal to the \(m\)-th element of \(l\) itself, and the hypothesis that \(m < n\), we can simplify the proposition we want to show to \((\text{take } n \, l).get? \, m = l.get? \, m\). This simplification directly proves the goal. -/
  simp [getElem?_take, h]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34436,List.take_left',theorem List.take_left' {l₁ l₂ : List α} {n} (h : length l₁ = n) : take n (l₁ ++ l₂) = l₁ := by sorry,"First \( n \) Elements of Concatenated List Equal to \( l_1 \) if \( |l_1| = n \) : For any type \( \alpha \) and any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), if the length of \( l_1 \) is equal to \( n \), then the first \( n \) elements of the concatenated list \( l_1 ++ l_2 \) are equal to \( l_1 \). Mathematically, this can be expressed as:
\[ \text{If } |l_1| = n, \text{ then } \text{take } n \ (l_1 ++ l_2) = l_1. \]","theorem List.take_left' {l₁ l₂ : List α} {n} (h : length l₁ = n) : take n (l₁ ++ l₂) = l₁ := by
  rw [← h]; apply take_left","We start with the assumption that the length of \( l_1 \) is \( n \), i.e., \( |l_1| = n \). We need to show that the first \( n \) elements of the concatenated list \( l_1 ++ l_2 \) are equal to \( l_1 \).

1. Using the assumption \( |l_1| = n \), we rewrite the goal to show that the first \( l_1 \).length elements of \( l_1 ++ l_2 \) are equal to \( l_1 \).
2. By the theorem that states the first \( l_1 \).length elements of \( l_1 ++ l_2 \) are indeed \( l_1 \), we conclude that \( \text{take } n \ (l_1 ++ l_2) = l_1 \).

Thus, the theorem is proved.","theorem List.take_left' {l₁ l₂ : List α} {n} (h : length l₁ = n) : take n (l₁ ++ l₂) = l₁ := by
/- First, we use the assumption \( l_1 \) has length \( n \) (i.e., \( |l_1| = n \)) to rewrite the goal. Specifically, we substitute \( n \) with \( l_1 \).length in the goal. This simplifies the goal to showing that the first \( l_1 \).length elements of the concatenated list \( l_1 ++ l_2 \) are equal to \( l_1 \). Then, we apply the theorem that states the first \( l_1 \).length elements of \( l_1 ++ l_2 \) are indeed \( l_1 \). -/
  rw [← h]; apply take_left","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34437,List.pairwise_append_comm,"theorem List.pairwise_append_comm {R : α → α → Prop} (s : ∀ {x y}, R x y → R y x) {l₁ l₂ : List α} :
    Pairwise R (l₁ ++ l₂) ↔ Pairwise R (l₂ ++ l₁) := by sorry","Symmetric Pairwise Relation on Appended Lists: \(\text{Pairwise } R (l_1 ++ l_2) \leftrightarrow \text{Pairwise } R (l_2 ++ l_1)\) : For any type \( \alpha \) and any symmetric relation \( R \) on \( \alpha \), and for any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), the list \( l_1 \) appended to \( l_2 \) satisfies the pairwise relation \( R \) if and only if the list \( l_2 \) appended to \( l_1 \) satisfies the pairwise relation \( R \). In other words, if \( R \) is symmetric, then \( \text{Pairwise } R (l_1 ++ l_2) \) holds if and only if \( \text{Pairwise } R (l_2 ++ l_1) \) holds.","theorem List.pairwise_append_comm {R : α → α → Prop} (s : ∀ {x y}, R x y → R y x) {l₁ l₂ : List α} :
    Pairwise R (l₁ ++ l₂) ↔ Pairwise R (l₂ ++ l₁) := by
  have (l₁ l₂ : List α) (H : ∀ x : α, x ∈ l₁ → ∀ y : α, y ∈ l₂ → R x y)
    (x : α) (xm : x ∈ l₂) (y : α) (ym : y ∈ l₁) : R x y := s (H y ym x xm)
  simp only [pairwise_append, and_left_comm]; rw [Iff.intro (this l₁ l₂) (this l₂ l₁)]","We start by constructing a lemma: for any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), and for any elements \( x \) and \( y \) of type \( \alpha \), if \( x \) is in \( l_2 \) and \( y \) is in \( l_1 \), and if \( R \) holds for all elements in \( l_1 \) and \( l_2 \), then \( R \) also holds for \( x \) and \( y \). This follows from the symmetry of \( R \).

Next, we use the definition of the pairwise relation on appended lists and the commutativity of conjunction to simplify the goal. We need to show that the pairwise relation \( R \) holds for \( l_1 \) appended to \( l_2 \) if and only if it holds for \( l_2 \) appended to \( l_1 \). This is equivalent to showing that the pairwise relation \( R \) holds for \( l_1 \) and \( l_2 \) in both orders, which we have already established in the lemma.

Thus, we conclude that \( \text{Pairwise } R (l_1 ++ l_2) \) holds if and only if \( \text{Pairwise } R (l_2 ++ l_1) \) holds. This completes the proof.","theorem List.pairwise_append_comm {R : α → α → Prop} (s : ∀ {x y}, R x y → R y x) {l₁ l₂ : List α} :
    Pairwise R (l₁ ++ l₂) ↔ Pairwise R (l₂ ++ l₁) := by
/- We first construct a lemma: for any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), and for any elements \( x \) and \( y \) of type \( \alpha \), if \( x \) is in \( l_2 \) and \( y \) is in \( l_1 \), and if \( R \) holds for all elements in \( l_1 \) and \( l_2 \), then \( R \) also holds for \( x \) and \( y \). This follows from the symmetry of \( R \). -/
  have (l₁ l₂ : List α) (H : ∀ x : α, x ∈ l₁ → ∀ y : α, y ∈ l₂ → R x y)
    (x : α) (xm : x ∈ l₂) (y : α) (ym : y ∈ l₁) : R x y := s (H y ym x xm)
/- Using the definition of pairwise relation on appended lists and the commutativity of conjunction, we simplify the goal to show that the pairwise relation \( R \) holds for \( l_1 \) appended to \( l_2 \) if and only if it holds for \( l_2 \) appended to \( l_1 \). This is equivalent to showing that the pairwise relation \( R \) holds for \( l_1 \) and \( l_2 \) in both orders, which we have already established in the lemma. -/
  simp only [pairwise_append, and_left_comm]; rw [Iff.intro (this l₁ l₂) (this l₂ l₁)]","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Nat
"
34438,List.get_cons_drop,theorem List.get_cons_drop (l : List α) (i) : get l i :: drop (i + 1) l = drop i l := by sorry,"List Element at Index Preceded by Tail Equals Dropped List : For any list \( l \) of elements of type \( \alpha \) and any index \( i \) of type \( \text{Fin } l.\text{length} \), the list obtained by taking the \( i \)-th element of \( l \) and appending the list obtained by dropping the first \( i + 1 \) elements of \( l \) is equal to the list obtained by dropping the first \( i \) elements of \( l \). In other words, \( l[i] :: \text{List.drop}(i + 1, l) = \text{List.drop}(i, l) \).","theorem List.get_cons_drop (l : List α) (i) : get l i :: drop (i + 1) l = drop i l := by
  simp","We need to show that for any list \( l \) and any index \( i \) in the range of the length of \( l \), the following equality holds:
\[ l[i] :: \text{List.drop}(i + 1, l) = \text{List.drop}(i, l). \]

To prove this, we use the properties of list operations and element retrieval. Specifically, we use the following properties:
1. The `List.cons` function constructs a new list by adding an element to the front of an existing list.
2. The `List.drop` function removes the first \( n \) elements from a list.
3. The `GetElem.getElem` function retrieves the element at a specified index in a list, provided the index is valid.

By these properties, we can simplify the left-hand side of the equation:
\[ l[i] :: \text{List.drop}(i + 1, l). \]

The element \( l[i] \) is the \( i \)-th element of the list \( l \). The list \( \text{List.drop}(i + 1, l) \) is the list obtained by removing the first \( i + 1 \) elements of \( l \). Therefore, appending \( l[i] \) to the front of \( \text{List.drop}(i + 1, l) \) results in a list that is equivalent to the list obtained by removing the first \( i \) elements of \( l \), which is \( \text{List.drop}(i, l) \).

Thus, we have:
\[ l[i] :: \text{List.drop}(i + 1, l) = \text{List.drop}(i, l). \]

This completes the proof.","theorem List.get_cons_drop (l : List α) (i) : get l i :: drop (i + 1) l = drop i l := by
/- Using the properties of list operations and element retrieval, we can simplify the proposition we want to show. Specifically, we need to show that the list obtained by taking the \( i \)-th element of \( l \) and appending the list obtained by dropping the first \( i + 1 \) elements of \( l \) is equal to the list obtained by dropping the first \( i \) elements of \( l \). This simplification is straightforward and follows from the definitions and properties of list operations. -/
  simp","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34439,List.take_of_length_le,theorem List.take_of_length_le {l : List α} (h : l.length ≤ i) : take i l = l := by sorry,"Taking First \( i \) Elements of a List Equals the List if Length is Less Than or Equal to \( i \) : For any list \( l \) of elements of type \( \alpha \) and any natural number \( i \), if the length of \( l \) is less than or equal to \( i \), then taking the first \( i \) elements of \( l \) results in the list \( l \) itself, i.e., \( \text{take}(i, l) = l \).","theorem List.take_of_length_le {l : List α} (h : l.length ≤ i) : take i l = l := by
  have := take_append_drop i l
  rw [drop_of_length_le h, append_nil] at this; exact this","We start by using the lemma that the concatenation of the first $i$ elements of a list $l$ and the list obtained by dropping the first $i$ elements of $l$ is equal to the original list $l$. This gives us the equation:
\[
\text{take}(i, l) \oplus \text{drop}(i, l) = l
\]
Next, we use the fact that if the length of $l$ is less than or equal to $i$, then dropping the first $i$ elements of $l$ results in the empty list. Therefore, we have:
\[
\text{drop}(i, l) = \text{nil}
\]
Substituting this into our equation, we get:
\[
\text{take}(i, l) \oplus \text{nil} = l
\]
Since concatenating any list with the empty list results in the original list, we have:
\[
\text{take}(i, l) = l
\]
This completes the proof.","theorem List.take_of_length_le {l : List α} (h : l.length ≤ i) : take i l = l := by
/- First, we use the lemma that the concatenation of the first $i$ elements of a list $l$ and the list obtained by dropping the first $i$ elements of $l$ is equal to the original list $l$. This gives us the equation $\text{take}(i, l) \oplus \text{drop}(i, l) = l$. -/
  have := take_append_drop i l
/- Next, we use the fact that if the length of $l$ is less than or equal to $i$, then dropping the first $i$ elements of $l$ results in the empty list. This simplifies our equation to $\text{take}(i, l) \oplus \text{nil} = l$. Since concatenating any list with the empty list results in the original list, we have $\text{take}(i, l) = l$. This completes the proof. -/
  rw [drop_of_length_le h, append_nil] at this; exact this","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34444,List.pairwise_append,"theorem List.pairwise_append {l₁ l₂ : List α} :
    (l₁ ++ l₂).Pairwise R ↔ l₁.Pairwise R ∧ l₂.Pairwise R ∧ ∀ a ∈ l₁, ∀ b ∈ l₂, R a b := by sorry","Pairwise Relation on Appended Lists : For any type \( \alpha \) and any relation \( R : \alpha \to \alpha \to \text{Prop} \), the list \( l_1 \) appended with the list \( l_2 \) (denoted as \( l_1 ++ l_2 \)) satisfies the pairwise relation \( R \) if and only if:
1. \( l_1 \) satisfies the pairwise relation \( R \),
2. \( l_2 \) satisfies the pairwise relation \( R \), and
3. For any elements \( a \) in \( l_1 \) and \( b \) in \( l_2 \), the relation \( R a b \) holds.","theorem List.pairwise_append {l₁ l₂ : List α} :
    (l₁ ++ l₂).Pairwise R ↔ l₁.Pairwise R ∧ l₂.Pairwise R ∧ ∀ a ∈ l₁, ∀ b ∈ l₂, R a b := by
  induction l₁ <;> simp [*, or_imp, forall_and, and_assoc, and_left_comm]","We perform induction on the list \( l_1 \).

**Base Case:**
When \( l_1 \) is the empty list, we need to show that the pairwise relation \( R \) holds for the empty list appended with \( l_2 \) if and only if the pairwise relation \( R \) holds for \( l_2 \) and for any elements \( a \) in the empty list and \( b \) in \( l_2 \), the relation \( R a b \) holds. Since the empty list has no elements, the condition \( a \in \text{empty list} \) is always false, making the implication \( a \in \text{empty list} \to R a b \) vacuously true. Therefore, the pairwise relation \( R \) holds for the empty list appended with \( l_2 \) if and only if the pairwise relation \( R \) holds for \( l_2 \).

**Inductive Step:**
Assume \( l_1 = \text{head} :: \text{tail} \). By the inductive hypothesis, the pairwise relation \( R \) holds for \( \text{tail} \) appended with \( l_2 \) if and only if the pairwise relation \( R \) holds for \( \text{tail} \) and \( l_2 \), and for any elements \( a \) in \( \text{tail} \) and \( b \) in \( l_2 \), the relation \( R a b \) holds. We need to show that the pairwise relation \( R \) holds for \( \text{head} :: \text{tail} \) appended with \( l_2 \) if and only if the pairwise relation \( R \) holds for \( \text{head} :: \text{tail} \), \( l_2 \), and for any elements \( a \) in \( \text{head} :: \text{tail} \) and \( b \) in \( l_2 \), the relation \( R a b \) holds.

Using the properties of logical conjunction and disjunction, we simplify the goal. The pairwise relation \( R \) holds for \( \text{head} :: \text{tail} \) if and only if \( R \) holds for \( \text{head} \) and all elements in \( \text{tail} \), and \( R \) holds for all elements in \( \text{tail} \). Therefore, the pairwise relation \( R \) holds for \( \text{head} :: \text{tail} \) appended with \( l_2 \) if and only if:
1. \( R \) holds for \( \text{head} \) and all elements in \( \text{tail} \),
2. \( R \) holds for all elements in \( \text{tail} \),
3. \( R \) holds for all elements in \( l_2 \),
4. For any elements \( a \) in \( \text{head} :: \text{tail} \) and \( b \) in \( l_2 \), the relation \( R a b \) holds.

By the inductive hypothesis, the pairwise relation \( R \) holds for \( \text{tail} \) appended with \( l_2 \) if and only if the pairwise relation \( R \) holds for \( \text{tail} \) and \( l_2 \), and for any elements \( a \) in \( \text{tail} \) and \( b \) in \( l_2 \), the relation \( R a b \) holds. Therefore, the pairwise relation \( R \) holds for \( \text{head} :: \text{tail} \) appended with \( l_2 \) if and only if the pairwise relation \( R \) holds for \( \text{head} :: \text{tail} \), \( l_2 \), and for any elements \( a \) in \( \text{head} :: \text{tail} \) and \( b \) in \( l_2 \), the relation \( R a b \) holds.

This completes the proof.","theorem List.pairwise_append {l₁ l₂ : List α} :
    (l₁ ++ l₂).Pairwise R ↔ l₁.Pairwise R ∧ l₂.Pairwise R ∧ ∀ a ∈ l₁, ∀ b ∈ l₂, R a b := by
/- We perform induction on the list \( l_1 \). For the base case where \( l_1 \) is the empty list, we need to show that the pairwise relation \( R \) holds for the empty list appended with \( l_2 \) if and only if the pairwise relation \( R \) holds for \( l_2 \) and for any elements \( a \) in the empty list and \( b \) in \( l_2 \), the relation \( R a b \) holds. For the inductive step, assume \( l_1 = \text{head} :: \text{tail} \) and use the inductive hypothesis that the pairwise relation \( R \) holds for \( \text{tail} \) appended with \( l_2 \) if and only if the pairwise relation \( R \) holds for \( \text{tail} \) and \( l_2 \), and for any elements \( a \) in \( \text{tail} \) and \( b \) in \( l_2 \), the relation \( R a b \) holds. We then need to show that the pairwise relation \( R \) holds for \( \text{head} :: \text{tail} \) appended with \( l_2 \) if and only if the pairwise relation \( R \) holds for \( \text{head} :: \text{tail} \), \( l_2 \), and for any elements \( a \) in \( \text{head} :: \text{tail} \) and \( b \) in \( l_2 \), the relation \( R a b \) holds. Using the properties of logical conjunction and disjunction, we simplify the goal to show the equivalence. -/
  induction l₁ <;> simp [*, or_imp, forall_and, and_assoc, and_left_comm]","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Nat
"
34445,List.takeWhile_cons_of_neg,"theorem List.takeWhile_cons_of_neg {p : α → Bool} {a : α} {l : List α} (h : ¬ p a) :
    (a :: l).takeWhile p = [] := by sorry","TakeWhile of Cons with Negative Predicate Returns Empty List : For any type \( \alpha \), predicate \( p : \alpha \to \text{Bool} \), element \( a \in \alpha \), and list \( l \) of elements of type \( \alpha \), if \( p(a) \) is `false`, then the longest initial segment of the list \( a :: l \) that satisfies \( p \) is the empty list, i.e., \(\text{takeWhile } p (a :: l) = []\).","theorem List.takeWhile_cons_of_neg {p : α → Bool} {a : α} {l : List α} (h : ¬ p a) :
    (a :: l).takeWhile p = [] := by
  simp [takeWhile_cons, h]","We start with the given hypothesis that \( p(a) \) is `false`. According to the definition of `List.takeWhile` on a cons list, we have:
\[ \text{List.takeWhile } p (a :: l) = \begin{cases}
a :: \text{List.takeWhile } p \, l & \text{if } p(a) = \text{true} \\
[] & \text{if } p(a) = \text{false}
\end{cases} \]
Since \( p(a) = \text{false} \) by the hypothesis, it follows that:
\[ \text{List.takeWhile } p (a :: l) = [] \]
Thus, the longest initial segment of the list \( a :: l \) that satisfies \( p \) is indeed the empty list. This completes the proof.","theorem List.takeWhile_cons_of_neg {p : α → Bool} {a : α} {l : List α} (h : ¬ p a) :
    (a :: l).takeWhile p = [] := by
/- Using the definition of `List.takeWhile` on a cons list and the hypothesis \( \neg p(a) = \text{true} \), we can simplify the proposition we want to show. Specifically, the definition of `List.takeWhile` on a cons list states that:
\[ \text{List.takeWhile } p (a :: l) = \begin{cases}
a :: \text{List.takeWhile } p \, l & \text{if } p(a) = \text{true} \\
[] & \text{if } p(a) = \text{false}
\end{cases} \]
Since \( \neg p(a) = \text{true} \) is given, it follows that \( p(a) = \text{false} \). Therefore, \(\text{List.takeWhile } p (a :: l) = []\). -/
  simp [takeWhile_cons, h]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34447,List.drop_eq_get_cons,"theorem List.drop_eq_get_cons {n} {l : List α} (h) : drop n l = get l ⟨n, h⟩ :: drop (n + 1) l := by sorry","List Drop Equals Get Cons: \(\text{drop}(n, l) = l[n] :: \text{drop}(n + 1, l)\) : For any type \(\alpha\), natural number \(n\), and list \(l\) of elements of type \(\alpha\), if \(n\) is less than the length of \(l\), then the list obtained by dropping the first \(n\) elements of \(l\) is equal to the list formed by the \(n\)-th element of \(l\) followed by the list obtained by dropping the first \(n + 1\) elements of \(l\). Mathematically, this can be expressed as:
\[
\text{If } n < \text{length}(l), \text{ then } \text{drop}(n, l) = l[n] :: \text{drop}(n + 1, l).
\]","theorem List.drop_eq_get_cons {n} {l : List α} (h) : drop n l = get l ⟨n, h⟩ :: drop (n + 1) l := by
  simp [drop_eq_getElem_cons]","To prove the theorem, we start with the assumption that \( n < \text{length}(l) \). We need to show that:
\[
\text{drop}(n, l) = l[n] :: \text{drop}(n + 1, l).
\]

We use the theorem that states the list obtained by dropping the first \( n \) elements of \( l \) is equal to the \( n \)-th element of \( l \) followed by the list obtained by dropping the first \( n + 1 \) elements of \( l \). This theorem, which we will refer to as the ""drop and get element theorem,"" directly gives us the desired equality:
\[
\text{drop}(n, l) = l[n] :: \text{drop}(n + 1, l).
\]

Thus, the theorem is proved. \(\blacksquare\)","theorem List.drop_eq_get_cons {n} {l : List α} (h) : drop n l = get l ⟨n, h⟩ :: drop (n + 1) l := by
/- Using the theorem that states the list obtained by dropping the first \( n \) elements of \( l \) is equal to the \( n \)-th element of \( l \) followed by the list obtained by dropping the first \( n + 1 \) elements of \( l \), we can simplify the goal to show that:
\[
\text{drop}(n, l) = l[n] :: \text{drop}(n + 1, l).
\]
This simplification is valid because the theorem `drop_eq_getElem_cons` directly states this equality under the assumption that \( n < \text{length}(l) \). -/
  simp [drop_eq_getElem_cons]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34448,List.nodup_cons,theorem List.nodup_cons {a : α} {l : List α} : Nodup (a :: l) ↔ a ∉ l ∧ Nodup l := by sorry,"Cons of List Preserves No Duplicates if and only if Element is Not in List and List has No Duplicates : For any type \( \alpha \), any element \( a \) of type \( \alpha \), and any list \( l \) of elements of type \( \alpha \), the list \( a :: l \) (i.e., the list obtained by adding \( a \) to the front of \( l \)) has no duplicate elements if and only if \( a \) is not a member of \( l \) and \( l \) itself has no duplicate elements. Formally, \((a :: l).Nodup \leftrightarrow \neg (a \in l) \land l.Nodup\).","theorem List.nodup_cons {a : α} {l : List α} : Nodup (a :: l) ↔ a ∉ l ∧ Nodup l := by
  simp only [Nodup, pairwise_cons, forall_mem_ne]","To prove the theorem, we start by using the definitions of the relevant concepts:

1. **Definition of `Nodup`:** A list \( l \) has no duplicate elements if and only if for all elements \( x \) and \( y \) in \( l \), if \( x \neq y \), then \( x \) and \( y \) are not the same element.
2. **Definition of `pairwise_cons`:** The list \( a :: l \) has no duplicate elements if and only if \( a \) is not in \( l \) and \( l \) has no duplicate elements.
3. **Definition of `forall_mem_ne`:** For all elements \( x \) and \( y \) in \( l \), if \( x \neq y \), then \( x \) and \( y \) are not the same element.

Using these definitions, we can simplify the proposition \((a :: l).Nodup\) to \(\neg (a \in l) \land l.Nodup\). This means that the list \( a :: l \) has no duplicate elements if and only if \( a \) is not a member of \( l \) and \( l \) itself has no duplicate elements.

Thus, we have shown that \((a :: l).Nodup \leftrightarrow \neg (a \in l) \land l.Nodup\). This completes the proof. \(\blacksquare\)","theorem List.nodup_cons {a : α} {l : List α} : Nodup (a :: l) ↔ a ∉ l ∧ Nodup l := by
/- Using the definitions of `Nodup`, `pairwise_cons`, and `forall_mem_ne`, we can simplify the proposition we want to show to \((a :: l).Nodup \leftrightarrow \neg (a \in l) \land l.Nodup\). -/
  simp only [Nodup, pairwise_cons, forall_mem_ne]","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Nat
"
34450,List.Pairwise.and,"theorem List.Pairwise.and (hR : Pairwise R l) (hS : Pairwise S l) :
    l.Pairwise fun a b => R a b ∧ S a b := by sorry","Pairwise Relations Combine under Conjunction: \( \text{Pairwise } R \land \text{Pairwise } S \to \text{Pairwise } (R \land S) \) : For any type \( \alpha \) and any two relations \( R \) and \( S \) on \( \alpha \), if a list \( l \) of elements of type \( \alpha \) is pairwise \( R \)-related and pairwise \( S \)-related, then \( l \) is pairwise \((R \land S)\)-related. In other words, if for all elements \( a \) and \( b \) in \( l \) where \( a \) appears before \( b \), both \( R(a, b) \) and \( S(a, b) \) hold, then \( (R \land S)(a, b) \) also holds for all such pairs.","theorem List.Pairwise.and (hR : Pairwise R l) (hS : Pairwise S l) :
    l.Pairwise fun a b => R a b ∧ S a b := by
  induction hR with
  | nil => simp only [Pairwise.nil]
  | cons R1 _ IH =>
    simp only [Pairwise.nil, pairwise_cons] at hS ⊢
    exact ⟨fun b bl => ⟨R1 b bl, hS.1 b bl⟩, IH hS.2⟩","We proceed by induction on the list \( l \).

1. **Base Case:**
- If \( l \) is the empty list, the pairwise \((R \land S)\)-related property holds trivially, as there are no elements to compare. This is a direct consequence of the definition of the pairwise property for an empty list.

2. **Inductive Step:**
- Assume \( l \) is a non-empty list of the form \( a :: l' \), where \( a \) is the first element and \( l' \) is the rest of the list.
- We need to show that \( l \) is pairwise \((R \land S)\)-related.
- By the induction hypothesis, \( l' \) is pairwise \((R \land S)\)-related.
- We also have the hypotheses that \( l \) is pairwise \( R \)-related and pairwise \( S \)-related.
- Specifically, for every element \( b \) in \( l' \), \( R(a, b) \) and \( S(a, b) \) hold.
- Therefore, for every element \( b \) in \( l' \), \( (R \land S)(a, b) \) holds.
- Combining this with the induction hypothesis, we conclude that \( l \) is pairwise \((R \land S)\)-related.

Thus, we have shown that if a list \( l \) is pairwise \( R \)-related and pairwise \( S \)-related, then \( l \) is pairwise \((R \land S)\)-related. This completes the proof. \(\blacksquare\)","theorem List.Pairwise.and (hR : Pairwise R l) (hS : Pairwise S l) :
    l.Pairwise fun a b => R a b ∧ S a b := by
  induction hR with
/- If the list \( l \) is empty, then the pairwise \((R \land S)\)-related property holds trivially, as there are no elements to compare. This is a direct consequence of the definition of the pairwise property for an empty list. -/
  | nil => simp only [Pairwise.nil]
/- We perform induction on the list \( l \). For the case where \( l \) is a non-empty list, we assume \( l \) is of the form \( a :: l' \), where \( a \) is the first element and \( l' \) is the rest of the list. We need to show that \( l \) is pairwise \((R \land S)\)-related. This involves proving that \( a \) is related to all elements in \( l' \) by both \( R \) and \( S \), and that \( l' \) itself is pairwise \((R \land S)\)-related. -/
  | cons R1 _ IH =>
/- We simplify the goal and the hypothesis \( hS \) using the definitions of the pairwise property for an empty list and the cons constructor. This simplification shows that \( hS \) can be decomposed into two parts: \( hS.1 \), which states that \( a \) is related to all elements in \( l' \) by \( S \), and \( hS.2 \), which states that \( l' \) is pairwise \( S \)-related. The goal is now to show that \( a \) is related to all elements in \( l' \) by both \( R \) and \( S \), and that \( l' \) is pairwise \((R \land S)\)-related. -/
    simp only [Pairwise.nil, pairwise_cons] at hS ⊢
/- To prove that the list \( l \) is pairwise \((R \land S)\)-related, we need to show that for every element \( b \) in \( l \) (where \( b \) appears after \( a \)), both \( R(a, b) \) and \( S(a, b) \) hold. This is achieved by using the fact that \( R1 \) and \( hS.1 \) provide the necessary proofs for \( R(a, b) \) and \( S(a, b) \) respectively, and the induction hypothesis \( IH \) ensures that the rest of the list \( l \) is pairwise \((R \land S)\)-related. -/
    exact ⟨fun b bl => ⟨R1 b bl, hS.1 b bl⟩, IH hS.2⟩","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Pairwise
open Nat
"
34451,List.pairwise_filter,"theorem List.pairwise_filter (p : α → Prop) [DecidablePred p] {l : List α} :
    Pairwise R (filter p l) ↔ Pairwise (fun x y => p x → p y → R x y) l := by sorry","Filtering Preserves Pairwise Relation if and only if Original List Satisfies Filtered Pairwise Relation : For any type \(\alpha\) and any relation \(R : \alpha \to \alpha \to \text{Prop}\), if \(p : \alpha \to \text{Prop}\) is a decidable predicate, then the list obtained by filtering a list \(l\) of elements of type \(\alpha\) using the predicate \(p\) is pairwise \(R\)-related if and only if the original list \(l\) is pairwise \((p x \to p y \to R x y)\)-related. In other words, if \(l\) is pairwise \(R\)-related, then \(\text{filter} \, p \, l\) is pairwise \(R\)-related, and conversely, if \(\text{filter} \, p \, l\) is pairwise \(R\)-related, then \(l\) is pairwise \((p x \to p y \to R x y)\)-related.","theorem List.pairwise_filter (p : α → Prop) [DecidablePred p] {l : List α} :
    Pairwise R (filter p l) ↔ Pairwise (fun x y => p x → p y → R x y) l := by
  rw [← filterMap_eq_filter, pairwise_filterMap]
  simp","To prove the theorem, we start by using the equivalence that the `filterMap` operation applied to the function `Option.guard p` is the same as the `filter` operation applied to the predicate \( p \). This allows us to rewrite the goal as follows:
\[
\text{Pairwise } R (\text{filter } p \, l) \leftrightarrow \text{Pairwise } (\forall b \in \text{Option.guard } p \, a, \forall b' \in \text{Option.guard } p \, a', R \, b \, b') \, l
\]
Next, we use the theorem that the pairwise relation on the filtered and mapped list is equivalent to the pairwise relation on the original list with a modified relation. Specifically, the list obtained by filtering \( l \) using \( p \) is pairwise \( R \)-related if and only if the original list \( l \) is pairwise \((\forall b \in \text{Option.guard } p \, a, \forall b' \in \text{Option.guard } p \, a', R \, b \, b')\)-related.

Finally, we simplify the proposition we want to show. The simplification process uses the properties of the `Option.guard` function and the decidable predicate \( p \) to reduce the goal to the desired form:
\[
\text{Pairwise } R (\text{filter } p \, l) \leftrightarrow \text{Pairwise } (p \, x \to p \, y \to R \, x \, y) \, l
\]
This completes the proof.","theorem List.pairwise_filter (p : α → Prop) [DecidablePred p] {l : List α} :
    Pairwise R (filter p l) ↔ Pairwise (fun x y => p x → p y → R x y) l := by
/- First, we use the equivalence that the `filterMap` operation applied to the function `Option.guard p` is the same as the `filter` operation applied to the predicate \( p \). This allows us to rewrite the goal. Then, we use the theorem that the pairwise relation on the filtered and mapped list is equivalent to the pairwise relation on the original list with a modified relation. Specifically, the list obtained by filtering \( l \) using \( p \) is pairwise \( R \)-related if and only if the original list \( l \) is pairwise \((\forall b \in \text{Option.guard } p \, a, \forall b' \in \text{Option.guard } p \, a', R \, b \, b')\)-related. -/
  rw [← filterMap_eq_filter, pairwise_filterMap]
/- Next, we simplify the proposition we want to show. The simplification process uses the properties of the `Option.guard` function and the decidable predicate \( p \) to reduce the goal to the desired form. Specifically, the simplified goal is that the list \( l \) is pairwise \((p \, x \to p \, y \to R \, x \, y)\)-related. -/
  simp","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Nat
"
34453,List.dropWhile_cons,"theorem List.dropWhile_cons :
    (x :: xs : List α).dropWhile p = if p x then xs.dropWhile p else x :: xs := by sorry","Drop While Predicate is True for First Element, Otherwise Keep First Element : For any type \( \alpha \), any element \( x \in \alpha \), any list \( xs \) of elements of type \( \alpha \), and any predicate \( p : \alpha \to \text{Bool} \), the result of applying `List.dropWhile p` to the list \( x :: xs \) is:
- If \( p(x) \) is `true`, then the result is `List.dropWhile p xs`.
- If \( p(x) \) is `false`, then the result is \( x :: xs \).","theorem List.dropWhile_cons :
    (x :: xs : List α).dropWhile p = if p x then xs.dropWhile p else x :: xs := by
  split <;> simp_all [dropWhile]","We start by considering the two cases based on the value of \( p(x) \).

1. **Case 1: \( p(x) = \text{true} \)**
- In this case, we need to show that \( \text{List.dropWhile } p (x :: xs) = \text{List.dropWhile } p \, xs \).
- By the definition of `List.dropWhile`, if \( p(x) = \text{true} \), the function `List.dropWhile p` will skip the first element \( x \) and continue to process the rest of the list \( xs \).
- Therefore, \( \text{List.dropWhile } p (x :: xs) = \text{List.dropWhile } p \, xs \).

2. **Case 2: \( p(x) = \text{false} \)**
- In this case, we need to show that \( \text{List.dropWhile } p (x :: xs) = x :: xs \).
- By the definition of `List.dropWhile`, if \( p(x) = \text{false} \), the function `List.dropWhile p` will stop dropping elements and return the list starting from \( x \) and including all subsequent elements \( xs \).
- Therefore, \( \text{List.dropWhile } p (x :: xs) = x :: xs \).

In both cases, the goal is satisfied. Hence, the theorem is proved.","theorem List.dropWhile_cons :
    (x :: xs : List α).dropWhile p = if p x then xs.dropWhile p else x :: xs := by
/- We discuss by cases based on the condition \( p(x) = \text{true} \) or \( p(x) = \text{false} \). For each case, we simplify the goal using the definition of `List.dropWhile`. -/
  split <;> simp_all [dropWhile]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34455,List.takeWhile_cons_of_pos,"theorem List.takeWhile_cons_of_pos {p : α → Bool} {a : α} {l : List α} (h : p a) :
    (a :: l).takeWhile p = a :: l.takeWhile p := by sorry","TakeWhile of Cons with Positive Predicate Returns Cons of Element and TakeWhile of Tail : For any type \( \alpha \), predicate \( p : \alpha \to \text{Bool} \), element \( a \in \alpha \), and list \( l \) of elements of type \( \alpha \), if \( p(a) \) is `true`, then the longest initial segment of the list \( a :: l \) that satisfies \( p \) is \( a \) followed by the longest initial segment of \( l \) that satisfies \( p \), i.e., \(\text{takeWhile } p (a :: l) = a :: \text{takeWhile } p \, l\).","theorem List.takeWhile_cons_of_pos {p : α → Bool} {a : α} {l : List α} (h : p a) :
    (a :: l).takeWhile p = a :: l.takeWhile p := by
  simp [takeWhile_cons, h]","To prove the theorem, we start with the given hypothesis that \( p(a) = \text{true} \). We need to show that \(\text{takeWhile } p (a :: l) = a :: \text{takeWhile } p \, l\).

Using the definition of `List.takeWhile` on a cons list, we know that:
\[
\text{List.takeWhile } p (a :: l) =
\begin{cases}
a :: \text{List.takeWhile } p \, l & \text{if } p(a) = \text{true} \\
\text{[]} & \text{if } p(a) = \text{false}
\end{cases}
\]

Since \( p(a) = \text{true} \) by the hypothesis, the definition simplifies to:
\[
\text{List.takeWhile } p (a :: l) = a :: \text{List.takeWhile } p \, l
\]

Thus, the goal is trivially satisfied. This completes the proof.","theorem List.takeWhile_cons_of_pos {p : α → Bool} {a : α} {l : List α} (h : p a) :
    (a :: l).takeWhile p = a :: l.takeWhile p := by
/- Using the definition of `List.takeWhile` on a cons list and the hypothesis \( p(a) = \text{true} \), we can simplify the proposition we want to show. Specifically, the definition of `List.takeWhile` on a cons list states that if \( p(a) \) is `true`, then `List.takeWhile p (a :: l)` is equal to \( a \) followed by `List.takeWhile p l`. Since \( p(a) = \text{true} \) by the hypothesis \( h \), the proposition simplifies to \( a :: \text{List.takeWhile} \, p \, l \). Therefore, the goal is trivially satisfied. -/
  simp [takeWhile_cons, h]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34456,List.head_dropWhile_not,"theorem List.head_dropWhile_not (p : α → Bool) (l : List α) (w) :
    p ((l.dropWhile p).head w) = false := by sorry","First Element of `dropWhile` Result Does Not Satisfy Predicate: $p(\text{head}(\text{dropWhile}(p, l))) = \text{false}$ : For any type $\alpha$ and any predicate $p : \alpha \to \text{Bool}$, if the list $l : \text{List} \, \alpha$ is non-empty after applying `List.dropWhile p` to it, then the first element of the resulting list does not satisfy the predicate $p$, i.e., $p(\text{head}(\text{dropWhile}(p, l))) = \text{false}$.","theorem List.head_dropWhile_not (p : α → Bool) (l : List α) (w) :
    p ((l.dropWhile p).head w) = false := by
  simpa [head?_eq_head, w] using head?_dropWhile_not p l","We need to show that if the list $l$ is non-empty after applying `List.dropWhile p` to it, then the first element of the resulting list does not satisfy the predicate $p$.

First, we use the fact that the optional head of a non-empty list is `some` of its first element. This means that if the list `List.dropWhile p l` is non-empty, then `List.head? (List.dropWhile p l)` is `some (List.head (List.dropWhile p l) w)`, where `w` is a proof that `List.dropWhile p l` is non-empty.

Next, we use the fact that the first element of the list resulting from `List.dropWhile p l` does not satisfy the predicate $p$. This means that if `List.dropWhile p l` is non-empty, then $p(\text{head}(\text{dropWhile}(p, l))) = \text{false}$.

Combining these two facts, we can simplify the proposition we want to show to $p(\text{head}(\text{dropWhile}(p, l))) = \text{false}$. We see that this is exactly what we have proved, thus completing the proof. $\blacksquare$","theorem List.head_dropWhile_not (p : α → Bool) (l : List α) (w) :
    p ((l.dropWhile p).head w) = false := by
/- Using the fact that the optional head of a non-empty list is `some` of its first element, and the fact that the first element of the list resulting from `List.dropWhile p l` does not satisfy the predicate $p$, we can simplify the proposition we want to show to $p(\text{head}(\text{dropWhile}(p, l))) = \text{false}$. We see that this is exactly what we have proved, thus finishing the proof. -/
  simpa [head?_eq_head, w] using head?_dropWhile_not p l","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34457,List.Pairwise.imp_of_mem,"theorem List.Pairwise.imp_of_mem {S : α → α → Prop}
    (H : ∀ {a b}, a ∈ l → b ∈ l → R a b → S a b) (p : Pairwise R l) : Pairwise S l := by sorry","Pairwise Implication for List Elements: \(\text{Pairwise } R \, l \to \text{Pairwise } S \, l\) : For any list \( l \) of elements of type \( \alpha \) and any relations \( R \) and \( S \) on \( \alpha \), if for all elements \( a \) and \( b \) in \( l \), \( a \in l \) and \( b \in l \) and \( R a b \) imply \( S a b \), then the pairwise relation \( R \) holding on \( l \) implies the pairwise relation \( S \) also holds on \( l \). In other words, if \( R \) implies \( S \) for all pairs of elements in \( l \), then \( \text{Pairwise } R \, l \) implies \( \text{Pairwise } S \, l \).","theorem List.Pairwise.imp_of_mem {S : α → α → Prop}
    (H : ∀ {a b}, a ∈ l → b ∈ l → R a b → S a b) (p : Pairwise R l) : Pairwise S l := by
  induction p with
  | nil => constructor
  | @cons a l r _ ih =>
    constructor
    · exact fun x h => H (mem_cons_self ..) (mem_cons_of_mem _ h) <| r x h
    · exact ih fun m m' => H (mem_cons_of_mem _ m) (mem_cons_of_mem _ m')","We prove this by induction on the list \( l \).

1. **Base Case:**
- If \( l \) is the empty list, the pairwise relation \( S \) trivially holds for the empty list. This is because there are no elements to compare, and thus the condition is vacuously true.

2. **Inductive Step:**
- Assume \( l \) is a list of the form \( a :: l \), where \( a \) is an element of type \( \alpha \) and \( l \) is a list of elements of type \( \alpha \).
- We need to show that the pairwise relation \( S \) holds for the list \( a :: l \).
- To do this, we need to show two things:
1. For any element \( a' \) in \( l \), \( S a a' \) holds.
2. The pairwise relation \( S \) holds for the list \( l \).

- **First Part:**
- For any element \( a' \) in \( l \), since \( a \) is a member of \( a :: l \) and \( a' \) is a member of \( a :: l \) (because \( a' \in l \)), and \( R a a' \) holds by the hypothesis \( r \), it follows that \( S a a' \) holds by the hypothesis \( H \).

- **Second Part:**
- To show that the pairwise relation \( S \) holds for the list \( l \), we use the induction hypothesis \( \text{ih} \). Specifically, for any elements \( m \) and \( m' \) in \( l \), if \( m \in l \) and \( m' \in l \), and \( R m m' \) holds, then \( S m m' \) must also hold. This is because \( m \) and \( m' \) are also members of the list \( a :: l \), and by the hypothesis \( H \), \( R m m' \) implies \( S m m' \).

By induction, we have shown that if \( R \) implies \( S \) for all pairs of elements in \( l \), then \( \text{Pairwise } R \, l \) implies \( \text{Pairwise } S \, l \). This completes the proof.","theorem List.Pairwise.imp_of_mem {S : α → α → Prop}
    (H : ∀ {a b}, a ∈ l → b ∈ l → R a b → S a b) (p : Pairwise R l) : Pairwise S l := by
  induction p with
/- We perform induction on the list \( l \). For the base case where \( l \) is the empty list, the pairwise relation \( S \) trivially holds for the empty list. This is because there are no elements to compare, and thus the condition is vacuously true. -/
  | nil => constructor
/- For the inductive step, assume \( l \) is a list of the form \( a :: l \), where \( a \) is an element of type \( \alpha \) and \( l \) is a list of elements of type \( \alpha \). We need to show that the pairwise relation \( S \) holds for the list \( a :: l \). -/
  | @cons a l r _ ih =>
/- To prove that the pairwise relation \( S \) holds for the list \( a :: l \), we need to show two things:
1. For any element \( a' \) in \( l \), \( S a a' \) holds.
2. The pairwise relation \( S \) holds for the list \( l \). -/
    constructor
/- To show that \( S a a' \) holds for any element \( a' \) in \( l \), we use the hypothesis \( H \). Specifically, since \( a \) is a member of \( a :: l \) and \( a' \) is a member of \( a :: l \) (because \( a' \in l \)), and \( R a a' \) holds by the hypothesis \( r \), it follows that \( S a a' \) holds by the hypothesis \( H \). -/
    · exact fun x h => H (mem_cons_self ..) (mem_cons_of_mem _ h) <| r x h
/- To prove that the pairwise relation \( S \) holds for the list \( l \), we use the induction hypothesis \( \text{ih} \). Specifically, for any elements \( m \) and \( m' \) in \( l \), if \( m \in l \) and \( m' \in l \), and \( R m m' \) holds, then \( S m m' \) must also hold. This is because \( m \) and \( m' \) are also members of the list \( a :: l \), and by the hypothesis \( H \), \( R m m' \) implies \( S m m' \). -/
/- To show that the pairwise relation \( S \) holds for the list \( l \), we use the induction hypothesis \( \text{ih} \). Specifically, for any elements \( m \) and \( m' \) in \( l \), if \( m \in l \) and \( m' \in l \), and \( R m m' \) holds, then \( S m m' \) must also hold. This is because \( m \) and \( m' \) are also members of the list \( a :: l \), and by the hypothesis \( H \), \( R m m' \) implies \( S m m' \). -/
    · exact ih fun m m' => H (mem_cons_of_mem _ m) (mem_cons_of_mem _ m')","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Pairwise
open Nat
"
34458,List.rotateLeft_zero,theorem List.rotateLeft_zero (l : List α) : rotateLeft l 0 = l := by sorry,"Left Rotation by Zero Preserves the List : For any list \( l \) of elements of type \( \alpha \), rotating \( l \) to the left by 0 positions results in the same list \( l \). Formally, \( l.\text{rotateLeft}(0) = l \).","theorem List.rotateLeft_zero (l : List α) : rotateLeft l 0 = l := by
  simp [rotateLeft]","To prove that rotating a list \( l \) to the left by 0 positions results in the same list \( l \), we use the definition of the `rotateLeft` function. By definition, rotating a list by 0 positions means that the list remains unchanged. Therefore, \( l.\text{rotateLeft}(0) = l \) is trivially true. This completes the proof.","theorem List.rotateLeft_zero (l : List α) : rotateLeft l 0 = l := by
/- Using the definition of the `rotateLeft` function, we simplify the proposition we want to show, which is \( l.\text{rotateLeft}(0) = l \). The definition of `rotateLeft` states that rotating a list by 0 positions results in the same list. Therefore, the simplified goal is trivially true. -/
  simp [rotateLeft]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34462,List.getElem?_take,theorem List.getElem?_take {l : List α} {n m : Nat} (h : m < n) : (l.take n)[m]? = l[m]? := by sorry,"Element Retrieval in Sublist Equals Element Retrieval in Original List : For any type \(\alpha\), any list \(l\) of elements of type \(\alpha\), and any natural numbers \(m\) and \(n\) such that \(m < n\), the \(m\)-th element of the list obtained by taking the first \(n\) elements of \(l\) is equal to the \(m\)-th element of \(l\) itself, i.e., \((\text{take } n \, l)[m]? = l[m]?\).","theorem List.getElem?_take {l : List α} {n m : Nat} (h : m < n) : (l.take n)[m]? = l[m]? := by
  induction n generalizing l m with
  | zero =>
    exact absurd h (Nat.not_lt_of_le m.zero_le)
  | succ _ hn =>
    cases l with
    | nil => simp only [take_nil]
    | cons hd tl =>
      cases m
      · simp
      · simpa using hn (Nat.lt_of_succ_lt_succ h)","We prove this by induction on the natural number \( n \).

**Base Case:**
For \( n = 0 \), we need to show that \((\text{take } 0 \, l)[m]? = l[m]?\). Since \( m < 0 \) is impossible (as \( m \) is a natural number and \( 0 \leq m \)), the goal is vacuously true.

**Inductive Step:**
Assume the statement holds for \( n = n' \), i.e., for any list \( l \) and any natural number \( m \) such that \( m < n' \), \((\text{take } n' \, l)[m]? = l[m]?\). We need to show that the statement holds for \( n = n' + 1 \).

**Case 1:**
If \( l \) is the empty list, then \((\text{take } (n' + 1) \, \text{nil})[m]? = \text{nil}[m]?\). Since taking any number of elements from an empty list results in an empty list, this is trivially true.

**Case 2:**
If \( l \) is a non-empty list, i.e., \( l = \text{hd} :: \text{tl} \), we perform case analysis on \( m \).

- **Subcase 1:**
If \( m = 0 \), we need to show that \((\text{take } (n' + 1) \, (\text{hd} :: \text{tl}))[0]? = (\text{hd} :: \text{tl})[0]?\). This is trivially true because the first element of the list is \( \text{hd} \).

- **Subcase 2:**
If \( m = m' + 1 \), we need to show that \((\text{take } (n' + 1) \, (\text{hd} :: \text{tl}))[m' + 1]? = (\text{hd} :: \text{tl})[m' + 1]?\). Using the fact that if \( m' + 1 < n' + 1 \), then \( m' < n' \), and by the induction hypothesis, we have \((\text{take } n' \, \text{tl})[m']? = \text{tl}[m']?\). Therefore, \((\text{take } (n' + 1) \, (\text{hd} :: \text{tl}))[m' + 1]? = (\text{hd} :: \text{tl})[m' + 1]?\).

By induction, the statement holds for all natural numbers \( n \). This completes the proof. \(\blacksquare\)","theorem List.getElem?_take {l : List α} {n m : Nat} (h : m < n) : (l.take n)[m]? = l[m]? := by
  induction n generalizing l m with
/- We perform induction on the natural number \( n \) and consider the base case where \( n = 0 \). -/
  | zero =>
/- In the base case where \( n = 0 \), we need to show that \((\text{take } 0 \, l)[m]? = l[m]?\). Since \( m < 0 \) is impossible (as \( m \) is a natural number and \( 0 \leq m \)), the goal is vacuously true. -/
    exact absurd h (Nat.not_lt_of_le m.zero_le)
/- We consider the inductive step where \( n = n' + 1 \) for some natural number \( n' \). -/
  | succ _ hn =>
    cases l with
/- In the inductive step, we consider the case where the list \( l \) is empty. Using the fact that taking any number of elements from an empty list results in an empty list, we simplify the goal to show that the \( m \)-th element of the empty list is equal to the \( m \)-th element of the empty list, which is trivially true. -/
    | nil => simp only [take_nil]
/- In the inductive step, we consider the case where the list \( l \) is non-empty, i.e., \( l = \text{hd} :: \text{tl} \). -/
    | cons hd tl =>
/- We perform case analysis on the natural number \( m \). We consider two cases: \( m = 0 \) and \( m = m' + 1 \) for some natural number \( m' \). -/
      cases m
/- In the case where \( m = 0 \), we simplify the goal to show that the first element of the list obtained by taking the first \( n' + 1 \) elements of \( \text{hd} :: \text{tl} \) is equal to the first element of \( \text{hd} :: \text{tl} \). This is trivially true because the first element of the list is \( \text{hd} \). -/
      · simp
/- First, we use the fact that if \( n + 1 < m + 1 \), then \( n < m \) to simplify the hypothesis \( h \) to \( n < n' \). Then, using the induction hypothesis \( \text{hn} \), we can simplify the goal to show that the \( m \)-th element of the list obtained by taking the first \( n' \) elements of \( l \) is equal to the \( m \)-th element of \( l \). -/
/- In the case where \( m = m' + 1 \), we use the fact that if \( m' + 1 < n' + 1 \), then \( m' < n' \). Using the induction hypothesis \( \text{hn} \), we simplify the goal to show that the \( m' + 1 \)-th element of the list obtained by taking the first \( n' + 1 \) elements of \( \text{hd} :: \text{tl} \) is equal to the \( m' + 1 \)-th element of \( \text{hd} :: \text{tl} \). This is true by the induction hypothesis. -/
      · simpa using hn (Nat.lt_of_succ_lt_succ h)","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34463,List.rotateRight_zero,theorem List.rotateRight_zero (l : List α) : rotateRight l 0 = l := by sorry,"Right Rotation by Zero Preserves the List : For any list \( l \) of elements of type \( \alpha \), rotating \( l \) to the right by 0 positions results in the same list \( l \). Formally, \( l.\text{rotateRight}(0) = l \).","theorem List.rotateRight_zero (l : List α) : rotateRight l 0 = l := by
  simp [rotateRight]","To prove that rotating a list \( l \) to the right by 0 positions results in the same list \( l \), we use the definition of the `rotateRight` function. The `rotateRight` function for a list \( l \) and a natural number \( n \) is defined as follows:
- Split the list \( l \) into two parts: the first \( n \) elements and the rest.
- Concatenate the rest with the first \( n \) elements.

When \( n = 0 \), the first \( 0 \) elements are an empty list, and the rest is the entire list \( l \). Therefore, concatenating the rest with the first \( 0 \) elements results in the original list \( l \). Hence, \( l.\text{rotateRight}(0) = l \).

This completes the proof.","theorem List.rotateRight_zero (l : List α) : rotateRight l 0 = l := by
/- Using the definition of the `rotateRight` function, we simplify the proposition we want to show, which is \( l.\text{rotateRight}(0) = l \). The definition of `rotateRight` for a list \( l \) and a natural number \( n \) is such that it splits the list into two parts: the first \( n \) elements and the rest, and then concatenates the rest with the first \( n \) elements. When \( n = 0 \), the first \( 0 \) elements are an empty list, and the rest is the entire list \( l \). Therefore, concatenating the rest with the first \( 0 \) elements results in the original list \( l \). Hence, \( l.\text{rotateRight}(0) = l \). -/
  simp [rotateRight]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34464,List.dropLast_eq_take,theorem List.dropLast_eq_take (l : List α) : l.dropLast = l.take (l.length - 1) := by sorry,"Removing Last Element is Equivalent to Taking All but the Last Element : For any list \( l \) of elements of type \( \alpha \), the list obtained by removing the last element of \( l \) is equal to the list of the first \( \text{length}(l) - 1 \) elements of \( l \). In other words, \( l.\text{dropLast} = \text{take}(\text{length}(l) - 1, l) \).","theorem List.dropLast_eq_take (l : List α) : l.dropLast = l.take (l.length - 1) := by
  cases l with
  | nil => simp [dropLast]
  | cons x l =>
    induction l generalizing x <;> simp_all [dropLast]","We prove this by induction on the list \( l \).

**Base Case:**
For the empty list \( l = [] \):
- The left-hand side is \( \text{dropLast}([]) \), which is defined as \( [] \).
- The right-hand side is \( \text{take}(\text{length}([]) - 1, []) \), which is \( \text{take}(0 - 1, []) \). Since the length of the empty list is \( 0 \), this simplifies to \( \text{take}(-1, []) \), which is \( [] \).
- Therefore, \( \text{dropLast}([]) = \text{take}(\text{length}([]) - 1, []) \).

**Inductive Step:**
Assume the statement holds for a list \( l \), i.e., \( l.\text{dropLast} = \text{take}(\text{length}(l) - 1, l) \). We need to show that the statement holds for the list \( x :: l \), where \( x \) is an element of type \( \alpha \).

- The left-hand side is \( (x :: l).\text{dropLast} \), which is defined as \( x :: \text{dropLast}(l) \).
- The right-hand side is \( \text{take}((x :: l).\text{length} - 1, x :: l) \). Since the length of \( x :: l \) is \( \text{length}(l) + 1 \), this simplifies to \( \text{take}((\text{length}(l) + 1) - 1, x :: l) \), which is \( \text{take}(\text{length}(l), x :: l) \).
- By the definition of `take`, \( \text{take}(\text{length}(l), x :: l) \) is \( x :: \text{take}(\text{length}(l) - 1, l) \).
- By the inductive hypothesis, \( \text{dropLast}(l) = \text{take}(\text{length}(l) - 1, l) \).
- Therefore, \( x :: \text{dropLast}(l) = x :: \text{take}(\text{length}(l) - 1, l) \), which is \( \text{take}(\text{length}(l), x :: l) \).

Thus, the statement holds for \( x :: l \).

By induction, the theorem is true for all lists \( l \). This completes the proof. \(\blacksquare\)","theorem List.dropLast_eq_take (l : List α) : l.dropLast = l.take (l.length - 1) := by
  cases l with
/- For the base case where \( l \) is the empty list, we simplify the goal using the definition of `dropLast` and `take`. Since the empty list has no elements, both `dropLast []` and `take (0 - 1) []` are the empty list, and the goal is trivially true. -/
  | nil => simp [dropLast]
/- For the inductive step, assume \( l \) is a list with a head \( x \) and a tail \( l \). We need to show that \((x :: l).dropLast = \text{take}((x :: l).length - 1, x :: l)\). -/
  | cons x l =>
/- We perform induction on the list \( l \) and generalize over the variable \( x \). For the base case, we simplify the goal using the definition of `dropLast` and `take`. -/
/- We perform induction on the list \( l \) and generalize over the variable \( x \). For the base case, we simplify the goal using the definition of `dropLast` and `take`. For the inductive step, we use the inductive hypothesis and simplify the goal using the definition of `dropLast` and `take`. -/
    induction l generalizing x <;> simp_all [dropLast]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34465,List.takeWhile_filter,"theorem List.takeWhile_filter (p q : α → Bool) (l : List α) :
    (l.filter p).takeWhile q = (l.takeWhile fun a => !p a || q a).filter p := by sorry","TakeWhile and Filter Commute: \(\text{takeWhile } q \, (\text{filter } p \, l) = \text{filter } p \, (\text{takeWhile } (\text{not } p \, a \, \text{ or } q \, a) \, l)\) : For any type \( \alpha \) and any predicates \( p, q : \alpha \to \text{Bool} \), and for any list \( l \) of elements of type \( \alpha \), the list obtained by taking the longest initial segment of the filtered list \( \text{filter } p \, l \) for which \( q \) returns `true` is equal to the list obtained by filtering the list \( l \) after taking the longest initial segment of \( l \) for which the predicate \( \text{not } p \, a \, \text{ or } q \, a \) returns `true`. In other words:
\[
\text{takeWhile } q \, (\text{filter } p \, l) = \text{filter } p \, (\text{takeWhile } (\text{not } p \, a \, \text{ or } q \, a) \, l)
\]","theorem List.takeWhile_filter (p q : α → Bool) (l : List α) :
    (l.filter p).takeWhile q = (l.takeWhile fun a => !p a || q a).filter p := by
  simp [← filterMap_eq_filter, takeWhile_filterMap]","To prove the theorem, we use the following steps:

1. **Simplify the Goal:**
We use the theorem that the `filterMap` operation is equivalent to the `filter` operation and the theorem that `takeWhile` and `filterMap` commute. Specifically, we use the fact that:
\[
\text{filterMap } f \, l = \text{filter } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, l
\]
and
\[
\text{takeWhile } p \, (\text{filterMap } f \, l) = \text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, l)
\]
to simplify the goal. This simplification shows that:
\[
\text{takeWhile } q \, (\text{filter } p \, l) = \text{filter } p \, (\text{takeWhile } (\lambda a, \, \text{not } p \, a \, \text{ or } q \, a) \, l)
\]

2. **Conclusion:**
Since the goal is simplified to the desired equality, the theorem is proved.

Thus, we have shown that:
\[
\text{takeWhile } q \, (\text{filter } p \, l) = \text{filter } p \, (\text{takeWhile } (\text{not } p \, a \, \text{ or } q \, a) \, l)
\]
This completes the proof.","theorem List.takeWhile_filter (p q : α → Bool) (l : List α) :
    (l.filter p).takeWhile q = (l.takeWhile fun a => !p a || q a).filter p := by
/- Using the theorem that the `filterMap` operation is equivalent to the `filter` operation and the theorem that `takeWhile` and `filterMap` commute, we can simplify the proposition we want to show. Specifically, we use the fact that:
\[
\text{filterMap } f \, l = \text{filter } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, l
\]
and
\[
\text{takeWhile } p \, (\text{filterMap } f \, l) = \text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, l)
\]
to simplify the goal. This simplification shows that:
\[
\text{takeWhile } q \, (\text{filter } p \, l) = \text{filter } p \, (\text{takeWhile } (\lambda a, \, \text{not } p \, a \, \text{ or } q \, a) \, l)
\]
Thus, the goal is proved. -/
  simp [← filterMap_eq_filter, takeWhile_filterMap]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34467,List.takeWhile_replicate,"theorem List.takeWhile_replicate (p : α → Bool) :
    (replicate n a).takeWhile p = if p a then replicate n a else [] := by sorry","Longest Initial Segment of Replicated List Equals Entire List or Empty List Based on Predicate : For any type $\alpha$, natural number $n$, and element $a \in \alpha$, and for any predicate $p : \alpha \to \text{Bool}$, the longest initial segment of the list `replicate n a` that satisfies $p$ is:
- The entire list `replicate n a` if $p(a) = \text{true}$.
- The empty list if $p(a) = \text{false}$.","theorem List.takeWhile_replicate (p : α → Bool) :
    (replicate n a).takeWhile p = if p a then replicate n a else [] := by
  rw [takeWhile_replicate_eq_filter, filter_replicate]","To prove the theorem, we start by using the theorem that the longest initial segment of a replicated list that satisfies a predicate is equal to the filtered list of the replicated list. This transforms our goal to show that the filtered list of `replicate n a` is equal to the list `replicate n a` if $p(a) = \text{true}$, and is the empty list if $p(a) = \text{false}$.

Next, we use the theorem that the filtered list of `replicate n a` is equal to `replicate n a` if $p(a) = \text{true}$, and is the empty list if $p(a) = \text{false}$. This directly matches our goal, and thus the proof is complete.

Therefore, the longest initial segment of the list `replicate n a` that satisfies the predicate $p$ is:
- The entire list `replicate n a` if $p(a) = \text{true}$.
- The empty list if $p(a) = \text{false}$.

This completes the proof.","theorem List.takeWhile_replicate (p : α → Bool) :
    (replicate n a).takeWhile p = if p a then replicate n a else [] := by
/- First, we use the theorem that the longest initial segment of a replicated list that satisfies a predicate is equal to the filtered list of the replicated list. This transforms our goal to show that the filtered list of `replicate n a` is equal to the list `replicate n a` if $p(a) = \text{true}$, and is the empty list if $p(a) = \text{false}$. -/
/- Next, we use the theorem that the filtered list of `replicate n a` is equal to `replicate n a` if $p(a) = \text{true}$, and is the empty list if $p(a) = \text{false}$. This directly matches our goal, and thus the proof is complete. -/
  rw [takeWhile_replicate_eq_filter, filter_replicate]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34468,List.set_drop,"theorem List.set_drop {l : List α} {n m : Nat} {a : α} :
    (l.drop n).set m a = (l.set (n + m) a).drop n := by sorry","List Update and Drop: \((\text{List.drop } n \, l). \text{set } m \, a = \text{List.drop } n \, (l. \text{set } (n + m) \, a)\) : For any list \( l \) of elements of type \( \alpha \), and for any natural numbers \( n \) and \( m \), and for any element \( a \) of type \( \alpha \), the list obtained by updating the \( m \)-th element of the list \( \text{List.drop } n \, l \) to \( a \) is equal to the list obtained by first updating the \( (n + m) \)-th element of \( l \) to \( a \) and then dropping the first \( n \) elements of the resulting list. Formally, this can be written as:
\[
(\text{List.drop } n \, l). \text{set } m \, a = \text{List.drop } n \, (l. \text{set } (n + m) \, a)
\]","theorem List.set_drop {l : List α} {n m : Nat} {a : α} :
    (l.drop n).set m a = (l.set (n + m) a).drop n := by
  rw [drop_set, if_neg, add_sub_self_left n m]
  exact (Nat.not_lt).2 (le_add_right n m)","We start by using the theorem that describes the relationship between dropping elements and updating elements in a list. Specifically, for any list \( l \) of elements of type \( \alpha \), and for any natural numbers \( n \) and \( m \), and for any element \( a \) of type \( \alpha \), the list obtained by dropping the first \( n \) elements of \( l \) and then updating the \( m \)-th element to \( a \) is equal to the list obtained by first updating the \( m \)-th element of \( l \) to \( a \) and then dropping the first \( n \) elements of the resulting list. Formally, this can be written as:
\[
\text{List.drop } n \, (l.\text{set } m \, a) =
\begin{cases}
\text{List.drop } n \, l & \text{if } m < n \\
(\text{List.drop } n \, l).\text{set } (m - n) \, a & \text{if } m \geq n
\end{cases}
\]
Since \( n + m \geq n \), the condition \( n + m < n \) is false. Therefore, we can simplify the expression to:
\[
(\text{List.drop } n \, l).\text{set } m \, a = (\text{List.drop } n \, l).\text{set } (n + m - n) \, a
\]
Using the property of natural numbers that \( n + m - n = m \), we get:
\[
(\text{List.drop } n \, l).\text{set } m \, a = (\text{List.drop } n \, l).\text{set } m \, a
\]
Thus, the goal is to show that \( n + m \geq n \).

To show that \( n + m \geq n \), we use the property of natural numbers that adding a non-negative number to another number preserves the order. Specifically, for any natural numbers \( n \) and \( m \), \( n \leq n + m \). This is a direct consequence of the fact that adding a non-negative number to \( n \) results in a number that is at least \( n \). Therefore, \( n + m \geq n \) is true, and the proof is complete.","theorem List.set_drop {l : List α} {n m : Nat} {a : α} :
    (l.drop n).set m a = (l.set (n + m) a).drop n := by
/- First, we use the theorem that states the relationship between dropping elements and updating elements in a list. Specifically, for any list \( l \) of elements of type \( \alpha \), and for any natural numbers \( n \) and \( m \), and for any element \( a \) of type \( \alpha \), the list obtained by dropping the first \( n \) elements of \( l \) and then updating the \( m \)-th element to \( a \) is equal to the list obtained by first updating the \( m \)-th element of \( l \) to \( a \) and then dropping the first \( n \) elements of the resulting list. Formally, this can be written as:
\[
\text{List.drop } n \, (l.\text{set } m \, a) =
\begin{cases}
\text{List.drop } n \, l & \text{if } m < n \\
(\text{List.drop } n \, l).\text{set } (m - n) \, a & \text{if } m \geq n
\end{cases}
\]
Since \( n + m \geq n \), the condition \( n + m < n \) is false. Therefore, we can simplify the expression to:
\[
(\text{List.drop } n \, l).\text{set } m \, a = (\text{List.drop } n \, l).\text{set } (n + m - n) \, a
\]
Using the property of natural numbers that \( n + m - n = m \), we get:
\[
(\text{List.drop } n \, l).\text{set } m \, a = (\text{List.drop } n \, l).\text{set } m \, a
\]
Thus, the goal is to show that \( n + m \geq n \). -/
  rw [drop_set, if_neg, add_sub_self_left n m]
/- To show that \( n + m \geq n \), we use the property of natural numbers that adding a non-negative number to another number preserves the order. Specifically, for any natural numbers \( n \) and \( m \), \( n \leq n + m \). This is a direct consequence of the fact that adding a non-negative number to \( n \) results in a number that is at least \( n \). Therefore, \( n + m \geq n \) is true, and the proof is complete. -/
  exact (Nat.not_lt).2 (le_add_right n m)","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34470,List.pairwise_reverse,"theorem List.pairwise_reverse {l : List α} :
    l.reverse.Pairwise R ↔ l.Pairwise (fun a b => R b a) := by sorry","Pairwise Relation on Reversed List: \(\text{Pairwise } R \, (l.\text{reverse}) \leftrightarrow \text{Pairwise } (R \, \text{reversed}) \, l\) : For any type \(\alpha\) and any relation \(R\) on \(\alpha\), a list \(l\) of elements of type \(\alpha\) satisfies the pairwise relation \(R\) on its reverse, \(l.\text{reverse}\), if and only if the list \(l\) satisfies the pairwise relation \(R\) with the order of the elements reversed, i.e., \(\text{Pairwise } R \, (l.\text{reverse}) \leftrightarrow \text{Pairwise } (R \, \text{reversed}) \, l\).","theorem List.pairwise_reverse {l : List α} :
    l.reverse.Pairwise R ↔ l.Pairwise (fun a b => R b a) := by
  induction l <;> simp [*, pairwise_append, and_comm]","We perform induction on the list \( l \).

**Base Case:**
For the empty list \( l = [] \), we need to show that:
\[
\text{Pairwise } R \, (l.\text{reverse}) \leftrightarrow \text{Pairwise } (R \, \text{reversed}) \, l
\]
Since the reverse of the empty list is the empty list itself, we have:
\[
\text{Pairwise } R \, [] \leftrightarrow \text{Pairwise } (R \, \text{reversed}) \, []
\]
Both sides of the equivalence are trivially true because the pairwise relation on an empty list is always true. Therefore, the base case holds.

**Inductive Step:**
Assume the inductive hypothesis that for any list \( \text{tail} \) of elements of type \(\alpha\), the pairwise relation \( R \) holds for the reverse of the tail if and only if it holds for the tail with the order of elements reversed:
\[
\text{Pairwise } R \, (\text{tail}.\text{reverse}) \leftrightarrow \text{Pairwise } (R \, \text{reversed}) \, \text{tail}
\]
We need to show that for any element \( \text{head} \) and list \( \text{tail} \), the pairwise relation \( R \) holds for the reverse of the entire list \( \text{head} :: \text{tail} \) if and only if it holds for the entire list with the order of elements reversed:
\[
\text{Pairwise } R \, ((\text{head} :: \text{tail}).\text{reverse}) \leftrightarrow \text{Pairwise } (R \, \text{reversed}) \, (\text{head} :: \text{tail})
\]
Using the property of the reverse of a cons list, we have:
\[
(\text{head} :: \text{tail}).\text{reverse} = \text{tail}.\text{reverse} \, ++ \, [\text{head}]
\]
Thus, the goal becomes:
\[
\text{Pairwise } R \, (\text{tail}.\text{reverse} \, ++ \, [\text{head}]) \leftrightarrow \text{Pairwise } (R \, \text{reversed}) \, (\text{head} :: \text{tail})
\]
We simplify the left-hand side using the definition of pairwise relations and the inductive hypothesis. The pairwise relation on the concatenation of two lists is equivalent to the pairwise relation on each list and the relation between the last element of the first list and the first element of the second list. Therefore, we have:
\[
\text{Pairwise } R \, (\text{tail}.\text{reverse} \, ++ \, [\text{head}]) \leftrightarrow \text{Pairwise } R \, (\text{tail}.\text{reverse}) \land R \, (\text{last}(\text{tail}.\text{reverse})) \, \text{head}
\]
Using the inductive hypothesis, this becomes:
\[
\text{Pairwise } R \, (\text{tail}.\text{reverse}) \land R \, (\text{last}(\text{tail}.\text{reverse})) \, \text{head} \leftrightarrow \text{Pairwise } (R \, \text{reversed}) \, \text{tail} \land R \, (\text{last}(\text{tail}.\text{reverse})) \, \text{head}
\]
Since \(\text{last}(\text{tail}.\text{reverse})\) is the first element of \(\text{tail}\), we have:
\[
\text{Pairwise } R \, (\text{tail}.\text{reverse}) \land R \, (\text{first}(\text{tail})) \, \text{head} \leftrightarrow \text{Pairwise } (R \, \text{reversed}) \, \text{tail} \land R \, (\text{first}(\text{tail})) \, \text{head}
\]
This is equivalent to:
\[
\text{Pairwise } (R \, \text{reversed}) \, \text{tail} \land (R \, \text{reversed}) \, \text{head} \, \text{first}(\text{tail}) \leftrightarrow \text{Pairwise } (R \, \text{reversed}) \, \text{tail} \land R \, \text{head} \, \text{first}(\text{tail})
\]
By the commutativity of conjunction, this is:
\[
\text{Pairwise } (R \, \text{reversed}) \, \text{tail} \land R \, \text{head} \, \text{first}(\text{tail}) \leftrightarrow \text{Pairwise } (R \, \text{reversed}) \, \text{tail} \land R \, \text{head} \, \text{first}(\text{tail})
\]
Thus, the inductive step holds.

By induction, the theorem is proved. \(\blacksquare\)","theorem List.pairwise_reverse {l : List α} :
    l.reverse.Pairwise R ↔ l.Pairwise (fun a b => R b a) := by
/- We perform induction on the list \( l \). For the base case, we need to show that the pairwise relation \( R \) holds for the reverse of the empty list if and only if it holds for the empty list with the order of elements reversed. For the inductive step, we assume the inductive hypothesis that the pairwise relation \( R \) holds for the reverse of the tail of the list if and only if it holds for the tail of the list with the order of elements reversed. We then need to show that the pairwise relation \( R \) holds for the reverse of the entire list if and only if it holds for the entire list with the order of elements reversed. We simplify the goal using the properties of pairwise relations and the commutativity of conjunction. -/
  induction l <;> simp [*, pairwise_append, and_comm]","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Nat
"
34473,List.drop_eq_nil_iff_le,theorem List.drop_eq_nil_iff_le {l : List α} {k : Nat} : l.drop k = [] ↔ l.length ≤ k := by sorry,"Condition for Dropped List to be Empty: \(\text{drop}(k, l) = [] \leftrightarrow \text{length}(l) \le k\) : For any list \( l \) of elements of type \( \alpha \) and any natural number \( k \), the list obtained by dropping the first \( k \) elements from \( l \) is empty if and only if the length of \( l \) is less than or equal to \( k \), i.e., \(\text{drop}(k, l) = [] \leftrightarrow \text{length}(l) \le k\).","theorem List.drop_eq_nil_iff_le {l : List α} {k : Nat} : l.drop k = [] ↔ l.length ≤ k := by
  refine' ⟨fun h => _, drop_eq_nil_of_le⟩
  induction k generalizing l with
  | zero =>
    simp only [drop] at h
    simp [h]
  | succ k hk =>
    cases l
    · simp
    · simp only [drop] at h
      simpa [Nat.succ_le_succ_iff] using hk h","To prove the equivalence \(\text{drop}(k, l) = [] \leftrightarrow \text{length}(l) \le k\), we need to show both directions.

1. **(\(\Rightarrow\))**: Assume \(\text{drop}(k, l) = []\). We need to show that \(\text{length}(l) \le k\).

- **Base Case**: \(k = 0\).
- If \(\text{drop}(0, l) = []\), then by the definition of \(\text{drop}\), \(l = []\).
- The length of \(l\) is \(0\), which is clearly less than or equal to \(0\).

- **Inductive Step**: Assume \(k = k' + 1\) and that the statement holds for \(k'\). We need to show that if \(\text{drop}(k' + 1, l) = []\), then \(\text{length}(l) \le k' + 1\).
- Consider two cases for \(l\):
- **Case 1**: \(l = []\).
- \(\text{drop}(k' + 1, []) = []\) is trivially true, and the length of \(l\) is \(0\), which is less than or equal to \(k' + 1\).
- **Case 2**: \(l = \text{head} :: \text{tail}\).
- Using the definition of \(\text{drop}\), \(\text{drop}(k' + 1, \text{head} :: \text{tail}) = \text{drop}(k', \text{tail})\).
- By the induction hypothesis, \(\text{drop}(k', \text{tail}) = []\) implies \(\text{length}(\text{tail}) \le k'\).
- Since \(\text{length}(l) = \text{length}(\text{tail}) + 1\), we have \(\text{length}(l) \le k' + 1\).

2. **(\(\Leftarrow\))**: Assume \(\text{length}(l) \le k\). We need to show that \(\text{drop}(k, l) = []\).

- This is given by the theorem that if \(\text{length}(l) \le k\), then \(\text{drop}(k, l) = []\).

Thus, we have shown both directions, completing the proof. \(\blacksquare\)","theorem List.drop_eq_nil_iff_le {l : List α} {k : Nat} : l.drop k = [] ↔ l.length ≤ k := by
/- To prove the equivalence \(\text{drop}(k, l) = [] \leftrightarrow \text{length}(l) \le k\), we need to show both directions. First, we assume \(\text{drop}(k, l) = []\) and show that \(\text{length}(l) \le k\). The other direction is given by the theorem that if \(\text{length}(l) \le k\), then \(\text{drop}(k, l) = []\). -/
  refine' ⟨fun h => _, drop_eq_nil_of_le⟩
  induction k generalizing l with
/- We perform induction on \(k\). For the base case \(k = 0\), we need to show that if \(\text{drop}(0, l) = []\), then \(\text{length}(l) \le 0\). -/
  | zero =>
/- Using the definition of \(\text{drop}\), we simplify the hypothesis \(\text{drop}(0, l) = []\) to \(l = []\). -/
    simp only [drop] at h
/- Since \(l = []\), the length of \(l\) is \(0\), which is clearly less than or equal to \(0\). This completes the base case. -/
    simp [h]
/- For the inductive step, assume \(k = k' + 1\) and that the statement holds for \(k'\). We need to show that if \(\text{drop}(k' + 1, l) = []\), then \(\text{length}(l) \le k' + 1\). -/
  | succ k hk =>
/- We consider two cases for the list \(l\): \(l\) is empty or \(l\) is non-empty. -/
    cases l
/- If \(l\) is empty, then \(\text{drop}(k' + 1, []) = []\) is trivially true, and the length of \(l\) is \(0\), which is less than or equal to \(k' + 1\). -/
    · simp
/- If \(l\) is non-empty, let \(l = \text{head} :: \text{tail}\). Using the definition of \(\text{drop}\), we simplify the hypothesis \(\text{drop}(k' + 1, \text{head} :: \text{tail}) = []\) to \(\text{drop}(k', \text{tail}) = []\). -/
    · simp only [drop] at h
/- We use the theorem that \(\text{length}(l) \le k\) if and only if \(\text{length}(\text{tail}(l)) \le k - 1\) to simplify the goal. Given that \(\text{drop}(k, \text{tail}(l)) = []\), we can use the induction hypothesis to conclude that \(\text{length}(\text{tail}(l)) \le k\). Therefore, \(\text{length}(l) \le k + 1\). -/
/- Using the induction hypothesis, we know that \(\text{length}(\text{tail}) \le k'\). Since \(\text{length}(l) = \text{length}(\text{tail}) + 1\), we have \(\text{length}(l) \le k' + 1\). This completes the inductive step. -/
      simpa [Nat.succ_le_succ_iff] using hk h","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34475,List.head_takeWhile,"theorem List.head_takeWhile (p : α → Bool) (l : List α) (w) :
    (l.takeWhile p).head w = l.head (by rintro rfl; simp_all) := by sorry","First Element of `takeWhile` Result is the First Element of Original List: $(\text{List.takeWhile} \, p \, l).head = l.head$ : For any type $\alpha$ and any predicate $p : \alpha \to \text{Bool}$, if the list $l : \text{List} \, \alpha$ is non-empty after applying `List.takeWhile p` to it, then the first element of the resulting list is equal to the first element of the original list $l$. Formally, if $w : \text{List.takeWhile} \, p \, l \neq \text{nil}$, then $(\text{List.takeWhile} \, p \, l).head \, w = l.head$.","theorem List.head_takeWhile (p : α → Bool) (l : List α) (w) :
    (l.takeWhile p).head w = l.head (by rintro rfl; simp_all) := by
  cases l with
  | nil => rfl
  | cons x xs =>
    simp only [takeWhile_cons, head_cons]
    simp only [takeWhile_cons] at w
    split <;> simp_all","We need to show that for any list \( l \) and predicate \( p \), if the list \( \text{List.takeWhile} \, p \, l \) is non-empty, then the head of this list is equal to the head of the original list \( l \).

1. **Base Case:**
- If \( l \) is the empty list, the goal is trivially true because both sides of the equality are definitionally equal to the head of the empty list, which is undefined (or the goal is vacuously true).

2. **Inductive Step:**
- Suppose \( l \) is a non-empty list, which can be written as \( x :: xs \).
- We need to show that the head of the list \(\text{List.takeWhile} \, p \, (x :: xs)\) is equal to the head of the original list \( x :: xs \).

3. **Simplification:**
- Using the definition of `List.takeWhile`, we have:
\[
\text{List.takeWhile} \, p \, (x :: xs) =
\begin{cases}
x :: \text{List.takeWhile} \, p \, xs & \text{if } p(x) = \text{true} \\
\text{nil} & \text{if } p(x) = \text{false}
\end{cases}
\]
- Using the definition of `List.head`, we have:
\[
\text{List.head} \, (x :: xs) = x
\]

4. **Case Analysis:**
- **Case 1: \( p(x) = \text{true} \)**
- In this case, \(\text{List.takeWhile} \, p \, (x :: xs) = x :: \text{List.takeWhile} \, p \, xs\).
- Therefore, \(\text{List.head} \, (\text{List.takeWhile} \, p \, (x :: xs)) = x\).
- This matches the head of the original list \( x :: xs \), which is \( x \).

- **Case 2: \( p(x) = \text{false} \)**
- In this case, \(\text{List.takeWhile} \, p \, (x :: xs) = \text{nil}\).
- However, the assumption \( w : \text{List.takeWhile} \, p \, (x :: xs) \neq \text{nil} \) contradicts this, so this case is not possible.

Thus, in both cases, the head of the list \(\text{List.takeWhile} \, p \, l\) is equal to the head of the original list \( l \). This completes the proof. \(\blacksquare\)","theorem List.head_takeWhile (p : α → Bool) (l : List α) (w) :
    (l.takeWhile p).head w = l.head (by rintro rfl; simp_all) := by
  cases l with
/- In the case where the list \( l \) is empty, the goal is trivially true because both sides of the equality are definitionally equal to the head of the empty list, which is undefined (or the goal is vacuously true). -/
  | nil => rfl
/- In the case where the list \( l \) is non-empty and can be written as \( x :: xs \), we need to show that the head of the list `List.takeWhile p (x :: xs)` is equal to the head of the original list \( x :: xs \). -/
  | cons x xs =>
/- Using the definitions of `List.takeWhile` and `List.head`, we simplify the goal. Specifically, we use the fact that `List.takeWhile p (x :: xs)` is either \( x :: \text{List.takeWhile} \, p \, xs \) if \( p(x) = \text{true} \), or the empty list if \( p(x) = \text{false} \). Similarly, `List.head (x :: xs)` is \( x \). -/
    simp only [takeWhile_cons, head_cons]
/- We simplify the assumption \( w \) using the definition of `List.takeWhile`. This gives us a more specific form of the assumption, which helps in further simplifying the goal. -/
    simp only [takeWhile_cons] at w
/- We consider two cases based on the condition \( p(x) = \text{true} \) or \( p(x) = \text{false} \). In each case, we simplify the goal using the definitions and properties of `List.takeWhile` and `List.head`. -/
/- We split the goal into two cases based on the condition \( p(x) = \text{true} \) or \( p(x) = \text{false} \). In each case, we simplify the goal using the definitions and properties of `List.takeWhile` and `List.head`. -/
    split <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34478,List.dropWhile_append_of_pos,"theorem List.dropWhile_append_of_pos {p : α → Bool} {l₁ l₂ : List α} (h : ∀ a ∈ l₁, p a) :
    (l₁ ++ l₂).dropWhile p = l₂.dropWhile p := by sorry","Drop While Preserves List Concatenation if Predicate is True on First List : For any type $\alpha$, predicate $p : \alpha \to \text{Bool}$, and lists $l_1, l_2$ of elements of type $\alpha$, if every element in $l_1$ satisfies $p$, then the result of applying `dropWhile p` to the concatenation of $l_1$ and $l_2$ is the same as applying `dropWhile p` to $l_2$ alone. In other words, if $p(a) = \text{true}$ for all $a \in l_1$, then $\text{dropWhile } p (l_1 \oplus l_2) = \text{dropWhile } p (l_2)$.","theorem List.dropWhile_append_of_pos {p : α → Bool} {l₁ l₂ : List α} (h : ∀ a ∈ l₁, p a) :
    (l₁ ++ l₂).dropWhile p = l₂.dropWhile p := by
  induction l₁ with
  | nil => simp
  | cons x xs ih => simp_all [dropWhile_cons]","We prove this by induction on the list \(l_1\).

1. **Base Case:**
- Suppose \(l_1\) is the empty list, i.e., \(l_1 = []\).
- We need to show that \(\text{dropWhile } p (l_1 \oplus l_2) = \text{dropWhile } p (l_2)\).
- Since \(l_1\) is empty, the concatenation \(l_1 \oplus l_2\) is simply \(l_2\).
- Therefore, \(\text{dropWhile } p (l_1 \oplus l_2) = \text{dropWhile } p (l_2)\) holds trivially.

2. **Inductive Step:**
- Suppose \(l_1\) is a non-empty list, i.e., \(l_1 = x :: xs\).
- We need to show that \(\text{dropWhile } p (x :: xs \oplus l_2) = \text{dropWhile } p (l_2)\).
- By the definition of \(\text{dropWhile}\), if \(p(x) = \text{true}\), then \(\text{dropWhile } p (x :: xs \oplus l_2) = \text{dropWhile } p (xs \oplus l_2)\).
- By the inductive hypothesis, \(\text{dropWhile } p (xs \oplus l_2) = \text{dropWhile } p (l_2)\).
- Therefore, \(\text{dropWhile } p (x :: xs \oplus l_2) = \text{dropWhile } p (l_2)\).

By induction, the theorem holds for all lists \(l_1\) and \(l_2\). This completes the proof. \(\blacksquare\)","theorem List.dropWhile_append_of_pos {p : α → Bool} {l₁ l₂ : List α} (h : ∀ a ∈ l₁, p a) :
    (l₁ ++ l₂).dropWhile p = l₂.dropWhile p := by
  induction l₁ with
/- First, consider the base case where the list \( l_1 \) is empty. We need to show that \(\text{dropWhile } p (l_1 \oplus l_2) = \text{dropWhile } p (l_2)\). Since \( l_1 \) is empty, the concatenation \( l_1 \oplus l_2 \) is simply \( l_2 \). Therefore, \(\text{dropWhile } p (l_1 \oplus l_2) = \text{dropWhile } p (l_2)\) holds trivially. -/
  | nil => simp
/- Next, consider the inductive case where \( l_1 \) is a non-empty list, i.e., \( l_1 = x :: xs \). We need to show that \(\text{dropWhile } p (x :: xs \oplus l_2) = \text{dropWhile } p (l_2)\). By the definition of \(\text{dropWhile}\), if \( p(x) = \text{true} \), then \(\text{dropWhile } p (x :: xs \oplus l_2) = \text{dropWhile } p (xs \oplus l_2)\). By the inductive hypothesis, \(\text{dropWhile } p (xs \oplus l_2) = \text{dropWhile } p (l_2)\). Therefore, \(\text{dropWhile } p (x :: xs \oplus l_2) = \text{dropWhile } p (l_2)\). -/
  | cons x xs ih => simp_all [dropWhile_cons]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34479,List.takeWhile_map,"theorem List.takeWhile_map (f : α → β) (p : β → Bool) (l : List α) :
    (l.map f).takeWhile p = (l.takeWhile (p ∘ f)).map f := by sorry","Take-While and Map Commute: $\text{takeWhile}(p, \text{map}(f, l)) = \text{map}(f, \text{takeWhile}(p \circ f, l))$ : For any types $\alpha$ and $\beta$, any function $f : \alpha \to \beta$, any predicate $p : \beta \to \text{Bool}$, and any list $l : \text{List} \, \alpha$, the following equality holds:
\[
\text{takeWhile}(p, \text{map}(f, l)) = \text{map}(f, \text{takeWhile}(p \circ f, l)).
\]
This means that applying the predicate $p$ to the elements of the list after mapping them with $f$ and taking the longest initial segment that satisfies $p$ is the same as first taking the longest initial segment of $l$ that satisfies the composed predicate $p \circ f$ and then mapping the elements of this segment with $f$.","theorem List.takeWhile_map (f : α → β) (p : β → Bool) (l : List α) :
    (l.map f).takeWhile p = (l.takeWhile (p ∘ f)).map f := by
  induction l with
  | nil => rfl
  | cons x xs ih =>
    simp only [map_cons, takeWhile_cons]
    split <;> simp_all","We prove this by induction on the list \(l\).

1. **Base Case:**
For the base case where the list is empty, the equality holds trivially due to the reflexive property of equality. Specifically, both sides of the equation are the empty list:
\[
\text{takeWhile}(p, \text{map}(f, [])) = \text{map}(f, \text{takeWhile}(p \circ f, [])).
\]
Both sides are \([]\).

2. **Inductive Step:**
Assume the list is of the form \( x :: xs \) and that the property holds for the list \( xs \). We need to show that the property holds for the list \( x :: xs \).

Using the definitions of `map` and `takeWhile` on a cons list, we simplify the proposition we want to show to:
\[
\text{if } p(f(x)) = \text{true} \text{ then } f(x) :: \text{takeWhile}(p, \text{map}(f, xs)) \text{ else } []
\]
is equal to
\[
\text{map}(f, \text{if } (p \circ f)(x) = \text{true} \text{ then } x :: \text{takeWhile}(p \circ f, xs) \text{ else } []).
\]

We discuss by cases based on the condition \( p(f(x)) = \text{true} \):

- **Case 1: \( p(f(x)) = \text{true} \):**
In this case, the left-hand side becomes:
\[
f(x) :: \text{takeWhile}(p, \text{map}(f, xs)),
\]
and the right-hand side becomes:
\[
\text{map}(f, x :: \text{takeWhile}(p \circ f, xs)) = f(x) :: \text{map}(f, \text{takeWhile}(p \circ f, xs)).
\]
By the inductive hypothesis, we have:
\[
\text{takeWhile}(p, \text{map}(f, xs)) = \text{map}(f, \text{takeWhile}(p \circ f, xs)).
\]
Therefore, both sides are equal.

- **Case 2: \( p(f(x)) = \text{false} \):**
In this case, the left-hand side becomes:
\[
[],
\]
and the right-hand side becomes:
\[
\text{map}(f, []).
\]
Both sides are \([]\).

In both cases, the equality holds. Therefore, by induction, the property holds for all lists \( l \).

This completes the proof. \(\blacksquare\)","theorem List.takeWhile_map (f : α → β) (p : β → Bool) (l : List α) :
    (l.map f).takeWhile p = (l.takeWhile (p ∘ f)).map f := by
  induction l with
/- For the base case where the list is empty, the equality holds trivially due to the reflexive property of equality. Specifically, both sides of the equation are the empty list. -/
  | nil => rfl
/- For the inductive step, assume the list is of the form \( x :: xs \) and that the property holds for the list \( xs \). We need to show that the property holds for the list \( x :: xs \). -/
  | cons x xs ih =>
/- Using the definitions of `map` and `takeWhile` on a cons list, we simplify the proposition we want to show to:
\[
\text{if } p(f(x)) = \text{true} \text{ then } f(x) :: \text{takeWhile}(p, \text{map}(f, xs)) \text{ else } []
\]
is equal to
\[
\text{map}(f, \text{if } (p \circ f)(x) = \text{true} \text{ then } x :: \text{takeWhile}(p \circ f, xs) \text{ else } []).
\] -/
    simp only [map_cons, takeWhile_cons]
/- We discuss by cases based on the condition \( p(f(x)) = \text{true} \). For each case, we simplify the proposition we want to show and the known hypothesis using the properties of the if-then-else function and the inductive hypothesis. -/
/- We discuss by cases based on the condition \( p(f(x)) = \text{true} \). For each case, we simplify the proposition we want to show and the known hypothesis using the properties of the if-then-else function and the inductive hypothesis. -/
    split <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34480,List.dropWhile_filter,"theorem List.dropWhile_filter (p q : α → Bool) (l : List α) :
    (l.filter p).dropWhile q = (l.dropWhile fun a => !p a || q a).filter p := by sorry","DropWhile and Filter Commute: \(\text{dropWhile } q \, (\text{filter } p \, l) = \text{filter } p \, (\text{dropWhile } (\text{not } p \, a \, \text{ or } q \, a) \, l)\) : For any type \( \alpha \) and any predicates \( p, q : \alpha \to \text{Bool} \), and for any list \( l \) of elements of type \( \alpha \), the list obtained by dropping elements from the filtered list \( \text{filter } p \, l \) while \( q \) returns `true` is equal to the list obtained by filtering the list \( l \) after dropping elements while the predicate \( \text{not } p \, a \, \text{ or } q \, a \) returns `true`. In other words, \( \text{dropWhile } q \, (\text{filter } p \, l) = \text{filter } p \, (\text{dropWhile } (\text{not } p \, a \, \text{ or } q \, a) \, l) \).","theorem List.dropWhile_filter (p q : α → Bool) (l : List α) :
    (l.filter p).dropWhile q = (l.dropWhile fun a => !p a || q a).filter p := by
  simp [← filterMap_eq_filter, dropWhile_filterMap]","To prove the theorem, we start by using the theorems `filterMap_eq_filter` and `dropWhile_filterMap` to simplify the goal. The theorem `filterMap_eq_filter` states that for any type \( \alpha \), a predicate \( p : \alpha \to \text{Bool} \), and a list \( l \) of elements of type \( \alpha \), the following equality holds:
\[
\text{filterMap } (\text{guard } p) \, l = \text{filter } p \, l
\]
The theorem `dropWhile_filterMap` states that for any types \( \alpha \) and \( \beta \), a function \( f : \alpha \to \text{Option} \beta \), a predicate \( p : \beta \to \text{Bool} \), and a list \( l \) of elements of type \( \alpha \), the following equality holds:
\[
\text{dropWhile } p \, (\text{filterMap } f \, l) = \text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, l)
\]
Using these theorems, we can simplify the goal to:
\[
\text{dropWhile } q \, (\text{filter } p \, l) = \text{filter } p \, (\text{dropWhile } (\lambda a, \, \text{not } p \, a \, \text{ or } q \, a) \, l)
\]
This completes the proof.","theorem List.dropWhile_filter (p q : α → Bool) (l : List α) :
    (l.filter p).dropWhile q = (l.dropWhile fun a => !p a || q a).filter p := by
/- We start by using the theorems `filterMap_eq_filter` and `dropWhile_filterMap` to simplify the goal. The theorem `filterMap_eq_filter` states that for any type \( \alpha \), a predicate \( p : \alpha \to \text{Bool} \), and a list \( l \) of elements of type \( \alpha \), the following equality holds:
\[
\text{filterMap } (\text{guard } p) \, l = \text{filter } p \, l
\]
The theorem `dropWhile_filterMap` states that for any types \( \alpha \) and \( \beta \), a function \( f : \alpha \to \text{Option} \beta \), a predicate \( p : \beta \to \text{Bool} \), and a list \( l \) of elements of type \( \alpha \), the following equality holds:
\[
\text{dropWhile } p \, (\text{filterMap } f \, l) = \text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, l)
\]
Using these theorems, we can simplify the goal to:
\[
\text{dropWhile } q \, (\text{filter } p \, l) = \text{filter } p \, (\text{dropWhile } (\lambda a, \, \text{not } p \, a \, \text{ or } q \, a) \, l)
\] -/
  simp [← filterMap_eq_filter, dropWhile_filterMap]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34481,List.head?_takeWhile,theorem List.head?_takeWhile (p : α → Bool) (l : List α) : (l.takeWhile p).head? = l.head?.filter p := by sorry,"Head of Longest Initial Segment Satisfying Predicate Equals Filtered Head of List: $\text{head}(\text{takeWhile } p \, l) = \text{Option.filter } p \, (\text{head? } l)$ : For any type $\alpha$ and a predicate $p : \alpha \to \text{Bool}$, and for any list $l$ of elements of type $\alpha$, the head of the list obtained by taking the longest initial segment of $l$ that satisfies $p$ is equal to the optional value obtained by filtering the head of $l$ through $p$. Formally, this is expressed as:
\[
\text{head}( \text{takeWhile } p \, l ) = \text{Option.filter } p \, (\text{head? } l)
\]","theorem List.head?_takeWhile (p : α → Bool) (l : List α) : (l.takeWhile p).head? = l.head?.filter p := by
  cases l with
  | nil => rfl
  | cons x xs =>
    simp only [takeWhile_cons, head?_cons, Option.filter_some]
    split <;> simp","We proceed by induction on the list \( l \).

1. **Base Case:**
- If \( l \) is the empty list, then:
\[
\text{head}(\text{takeWhile } p \, []) = \text{head}([]) = \text{none}
\]
and
\[
\text{Option.filter } p \, (\text{head? } []) = \text{Option.filter } p \, \text{none} = \text{none}
\]
Therefore, the equality holds trivially.

2. **Inductive Case:**
- Suppose \( l \) is a non-empty list, which can be written as \( x :: xs \). We need to show:
\[
\text{head}(\text{takeWhile } p \, (x :: xs)) = \text{Option.filter } p \, (\text{head? } (x :: xs))
\]
- We discuss by cases based on the condition \( p(x) = \text{true} \) or \( p(x) = \text{false} \).

- **Case 1: \( p(x) = \text{true} \)**
- The head of the list obtained by taking the longest initial segment of \( x :: xs \) that satisfies \( p \) is:
\[
\text{head}(\text{takeWhile } p \, (x :: xs)) = \text{head}(x :: \text{takeWhile } p \, xs) = \text{some } x
\]
- The filtered head of \( x :: xs \) through \( p \) is:
\[
\text{Option.filter } p \, (\text{head? } (x :: xs)) = \text{Option.filter } p \, (\text{some } x) = \text{some } x
\]
- Therefore, the equality holds.

- **Case 2: \( p(x) = \text{false} \)**
- The head of the list obtained by taking the longest initial segment of \( x :: xs \) that satisfies \( p \) is:
\[
\text{head}(\text{takeWhile } p \, (x :: xs)) = \text{head}([]) = \text{none}
\]
- The filtered head of \( x :: xs \) through \( p \) is:
\[
\text{Option.filter } p \, (\text{head? } (x :: xs)) = \text{Option.filter } p \, (\text{some } x) = \text{none}
\]
- Therefore, the equality holds.

By induction, the theorem holds for all lists \( l \). This completes the proof. \(\blacksquare\)","theorem List.head?_takeWhile (p : α → Bool) (l : List α) : (l.takeWhile p).head? = l.head?.filter p := by
  cases l with
/- For the base case where the list \( l \) is empty, the head of the empty list is `none`, and the filtered head of the empty list is also `none`. Therefore, the equality holds trivially due to the reflexive property. -/
  | nil => rfl
/- For the inductive case where the list \( l \) is non-empty and can be written as \( x :: xs \), we need to show that the head of the list obtained by taking the longest initial segment of \( l \) that satisfies \( p \) is equal to the optional value obtained by filtering the head of \( l \) through \( p \). -/
  | cons x xs =>
/- Using the definitions of `takeWhile` on a cons list, `head?` on a cons list, and `Option.filter` on a `some` value, we simplify the proposition we want to show to:
\[
\text{if } p(x) = \text{true} \text{ then } x :: \text{takeWhile } p \, xs \text{ else } [] \text{ has head } \text{some } x \text{ if } p(x) = \text{true} \text{ and } \text{none otherwise}
\] -/
    simp only [takeWhile_cons, head?_cons, Option.filter_some]
/- We discuss by cases based on the condition \( p(x) = \text{true} \) or \( p(x) = \text{false} \). For each case, we simplify the proposition we want to show using the definitions and properties of `takeWhile`, `head?`, and `Option.filter`. -/
/- We discuss by cases based on the condition \( p(x) = \text{true} \) or \( p(x) = \text{false} \). For each case, we simplify the proposition we want to show using the definitions and properties of `head?` and `Option.filter`. -/
    split <;> simp","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34482,List.takeWhile_append_of_pos,"theorem List.takeWhile_append_of_pos {p : α → Bool} {l₁ l₂ : List α} (h : ∀ a ∈ l₁, p a) :
    (l₁ ++ l₂).takeWhile p = l₁ ++ l₂.takeWhile p := by sorry","TakeWhile of Concatenated Lists with Positive Predicate on First List: \(\text{takeWhile } p \, (l_1 ++ l_2) = l_1 ++ \text{takeWhile } p \, l_2\) : For any type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), and for any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), if every element \( a \) in \( l_1 \) satisfies \( p(a) = \text{true} \), then the longest initial segment of the concatenated list \( l_1 ++ l_2 \) for which \( p \) returns `true` is given by:
\[ \text{takeWhile } p \, (l_1 ++ l_2) = l_1 ++ \text{takeWhile } p \, l_2. \]","theorem List.takeWhile_append_of_pos {p : α → Bool} {l₁ l₂ : List α} (h : ∀ a ∈ l₁, p a) :
    (l₁ ++ l₂).takeWhile p = l₁ ++ l₂.takeWhile p := by
  induction l₁ with
  | nil => simp
  | cons x xs ih => simp_all [takeWhile_cons]","We prove this by induction on the list \( l_1 \).

**Base Case:**
Consider \( l_1 = [] \). We need to show:
\[ \text{takeWhile } p \, ([] ++ l_2) = [] ++ \text{takeWhile } p \, l_2. \]
Since the concatenation of the empty list with any list \( l_2 \) is just \( l_2 \), the left-hand side simplifies to:
\[ \text{takeWhile } p \, l_2. \]
The right-hand side is:
\[ [] ++ \text{takeWhile } p \, l_2 = \text{takeWhile } p \, l_2. \]
Thus, the base case holds trivially.

**Inductive Case:**
Assume the statement holds for some list \( xs \), i.e.,
\[ \text{takeWhile } p \, (xs ++ l_2) = xs ++ \text{takeWhile } p \, l_2. \]
We need to show that the statement holds for \( l_1 = x :: xs \). Specifically, we need to show:
\[ \text{takeWhile } p \, ((x :: xs) ++ l_2) = (x :: xs) ++ \text{takeWhile } p \, l_2. \]
By the definition of `takeWhile`, the left-hand side can be expanded as:
\[ \text{takeWhile } p \, (x :: (xs ++ l_2)). \]
Since \( p(x) = \text{true} \) (by the hypothesis that every element in \( l_1 \) satisfies \( p \)), the `takeWhile` function will include \( x \) and then continue to process the rest of the list:
\[ \text{takeWhile } p \, (x :: (xs ++ l_2)) = x :: \text{takeWhile } p \, (xs ++ l_2). \]
By the inductive hypothesis, we know that:
\[ \text{takeWhile } p \, (xs ++ l_2) = xs ++ \text{takeWhile } p \, l_2. \]
Substituting this into the previous equation, we get:
\[ x :: \text{takeWhile } p \, (xs ++ l_2) = x :: (xs ++ \text{takeWhile } p \, l_2). \]
This simplifies to:
\[ (x :: xs) ++ \text{takeWhile } p \, l_2. \]
Thus, the inductive case holds.

By induction, the theorem is proved.","theorem List.takeWhile_append_of_pos {p : α → Bool} {l₁ l₂ : List α} (h : ∀ a ∈ l₁, p a) :
    (l₁ ++ l₂).takeWhile p = l₁ ++ l₂.takeWhile p := by
  induction l₁ with
/- First, consider the base case where \( l_1 \) is the empty list. We need to show that:
\[ \text{takeWhile } p \, ([] ++ l_2) = [] ++ \text{takeWhile } p \, l_2. \]
Since the concatenation of the empty list with any list \( l_2 \) is just \( l_2 \), the left-hand side simplifies to:
\[ \text{takeWhile } p \, l_2. \]
The right-hand side is:
\[ [] ++ \text{takeWhile } p \, l_2 = \text{takeWhile } p \, l_2. \]
Thus, the base case holds trivially. -/
  | nil => simp
/- Next, consider the inductive case where \( l_1 \) is a non-empty list, specifically \( l_1 = x :: xs \). We need to show that:
\[ \text{takeWhile } p \, ((x :: xs) ++ l_2) = (x :: xs) ++ \text{takeWhile } p \, l_2. \]
By the definition of `takeWhile`, the left-hand side can be expanded as:
\[ \text{takeWhile } p \, (x :: (xs ++ l_2)). \]
Since \( p(x) = \text{true} \) (by the hypothesis that every element in \( l_1 \) satisfies \( p \)), the `takeWhile` function will include \( x \) and then continue to process the rest of the list:
\[ \text{takeWhile } p \, (x :: (xs ++ l_2)) = x :: \text{takeWhile } p \, (xs ++ l_2). \]
By the inductive hypothesis, we know that:
\[ \text{takeWhile } p \, (xs ++ l_2) = xs ++ \text{takeWhile } p \, l_2. \]
Substituting this into the previous equation, we get:
\[ x :: \text{takeWhile } p \, (xs ++ l_2) = x :: (xs ++ \text{takeWhile } p \, l_2). \]
This simplifies to:
\[ (x :: xs) ++ \text{takeWhile } p \, l_2. \]
Thus, the inductive case holds. -/
  | cons x xs ih => simp_all [takeWhile_cons]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34483,List.take_eq_nil_iff,theorem List.take_eq_nil_iff {l : List α} {k : Nat} : l.take k = [] ↔ k = 0 ∨ l = [] := by sorry,"Condition for First \( k \) Elements of a List to be Empty: \( \text{take}(k, l) = [] \leftrightarrow k = 0 \lor l = [] \) : For any list \( l \) of elements of type \( \alpha \) and any natural number \( k \), the first \( k \) elements of \( l \) form an empty list if and only if \( k = 0 \) or \( l \) is the empty list, i.e., \( \text{take}(k, l) = [] \leftrightarrow k = 0 \lor l = [] \).","theorem List.take_eq_nil_iff {l : List α} {k : Nat} : l.take k = [] ↔ k = 0 ∨ l = [] := by
  cases l <;> cases k <;> simp [Nat.succ_ne_zero]","We will consider every possible case for the list \( l \) and the natural number \( k \).

1. **Case 1: \( l = [] \)**
- **Subcase 1.1: \( k = 0 \)**
- We need to show that \( \text{take}(0, []) = [] \leftrightarrow 0 = 0 \lor [] = [] \).
- This is trivially true because \( \text{take}(0, []) = [] \) and \( 0 = 0 \) is true.
- **Subcase 1.2: \( k = n + 1 \) for some natural number \( n \)**
- We need to show that \( \text{take}(n + 1, []) = [] \leftrightarrow n + 1 = 0 \lor [] = [] \).
- This is trivially true because \( \text{take}(n + 1, []) = [] \) and \( n + 1 \neq 0 \).

2. **Case 2: \( l = \text{head} :: \text{tail} \)**
- **Subcase 2.1: \( k = 0 \)**
- We need to show that \( \text{take}(0, \text{head} :: \text{tail}) = [] \leftrightarrow 0 = 0 \lor \text{head} :: \text{tail} = [] \).
- This is trivially true because \( \text{take}(0, \text{head} :: \text{tail}) = [] \) and \( 0 = 0 \) is true.
- **Subcase 2.2: \( k = n + 1 \) for some natural number \( n \)**
- We need to show that \( \text{take}(n + 1, \text{head} :: \text{tail}) = [] \leftrightarrow n + 1 = 0 \lor \text{head} :: \text{tail} = [] \).
- This is trivially true because \( \text{take}(n + 1, \text{head} :: \text{tail}) = \text{head} :: \text{take}(n, \text{tail}) \neq [] \) and \( n + 1 \neq 0 \).

Thus, in all cases, the statement \( \text{take}(k, l) = [] \leftrightarrow k = 0 \lor l = [] \) holds. This completes the proof.","theorem List.take_eq_nil_iff {l : List α} {k : Nat} : l.take k = [] ↔ k = 0 ∨ l = [] := by
/- We will consider every possible case for the list \( l \) and the natural number \( k \). For each case, we will simplify the goal using the fact that the successor of any natural number is not zero. -/
/- We will consider two cases for the list \( l \):
1. \( l \) is the empty list \( [] \).
2. \( l \) is a non-empty list of the form \( \text{head} :: \text{tail} \). -/
/- For the case where \( l \) is the empty list \( [] \), we will consider two cases for the natural number \( k \):
1. \( k = 0 \).
2. \( k = n + 1 \) for some natural number \( n \). -/
/- For the case where \( l \) is a non-empty list \( \text{head} :: \text{tail} \), we will consider two cases for the natural number \( k \):
1. \( k = 0 \).
2. \( k = n + 1 \) for some natural number \( n \). -/
/- For the case where \( l = [] \) and \( k = 0 \), we simplify the goal using the fact that the successor of any natural number is not zero. This simplifies the goal to \( \text{take}(0, []) = [] \leftrightarrow 0 = 0 \lor [] = [] \), which is trivially true. -/
/- For the case where \( l = [] \) and \( k = n + 1 \), we simplify the goal using the fact that the successor of any natural number is not zero. This simplifies the goal to \( \text{take}(n + 1, []) = [] \leftrightarrow n + 1 = 0 \lor [] = [] \), which is trivially true because \( n + 1 \neq 0 \). -/
/- For the case where \( l = \text{head} :: \text{tail} \) and \( k = 0 \), we simplify the goal using the fact that the successor of any natural number is not zero. This simplifies the goal to \( \text{take}(0, \text{head} :: \text{tail}) = [] \leftrightarrow 0 = 0 \lor \text{head} :: \text{tail} = [] \), which is trivially true. -/
/- For the case where \( l = \text{head} :: \text{tail} \) and \( k = n + 1 \), we simplify the goal using the fact that the successor of any natural number is not zero. This simplifies the goal to \( \text{take}(n + 1, \text{head} :: \text{tail}) = [] \leftrightarrow n + 1 = 0 \lor \text{head} :: \text{tail} = [] \), which is trivially true because \( n + 1 \neq 0 \). -/
  cases l <;> cases k <;> simp [Nat.succ_ne_zero]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34484,List.head?_dropWhile_not,"theorem List.head?_dropWhile_not (p : α → Bool) (l : List α) :
    match (l.dropWhile p).head? with | some x => p x = false | none => True := by sorry","First Element of `dropWhile` Result is Not Satisfying Predicate : For any type $\alpha$ and any predicate $p : \alpha \to \text{Bool}$, if the list $l : \text{List} \, \alpha$ is non-empty after applying `List.dropWhile p` to it, then the first element of the resulting list satisfies $p(x) = \text{false}$. If the resulting list is empty, the statement is trivially true.","theorem List.head?_dropWhile_not (p : α → Bool) (l : List α) :
    match (l.dropWhile p).head? with | some x => p x = false | none => True := by
  induction l with
  | nil => simp
  | cons x xs ih =>
    simp only [dropWhile_cons]
    split <;> rename_i h <;> split at h <;> simp_all","We proceed by induction on the list \( l \).

1. **Base Case:**
- If the list \( l \) is empty, the result is trivially true because the `head?` of an empty list is `none`, and the statement \( p(x) = \text{false} \) is vacuously true.

2. **Inductive Step:**
- Suppose the list \( l \) is non-empty and can be written as \( x :: xs \). We use the induction hypothesis \( ih \) which states that the result holds for the list \( xs \).

- We consider two cases based on the condition \( p(x) = \text{true} \) or \( p(x) = \text{false} \):
- **Case 1: \( p(x) = \text{true} \)**
- In this case, the result of `dropWhile p (x :: xs)` is `dropWhile p xs`.
- By the induction hypothesis \( ih \), the first element of `dropWhile p xs` satisfies \( p(x) = \text{false} \).

- **Case 2: \( p(x) = \text{false} \)**
- In this case, the result of `dropWhile p (x :: xs)` is \( x :: xs \).
- The first element of \( x :: xs \) is \( x \), and by the condition \( p(x) = \text{false} \), the statement holds.

In both cases, the result follows from the properties of the `dropWhile` function and the induction hypothesis. Therefore, the theorem is proved. \(\blacksquare\)","theorem List.head?_dropWhile_not (p : α → Bool) (l : List α) :
    match (l.dropWhile p).head? with | some x => p x = false | none => True := by
  induction l with
/- If the list is empty, the result is trivially true because the `head?` of an empty list is `none`, and the statement \( p(x) = \text{false} \) is vacuously true. -/
  | nil => simp
/- If the list is non-empty, we consider the list as \( x :: xs \) and use the induction hypothesis \( ih \) which states that the result holds for the list \( xs \). -/
  | cons x xs ih =>
/- We simplify the goal using the definition of `dropWhile` for a non-empty list. The result of `dropWhile p (x :: xs)` is:
- If \( p(x) = \text{true} \), then it is `dropWhile p xs`.
- If \( p(x) = \text{false} \), then it is \( x :: xs \). -/
    simp only [dropWhile_cons]
/- We consider two cases based on whether the list is empty or not. If the list is empty, the result is trivially true. If the list is non-empty, we rename the hypothesis and split it into two cases based on the condition \( p(x) = \text{true} \) or \( p(x) = \text{false} \). In both cases, we simplify the goal using the properties of the `dropWhile` function and the hypothesis. -/
/- We consider two cases based on the condition \( p(x) = \text{true} \) or \( p(x) = \text{false} \):
- If \( p(x) = \text{true} \), we need to show that the first element of `dropWhile p xs` satisfies \( p(x) = \text{false} \).
- If \( p(x) = \text{false} \), we need to show that the first element of \( x :: xs \) is \( x \) and \( p(x) = \text{false} \).

In both cases, we simplify the goal using the properties of the `dropWhile` function and the hypothesis. -/
    split <;> rename_i h <;> split at h <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34485,List.dropWhile_map,"theorem List.dropWhile_map (f : α → β) (p : β → Bool) (l : List α) :
    (l.map f).dropWhile p = (l.dropWhile (p ∘ f)).map f := by sorry","Drop-While and Map Commute: \(\text{dropWhile } p \, (\text{map } f \, l) = \text{map } f \, (\text{dropWhile } (p \circ f) \, l)\) : For any types \( \alpha \) and \( \beta \), a function \( f : \alpha \to \beta \), a predicate \( p : \beta \to \text{Bool} \), and a list \( l \) of elements of type \( \alpha \), the following equality holds:
\[
\text{dropWhile } p \, (\text{map } f \, l) = \text{map } f \, (\text{dropWhile } (p \circ f) \, l)
\]
This theorem states that the list obtained by first applying the function \( f \) to each element of \( l \) and then dropping elements from the beginning of the resulting list while the predicate \( p \) holds is the same as the list obtained by first dropping elements from the beginning of \( l \) while the predicate \( p \) holds for the result of \( f \) and then applying \( f \) to the remaining elements.","theorem List.dropWhile_map (f : α → β) (p : β → Bool) (l : List α) :
    (l.map f).dropWhile p = (l.dropWhile (p ∘ f)).map f := by
  induction l with
  | nil => rfl
  | cons x xs ih =>
    simp only [map_cons, dropWhile_cons]
    split <;> simp_all","We prove this by induction on the list \( l \).

1. **Base Case:**
- If \( l \) is the empty list, then both sides of the equation are the empty list. Therefore, the equality holds trivially by the reflexive property of equality.

2. **Inductive Step:**
- Assume \( l \) is of the form \( x :: xs \) and that the property holds for the list \( xs \). We need to show that the property holds for the list \( x :: xs \).
- Using the definitions of `map` and `dropWhile` for the cons constructor, we simplify the goal to:
\[
\text{if } p(f(x)) = \text{true} \text{ then } \text{dropWhile } p \, (\text{map } f \, xs) \text{ else } f(x) :: \text{map } f \, xs
\]
is equal to
\[
\text{map } f \, (\text{if } (p \circ f)(x) = \text{true} \text{ then } \text{dropWhile } (p \circ f) \, xs \text{ else } x :: xs)
\]
- We discuss by cases based on the condition \( p(f(x)) = \text{true} \):
- **Case 1: \( p(f(x)) = \text{true} \)**
- The left-hand side simplifies to \( \text{dropWhile } p \, (\text{map } f \, xs) \).
- The right-hand side simplifies to \( \text{map } f \, (\text{dropWhile } (p \circ f) \, xs) \).
- By the induction hypothesis, \( \text{dropWhile } p \, (\text{map } f \, xs) = \text{map } f \, (\text{dropWhile } (p \circ f) \, xs) \), so the equality holds.
- **Case 2: \( p(f(x)) = \text{false} \)**
- The left-hand side simplifies to \( f(x) :: \text{map } f \, xs \).
- The right-hand side simplifies to \( f(x) :: \text{map } f \, xs \).
- Both sides are equal, so the equality holds.

Thus, by induction, the theorem holds for all lists \( l \). This completes the proof. \(\blacksquare\)","theorem List.dropWhile_map (f : α → β) (p : β → Bool) (l : List α) :
    (l.map f).dropWhile p = (l.dropWhile (p ∘ f)).map f := by
  induction l with
/- For the base case where the list \( l \) is empty, the equality holds trivially by the reflexive property of equality. Specifically, both sides of the equation are the empty list. -/
  | nil => rfl
/- For the inductive step, assume the list \( l \) is of the form \( x :: xs \) and that the property holds for the list \( xs \). We need to show that the property holds for the list \( x :: xs \). -/
  | cons x xs ih =>
/- Using the definitions of `map` and `dropWhile` for the cons constructor, we simplify the goal to:
\[
\text{if } p(f(x)) = \text{true} \text{ then } \text{dropWhile } p \, (\text{map } f \, xs) \text{ else } f(x) :: \text{map } f \, xs
\]
is equal to
\[
\text{map } f \, (\text{if } (p \circ f)(x) = \text{true} \text{ then } \text{dropWhile } (p \circ f) \, xs \text{ else } x :: xs)
\] -/
    simp only [map_cons, dropWhile_cons]
/- We discuss by cases based on the condition \( p(f(x)) = \text{true} \). For each case, we simplify the proposition and the hypothesis using the properties of the if-then-else function and the induction hypothesis. -/
/- We discuss by cases based on the condition \( p(f(x)) = \text{true} \). For each case, we simplify the proposition and the hypothesis using the properties of the if-then-else function and the induction hypothesis. -/
    split <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34486,List.all_takeWhile,theorem List.all_takeWhile {l : List α} : (l.takeWhile p).all p = true := by sorry,"All Elements in TakeWhile Satisfy Predicate: \((\text{takeWhile } p \, l). \text{all } p = \text{true}\) : For any list \( l \) of elements of type \( \alpha \) and a predicate \( p : \alpha \to \text{Bool} \), the longest initial segment of \( l \) that satisfies \( p \) has all elements satisfying \( p \). In other words, if \( \text{takeWhile } p \, l \) is the longest initial segment of \( l \) for which \( p \) returns `true`, then every element in \( \text{takeWhile } p \, l \) satisfies \( p \).","theorem List.all_takeWhile {l : List α} : (l.takeWhile p).all p = true := by
  induction l with
  | nil => rfl
  | cons h t ih => by_cases p h <;> simp_all","We prove this by induction on the list \( l \).

1. **Base Case: \( l \) is empty.**
- If \( l \) is empty, then the longest initial segment of \( l \) that satisfies \( p \) is also empty. The empty list trivially satisfies the property that all elements satisfy \( p \). Therefore, the goal is trivially true due to the reflexive property.

2. **Inductive Step: \( l \) is non-empty.**
- Let \( l = h :: t \) for some head element \( h \) and tail list \( t \). We need to show that the longest initial segment of \( l \) that satisfies \( p \) has all elements satisfying \( p \). We split the proof into two cases based on whether \( p(h) \) is true or false.

- **Case 1: \( p(h) \) is true.**
- If \( p(h) \) is true, then \( h \) is included in the longest initial segment of \( l \) that satisfies \( p \). By the inductive hypothesis, the longest initial segment of \( t \) that satisfies \( p \) has all elements satisfying \( p \). Therefore, the longest initial segment of \( l \) that satisfies \( p \) is \( h \) followed by the longest initial segment of \( t \) that satisfies \( p \). Since both \( h \) and the elements in the longest initial segment of \( t \) satisfy \( p \), the entire segment satisfies \( p \). This simplifies the goal to a trivially true statement.

- **Case 2: \( p(h) \) is false.**
- If \( p(h) \) is false, then \( h \) is not included in the longest initial segment of \( l \) that satisfies \( p \). Therefore, the longest initial segment of \( l \) that satisfies \( p \) is the same as the longest initial segment of \( t \) that satisfies \( p \). By the inductive hypothesis, the longest initial segment of \( t \) that satisfies \( p \) has all elements satisfying \( p \). This simplifies the goal to a trivially true statement.

By induction, the theorem holds for all lists \( l \). This completes the proof. \(\blacksquare\)","theorem List.all_takeWhile {l : List α} : (l.takeWhile p).all p = true := by
  induction l with
/- First, consider the base case where the list \( l \) is empty. In this case, the longest initial segment of \( l \) that satisfies \( p \) is also empty. Since the empty list trivially satisfies the property that all elements satisfy \( p \), the goal is trivially true due to the reflexive property. -/
  | nil => rfl
/- Next, consider the inductive step where the list \( l \) is non-empty, i.e., \( l = h :: t \) for some head element \( h \) and tail list \( t \). We need to show that the longest initial segment of \( l \) that satisfies \( p \) has all elements satisfying \( p \). We split the proof into two cases based on whether \( p(h) \) is true or false.

1. **Case 1: \( p(h) \) is true.**
- If \( p(h) \) is true, then \( h \) is included in the longest initial segment of \( l \) that satisfies \( p \). By the inductive hypothesis, the longest initial segment of \( t \) that satisfies \( p \) has all elements satisfying \( p \). Therefore, the longest initial segment of \( l \) that satisfies \( p \) is \( h \) followed by the longest initial segment of \( t \) that satisfies \( p \). Since both \( h \) and the elements in the longest initial segment of \( t \) satisfy \( p \), the entire segment satisfies \( p \). This simplifies the goal to a trivially true statement.

2. **Case 2: \( p(h) \) is false.**
- If \( p(h) \) is false, then \( h \) is not included in the longest initial segment of \( l \) that satisfies \( p \). Therefore, the longest initial segment of \( l \) that satisfies \( p \) is the same as the longest initial segment of \( t \) that satisfies \( p \). By the inductive hypothesis, the longest initial segment of \( t \) that satisfies \( p \) has all elements satisfying \( p \). This simplifies the goal to a trivially true statement. -/
  | cons h t ih => by_cases p h <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34488,List.takeWhile_replicate_eq_filter,"theorem List.takeWhile_replicate_eq_filter (p : α → Bool) :
    (replicate n a).takeWhile p = (replicate n a).filter p := by sorry","Longest Initial Segment of Replicated List Equals Filtered Replicated List : For any type $\alpha$, natural number $n$, and element $a \in \alpha$, and for any predicate $p : \alpha \to \text{Bool}$, the longest initial segment of the list `replicate n a` that satisfies $p$ is equal to the list of elements in `replicate n a` that satisfy $p$. In other words, if $p(a) = \text{true}$, then `takeWhile p (replicate n a)` is the same as `filter p (replicate n a)`, and if $p(a) = \text{false}$, both `takeWhile p (replicate n a)` and `filter p (replicate n a)` return the empty list.","theorem List.takeWhile_replicate_eq_filter (p : α → Bool) :
    (replicate n a).takeWhile p = (replicate n a).filter p := by
  induction n with
  | zero => simp
  | succ n ih =>
    simp only [replicate_succ, takeWhile_cons]
    split <;> simp_all","We prove this by induction on \(n\).

**Base Case:**
For \(n = 0\), the list `replicate 0 a` is the empty list. Therefore, both `takeWhile p (replicate 0 a)` and `filter p (replicate 0 a)` are the empty list, and thus they are equal.

**Inductive Step:**
Assume that the statement holds for \(n\). We need to show that it holds for \(n + 1\).

Consider the list `replicate (n + 1) a`, which is `a :: replicate n a`.

1. **Case 1: \(p(a) = \text{true}\)**
- By the definition of `takeWhile`, `takeWhile p (a :: replicate n a)` is `a :: takeWhile p (replicate n a)`.
- By the inductive hypothesis, `takeWhile p (replicate n a) = filter p (replicate n a)`.
- Therefore, `takeWhile p (a :: replicate n a) = a :: filter p (replicate n a)`.
- By the definition of `filter`, `filter p (a :: replicate n a)` is `a :: filter p (replicate n a)`.
- Hence, `takeWhile p (a :: replicate n a) = filter p (a :: replicate n a)`.

2. **Case 2: \(p(a) = \text{false}\)**
- By the definition of `takeWhile`, `takeWhile p (a :: replicate n a)` is the empty list.
- By the definition of `filter`, `filter p (a :: replicate n a)` is the empty list.
- Therefore, `takeWhile p (a :: replicate n a) = filter p (a :: replicate n a)`.

In both cases, the statement holds for \(n + 1\). By the principle of mathematical induction, the statement holds for all natural numbers \(n\).

\(\blacksquare\)","theorem List.takeWhile_replicate_eq_filter (p : α → Bool) :
    (replicate n a).takeWhile p = (replicate n a).filter p := by
  induction n with
/- For the base case where \( n = 0 \), we simplify the goal using the properties of `replicate`, `takeWhile`, and `filter`. Since `replicate 0 a` is the empty list, both `takeWhile p (replicate 0 a)` and `filter p (replicate 0 a)` are the empty list, and thus they are equal. -/
  | zero => simp
/- For the inductive step, assume that the statement holds for \( n \). We need to show that it holds for \( n + 1 \). -/
  | succ n ih =>
/- Using the definitions of `replicate` and `takeWhile`, we simplify the goal. Specifically, `replicate (n + 1) a` is `a :: replicate n a`, and `takeWhile p (a :: l)` is `a :: takeWhile p l` if \( p(a) = \text{true} \), and the empty list otherwise. -/
    simp only [replicate_succ, takeWhile_cons]
/- We consider two cases based on the condition \( p(a) = \text{true} \) or \( p(a) = \text{false} \). In each case, we simplify the goal using the properties of `takeWhile` and `filter` on lists. -/
/- We consider two cases based on the condition \( p(a) = \text{true} \) or \( p(a) = \text{false} \). In each case, we simplify the goal using the properties of `takeWhile` and `filter` on lists. -/
    split <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34496,List.dropWhile_replicate_eq_filter_not,"theorem List.dropWhile_replicate_eq_filter_not (p : α → Bool) :
    (replicate n a).dropWhile p = (replicate n a).filter (fun a => !p a) := by sorry","Drop While Equals Filter Not in Replicated List : For any type $\alpha$, natural number $n$, and element $a \in \alpha$, and for any predicate $p : \alpha \to \text{Bool}$, the list obtained by dropping elements from the list `replicate n a` while the predicate $p$ is true is equal to the list obtained by filtering `replicate n a` to keep only the elements for which the predicate $p$ is false. In other words, `dropWhile p (replicate n a)` is equal to `filter (not p) (replicate n a)`.","theorem List.dropWhile_replicate_eq_filter_not (p : α → Bool) :
    (replicate n a).dropWhile p = (replicate n a).filter (fun a => !p a) := by
  induction n with
  | zero => simp
  | succ n ih =>
    simp only [replicate_succ, dropWhile_cons]
    split <;> simp_all","We prove this by induction on \(n\).

**Base Case:**
For \(n = 0\), the list `replicate 0 a` is the empty list. Therefore, both `dropWhile p (replicate 0 a)` and `filter (fun a => !p a) (replicate 0 a)` are the empty list, and thus they are equal.

**Inductive Step:**
Assume the inductive hypothesis that for some \(k \geq 0\), `dropWhile p (replicate k a) = filter (fun a => !p a) (replicate k a)`. We need to show that `dropWhile p (replicate (k + 1) a) = filter (fun a => !p a) (replicate (k + 1) a)`.

By the definition of `replicate`, `replicate (k + 1) a` is `a :: replicate k a`. We consider two cases based on the value of \(p(a)\):

1. **Case 1: \(p(a) = \text{true}\)**
- By the definition of `dropWhile`, `dropWhile p (a :: replicate k a)` is `dropWhile p (replicate k a)`.
- By the inductive hypothesis, `dropWhile p (replicate k a) = filter (fun a => !p a) (replicate k a)`.
- By the definition of `filter`, `filter (fun a => !p a) (a :: replicate k a)` is `filter (fun a => !p a) (replicate k a)` because \(p(a) = \text{true}\) implies \(!p(a) = \text{false}\).
- Therefore, `dropWhile p (replicate (k + 1) a) = filter (fun a => !p a) (replicate (k + 1) a)`.

2. **Case 2: \(p(a) = \text{false}\)**
- By the definition of `dropWhile`, `dropWhile p (a :: replicate k a)` is `a :: replicate k a`.
- By the definition of `filter`, `filter (fun a => !p a) (a :: replicate k a)` is `a :: filter (fun a => !p a) (replicate k a)` because \(p(a) = \text{false}\) implies \(!p(a) = \text{true}\).
- Therefore, `a :: replicate k a = a :: filter (fun a => !p a) (replicate k a)`, and thus `dropWhile p (replicate (k + 1) a) = filter (fun a => !p a) (replicate (k + 1) a)`.

By induction, the theorem holds for all natural numbers \(n\). This completes the proof. \(\blacksquare\)","theorem List.dropWhile_replicate_eq_filter_not (p : α → Bool) :
    (replicate n a).dropWhile p = (replicate n a).filter (fun a => !p a) := by
  induction n with
/- For the base case where \( n = 0 \), we simplify the goal using the properties of the `dropWhile` and `filter` operations on the empty list. Since `replicate 0 a` is the empty list, both `dropWhile p (replicate 0 a)` and `filter (fun a => !p a) (replicate 0 a)` are the empty list, and thus they are equal. -/
  | zero => simp
/- For the inductive step where \( n = k + 1 \), we assume the inductive hypothesis that `dropWhile p (replicate k a) = filter (fun a => !p a) (replicate k a)` holds. We need to show that `dropWhile p (replicate (k + 1) a) = filter (fun a => !p a) (replicate (k + 1) a)`. -/
  | succ n ih =>
/- We simplify the goal using the definitions of `replicate` and `dropWhile`. Specifically, `replicate (k + 1) a` is `a :: replicate k a`, and `dropWhile p (a :: xs)` is:
- If \( p(a) = \text{true} \), then `dropWhile p xs`.
- If \( p(a) = \text{false} \), then `a :: xs`.

Thus, the goal becomes:
- If \( p(a) = \text{true} \), then `dropWhile p (replicate k a)`.
- If \( p(a) = \text{false} \), then `a :: replicate k a`. -/
    simp only [replicate_succ, dropWhile_cons]
/- We consider the two cases based on the condition \( p(a) \). For each case, we simplify the goal using the properties of the `dropWhile` and `filter` operations on lists. -/
/- We consider the two cases based on the condition \( p(a) \):
1. If \( p(a) = \text{true} \), we need to show that `dropWhile p (replicate k a) = filter (fun a => !p a) (a :: replicate k a)`.
2. If \( p(a) = \text{false} \), we need to show that `a :: replicate k a = filter (fun a => !p a) (a :: replicate k a)`.

For each case, we simplify the goal using the properties of the `dropWhile` and `filter` operations on lists. -/
    split <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34497,List.dropWhile_replicate,"theorem List.dropWhile_replicate (p : α → Bool) :
    (replicate n a).dropWhile p = if p a then [] else replicate n a := by sorry","DropWhile on Replicated List: \(\text{dropWhile } p \, (\text{replicate } n \, a) = \text{if } p(a) = \text{true then } [] \text{ else } \text{replicate } n \, a\) : For any type \( \alpha \), natural number \( n \), and element \( a \in \alpha \), the function `List.dropWhile p` applied to the list `List.replicate n a` results in the empty list if the predicate \( p \) is true for \( a \), and the original list `List.replicate n a` otherwise. In other words, if \( p(a) = \text{true} \), then `List.dropWhile p (List.replicate n a) = []`; otherwise, `List.dropWhile p (List.replicate n a) = List.replicate n a`.","theorem List.dropWhile_replicate (p : α → Bool) :
    (replicate n a).dropWhile p = if p a then [] else replicate n a := by
  simp only [dropWhile_replicate_eq_filter_not, filter_replicate]
  split <;> simp_all","We start by using the fact that `List.dropWhile p (List.replicate n a)` is equivalent to `List.filter (not p) (List.replicate n a)`. We also use the fact that `List.filter p (List.replicate n a)` is `List.replicate n a` if \( p a \) is true and `[]` otherwise. This simplifies our goal to:
\[
\text{if } (\neg p a) = \text{true} \text{ then } \text{replicate } n \, a \text{ else } [] = \text{if } p a = \text{true} \text{ then } [] \text{ else } \text{replicate } n \, a
\]

We discuss by cases based on the condition \((\neg p a) = \text{true}\):

1. **Case 1: \((\neg p a) = \text{true}\)**
- In this case, the left-hand side of the equation is \(\text{replicate } n \, a\).
- The right-hand side of the equation is \(\text{if } p a = \text{true} \text{ then } [] \text{ else } \text{replicate } n \, a\).
- Since \((\neg p a) = \text{true}\), it follows that \(p a = \text{false}\).
- Therefore, the right-hand side simplifies to \(\text{replicate } n \, a\).
- Hence, the equation holds: \(\text{replicate } n \, a = \text{replicate } n \, a\).

2. **Case 2: \((\neg p a) = \text{false}\)**
- In this case, the left-hand side of the equation is \([]\).
- The right-hand side of the equation is \(\text{if } p a = \text{true} \text{ then } [] \text{ else } \text{replicate } n \, a\).
- Since \((\neg p a) = \text{false}\), it follows that \(p a = \text{true}\).
- Therefore, the right-hand side simplifies to \([]\).
- Hence, the equation holds: \([] = []\).

In both cases, the equation holds, thus completing the proof.","theorem List.dropWhile_replicate (p : α → Bool) :
    (replicate n a).dropWhile p = if p a then [] else replicate n a := by
/- Using the fact that `List.dropWhile p (List.replicate n a)` is equivalent to `List.filter (not p) (List.replicate n a)`, and the fact that `List.filter p (List.replicate n a)` is `List.replicate n a` if `p a` is true and `[]` otherwise, we can simplify the goal to:
\[
\text{if } (\neg p a) = \text{true} \text{ then } \text{replicate } n \, a \text{ else } [] = \text{if } p a = \text{true} \text{ then } [] \text{ else } \text{replicate } n \, a
\] -/
  simp only [dropWhile_replicate_eq_filter_not, filter_replicate]
/- We discuss by cases based on the condition \((\neg p a) = \text{true}\):

1. **Case 1: \((\neg p a) = \text{true}\)**
- In this case, the left-hand side of the equation is \(\text{replicate } n \, a\).
- The right-hand side of the equation is \(\text{if } p a = \text{true} \text{ then } [] \text{ else } \text{replicate } n \, a\).
- Since \((\neg p a) = \text{true}\), it follows that \(p a = \text{false}\).
- Therefore, the right-hand side simplifies to \(\text{replicate } n \, a\).
- Hence, the equation holds: \(\text{replicate } n \, a = \text{replicate } n \, a\).

2. **Case 2: \((\neg p a) = \text{false}\)**
- In this case, the left-hand side of the equation is \([]\).
- The right-hand side of the equation is \(\text{if } p a = \text{true} \text{ then } [] \text{ else } \text{replicate } n \, a\).
- Since \((\neg p a) = \text{false}\), it follows that \(p a = \text{true}\).
- Therefore, the right-hand side simplifies to \([]\).
- Hence, the equation holds: \([] = []\). -/
  split <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34498,List.take_succ,theorem List.take_succ {l : List α} {n : Nat} : l.take (n + 1) = l.take n ++ l[n]?.toList := by sorry,"First \( n + 1 \) Elements of a List are the First \( n \) Elements Concatenated with the \( n \)-th Element: \(\text{take } (n + 1) \ l = \text{take } n \ l \ ++ \ [l[n]]\) : For any type \( \alpha \) and any list \( l \) of elements of type \( \alpha \), and for any natural number \( n \), the first \( n + 1 \) elements of \( l \) are equal to the concatenation of the first \( n \) elements of \( l \) and the list containing the element at index \( n \) of \( l \). Mathematically, this can be expressed as:
\[ \text{take } (n + 1) \ l = \text{take } n \ l \ ++ \ [l[n]]. \]","theorem List.take_succ {l : List α} {n : Nat} : l.take (n + 1) = l.take n ++ l[n]?.toList := by
  induction l generalizing n with
  | nil =>
    simp only [take_nil, Option.toList, getElem?_nil, append_nil]
  | cons hd tl hl =>
    cases n
    · simp only [take, Option.toList, getElem?_cons_zero, nil_append]
    · simp only [take, hl, getElem?_cons_succ, cons_append]","We prove this by induction on the list \( l \).

**Base Case:**
Consider the case where \( l \) is the empty list. We need to show:
\[ \text{take } (n + 1) \ \text{nil} = \text{take } n \ \text{nil} \ ++ \ [\text{nil}[n]]. \]
Using the properties that taking elements from an empty list results in an empty list, converting `none` to a list results in an empty list, and appending an empty list to any list results in the original list, we have:
\[ \text{take } (n + 1) \ \text{nil} = \text{nil} \]
and
\[ \text{take } n \ \text{nil} \ ++ \ [\text{nil}[n]] = \text{nil} \ ++ \ \text{nil} = \text{nil}. \]
Thus, the base case holds.

**Inductive Step:**
Assume the statement holds for a list \( tl \), i.e., for any natural number \( n \),
\[ \text{take } (n + 1) \ tl = \text{take } n \ tl \ ++ \ [tl[n]]. \]
We need to show that the statement holds for the cons list \( hd :: tl \). We consider two cases for \( n \).

**Case 1: \( n = 0 \)**
We need to show:
\[ \text{take } (0 + 1) \ (hd :: tl) = \text{take } 0 \ (hd :: tl) \ ++ \ [(hd :: tl)[0]]. \]
Using the definitions of `take` and the property that the element at index 0 in a cons list is the head of the list, we have:
\[ \text{take } 1 \ (hd :: tl) = [hd] \]
and
\[ \text{take } 0 \ (hd :: tl) \ ++ \ [(hd :: tl)[0]] = \text{nil} \ ++ \ [hd] = [hd]. \]
Thus, the case \( n = 0 \) holds.

**Case 2: \( n = m + 1 \)**
We need to show:
\[ \text{take } (m + 1 + 1) \ (hd :: tl) = \text{take } (m + 1) \ (hd :: tl) \ ++ \ [(hd :: tl)[m + 1]]. \]
Using the definitions of `take`, the inductive hypothesis, and the property that the element at the successor index in a cons list is the element at the current index in the tail list, we have:
\[ \text{take } (m + 2) \ (hd :: tl) = hd :: \text{take } (m + 1) \ tl \]
and
\[ \text{take } (m + 1) \ (hd :: tl) \ ++ \ [(hd :: tl)[m + 1]] = (hd :: \text{take } m \ tl) \ ++ \ [tl[m]]. \]
By the inductive hypothesis, we know:
\[ \text{take } (m + 1) \ tl = \text{take } m \ tl \ ++ \ [tl[m]]. \]
Thus,
\[ \text{take } (m + 2) \ (hd :: tl) = hd :: (\text{take } m \ tl \ ++ \ [tl[m]]) = (hd :: \text{take } m \ tl) \ ++ \ [tl[m]]. \]
Therefore, the case \( n = m + 1 \) holds.

By induction, the statement holds for all natural numbers \( n \) and all lists \( l \). This completes the proof. \(\blacksquare\)","theorem List.take_succ {l : List α} {n : Nat} : l.take (n + 1) = l.take n ++ l[n]?.toList := by
  induction l generalizing n with
/- We perform induction on the list `l` and consider the base case where `l` is the empty list. In this case, we need to show that the first \( n + 1 \) elements of the empty list are equal to the concatenation of the first \( n \) elements of the empty list and the list containing the element at index \( n \) of the empty list. -/
  | nil =>
/- Using the properties that taking elements from an empty list results in an empty list, converting `none` to a list results in an empty list, and appending an empty list to any list results in the original list, we simplify the goal to the trivial equality of the empty list with itself. This completes the base case. -/
    simp only [take_nil, Option.toList, getElem?_nil, append_nil]
/- Next, we consider the inductive step where `l` is a cons list `hd :: tl`. We need to show that the first \( n + 1 \) elements of `hd :: tl` are equal to the concatenation of the first \( n \) elements of `hd :: tl` and the list containing the element at index \( n \) of `hd :: tl`. -/
  | cons hd tl hl =>
/- We perform case analysis on the natural number \( n \). We consider two cases: \( n = 0 \) and \( n = m + 1 \) for some natural number \( m \). -/
    cases n
/- For the case \( n = 0 \), we simplify the goal using the definitions of `take`, the property that the element at index 0 in a cons list is the head of the list, and the property that appending an empty list to any list results in the original list. This simplifies the goal to the trivial equality of the list containing the head of the list with itself. This completes the case \( n = 0 \). -/
    · simp only [take, Option.toList, getElem?_cons_zero, nil_append]
/- First, we simplify the goal using the definitions of `take`, the hypothesis `hl`, the property that the element at the successor index in a cons list is the element at the current index in the tail list, and the property that appending a list to a cons list is equivalent to consing the head to the appended tail list. This simplifies the goal to the desired form. -/
/- For the case \( n = m + 1 \), we simplify the goal using the definitions of `take`, the hypothesis `hl`, the property that the element at the successor index in a cons list is the element at the current index in the tail list, and the property that appending a list to a cons list is equivalent to consing the head to the appended tail list. This simplifies the goal to the desired form, completing the inductive step. -/
    · simp only [take, hl, getElem?_cons_succ, cons_append]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34499,List.pairwise_replicate,"theorem List.pairwise_replicate {n : Nat} {a : α} :
    (replicate n a).Pairwise R ↔ n ≤ 1 ∨ R a a := by sorry","Pairwise Relation on Replicated List: \( \text{Pairwise } R \, (\text{replicate } n \, a) \leftrightarrow n \leq 1 \lor R \, a \, a \) : For any type \(\alpha\), any relation \(R\) on \(\alpha\), any natural number \(n\), and any element \(a \in \alpha\), the list `replicate n a` satisfies the pairwise relation \(R\) if and only if \(n \leq 1\) or \(R a a\) holds.","theorem List.pairwise_replicate {n : Nat} {a : α} :
    (replicate n a).Pairwise R ↔ n ≤ 1 ∨ R a a := by
  induction n with
  | zero => simp
  | succ n ih =>
    simp only [replicate_succ, pairwise_cons, mem_replicate, ne_eq, and_imp,
      forall_eq_apply_imp_iff, ih]
    constructor
    · rintro ⟨h, h' | h'⟩
      · by_cases w : n = 0
        · left
          subst w
          simp
        · right
          exact h w
      · right
        exact h'
    · rintro (h | h)
      · obtain rfl := eq_zero_of_le_zero (le_of_lt_succ h)
        simp
      · exact ⟨fun _ => h, Or.inr h⟩","We prove the theorem by induction on \(n\).

1. **Base Case: \(n = 0\)**

- The list `replicate 0 a` is the empty list.
- The pairwise relation \(R\) on the empty list is trivially true.
- Therefore, `Pairwise R (replicate 0 a)` is equivalent to \(0 \leq 1 \lor R a a\), which is true because \(0 \leq 1\) is always true.

2. **Inductive Step: \(n = k + 1\)**

- Assume the inductive hypothesis: `Pairwise R (replicate k a) ↔ k ≤ 1 ∨ R a a`.
- We need to show that `Pairwise R (replicate (k + 1) a) ↔ (k + 1) ≤ 1 ∨ R a a`.

- **Forward Direction:**
- We need to show that \((\neg k = 0 \to R a a) \land (k \leq 1 \lor R a a) \to (k + 1) \leq 1 \lor R a a\).
- Consider two cases:
- **Case 1: \(k = 0\)**:
- If \(k = 0\), then \(k + 1 = 1\).
- Therefore, \((k + 1) \leq 1\) is true.
- **Case 2: \(k \neq 0\)**:
- If \(k \neq 0\), then \(\neg k = 0\).
- By the inductive hypothesis, \(R a a\) holds.
- Therefore, \(R a a\) implies \((k + 1) \leq 1 \lor R a a\).

- **Backward Direction:**
- We need to show that \((k + 1) \leq 1 \lor R a a \to (\neg k = 0 \to R a a) \land (k \leq 1 \lor R a a)\).
- Consider two cases:
- **Case 1: \((k + 1) \leq 1\)**:
- If \((k + 1) \leq 1\), then \(k \leq 0\).
- Since \(k\) is a natural number, \(k = 0\).
- Therefore, \(\neg 0 = 0 \to R a a\) is trivially true, and \(0 \leq 1 \lor R a a\) is true.
- **Case 2: \(R a a\)**:
- If \(R a a\) holds, then \(\neg k = 0 \to R a a\) is true, and \(k \leq 1 \lor R a a\) is true.

By induction, the theorem holds for all natural numbers \(n\). Therefore, the list `replicate n a` satisfies the pairwise relation \(R\) if and only if \(n \leq 1\) or \(R a a\) holds. \(\blacksquare\)","theorem List.pairwise_replicate {n : Nat} {a : α} :
    (replicate n a).Pairwise R ↔ n ≤ 1 ∨ R a a := by
  induction n with
/- We consider the base case where \(n = 0\). Using the definition of `replicate 0 a`, which is the empty list, and the definition of `Pairwise R` on the empty list, we simplify the goal to show that \(0 \leq 1 \lor R a a\). Since \(0 \leq 1\) is always true, the goal is trivially satisfied. -/
  | zero => simp
/- We consider the inductive step where \(n = k + 1\) for some natural number \(k\). We assume the inductive hypothesis that `Pairwise R (replicate k a) ↔ k ≤ 1 ∨ R a a` and need to show that `Pairwise R (replicate (k + 1) a) ↔ (k + 1) ≤ 1 ∨ R a a`. -/
  | succ n ih =>
/- We simplify the goal using the definitions and properties of `replicate`, `pairwise`, and the inductive hypothesis. Specifically, we use the fact that `replicate (k + 1) a` is `a :: replicate k a`, and the definition of `pairwise` on a list with a head and a tail. This simplifies the goal to \((\neg k = 0 \to R a a) \land (k \leq 1 \lor R a a) ↔ (k + 1) \leq 1 \lor R a a\). -/
    simp only [replicate_succ, pairwise_cons, mem_replicate, ne_eq, and_imp,
      forall_eq_apply_imp_iff, ih]
/- To prove the bi-implication, we need to show both directions. We start by showing the forward direction: \((\neg k = 0 \to R a a) \land (k \leq 1 \lor R a a) \to (k + 1) \leq 1 \lor R a a\). -/
    constructor
/- We consider the cases for the left-hand side of the implication. We have two cases: either \(h\) is a proof of \(\neg k = 0 \to R a a\) and \(h'\) is a proof of \(k \leq 1\), or \(h'\) is a proof of \(R a a\). -/
    · rintro ⟨h, h' | h'⟩
/- We consider two cases: either \(k = 0\) or \(k \neq 0\). -/
      · by_cases w : n = 0
/- If \(k = 0\), we need to show that \((k + 1) \leq 1 \lor R a a\). Since \(k + 1 = 1\), we have \(1 \leq 1\), which is true. Therefore, the left disjunct is true. -/
        · left
/- We substitute \(k = 0\) into the goal, simplifying it to show that \(1 \leq 1\), which is trivially true. -/
          subst w
/- Simplify the goal to show that \(1 \leq 1\), which is trivially true. -/
          simp
/- If \(k \neq 0\), we need to show that \((k + 1) \leq 1 \lor R a a\). Since \(k \neq 0\), we have \(\neg k = 0\), and by the inductive hypothesis, \(R a a\) holds. Therefore, the right disjunct is true. -/
        · right
/- The current goal is exactly proved by \(h\) and \(w\), which are the proofs of \(\neg k = 0 \to R a a\) and \(k \neq 0\), respectively. -/
          exact h w
/- We need to show that \((k + 1) \leq 1 \lor R a a\). Since \(h'\) is a proof of \(R a a\), the right disjunct is true. -/
      · right
/- The current goal is exactly proved by \(h'\), which is a proof of \(R a a\). -/
        exact h'
/- We consider the cases for the right-hand side of the implication. We have two cases: either \(h\) is a proof of \((k + 1) \leq 1\) or \(h\) is a proof of \(R a a\). -/
    · rintro (h | h)
/- If \(h\) is a proof of \((k + 1) \leq 1\), we use the fact that \(k + 1 \leq 1\) implies \(k \leq 0\). Since \(k\) is a natural number, \(k \leq 0\) implies \(k = 0\). We substitute \(k = 0\) into the goal, simplifying it to show that \((\neg 0 = 0 \to R a a) \land (0 \leq 1 \lor R a a)\). -/
      · obtain rfl := eq_zero_of_le_zero (le_of_lt_succ h)
/- Simplify the goal to show that \((\neg 0 = 0 \to R a a) \land (0 \leq 1 \lor R a a)\), which is trivially true because \(0 \leq 1\) is always true. -/
        simp
/- To prove the current goal, we need to show that \((\neg n = 0 \to R a a) \land (n \leq 1 \lor R a a)\). We can construct this by showing that \(\neg n = 0 \to R a a\) and \(n \leq 1 \lor R a a\). The first part is trivially true because \(h\) is a proof of \(R a a\), and the second part is true because \(h\) is a proof of \(R a a\), which implies \(n \leq 1 \lor R a a\). -/
/- If \(h\) is a proof of \(R a a\), we need to show that \((\neg k = 0 \to R a a) \land (k \leq 1 \lor R a a)\). The first part is trivially true because \(h\) is a proof of \(R a a\), and the second part is true because \(h\) is a proof of \(R a a\), which implies \(k \leq 1 \lor R a a\). -/
      · exact ⟨fun _ => h, Or.inr h⟩","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Nat
"
34502,List.takeWhile_append,"theorem List.takeWhile_append {xs ys : List α} :
    (xs ++ ys).takeWhile p =
      if (xs.takeWhile p).length = xs.length then xs ++ ys.takeWhile p else xs.takeWhile p := by sorry","TakeWhile of Concatenated Lists: \(\text{takeWhile } p \, (xs ++ ys)\) : For any type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), and for any lists \( xs \) and \( ys \) of elements of type \( \alpha \), the longest initial segment of the concatenated list \( xs ++ ys \) for which \( p \) returns `true` is given by:
\[ \text{takeWhile } p \, (xs ++ ys) = 
  \begin{cases} 
   xs ++ \text{takeWhile } p \, ys & \text{if } \text{length}(\text{takeWhile } p \, xs) = \text{length}(xs) \\
   \text{takeWhile } p \, xs & \text{otherwise}
  \end{cases}
\]","theorem List.takeWhile_append {xs ys : List α} :
    (xs ++ ys).takeWhile p =
      if (xs.takeWhile p).length = xs.length then xs ++ ys.takeWhile p else xs.takeWhile p := by
  induction xs with
  | nil => simp
  | cons x xs ih =>
    simp only [cons_append, takeWhile_cons]
    split
    · simp_all only [length_cons, add_one_inj]
      split <;> rfl
    · simp_all","We prove this theorem by induction on the list \( xs \).

1. **Base Case: \( xs = [] \)**
- We need to show that \(\text{takeWhile } p \, ([] ++ ys) = \text{takeWhile } p \, ys\).
- Using the properties of list concatenation, we have \(\text{takeWhile } p \, ([] ++ ys) = \text{takeWhile } p \, ys\).
- This is trivially true.

2. **Inductive Step: \( xs = x :: xs' \)**
- Assume the proposition holds for the list \( xs' \), i.e., \(\text{takeWhile } p \, (xs' ++ ys) = \text{takeWhile } p \, xs' \) if \(\text{length}(\text{takeWhile } p \, xs') = \text{length}(xs')\), and \(\text{takeWhile } p \, xs'\) otherwise.
- We need to show that \(\text{takeWhile } p \, (x :: xs' ++ ys) = \text{takeWhile } p \, (x :: xs')\) if \(\text{length}(\text{takeWhile } p \, (x :: xs')) = \text{length}(x :: xs')\), and \(\text{takeWhile } p \, (x :: xs')\) otherwise.
- Using the properties of the `takeWhile` function, we have:
\[
\text{takeWhile } p \, (x :: xs' ++ ys) =
\begin{cases}
x :: \text{takeWhile } p \, (xs' ++ ys) & \text{if } p(x) = \text{true} \\
[] & \text{if } p(x) = \text{false}
\end{cases}
\]
- We consider two cases based on the value of \( p(x) \):

- **Case 1: \( p(x) = \text{true} \)**
- We need to show that:
\[
x :: \text{takeWhile } p \, (xs' ++ ys) =
\begin{cases}
x :: (xs' ++ \text{takeWhile } p \, ys) & \text{if } \text{length}(\text{takeWhile } p \, xs') = \text{length}(xs') \\
x :: \text{takeWhile } p \, xs' & \text{otherwise}
\end{cases}
\]
- Using the inductive hypothesis, we have:
\[
\text{takeWhile } p \, (xs' ++ ys) =
\begin{cases}
xs' ++ \text{takeWhile } p \, ys & \text{if } \text{length}(\text{takeWhile } p \, xs') = \text{length}(xs') \\
\text{takeWhile } p \, xs' & \text{otherwise}
\end{cases}
\]
- Therefore, the goal reduces to:
\[
x :: \text{takeWhile } p \, (xs' ++ ys) =
\begin{cases}
x :: (xs' ++ \text{takeWhile } p \, ys) & \text{if } \text{length}(\text{takeWhile } p \, xs') = \text{length}(xs') \\
x :: \text{takeWhile } p \, xs' & \text{otherwise}
\end{cases}
\]
- This is trivially true.

- **Case 2: \( p(x) = \text{false} \)**
- We need to show that:
\[
[] =
\begin{cases}
x :: (xs' ++ \text{takeWhile } p \, ys) & \text{if } \text{length}(\text{takeWhile } p \, xs') = \text{length}(xs') \\
[] & \text{otherwise}
\end{cases}
\]
- Since \( p(x) = \text{false} \), the condition \(\text{length}(\text{takeWhile } p \, (x :: xs')) = \text{length}(x :: xs')\) is false.
- Therefore, the goal reduces to:
\[
[] = []
\]
- This is trivially true.

Thus, by induction, the theorem holds for all lists \( xs \) and \( ys \). This completes the proof. \(\blacksquare\)","theorem List.takeWhile_append {xs ys : List α} :
    (xs ++ ys).takeWhile p =
      if (xs.takeWhile p).length = xs.length then xs ++ ys.takeWhile p else xs.takeWhile p := by
  induction xs with
/- We consider the base case where the list `xs` is empty. Using the properties of the `takeWhile` function and list concatenation, we simplify the goal and show that the proposition holds trivially. -/
  | nil => simp
/- We perform induction on the list `xs`. For the inductive step, we assume that the proposition holds for the list `xs` and consider the list `x :: xs`. We need to show that the proposition holds for the list `x :: xs`. -/
  | cons x xs ih =>
/- Using the properties of list concatenation and the `takeWhile` function, we simplify the goal to a more manageable form. Specifically, we use the fact that `takeWhile p (x :: xs)` is `x :: takeWhile p xs` if `p x` is `true`, and the empty list otherwise. -/
    simp only [cons_append, takeWhile_cons]
/- We discuss by cases based on the condition `p x = true`. We consider two cases: when `p x` is `true` and when `p x` is `false`. -/
    split
/- First, we simplify the proposition we want to show using the properties of list concatenation and the `takeWhile` function. This simplification reduces the goal to a more manageable form. -/
    · simp_all only [length_cons, add_one_inj]
/- We further split the goal into two subgoals based on the condition `(takeWhile p xs).length = xs.length`. For each subgoal, we show that the equality holds trivially due to the reflexive property of equality. -/
      split <;> rfl
/- For the case where `p x = true`, we simplify the goal using the properties of list length and the fact that adding one to a number is injective. This simplification reduces the goal to a more manageable form. -/
/- For the case where `p x = false`, we simplify the goal using the properties of the `takeWhile` function and list concatenation. This simplification reduces the goal to a trivial equality, which holds due to the reflexive property of equality. -/
    · simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34504,List.dropWhile_append,"theorem List.dropWhile_append {xs ys : List α} :
    (xs ++ ys).dropWhile p =
      if (xs.dropWhile p).isEmpty then ys.dropWhile p else xs.dropWhile p ++ ys := by sorry","Drop While on Concatenation of Lists : For any type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), and for any lists \( xs \) and \( ys \) of elements of type \( \alpha \), the result of applying the `dropWhile` function to the concatenation of \( xs \) and \( ys \) is:
- \( \text{dropWhile } p \, ys \) if \( \text{dropWhile } p \, xs \) is an empty list,
- \( \text{dropWhile } p \, xs \) concatenated with \( \text{dropWhile } p \, ys \) otherwise.","theorem List.dropWhile_append {xs ys : List α} :
    (xs ++ ys).dropWhile p =
      if (xs.dropWhile p).isEmpty then ys.dropWhile p else xs.dropWhile p ++ ys := by
  induction xs with
  | nil => simp
  | cons h t ih =>
    simp only [cons_append, dropWhile_cons]
    split <;> simp_all","We prove the theorem by induction on the list \( xs \).

1. **Base Case: \( xs \) is the empty list.**
- The goal is to show that \( \text{dropWhile } p \, ([] ++ ys) = \text{dropWhile } p \, ys \).
- Since the concatenation of the empty list with any list \( ys \) is just \( ys \), and the `dropWhile` of an empty list is also an empty list, the goal simplifies to:
\[
\text{dropWhile } p \, ys = \text{dropWhile } p \, ys
\]
- This is trivially true.

2. **Inductive Step: \( xs \) is a non-empty list.**
- Assume \( xs \) is of the form \( h :: t \), where \( h \) is the head of the list and \( t \) is the tail.
- Assume the induction hypothesis that for any list \( t \) and \( ys \), the property holds:
\[
\text{dropWhile } p \, (t ++ ys) = \text{if } (\text{dropWhile } p \, t).isEmpty = \text{true} \text{ then } \text{dropWhile } p \, ys \text{ else } \text{dropWhile } p \, t ++ ys
\]
- We need to show that:
\[
\text{dropWhile } p \, (h :: t ++ ys) = \text{if } (\text{dropWhile } p \, (h :: t)).isEmpty = \text{true} \text{ then } \text{dropWhile } p \, ys \text{ else } \text{dropWhile } p \, (h :: t) ++ ys
\]
- Using the properties of the `cons` function and the `dropWhile` function, we have:
\[
\text{dropWhile } p \, (h :: t ++ ys) = \text{if } p(h) = \text{true} \text{ then } \text{dropWhile } p \, (t ++ ys) \text{ else } h :: (t ++ ys)
\]
- We consider two sub-cases based on whether \( p(h) \) is true or false.

- **Sub-case 1: \( p(h) = \text{true} \)**
- The goal simplifies to:
\[
\text{dropWhile } p \, (t ++ ys) = \text{if } (\text{dropWhile } p \, t).isEmpty = \text{true} \text{ then } \text{dropWhile } p \, ys \text{ else } \text{dropWhile } p \, t ++ ys
\]
- By the induction hypothesis, this is true.

- **Sub-case 2: \( p(h) = \text{false} \)**
- The goal simplifies to:
\[
h :: (t ++ ys) = \text{if } (h :: t).isEmpty = \text{true} \text{ then } \text{dropWhile } p \, ys \text{ else } h :: t ++ ys
\]
- Since \( h :: t \) is not an empty list, the condition \( (h :: t).isEmpty = \text{true} \) is false. Therefore, the goal further simplifies to:
\[
h :: (t ++ ys) = h :: t ++ ys
\]
- This is trivially true.

Thus, by induction, the theorem holds for all lists \( xs \) and \( ys \). This completes the proof. \(\blacksquare\)","theorem List.dropWhile_append {xs ys : List α} :
    (xs ++ ys).dropWhile p =
      if (xs.dropWhile p).isEmpty then ys.dropWhile p else xs.dropWhile p ++ ys := by
  induction xs with
/- In the case where \( xs \) is the empty list, we simplify the goal using the properties of the `dropWhile` function and the if-then-else construct. Since the empty list concatenated with any list \( ys \) is just \( ys \), and the `dropWhile` of an empty list is also an empty list, the goal simplifies to the desired result. -/
  | nil => simp
/- In the case where \( xs \) is a non-empty list, we assume \( xs \) is of the form \( h :: t \), where \( h \) is the head of the list and \( t \) is the tail. We also assume the induction hypothesis that the property holds for the tail \( t \). -/
  | cons h t ih =>
/- Using the properties of the `cons` function and the `dropWhile` function, we simplify the goal. Specifically, we use the fact that the `dropWhile` of a list starting with an element \( h \) is either the `dropWhile` of the tail \( t \) if \( p(h) \) is true, or the list \( h :: t \) if \( p(h) \) is false. -/
    simp only [cons_append, dropWhile_cons]
/- We consider two cases based on whether the list \( xs \) is empty or not. For each case, we simplify the goal using the properties of the `dropWhile` function and the if-then-else construct. -/
/- We consider two sub-cases based on whether \( p(h) \) is true or false. For each sub-case, we simplify the goal using the properties of the `dropWhile` function and the if-then-else construct. -/
    split <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34505,List.drop_sizeOf_le,theorem List.drop_sizeOf_le [SizeOf α] (l : List α) (n : Nat) : sizeOf (l.drop n) ≤ sizeOf l := by sorry,"Size of Dropped List is Less Than or Equal to Original List Size: \(\text{sizeOf}(\text{List.drop}(n, l)) \leq \text{sizeOf}(l)\) : For any list \( l \) of elements of type \( \alpha \) and any natural number \( n \), the size of the list obtained by dropping the first \( n \) elements of \( l \) is less than or equal to the size of \( l \). Formally, if \( l \) is a list of elements of type \( \alpha \) and \( n \) is a natural number, then \( \text{sizeOf}(\text{List.drop}(n, l)) \leq \text{sizeOf}(l) \).","theorem List.drop_sizeOf_le [SizeOf α] (l : List α) (n : Nat) : sizeOf (l.drop n) ≤ sizeOf l := by
  induction l generalizing n with
  | nil => rw [drop_nil]; apply Nat.le_refl
  | cons _ _ lih =>
    induction n with
    | zero => apply Nat.le_refl
    | succ n =>
      exact Trans.trans (lih _) (Nat.le_add_left _ _)","We will prove this by induction on the structure of the list \( l \).

1. **Base Case:**
- Consider the case where the list \( l \) is empty, i.e., \( l = \text{nil} \).
- By the definition of the `drop` function, dropping any number of elements from the empty list results in the empty list:
\[ \text{drop}(n, \text{nil}) = \text{nil} \]
- Therefore, the size of the empty list is less than or equal to the size of the empty list:
\[ \text{sizeOf}(\text{nil}) \leq \text{sizeOf}(\text{nil}) \]
- This is trivially true by the reflexivity of the less than or equal to relation.

2. **Inductive Step:**
- Consider the case where the list \( l \) is non-empty, i.e., \( l = \text{head} :: \text{tail} \).
- We will use induction on the natural number \( n \) to prove the statement.

- **Base Case for \( n = 0 \):**
- When \( n = 0 \), we need to show that the size of the list obtained by dropping 0 elements from \( \text{head} :: \text{tail} \) is less than or equal to the size of \( \text{head} :: \text{tail} \).
- Dropping 0 elements from a list results in the list itself:
\[ \text{drop}(0, \text{head} :: \text{tail}) = \text{head} :: \text{tail} \]
- Therefore, the size of the list remains unchanged:
\[ \text{sizeOf}(\text{head} :: \text{tail}) \leq \text{sizeOf}(\text{head} :: \text{tail}) \]
- This is true by the reflexivity of the less than or equal to relation.

- **Inductive Step for \( n + 1 \):**
- Assume that the statement holds for \( n \), i.e., \( \text{sizeOf}(\text{drop}(n, \text{tail})) \leq \text{sizeOf}(\text{tail}) \).
- We need to show that the statement holds for \( n + 1 \), i.e., \( \text{sizeOf}(\text{drop}(n + 1, \text{head} :: \text{tail})) \leq \text{sizeOf}(\text{head} :: \text{tail}) \).

- By the definition of the `drop` function, dropping \( n + 1 \) elements from \( \text{head} :: \text{tail} \) is equivalent to dropping \( n \) elements from \( \text{tail} \):
\[ \text{sizeOf}(\text{drop}(n + 1, \text{head} :: \text{tail})) = \text{sizeOf}(\text{drop}(n, \text{tail})) \]

- By the inductive hypothesis, we know:
\[ \text{sizeOf}(\text{drop}(n, \text{tail})) \leq \text{sizeOf}(\text{tail}) \]

- Since the size of \( \text{head} :: \text{tail} \) is the size of \( \text{head} \) plus the size of \( \text{tail} \):
\[ \text{sizeOf}(\text{head} :: \text{tail}) = \text{sizeOf}(\text{head}) + \text{sizeOf}(\text{tail}) \]

- Using the transitivity of the less than or equal to relation and the fact that adding a non-negative number (the size of \( \text{head} \)) to both sides of an inequality preserves the inequality, we get:
\[ \text{sizeOf}(\text{drop}(n, \text{tail})) \leq \text{sizeOf}(\text{tail}) \leq \text{sizeOf}(\text{head}) + \text{sizeOf}(\text{tail}) \]

- Thus, we have:
\[ \text{sizeOf}(\text{drop}(n + 1, \text{head} :: \text{tail})) \leq \text{sizeOf}(\text{head} :: \text{tail}) \]

This completes the inductive step and the proof.","theorem List.drop_sizeOf_le [SizeOf α] (l : List α) (n : Nat) : sizeOf (l.drop n) ≤ sizeOf l := by
  induction l generalizing n with
/- First, consider the case where the list \( l \) is empty. By the definition of the `drop` function, dropping any number of elements from the empty list results in the empty list. Therefore, the size of the empty list is less than or equal to the size of the empty list, which is trivially true by the reflexivity of the less than or equal to relation. -/
  | nil => rw [drop_nil]; apply Nat.le_refl
/- Next, consider the case where the list \( l \) is non-empty, i.e., \( l = \text{head} :: \text{tail} \). We will use induction on the natural number \( n \) to prove the statement. -/
  | cons _ _ lih =>
    induction n with
/- For the base case, when \( n = 0 \), we need to show that the size of the list obtained by dropping 0 elements from \( \text{head} :: \text{tail} \) is less than or equal to the size of \( \text{head} :: \text{tail} \). Dropping 0 elements from a list results in the list itself, so the size of the list remains unchanged. Therefore, the size of the list is less than or equal to itself, which is true by the reflexivity of the less than or equal to relation. -/
    | zero => apply Nat.le_refl
    | succ n =>
/- For the inductive step, assume that the statement holds for \( n \), i.e., \( \text{sizeOf}(\text{drop}(n, \text{tail})) \leq \text{sizeOf}(\text{tail}) \). We need to show that the statement holds for \( n + 1 \), i.e., \( \text{sizeOf}(\text{drop}(n + 1, \text{head} :: \text{tail})) \leq \text{sizeOf}(\text{head} :: \text{tail}) \).

By the definition of the `drop` function, dropping \( n + 1 \) elements from \( \text{head} :: \text{tail} \) is equivalent to dropping \( n \) elements from \( \text{tail} \). Therefore, we have:
\[ \text{sizeOf}(\text{drop}(n + 1, \text{head} :: \text{tail})) = \text{sizeOf}(\text{drop}(n, \text{tail})) \]

By the inductive hypothesis, we know:
\[ \text{sizeOf}(\text{drop}(n, \text{tail})) \leq \text{sizeOf}(\text{tail}) \]

Since the size of \( \text{head} :: \text{tail} \) is the size of \( \text{head} \) plus the size of \( \text{tail} \), we have:
\[ \text{sizeOf}(\text{head} :: \text{tail}) = \text{sizeOf}(\text{head}) + \text{sizeOf}(\text{tail}) \]

Using the transitivity of the less than or equal to relation and the fact that adding a non-negative number (the size of \( \text{head} \)) to both sides of an inequality preserves the inequality, we get:
\[ \text{sizeOf}(\text{drop}(n, \text{tail})) \leq \text{sizeOf}(\text{tail}) \leq \text{sizeOf}(\text{head}) + \text{sizeOf}(\text{tail}) \]

Thus, we have:
\[ \text{sizeOf}(\text{drop}(n + 1, \text{head} :: \text{tail})) \leq \text{sizeOf}(\text{head} :: \text{tail}) \]

This completes the inductive step. -/
      exact Trans.trans (lih _) (Nat.le_add_left _ _)","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34513,List.any_dropWhile,"theorem List.any_dropWhile {l : List α} :
    (l.dropWhile p).any (fun x => !p x) = !l.all p := by sorry","Any Element in Dropped List Satisfies Negated Predicate if and only if Not All Elements in Original List Satisfy Predicate: \((\text{List.dropWhile } p \, l). \text{any } (\lambda x, \, \neg p(x)) = \neg (\text{List.all } p \, l)\) : For any list \( l \) of elements of type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), the boolean value \((\text{List.dropWhile } p \, l). \text{any } (\lambda x, \, \neg p(x))\) is equal to the negation of \(\text{List.all } p \, l\). In other words, if there is any element in the list \( l \) that does not satisfy the predicate \( p \), then \((\text{List.dropWhile } p \, l). \text{any } (\lambda x, \, \neg p(x))\) will be `true`, and if all elements in \( l \) satisfy \( p \), then \((\text{List.dropWhile } p \, l). \text{any } (\lambda x, \, \neg p(x))\) will be `false`.","theorem List.any_dropWhile {l : List α} :
    (l.dropWhile p).any (fun x => !p x) = !l.all p := by
  induction l with
  | nil => rfl
  | cons h t ih => by_cases p h <;> simp_all","We prove the theorem by induction on the list \( l \).

1. **Base Case: \( l \) is empty.**
- The goal is to show that \((\text{List.dropWhile } p \, []). \text{any } (\lambda x, \, \neg p(x)) = \neg (\text{List.all } p \, [])\).
- Since the list is empty, \(\text{List.dropWhile } p \, []\) is also empty, and \(\text{List.any } (\lambda x, \, \neg p(x))\) on an empty list is `false`.
- Similarly, \(\text{List.all } p \, []\) is `true` because there are no elements to check.
- Therefore, \(\neg (\text{List.all } p \, [])\) is `false`.
- Hence, both sides of the equation are `false`, and the base case holds.

2. **Inductive Case: \( l \) is of the form \( h :: t \).**
- We split the proof into two cases based on the value of the predicate \( p(h) \).

- **Case 1: \( p(h) \) is true.**
- In this case, \(\text{List.dropWhile } p \, (h :: t)\) is equal to \(\text{List.dropWhile } p \, t\).
- We need to show that \((\text{List.dropWhile } p \, t). \text{any } (\lambda x, \, \neg p(x)) = \neg (h :: t). \text{all } p\).
- By the inductive hypothesis, \((\text{List.dropWhile } p \, t). \text{any } (\lambda x, \, \neg p(x)) = \neg t. \text{all } p\).
- Since \( p(h) \) is true, \((h :: t). \text{all } p\) is equivalent to \( t. \text{all } p \).
- Therefore, the goal simplifies to \(\neg t. \text{all } p = \neg t. \text{all } p\), which is trivially true.

- **Case 2: \( p(h) \) is false.**
- In this case, \(\text{List.dropWhile } p \, (h :: t)\) is equal to \( h :: \text{List.dropWhile } p \, t \).
- We need to show that \((h :: \text{List.dropWhile } p \, t). \text{any } (\lambda x, \, \neg p(x)) = \neg (h :: t). \text{all } p\).
- Since \( p(h) \) is false, \( h \) satisfies \(\neg p(h)\).
- Therefore, \((h :: \text{List.dropWhile } p \, t). \text{any } (\lambda x, \, \neg p(x))\) is true.
- On the other hand, \((h :: t). \text{all } p\) is false because \( p(h) \) is false.
- Therefore, \(\neg (h :: t). \text{all } p\) is true.
- Hence, the goal \((h :: \text{List.dropWhile } p \, t). \text{any } (\lambda x, \, \neg p(x)) = \neg (h :: t). \text{all } p\) is true.

By induction, the theorem holds for all lists \( l \). This completes the proof.","theorem List.any_dropWhile {l : List α} :
    (l.dropWhile p).any (fun x => !p x) = !l.all p := by
  induction l with
/- First, consider the base case where the list \( l \) is empty. The goal is to show that \((\text{List.dropWhile } p \, []). \text{any } (\lambda x, \, \neg p(x)) = \neg (\text{List.all } p \, [])\). This is trivially true because both sides of the equation are definitionally equal to `false`. -/
  | nil => rfl
/- Next, consider the inductive case where the list \( l \) is of the form \( h :: t \). We split the proof into two cases based on the value of the predicate \( p(h) \):

1. **Case 1: \( p(h) \) is true.**
- In this case, the list \( \text{List.dropWhile } p \, (h :: t) \) is equal to \(\text{List.dropWhile } p \, t\). We need to show that \((\text{List.dropWhile } p \, t). \text{any } (\lambda x, \, \neg p(x)) = \neg (h :: t). \text{all } p\).
- By the inductive hypothesis, we know that \((\text{List.dropWhile } p \, t). \text{any } (\lambda x, \, \neg p(x)) = \neg t. \text{all } p\).
- Since \( p(h) \) is true, \((h :: t). \text{all } p\) is equivalent to \( t. \text{all } p \). Therefore, the goal simplifies to \(\neg t. \text{all } p = \neg t. \text{all } p\), which is trivially true.

2. **Case 2: \( p(h) \) is false.**
- In this case, the list \( \text{List.dropWhile } p \, (h :: t) \) is equal to \( h :: \text{List.dropWhile } p \, t \). We need to show that \((h :: \text{List.dropWhile } p \, t). \text{any } (\lambda x, \, \neg p(x)) = \neg (h :: t). \text{all } p\).
- Since \( p(h) \) is false, \( h \) satisfies \(\neg p(h)\). Therefore, \((h :: \text{List.dropWhile } p \, t). \text{any } (\lambda x, \, \neg p(x))\) is true.
- On the other hand, \((h :: t). \text{all } p\) is false because \( p(h) \) is false. Therefore, \(\neg (h :: t). \text{all } p\) is true.
- Hence, the goal \((h :: \text{List.dropWhile } p \, t). \text{any } (\lambda x, \, \neg p(x)) = \neg (h :: t). \text{all } p\) is true. -/
  | cons h t ih => by_cases p h <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34515,List.pairwise_iff_forall_sublist,"theorem List.pairwise_iff_forall_sublist : l.Pairwise R ↔ (∀ {a b}, [a,b] <+ l → R a b) := by sorry","Pairwise Relation on a List is Equivalent to Sublist Condition: \( \text{Pairwise } R \, l \leftrightarrow \forall a, b \in l, [a, b] \text{ is a sublist of } l \rightarrow R a b \) : For any type \( \alpha \) and any list \( l \) of elements of type \( \alpha \), the predicate `Pairwise R l` holds if and only if for all elements \( a \) and \( b \) in \( l \), where \( [a, b] \) is a sublist of \( l \), the relation \( R a b \) holds. In other words, `Pairwise R l` is true if and only if for every pair of elements \( a \) and \( b \) in \( l \) such that \( a \) appears before \( b \), the relation \( R a b \) is satisfied.","theorem List.pairwise_iff_forall_sublist : l.Pairwise R ↔ (∀ {a b}, [a,b] <+ l → R a b) := by
  induction l with
  | nil => simp
  | cons hd tl IH =>
    rw [List.pairwise_cons]
    constructor <;> intro h
    · intro
      | a, b, .cons _ hab => exact IH.mp h.2 hab
      | _, b, .cons₂ _ hab => refine h.1 _ (hab.subset ?_); simp
    · constructor
      · intro x hx
        apply h
        rw [List.cons_sublist_cons, List.singleton_sublist]
        exact hx
      · apply IH.mpr
        intro a b hab
        apply h; exact hab.cons _","We start by noting that the assumption that the cardinality of $n$ is zero is equivalent to, and thus can be converted to $n$ being empty. We need to prove that the determinant of $M$ is $1$. First, we try to show that $M = 1$ (the identity matrix). To show this, we prove that for every $i \in n$, $M i = 1 i$. However, since $n$ is empty, $M i = 1 i$ holds for every $i \in n$ vacuously. Hence, $M = 1$. Therefore, the determinant of $M$ is $\det M = \det 1 = 1$. This completes the proof.

---

### Line by Line Informal Proof

#### Informal Step 1

**Formal proof line:**
apply h; exact hab.cons _

**Informal translation:**
To prove the current goal $R a b$, using the hypothesis $h$, it suffices to show that $[a, b]$ is a sublist of $hd :: tl$. Since $[a, b]$ is a sublist of $tl$ (by $hab$), and $hd :: tl$ is a cons list, we can conclude that $[a, b]$ is a sublist of $hd :: tl$.

#### Informal Step 2

**Formal proof line:**
| nil => simp

**Informal translation:**
For the base case where the list is empty, we simplify the goal. Since the empty list has no elements, the pairwise relation holds trivially. Therefore, the goal is satisfied.

#### Informal Step 3

**Formal proof line:**
| cons hd tl IH =>

**Informal translation:**
For the inductive step, assume the list is of the form $hd :: tl$. We need to show that the pairwise relation holds for the list $hd :: tl$.

#### Informal Step 4

**Formal proof line:**
rw [List.pairwise_cons]

**Informal translation:**
Using the definition of the pairwise relation on a cons list, we rewrite the goal. The pairwise relation on $hd :: tl$ holds if and only if for all elements $a'$ in $tl$, $R hd a'$ holds, and the pairwise relation holds for $tl$.

#### Informal Step 5

**Formal proof line:**
constructor <;> intro h

**Informal translation:**
To prove the current goal, it suffices to show two things: (1) for all elements $a'$ in $tl$, $R hd a'$ holds, and (2) the pairwise relation holds for $tl$. We introduce a hypothesis $h$ for the first part and another hypothesis for the second part.

#### Informal Step 6

**Formal proof line:**
· intro

**Informal translation:**
Let's concentrate on the proof of the first part. We need to show that for all elements $a'$ in $tl$, $R hd a'$ holds.

#### Informal Step 7

**Formal proof line:**
| a, b, .cons _ hab => exact IH.mp h.2 hab

**Informal translation:**
For the first part, consider elements $a$ and $b$ in the list. Since $[a, b]$ is a sublist of $tl$ (by $hab$), and the inductive hypothesis $IH$ states that the pairwise relation holds for $tl$, we can conclude that $R a b$ holds.

#### Informal Step 8

**Formal proof line:**
| _, b, .cons₂ _ hab => refine h.1 _ (hab.subset ?_); simp

**Informal translation:**
For the second part, consider elements $a$ and $b$ in the list. Since $[a, b]$ is a sublist of $tl$ (by $hab$), and the hypothesis $h$ states that for all elements $a'$ in $tl$, $R hd a'$ holds, we can conclude that $R hd b$ holds. We simplify the goal to show that $b$ is in $tl$.

#### Informal Step 9

**Formal proof line:**
· constructor

**Informal translation:**
To prove the current goal, it suffices to show two things: (1) for all elements $a'$ in $tl$, $R hd a'$ holds, and (2) the pairwise relation holds for $tl$. We introduce a hypothesis for each part.

#### Informal Step 10

**Formal proof line:**
· intro x hx

**Informal translation:**
Let $x$ be an arbitrary element in $tl$ (by $hx$), we need to show that $R hd x$ holds.

#### Informal Step 11

**Formal proof line:**
apply h

**Informal translation:**
To prove $R hd x$, using the hypothesis $h$, it suffices to show that $[hd, x]$ is a sublist of $hd :: tl$.

#### Informal Step 12

**Formal proof line:**
rw [List.cons_sublist_cons, List.singleton_sublist]

**Informal translation:**
Using the properties of sublists, we rewrite the goal. The list $[hd, x]$ is a sublist of $hd :: tl$ if and only if $[x]$ is a sublist of $tl$. Since $[x]$ is a sublist of $tl$ if and only if $x$ is in $tl$, we need to show that $x$ is in $tl$.

#### Informal Step 13

**Formal proof line:**
exact hx

**Informal translation:**
The current goal $x \in tl$ is exactly proved by the hypothesis $hx$.

#### Informal Step 14

**Formal proof line:**
· apply IH.mpr

**Informal translation:**
To prove the pairwise relation holds for $tl$, using the inductive hypothesis $IH$, it suffices to show that for all elements $a$ and $b$ in $tl$, $R a b$ holds.

#### Informal Step 15

**Formal proof line:**
intro a b hab

**Informal translation:**
Let $a$ and $b$ be arbitrary elements in $tl$ (by $hab$), we need to show that $R a b$ holds.

#### Informal Step 16

**Formal proof line:**
apply h; exact hab.cons _

**Informal translation:**
To prove $R a b$, using the hypothesis $h$, it suffices to show that $[a, b]$ is a sublist of $hd :: tl$. Since $[a, b]$ is a sublist of $tl$ (by $hab$), and $hd :: tl$ is a cons list, we can conclude that $[a, b]$ is a sublist of $hd :: tl$.

### Whole Informal Proof

**Theorem:**
For any type $\alpha$ and any list $l$ of elements of type $\alpha$, the predicate `Pairwise R l` holds if and only if for all elements $a$ and $b$ in $l$, where $[a, b]$ is a sublist of $l$, the relation $R a b$ holds.

**Proof:**
We prove the theorem by induction on the list $l$.

**Base Case:**
For the base case where the list is empty, we need to show that the pairwise relation holds. Since the empty list has no elements, the pairwise relation holds trivially. Therefore, the goal is satisfied.

**Inductive Step:**
For the inductive step, assume the list is of the form $hd :: tl$. We need to show that the pairwise relation holds for the list $hd :: tl$.

Using the definition of the pairwise relation on a cons list, we rewrite the goal. The pairwise relation on $hd :: tl$ holds if and only if for all elements $a'$ in $tl$, $R hd a'$ holds, and the pairwise relation holds for $tl$.

To prove the first part, we need to show that for all elements $a'$ in $tl$, $R hd a'$ holds. Let $x$ be an arbitrary element in $tl$ (by $hx$). We need to show that $R hd x$ holds. Using the hypothesis $h$, it suffices to show that $[hd, x]$ is a sublist of $hd :: tl$. Since $[hd, x]$ is a sublist of $hd :: tl$ if and only if $[x]$ is a sublist of $tl$, and $[x]$ is a sublist of $tl$ if and only if $x$ is in $tl$, we conclude that $R hd x$ holds.

To prove the second part, we need to show that the pairwise relation holds for $tl$. Using the inductive hypothesis $IH$, it suffices to show that for all elements $a$ and $b$ in $tl$, $R a b$ holds. Let $a$ and $b$ be arbitrary elements in $tl$ (by $hab$). We need to show that $R a b$ holds. Using the hypothesis $h$, it suffices to show that $[a, b]$ is a sublist of $hd :: tl$. Since $[a, b]$ is a sublist of $tl$ (by $hab$), and $hd :: tl$ is a cons list, we conclude that $[a, b]$ is a sublist of $hd :: tl$.

Therefore, the pairwise relation holds for $hd :: tl$. This completes the proof.","theorem List.pairwise_iff_forall_sublist : l.Pairwise R ↔ (∀ {a b}, [a,b] <+ l → R a b) := by
/- First, we use the equivalence that the cardinality of a finite type is $0$ if and only if this type is empty, to convert the assumption of cardinality of $n = 0$ into $n$ is empty. -/
/- It suffices to show that $M = 1$, because if this is true, by using this $M = 1$ and simplifying, we get the determinant of $M$ is $1$ automatically. -/
/- Using extensionality, to prove that $M = 1$, we only need to show that $M i = 1 i$ for every $i \in n$. -/
/- Since $n$ is empty, this $M i = 1 i$ holds for every $i \in n$ vacuously. This finishes the proof. -/
  induction l with
  | nil => simp
  | cons hd tl IH =>
    rw [List.pairwise_cons]
    constructor <;> intro h
    · intro
      | a, b, .cons _ hab => exact IH.mp h.2 hab
      | _, b, .cons₂ _ hab => refine h.1 _ (hab.subset ?_); simp
    · constructor
      · intro x hx
        apply h
        rw [List.cons_sublist_cons, List.singleton_sublist]
        exact hx
      · apply IH.mpr
        intro a b hab
        apply h; exact hab.cons _","import Init.Data.List.Sublist
import Init.Data.List.Pairwise

open List
open Nat
"
34517,List.set_take,"theorem List.set_take {l : List α} {n m : Nat} {a : α} :
    (l.set m a).take n = (l.take n).set m a := by sorry","Take of Updated List Equals Update of Taken List: \(\text{List.take } n \, (l.\text{set } m \, a) = (\text{List.take } n \, l).\text{set } m \, a\) : For any list \( l \) of elements of type \( \alpha \), any natural numbers \( n \) and \( m \), and any element \( a \) of type \( \alpha \), the first \( n \) elements of the list \( l \) with the element at index \( m \) updated to \( a \) is equal to the list of the first \( n \) elements of \( l \) with the element at index \( m \) updated to \( a \). Formally, for a list \( l \) and natural numbers \( n \) and \( m \), we have:
\[
\text{List.take } n \, (l.\text{set } m \, a) = (\text{List.take } n \, l).\text{set } m \, a
\]","theorem List.set_take {l : List α} {n m : Nat} {a : α} :
    (l.set m a).take n = (l.take n).set m a := by
  induction n generalizing l m with
  | zero => simp
  | succ _ hn =>
    cases l with
    | nil => simp
    | cons hd tl => cases m <;> simp_all","We prove this by induction on \( n \).

**Base Case: \( n = 0 \)**
- For any list \( l \) and any index \( m \), the first 0 elements of \( l \) with the element at index \( m \) updated to \( a \) is the empty list. Therefore, we have:
\[
\text{List.take } 0 \, (l.\text{set } m \, a) = \text{nil}
\]
- Similarly, the first 0 elements of \( l \) is the empty list, and updating the empty list at any index \( m \) with \( a \) still results in the empty list. Therefore, we have:
\[
(\text{List.take } 0 \, l).\text{set } m \, a = \text{nil}
\]
- Hence, the base case holds:
\[
\text{List.take } 0 \, (l.\text{set } m \, a) = (\text{List.take } 0 \, l).\text{set } m \, a
\]

**Inductive Step:**
- Assume the property holds for \( n = k \), i.e., for any list \( l \) and any index \( m \):
\[
\text{List.take } k \, (l.\text{set } m \, a) = (\text{List.take } k \, l).\text{set } m \, a
\]
- We need to show that the property holds for \( n = k + 1 \).

**Case 1: \( l \) is empty**
- If \( l \) is the empty list, then taking the first \( k + 1 \) elements of the empty list results in the empty list. Therefore, we have:
\[
\text{List.take } (k + 1) \, ([].\text{set } m \, a) = \text{nil}
\]
- Similarly, the first \( k + 1 \) elements of the empty list is the empty list, and updating the empty list at any index \( m \) with \( a \) still results in the empty list. Therefore, we have:
\[
(\text{List.take } (k + 1) \, []).\text{set } m \, a = \text{nil}
\]
- Hence, the property holds for the empty list:
\[
\text{List.take } (k + 1) \, ([].\text{set } m \, a) = (\text{List.take } (k + 1) \, []).\text{set } m \, a
\]

**Case 2: \( l \) is non-empty, i.e., \( l = \text{hd} :: \text{tl} \)**
- We perform case analysis on the index \( m \).

**Subcase 2.1: \( m = 0 \)**
- If \( m = 0 \), then updating the first element of \( l \) to \( a \) results in the list \( a :: \text{tl} \). Therefore, we have:
\[
\text{List.take } (k + 1) \, ((\text{hd} :: \text{tl}).\text{set } 0 \, a) = \text{List.take } (k + 1) \, (a :: \text{tl})
\]
- The first \( k + 1 \) elements of \( a :: \text{tl} \) is \( a :: \text{List.take } k \, \text{tl} \). Therefore, we have:
\[
\text{List.take } (k + 1) \, (a :: \text{tl}) = a :: \text{List.take } k \, \text{tl}
\]
- On the other hand, the first \( k + 1 \) elements of \( \text{hd} :: \text{tl} \) is \( \text{hd} :: \text{List.take } k \, \text{tl} \), and updating the first element of this list to \( a \) results in \( a :: \text{List.take } k \, \text{tl} \). Therefore, we have:
\[
(\text{List.take } (k + 1) \, (\text{hd} :: \text{tl})).\text{set } 0 \, a = a :: \text{List.take } k \, \text{tl}
\]
- Hence, the property holds for \( m = 0 \):
\[
\text{List.take } (k + 1) \, ((\text{hd} :: \text{tl}).\text{set } 0 \, a) = (\text{List.take } (k + 1) \, (\text{hd} :: \text{tl})).\text{set } 0 \, a
\]

**Subcase 2.2: \( m > 0 \)**
- If \( m > 0 \), then updating the element at index \( m \) in \( \text{hd} :: \text{tl} \) results in the list \( \text{hd} :: (\text{tl}.\text{set } (m - 1) \, a) \). Therefore, we have:
\[
\text{List.take } (k + 1) \, ((\text{hd} :: \text{tl}).\text{set } m \, a) = \text{List.take } (k + 1) \, (\text{hd} :: (\text{tl}.\text{set } (m - 1) \, a))
\]
- The first \( k + 1 \) elements of \( \text{hd} :: (\text{tl}.\text{set } (m - 1) \, a) \) is \( \text{hd} :: \text{List.take } k \, (\text{tl}.\text{set } (m - 1) \, a) \). Therefore, we have:
\[
\text{List.take } (k + 1) \, (\text{hd} :: (\text{tl}.\text{set } (m - 1) \, a)) = \text{hd} :: \text{List.take } k \, (\text{tl}.\text{set } (m - 1) \, a)
\]
- On the other hand, the first \( k + 1 \) elements of \( \text{hd} :: \text{tl} \) is \( \text{hd} :: \text{List.take } k \, \text{tl} \), and updating the element at index \( m \) in this list to \( a \) results in \( \text{hd} :: (\text{List.take } k \, \text{tl}).\text{set } (m - 1) \, a \). Therefore, we have:
\[
(\text{List.take } (k + 1) \, (\text{hd} :: \text{tl})).\text{set } m \, a = \text{hd} :: (\text{List.take } k \, \text{tl}).\text{set } (m - 1) \, a
\]
- By the induction hypothesis, we have:
\[
\text{List.take } k \, (\text{tl}.\text{set } (m - 1) \, a) = (\text{List.take } k \, \text{tl}).\text{set } (m - 1) \, a
\]
- Therefore, we have:
\[
\text{hd} :: \text{List.take } k \, (\text{tl}.\text{set } (m - 1) \, a) = \text{hd} :: (\text{List.take } k \, \text{tl}).\text{set } (m - 1) \, a
\]
- Hence, the property holds for \( m > 0 \):
\[
\text{List.take } (k + 1) \, ((\text{hd} :: \text{tl}).\text{set } m \, a) = (\text{List.take } (k + 1) \, (\text{hd} :: \text{tl})).\text{set } m \, a
\]

By induction, the property holds for all natural numbers \( n \). Therefore, the theorem is proved. \(\blacksquare\)","theorem List.set_take {l : List α} {n m : Nat} {a : α} :
    (l.set m a).take n = (l.take n).set m a := by
  induction n generalizing l m with
/- In the case where \( n = 0 \), we simplify the goal using the definition of `List.take`. Since taking the first 0 elements of any list results in the empty list, the goal simplifies to:
\[
\text{List.take } 0 \, (l.\text{set } m \, a) = (\text{List.take } 0 \, l).\text{set } m \, a
\]
which is trivially true because both sides are the empty list. -/
  | zero => simp
/- In the case where \( n = k + 1 \) for some natural number \( k \), we use the induction hypothesis \( \text{hn} \), which states that the property holds for \( k \). We need to show that the property holds for \( k + 1 \). -/
  | succ _ hn =>
    cases l with
/- In the case where the list \( l \) is empty, we simplify the goal using the definition of `List.take`. Since taking the first \( k + 1 \) elements of the empty list results in the empty list, the goal simplifies to:
\[
\text{List.take } (k + 1) \, ([].\text{set } m \, a) = (\text{List.take } (k + 1) \, []).\text{set } m \, a
\]
which is trivially true because both sides are the empty list. -/
    | nil => simp
/- We consider the case where the list \( l \) is non-empty, i.e., \( l = \text{hd} :: \text{tl} \). We then perform case analysis on the index \( m \). For each case, we simplify the goal using the definitions and properties of the `List.take` and `List.set` functions. -/
/- In the case where the list \( l \) is non-empty, i.e., \( l = \text{hd} :: \text{tl} \), we perform case analysis on the index \( m \). For each case, we simplify the goal using the definitions and properties of the `List.take` and `List.set` functions. -/
    | cons hd tl => cases m <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34520,List.take_takeWhile,"theorem List.take_takeWhile {l : List α} (p : α → Bool) n :
    (l.takeWhile p).take n = (l.take n).takeWhile p := by sorry","Equality of Take and TakeWhile Operations: \(\text{take } n \, (\text{takeWhile } p \, l) = \text{takeWhile } p \, (\text{take } n \, l)\) : For any list \( l \) of elements of type \( \alpha \), a predicate \( p : \alpha \to \text{Bool} \), and a natural number \( n \), the first \( n \) elements of the longest initial segment of \( l \) that satisfies \( p \) are equal to the longest initial segment of the first \( n \) elements of \( l \) that satisfies \( p \). In other words, \(\text{take } n \, (\text{takeWhile } p \, l) = \text{takeWhile } p \, (\text{take } n \, l)\).","theorem List.take_takeWhile {l : List α} (p : α → Bool) n :
    (l.takeWhile p).take n = (l.take n).takeWhile p := by
  induction l generalizing n with
  | nil => simp
  | cons x xs ih =>
    by_cases h : p x <;> cases n <;> simp [takeWhile_cons, h, ih, take_succ_cons]","We proceed by induction on the list \( l \).

1. **Base Case:**
- If \( l \) is the empty list, the goal simplifies to:
\[
\text{take } n \, (\text{takeWhile } p \, []) = \text{takeWhile } p \, (\text{take } n \, [])
\]
By the definition of `take` and `takeWhile`, both sides are the empty list \( [] \), so the equality holds.

2. **Inductive Step:**
- Assume \( l \) is a non-empty list and can be written as \( x :: xs \). We proceed by induction on \( xs \) with the induction hypothesis \( \text{ih} \) stating that for any natural number \( n \), \( \text{take } n \, (\text{takeWhile } p \, xs) = \text{takeWhile } p \, (\text{take } n \, xs) \).

- We consider two cases based on whether the predicate \( p \) holds for the first element \( x \) of the list \( l \).

- **Case 1: \( p(x) = \text{true} \)**
- We further consider the cases where \( n \) is \( 0 \) or a successor of some natural number \( n' \).

- **Subcase 1.1: \( n = 0 \)**
- The goal simplifies to:
\[
\text{take } 0 \, (\text{takeWhile } p \, (x :: xs)) = \text{takeWhile } p \, (\text{take } 0 \, (x :: xs))
\]
By the definition of `take`, both sides are the empty list \( [] \), so the equality holds.

- **Subcase 1.2: \( n = n' + 1 \)**
- The goal simplifies to:
\[
\text{take } (n' + 1) \, (\text{takeWhile } p \, (x :: xs)) = \text{takeWhile } p \, (\text{take } (n' + 1) \, (x :: xs))
\]
Using the definitions of `takeWhile` and `take`, and the induction hypothesis \( \text{ih} \), we can simplify this to:
\[
x :: \text{take } n' \, (\text{takeWhile } p \, xs) = x :: \text{takeWhile } p \, (\text{take } n' \, xs)
\]
By the induction hypothesis, \( \text{take } n' \, (\text{takeWhile } p \, xs) = \text{takeWhile } p \, (\text{take } n' \, xs) \), so the equality holds.

- **Case 2: \( p(x) = \text{false} \)**
- We further consider the cases where \( n \) is \( 0 \) or a successor of some natural number \( n' \).

- **Subcase 2.1: \( n = 0 \)**
- The goal simplifies to:
\[
\text{take } 0 \, (\text{takeWhile } p \, (x :: xs)) = \text{takeWhile } p \, (\text{take } 0 \, (x :: xs))
\]
By the definition of `take`, both sides are the empty list \( [] \), so the equality holds.

- **Subcase 2.2: \( n = n' + 1 \)**
- The goal simplifies to:
\[
\text{take } (n' + 1) \, (\text{takeWhile } p \, (x :: xs)) = \text{takeWhile } p \, (\text{take } (n' + 1) \, (x :: xs))
\]
Using the definitions of `takeWhile` and `take`, and the induction hypothesis \( \text{ih} \), we can simplify this to:
\[
\text{take } n' \, (\text{takeWhile } p \, xs) = \text{takeWhile } p \, (\text{take } n' \, xs)
\]
By the induction hypothesis, \( \text{take } n' \, (\text{takeWhile } p \, xs) = \text{takeWhile } p \, (\text{take } n' \, xs) \), so the equality holds.

Thus, by induction, the theorem holds for all lists \( l \) and natural numbers \( n \). This completes the proof.","theorem List.take_takeWhile {l : List α} (p : α → Bool) n :
    (l.takeWhile p).take n = (l.take n).takeWhile p := by
  induction l generalizing n with
/- If the list \( l \) is empty, the goal simplifies to the trivial equality \( \text{take } n \, (\text{takeWhile } p \, []) = \text{takeWhile } p \, (\text{take } n \, []) \), which holds by the definition of `take` and `takeWhile`. -/
  | nil => simp
/- If the list \( l \) is non-empty and can be written as \( x :: xs \), we proceed by induction on the list \( xs \). The induction hypothesis \( \text{ih} \) states that for any natural number \( n \), \( \text{take } n \, (\text{takeWhile } p \, xs) = \text{takeWhile } p \, (\text{take } n \, xs) \). -/
  | cons x xs ih =>
/- We consider two cases based on whether the predicate \( p \) holds for the first element \( x \) of the list \( l \). For each case, we further consider the cases where \( n \) is \( 0 \) or a successor of some natural number \( n' \). In each subcase, we simplify the goal using the definitions and properties of `takeWhile` and `take`. -/
/- We consider two cases based on whether the predicate \( p \) holds for the first element \( x \) of the list \( l \). For each case, we further consider the cases where \( n \) is \( 0 \) or a successor of some natural number \( n' \). In each subcase, we simplify the goal using the definitions and properties of `takeWhile` and `take`. -/
/- If \( n = 0 \), the goal simplifies to \( \text{take } 0 \, (\text{takeWhile } p \, (x :: xs)) = \text{takeWhile } p \, (\text{take } 0 \, (x :: xs)) \). Using the definitions of `takeWhile` and `take`, this simplifies to the trivial equality \( [] = [] \). -/
/- If \( n = n' + 1 \), the goal simplifies to \( \text{take } (n' + 1) \, (\text{takeWhile } p \, (x :: xs)) = \text{takeWhile } p \, (\text{take } (n' + 1) \, (x :: xs)) \). Using the definitions of `takeWhile` and `take`, and the induction hypothesis \( \text{ih} \), we can simplify this to the desired equality. -/
/- If \( n = 0 \), the goal simplifies to \( \text{take } 0 \, (\text{takeWhile } p \, (x :: xs)) = \text{takeWhile } p \, (\text{take } 0 \, (x :: xs)) \). Using the definitions of `takeWhile` and `take`, this simplifies to the trivial equality \( [] = [] \). -/
/- If \( n = n' + 1 \), the goal simplifies to \( \text{take } (n' + 1) \, (\text{takeWhile } p \, (x :: xs)) = \text{takeWhile } p \, (\text{take } (n' + 1) \, (x :: xs)) \). Using the definitions of `takeWhile` and `take`, and the induction hypothesis \( \text{ih} \), we can simplify this to the desired equality. -/
    by_cases h : p x <;> cases n <;> simp [takeWhile_cons, h, ih, take_succ_cons]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34523,List.takeWhile_filterMap,"theorem List.takeWhile_filterMap (f : α → Option β) (p : β → Bool) (l : List α) :
    (l.filterMap f).takeWhile p = (l.takeWhile fun a => (f a).all p).filterMap f := by sorry","Take-While and Filter-Map Commute: \(\text{takeWhile } p \, (\text{filterMap } f \, l) = \text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, l)\) : For any types \( \alpha \) and \( \beta \), a function \( f : \alpha \to \text{Option} \beta \), a predicate \( p : \beta \to \text{Bool} \), and a list \( l \) of elements of type \( \alpha \), the following equality holds:
\[
\text{takeWhile } p \, (\text{filterMap } f \, l) = \text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, l)
\]
This theorem states that the longest initial segment of the list \( l \) for which the predicate \( p \) holds after applying \( f \) and filtering out `none` values is the same as the list obtained by first taking the longest initial segment of \( l \) for which the predicate \( p \) holds for the result of \( f \) (if it is `some`), and then applying \( f \) and filtering out `none` values.","theorem List.takeWhile_filterMap (f : α → Option β) (p : β → Bool) (l : List α) :
    (l.filterMap f).takeWhile p = (l.takeWhile fun a => (f a).all p).filterMap f := by
  induction l with
  | nil => rfl
  | cons x xs ih =>
    simp only [filterMap_cons]
    split <;> rename_i h
    · simp only [takeWhile_cons, h]
      split <;> simp_all
    · simp [takeWhile_cons, h, ih]
      split <;> simp_all [filterMap_cons]","We proceed by induction on the list \( l \).

1. **Base Case:**
- If \( l \) is the empty list, the goal is trivially true by the reflexive property of equality:
\[
\text{takeWhile } p \, (\text{filterMap } f \, []) = \text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, [])
\]
Both sides are the empty list, so the equality holds.

2. **Inductive Step:**
- Assume the list \( l \) is \( x :: xs \), where \( x \) is the head and \( xs \) is the tail. We use the induction hypothesis \( \text{ih} \) which states:
\[
\text{takeWhile } p \, (\text{filterMap } f \, xs) = \text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs)
\]
- We need to show:
\[
\text{takeWhile } p \, (\text{filterMap } f \, (x :: xs)) = \text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, (x :: xs))
\]
- We consider two cases based on the result of \( f(x) \):
- **Case 1: \( f(x) = \text{none} \)**
- Using the definition of `filterMap_cons`, we have:
\[
\text{filterMap } f \, (x :: xs) = \text{filterMap } f \, xs
\]
- Using the definition of `takeWhile_cons`, we have:
\[
\text{takeWhile } p \, (\text{filterMap } f \, (x :: xs)) = \text{takeWhile } p \, (\text{filterMap } f \, xs)
\]
- By the induction hypothesis, this is:
\[
\text{takeWhile } p \, (\text{filterMap } f \, xs) = \text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs)
\]
- Therefore, we need to show:
\[
\text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, (x :: xs)) = \text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs)
\]
- Since \( f(x) = \text{none} \), \( \text{Option.all } p \, (f \, x) = \text{false} \), so:
\[
\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, (x :: xs) = \text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs
\]
- Thus, the equality holds.
- **Case 2: \( f(x) = \text{some } b \)**
- Using the definition of `filterMap_cons`, we have:
\[
\text{filterMap } f \, (x :: xs) = b :: \text{filterMap } f \, xs
\]
- Using the definition of `takeWhile_cons`, we have:
\[
\text{takeWhile } p \, (\text{filterMap } f \, (x :: xs)) = \text{takeWhile } p \, (b :: \text{filterMap } f \, xs)
\]
- This is:
\[
\text{if } p(b) = \text{true} \text{ then } b :: \text{takeWhile } p \, (\text{filterMap } f \, xs) \text{ else } []
\]
- By the induction hypothesis, this is:
\[
\text{if } p(b) = \text{true} \text{ then } b :: \text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs) \text{ else } []
\]
- Therefore, we need to show:
\[
\text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, (x :: xs)) = \text{if } p(b) = \text{true} \text{ then } b :: \text{filterMap } f \, (\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs) \text{ else } []
\]
- Since \( f(x) = \text{some } b \), \( \text{Option.all } p \, (f \, x) = p(b) \), so:
\[
\text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, (x :: xs) = \text{if } p(b) = \text{true} \text{ then } x :: \text{takeWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs \text{ else } []
\]
- Thus, the equality holds.

This completes the proof.","theorem List.takeWhile_filterMap (f : α → Option β) (p : β → Bool) (l : List α) :
    (l.filterMap f).takeWhile p = (l.takeWhile fun a => (f a).all p).filterMap f := by
  induction l with
/- If the list \( l \) is empty, the goal is trivially true by the reflexive property of equality. -/
  | nil => rfl
/- If the list \( l \) is not empty, we consider the list as \( x :: xs \), where \( x \) is the head and \( xs \) is the tail. We use the induction hypothesis \( \text{ih} \) to proceed with the proof. -/
  | cons x xs ih =>
/- We simplify the goal using the definition of `filterMap_cons`, which states that `filterMap f (x :: xs)` is `match f x with | none => filterMap f xs | some b => b :: filterMap f xs`. -/
    simp only [filterMap_cons]
/- We consider two cases based on the result of \( f(x) \). If \( f(x) = \text{none} \), we rename the hypothesis to \( h \). If \( f(x) = \text{some } b \), we also rename the hypothesis to \( h \). -/
    split <;> rename_i h
/- We simplify the goal using the definition of `takeWhile_cons` and the hypothesis \( h \). The definition of `takeWhile_cons` states that `takeWhile p (a :: l)` is `if p a = \text{true} then a :: takeWhile p l else []`. -/
    · simp only [takeWhile_cons, h]
/- We consider two cases based on the result of \( \text{Option.all } p \, \text{none} \). If \( \text{Option.all } p \, \text{none} = \text{true} \), we simplify the goal. If \( \text{Option.all } p \, \text{none} = \text{false} \), we also simplify the goal. -/
      split <;> simp_all
/- We simplify the goal using the definition of `takeWhile_cons`, the hypothesis \( h \), and the induction hypothesis \( \text{ih} \). -/
    · simp [takeWhile_cons, h, ih]
/- We consider two cases based on whether the list \( l \) is empty or not. If \( l \) is empty, the goal is trivially true. If \( l \) is not empty, we simplify the goal using the definition of `filterMap_cons`. -/
/- We consider two cases based on the result of \( p(b) \). If \( p(b) = \text{true} \), we simplify the goal using the definition of `filterMap_cons`. If \( p(b) = \text{false} \), we also simplify the goal using the definition of `filterMap_cons`. -/
      split <;> simp_all [filterMap_cons]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34525,List.dropWhile_filterMap,"theorem List.dropWhile_filterMap (f : α → Option β) (p : β → Bool) (l : List α) :
    (l.filterMap f).dropWhile p = (l.dropWhile fun a => (f a).all p).filterMap f := by sorry","Drop While Preserves Filter Map in Lists : For any types \( \alpha \) and \( \beta \), a function \( f : \alpha \to \text{Option} \beta \), a predicate \( p : \beta \to \text{Bool} \), and a list \( l \) of elements of type \( \alpha \), the following equality holds:
\[
\text{dropWhile } p \, (\text{filterMap } f \, l) = \text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, l)
\]
This theorem states that applying `dropWhile` to a predicate \( p \) on the result of `filterMap` applied to \( f \) and \( l \) is equivalent to applying `filterMap` to \( f \) on the result of `dropWhile` applied to a modified predicate that checks if \( p \) holds for the optional value returned by \( f \).","theorem List.dropWhile_filterMap (f : α → Option β) (p : β → Bool) (l : List α) :
    (l.filterMap f).dropWhile p = (l.dropWhile fun a => (f a).all p).filterMap f := by
  induction l with
  | nil => rfl
  | cons x xs ih =>
    simp only [filterMap_cons]
    split <;> rename_i h
    · simp only [dropWhile_cons, h]
      split <;> simp_all
    · simp [dropWhile_cons, h, ih]
      split <;> simp_all [filterMap_cons]","We prove the theorem by induction on the list \( l \).

1. **Base Case:**
- If \( l \) is the empty list, then both sides of the equation are the empty list. Therefore, the goal is trivially true.

2. **Inductive Step:**
- Assume \( l = x :: xs \) and the inductive hypothesis \( \text{dropWhile } p \, (\text{filterMap } f \, xs) = \text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs) \).
- We need to show:
\[
\text{dropWhile } p \, (\text{filterMap } f \, (x :: xs)) = \text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, (x :: xs))
\]
- We consider two cases based on the result of \( f \, x \):
- **Case 1: \( f \, x = \text{none} \)**
- The left-hand side becomes:
\[
\text{dropWhile } p \, (\text{filterMap } f \, xs)
\]
- The right-hand side becomes:
\[
\text{filterMap } f \, (\text{if } \text{Option.all } p \, \text{none} = \text{true} \, \text{then } \text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs \, \text{else } x :: xs)
\]
- We consider two sub-cases:
- **Sub-case 1.1: \( \text{Option.all } p \, \text{none} = \text{true} \)**
- The right-hand side simplifies to:
\[
\text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs)
\]
- By the inductive hypothesis, this is equal to:
\[
\text{dropWhile } p \, (\text{filterMap } f \, xs)
\]
- **Sub-case 1.2: \( \text{Option.all } p \, \text{none} = \text{false} \)**
- The right-hand side simplifies to:
\[
\text{filterMap } f \, (x :: xs)
\]
- By the definition of `filterMap`, this is equal to:
\[
\text{filterMap } f \, xs
\]
- By the inductive hypothesis, this is equal to:
\[
\text{dropWhile } p \, (\text{filterMap } f \, xs)
\]
- **Case 2: \( f \, x = \text{some } b \)**
- The left-hand side becomes:
\[
\text{dropWhile } p \, (b :: \text{filterMap } f \, xs)
\]
- The right-hand side becomes:
\[
\text{filterMap } f \, (\text{if } p \, b = \text{true} \, \text{then } \text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs \, \text{else } x :: xs)
\]
- We consider two sub-cases:
- **Sub-case 2.1: \( p \, b = \text{true} \)**
- The right-hand side simplifies to:
\[
\text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs)
\]
- By the inductive hypothesis, this is equal to:
\[
\text{dropWhile } p \, (\text{filterMap } f \, xs)
\]
- **Sub-case 2.2: \( p \, b = \text{false} \)**
- The right-hand side simplifies to:
\[
\text{filterMap } f \, (x :: xs)
\]
- By the definition of `filterMap`, this is equal to:
\[
b :: \text{filterMap } f \, xs
\]
- By the inductive hypothesis, this is equal to:
\[
\text{dropWhile } p \, (b :: \text{filterMap } f \, xs)
\]

Thus, the theorem holds for all lists \( l \). This completes the proof. \(\blacksquare\)","theorem List.dropWhile_filterMap (f : α → Option β) (p : β → Bool) (l : List α) :
    (l.filterMap f).dropWhile p = (l.dropWhile fun a => (f a).all p).filterMap f := by
  induction l with
/- If the list \( l \) is empty, the goal is trivially true because both sides of the equation are the empty list. -/
  | nil => rfl
/- If the list \( l \) is not empty, we assume \( l = x :: xs \) and use the inductive hypothesis \( \text{dropWhile } p \, (\text{filterMap } f \, xs) = \text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs) \). -/
  | cons x xs ih =>
/- We simplify the goal using the definition of `filterMap` for the list \( x :: xs \). This reduces the goal to:
\[
\text{dropWhile } p \, (\text{match } f \, x \, \text{with} \, \text{none} \, \Rightarrow \, \text{filterMap } f \, xs \, | \, \text{some } b \, \Rightarrow \, b :: \text{filterMap } f \, xs) = \text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, (x :: xs))
\] -/
    simp only [filterMap_cons]
/- We consider two cases based on the result of \( f \, x \):
1. \( f \, x = \text{none} \)
2. \( f \, x = \text{some } b \)
We rename the hypothesis \( f \, x = \text{none} \) to \( h \) in the first case and \( f \, x = \text{some } b \) to \( h \) in the second case. -/
    split <;> rename_i h
/- In the case where \( f \, x = \text{none} \), we simplify the goal using the definition of `dropWhile` and the hypothesis \( h \). This reduces the goal to:
\[
\text{dropWhile } p \, (\text{filterMap } f \, xs) = \text{filterMap } f \, (\text{if } \text{Option.all } p \, \text{none} = \text{true} \, \text{then } \text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs \, \text{else } x :: xs)
\] -/
    · simp only [dropWhile_cons, h]
/- We consider two sub-cases based on whether \( \text{Option.all } p \, \text{none} = \text{true} \):
1. If \( \text{Option.all } p \, \text{none} = \text{true} \), the goal simplifies to:
\[
\text{dropWhile } p \, (\text{filterMap } f \, xs) = \text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs)
\]
2. If \( \text{Option.all } p \, \text{none} = \text{false} \), the goal simplifies to:
\[
\text{dropWhile } p \, (\text{filterMap } f \, xs) = \text{filterMap } f \, (x :: xs)
\]
Both sub-cases are trivially true by the inductive hypothesis. -/
      split <;> simp_all
/- In the case where \( f \, x = \text{some } b \), we simplify the goal using the definition of `dropWhile` and the hypothesis \( h \). This reduces the goal to:
\[
\text{if } p \, b = \text{true} \, \text{then } \text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs) \, \text{else } b :: \text{filterMap } f \, xs = \text{filterMap } f \, (\text{if } p \, b = \text{true} \, \text{then } \text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs \, \text{else } x :: xs)
\] -/
    · simp [dropWhile_cons, h, ih]
/- We consider two cases based on whether the list \( l \) is empty or not. If \( l \) is empty, we simplify the goal using the definition of `filterMap` and `dropWhile` for the empty list. If \( l \) is not empty, we proceed with the inductive step. -/
/- We consider two sub-cases based on whether \( p \, b = \text{true} \):
1. If \( p \, b = \text{true} \), the goal simplifies to:
\[
\text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs) = \text{filterMap } f \, (\text{dropWhile } (\lambda a, \, \text{Option.all } p \, (f \, a)) \, xs)
\]
2. If \( p \, b = \text{false} \), the goal simplifies to:
\[
b :: \text{filterMap } f \, xs = \text{filterMap } f \, (x :: xs)
\]
Both sub-cases are trivially true by the inductive hypothesis. -/
      split <;> simp_all [filterMap_cons]","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34530,List.drop_set,"theorem List.drop_set {l : List α} {n m : Nat} {a : α} :
    (l.set m a).drop n = if m < n then l.drop n else (l.drop n).set (m - n) a := by sorry","Drop and Update: \(\text{List.drop } n \, (l.\text{set } m \, a) = \text{if } m < n \text{ then } \text{List.drop } n \, l \text{ else } (\text{List.drop } n \, l).\text{set } (m - n) \, a\) : For any list \( l \) of elements of type \( \alpha \), and for any natural numbers \( n \) and \( m \), and for any element \( a \) of type \( \alpha \), the list obtained by dropping the first \( n \) elements of \( l \) and then updating the \( m \)-th element to \( a \) is equal to the list obtained by first updating the \( m \)-th element of \( l \) to \( a \) and then dropping the first \( n \) elements of the resulting list. Formally, this can be written as:
\[
\text{List.drop } n \, (l.\text{set } m \, a) = 
\begin{cases} 
\text{List.drop } n \, l & \text{if } m < n \\
(\text{List.drop } n \, l).\text{set } (m - n) \, a & \text{if } m \geq n 
\end{cases}
\]","theorem List.drop_set {l : List α} {n m : Nat} {a : α} :
    (l.set m a).drop n = if m < n then l.drop n else (l.drop n).set (m - n) a := by
  induction n generalizing l m with
  | zero => simp
  | succ _ hn =>
    cases l with
    | nil => simp
    | cons hd tl =>
      cases m
      · simp_all
      · simp only [hn, set_cons_succ, drop_succ_cons, succ_lt_succ_iff]
        congr 2
        exact (Nat.add_sub_add_right ..).symm","We proceed by induction on \( n \).

**Base Case: \( n = 0 \)**
We need to show that \( \text{List.drop } 0 \, (l.\text{set } m \, a) = \text{if } m < 0 \text{ then } \text{List.drop } 0 \, l \text{ else } (\text{List.drop } 0 \, l).\text{set } (m - 0) \, a \). Since \( m < 0 \) is false, the if-then-else expression simplifies to \( \text{List.drop } 0 \, l \), which is trivially true.

**Inductive Step: \( n = n' + 1 \)**
We assume the inductive hypothesis:
\[
\text{List.drop } n' \, (l.\text{set } m \, a) = \text{if } m < n' \text{ then } \text{List.drop } n' \, l \text{ else } (\text{List.drop } n' \, l).\text{set } (m - n') \, a
\]
We need to show that:
\[
\text{List.drop } (n' + 1) \, (l.\text{set } m \, a) = \text{if } m < n' + 1 \text{ then } \text{List.drop } (n' + 1) \, l \text{ else } (\text{List.drop } (n' + 1) \, l).\text{set } (m - (n' + 1)) \, a
\]

**Case 1: \( l = [] \)**
We need to show that:
\[
\text{List.drop } (n' + 1) \, ([].\text{set } m \, a) = \text{if } m < n' + 1 \text{ then } \text{List.drop } (n' + 1) \, [] \text{ else } (\text{List.drop } (n' + 1) \, []).\text{set } (m - (n' + 1)) \, a
\]
Since the list is empty, the left-hand side and right-hand side both simplify to the empty list, which is trivially true.

**Case 2: \( l = \text{hd} :: \text{tl} \)**
We need to show that:
\[
\text{List.drop } (n' + 1) \, ((\text{hd} :: \text{tl}).\text{set } m \, a) = \text{if } m < n' + 1 \text{ then } \text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl}) \text{ else } (\text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl})).\text{set } (m - (n' + 1)) \, a
\]

**Subcase 2.1: \( m = 0 \)**
We need to show that:
\[
\text{List.drop } (n' + 1) \, ((\text{hd} :: \text{tl}).\text{set } 0 \, a) = \text{if } 0 < n' + 1 \text{ then } \text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl}) \text{ else } (\text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl})).\text{set } (0 - (n' + 1)) \, a
\]
Since \( 0 < n' + 1 \) is true, the if-then-else expression simplifies to \( \text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl}) \), which is trivially true.

**Subcase 2.2: \( m = n + 1 \) for some \( n \in \mathbb{N} \)**
We need to show that:
\[
\text{List.drop } (n' + 1) \, ((\text{hd} :: \text{tl}).\text{set } (n + 1) \, a) = \text{if } n + 1 < n' + 1 \text{ then } \text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl}) \text{ else } (\text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl})).\text{set } (n + 1 - (n' + 1)) \, a
\]
Using the inductive hypothesis and the properties of list operations, we simplify the goal to:
\[
(if \, n < n' \, then \, \text{List.drop } n' \, \text{tl} \, else \, (\text{List.drop } n' \, \text{tl}).\text{set } (n - n') \, a) = (if \, n < n' \, then \, \text{List.drop } n' \, \text{tl} \, else \, (\text{List.drop } n' \, \text{tl}).\text{set } (n + 1 - (n' + 1)) \, a)
\]
To establish this equality, we need to show that:
\[
n - n' = n + 1 - (n' + 1)
\]
We use the property of natural numbers that for any \( n, k, m \in \mathbb{N} \), the equation \( n + k - (m + k) = n - m \) holds. By symmetry, this implies \( n - m = n + k - (m + k) \). Therefore, the current goal \( n - n' = n + 1 - (n' + 1) \) is exactly proved by this property.

This completes the proof.","theorem List.drop_set {l : List α} {n m : Nat} {a : α} :
    (l.set m a).drop n = if m < n then l.drop n else (l.drop n).set (m - n) a := by
  induction n generalizing l m with
/- We consider the base case where \( n = 0 \). Using the simplification rules, we can directly simplify the goal to show that \( \text{List.drop } 0 \, (l.\text{set } m \, a) = \text{if } m < 0 \text{ then } \text{List.drop } 0 \, l \text{ else } (\text{List.drop } 0 \, l).\text{set } (m - 0) \, a \). Since \( m < 0 \) is false, the if-then-else expression simplifies to \( \text{List.drop } 0 \, l \), which is trivially true. -/
  | zero => simp
/- We consider the inductive case where \( n = n' + 1 \). We assume the inductive hypothesis \( \text{List.drop } n' \, (l.\text{set } m \, a) = \text{if } m < n' \text{ then } \text{List.drop } n' \, l \text{ else } (\text{List.drop } n' \, l).\text{set } (m - n') \, a \) and need to show that \( \text{List.drop } (n' + 1) \, (l.\text{set } m \, a) = \text{if } m < n' + 1 \text{ then } \text{List.drop } (n' + 1) \, l \text{ else } (\text{List.drop } (n' + 1) \, l).\text{set } (m - (n' + 1)) \, a \). -/
  | succ _ hn =>
    cases l with
/- We consider the case where the list \( l \) is empty. Using the simplification rules, we can directly simplify the goal to show that \( \text{List.drop } (n' + 1) \, ([].\text{set } m \, a) = \text{if } m < n' + 1 \text{ then } \text{List.drop } (n' + 1) \, [] \text{ else } (\text{List.drop } (n' + 1) \, []).\text{set } (m - (n' + 1)) \, a \). Since the list is empty, the left-hand side and right-hand side both simplify to the empty list, which is trivially true. -/
    | nil => simp
/- We consider the case where the list \( l \) is non-empty, i.e., \( l = \text{hd} :: \text{tl} \). We need to show that \( \text{List.drop } (n' + 1) \, ((\text{hd} :: \text{tl}).\text{set } m \, a) = \text{if } m < n' + 1 \text{ then } \text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl}) \text{ else } (\text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl})).\text{set } (m - (n' + 1)) \, a \). -/
    | cons hd tl =>
/- We consider two cases for \( m \):
1. \( m = 0 \)
2. \( m = n + 1 \) for some \( n \in \mathbb{N} \) -/
      cases m
/- For the case \( m = 0 \), we use the simplification rules to show that \( \text{List.drop } (n' + 1) \, ((\text{hd} :: \text{tl}).\text{set } 0 \, a) = \text{if } 0 < n' + 1 \text{ then } \text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl}) \text{ else } (\text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl})).\text{set } (0 - (n' + 1)) \, a \). Since \( 0 < n' + 1 \) is true, the if-then-else expression simplifies to \( \text{List.drop } (n' + 1) \, (\text{hd} :: \text{tl}) \), which is trivially true. -/
      · simp_all
/- For the case \( m = n + 1 \), we use the inductive hypothesis and the properties of list operations to simplify the goal. Specifically, we use the inductive hypothesis \( \text{List.drop } n' \, (l.\text{set } m \, a) = \text{if } m < n' \text{ then } \text{List.drop } n' \, l \text{ else } (\text{List.drop } n' \, l).\text{set } (m - n') \, a \), the property of setting an element in a list \( \text{set\_cons\_succ} \), the property of dropping elements from a list \( \text{drop\_succ\_cons} \), and the property of natural number inequalities \( \text{succ\_lt\_succ\_iff} \). This simplifies the goal to \( (if \, n < n' \, then \, \text{List.drop } n' \, \text{tl} \, else \, (\text{List.drop } n' \, \text{tl}).\text{set } (n - n') \, a) = (if \, n < n' \, then \, \text{List.drop } n' \, \text{tl} \, else \, (\text{List.drop } n' \, \text{tl}).\text{set } (n + 1 - (n' + 1)) \, a) \). -/
      · simp only [hn, set_cons_succ, drop_succ_cons, succ_lt_succ_iff]
/- To establish the equality \( (if \, n < n' \, then \, \text{List.drop } n' \, \text{tl} \, else \, (\text{List.drop } n' \, \text{tl}).\text{set } (n - n') \, a) = (if \, n < n' \, then \, \text{List.drop } n' \, \text{tl} \, else \, (\text{List.drop } n' \, \text{tl}).\text{set } (n + 1 - (n' + 1)) \, a) \), we decompose it into proving that \( n - n' = n + 1 - (n' + 1) \). -/
        congr 2
/- We use the property of natural numbers that for any \( n, k, m \in \mathbb{N} \), the equation \( n + k - (m + k) = n - m \) holds. By symmetry, this implies \( n - m = n + k - (m + k) \). Therefore, the current goal \( n - n' = n + 1 - (n' + 1) \) is exactly proved by this property. -/
/- We use the property of natural numbers that for any \( n, k, m \in \mathbb{N} \), the equation \( n + k - (m + k) = n - m \) holds. By symmetry, this implies \( n - m = n + k - (m + k) \). Therefore, the current goal \( n - n' = n + 1 - (n' + 1) \) is exactly proved by this property. -/
        exact (Nat.add_sub_add_right ..).symm","import Init.Data.List.Lemmas
import Init.Data.List.TakeDrop

open List
open Nat
"
34950,List.isPrefixOf_cons₂_self,"theorem List.isPrefixOf_cons₂_self [LawfulBEq α] {a : α} :
    isPrefixOf (a::as) (a::bs) = isPrefixOf as bs := by sorry","Prefix Consistency: \((a :: \text{as}).\text{isPrefixOf} (a :: \text{bs}) \leftrightarrow \text{as}.\text{isPrefixOf} \text{bs}\) : For any type \( \alpha \) and any lists \( \text{as} \) and \( \text{bs} \) of elements of type \( \alpha \), and for any element \( a \) of type \( \alpha \), the list \( a :: \text{as} \) is a prefix of the list \( a :: \text{bs} \) if and only if the list \( \text{as} \) is a prefix of the list \( \text{bs} \). This can be written as:
\[
(a :: \text{as}).\text{isPrefixOf} (a :: \text{bs}) = \text{as}.\text{isPrefixOf} \text{bs}
\]","theorem List.isPrefixOf_cons₂_self [LawfulBEq α] {a : α} :
    isPrefixOf (a::as) (a::bs) = isPrefixOf as bs := by
  simp [isPrefixOf_cons₂]","To prove the theorem, we need to show that the list \(a :: \text{as}\) is a prefix of the list \(a :: \text{bs}\) if and only if the list \(\text{as}\) is a prefix of the list \(\text{bs}\).

1. **Simplification:**
Using the definition of `isPrefixOf_cons₂`, we can simplify the proposition we want to show. Specifically, the statement \((a :: \text{as}).\text{isPrefixOf} (a :: \text{bs})\) is equivalent to \(\text{as}.\text{isPrefixOf} \text{bs}\). This simplification is based on the fact that the prefix relationship is preserved when the same element is added to the front of both lists.

2. **Conclusion:**
Since the simplification shows that \((a :: \text{as}).\text{isPrefixOf} (a :: \text{bs})\) is equivalent to \(\text{as}.\text{isPrefixOf} \text{bs}\), the theorem is proved.

This completes the proof.","theorem List.isPrefixOf_cons₂_self [LawfulBEq α] {a : α} :
    isPrefixOf (a::as) (a::bs) = isPrefixOf as bs := by
  simp [isPrefixOf_cons₂]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
"
34952,List.Sublist.filter,theorem List.Sublist.filter (p : α → Bool) {l₁ l₂} (s : l₁ <+ l₂) : filter p l₁ <+ filter p l₂ := by sorry,"Sublist Preservation under Filter: \( l_1 \subseteq l_2 \implies \text{filter } p \, l_1 \subseteq \text{filter } p \, l_2 \) : For any types \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), if \( l_1 \) is a sublist of \( l_2 \), then the list obtained by filtering \( l_1 \) with \( p \) is a sublist of the list obtained by filtering \( l_2 \) with \( p \). In other words, if \( l_1 \subseteq l_2 \), then \( \text{filter } p \, l_1 \subseteq \text{filter } p \, l_2 \).","theorem List.Sublist.filter (p : α → Bool) {l₁ l₂} (s : l₁ <+ l₂) : filter p l₁ <+ filter p l₂ := by
  rw [← filterMap_eq_filter]; apply s.filterMap","To prove the theorem, we start by noting that the filter operation on a list can be expressed as a filter map operation. Specifically, we use the equivalence that \( \text{filter } p \, l = \text{filterMap } p \, l \). This allows us to rewrite the goal from showing that the filtered list of \( l_1 \) is a sublist of the filtered list of \( l_2 \) to showing that the filter map of \( l_1 \) is a sublist of the filter map of \( l_2 \).

Given that \( l_1 \) is a sublist of \( l_2 \), we can apply the property that if \( l_1 \) is a sublist of \( l_2 \), then the filter map of \( l_1 \) is a sublist of the filter map of \( l_2 \). Therefore, we conclude that \( \text{filter } p \, l_1 \) is a sublist of \( \text{filter } p \, l_2 \).

This completes the proof.","theorem List.Sublist.filter (p : α → Bool) {l₁ l₂} (s : l₁ <+ l₂) : filter p l₁ <+ filter p l₂ := by
/- First, we use the equivalence that the filter operation on a list can be expressed as a filter map operation. This allows us to rewrite the goal from showing that the filtered list of \( l_1 \) is a sublist of the filtered list of \( l_2 \) to showing that the filter map of \( l_1 \) is a sublist of the filter map of \( l_2 \). Then, we apply the fact that if \( l_1 \) is a sublist of \( l_2 \), then the filter map of \( l_1 \) is a sublist of the filter map of \( l_2 \). This completes the proof. -/
  rw [← filterMap_eq_filter]; apply s.filterMap","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Sublist
open Nat
variable [BEq α]
variable [BEq α]
"
34953,List.sublist_filter_iff,"theorem List.sublist_filter_iff {l₁ : List α} {p : α → Bool} :
    l₁ <+ l₂.filter p ↔ ∃ l', l' <+ l₂ ∧ l₁ = l'.filter p := by sorry","Sublist of Filtered List Equivalence: \( l_1 \text{ is a sublist of } \text{List.filter } p \, l_2 \leftrightarrow \exists l', l' \text{ is a sublist of } l_2 \text{ and } l_1 = \text{List.filter } p \, l' \) : For any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \) and for any predicate \( p : \alpha \to \text{Bool} \), the list \( l_1 \) is a sublist of the list \( \text{List.filter } p \, l_2 \) if and only if there exists a list \( l' \) such that \( l' \) is a sublist of \( l_2 \) and \( l_1 = \text{List.filter } p \, l' \).","theorem List.sublist_filter_iff {l₁ : List α} {p : α → Bool} :
    l₁ <+ l₂.filter p ↔ ∃ l', l' <+ l₂ ∧ l₁ = l'.filter p := by
  simp only [← filterMap_eq_filter, sublist_filterMap_iff]","We start by using the equivalence that the filtered list `List.filter p l` is the same as the filtered map `List.filterMap (λ x, if p x then some x else none) l`. This equivalence allows us to rewrite the original statement.

Next, we use the fact that a list \( l_1 \) is a sublist of the filtered map of another list \( l_2 \) if and only if there exists a sublist \( l' \) of \( l_2 \) such that \( l_1 \) is equal to the filtered list of \( l' \). This is a known property of sublists and filtered maps.

By applying these equivalences, we can simplify the original proposition to the desired form:
\[
l_1 \text{ is a sublist of } \text{List.filter } p \, l_2 \leftrightarrow \exists l', l' \text{ is a sublist of } l_2 \text{ and } l_1 = \text{List.filter } p \, l'
\]

This completes the proof.","theorem List.sublist_filter_iff {l₁ : List α} {p : α → Bool} :
    l₁ <+ l₂.filter p ↔ ∃ l', l' <+ l₂ ∧ l₁ = l'.filter p := by
/- Using the equivalence that `List.filter p l` is the same as `List.filterMap (λ x, if p x then some x else none) l` and the fact that a list is a sublist of the filtered map of another list if and only if there exists a sublist of the original list that, when filtered, equals the first list, we can simplify the proposition we want to show to the desired form. -/
  simp only [← filterMap_eq_filter, sublist_filterMap_iff]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34954,List.isSuffixOf_replicate,"theorem List.isSuffixOf_replicate {a : α} :
    isSuffixOf l (replicate n a) = (decide (l.length ≤ n) && l.all (· == a)) := by sorry","Suffix of Replicated List: \( l \text{ is a suffix of } \text{replicate } n \, a \iff l.\text{length} \le n \land \forall x \in l, x = a \) : For any type \( \alpha \) and any list \( l \) of elements of type \( \alpha \), and for any natural number \( n \) and any element \( a \) of type \( \alpha \), the list \( l \) is a suffix of the list `replicate n a` if and only if the length of \( l \) is less than or equal to \( n \) and every element in \( l \) is equal to \( a \). Formally, this can be written as:
\[ l \text{ is a suffix of } \text{replicate } n \, a \iff \text{decide}(l.\text{length} \le n) \land l.\text{all} \, (\lambda x, x = a) \]","theorem List.isSuffixOf_replicate {a : α} :
    isSuffixOf l (replicate n a) = (decide (l.length ≤ n) && l.all (· == a)) := by
  simp [isSuffixOf, all_eq]","To prove the theorem, we start by using the definitions of `isSuffixOf` and `all_eq` to simplify the proposition. Specifically, we need to show that:
\[ l \text{ is a suffix of } \text{replicate } n \, a \iff \text{decide}(l.\text{length} \le n) \land l.\text{all} \, (\lambda x, x = a) \]

1. **Simplification using Definitions:**
- The function `List.length` computes the length of a list. For example, the length of the empty list `[]` is \(0\), and the length of a list `a :: l` is the length of `l` plus \(1\).
- The boolean ""and"" operation `x && y` returns `false` if \( x \) is `false`, and returns the value of \( y \) if \( x \) is `true`.
- The function `List.all p l` returns `true` if and only if the predicate \( p \) holds for all elements in the list \( l \). Formally, this means \( \text{List.all } p \, l = \text{true} \) if and only if \( \forall x \in l, \, p(x) = \text{true} \).

2. **Simplification of the Goal:**
- Using these definitions, we can simplify the goal to:
\[
l \text{ is a suffix of } \text{replicate } n \, a \iff \text{decide}(l.\text{length} \le n) \land l.\text{all} \, (\lambda x, x = a)
\]
- This means that \( l \) is a suffix of the list `replicate n a` if and only if the length of \( l \) is less than or equal to \( n \) and every element in \( l \) is equal to \( a \).

3. **Conclusion:**
- Since the simplification using the definitions of `isSuffixOf` and `all_eq` directly gives us the desired equivalence, the theorem is proved.

This completes the proof.","theorem List.isSuffixOf_replicate {a : α} :
    isSuffixOf l (replicate n a) = (decide (l.length ≤ n) && l.all (· == a)) := by
/- Using the definitions of `isSuffixOf` and `all_eq`, we can simplify the proposition we want to show. Specifically, the list \( l \) is a suffix of the list `replicate n a` if and only if the length of \( l \) is less than or equal to \( n \) and every element in \( l \) is equal to \( a \). This simplification is based on the following:
- The length of a list \( l \) is computed by the function `List.length`.
- The boolean ""and"" operation `x && y` returns `false` if \( x \) is `false`, and returns the value of \( y \) if \( x \) is `true`.
- The function `List.all p l` returns `true` if and only if the predicate \( p \) holds for all elements in the list \( l \). -/
  simp [isSuffixOf, all_eq]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34955,List.sublist_map_iff,"theorem List.sublist_map_iff {l₁ : List β} {f : α → β} :
    l₁ <+ l₂.map f ↔ ∃ l', l' <+ l₂ ∧ l₁ = l'.map f := by sorry","Sublist of Mapped List Equivalence : For any lists \( l_1 \) and \( l_2 \) of types \( \beta \) and \( \alpha \) respectively, and for any function \( f : \alpha \to \beta \), the list \( l_1 \) is a sublist of the list \( \text{List.map } f \, l_2 \) if and only if there exists a list \( l' \) such that \( l' \) is a sublist of \( l_2 \) and \( l_1 = \text{List.map } f \, l' \).","theorem List.sublist_map_iff {l₁ : List β} {f : α → β} :
    l₁ <+ l₂.map f ↔ ∃ l', l' <+ l₂ ∧ l₁ = l'.map f := by
  simp only [← filterMap_eq_map, sublist_filterMap_iff]","To prove the equivalence, we use the following steps:

1. **Simplification:**
We use the equivalence that the filter map of a list is equal to the map of the list and the fact that a list is a sublist of the filter map of another list if and only if it is a sublist of the map of that list. This allows us to simplify the proposition we want to show. Specifically, the statement \( l_1 \) is a sublist of \( \text{List.map } f \, l_2 \) is equivalent to the existence of a list \( l' \) such that \( l' \) is a sublist of \( l_2 \) and \( l_1 = \text{List.map } f \, l' \).

2. **Conclusion:**
Therefore, the original statement \( l_1 \) is a sublist of \( \text{List.map } f \, l_2 \) is true if and only if there exists a list \( l' \) such that \( l' \) is a sublist of \( l_2 \) and \( l_1 = \text{List.map } f \, l' \).

This completes the proof. \(\blacksquare\)","theorem List.sublist_map_iff {l₁ : List β} {f : α → β} :
    l₁ <+ l₂.map f ↔ ∃ l', l' <+ l₂ ∧ l₁ = l'.map f := by
/- Using the equivalence that the filter map of a list is equal to the map of the list and the fact that a list is a sublist of the filter map of another list if and only if it is a sublist of the map of that list, we can simplify the proposition we want to show. Specifically, the statement \( l_1 \) is a sublist of \( \text{List.map } f \, l_2 \) is equivalent to the existence of a list \( l' \) such that \( l' \) is a sublist of \( l_2 \) and \( l_1 = \text{List.map } f \, l' \). -/
  simp only [← filterMap_eq_map, sublist_filterMap_iff]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34960,List.reverse_subset,theorem List.reverse_subset {l₁ l₂ : List α} : reverse l₁ ⊆ l₂ ↔ l₁ ⊆ l₂ := by sorry,"Reverse of a List is a Subset if and Only If the Original List is a Subset: \( l_1^{\text{reverse}} \subseteq l_2 \leftrightarrow l_1 \subseteq l_2 \) : For any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), the reverse of \( l_1 \) is a subset of \( l_2 \) if and only if \( l_1 \) is a subset of \( l_2 \). In other words, \( l_1^{\text{reverse}} \subseteq l_2 \) if and only if \( l_1 \subseteq l_2 \).","theorem List.reverse_subset {l₁ l₂ : List α} : reverse l₁ ⊆ l₂ ↔ l₁ ⊆ l₂ := by
  simp [subset_def]","To prove the theorem, we start by using the definition of subset. A list \( l_1 \) is a subset of a list \( l_2 \) if and only if every element of \( l_1 \) is also an element of \( l_2 \). This definition can be written as:
\[ l_1 \subseteq l_2 \iff \forall x \in l_1, x \in l_2. \]

Similarly, the reverse of \( l_1 \) is a subset of \( l_2 \) if and only if every element of \( l_1^{\text{reverse}} \) is also an element of \( l_2 \). This can be written as:
\[ l_1^{\text{reverse}} \subseteq l_2 \iff \forall x \in l_1^{\text{reverse}}, x \in l_2. \]

Since the reverse of a list \( l_1 \) contains exactly the same elements as \( l_1 \), just in reverse order, the set of elements in \( l_1 \) and \( l_1^{\text{reverse}} \) are the same. Therefore, the condition \( \forall x \in l_1, x \in l_2 \) is equivalent to \( \forall x \in l_1^{\text{reverse}}, x \in l_2 \).

Thus, we have:
\[ l_1^{\text{reverse}} \subseteq l_2 \iff l_1 \subseteq l_2. \]

This completes the proof.","theorem List.reverse_subset {l₁ l₂ : List α} : reverse l₁ ⊆ l₂ ↔ l₁ ⊆ l₂ := by
/- Using the definition of subset, we can simplify the proposition we want to show. The definition of subset states that a list \( l_1 \) is a subset of a list \( l_2 \) if and only if every element of \( l_1 \) is also an element of \( l_2 \). Therefore, the goal \( l_1^{\text{reverse}} \subseteq l_2 \leftrightarrow l_1 \subseteq l_2 \) is equivalent to showing that for every element \( x \) in \( l_1 \), \( x \) is in \( l_2 \) if and only if \( x \) is in \( l_2 \) when considering the reverse of \( l_1 \). -/
  simp [subset_def]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34962,List.append_subset,"theorem List.append_subset {l₁ l₂ l : List α} :
    l₁ ++ l₂ ⊆ l ↔ l₁ ⊆ l ∧ l₂ ⊆ l := by sorry","Concatenation of Lists is a Subset if and Only If Both Lists are Subsets: \( l_1 ++ l_2 \subseteq l \leftrightarrow l_1 \subseteq l \land l_2 \subseteq l \) : For any type \( \alpha \) and lists \( l_1, l_2, l \) of elements of type \( \alpha \), the list \( l_1 \) concatenated with \( l_2 \) is a subset of \( l \) if and only if both \( l_1 \) and \( l_2 \) are subsets of \( l \). In other words, \( l_1 \) and \( l_2 \) are subsets of \( l \) if and only if \( l_1 ++ l_2 \subseteq l \).","theorem List.append_subset {l₁ l₂ l : List α} :
    l₁ ++ l₂ ⊆ l ↔ l₁ ⊆ l ∧ l₂ ⊆ l := by
  simp [subset_def, or_imp, forall_and]","To prove the theorem, we need to show that \( l_1 ++ l_2 \subseteq l \) if and only if \( l_1 \subseteq l \) and \( l_2 \subseteq l \).

1. **Simplification:**
Using the definitions of subset, the logical implication of disjunction, and the equivalence of universal quantification and conjunction, we can simplify the proposition we want to show. Specifically, we need to prove that:
\[
l_1 ++ l_2 \subseteq l \leftrightarrow (l_1 \subseteq l) \land (l_2 \subseteq l)
\]

2. **Forward Direction:**
- Assume \( l_1 ++ l_2 \subseteq l \).
- We need to show that \( l_1 \subseteq l \) and \( l_2 \subseteq l \).
- By the definition of subset, \( l_1 ++ l_2 \subseteq l \) means that for every element \( x \) in \( l_1 ++ l_2 \), \( x \) is also in \( l \).
- Since \( l_1 \) is a prefix of \( l_1 ++ l_2 \), every element of \( l_1 \) is also in \( l_1 ++ l_2 \). Therefore, every element of \( l_1 \) is in \( l \), which means \( l_1 \subseteq l \).
- Similarly, since \( l_2 \) is a suffix of \( l_1 ++ l_2 \), every element of \( l_2 \) is also in \( l_1 ++ l_2 \). Therefore, every element of \( l_2 \) is in \( l \), which means \( l_2 \subseteq l \).

3. **Backward Direction:**
- Assume \( l_1 \subseteq l \) and \( l_2 \subseteq l \).
- We need to show that \( l_1 ++ l_2 \subseteq l \).
- By the definition of subset, \( l_1 \subseteq l \) means that every element of \( l_1 \) is in \( l \).
- Similarly, \( l_2 \subseteq l \) means that every element of \( l_2 \) is in \( l \).
- Since \( l_1 ++ l_2 \) is the concatenation of \( l_1 \) and \( l_2 \), every element of \( l_1 ++ l_2 \) is either in \( l_1 \) or in \( l_2 \). Therefore, every element of \( l_1 ++ l_2 \) is in \( l \), which means \( l_1 ++ l_2 \subseteq l \).

Thus, we have shown that \( l_1 ++ l_2 \subseteq l \) if and only if \( l_1 \subseteq l \) and \( l_2 \subseteq l \). This completes the proof. \(\blacksquare\)","theorem List.append_subset {l₁ l₂ l : List α} :
    l₁ ++ l₂ ⊆ l ↔ l₁ ⊆ l ∧ l₂ ⊆ l := by
  simp [subset_def, or_imp, forall_and]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34967,List.filterMap_subset,"theorem List.filterMap_subset {l₁ l₂ : List α} (f : α → Option β) (H : l₁ ⊆ l₂) :
    filterMap f l₁ ⊆ filterMap f l₂ := by sorry","Filter and Map Preserves Subset Relation in Lists: \( l_1 \subseteq l_2 \to \text{filterMap } f \, l_1 \subseteq \text{filterMap } f \, l_2 \) : For any types \( \alpha \) and \( \beta \), and any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), if \( l_1 \subseteq l_2 \) and \( f : \alpha \to \text{Option} \beta \) is a function, then the list obtained by applying `filterMap` to \( l_1 \) with \( f \) is a subset of the list obtained by applying `filterMap` to \( l_2 \) with \( f \). In other words, if every element of \( l_1 \) is also an element of \( l_2 \), then every element of \( \text{filterMap } f \, l_1 \) is also an element of \( \text{filterMap } f \, l_2 \).","theorem List.filterMap_subset {l₁ l₂ : List α} (f : α → Option β) (H : l₁ ⊆ l₂) :
    filterMap f l₁ ⊆ filterMap f l₂ := by
  intro x
  simp only [mem_filterMap]
  rintro ⟨a, h, w⟩
  exact ⟨a, H h, w⟩","Let \( x \) be an arbitrary element of type \( \beta \). We need to show that if \( x \) is in the list obtained by applying `filterMap` to \( l_1 \) with \( f \), then \( x \) is also in the list obtained by applying `filterMap` to \( l_2 \) with \( f \).

Using the definition of `filterMap`, this is equivalent to showing that if there exists an element \( a \) in \( l_1 \) such that \( f(a) = \text{some } x \), then there exists an element \( a \) in \( l_2 \) such that \( f(a) = \text{some } x \).

Let \( a \) be an element of type \( \alpha \), \( h \) be a proof that \( a \) is in \( l_1 \), and \( w \) be a proof that \( f(a) = \text{some } x \). Since \( l_1 \subseteq l_2 \), the element \( a \) that is in \( l_1 \) (as proven by \( h \)) is also in \( l_2 \) (as proven by \( H h \)). Therefore, we have \( a \in l_2 \) and \( f(a) = \text{some } x \) (as proven by \( w \)).

Thus, the list obtained by applying `filterMap` to \( l_1 \) with \( f \) is a subset of the list obtained by applying `filterMap` to \( l_2 \) with \( f \). This completes the proof. \(\blacksquare\)","theorem List.filterMap_subset {l₁ l₂ : List α} (f : α → Option β) (H : l₁ ⊆ l₂) :
    filterMap f l₁ ⊆ filterMap f l₂ := by
/- Let \( x \) be an arbitrary element of type \( \beta \). We need to show that if \( x \) is in the list obtained by applying `filterMap` to \( l_1 \) with \( f \), then \( x \) is also in the list obtained by applying `filterMap` to \( l_2 \) with \( f \). -/
  intro x
/- Using the definition of `filterMap`, we can simplify the proposition we want to show to: if there exists an element \( a \) in \( l_1 \) such that \( f(a) = \text{some } x \), then there exists an element \( a \) in \( l_2 \) such that \( f(a) = \text{some } x \). -/
  simp only [mem_filterMap]
/- Let \( a \) be an element of type \( \alpha \), \( h \) be a proof that \( a \) is in \( l_1 \), and \( w \) be a proof that \( f(a) = \text{some } x \). We need to show that there exists an element \( a \) in \( l_2 \) such that \( f(a) = \text{some } x \). -/
  rintro ⟨a, h, w⟩
/- Since \( l_1 \subseteq l_2 \), the element \( a \) that is in \( l_1 \) (as proven by \( h \)) is also in \( l_2 \) (as proven by \( H h \)). Therefore, we have \( a \in l_2 \) and \( f(a) = \text{some } x \) (as proven by \( w \)). This completes the proof. -/
  exact ⟨a, H h, w⟩","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34972,List.singleton_sublist,theorem List.singleton_sublist {a : α} {l} : [a] <+ l ↔ a ∈ l := by sorry,"Singleton List is Sublist if and only if Element is in List: \([a] \subseteq l \leftrightarrow a \in l\) : For any type \( \alpha \), a list \( l \) of elements of type \( \alpha \), and an element \( a \) of type \( \alpha \), the singleton list \([a]\) is a sublist of \( l \) if and only if \( a \) is a member of \( l \). In other words, \([a] \subseteq l \leftrightarrow a \in l\).","theorem List.singleton_sublist {a : α} {l} : [a] <+ l ↔ a ∈ l := by
  refine ⟨fun h => h.subset (mem_singleton_self _), fun h => ?_⟩
  obtain ⟨_, _, rfl⟩ := append_of_mem h
  exact ((nil_sublist _).cons₂ _).trans (sublist_append_right ..)","To prove the equivalence \([a] \subseteq l \leftrightarrow a \in l\), we need to show both directions.

1. **(\(\Rightarrow\)) Assume \([a] \subseteq l\):**
- By the property that a sublist implies a subset, and the fact that \(a \in [a]\), it follows that \(a \in l\).

2. **(\(\Leftarrow\)) Assume \(a \in l\):**
- By the property that if an element is in a list, there exist sublists \(s\) and \(t\) such that \(l = s ++ [a] ++ t\), we can write \(l\) as \(s ++ [a] ++ t\).
- To show that \([a] \subseteq l\), we use the fact that the empty list is a sublist of any list, and the property that if a list is a sublist of another, adding the same element to the front of both lists preserves the sublist relation.
- Specifically, since \([] \subseteq s\), it follows that \([a] \subseteq [a] ++ s\).
- By the property that a list is a sublist of its concatenation with another list, we have \([a] ++ s \subseteq s ++ [a] ++ t\).
- Therefore, by transitivity, \([a] \subseteq s ++ [a] ++ t\), which is \(l\).

Thus, we have shown both directions, and the proof is complete. \(\blacksquare\)","theorem List.singleton_sublist {a : α} {l} : [a] <+ l ↔ a ∈ l := by
/- To prove the equivalence \([a] \subseteq l \leftrightarrow a \in l\), we need to show both directions. First, assume \([a] \subseteq l\). By the property that a sublist implies a subset, and the fact that \(a \in [a]\), it follows that \(a \in l\). Second, we need to show that if \(a \in l\), then \([a] \subseteq l\). This second part will be proved later. -/
  refine ⟨fun h => h.subset (mem_singleton_self _), fun h => ?_⟩
/- Assume \(a \in l\). By the property that if an element is in a list, there exist sublists \(s\) and \(t\) such that \(l = s ++ [a] ++ t\), we can write \(l\) as \(s ++ [a] ++ t\). Here, \(s\) and \(t\) are lists such that \(l = s ++ [a] ++ t\). -/
  obtain ⟨_, _, rfl⟩ := append_of_mem h
/- To show that \([a] \subseteq l\), we use the fact that the empty list is a sublist of any list, and the property that if a list is a sublist of another, adding the same element to the front of both lists preserves the sublist relation. Specifically, since \([] \subseteq s\), it follows that \([a] \subseteq [a] ++ s\). By the property that a list is a sublist of its concatenation with another list, we have \([a] ++ s \subseteq s ++ [a] ++ t\). Therefore, by transitivity, \([a] \subseteq s ++ [a] ++ t\), which is \(l\). This completes the proof. -/
  exact ((nil_sublist _).cons₂ _).trans (sublist_append_right ..)","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34973,List.subset_reverse,theorem List.subset_reverse {l₁ l₂ : List α} : l₁ ⊆ reverse l₂ ↔ l₁ ⊆ l₂ := by sorry,"Subset of Reverse List is Equivalent to Subset of Original List: \( l_1 \subseteq l_2^{\text{reverse}} \leftrightarrow l_1 \subseteq l_2 \) : For any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), \( l_1 \) is a subset of the reverse of \( l_2 \) if and only if \( l_1 \) is a subset of \( l_2 \). In other words, \( l_1 \subseteq l_2^{\text{reverse}} \) if and only if \( l_1 \subseteq l_2 \).","theorem List.subset_reverse {l₁ l₂ : List α} : l₁ ⊆ reverse l₂ ↔ l₁ ⊆ l₂ := by
  simp [subset_def]","To prove the theorem, we start by using the definition of subset. A list \( l_1 \) is a subset of another list \( l_2 \) if and only if every element of \( l_1 \) is also an element of \( l_2 \). Therefore, the statement \( l_1 \subseteq l_2^{\text{reverse}} \leftrightarrow l_1 \subseteq l_2 \) can be simplified to showing that for every element \( x \) in \( l_1 \), \( x \) is in \( l_2^{\text{reverse}} \) if and only if \( x \) is in \( l_2 \).

Since the reverse of a list \( l_2 \) contains exactly the same elements as \( l_2 \), just in a different order, the membership of an element \( x \) in \( l_2 \) is equivalent to its membership in \( l_2^{\text{reverse}} \). Hence, for any element \( x \) in \( l_1 \), \( x \) is in \( l_2^{\text{reverse}} \) if and only if \( x \) is in \( l_2 \).

Therefore, \( l_1 \subseteq l_2^{\text{reverse}} \) if and only if \( l_1 \subseteq l_2 \). This completes the proof.","theorem List.subset_reverse {l₁ l₂ : List α} : l₁ ⊆ reverse l₂ ↔ l₁ ⊆ l₂ := by
/- Using the definition of subset, we can simplify the proposition we want to show. The definition of subset states that a list \( l_1 \) is a subset of another list \( l_2 \) if and only if every element of \( l_1 \) is also an element of \( l_2 \). Therefore, the goal \( l_1 \subseteq l_2^{\text{reverse}} \leftrightarrow l_1 \subseteq l_2 \) simplifies to showing that for every element \( x \) in \( l_1 \), \( x \) is in \( l_2^{\text{reverse}} \) if and only if \( x \) is in \( l_2 \). -/
  simp [subset_def]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34977,List.replicate_subset,theorem List.replicate_subset {n : Nat} {a : α} {l : List α} : replicate n a ⊆ l ↔ n = 0 ∨ a ∈ l := by sorry,"Replicated List is a Subset if and Only If \( n = 0 \) or \( a \in l \) : For any type \( \alpha \), natural number \( n \), element \( a \in \alpha \), and list \( l \) of elements of type \( \alpha \), the list \(\text{replicate } n \, a\) is a subset of \( l \) if and only if \( n = 0 \) or \( a \in l \). In other words, \(\{a, a, \ldots, a\} \subseteq l\) (where the list contains \( n \) copies of \( a \)) if and only if \( n = 0 \) or \( a \) is an element of \( l \).","theorem List.replicate_subset {n : Nat} {a : α} {l : List α} : replicate n a ⊆ l ↔ n = 0 ∨ a ∈ l := by
  induction n with
  | zero => simp
  | succ n ih => simp (config := {contextual := true}) [replicate_succ, ih, cons_subset]","We prove this by induction on \( n \).

**Base Case:**
Consider \( n = 0 \). We need to show that \(\text{replicate } 0 \, a \subseteq l\) if and only if \( 0 = 0 \) or \( a \in l \). Since \(\text{replicate } 0 \, a\) is the empty list, it is a subset of any list \( l \). Therefore, the left-hand side of the equivalence is always true. The right-hand side is also always true because \( 0 = 0 \) is true. Hence, the equivalence holds.

**Inductive Step:**
Assume the inductive hypothesis that \(\text{replicate } k \, a \subseteq l\) if and only if \( k = 0 \) or \( a \in l \). We need to show that \(\text{replicate } (k + 1) \, a \subseteq l\) if and only if \( k + 1 = 0 \) or \( a \in l \).

Using the definition of \(\text{replicate}\), we have \(\text{replicate } (k + 1) \, a = a :: \text{replicate } k \, a\). Therefore, \(\text{replicate } (k + 1) \, a \subseteq l\) if and only if \( a \in l \) and \(\text{replicate } k \, a \subseteq l \).

By the inductive hypothesis, \(\text{replicate } k \, a \subseteq l\) if and only if \( k = 0 \) or \( a \in l \). Combining these, we get:
- If \( k + 1 = 0 \), then \( k = -1 \), which is impossible since \( k \) is a natural number.
- If \( a \in l \), then \(\text{replicate } k \, a \subseteq l\) holds by the inductive hypothesis.

Thus, \(\text{replicate } (k + 1) \, a \subseteq l\) if and only if \( a \in l \). This completes the inductive step.

By induction, the theorem holds for all natural numbers \( n \). Therefore, the list \(\text{replicate } n \, a\) is a subset of \( l \) if and only if \( n = 0 \) or \( a \in l \). This completes the proof. \(\blacksquare\)","theorem List.replicate_subset {n : Nat} {a : α} {l : List α} : replicate n a ⊆ l ↔ n = 0 ∨ a ∈ l := by
  induction n with
/- First, consider the base case where \( n = 0 \). We need to show that \(\text{replicate } 0 \, a \subseteq l\) if and only if \( 0 = 0 \) or \( a \in l \). Since \(\text{replicate } 0 \, a\) is the empty list, it is a subset of any list \( l \). Therefore, the left-hand side of the equivalence is always true. The right-hand side is also always true because \( 0 = 0 \) is true. Hence, the equivalence holds. -/
  | zero => simp
/- Next, consider the inductive step where \( n = k + 1 \) for some \( k \). We assume the inductive hypothesis that \(\text{replicate } k \, a \subseteq l\) if and only if \( k = 0 \) or \( a \in l \). We need to show that \(\text{replicate } (k + 1) \, a \subseteq l\) if and only if \( k + 1 = 0 \) or \( a \in l \).

Using the definition of \(\text{replicate}\), we have \(\text{replicate } (k + 1) \, a = a :: \text{replicate } k \, a\). Therefore, \(\text{replicate } (k + 1) \, a \subseteq l\) if and only if \( a \in l \) and \(\text{replicate } k \, a \subseteq l \).

By the inductive hypothesis, \(\text{replicate } k \, a \subseteq l\) if and only if \( k = 0 \) or \( a \in l \). Combining these, we get:
- If \( k + 1 = 0 \), then \( k = -1 \), which is impossible since \( k \) is a natural number.
- If \( a \in l \), then \(\text{replicate } k \, a \subseteq l\) holds by the inductive hypothesis.

Thus, \(\text{replicate } (k + 1) \, a \subseteq l\) if and only if \( a \in l \). This completes the inductive step. -/
  | succ n ih => simp (config := {contextual := true}) [replicate_succ, ih, cons_subset]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34978,List.isSuffixOf_iff_suffix,"theorem List.isSuffixOf_iff_suffix [BEq α] [LawfulBEq α] {l₁ l₂ : List α} :
    l₁.isSuffixOf l₂ ↔ l₁ <:+ l₂ := by sorry","Suffix of a List: `isSuffixOf l₁ l₂ = true` if and only if \( l_1 \) is a suffix of \( l_2 \) : For any type \( \alpha \) with a decidable equality, and for any two lists \( l_1 \) and \( l_2 \) of type \( \alpha \), the function `isSuffixOf l₁ l₂` returns `true` if and only if \( l_1 \) is a suffix of \( l_2 \). In other words, \( l_1 \) is a suffix of \( l_2 \) if and only if there exists a list \( t \) such that \( l_2 = t ++ l_1 \).","theorem List.isSuffixOf_iff_suffix [BEq α] [LawfulBEq α] {l₁ l₂ : List α} :
    l₁.isSuffixOf l₂ ↔ l₁ <:+ l₂ := by
  simp [isSuffixOf]","To prove the theorem, we start by using the definition of the function `isSuffixOf`. The function `isSuffixOf l₁ l₂` returns `true` if and only if \( l_1 \) is a suffix of \( l_2 \). By the definition of a suffix, \( l_1 \) is a suffix of \( l_2 \) if and only if there exists a list \( t \) such that \( l_2 = t ++ l_1 \).

Thus, the proposition \( l_1 \).isSuffixOf \( l_2 \) = true is equivalent to \( l_1 \) <:+ \( l_2 \). This completes the proof.","theorem List.isSuffixOf_iff_suffix [BEq α] [LawfulBEq α] {l₁ l₂ : List α} :
    l₁.isSuffixOf l₂ ↔ l₁ <:+ l₂ := by
/- Using the definition of `isSuffixOf`, we can simplify the proposition we want to show. The function `isSuffixOf l₁ l₂` returns `true` if and only if \( l_1 \) is a suffix of \( l_2 \). This means there exists a list \( t \) such that \( l_2 = t ++ l_1 \). Therefore, the proposition \( l_1 \).isSuffixOf \( l_2 \) = true is equivalent to \( l_1 \) <:+ \( l_2 \). -/
  simp [isSuffixOf]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34979,List.isPrefixOf_length_pos_nil,theorem List.isPrefixOf_length_pos_nil {L : List α} (h : 0 < L.length) : isPrefixOf L [] = false := by sorry,"Non-empty List is Not a Prefix of the Empty List: \( 0 < |L| \implies L.\text{isPrefixOf} [] = \text{false} \) : For any type \( \alpha \) and any list \( L \) of elements of type \( \alpha \), if the length of \( L \) is greater than 0, then \( L \) is not a prefix of the empty list. This can be written as:
\[
0 < |L| \implies L.\text{isPrefixOf} [] = \text{false}
\]
where \( |L| \) denotes the length of the list \( L \).","theorem List.isPrefixOf_length_pos_nil {L : List α} (h : 0 < L.length) : isPrefixOf L [] = false := by
  cases L <;> simp_all [isPrefixOf]","We will consider every possible case of the list \( L \).

**Case 1: \( L \) is the empty list.**
- The assumption \( 0 < |L| \) becomes \( 0 < 0 \), which is false. Therefore, this case is vacuously true.
- We need to show that \( L.\text{isPrefixOf} [] = \text{false} \). Since \( L \) is the empty list, \( L.\text{isPrefixOf} [] \) is \( \text{true} \) by definition. However, this case is vacuously true because the assumption \( 0 < |L| \) is false.

**Case 2: \( L \) is a non-empty list, i.e., \( L = \text{head} :: \text{tail} \).**
- The assumption \( 0 < |L| \) becomes \( 0 < 1 + |\text{tail}| \), which is true.
- We need to show that \( (\text{head} :: \text{tail}).\text{isPrefixOf} [] = \text{false} \). By the definition of `isPrefixOf`, if the second list is empty and the first list is non-empty, then \( \text{isPrefixOf} \) returns `false`. Therefore, \( (\text{head} :: \text{tail}).\text{isPrefixOf} [] = \text{false} \).

In both cases, the statement holds. Therefore, we have shown that if the length of \( L \) is greater than 0, then \( L \) is not a prefix of the empty list. This completes the proof. \(\blacksquare\)","theorem List.isPrefixOf_length_pos_nil {L : List α} (h : 0 < L.length) : isPrefixOf L [] = false := by
/- We will consider every possible case of the list \( L \).

**Case 1: \( L \) is the empty list.**
- The assumption \( 0 < |L| \) becomes \( 0 < 0 \), which is false. Therefore, this case is vacuously true.
- We need to show that \( L.\text{isPrefixOf} [] = \text{false} \). Since \( L \) is the empty list, \( L.\text{isPrefixOf} [] \) is \( \text{true} \) by definition. However, this case is vacuously true because the assumption \( 0 < |L| \) is false.

**Case 2: \( L \) is a non-empty list, i.e., \( L = \text{head} :: \text{tail} \).**
- The assumption \( 0 < |L| \) becomes \( 0 < 1 + |\text{tail}| \), which is true.
- We need to show that \( (\text{head} :: \text{tail}).\text{isPrefixOf} [] = \text{false} \). By the definition of `isPrefixOf`, if the second list is empty and the first list is non-empty, then \( \text{isPrefixOf} \) returns `false`. Therefore, \( (\text{head} :: \text{tail}).\text{isPrefixOf} [] = \text{false} \). -/
  cases L <;> simp_all [isPrefixOf]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
"
34980,List.reverse_prefix,theorem List.reverse_prefix : reverse l₁ <+: reverse l₂ ↔ l₁ <:+ l₂ := by sorry,"Reversing Lists Preserves Prefix-Suffix Relationship: \( l_1^{\text{reverse}} <+: l_2^{\text{reverse}} \leftrightarrow l_1 <:+ l_2 \) : For any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), the reverse of \( l_1 \) is a prefix of the reverse of \( l_2 \) if and only if \( l_1 \) is a suffix of \( l_2 \). In other words, \( l_1^{\text{reverse}} \) is a prefix of \( l_2^{\text{reverse}} \) if and only if \( l_1 \) is a suffix of \( l_2 \).","theorem List.reverse_prefix : reverse l₁ <+: reverse l₂ ↔ l₁ <:+ l₂ := by
  rw [← reverse_suffix]; simp only [reverse_reverse]","To prove the theorem, we start by using the equivalence that \( l_1 \) is a suffix of \( l_2 \) if and only if \( l_1^{\text{reverse}} \) is a prefix of \( l_2^{\text{reverse}} \). This allows us to rewrite the goal as:
\[ l_1^{\text{reverse}} <+: l_2^{\text{reverse}} \leftrightarrow l_1^{\text{reverse}} <+: l_2^{\text{reverse}}. \]

Next, we simplify the expression using the fact that the reverse of the reverse of a list is the original list, i.e., \( (l_1^{\text{reverse}})^{\text{reverse}} = l_1 \) and \( (l_2^{\text{reverse}})^{\text{reverse}} = l_2 \). This simplifies the goal to:
\[ l_1^{\text{reverse}} <+: l_2^{\text{reverse}} \leftrightarrow l_1 <:+ l_2. \]

Thus, we have shown that the reverse of \( l_1 \) is a prefix of the reverse of \( l_2 \) if and only if \( l_1 \) is a suffix of \( l_2 \). This completes the proof.","theorem List.reverse_prefix : reverse l₁ <+: reverse l₂ ↔ l₁ <:+ l₂ := by
/- First, we use the equivalence that \( l_1 \) is a suffix of \( l_2 \) if and only if \( l_1^{\text{reverse}} \) is a prefix of \( l_2^{\text{reverse}} \). This allows us to rewrite the goal as \( l_1^{\text{reverse}} <+: l_2^{\text{reverse}} \leftrightarrow l_1^{\text{reverse}} <+: l_2^{\text{reverse}} \). Then, we simplify the expression using the fact that the reverse of the reverse of a list is the original list, i.e., \( (l_1^{\text{reverse}})^{\text{reverse}} = l_1 \) and \( (l_2^{\text{reverse}})^{\text{reverse}} = l_2 \). This simplifies the goal to \( l_1^{\text{reverse}} <+: l_2^{\text{reverse}} \leftrightarrow l_1 <:+ l_2 \). -/
  rw [← reverse_suffix]; simp only [reverse_reverse]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34981,List.infix_append',theorem List.infix_append' (l₁ l₂ l₃ : List α) : l₂ <:+: l₁ ++ (l₂ ++ l₃) := by sorry,"Contiguous Substring in Concatenated Lists: \( l_2 \) is a contiguous substring of \( l_1 ++ (l_2 ++ l_3) \) : For any lists \( l_1 \), \( l_2 \), and \( l_3 \) of elements of type \( \alpha \), the list \( l_2 \) is a contiguous substring of the list \( l_1 ++ (l_2 ++ l_3) \).","theorem List.infix_append' (l₁ l₂ l₃ : List α) : l₂ <:+: l₁ ++ (l₂ ++ l₃) := by
  rw [← List.append_assoc]; apply infix_append","To prove that \( l_2 \) is a contiguous substring of \( l_1 ++ (l_2 ++ l_3) \), we start by using the associativity of list concatenation. The associativity property states that for any lists \( l_1 \), \( l_2 \), and \( l_3 \), the expression \( l_1 ++ (l_2 ++ l_3) \) is equal to \( (l_1 ++ l_2) ++ l_3 \). Therefore, we can rewrite our goal to show that \( l_2 \) is a contiguous substring of \( (l_1 ++ l_2) ++ l_3 \).

Next, we apply the theorem that states \( l_2 \) is a contiguous substring of \( l_1 ++ l_2 \). This theorem directly implies that \( l_2 \) is a contiguous substring of \( (l_1 ++ l_2) ++ l_3 \) because \( l_2 \) is already a contiguous substring of \( l_1 ++ l_2 \), and concatenating \( l_3 \) to the end of \( l_1 ++ l_2 \) does not affect the fact that \( l_2 \) is a contiguous substring.

Thus, we have shown that \( l_2 \) is a contiguous substring of \( l_1 ++ (l_2 ++ l_3) \). This completes the proof.","theorem List.infix_append' (l₁ l₂ l₃ : List α) : l₂ <:+: l₁ ++ (l₂ ++ l₃) := by
/- First, we use the associativity of list concatenation, which states that for any lists \( l_1 \), \( l_2 \), and \( l_3 \), the expression \( l_1 ++ (l_2 ++ l_3) \) is equal to \( (l_1 ++ l_2) ++ l_3 \). This allows us to rewrite the goal to show that \( l_2 \) is a contiguous substring of \( (l_1 ++ l_2) ++ l_3 \). Then, we apply the theorem that states \( l_2 \) is a contiguous substring of \( l_1 ++ l_2 \) to conclude that \( l_2 \) is a contiguous substring of \( (l_1 ++ l_2) ++ l_3 \). -/
  rw [← List.append_assoc]; apply infix_append","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34982,List.sublist_cons_iff,"theorem List.sublist_cons_iff {a : α} {l l'} :
    l <+ a :: l' ↔ l <+ l' ∨ ∃ r, l = a :: r ∧ r <+ l' := by sorry","Sublist Condition for Cons: \( l \subseteq (a :: l') \leftrightarrow l \subseteq l' \lor \exists r, l = a :: r \land r \subseteq l' \) : For any type \( \alpha \) and elements \( a \in \alpha \), lists \( l, l' \) of type \( \alpha \), the list \( l \) is a sublist of \( a :: l' \) if and only if \( l \) is a sublist of \( l' \) or there exists a list \( r \) such that \( l = a :: r \) and \( r \) is a sublist of \( l' \).","theorem List.sublist_cons_iff {a : α} {l l'} :
    l <+ a :: l' ↔ l <+ l' ∨ ∃ r, l = a :: r ∧ r <+ l' := by
  constructor
  · intro h
    cases h with
    | cons _ h => exact Or.inl h
    | cons₂ _ h => exact Or.inr ⟨_, rfl, h⟩
  · rintro (h | ⟨r, rfl, h⟩)
    · exact h.cons _
    · exact h.cons₂ _","To prove the equivalence \( l \subseteq (a :: l') \leftrightarrow l \subseteq l' \lor \exists r, l = a :: r \land r \subseteq l' \), we need to show both directions of the implication.

1. **Forward Direction:**
- Let \( h \) be a proof that \( l \subseteq (a :: l') \).
- We need to show that \( l \subseteq l' \) or there exists a list \( r \) such that \( l = a :: r \) and \( r \subseteq l' \).
- **Case 1:** If \( l \subseteq l' \), then we can directly use \( h \) to show that \( l \subseteq l' \). This satisfies the first disjunct of the goal.
- **Case 2:** If \( l = a :: r \) and \( r \subseteq l' \), then we can use the reflexivity of equality and the fact that \( r \subseteq l' \) to show that \( l = a :: r \) and \( r \subseteq l' \). This satisfies the second disjunct of the goal.

2. **Backward Direction:**
- Let \( h \) be a proof that \( l \subseteq l' \) or there exists a list \( r \) such that \( l = a :: r \) and \( r \subseteq l' \).
- We discuss the two cases:
- **Case 1:** If \( l \subseteq l' \), then by the property of the sublist relation, \( l \subseteq (a :: l') \).
- **Case 2:** If \( l = a :: r \) and \( r \subseteq l' \), then by the property of the sublist relation under cons, \( a :: r \subseteq a :: l' \). Since \( l = a :: r \), it follows that \( l \subseteq (a :: l') \).

Thus, we have shown both directions of the equivalence, completing the proof. \(\blacksquare\)","theorem List.sublist_cons_iff {a : α} {l l'} :
    l <+ a :: l' ↔ l <+ l' ∨ ∃ r, l = a :: r ∧ r <+ l' := by
/- To prove the equivalence \( l \subseteq (a :: l') \leftrightarrow l \subseteq l' \lor \exists r, l = a :: r \land r \subseteq l' \), we need to show both directions of the implication. We start by proving the forward direction and then the backward direction. -/
  constructor
/- Let \( h \) be a proof that \( l \subseteq (a :: l') \). We need to show that \( l \subseteq l' \) or there exists a list \( r \) such that \( l = a :: r \) and \( r \subseteq l' \). -/
  · intro h
    cases h with
/- If \( l \) is a sublist of \( l' \), then we can directly use \( h \) to show that \( l \subseteq l' \). This satisfies the first disjunct of the goal. -/
    | cons _ h => exact Or.inl h
/- If \( l = a :: r \) and \( r \subseteq l' \), then we can use the reflexivity of equality and the fact that \( r \subseteq l' \) to show that \( l = a :: r \) and \( r \subseteq l' \). This satisfies the second disjunct of the goal. -/
    | cons₂ _ h => exact Or.inr ⟨_, rfl, h⟩
/- We now consider the backward direction. Let \( h \) be a proof that \( l \subseteq l' \) or there exists a list \( r \) such that \( l = a :: r \) and \( r \subseteq l' \). We discuss the two cases:
1. \( l \subseteq l' \)
2. There exists a list \( r \) such that \( l = a :: r \) and \( r \subseteq l' \) -/
  · rintro (h | ⟨r, rfl, h⟩)
/- In the first case, if \( l \subseteq l' \), then by the property of the sublist relation, \( l \subseteq (a :: l') \). -/
    · exact h.cons _
/- In the second case, if \( l = a :: r \) and \( r \subseteq l' \), then by the property of the sublist relation under cons, \( a :: r \subseteq a :: l' \). Since \( l = a :: r \), it follows that \( l \subseteq (a :: l') \). -/
    · exact h.cons₂ _","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34984,List.sublist_join_of_mem,theorem List.sublist_join_of_mem {L : List (List α)} {l} (h : l ∈ L) : l <+ L.join := by sorry,"Element of List of Lists is a Sublist of Concatenation: \( l \in L \to l \subseteq \text{join}(L) \) : For any type \( \alpha \) and any list \( L \) of lists of type \( \alpha \), if a list \( l \) is an element of \( L \), then \( l \) is a sublist of the concatenation of all lists in \( L \), i.e., \( l \subseteq \text{join}(L) \).","theorem List.sublist_join_of_mem {L : List (List α)} {l} (h : l ∈ L) : l <+ L.join := by
  induction L with
  | nil => cases h
  | cons l' L ih =>
    rcases mem_cons.1 h with (rfl | h)
    · simp [h]
    · simp [ih h, join_cons, sublist_append_of_sublist_right]","We prove this by induction on the list \( L \).

1. **Base Case:**
- Suppose \( L \) is the empty list, i.e., \( L = [] \).
- If \( l \) is an element of the empty list, this is a contradiction. Therefore, the goal is vacuously true.

2. **Inductive Case:**
- Suppose \( L \) is a cons list, i.e., \( L = l' :: L' \).
- Assume the induction hypothesis: for any list \( l \) in \( L' \), \( l \) is a sublist of \( L'.join \).
- We need to show that if \( l \) is an element of \( l' :: L' \), then \( l \) is a sublist of \( (l' :: L').join \).

We consider two cases based on the membership property of cons lists:
- **Case 1: \( l = l' \)**
- If \( l \) is equal to \( l' \), then \( l \) is the first element of the list \( l' :: L' \).
- Therefore, \( l \) is a sublist of \( (l' :: L').join \), which is trivially true because \( l \) is the first element of the list.
- **Case 2: \( l \in L' \)**
- If \( l \) is an element of \( L' \), then by the induction hypothesis, \( l \) is a sublist of \( L'.join \).
- Since \( (l' :: L').join = l' ++ L'.join \), and a sublist of \( L'.join \) is also a sublist of \( l' ++ L'.join \), it follows that \( l \) is a sublist of \( (l' :: L').join \).

Thus, in both cases, we have shown that if \( l \) is an element of \( L \), then \( l \) is a sublist of \( L.join \). This completes the proof. \(\blacksquare\)","theorem List.sublist_join_of_mem {L : List (List α)} {l} (h : l ∈ L) : l <+ L.join := by
  induction L with
/- We consider the base case where `L` is the empty list. Since `l` is an element of the empty list, this case is impossible. Therefore, the goal is vacuously true. -/
  | nil => cases h
/- We consider the inductive case where `L` is a cons list, i.e., `L = l' :: L'`. We assume the induction hypothesis `ih` that for any list `l` in `L'`, `l` is a sublist of `L'.join`. -/
  | cons l' L ih =>
/- We use the membership property of cons lists to split the assumption `h` into two cases: either `l` is equal to `l'`, or `l` is an element of `L`. -/
    rcases mem_cons.1 h with (rfl | h)
/- In the first case where `l` is equal to `l'`, we simplify the goal using the assumption `h`. This shows that `l` is a sublist of `(l :: L).join`, which is trivially true because `l` is the first element of the list. -/
    · simp [h]
/- We simplify the goal using the induction hypothesis `ih`, the assumption `h`, the definition of `join` for a cons list, and the property that a sublist of a list is also a sublist of the concatenation of that list with another list. This simplification shows that if `l` is a sublist of `L.join`, then `l` is a sublist of `(l' :: L).join`. -/
/- In the second case where `l` is an element of `L`, we simplify the goal using the induction hypothesis `ih`, the assumption `h`, the definition of `join` for a cons list, and the property that a sublist of a list is also a sublist of the concatenation of that list with another list. This simplification shows that if `l` is a sublist of `L.join`, then `l` is a sublist of `(l' :: L).join`. -/
    · simp [ih h, join_cons, sublist_append_of_sublist_right]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34986,List.IsInfix.filter,"theorem List.IsInfix.filter (p : α → Bool) ⦃l₁ l₂ : List α⦄ (h : l₁ <:+: l₂) :
    l₁.filter p <:+: l₂.filter p := by sorry","Filtering Preserves Contiguous Substring Property in Lists : For any type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), if a list \( l_1 \) is a contiguous substring of a list \( l_2 \), then the list obtained by filtering \( l_1 \) with \( p \) is a contiguous substring of the list obtained by filtering \( l_2 \) with \( p \). In other words, if \( l_1 \) is a contiguous substring of \( l_2 \), then \( \text{filter } p \, l_1 \) is a contiguous substring of \( \text{filter } p \, l_2 \).","theorem List.IsInfix.filter (p : α → Bool) ⦃l₁ l₂ : List α⦄ (h : l₁ <:+: l₂) :
    l₁.filter p <:+: l₂.filter p := by
  obtain ⟨xs, ys, rfl⟩ := h
  rw [filter_append, filter_append]; apply infix_append _","Assume \( l_1 \) is a contiguous substring of \( l_2 \). By the definition of a contiguous substring, there exist lists \( xs \) and \( ys \) such that \( l_2 = xs ++ l_1 ++ ys \).

Next, we use the property of the filter operation on lists, which states that the filter of a concatenation of lists is the concatenation of the filters of the individual lists. Therefore, we have:
\[ \text{filter } p \, (xs ++ l_1 ++ ys) = (\text{filter } p \, xs) ++ (\text{filter } p \, l_1) ++ (\text{filter } p \, ys) \]

This means that \( \text{filter } p \, l_1 \) is a contiguous substring of \( (\text{filter } p \, xs) ++ (\text{filter } p \, l_1) ++ (\text{filter } p \, ys) \). By the definition of a contiguous substring, \( \text{filter } p \, l_1 \) is indeed a contiguous substring of \( \text{filter } p \, l_2 \).

Thus, we have shown that if \( l_1 \) is a contiguous substring of \( l_2 \), then \( \text{filter } p \, l_1 \) is a contiguous substring of \( \text{filter } p \, l_2 \). This completes the proof.","theorem List.IsInfix.filter (p : α → Bool) ⦃l₁ l₂ : List α⦄ (h : l₁ <:+: l₂) :
    l₁.filter p <:+: l₂.filter p := by
/- Since \( l_1 \) is a contiguous substring of \( l_2 \), there exist lists \( xs \) and \( ys \) such that \( l_2 = xs ++ l_1 ++ ys \). This is given by the assumption \( h \). -/
  obtain ⟨xs, ys, rfl⟩ := h
/- Using the property that the filter of a concatenation of lists is the concatenation of the filters of the individual lists, we can rewrite the goal. Specifically, we have:
\[ \text{filter } p \, (xs ++ l_1 ++ ys) = (\text{filter } p \, xs) ++ (\text{filter } p \, l_1) ++ (\text{filter } p \, ys) \]
Thus, the goal reduces to showing that \( \text{filter } p \, l_1 \) is a contiguous substring of \( (\text{filter } p \, xs) ++ (\text{filter } p \, l_1) ++ (\text{filter } p \, ys) \). This is true by the definition of a contiguous substring, as \( \text{filter } p \, l_1 \) is exactly the middle part of the concatenated list. -/
  rw [filter_append, filter_append]; apply infix_append _","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open IsInfix
open Nat
variable [BEq α]
variable [BEq α]
"
34987,List.Sublist.map,theorem List.Sublist.map (f : α → β) {l₁ l₂} (s : l₁ <+ l₂) : map f l₁ <+ map f l₂ := by sorry,"Sublist Preservation under Mapping: \( l_1 \subseteq l_2 \implies \text{map } f \, l_1 \subseteq \text{map } f \, l_2 \) : For any types \( \alpha \) and \( \beta \), and for any function \( f : \alpha \to \beta \), if \( l_1 \) is a sublist of \( l_2 \), then the list obtained by applying `map` to \( l_1 \) is a sublist of the list obtained by applying `map` to \( l_2 \). In other words, if \( l_1 \subseteq l_2 \), then \( \text{map } f \, l_1 \subseteq \text{map } f \, l_2 \).","theorem List.Sublist.map (f : α → β) {l₁ l₂} (s : l₁ <+ l₂) : map f l₁ <+ map f l₂ := by
  induction s with
  | slnil => simp
  | cons a s ih =>
    simpa using cons (f a) ih
  | cons₂ a s ih =>
    simpa using cons₂ (f a) ih","We prove this by induction on the structure of the sublist relation.

1. **Base Case:**
- Consider the case where \( l_1 \) and \( l_2 \) are both empty lists. The map of an empty list is an empty list, so \( \text{map } f \, [] = [] \). Since the empty list is a sublist of itself, the base case is trivially true.

2. **Inductive Step:**
- **Case 1:**
- Assume \( l_1 = a :: l_1' \) and \( l_2 = a :: l_2' \), and \( l_1' \) is a sublist of \( l_2' \). By the induction hypothesis, \( \text{map } f \, l_1' \) is a sublist of \( \text{map } f \, l_2' \). Using the property that if \( l_1' \) is a sublist of \( l_2' \), then adding the same element \( f(a) \) to the front of both lists results in \( f(a) :: \text{map } f \, l_1' \) being a sublist of \( f(a) :: \text{map } f \, l_2' \), we have \( \text{map } f \, (a :: l_1') \) is a sublist of \( \text{map } f \, (a :: l_2') \). This completes the proof for this case.
- **Case 2:**
- Assume \( l_1 = a :: l_1' \) and \( l_2 = a :: l_2' \), and \( l_1' \) is a sublist of \( l_2' \). By the induction hypothesis, \( \text{map } f \, l_1' \) is a sublist of \( \text{map } f \, l_2' \). Using the property that if \( l_1' \) is a sublist of \( l_2' \), then adding the same element \( f(a) \) to the front of both lists results in \( f(a) :: \text{map } f \, l_1' \) being a sublist of \( f(a) :: \text{map } f \, l_2' \), we have \( \text{map } f \, (a :: l_1') \) is a sublist of \( \text{map } f \, (a :: l_2') \). This completes the proof for this case.

By induction, we have shown that if \( l_1 \) is a sublist of \( l_2 \), then \( \text{map } f \, l_1 \) is a sublist of \( \text{map } f \, l_2 \). This completes the proof.","theorem List.Sublist.map (f : α → β) {l₁ l₂} (s : l₁ <+ l₂) : map f l₁ <+ map f l₂ := by
  induction s with
/- Consider the base case where \( l_1 \) and \( l_2 \) are both empty lists. Using the fact that the map of an empty list is an empty list, we can simplify the goal to show that the empty list is a sublist of the empty list, which is trivially true. -/
  | slnil => simp
/- Consider the case where \( l_1 \) and \( l_2 \) are non-empty lists, and \( l_1 \) is a sublist of \( l_2 \). We assume \( l_1 = a :: l_1' \) and \( l_2 = a :: l_2' \), and we have the induction hypothesis that \( \text{map } f \, l_1' \) is a sublist of \( \text{map } f \, l_2' \). -/
  | cons a s ih =>
/- Using the property that if \( l_1' \) is a sublist of \( l_2' \), then adding the same element \( f(a) \) to the front of both lists results in \( f(a) :: \text{map } f \, l_1' \) being a sublist of \( f(a) :: \text{map } f \, l_2' \), and the induction hypothesis that \( \text{map } f \, l_1' \) is a sublist of \( \text{map } f \, l_2' \), we can simplify the goal to show that \( \text{map } f \, (a :: l_1') \) is a sublist of \( \text{map } f \, (a :: l_2') \). This simplification shows that the goal is exactly what we need to prove, thus finishing this case. -/
    simpa using cons (f a) ih
/- Consider the case where \( l_1 \) and \( l_2 \) are non-empty lists, and \( l_1 \) is a sublist of \( l_2 \). We assume \( l_1 = a :: l_1' \) and \( l_2 = a :: l_2' \), and we have the induction hypothesis that \( \text{map } f \, l_1' \) is a sublist of \( \text{map } f \, l_2' \). -/
  | cons₂ a s ih =>
/- Using the property that if \( l_1 \) is a sublist of \( l_2 \), then adding the same element \( a \) to the front of both lists results in \( a :: l_1 \) being a sublist of \( a :: l_2 \), and the induction hypothesis that \( \text{map } f \, l_1 \) is a sublist of \( \text{map } f \, l_2 \), we can simplify the goal to show that \( \text{map } f \, (a :: l_1) \) is a sublist of \( \text{map } f \, (a :: l_2) \). This simplification shows that the goal is exactly what we need to prove, thus finishing this case. -/
/- Using the property that if \( l_1' \) is a sublist of \( l_2' \), then adding the same element \( f(a) \) to the front of both lists results in \( f(a) :: \text{map } f \, l_1' \) being a sublist of \( f(a) :: \text{map } f \, l_2' \), and the induction hypothesis that \( \text{map } f \, l_1' \) is a sublist of \( \text{map } f \, l_2' \), we can simplify the goal to show that \( \text{map } f \, (a :: l_1') \) is a sublist of \( \text{map } f \, (a :: l_2') \). This simplification shows that the goal is exactly what we need to prove, thus finishing this case. -/
    simpa using cons₂ (f a) ih","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Sublist
open Nat
variable [BEq α]
variable [BEq α]
"
34991,List.replicate_sublist_replicate,"theorem List.replicate_sublist_replicate {m n} (a : α) :
    replicate m a <+ replicate n a ↔ m ≤ n := by sorry","Sublist Condition for Replicated Lists: \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a) \leftrightarrow m \leq n\) : For any natural numbers \( m \) and \( n \) and any element \( a \) of type \( \alpha \), the list containing \( m \) copies of \( a \) is a sublist of the list containing \( n \) copies of \( a \) if and only if \( m \leq n \). In other words, \( \text{replicate}(m, a) \subseteq \text{replicate}(n, a) \) if and only if \( m \leq n \).","theorem List.replicate_sublist_replicate {m n} (a : α) :
    replicate m a <+ replicate n a ↔ m ≤ n := by
  refine ⟨fun h => ?_, fun h => ?_⟩
  · have := h.length_le; simp only [length_replicate] at this ⊢; exact this
  · induction h with
    | refl => apply Sublist.refl
    | step => simp [*, replicate, Sublist.cons]","To prove the bi-implication \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a) \leftrightarrow m \leq n\), we need to show both directions.

1. **(\(\Rightarrow\)) If \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\), then \(m \leq n\):**
- Assume \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\).
- By the property of sublists, if \(\text{replicate}(m, a)\) is a sublist of \(\text{replicate}(n, a)\), then the length of \(\text{replicate}(m, a)\) is less than or equal to the length of \(\text{replicate}(n, a)\).
- Since the length of \(\text{replicate}(m, a)\) is \(m\) and the length of \(\text{replicate}(n, a)\) is \(n\), we have \(m \leq n\).

2. **(\(\Leftarrow\)) If \(m \leq n\), then \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\):**
- We use induction on the natural number \(n\).
- **Base case:** If \(m = n\), then \(\text{replicate}(m, a) = \text{replicate}(n, a)\). By the reflexivity of the sublist relation, \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\).
- **Inductive step:** Assume \(m \leq n\) and \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\). We need to show that \(\text{replicate}(m, a) \subseteq \text{replicate}(n + 1, a)\).
- By the definition of \(\text{replicate}\), \(\text{replicate}(n + 1, a) = a :: \text{replicate}(n, a)\).
- Since \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\), and adding \(a\) to the front of both lists preserves the sublist relation, we have \(\text{replicate}(m, a) \subseteq \text{replicate}(n + 1, a)\).

Thus, we have shown both directions, and the theorem is proved. \(\blacksquare\)","theorem List.replicate_sublist_replicate {m n} (a : α) :
    replicate m a <+ replicate n a ↔ m ≤ n := by
/- To prove the bi-implication \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a) \leftrightarrow m \leq n\), we need to show both directions. First, we assume \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\) and show \(m \leq n\). Second, we assume \(m \leq n\) and show \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\). -/
  refine ⟨fun h => ?_, fun h => ?_⟩
/- First, we show that if \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\), then \(m \leq n\). By the property of sublists, if \(\text{replicate}(m, a)\) is a sublist of \(\text{replicate}(n, a)\), then the length of \(\text{replicate}(m, a)\) is less than or equal to the length of \(\text{replicate}(n, a)\). Since the length of \(\text{replicate}(m, a)\) is \(m\) and the length of \(\text{replicate}(n, a)\) is \(n\), we have \(m \leq n\). -/
  · have := h.length_le; simp only [length_replicate] at this ⊢; exact this
/- Next, we show that if \(m \leq n\), then \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\). We use induction on the natural number \(n\). -/
  · induction h with
/- For the base case, if \(m = n\), then \(\text{replicate}(m, a) = \text{replicate}(n, a)\). By the reflexivity of the sublist relation, \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\). -/
    | refl => apply Sublist.refl
/- For the inductive step, assume \(m \leq n\) and \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\). We need to show that \(\text{replicate}(m, a) \subseteq \text{replicate}(n + 1, a)\). By the definition of \(\text{replicate}\), \(\text{replicate}(n + 1, a) = a :: \text{replicate}(n, a)\). Since \(\text{replicate}(m, a) \subseteq \text{replicate}(n, a)\), and adding \(a\) to the front of both lists preserves the sublist relation, we have \(\text{replicate}(m, a) \subseteq \text{replicate}(n + 1, a)\). -/
    | step => simp [*, replicate, Sublist.cons]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
34992,List.IsPrefix.filter,"theorem List.IsPrefix.filter (p : α → Bool) ⦃l₁ l₂ : List α⦄ (h : l₁ <+: l₂) :
    l₁.filter p <+: l₂.filter p := by sorry","Filtering Preserves Prefix Relationship in Lists : For any type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), if the list \( l_1 \) is a prefix of the list \( l_2 \), then the list obtained by filtering \( l_1 \) with \( p \) is a prefix of the list obtained by filtering \( l_2 \) with \( p \). In other words, if \( l_1 \) is a prefix of \( l_2 \), then \( \text{filter } p \, l_1 \) is a prefix of \( \text{filter } p \, l_2 \).","theorem List.IsPrefix.filter (p : α → Bool) ⦃l₁ l₂ : List α⦄ (h : l₁ <+: l₂) :
    l₁.filter p <+: l₂.filter p := by
  obtain ⟨xs, rfl⟩ := h
  rw [filter_append]; apply prefix_append","Assume \( l_1 \) is a prefix of \( l_2 \). By the definition of prefix, there exists a list \( xs \) such that \( l_2 = l_1 ++ xs \). We need to show that \( \text{filter } p \, l_1 \) is a prefix of \( \text{filter } p \, l_2 \).

Using the property of the filter operation, we have:
\[
\text{filter } p \, (l_1 ++ xs) = \text{filter } p \, l_1 ++ \text{filter } p \, xs
\]
Thus, \( \text{filter } p \, l_2 = \text{filter } p \, l_1 ++ \text{filter } p \, xs \).

By the definition of prefix, \( \text{filter } p \, l_1 \) is a prefix of \( \text{filter } p \, l_1 ++ \text{filter } p \, xs \). Therefore, \( \text{filter } p \, l_1 \) is a prefix of \( \text{filter } p \, l_2 \).

This completes the proof.","theorem List.IsPrefix.filter (p : α → Bool) ⦃l₁ l₂ : List α⦄ (h : l₁ <+: l₂) :
    l₁.filter p <+: l₂.filter p := by
/- Since \( l_1 \) is a prefix of \( l_2 \), there exists a list \( xs \) such that \( l_2 = l_1 ++ xs \). We can rewrite \( l_2 \) as \( l_1 ++ xs \) using the definition of prefix. -/
  obtain ⟨xs, rfl⟩ := h
/- Using the property that the filter of a concatenation of two lists is the concatenation of their filters, we have \( \text{filter } p \, (l_1 ++ xs) = \text{filter } p \, l_1 ++ \text{filter } p \, xs \). Therefore, to show that \( \text{filter } p \, l_1 \) is a prefix of \( \text{filter } p \, l_2 \), it suffices to show that \( \text{filter } p \, l_1 \) is a prefix of \( \text{filter } p \, l_1 ++ \text{filter } p \, xs \). This is true by the definition of prefix, as \( \text{filter } p \, l_1 \) is the first part of the concatenation. -/
  rw [filter_append]; apply prefix_append","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open IsPrefix
open Nat
variable [BEq α]
variable [BEq α]
"
34993,List.isPrefixOf_iff_prefix,"theorem List.isPrefixOf_iff_prefix [BEq α] [LawfulBEq α] {l₁ l₂ : List α} :
    l₁.isPrefixOf l₂ ↔ l₁ <+: l₂ := by sorry","Boolean Prefix Check is Equivalent to List Prefix Relation: \( l_1 \text{ is a prefix of } l_2 \leftrightarrow l_1 <+: l_2 \) : For any type \( \alpha \) with a decidable equality, and for any two lists \( l_1 \) and \( l_2 \) of type \( \alpha \), the boolean function `isPrefixOf` returns `true` if and only if \( l_1 \) is a prefix of \( l_2 \). Formally, \( l_1 \) is a prefix of \( l_2 \) (denoted as \( l_1 <+: l_2 \)) if and only if there exists a list \( t \) such that \( l_2 = l_1 ++ t \).","theorem List.isPrefixOf_iff_prefix [BEq α] [LawfulBEq α] {l₁ l₂ : List α} :
    l₁.isPrefixOf l₂ ↔ l₁ <+: l₂ := by
  induction l₁ generalizing l₂ with
  | nil => simp
  | cons a l₁ ih =>
    cases l₂ with
    | nil => simp
    | cons a' l₂ => simp [isPrefixOf, ih]","We prove the theorem by induction on the list \( l_1 \).

1. **Base Case: \( l_1 \) is the empty list.**
- We need to show that `isPrefixOf [] l_2` returns `true` if and only if \( [] <+: l_2 \).
- By the definition of `isPrefixOf`, `isPrefixOf [] l_2` always returns `true`.
- By the definition of the prefix relation, the empty list is a prefix of any list \( l_2 \).
- Therefore, the base case holds.

2. **Inductive Step: \( l_1 \) is a non-empty list, specifically \( l_1 = a :: l_1' \).**
- Assume the induction hypothesis: for any list \( l_2 \), \( l_1' \) is a prefix of \( l_2 \) if and only if `isPrefixOf l_1' l_2` returns `true`.
- We need to show that \( a :: l_1' \) is a prefix of \( l_2 \) if and only if `isPrefixOf (a :: l_1') l_2` returns `true`.
- Consider the case where \( l_2 \) is a non-empty list, specifically \( l_2 = a' :: l_2' \).
- By the definition of `isPrefixOf`, `isPrefixOf (a :: l_1') (a' :: l_2')` returns `true` if and only if \( a = a' \) and `isPrefixOf l_1' l_2'` returns `true`.
- By the induction hypothesis, `isPrefixOf l_1' l_2'` returns `true` if and only if \( l_1' \) is a prefix of \( l_2' \).
- Therefore, \( a :: l_1' \) is a prefix of \( a' :: l_2' \) if and only if \( a = a' \) and \( l_1' \) is a prefix of \( l_2' \).

By induction, the theorem holds for all lists \( l_1 \) and \( l_2 \). This completes the proof. \(\blacksquare\)","theorem List.isPrefixOf_iff_prefix [BEq α] [LawfulBEq α] {l₁ l₂ : List α} :
    l₁.isPrefixOf l₂ ↔ l₁ <+: l₂ := by
  induction l₁ generalizing l₂ with
/- First, consider the case where \( l_1 \) is the empty list. Using the definition of `isPrefixOf` and the properties of the empty list, we can simplify the proposition to show that the boolean function `isPrefixOf` returns `true` for the empty list and any list \( l_2 \), and that the empty list is a prefix of any list \( l_2 \). This is trivially true. -/
  | nil => simp
/- Next, consider the case where \( l_1 \) is a non-empty list, specifically \( l_1 = a :: l_1' \). We perform induction on \( l_1 \) and assume the induction hypothesis \( \text{ih} \), which states that for any list \( l_2 \), \( l_1' \) is a prefix of \( l_2 \) if and only if `isPrefixOf l_1' l_2` returns `true`. -/
  | cons a l₁ ih =>
    cases l₂ with
    | nil => simp
/- Now, consider the case where \( l_2 \) is a non-empty list, specifically \( l_2 = a' :: l_2' \). Using the definition of `isPrefixOf` and the induction hypothesis, we can simplify the proposition to show that \( a :: l_1' \) is a prefix of \( a' :: l_2' \) if and only if `isPrefixOf (a :: l_1') (a' :: l_2')` returns `true`. This simplifies to showing that \( a = a' \) and \( l_1' \) is a prefix of \( l_2' \), which is exactly what the induction hypothesis states. -/
    | cons a' l₂ => simp [isPrefixOf, ih]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
35003,List.isPrefixOf_replicate,"theorem List.isPrefixOf_replicate {a : α} :
    isPrefixOf l (replicate n a) = (decide (l.length ≤ n) && l.all (· == a)) := by sorry","List is a Prefix of Replicated List if and only if Length Condition and All Elements are Equal: \( l.\text{isPrefixOf} (\text{replicate } n \, a) \leftrightarrow (|l| \le n \, \text{and} \, \forall x \in l, \, x = a) \) : For any type \( \alpha \) and any list \( l \) of elements of type \( \alpha \), and for any natural number \( n \) and any element \( a \) of type \( \alpha \), the list \( l \) is a prefix of the list `replicate n a` if and only if the length of \( l \) is less than or equal to \( n \) and every element in \( l \) is equal to \( a \). Formally, this can be written as:
\[
l.\text{isPrefixOf} (\text{replicate } n \, a) = (\text{decide } (|l| \le n) \, \text{and} \, \forall x \in l, \, x = a)
\]
where \( |l| \) denotes the length of the list \( l \).","theorem List.isPrefixOf_replicate {a : α} :
    isPrefixOf l (replicate n a) = (decide (l.length ≤ n) && l.all (· == a)) := by
  induction l generalizing n with
  | nil => simp
  | cons h t ih =>
    cases n
    · simp
    · simp [replicate_succ, isPrefixOf_cons₂, ih, Nat.succ_le_succ_iff, Bool.and_left_comm]","We prove this by induction on the list \( l \).

**Base Case:**
Consider the case where \( l \) is the empty list. We need to show that the empty list is a prefix of `replicate n a` if and only if the length of the empty list is less than or equal to \( n \) and every element in the empty list is equal to \( a \). This is trivially true because the length of the empty list is \( 0 \), which is always less than or equal to any natural number \( n \), and the condition on elements is vacuously true.

**Inductive Step:**
Assume the induction hypothesis: for any natural number \( m \), \( t \) is a prefix of `replicate m a` if and only if the length of \( t \) is less than or equal to \( m \) and every element in \( t \) is equal to \( a \).

Consider the list \( l = h :: t \). We need to show that \( h :: t \) is a prefix of `replicate n a` if and only if the length of \( h :: t \) is less than or equal to \( n \) and every element in \( h :: t \) is equal to \( a \).

We perform case analysis on \( n \):

1. **Case \( n = 0 \):**
- The goal is to show that \( h :: t \) is a prefix of the empty list if and only if the length of \( h :: t \) is less than or equal to \( 0 \) and every element in \( h :: t \) is equal to \( a \). This is trivially false because the length of \( h :: t \) is at least \( 1 \), which is not less than or equal to \( 0 \).

2. **Case \( n = m + 1 \):**
- The goal is to show that \( h :: t \) is a prefix of `a :: replicate m a` if and only if \( h = a \) and \( t \) is a prefix of `replicate m a`.
- By the definition of `isPrefixOf`, \( h :: t \) is a prefix of `a :: replicate m a` if and only if \( h = a \) and \( t \) is a prefix of `replicate m a`.
- By the induction hypothesis, \( t \) is a prefix of `replicate m a` if and only if the length of \( t \) is less than or equal to \( m \) and every element in \( t \) is equal to \( a \).
- Therefore, \( h :: t \) is a prefix of `a :: replicate m a` if and only if \( h = a \) and the length of \( t \) is less than or equal to \( m \) and every element in \( t \) is equal to \( a \).

This completes the proof. \(\blacksquare\)","theorem List.isPrefixOf_replicate {a : α} :
    isPrefixOf l (replicate n a) = (decide (l.length ≤ n) && l.all (· == a)) := by
  induction l generalizing n with
/- We consider the base case where the list \( l \) is empty. Using the definition of `isPrefixOf` and the properties of the empty list, we simplify the goal to show that the empty list is a prefix of `replicate n a` if and only if the length of the empty list is less than or equal to \( n \) and every element in the empty list is equal to \( a \). This is trivially true because the length of the empty list is \( 0 \), which is always less than or equal to any natural number \( n \), and the condition on elements is vacuously true. -/
  | nil => simp
/- We consider the inductive case where the list \( l \) is of the form \( h :: t \). We assume the induction hypothesis `ih`, which states that for any natural number \( n \), \( t \) is a prefix of `replicate n a` if and only if the length of \( t \) is less than or equal to \( n \) and every element in \( t \) is equal to \( a \). -/
  | cons h t ih =>
/- We perform case analysis on the natural number \( n \). We consider two cases:
1. \( n = 0 \)
2. \( n = m + 1 \) for some natural number \( m \) -/
    cases n
/- For the case \( n = 0 \), we simplify the goal using the definition of `replicate 0 a`, which is the empty list. The goal is to show that \( (h :: t) \) is a prefix of the empty list if and only if the length of \( h :: t \) is less than or equal to \( 0 \) and every element in \( h :: t \) is equal to \( a \). This is trivially false because the length of \( h :: t \) is at least \( 1 \), which is not less than or equal to \( 0 \). -/
    · simp
/- First, we simplify the goal using the following lemmas:
- The definition of `replicate (n + 1) a` is `a :: replicate n a`.
- The definition of `isPrefixOf (h :: t) (a :: l)` is `h == a ∧ t.isPrefixOf l`.
- The induction hypothesis `ih` states that for any natural number \( n \), \( t \) is a prefix of `replicate n a` if and only if the length of \( t \) is less than or equal to \( n \) and every element in \( t \) is equal to \( a \).
- The property that \( n + 1 \le m + 1 \) is equivalent to \( n \le m \).
- The left commutativity of conjunction, which states that \( a \land b \land c \) is equivalent to \( b \land a \land c \).

After simplification, the goal is reduced to showing that \( (h :: t) \) is a prefix of `replicate (n + 1) a` if and only if the length of \( h :: t \) is less than or equal to \( n + 1 \) and every element in \( h :: t \) is equal to \( a \). -/
/- For the case \( n = m + 1 \), we simplify the goal using the following lemmas:
- The definition of `replicate (m + 1) a` is `a :: replicate m a`.
- The definition of `isPrefixOf (h :: t) (a :: l)` is `h == a ∧ t.isPrefixOf l`.
- The induction hypothesis `ih` states that for any natural number \( m \), \( t \) is a prefix of `replicate m a` if and only if the length of \( t \) is less than or equal to \( m \) and every element in \( t \) is equal to \( a \).
- The property that \( n + 1 \le m + 1 \) is equivalent to \( n \le m \).
- The left commutativity of conjunction, which states that \( a \land b \land c \) is equivalent to \( b \land a \land c \).

After simplification, the goal is reduced to showing that \( (h :: t) \) is a prefix of `a :: replicate m a` if and only if \( h = a \) and \( t \) is a prefix of `replicate m a`. By the induction hypothesis, this is equivalent to \( h = a \) and the length of \( t \) is less than or equal to \( m \) and every element in \( t \) is equal to \( a \). This completes the proof. -/
    · simp [replicate_succ, isPrefixOf_cons₂, ih, Nat.succ_le_succ_iff, Bool.and_left_comm]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
"
35014,List.suffix_cons_iff,theorem List.suffix_cons_iff : l₁ <:+ a :: l₂ ↔ l₁ = a :: l₂ ∨ l₁ <:+ l₂ := by sorry,"Suffix of Cons List: \( l_1 \text{ is a suffix of } a :: l_2 \iff l_1 = a :: l_2 \lor l_1 \text{ is a suffix of } l_2 \) : For any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \) and any element \( a \) of type \( \alpha \), the list \( l_1 \) is a suffix of the list \( a :: l_2 \) if and only if \( l_1 \) is equal to \( a :: l_2 \) or \( l_1 \) is a suffix of \( l_2 \). This can be written as:
\[ l_1 \text{ is a suffix of } a :: l_2 \iff l_1 = a :: l_2 \lor l_1 \text{ is a suffix of } l_2. \]","theorem List.suffix_cons_iff : l₁ <:+ a :: l₂ ↔ l₁ = a :: l₂ ∨ l₁ <:+ l₂ := by
  constructor
  · rintro ⟨⟨hd, tl⟩, hl₃⟩
    · exact Or.inl hl₃
    · simp only [cons_append] at hl₃
      injection hl₃ with _ hl₄
      exact Or.inr ⟨_, hl₄⟩
  · rintro (rfl | hl₁)
    · exact (a :: l₂).suffix_refl
    · exact hl₁.trans (l₂.suffix_cons _)","To prove the equivalence, we need to show both directions of the implication.

1. **(\(\Rightarrow\)) If \( l_1 \) is a suffix of \( a :: l_2 \), then \( l_1 = a :: l_2 \) or \( l_1 \) is a suffix of \( l_2 \):**
- Assume \( l_1 \) is a suffix of \( a :: l_2 \). This means there exist lists \( \text{hd} \) and \( \text{tl} \) such that \( \text{hd} :: \text{tl} ++ l_1 = a :: l_2 \).
- Simplify the equation to \( \text{hd} :: (\text{tl} ++ l_1) = a :: l_2 \).
- By the injectivity of the cons operation, we have \( \text{hd} = a \) and \( \text{tl} ++ l_1 = l_2 \).
- Therefore, \( l_1 = a :: l_2 \) or \( l_1 \) is a suffix of \( l_2 \).

2. **(\(\Leftarrow\)) If \( l_1 = a :: l_2 \) or \( l_1 \) is a suffix of \( l_2 \), then \( l_1 \) is a suffix of \( a :: l_2 \):**
- **Case 1:** If \( l_1 = a :: l_2 \), then \( l_1 \) is a suffix of \( a :: l_2 \) by the reflexivity of the suffix relation.
- **Case 2:** If \( l_1 \) is a suffix of \( l_2 \), then \( l_1 \) is a suffix of \( a :: l_2 \) by the transitivity of the suffix relation, since \( l_2 \) is a suffix of \( a :: l_2 \).

Thus, we have shown both directions of the equivalence, completing the proof. \(\blacksquare\)","theorem List.suffix_cons_iff : l₁ <:+ a :: l₂ ↔ l₁ = a :: l₂ ∨ l₁ <:+ l₂ := by
/- To prove the equivalence \( l_1 \text{ is a suffix of } a :: l_2 \iff l_1 = a :: l_2 \lor l_1 \text{ is a suffix of } l_2 \), we need to show both directions of the implication. First, we show that if \( l_1 \) is a suffix of \( a :: l_2 \), then \( l_1 = a :: l_2 \) or \( l_1 \) is a suffix of \( l_2 \). Second, we show that if \( l_1 = a :: l_2 \) or \( l_1 \) is a suffix of \( l_2 \), then \( l_1 \) is a suffix of \( a :: l_2 \). -/
  constructor
/- Let \( l_1 \) be a suffix of \( a :: l_2 \). This means there exist lists \( \text{hd} \) and \( \text{tl} \) such that \( \text{hd} :: \text{tl} ++ l_1 = a :: l_2 \). We need to show that \( l_1 = a :: l_2 \) or \( l_1 \) is a suffix of \( l_2 \). -/
  · rintro ⟨⟨hd, tl⟩, hl₃⟩
/- Since \( \text{hd} :: \text{tl} ++ l_1 = a :: l_2 \), we have \( l_1 = a :: l_2 \). Therefore, \( l_1 = a :: l_2 \) or \( l_1 \) is a suffix of \( l_2 \) holds, and we are done with this direction. -/
    · exact Or.inl hl₃
/- Simplify the equation \( \text{hd} :: \text{tl} ++ l_1 = a :: l_2 \) to \( \text{hd} :: (\text{tl} ++ l_1) = a :: l_2 \). -/
    · simp only [cons_append] at hl₃
/- By the injectivity of the cons operation, we can conclude that \( \text{hd} = a \) and \( \text{tl} ++ l_1 = l_2 \). -/
      injection hl₃ with _ hl₄
/- Since \( \text{tl} ++ l_1 = l_2 \), we have \( l_1 \) is a suffix of \( l_2 \). Therefore, \( l_1 = a :: l_2 \) or \( l_1 \) is a suffix of \( l_2 \) holds, and we are done with this direction. -/
      exact Or.inr ⟨_, hl₄⟩
/- Now, we consider the other direction. We need to show that if \( l_1 = a :: l_2 \) or \( l_1 \) is a suffix of \( l_2 \), then \( l_1 \) is a suffix of \( a :: l_2 \). We discuss by cases:
1. If \( l_1 = a :: l_2 \), then \( l_1 \) is a suffix of \( a :: l_2 \) by the reflexivity of the suffix relation.
2. If \( l_1 \) is a suffix of \( l_2 \), then \( l_1 \) is a suffix of \( a :: l_2 \) by the transitivity of the suffix relation. -/
  · rintro (rfl | hl₁)
/- If \( l_1 = a :: l_2 \), then \( l_1 \) is a suffix of \( a :: l_2 \) by the reflexivity of the suffix relation. -/
    · exact (a :: l₂).suffix_refl
/- If \( l_1 \) is a suffix of \( l_2 \), then \( l_1 \) is a suffix of \( a :: l_2 \) by the transitivity of the suffix relation, since \( l_2 \) is a suffix of \( a :: l_2 \). -/
    · exact hl₁.trans (l₂.suffix_cons _)","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
35033,List.sublist_replicate_iff,"theorem List.sublist_replicate_iff : l <+ replicate m a ↔ ∃ n, n ≤ m ∧ l = replicate n a := by sorry","Sublist of Replicated List Characterization : For any list \( l \) of elements of type \( \alpha \), and for any natural number \( m \) and element \( a \) of type \( \alpha \), the list \( l \) is a sublist of the list containing \( m \) copies of \( a \) if and only if there exists a natural number \( n \) such that \( n \leq m \) and \( l \) is equal to the list containing \( n \) copies of \( a \).","theorem List.sublist_replicate_iff : l <+ replicate m a ↔ ∃ n, n ≤ m ∧ l = replicate n a := by
  induction l generalizing m with
  | nil =>
    simp only [nil_sublist, true_iff]
    exact ⟨0, zero_le m, by simp⟩
  | cons b l ih =>
    constructor
    · intro w
      cases m with
      | zero => simp at w
      | succ m =>
        simp [replicate_succ] at w
        cases w with
        | cons _ w =>
          obtain ⟨n, le, rfl⟩ := ih.1 (sublist_of_cons_sublist w)
          obtain rfl := (mem_replicate.1 (mem_of_cons_sublist w)).2
          exact ⟨n+1, Nat.add_le_add_right le 1, rfl⟩
        | cons₂ _ w =>
          obtain ⟨n, le, rfl⟩ := ih.1 w
          refine ⟨n+1, Nat.add_le_add_right le 1, by simp [replicate_succ]⟩
    · rintro ⟨n, le, w⟩
      rw [w]
      exact (replicate_sublist_replicate a).2 le","We prove the theorem by induction on the list \( l \).

1. **Base Case:**
- If \( l \) is the empty list, we need to show that the empty list is a sublist of \( \text{replicate}(m, a) \) if and only if there exists \( n \) such that \( n \leq m \) and the empty list is equal to \( \text{replicate}(n, a) \).
- The empty list is a sublist of any list, and \( \text{replicate}(0, a) \) is the empty list. Therefore, the base case holds with \( n = 0 \).

2. **Inductive Step:**
- Assume the inductive hypothesis: for any list \( l' \) and any natural number \( m \), \( l' \) is a sublist of \( \text{replicate}(m, a) \) if and only if there exists \( n \) such that \( n \leq m \) and \( l' = \text{replicate}(n, a) \).
- Consider the list \( l = b :: l' \).

- **Direction 1:**
- Suppose \( b :: l' \) is a sublist of \( \text{replicate}(m, a) \).
- By the inductive hypothesis, \( l' \) is a sublist of \( \text{replicate}(m, a) \), so there exists \( n \) such that \( n \leq m \) and \( l' = \text{replicate}(n, a) \).
- Since \( b \) is a member of \( \text{replicate}(m, a) \), it follows that \( b = a \).
- Therefore, \( b :: l' = a :: \text{replicate}(n, a) = \text{replicate}(n + 1, a) \).
- Since \( n + 1 \leq m + 1 \), \( b :: l' \) is a sublist of \( \text{replicate}(m + 1, a) \).

- **Direction 2:**
- Suppose there exists \( n \) such that \( n \leq m \) and \( b :: l' = \text{replicate}(n, a) \).
- Since \( b :: l' = \text{replicate}(n, a) \), it follows that \( b = a \) and \( l' = \text{replicate}(n - 1, a) \).
- By the inductive hypothesis, \( l' \) is a sublist of \( \text{replicate}(m, a) \).
- Therefore, \( b :: l' = a :: \text{replicate}(n - 1, a) = \text{replicate}(n, a) \) is a sublist of \( \text{replicate}(m, a) \).

This completes the proof. \(\blacksquare\)","theorem List.sublist_replicate_iff : l <+ replicate m a ↔ ∃ n, n ≤ m ∧ l = replicate n a := by
  induction l generalizing m with
/- Perform induction on the list \( l \) and consider the base case where \( l \) is the empty list. -/
  | nil =>
/- Simplify the goal using the fact that the empty list is a sublist of any list and the equivalence \( \text{True} \leftrightarrow p = p \). This reduces the goal to showing that there exists a natural number \( n \) such that \( n \leq m \) and the empty list is equal to \( \text{replicate}(n, a) \). -/
    simp only [nil_sublist, true_iff]
/- The current goal is exactly proved by taking \( n = 0 \), since \( 0 \leq m \) and the empty list is equal to \( \text{replicate}(0, a) \). -/
    exact ⟨0, zero_le m, by simp⟩
/- Consider the inductive step where \( l \) is a non-empty list, specifically \( l = b :: l' \). -/
  | cons b l ih =>
/- To prove the equivalence, it suffices to prove both directions: (1) if \( b :: l \) is a sublist of \( \text{replicate}(m, a) \), then there exists \( n \) such that \( n \leq m \) and \( b :: l = \text{replicate}(n, a) \), and (2) if there exists \( n \) such that \( n \leq m \) and \( b :: l = \text{replicate}(n, a) \), then \( b :: l \) is a sublist of \( \text{replicate}(m, a) \). -/
    constructor
/- Let \( w \) be an arbitrary sublist of \( b :: l \) in \( \text{replicate}(m, a) \). We need to show that there exists \( n \) such that \( n \leq m \) and \( b :: l = \text{replicate}(n, a) \). -/
    · intro w
      cases m with
/- Consider the case where \( m = 0 \). Simplify the hypothesis \( w \) to show that \( b :: l \) is a sublist of the empty list, which is impossible. This case is vacuously true. -/
      | zero => simp at w
/- Consider the case where \( m = m' + 1 \). -/
      | succ m =>
/- Simplify the hypothesis \( w \) using the fact that \( \text{replicate}(m + 1, a) = a :: \text{replicate}(m, a) \). This reduces the goal to showing that \( b :: l \) is a sublist of \( a :: \text{replicate}(m, a) \). -/
        simp [replicate_succ] at w
        cases w with
/- Consider the case where \( b :: l \) is a sublist of \( a :: \text{replicate}(m, a) \). -/
        | cons _ w =>
/- By the inductive hypothesis, since \( l \) is a sublist of \( \text{replicate}(m, a) \), there exists \( n \) such that \( n \leq m \) and \( l = \text{replicate}(n, a) \). -/
          obtain ⟨n, le, rfl⟩ := ih.1 (sublist_of_cons_sublist w)
/- Since \( b \) is a member of \( \text{replicate}(m + 1, a) \), it follows that \( b = a \). -/
          obtain rfl := (mem_replicate.1 (mem_of_cons_sublist w)).2
/- The current goal is exactly proved by taking \( n + 1 \), since \( n + 1 \leq m + 1 \) and \( b :: \text{replicate}(n, a) = \text{replicate}(n + 1, a) \). -/
          exact ⟨n+1, Nat.add_le_add_right le 1, rfl⟩
/- Consider the case where \( l \) is a sublist of \( \text{replicate}(m, a) \). -/
        | cons₂ _ w =>
/- By the inductive hypothesis, since \( l \) is a sublist of \( \text{replicate}(m, a) \), there exists \( n \) such that \( n \leq m \) and \( l = \text{replicate}(n, a) \). -/
          obtain ⟨n, le, rfl⟩ := ih.1 w
/- To construct the proof, we take \( n + 1 \), since \( n + 1 \leq m + 1 \) and \( a :: \text{replicate}(n, a) = \text{replicate}(n + 1, a) \). -/
          refine ⟨n+1, Nat.add_le_add_right le 1, by simp [replicate_succ]⟩
/- Let \( n \) be a natural number such that \( n \leq m \) and \( b :: l = \text{replicate}(n, a) \). We need to show that \( b :: l \) is a sublist of \( \text{replicate}(m, a) \). -/
    · rintro ⟨n, le, w⟩
/- Since \( b :: l = \text{replicate}(n, a) \), the goal is equivalent to showing that \( \text{replicate}(n, a) \) is a sublist of \( \text{replicate}(m, a) \). -/
      rw [w]
/- Since the list containing \( n \) copies of \( a \) is a sublist of the list containing \( m \) copies of \( a \) if and only if \( n \leq m \), and we have \( n \leq m \), it follows that \( \text{replicate}(n, a) \) is a sublist of \( \text{replicate}(m, a) \). -/
/- The current goal is exactly proved by the fact that \( \text{replicate}(n, a) \) is a sublist of \( \text{replicate}(m, a) \) if and only if \( n \leq m \), and we have \( n \leq m \). -/
      exact (replicate_sublist_replicate a).2 le","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
35040,List.reverse_infix,theorem List.reverse_infix : reverse l₁ <:+: reverse l₂ ↔ l₁ <:+: l₂ := by sorry,"Reversing Lists Preserves Contiguous Substring Property: \( l_1^{\text{reverse}} <:+: l_2^{\text{reverse}} \leftrightarrow l_1 <:+: l_2 \) : For any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), the reverse of \( l_1 \) is a contiguous substring of the reverse of \( l_2 \) if and only if \( l_1 \) is a contiguous substring of \( l_2 \). In other words, \( l_1^{\text{reverse}} \) is a contiguous substring of \( l_2^{\text{reverse}} \) if and only if \( l_1 \) is a contiguous substring of \( l_2 \).","theorem List.reverse_infix : reverse l₁ <:+: reverse l₂ ↔ l₁ <:+: l₂ := by
  refine ⟨fun ⟨s, t, e⟩ => ⟨reverse t, reverse s, ?_⟩, fun ⟨s, t, e⟩ => ⟨reverse t, reverse s, ?_⟩⟩
  · rw [← reverse_reverse l₁, append_assoc, ← reverse_append, ← reverse_append, e,
      reverse_reverse]
  · rw [append_assoc, ← reverse_append, ← reverse_append, e]","To prove the equivalence \( l_1^{\text{reverse}} <:+: l_2^{\text{reverse}} \leftrightarrow l_1 <:+: l_2 \), we need to show both directions.

1. **Forward Direction:**
- Assume \( l_1^{\text{reverse}} <:+: l_2^{\text{reverse}} \).
- This means there exist lists \( s \) and \( t \) such that \( s \oplus l_1^{\text{reverse}} \oplus t = l_2^{\text{reverse}} \).
- We need to show that \( l_1 <:+: l_2 \), i.e., there exist lists \( s' \) and \( t' \) such that \( s' \oplus l_1 \oplus t' = l_2 \).
- Choose \( s' = t^{\text{reverse}} \) and \( t' = s^{\text{reverse}} \).
- Using the properties of list operations, we have:
\[
t^{\text{reverse}} \oplus l_1 \oplus s^{\text{reverse}} = t^{\text{reverse}} \oplus (l_1^{\text{reverse}})^{\text{reverse}} \oplus s^{\text{reverse}} = (s \oplus l_1^{\text{reverse}} \oplus t)^{\text{reverse}} = l_2^{\text{reverse}}^{\text{reverse}} = l_2
\]
- Thus, \( t^{\text{reverse}} \oplus l_1 \oplus s^{\text{reverse}} = l_2 \), which completes the forward direction.

2. **Backward Direction:**
- Assume \( l_1 <:+: l_2 \).
- This means there exist lists \( s \) and \( t \) such that \( s \oplus l_1 \oplus t = l_2 \).
- We need to show that \( l_1^{\text{reverse}} <:+: l_2^{\text{reverse}} \), i.e., there exist lists \( s' \) and \( t' \) such that \( s' \oplus l_1^{\text{reverse}} \oplus t' = l_2^{\text{reverse}} \).
- Choose \( s' = t^{\text{reverse}} \) and \( t' = s^{\text{reverse}} \).
- Using the properties of list operations, we have:
\[
t^{\text{reverse}} \oplus l_1^{\text{reverse}} \oplus s^{\text{reverse}} = (s \oplus l_1 \oplus t)^{\text{reverse}} = l_2^{\text{reverse}}
\]
- Thus, \( t^{\text{reverse}} \oplus l_1^{\text{reverse}} \oplus s^{\text{reverse}} = l_2^{\text{reverse}} \), which completes the backward direction.

Therefore, we have shown that \( l_1^{\text{reverse}} <:+: l_2^{\text{reverse}} \leftrightarrow l_1 <:+: l_2 \). This completes the proof. \(\blacksquare\)","theorem List.reverse_infix : reverse l₁ <:+: reverse l₂ ↔ l₁ <:+: l₂ := by
/- To prove the equivalence \( l_1^{\text{reverse}} <:+: l_2^{\text{reverse}} \leftrightarrow l_1 <:+: l_2 \), we need to show both directions. For the forward direction, assume \( l_1^{\text{reverse}} <:+: l_2^{\text{reverse}} \). This means there exist lists \( s \) and \( t \) such that \( s \oplus l_1^{\text{reverse}} \oplus t = l_2^{\text{reverse}} \). We need to show that \( l_1 <:+: l_2 \), i.e., there exist lists \( s' \) and \( t' \) such that \( s' \oplus l_1 \oplus t' = l_2 \). We will choose \( s' = t^{\text{reverse}} \) and \( t' = s^{\text{reverse}} \). For the backward direction, assume \( l_1 <:+: l_2 \). This means there exist lists \( s \) and \( t \) such that \( s \oplus l_1 \oplus t = l_2 \). We need to show that \( l_1^{\text{reverse}} <:+: l_2^{\text{reverse}} \), i.e., there exist lists \( s' \) and \( t' \) such that \( s' \oplus l_1^{\text{reverse}} \oplus t' = l_2^{\text{reverse}} \). We will choose \( s' = t^{\text{reverse}} \) and \( t' = s^{\text{reverse}} \). -/
  refine ⟨fun ⟨s, t, e⟩ => ⟨reverse t, reverse s, ?_⟩, fun ⟨s, t, e⟩ => ⟨reverse t, reverse s, ?_⟩⟩
/- First, we show that if \( l_1^{\text{reverse}} <:+: l_2^{\text{reverse}} \), then \( l_1 <:+: l_2 \). Assume \( l_1^{\text{reverse}} <:+: l_2^{\text{reverse}} \), so there exist lists \( s \) and \( t \) such that \( s \oplus l_1^{\text{reverse}} \oplus t = l_2^{\text{reverse}} \). We need to show that \( t^{\text{reverse}} \oplus l_1 \oplus s^{\text{reverse}} = l_2 \). Using the properties of list operations, we have:
\[
t^{\text{reverse}} \oplus l_1 \oplus s^{\text{reverse}} = t^{\text{reverse}} \oplus (l_1^{\text{reverse}})^{\text{reverse}} \oplus s^{\text{reverse}} = (s \oplus l_1^{\text{reverse}} \oplus t)^{\text{reverse}} = l_2^{\text{reverse}}^{\text{reverse}} = l_2
\]
Thus, \( t^{\text{reverse}} \oplus l_1 \oplus s^{\text{reverse}} = l_2 \), which completes the forward direction. -/
  · rw [← reverse_reverse l₁, append_assoc, ← reverse_append, ← reverse_append, e,
      reverse_reverse]
/- Next, we show that if \( l_1 <:+: l_2 \), then \( l_1^{\text{reverse}} <:+: l_2^{\text{reverse}} \). Assume \( l_1 <:+: l_2 \), so there exist lists \( s \) and \( t \) such that \( s \oplus l_1 \oplus t = l_2 \). We need to show that \( t^{\text{reverse}} \oplus l_1^{\text{reverse}} \oplus s^{\text{reverse}} = l_2^{\text{reverse}} \). Using the properties of list operations, we have:
\[
t^{\text{reverse}} \oplus l_1^{\text{reverse}} \oplus s^{\text{reverse}} = (s \oplus l_1 \oplus t)^{\text{reverse}} = l_2^{\text{reverse}}
\]
Thus, \( t^{\text{reverse}} \oplus l_1^{\text{reverse}} \oplus s^{\text{reverse}} = l_2^{\text{reverse}} \), which completes the backward direction. -/
  · rw [append_assoc, ← reverse_append, ← reverse_append, e]","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
35055,List.prefix_cons_iff,"theorem List.prefix_cons_iff : l₁ <+: a :: l₂ ↔ l₁ = [] ∨ ∃ t, l₁ = a :: t ∧ t <+: l₂ := by sorry","Prefix of Cons List: \( l_1 <+: a :: l_2 \leftrightarrow l_1 = [] \lor \exists t, l_1 = a :: t \land t <+: l_2 \) : For any lists \( l_1 \) and \( l_2 \) of type \( \alpha \) and any element \( a \) of type \( \alpha \), the list \( l_1 \) is a prefix of the list \( a :: l_2 \) if and only if \( l_1 \) is the empty list or there exists a list \( t \) such that \( l_1 = a :: t \) and \( t \) is a prefix of \( l_2 \).","theorem List.prefix_cons_iff : l₁ <+: a :: l₂ ↔ l₁ = [] ∨ ∃ t, l₁ = a :: t ∧ t <+: l₂ := by
  cases l₁ with
  | nil => simp
  | cons a' l₁ =>
    constructor
    · rintro ⟨t, h⟩
      simp at h
      obtain ⟨rfl, rfl⟩ := h
      exact Or.inr ⟨l₁, rfl, prefix_append l₁ t⟩
    · rintro (h | ⟨t, w, ⟨s, h'⟩⟩)
      · simp [h]
      · simp only [w]
        refine ⟨s, by simp [h']⟩","We need to show that \( l_1 <+: a :: l_2 \) if and only if \( l_1 = [] \lor \exists t, l_1 = a :: t \land t <+: l_2 \).

1. **Case 1: \( l_1 = [] \)**
- If \( l_1 = [] \), then \( [] <+: a :: l_2 \) is true by definition.
- The right-hand side \( [] = [] \lor \exists t, [] = a :: t \land t <+: l_2 \) is also true because \( [] = [] \) is true.
- Therefore, the equivalence holds in this case.

2. **Case 2: \( l_1 = a' :: l_1 \)**
- Assume \( l_1 = a' :: l_1 \).
- We need to show both directions of the equivalence:
- **Direction 1: \( a' :: l_1 <+: a :: l_2 \) implies \( a' :: l_1 = [] \lor \exists t, a' :: l_1 = a :: t \land t <+: l_2 \)**
- Assume \( a' :: l_1 <+: a :: l_2 \).
- By the definition of prefix, there exists a list \( t \) such that \( a' :: l_1 ++ t = a :: l_2 \).
- Simplifying, we get \( a' = a \) and \( l_1 ++ t = l_2 \).
- Therefore, \( a' :: l_1 = a :: l_1 \) and \( l_1 <+: l_1 ++ t \).
- Hence, \( a' :: l_1 = a :: l_1 \) and \( l_1 <+: l_2 \), so the right-hand side is true.
- **Direction 2: \( a' :: l_1 = [] \lor \exists t, a' :: l_1 = a :: t \land t <+: l_2 \) implies \( a' :: l_1 <+: a :: l_2 \)**
- Consider the two sub-cases:
- **Sub-case 1: \( a' :: l_1 = [] \)**
- If \( a' :: l_1 = [] \), then \( [] <+: a :: l_2 \) is true by definition.
- **Sub-case 2: \( \exists t, a' :: l_1 = a :: t \land t <+: l_2 \)**
- Assume there exists a list \( t \) such that \( a' :: l_1 = a :: t \) and \( t <+: l_2 \).
- Using the hypothesis \( a' :: l_1 = a :: t \), we need to show \( a :: t <+: a :: l_2 \).
- Since \( t <+: l_2 \), there exists a list \( s \) such that \( t ++ s = l_2 \).
- Therefore, \( a :: t <+: a :: l_2 \) is true.

Thus, the equivalence \( l_1 <+: a :: l_2 \leftrightarrow l_1 = [] \lor \exists t, l_1 = a :: t \land t <+: l_2 \) holds in all cases. This completes the proof. \(\blacksquare\)","theorem List.prefix_cons_iff : l₁ <+: a :: l₂ ↔ l₁ = [] ∨ ∃ t, l₁ = a :: t ∧ t <+: l₂ := by
  cases l₁ with
/- Consider the case where \( l_1 \) is the empty list. We need to show that \( [] <+: a :: l_2 \) is equivalent to \( [] = [] \lor \exists t, [] = a :: t \land t <+: l_2 \). Simplifying the left-hand side, we see that \( [] <+: a :: l_2 \) is true, and the right-hand side is also true because \( [] = [] \) is true. Therefore, the equivalence holds. -/
  | nil => simp
/- Consider the case where \( l_1 \) is a non-empty list, i.e., \( l_1 = a' :: l_1 \). We need to show that \( a' :: l_1 <+: a :: l_2 \) is equivalent to \( a' :: l_1 = [] \lor \exists t, a' :: l_1 = a :: t \land t <+: l_2 \). -/
  | cons a' l₁ =>
/- To prove the equivalence, we need to show both directions:
1. If \( a' :: l_1 <+: a :: l_2 \), then \( a' :: l_1 = [] \lor \exists t, a' :: l_1 = a :: t \land t <+: l_2 \).
2. If \( a' :: l_1 = [] \lor \exists t, a' :: l_1 = a :: t \land t <+: l_2 \), then \( a' :: l_1 <+: a :: l_2 \). -/
    constructor
/- Assume \( a' :: l_1 <+: a :: l_2 \). By the definition of prefix, there exists a list \( t \) such that \( a' :: l_1 ++ t = a :: l_2 \). Let \( h \) be the proof of this equality. -/
    · rintro ⟨t, h⟩
/- Simplify the hypothesis \( h \) to get \( a' = a \) and \( l_1 ++ t = l_2 \). -/
      simp at h
/- From the simplified hypothesis, we have \( a' = a \) and \( l_1 ++ t = l_2 \). Therefore, \( a' :: l_1 = a :: l_1 \) and \( l_1 ++ t = l_2 \). -/
      obtain ⟨rfl, rfl⟩ := h
/- Since \( a' :: l_1 = a :: l_1 \) and \( l_1 ++ t = l_2 \), we can conclude that \( a' :: l_1 = a :: l_1 \) and \( l_1 <+: l_1 ++ t \). Therefore, \( a' :: l_1 <+: a :: l_2 \) holds, and the right-hand side of the equivalence is true. -/
      exact Or.inr ⟨l₁, rfl, prefix_append l₁ t⟩
/- Assume \( a' :: l_1 = [] \lor \exists t, a' :: l_1 = a :: t \land t <+: l_2 \). We consider two cases:
1. \( a' :: l_1 = [] \).
2. There exists a list \( t \) such that \( a' :: l_1 = a :: t \) and \( t <+: l_2 \). -/
    · rintro (h | ⟨t, w, ⟨s, h'⟩⟩)
/- In the case where \( a' :: l_1 = [] \), we need to show that \( [] <+: a :: l_2 \). Simplifying, we see that \( [] <+: a :: l_2 \) is true, so the left-hand side of the equivalence holds. -/
      · simp [h]
/- In the case where \( a' :: l_1 = a :: t \) and \( t <+: l_2 \), we need to show that \( a :: t <+: a :: l_2 \). Using the hypothesis \( w \) that \( a' :: l_1 = a :: t \), we can simplify the goal to \( a :: t <+: a :: l_2 \). -/
      · simp only [w]
/- To show that \( a :: t <+: a :: l_2 \), it suffices to show that \( t ++ s = l_2 \). Using the hypothesis \( h' \) that \( t ++ s = l_2 \), we can directly conclude that \( a :: t <+: a :: l_2 \). -/
/- To show that \( a :: t <+: a :: l_2 \), it suffices to show that \( t ++ s = l_2 \). Using the hypothesis \( h' \) that \( t ++ s = l_2 \), we can directly conclude that \( a :: t <+: a :: l_2 \). -/
        refine ⟨s, by simp [h']⟩","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
35065,List.cons_sublist_iff,"theorem List.cons_sublist_iff {a : α} {l l'} :
    a :: l <+ l' ↔ ∃ r₁ r₂, l' = r₁ ++ r₂ ∧ a ∈ r₁ ∧ l <+ r₂ := by sorry","Sublist Condition for Cons: $(a :: l) \text{ is a sublist of } l' \leftrightarrow \exists r_1, r_2, l' = r_1 ++ r_2 \land a \in r_1 \land l \text{ is a sublist of } r_2$ : For any type \( \alpha \) and elements \( a \in \alpha \), lists \( l, l' \) of type \( \alpha \), the list \( a :: l \) is a sublist of \( l' \) if and only if there exist lists \( r_1 \) and \( r_2 \) such that \( l' = r_1 ++ r_2 \), \( a \in r_1 \), and \( l \) is a sublist of \( r_2 \).","theorem List.cons_sublist_iff {a : α} {l l'} :
    a :: l <+ l' ↔ ∃ r₁ r₂, l' = r₁ ++ r₂ ∧ a ∈ r₁ ∧ l <+ r₂ := by
  induction l' with
  | nil => simp
  | cons a' l' ih =>
    constructor
    · intro w
      cases w with
      | cons _ w =>
        obtain ⟨r₁, r₂, rfl, h₁, h₂⟩ := ih.1 w
        exact ⟨a' :: r₁, r₂, by simp, mem_cons_of_mem a' h₁, h₂⟩
      | cons₂ _ w =>
        exact ⟨[a], l', by simp, mem_singleton_self _, w⟩
    · rintro ⟨r₁, r₂, w, h₁, h₂⟩
      rw [w, ← singleton_append]
      exact Sublist.append (by simpa) h₂","We need to prove the equivalence in both directions.

1. **(\(\Rightarrow\)) If \(a :: l\) is a sublist of \(l'\), then there exist lists \(r_1\) and \(r_2\) such that \(l' = r_1 ++ r_2\), \(a \in r_1\), and \(l\) is a sublist of \(r_2\):**

- **Base Case:** If \(l'\) is the empty list, then \(a :: l\) cannot be a sublist of \(l'\) unless \(l\) is also empty. This simplifies to a trivially true statement.
- **Inductive Step:** Assume \(l'\) is of the form \(a' :: l'\). Suppose \(a :: l\) is a sublist of \(a' :: l'\). By the inductive hypothesis, there exist lists \(r_1\) and \(r_2\) such that \(a' :: l' = r_1 ++ r_2\), \(a \in r_1\), and \(l\) is a sublist of \(r_2\). Therefore, we can take \(r_1\) to be \(a' :: r_1\) and \(r_2\) to be \(r_2\). Since \(a' :: l' = (a' :: r_1) ++ r_2\), \(a \in a' :: r_1\), and \(l\) is a sublist of \(r_2\), the conditions are satisfied.

2. **(\(\Leftarrow\)) If there exist lists \(r_1\) and \(r_2\) such that \(l' = r_1 ++ r_2\), \(a \in r_1\), and \(l\) is a sublist of \(r_2\), then \(a :: l\) is a sublist of \(l'\):**

- Assume there exist lists \(r_1\) and \(r_2\) such that \(l' = r_1 ++ r_2\), \(a \in r_1\), and \(l\) is a sublist of \(r_2\). Since the sublist relation is preserved under concatenation, and we have \(a \in r_1\) and \(l \subseteq r_2\), it follows that \([a] ++ l \subseteq r_1 ++ r_2\). Therefore, \(a :: l\) is a sublist of \(l'\).

This completes the proof. \(\blacksquare\)","theorem List.cons_sublist_iff {a : α} {l l'} :
    a :: l <+ l' ↔ ∃ r₁ r₂, l' = r₁ ++ r₂ ∧ a ∈ r₁ ∧ l <+ r₂ := by
  induction l' with
/- For the base case where \(l'\) is the empty list, we simplify the goal. Since the empty list has no elements, the only way \(a :: l\) can be a sublist of the empty list is if \(l\) is also empty. This simplifies to a trivially true statement, thus completing the base case. -/
  | nil => simp
/- For the inductive step, assume \(l'\) is of the form \(a' :: l'\). We need to show that \(a :: l\) is a sublist of \(a' :: l'\) if and only if there exist lists \(r_1\) and \(r_2\) such that \(a' :: l' = r_1 ++ r_2\), \(a \in r_1\), and \(l\) is a sublist of \(r_2\). -/
  | cons a' l' ih =>
/- To prove the equivalence, we need to show both directions. First, we show that if \(a :: l\) is a sublist of \(a' :: l'\), then there exist lists \(r_1\) and \(r_2\) such that \(a' :: l' = r_1 ++ r_2\), \(a \in r_1\), and \(l\) is a sublist of \(r_2\). -/
    constructor
/- Assume \(a :: l\) is a sublist of \(a' :: l'\). We need to find lists \(r_1\) and \(r_2\) that satisfy the conditions. -/
    · intro w
      cases w with
/- Consider the case where \(a :: l\) is a sublist of \(a' :: l'\) and \(a' :: l'\) is of the form \(a' :: l'\). We need to find lists \(r_1\) and \(r_2\) such that \(a' :: l' = r_1 ++ r_2\), \(a \in r_1\), and \(l\) is a sublist of \(r_2\). -/
      | cons _ w =>
/- By the inductive hypothesis, since \(a :: l\) is a sublist of \(a' :: l'\), there exist lists \(r_1\) and \(r_2\) such that \(a' :: l' = r_1 ++ r_2\), \(a \in r_1\), and \(l\) is a sublist of \(r_2\). -/
        obtain ⟨r₁, r₂, rfl, h₁, h₂⟩ := ih.1 w
/- We can take \(r_1\) to be \(a' :: r_1\) and \(r_2\) to be \(r_2\). Since \(a' :: l' = (a' :: r_1) ++ r_2\), \(a \in a' :: r_1\), and \(l\) is a sublist of \(r_2\), the conditions are satisfied. This completes the proof for this direction. -/
        exact ⟨a' :: r₁, r₂, by simp, mem_cons_of_mem a' h₁, h₂⟩
/- Consider the case where \(a :: l\) is a sublist of \(a' :: l'\) and \(a' :: l'\) is of the form \(a' :: l'\). We need to find lists \(r_1\) and \(r_2\) such that \(a' :: l' = r_1 ++ r_2\), \(a \in r_1\), and \(l\) is a sublist of \(r_2\). -/
      | cons₂ _ w =>
/- We can take \(r_1\) to be \([a]\) and \(r_2\) to be \(l'\). Since \(a' :: l' = [a] ++ l'\), \(a \in [a]\), and \(l\) is a sublist of \(l'\), the conditions are satisfied. This completes the proof for this direction. -/
        exact ⟨[a], l', by simp, mem_singleton_self _, w⟩
/- Assume there exist lists \(r_1\) and \(r_2\) such that \(a' :: l' = r_1 ++ r_2\), \(a \in r_1\), and \(l\) is a sublist of \(r_2\). We need to show that \(a :: l\) is a sublist of \(a' :: l'\). -/
    · rintro ⟨r₁, r₂, w, h₁, h₂⟩
/- Since \(a' :: l' = r_1 ++ r_2\) and \([a] ++ l = a :: l\), we can rewrite the goal to show that \([a] ++ l\) is a sublist of \(r_1 ++ r_2\). -/
      rw [w, ← singleton_append]
/- Since the sublist relation is preserved under concatenation, and we have already shown that \([a] \subseteq r_1\) and \(l \subseteq r_2\), it follows that \([a] ++ l \subseteq r_1 ++ r_2\). This completes the proof for this direction. -/
/- Since the sublist relation is preserved under concatenation, and we have already shown that \([a] \subseteq r_1\) and \(l \subseteq r_2\), it follows that \([a] ++ l \subseteq r_1 ++ r_2\). This completes the proof for this direction. -/
      exact Sublist.append (by simpa) h₂","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
35084,List.append_sublist_iff,"theorem List.append_sublist_iff {l₁ l₂ : List α} :
    l₁ ++ l₂ <+ r ↔ ∃ r₁ r₂, r = r₁ ++ r₂ ∧ l₁ <+ r₁ ∧ l₂ <+ r₂ := by sorry","Concatenation of Sublists is Sublist if and only if Splitting Condition Holds: \( (l_1 \oplus l_2) \subseteq r \leftrightarrow \exists r_1, r_2, r = r_1 \oplus r_2 \land l_1 \subseteq r_1 \land l_2 \subseteq r_2 \) : For any lists \( l_1 \) and \( l_2 \) of elements of type \( \alpha \), and for any list \( r \) of elements of type \( \alpha \), the list \( l_1 \) concatenated with \( l_2 \) is a sublist of \( r \) if and only if there exist lists \( r_1 \) and \( r_2 \) such that \( r = r_1 \) concatenated with \( r_2 \), \( l_1 \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \). In other words, \( l_1 \) and \( l_2 \) can be found as sublists in \( r \) in the same order they appear in \( l_1 \) and \( l_2 \).","theorem List.append_sublist_iff {l₁ l₂ : List α} :
    l₁ ++ l₂ <+ r ↔ ∃ r₁ r₂, r = r₁ ++ r₂ ∧ l₁ <+ r₁ ∧ l₂ <+ r₂ := by
  induction l₁ generalizing r with
  | nil =>
    constructor
    · intro w
      refine ⟨[], r, by simp_all⟩
    · rintro ⟨r₁, r₂, rfl, -, w₂⟩
      simp only [nil_append]
      exact sublist_append_of_sublist_right w₂
  | cons a l₁ ih =>
    constructor
    · rw [cons_append, cons_sublist_iff]
      rintro ⟨r₁, r₂, rfl, h₁, h₂⟩
      obtain ⟨s₁, s₂, rfl, t₁, t₂⟩ := ih.1 h₂
      refine ⟨r₁ ++ s₁, s₂, by simp, ?_, t₂⟩
      rw [← singleton_append]
      exact Sublist.append (by simpa) t₁
    · rintro ⟨r₁, r₂, rfl, h₁, h₂⟩
      exact Sublist.append h₁ h₂","We prove the theorem by induction on \( l_1 \).

**Base Case:**
Consider the case where \( l_1 \) is the empty list. We need to show that \( l_1 ++ l_2 \) is a sublist of \( r \) if and only if there exist lists \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( l_1 \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \).

1. **(\(\Rightarrow\))** Assume \( l_1 ++ l_2 \) is a sublist of \( r \). Since \( l_1 \) is the empty list, \( l_1 ++ l_2 = l_2 \). We can choose \( r_1 \) to be the empty list and \( r_2 \) to be \( r \). Since the empty list is a sublist of any list, \( l_1 \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \).

2. **(\(\Leftarrow\))** Assume there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( l_1 \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \). Since \( l_1 \) is the empty list, it is trivially a sublist of \( r_1 \). Therefore, \( l_2 \) is a sublist of \( r_2 \), and thus \( l_1 ++ l_2 = l_2 \) is a sublist of \( r_1 ++ r_2 = r \).

**Inductive Step:**
Consider the case where \( l_1 \) is of the form \( a :: l_1' \). We need to show that \( a :: l_1' ++ l_2 \) is a sublist of \( r \) if and only if there exist lists \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( a :: l_1' \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \).

1. **(\(\Rightarrow\))** Assume \( a :: l_1' ++ l_2 \) is a sublist of \( r \). By the definition of sublist, there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( a \in r_1 \), and \( l_1' ++ l_2 \) is a sublist of \( r_2 \). By the inductive hypothesis, since \( l_1' ++ l_2 \) is a sublist of \( r_2 \), there exist \( s_1 \) and \( s_2 \) such that \( r_2 = s_1 ++ s_2 \), \( l_1' \) is a sublist of \( s_1 \), and \( l_2 \) is a sublist of \( s_2 \). Therefore, we can choose \( r_1' = r_1 ++ s_1 \) and \( r_2' = s_2 \). Since \( a \in r_1 \) and \( l_1' \) is a sublist of \( s_1 \), \( a :: l_1' \) is a sublist of \( r_1 ++ s_1 = r_1' \). Thus, \( a :: l_1' \) is a sublist of \( r_1' \) and \( l_2 \) is a sublist of \( r_2' \).

2. **(\(\Leftarrow\))** Assume there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( a :: l_1' \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \). Since \( a :: l_1' \) is a sublist of \( r_1 \) and \( l_2 \) is a sublist of \( r_2 \), the concatenation \( a :: l_1' ++ l_2 \) is a sublist of \( r_1 ++ r_2 = r \).

This completes the proof.","theorem List.append_sublist_iff {l₁ l₂ : List α} :
    l₁ ++ l₂ <+ r ↔ ∃ r₁ r₂, r = r₁ ++ r₂ ∧ l₁ <+ r₁ ∧ l₂ <+ r₂ := by
  induction l₁ generalizing r with
/- Consider the base case where \( l_1 \) is the empty list. We need to show that \( l_1 ++ l_2 \) is a sublist of \( r \) if and only if there exist lists \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( l_1 \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \). -/
  | nil =>
/- To prove the equivalence, we need to show both directions: (1) if \( l_1 ++ l_2 \) is a sublist of \( r \), then there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( l_1 \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \); and (2) if there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( l_1 \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \), then \( l_1 ++ l_2 \) is a sublist of \( r \). -/
    constructor
/- Assume \( l_1 ++ l_2 \) is a sublist of \( r \). We need to show that there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( l_1 \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \). -/
    · intro w
/- We can choose \( r_1 \) to be the empty list and \( r_2 \) to be \( r \). Since \( l_1 \) is the empty list, it is trivially a sublist of the empty list, and \( l_2 \) is a sublist of \( r \). This satisfies the conditions. -/
      refine ⟨[], r, by simp_all⟩
/- Assume there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( l_1 \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \). We need to show that \( l_1 ++ l_2 \) is a sublist of \( r \). -/
    · rintro ⟨r₁, r₂, rfl, -, w₂⟩
/- Since \( l_1 \) is the empty list, the concatenation \( l_1 ++ l_2 \) is simply \( l_2 \). Therefore, we need to show that \( l_2 \) is a sublist of \( r_1 ++ r_2 \). -/
      simp only [nil_append]
/- Since \( l_2 \) is a sublist of \( r_2 \), it follows that \( l_2 \) is a sublist of \( r_1 ++ r_2 \). -/
      exact sublist_append_of_sublist_right w₂
/- Consider the inductive case where \( l_1 \) is of the form \( a :: l_1' \). We need to show that \( a :: l_1' ++ l_2 \) is a sublist of \( r \) if and only if there exist lists \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( a :: l_1' \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \). -/
  | cons a l₁ ih =>
/- To prove the equivalence, we need to show both directions: (1) if \( a :: l_1' ++ l_2 \) is a sublist of \( r \), then there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( a :: l_1' \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \); and (2) if there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( a :: l_1' \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \), then \( a :: l_1' ++ l_2 \) is a sublist of \( r \). -/
    constructor
/- Rewrite the goal using the properties of concatenation and the sublist condition for cons. We need to show that if \( a :: (l_1' ++ l_2) \) is a sublist of \( r \), then there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( a \in r_1 \), and \( l_1' ++ l_2 \) is a sublist of \( r_2 \). -/
    · rw [cons_append, cons_sublist_iff]
/- Assume there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( a \in r_1 \), and \( l_1' ++ l_2 \) is a sublist of \( r_2 \). We need to show that \( a :: l_1' \) is a sublist of \( r_1 \) and \( l_2 \) is a sublist of \( r_2 \). -/
      rintro ⟨r₁, r₂, rfl, h₁, h₂⟩
/- By the inductive hypothesis, since \( l_1' ++ l_2 \) is a sublist of \( r_2 \), there exist \( s_1 \) and \( s_2 \) such that \( r_2 = s_1 ++ s_2 \), \( l_1' \) is a sublist of \( s_1 \), and \( l_2 \) is a sublist of \( s_2 \). -/
      obtain ⟨s₁, s₂, rfl, t₁, t₂⟩ := ih.1 h₂
/- We can choose \( r_1' = r_1 ++ s_1 \) and \( r_2' = s_2 \). We need to show that \( a :: l_1' \) is a sublist of \( r_1' \) and \( l_2 \) is a sublist of \( r_2' \). -/
      refine ⟨r₁ ++ s₁, s₂, by simp, ?_, t₂⟩
/- Rewrite the goal using the property of concatenation of a singleton list with another list. We need to show that \( [a] ++ l_1' \) is a sublist of \( r_1 ++ s_1 \). -/
      rw [← singleton_append]
/- Since \( [a] \) is a sublist of \( r_1 \) and \( l_1' \) is a sublist of \( s_1 \), the concatenation \( [a] ++ l_1' \) is a sublist of \( r_1 ++ s_1 \). -/
      exact Sublist.append (by simpa) t₁
/- Assume there exist \( r_1 \) and \( r_2 \) such that \( r = r_1 ++ r_2 \), \( a :: l_1' \) is a sublist of \( r_1 \), and \( l_2 \) is a sublist of \( r_2 \). We need to show that \( a :: l_1' ++ l_2 \) is a sublist of \( r \). -/
    · rintro ⟨r₁, r₂, rfl, h₁, h₂⟩
/- Since \( l_1 \) is a sublist of \( r_1 \) and \( l_2 \) is a sublist of \( r_2 \), the concatenation \( l_1 ++ l_2 \) is a sublist of the concatenation \( r_1 ++ r_2 \). -/
/- Since \( a :: l_1' \) is a sublist of \( r_1 \) and \( l_2 \) is a sublist of \( r_2 \), the concatenation \( a :: l_1' ++ l_2 \) is a sublist of \( r_1 ++ r_2 \). -/
      exact Sublist.append h₁ h₂","import Init.Data.List.TakeDrop
import Init.Data.List.Sublist

open List
open Nat
variable [BEq α]
variable [BEq α]
"
36919,Classical.exists_or_forall_not,"theorem Classical.exists_or_forall_not (P : α → Prop) : (∃ a, P a) ∨ ∀ a, ¬ P a := by sorry","Existence or Universal Negation: \((\exists a, P(a)) \lor (\forall a, \neg P(a))\) : For any type \( \alpha \) and any predicate \( P : \alpha \to \text{Prop} \), either there exists an element \( a \in \alpha \) such that \( P(a) \) holds, or for all elements \( a \in \alpha \), \( P(a) \) does not hold. This can be expressed as:
\[
(\exists a \in \alpha, P(a)) \lor (\forall a \in \alpha, \neg P(a))
\]","theorem Classical.exists_or_forall_not (P : α → Prop) : (∃ a, P a) ∨ ∀ a, ¬ P a := by
  rw [← not_exists]; exact em _","To prove the statement \((\exists a \in \alpha, P(a)) \lor (\forall a \in \alpha, \neg P(a))\), we start by using the equivalence that the negation of the existence of an element \(a\) such that \(P(a)\) holds is equivalent to the universal statement that for all \(a \in \alpha\), \(P(a)\) does not hold. This transforms our goal into proving:
\[
\neg (\forall a \in \alpha, \neg P(a)) \lor (\forall a \in \alpha, \neg P(a))
\]
By the law of excluded middle, which states that for any proposition \(Q\), either \(Q\) or \(\neg Q\) is true, the above statement is always true. Therefore, the original statement \((\exists a \in \alpha, P(a)) \lor (\forall a \in \alpha, \neg P(a))\) is also true. This completes the proof.","theorem Classical.exists_or_forall_not (P : α → Prop) : (∃ a, P a) ∨ ∀ a, ¬ P a := by
/- To prove the statement \((\exists a \in \alpha, P(a)) \lor (\forall a \in \alpha, \neg P(a))\), we use the equivalence that the negation of the existence of an element \(a\) such that \(P(a)\) holds is equivalent to the universal statement that for all \(a \in \alpha\), \(P(a)\) does not hold. This transforms our goal into proving \(\neg (\forall a \in \alpha, \neg P(a)) \lor (\forall a \in \alpha, \neg P(a))\). By the law of excluded middle, this is always true. Therefore, the original statement is also true. -/
  rw [← not_exists]; exact em _","import Init.PropLemmas
import Init.Classical

open Classical

"
38169,String.Pos.zero_addChar_eq,theorem String.Pos.zero_addChar_eq (c : Char) : (0 : Pos) + c = ⟨c.utf8Size⟩ := by sorry,"Heterogeneous Addition of Zero and Character Equals UTF-8 Size : For any Unicode character \( c \), the heterogeneous addition of the byte position `0` and the character \( c \) results in a byte position with the byte index equal to the UTF-8 size of the character \( c \), i.e., \( 0 + c = \{ \text{byteIdx} := \text{utf8Size}(c) \} \).","theorem String.Pos.zero_addChar_eq (c : Char) : (0 : Pos) + c = ⟨c.utf8Size⟩ := by
  rw [← zero_addChar_byteIdx]","To prove the theorem, we start by using the theorem that the byte index of the byte position resulting from adding a character \( c \) to the byte position `0` is equal to the UTF-8 size of \( c \). This theorem states that \((0 + c).byteIdx = c.\text{utf8Size}\).

By substituting this equivalence into our goal, we need to show that:
\[ 0 + c = \{ \text{byteIdx} := (0 + c).byteIdx \} \]

Since \((0 + c).byteIdx = c.\text{utf8Size}\), the goal simplifies to:
\[ 0 + c = \{ \text{byteIdx} := c.\text{utf8Size} \} \]

This is exactly what we need to prove. Therefore, the theorem is proved.","theorem String.Pos.zero_addChar_eq (c : Char) : (0 : Pos) + c = ⟨c.utf8Size⟩ := by
  rw [← zero_addChar_byteIdx]","import Init.Data.List.Basic
import Init.Data.Char.Basic
import Init.Data.Option.Basic
import Init.Data.String.Basic

open String
open Pos

"
38171,String.Pos.zero_addChar_byteIdx,theorem String.Pos.zero_addChar_byteIdx (c : Char) : ((0 : Pos) + c).byteIdx = c.utf8Size := by sorry,"Byte Index of Zero Plus Character Equals UTF-8 Size of Character : For any Unicode character \( c \), the byte index of the byte position resulting from adding \( c \) to the byte position `0` is equal to the UTF-8 size of \( c \), i.e., \((0 + c).byteIdx = c.\text{utf8Size}\).","theorem String.Pos.zero_addChar_byteIdx (c : Char) : ((0 : Pos) + c).byteIdx = c.utf8Size := by
  simp only [addChar_byteIdx, byteIdx_zero, Nat.zero_add]","To prove the theorem, we start with the goal of showing that \((0 + c).byteIdx = c.\text{utf8Size}\) for any Unicode character \( c \).

1. **Simplification:**
Using the definitions and properties of the byte index of a character, the byte index of zero, and the identity property of zero in addition, we can simplify the proposition. Specifically:
- The byte index of zero is zero, i.e., \(0.byteIdx = 0\).
- Adding zero to any natural number \( n \) results in \( n \) itself, i.e., \(0 + n = n\).

Therefore, we have:
\[
(0 + c).byteIdx = c.byteIdx
\]

2. **UTF-8 Size:**
By the definition of the byte index of a character, \( c.byteIdx \) is equal to the UTF-8 size of \( c \), i.e., \( c.byteIdx = c.\text{utf8Size} \).

3. **Conclusion:**
Combining these results, we get:
\[
(0 + c).byteIdx = c.\text{utf8Size}
\]

Thus, the theorem is proved. \(\blacksquare\)","theorem String.Pos.zero_addChar_byteIdx (c : Char) : ((0 : Pos) + c).byteIdx = c.utf8Size := by
/- Using the definitions and properties of the byte index of a character, the byte index of zero, and the identity property of zero in addition, we can simplify the proposition we want to show to \((0 + c).byteIdx = c.\text{utf8Size}\). Specifically, we use the fact that adding zero to any natural number \( n \) results in \( n \) itself, and the byte index of zero is zero. This simplification directly leads to the desired equality. -/
  simp only [addChar_byteIdx, byteIdx_zero, Nat.zero_add]","import Init.Data.List.Basic
import Init.Data.Char.Basic
import Init.Data.Option.Basic
import Init.Data.String.Basic

open String
open Pos

"
38175,String.Pos.zero_addString_eq,theorem String.Pos.zero_addString_eq (s : String) : (0 : Pos) + s = ⟨s.utf8ByteSize⟩ := by sorry,"Zero Plus String Equals Byte Position with UTF-8 Byte Size : For any string \( s \), the byte position \( 0 + s \) is equal to the byte position with byte index \( s.\text{utf8ByteSize} \), i.e., \( 0 + s = \{ \text{byteIdx} := s.\text{utf8ByteSize} \} \).","theorem String.Pos.zero_addString_eq (s : String) : (0 : Pos) + s = ⟨s.utf8ByteSize⟩ := by
  rw [← zero_addString_byteIdx]","To prove that \( 0 + s = \{ \text{byteIdx} := s.\text{utf8ByteSize} \} \) for any string \( s \), we use the theorem that the byte index of the byte position \( 0 + s \) is equal to the UTF-8 byte size of \( s \). This theorem states that \((0 + s).byteIdx = s.\text{utf8ByteSize}\). Therefore, we can rewrite the goal \( 0 + s = \{ \text{byteIdx} := s.\text{utf8ByteSize} \} \) as \( 0 + s = \{ \text{byteIdx} := (0 + s).byteIdx \} \). This new goal is trivially true by the definition of equality. Hence, the original goal is proved.","theorem String.Pos.zero_addString_eq (s : String) : (0 : Pos) + s = ⟨s.utf8ByteSize⟩ := by
/- We use the theorem that the byte index of the byte position \( 0 + s \) is equal to the UTF-8 byte size of \( s \) to rewrite the goal. Specifically, since \((0 + s).byteIdx = s.\text{utf8ByteSize}\), we can replace the goal \( 0 + s = \{ \text{byteIdx} := s.\text{utf8ByteSize} \} \) with \( 0 + s = \{ \text{byteIdx} := (0 + s).byteIdx \} \). This new goal is trivially true by the definition of equality. -/
  rw [← zero_addString_byteIdx]","import Init.Data.List.Basic
import Init.Data.Char.Basic
import Init.Data.Option.Basic
import Init.Data.String.Basic

open String
open Pos

"
38178,String.prev_lt_of_pos,theorem String.prev_lt_of_pos (s : String) (i : Pos) (h : i ≠ 0) : (s.prev i).1 < i.1 := by sorry,"Previous Byte Position is Less Than Current Position in a String : For any string \( s \) and any byte position \( i \) in \( s \) such that \( i \neq 0 \), the byte index of the position immediately before \( i \) is strictly less than the byte index of \( i \). In other words, if \( i \) is a valid byte position in \( s \) and \( i \neq 0 \), then \(\text{byteIdx}(s.\text{prev}(i)) < \text{byteIdx}(i)\).","theorem String.prev_lt_of_pos (s : String) (i : Pos) (h : i ≠ 0) : (s.prev i).1 < i.1 := by
  simp [prev, h]
  exact utf8PrevAux_lt_of_pos _ _ _ h","To prove the theorem, we start by using the definition of the `prev` function and the assumption that \( i \neq 0 \). The `prev` function returns the byte position immediately before \( i \) in the string \( s \). If \( i = 0 \), the function returns \( 0 \). Since \( i \neq 0 \), we can simplify the goal to show that the byte index of the position immediately before \( i \) in the string \( s \) is less than the byte index of \( i \). Specifically, we need to show that \((\text{utf8PrevAux}(s.\text{data}, 0, i)).\text{byteIdx} < i.\text{byteIdx}\).

We use the theorem that for any list of characters \( cs \) and any valid byte positions \( i \) and \( p \) in a string, if \( p \neq 0 \), then the byte index of the position returned by the helper function `utf8PrevAux` applied to \( cs \), \( i \), and \( p \) is strictly less than the byte index of \( p \). Since \( i \neq 0 \), this theorem directly implies that \((\text{utf8PrevAux}(s.\text{data}, 0, i)).\text{byteIdx} < i.\text{byteIdx}\).

Therefore, the byte index of the position immediately before \( i \) in the string \( s \) is strictly less than the byte index of \( i \), completing the proof.","theorem String.prev_lt_of_pos (s : String) (i : Pos) (h : i ≠ 0) : (s.prev i).1 < i.1 := by
/- Using the definition of the `prev` function and the assumption \( i \neq 0 \), we can simplify the goal to show that the byte index of the position immediately before \( i \) in the string \( s \) is less than the byte index of \( i \). Specifically, we need to show that \((\text{utf8PrevAux}(s.\text{data}, 0, i)).\text{byteIdx} < i.\text{byteIdx}\). -/
  simp [prev, h]
/- The current goal is exactly proved by the theorem that for any list of characters \( cs \) and any valid byte positions \( i \) and \( p \) in a string, if \( p \neq 0 \), then the byte index of the position returned by the helper function `utf8PrevAux` applied to \( cs \), \( i \), and \( p \) is strictly less than the byte index of \( p \). Since \( i \neq 0 \), we have \((\text{utf8PrevAux}(s.\text{data}, 0, i)).\text{byteIdx} < i.\text{byteIdx}\). -/
  exact utf8PrevAux_lt_of_pos _ _ _ h","import Init.Data.List.Basic
import Init.Data.Char.Basic
import Init.Data.Option.Basic
import Init.Data.String.Basic

open String

"
38179,String.length_push,theorem String.length_push (c : Char) : (String.push s c).length = s.length + 1 := by sorry,"Length of String After Appending a Character: \(\text{length}(s \text{.push } c) = \text{length}(s) + 1\) : For any string \( s \) and any character \( c \), the length of the string obtained by appending \( c \) to \( s \) is equal to the length of \( s \) plus 1. Formally, this can be written as:
\[
\text{length}(s \text{.push } c) = \text{length}(s) + 1
\]","theorem String.length_push (c : Char) : (String.push s c).length = s.length + 1 := by
  rw [push, length_mk, List.length_append, List.length_singleton, Nat.succ.injEq]
  rfl","To prove the theorem, we start by using the definition of the `String.push` function. The function `String.push` appends a character \( c \) to the end of a string \( s \), resulting in a new string \( s ++ [c] \). Therefore, the length of the new string \( s \text{.push } c \) is the length of the concatenated list \( s.data ++ [c] \).

Next, we use the fact that the length of a string constructed from a list of characters is equal to the length of the list. This means that the length of the string \( s \text{.push } c \) is the length of the list \( s.data ++ [c] \).

Using the property of the length of concatenated lists, we have:
\[
\text{length}(s.data ++ [c]) = \text{length}(s.data) + \text{length}([c])
\]

Since the length of a singleton list \([c]\) is 1, we can rewrite the equation as:
\[
\text{length}(s.data ++ [c]) = \text{length}(s.data) + 1
\]

We know that the length of the string \( s \) is equal to the length of the list \( s.data \), so:
\[
\text{length}(s.data) = \text{length}(s)
\]

Substituting this into the equation, we get:
\[
\text{length}(s.data ++ [c]) = \text{length}(s) + 1
\]

Finally, using the injectivity of the successor function, we conclude that:
\[
\text{length}(s \text{.push } c) = \text{length}(s) + 1
\]

Thus, the theorem is proved. \(\blacksquare\)","theorem String.length_push (c : Char) : (String.push s c).length = s.length + 1 := by
/- First, we use the definition of `String.push` to rewrite the goal. The function `String.push` appends a character `c` to the end of a string `s`, resulting in a new string `s ++ [c]`. Next, we use the fact that the length of a string constructed from a list of characters is equal to the length of the list. This transforms the goal into showing that the length of the concatenated list `s.data ++ [c]` is equal to the length of `s` plus 1. Using the property of the length of concatenated lists, we rewrite the goal to show that the length of `s.data` plus the length of the singleton list `[c]` is equal to the length of `s` plus 1. Since the length of a singleton list is 1, the goal simplifies to showing that the length of `s.data` plus 1 is equal to the length of `s` plus 1. Finally, using the injectivity of the successor function, we reduce the goal to showing that the length of `s.data` is equal to the length of `s`. -/
  rw [push, length_mk, List.length_append, List.length_singleton, Nat.succ.injEq]
/- The current goal is trivially true due to the reflexive property. Since the length of `s.data` is definitionally equal to the length of `s`, the goal is satisfied. -/
  rfl","import Init.Data.List.Basic
import Init.Data.Char.Basic
import Init.Data.Option.Basic
import Init.Data.String.Basic

open String

"
38181,String.length_pushn,theorem String.length_pushn (c : Char) (n : Nat) : (pushn s c n).length = s.length + n := by sorry,"Length of String After Appending Character Repeatedly: \(\text{length}(s \text{.pushn } c \text{ } n) = \text{length}(s) + n\) : For any string \( s \), character \( c \), and natural number \( n \), the length of the string obtained by appending \( c \) repeated \( n \) times to \( s \) is equal to the length of \( s \) plus \( n \). Formally, this can be written as:
\[
\text{length}(s \text{.pushn } c \text{ } n) = \text{length}(s) + n
\]","theorem String.length_pushn (c : Char) (n : Nat) : (pushn s c n).length = s.length + n := by
  unfold pushn; induction n <;> simp [Nat.repeat, Nat.add_assoc, *]","To prove the theorem, we first unfold the definition of `pushn` to understand how the string is constructed by appending the character \( c \) repeated \( n \) times to \( s \). We then use induction on \( n \).

**Base Case:**
For \( n = 0 \), the string \( s \text{.pushn } c \text{ } 0 \) is simply \( s \). Therefore, the length of \( s \text{.pushn } c \text{ } 0 \) is the length of \( s \). This gives us:
\[
\text{length}(s \text{.pushn } c \text{ } 0) = \text{length}(s) + 0 = \text{length}(s)
\]
which is true.

**Inductive Step:**
Assume the statement is true for some \( n = k \), i.e.,
\[
\text{length}(s \text{.pushn } c \text{ } k) = \text{length}(s) + k
\]
We need to show that the statement holds for \( n = k + 1 \). By the definition of `pushn`, we have:
\[
s \text{.pushn } c \text{ } (k + 1) = (s \text{.pushn } c \text{ } k) \text{.push } c
\]
The length of the resulting string is:
\[
\text{length}((s \text{.pushn } c \text{ } k) \text{.push } c) = \text{length}(s \text{.pushn } c \text{ } k) + 1
\]
Using the inductive hypothesis, we substitute \(\text{length}(s \text{.pushn } c \text{ } k)\) with \(\text{length}(s) + k\):
\[
\text{length}((s \text{.pushn } c \text{ } k) \text{.push } c) = (\text{length}(s) + k) + 1 = \text{length}(s) + (k + 1)
\]
Thus, the statement holds for \( n = k + 1 \).

By the principle of mathematical induction, the statement is true for all natural numbers \( n \). Therefore, for any string \( s \), character \( c \), and natural number \( n \), the length of the string obtained by appending \( c \) repeated \( n \) times to \( s \) is:
\[
\text{length}(s \text{.pushn } c \text{ } n) = \text{length}(s) + n
\]
This completes the proof.","theorem String.length_pushn (c : Char) (n : Nat) : (pushn s c n).length = s.length + n := by
/- First, we unfold the definition of `pushn` to understand how the string is constructed by appending the character \( c \) repeated \( n \) times. We then use induction on \( n \) to prove the statement. For the base case, we simplify the expression using the definition of `Nat.repeat` and the associativity of addition. For the inductive step, we also simplify the expression using the same properties and the inductive hypothesis. -/
  unfold pushn; induction n <;> simp [Nat.repeat, Nat.add_assoc, *]","import Init.Data.List.Basic
import Init.Data.Char.Basic
import Init.Data.Option.Basic
import Init.Data.String.Basic

open String

"
38209,Substring.lt_next,"theorem Substring.lt_next (s : Substring) (i : String.Pos) (h : i.1 < s.bsize) :
    i.1 < (s.next i).1 := by sorry","Byte Index of Position is Less Than Byte Index of Next Codepoint in Substring : For any substring \( s \) and any byte position \( i \) in \( s \), if the byte index of \( i \) is strictly less than the byte size of \( s \), then the byte index of \( i \) is strictly less than the byte index of the next codepoint position in \( s \). In other words, if \( i \) is a valid position in \( s \) (i.e., \( i \) is not at the end of \( s \)), then \( i \) is strictly less than the position of the next codepoint.","theorem Substring.lt_next (s : Substring) (i : String.Pos) (h : i.1 < s.bsize) :
    i.1 < (s.next i).1 := by
  simp [next]; rw [if_neg ?a]
  case a =>
    refine mt (congrArg String.Pos.byteIdx) (Nat.ne_of_lt ?_)
    exact (Nat.add_comm .. ▸ Nat.add_lt_of_lt_sub h :)
  apply Nat.lt_sub_of_add_lt
  rw [Nat.add_comm]; apply String.lt_next","We start by simplifying the goal using the definition of `Substring.next`. This definition states that the next position in the substring is either the current position \( i \) if \( s.\text{startPos} + i = s.\text{stopPos} \), or the position obtained by advancing the current position in the original string and adjusting for the starting position of the substring. Since the condition \( s.\text{startPos} + i = s.\text{stopPos} \) is false, we can replace the goal with the else branch of the if-then-else expression. This simplifies the goal to showing that \( i.\text{byteIdx} < (s.\text{str.next}(s.\text{startPos} + i)).\text{byteIdx} - s.\text{startPos}.\text{byteIdx} \).

Next, we consider the case where \( s.\text{startPos} + i \neq s.\text{stopPos} \). To show this, we use the fact that if two byte positions are equal, their byte indices are also equal. We need to show that \( (s.\text{startPos} + i).\text{byteIdx} \neq s.\text{stopPos}.\text{byteIdx} \). This is equivalent to showing that \( (s.\text{startPos} + i).\text{byteIdx} < s.\text{stopPos}.\text{byteIdx} \). Using the commutativity of addition and the given hypothesis \( i.\text{byteIdx} < s.\text{bsize} \), we can show that \( (s.\text{startPos} + i).\text{byteIdx} < s.\text{stopPos}.\text{byteIdx} \).

To prove the current goal \( i.\text{byteIdx} < (s.\text{str.next}(s.\text{startPos} + i)).\text{byteIdx} - s.\text{startPos}.\text{byteIdx} \), we use the theorem that if \( a + b < c \), then \( a < c - b \). Therefore, it suffices to show that \( i.\text{byteIdx} + s.\text{startPos}.\text{byteIdx} < (s.\text{str.next}(s.\text{startPos} + i)).\text{byteIdx} \).

We use the commutativity of addition to rewrite the goal as \( s.\text{startPos}.\text{byteIdx} + i.\text{byteIdx} < (s.\text{str.next}(s.\text{startPos} + i)).\text{byteIdx} \). Then, we apply the theorem that for any string \( s \) and any valid byte position \( i \) in \( s \), the byte index of \( i \) is strictly less than the byte index of the next valid byte position \( s.\text{next}(i) \). This completes the proof. \(\blacksquare\)","theorem Substring.lt_next (s : Substring) (i : String.Pos) (h : i.1 < s.bsize) :
    i.1 < (s.next i).1 := by
/- First, we simplify the goal using the definition of `Substring.next`. This definition states that the next position in the substring is either the current position \( i \) if \( s.\text{startPos} + i = s.\text{stopPos} \), or the position obtained by advancing the current position in the original string and adjusting for the starting position of the substring. Since the condition \( s.\text{startPos} + i = s.\text{stopPos} \) is false, we can replace the goal with the else branch of the if-then-else expression. This simplifies the goal to showing that \( i.\text{byteIdx} < (s.\text{str.next}(s.\text{startPos} + i)).\text{byteIdx} - s.\text{startPos}.\text{byteIdx} \). -/
  simp [next]; rw [if_neg ?a]
/- We now consider the case where \( s.\text{startPos} + i \neq s.\text{stopPos} \). To show this, we use the fact that if two byte positions are equal, their byte indices are also equal. We need to show that \( (s.\text{startPos} + i).\text{byteIdx} \neq s.\text{stopPos}.\text{byteIdx} \). This is equivalent to showing that \( (s.\text{startPos} + i).\text{byteIdx} < s.\text{stopPos}.\text{byteIdx} \). Using the commutativity of addition and the given hypothesis \( i.\text{byteIdx} < s.\text{bsize} \), we can show that \( (s.\text{startPos} + i).\text{byteIdx} < s.\text{stopPos}.\text{byteIdx} \). -/
  case a =>
    refine mt (congrArg String.Pos.byteIdx) (Nat.ne_of_lt ?_)
    exact (Nat.add_comm .. ▸ Nat.add_lt_of_lt_sub h :)
/- To prove the current goal \( i.\text{byteIdx} < (s.\text{str.next}(s.\text{startPos} + i)).\text{byteIdx} - s.\text{startPos}.\text{byteIdx} \), we use the theorem that if \( a + b < c \), then \( a < c - b \). Therefore, it suffices to show that \( i.\text{byteIdx} + s.\text{startPos}.\text{byteIdx} < (s.\text{str.next}(s.\text{startPos} + i)).\text{byteIdx} \). -/
  apply Nat.lt_sub_of_add_lt
/- We use the commutativity of addition to rewrite the goal as \( s.\text{startPos}.\text{byteIdx} + i.\text{byteIdx} < (s.\text{str.next}(s.\text{startPos} + i)).\text{byteIdx} \). Then, we apply the theorem that for any string \( s \) and any valid byte position \( i \) in \( s \), the byte index of \( i \) is strictly less than the byte index of the next valid byte position \( s.\text{next}(i) \). This completes the proof. -/
  rw [Nat.add_comm]; apply String.lt_next","import Init.Data.List.Basic
import Init.Data.Char.Basic
import Init.Data.Option.Basic
import Init.Data.String.Basic

open Substring

"
38394,Nat.log2_le_self,theorem Nat.log2_le_self (n : Nat) : Nat.log2 n ≤ n := by sorry,"Base 2 Logarithm is Less Than or Equal to the Number: \(\text{Nat.log2}(n) \leq n\) : For any natural number \( n \), the base 2 logarithm of \( n \), denoted as \(\lfloor \max(0, \log_2 n) \rfloor\), is less than or equal to \( n \). In other words, \(\text{Nat.log2}(n) \leq n\).","theorem Nat.log2_le_self (n : Nat) : Nat.log2 n ≤ n := by
  unfold Nat.log2; split
  · next h =>
    have := log2_le_self (n / 2)
    exact Nat.lt_of_le_of_lt this (Nat.div_lt_self (Nat.le_of_lt h) (by decide))
  · apply Nat.zero_le
decreasing_by exact Nat.log2_terminates _ ‹_›","We start by expanding the definition of \(\text{Nat.log2}\), which is defined as:
\[
\text{Nat.log2}(n) = \begin{cases}
(n / 2).log2 + 1 & \text{if } n \geq 2 \\
0 & \text{otherwise}
\end{cases}
\]
We then split the proof into two cases based on whether \( n \geq 2 \) or \( n < 2 \).

**Case 1: \( n \geq 2 \)**
In this case, we need to show that \((n / 2).log2 + 1 \leq n\). We construct a lemma that \((n / 2).log2 \leq n / 2\). Using this lemma and the fact that \( n / 2 < n \) (since \( n \geq 2 \)), we conclude that:
\[
(n / 2).log2 + 1 \leq n / 2 + 1 \leq n
\]

**Case 2: \( n < 2 \)**
In this case, we need to show that \(0 \leq n\). This is true because \(0\) is less than or equal to any natural number.

Finally, we ensure that the recursive definition of \(\text{Nat.log2}\) terminates by showing that for any \( n \geq 2 \), \( n / 2 < n \).

Thus, we have shown that \(\text{Nat.log2}(n) \leq n\) for any natural number \( n \). This completes the proof. \(\blacksquare\)","theorem Nat.log2_le_self (n : Nat) : Nat.log2 n ≤ n := by
/- First, we expand the definition of \(\text{Nat.log2}\), which is defined as \(\text{Nat.log2}(n) = \begin{cases}
(n / 2).log2 + 1 & \text{if } n \geq 2 \\
0 & \text{otherwise}
\end{cases}\). We then split the proof into two cases based on whether \( n \geq 2 \) or \( n < 2 \). -/
  unfold Nat.log2; split
/- We consider the case where \( n \geq 2 \). In this case, we need to show that \((n / 2).log2 + 1 \leq n\). -/
  · next h =>
/- We construct a lemma that \((n / 2).log2 \leq n / 2\). -/
    have := log2_le_self (n / 2)
/- Using the lemma \((n / 2).log2 \leq n / 2\) and the fact that \( n / 2 < n \) (since \( n \geq 2 \)), we conclude that \((n / 2).log2 + 1 \leq n\). -/
    exact Nat.lt_of_le_of_lt this (Nat.div_lt_self (Nat.le_of_lt h) (by decide))
/- We consider the case where \( n < 2 \). In this case, we need to show that \(0 \leq n\). This is true because \(0\) is less than or equal to any natural number. -/
  · apply Nat.zero_le
/- We ensure that the recursive definition of \(\text{Nat.log2}\) terminates by showing that for any \( n \geq 2 \), \( n / 2 < n \). -/
decreasing_by exact Nat.log2_terminates _ ‹_›","import Init.Data.Nat.Linear
import Init.Data.Nat.Log2

open Nat

"
38992,ite_id,theorem ite_id [Decidable c] {α} (t : α) : (if c then t else t) = t := by sorry,"If-then-else Identity: $(\text{if } c \text{ then } t \text{ else } t) = t$ : For any proposition $c$ and any type $\alpha$, if $c$ is decidable, then the if-then-else expression `if c then t else t` is equal to $t$ for any element $t \in \alpha$. In other words, $(\text{if } c \text{ then } t \text{ else } t) = t$.","theorem ite_id [Decidable c] {α} (t : α) : (if c then t else t) = t := by
  split <;> rfl","We need to show that the if-then-else expression $(\text{if } c \text{ then } t \text{ else } t)$ is equal to $t$ for any element $t \in \alpha$. We discuss by cases based on the condition $c$:

1. **Case 1: $c$ is true.**
- In this case, the expression $(\text{if } c \text{ then } t \text{ else } t)$ simplifies to $t$.
- Therefore, we need to show that $t = t$.
- This is trivially true due to the reflexive property of equality.

2. **Case 2: $c$ is false.**
- In this case, the expression $(\text{if } c \text{ then } t \text{ else } t)$ simplifies to $t$.
- Therefore, we need to show that $t = t$.
- This is also trivially true due to the reflexive property of equality.

Since both cases are trivially true, we conclude that $(\text{if } c \text{ then } t \text{ else } t) = t$ for any element $t \in \alpha$. This completes the proof. $\blacksquare$","theorem ite_id [Decidable c] {α} (t : α) : (if c then t else t) = t := by
  split <;> rfl","import Init.Classical
import Init.ByCases



"
38998,apply_dite,"theorem apply_dite (f : α → β) (P : Prop) [Decidable P] (x : P → α) (y : ¬P → α) :
    f (dite P x y) = dite P (fun h => f (x h)) (fun h => f (y h)) := by sorry","Function Application to Dependent If-Then-Else Construct: $f(\text{dite } P \, x \, y) = \text{if } h : P \text{ then } f(x(h)) \text{ else } f(y(h))$ : For any types $\alpha$ and $\beta$, a function $f : \alpha \to \beta$, a decidable proposition $P$, and two functions $x : P \to \alpha$ and $y : \neg P \to \alpha$, the application of $f$ to the dependent if-then-else construct `dite P x y` is equal to the if-then-else construct applied to $f$ on each branch. Specifically, if $P$ is true, then $f(\text{dite } P \, x \, y) = f(x(h))$ where $h$ is a proof of $P$; if $P$ is false, then $f(\text{dite } P \, x \, y) = f(y(h))$ where $h$ is a proof of $\neg P$.","theorem apply_dite (f : α → β) (P : Prop) [Decidable P] (x : P → α) (y : ¬P → α) :
    f (dite P x y) = dite P (fun h => f (x h)) (fun h => f (y h)) := by
  by_cases h : P <;> simp [h]","To prove the theorem, we consider two cases based on the truth of the proposition $P$.

1. **Case 1: Assume $P$ holds.**
- Let $h$ be a proof of $P$.
- We need to show that $f(\text{dite } P \, x \, y) = f(x(h))$.
- By the definition of the dependent if-then-else construct, $\text{dite } P \, x \, y = x(h)$ when $P$ is true.
- Therefore, $f(\text{dite } P \, x \, y) = f(x(h))$.

2. **Case 2: Assume $P$ does not hold.**
- Let $h$ be a proof of $\neg P$.
- We need to show that $f(\text{dite } P \, x \, y) = f(y(h))$.
- By the definition of the dependent if-then-else construct, $\text{dite } P \, x \, y = y(h)$ when $P$ is false.
- Therefore, $f(\text{dite } P \, x \, y) = f(y(h))$.

In both cases, the goal is satisfied. Hence, the theorem is proved. $\blacksquare$","theorem apply_dite (f : α → β) (P : Prop) [Decidable P] (x : P → α) (y : ¬P → α) :
    f (dite P x y) = dite P (fun h => f (x h)) (fun h => f (y h)) := by
/- Consider two cases: (1) Assume $P$ holds, and (2) Assume $P$ does not hold. In each case, we simplify the goal using the assumption $h$. -/
/- Consider two cases: (1) Assume $P$ holds, and (2) Assume $P$ does not hold. -/
/- In the case where $P$ holds, using the assumption $h : P$, we simplify the goal to show that $f(\text{dite } P \, x \, y) = f(x(h))$. -/
/- In the case where $P$ does not hold, using the assumption $h : \neg P$, we simplify the goal to show that $f(\text{dite } P \, x \, y) = f(y(h))$. -/
  by_cases h : P <;> simp [h]","import Init.Classical
import Init.ByCases



"
38999,dite_eq_left_iff,"theorem dite_eq_left_iff {P : Prop} [Decidable P] {B : ¬ P → α} :
    dite P (fun _ => a) B = a ↔ ∀ h, B h = a := by sorry","Dependent If-Then-Else Equals Left if and only if Negation of Condition Implies Left Value: $\text{dite } P \, (\lambda x. a) \, B = a \leftrightarrow \forall h : \neg P, B(h) = a$ : For any type $\alpha$, any element $a \in \alpha$, any proposition $P$, and any function $B : \neg P \to \alpha$, the dependent if-then-else construct `dite P (fun x => a) B` is equal to $a$ if and only if for all proofs $h$ of $\neg P$, $B(h) = a$. In other words, $\text{dite } P \, (\lambda x. a) \, B = a$ if and only if $\forall h : \neg P, B(h) = a$.","theorem dite_eq_left_iff {P : Prop} [Decidable P] {B : ¬ P → α} :
    dite P (fun _ => a) B = a ↔ ∀ h, B h = a := by
  by_cases P <;> simp [*, forall_prop_of_true, forall_prop_of_false]","We consider two cases based on the truth of the proposition $P$.

1. **Case 1: Assume $P$ holds.**
- In this case, the dependent if-then-else construct $\text{dite } P \, (\lambda x. a) \, B$ simplifies to $a$ because the condition $P$ is true.
- We need to show that $\text{dite } P \, (\lambda x. a) \, B = a$ is equivalent to $\forall h : \neg P, B(h) = a$.
- Since $P$ is true, the statement $\forall h : \neg P, B(h) = a$ is vacuously true because there are no proofs of $\neg P$.
- Therefore, $\text{dite } P \, (\lambda x. a) \, B = a$ is true, and the equivalence holds.

2. **Case 2: Assume $P$ does not hold.**
- In this case, the dependent if-then-else construct $\text{dite } P \, (\lambda x. a) \, B$ simplifies to $B(h)$ for any proof $h$ of $\neg P$.
- We need to show that $\text{dite } P \, (\lambda x. a) \, B = a$ is equivalent to $\forall h : \neg P, B(h) = a$.
- Since $P$ is false, the statement $\text{dite } P \, (\lambda x. a) \, B = a$ simplifies to $B(h) = a$ for any proof $h$ of $\neg P$.
- Therefore, $\text{dite } P \, (\lambda x. a) \, B = a$ is true if and only if $\forall h : \neg P, B(h) = a$.

In both cases, the equivalence $\text{dite } P \, (\lambda x. a) \, B = a \leftrightarrow \forall h : \neg P, B(h) = a$ holds. This completes the proof. $\blacksquare$","theorem dite_eq_left_iff {P : Prop} [Decidable P] {B : ¬ P → α} :
    dite P (fun _ => a) B = a ↔ ∀ h, B h = a := by
/- Consider two cases: (1) Assume $P$ holds, and (2) Assume $P$ does not hold. In each case, we simplify the proposition we want to show using the properties of universal quantification over true and false propositions. -/
  by_cases P <;> simp [*, forall_prop_of_true, forall_prop_of_false]","import Init.Classical
import Init.ByCases



"
39004,dite_eq_right_iff,"theorem dite_eq_right_iff {P : Prop} [Decidable P] {A : P → α} :
    (dite P A fun _ => b) = b ↔ ∀ h, A h = b := by sorry","Dependent If-Then-Else Equals Right if Proposition is True: $(\text{dite } P \, A \, (\lambda h, b)) = b \leftrightarrow (\forall h : P, A(h) = b)$ : For any type $\alpha$, any element $b \in \alpha$, and any decidable proposition $P$, the dependent if-then-else construct `dite P A (fun x => b)` is equal to $b$ if and only if for every proof $h$ of $P$, the function $A$ applied to $h$ is equal to $b$. In other words, if $P$ is true, then $A(h) = b$ for all proofs $h$ of $P$; if $P$ is false, then the result is $b$.","theorem dite_eq_right_iff {P : Prop} [Decidable P] {A : P → α} :
    (dite P A fun _ => b) = b ↔ ∀ h, A h = b := by
  by_cases P <;> simp [*, forall_prop_of_true, forall_prop_of_false]","We need to show that the dependent if-then-else construct `dite P A (fun x => b)` is equal to $b$ if and only if for every proof $h$ of $P$, $A(h) = b$.

Consider two cases:

1. **Case 1: Assume $P$ holds.**
- In this case, the dependent if-then-else construct `dite P A (fun x => b)` simplifies to $A(h)$, where $h$ is a proof of $P$.
- We need to show that $A(h) = b$ for any proof $h$ of $P$.
- By the property of universal quantification over true propositions, $\forall h : P, A(h) = b$ is equivalent to $A(h) = b$ for any proof $h$ of $P$.
- Therefore, in this case, `dite P A (fun x => b) = b` if and only if $A(h) = b$ for any proof $h$ of $P$.

2. **Case 2: Assume $P$ does not hold.**
- In this case, the dependent if-then-else construct `dite P A (fun x => b)` simplifies to $b$.
- We need to show that $\forall h : P, A(h) = b$ is true.
- By the property of universal quantification over false propositions, $\forall h : P, A(h) = b$ is equivalent to `True` if $P$ is false.
- Therefore, in this case, `dite P A (fun x => b) = b` is always true.

Combining both cases, we conclude that `dite P A (fun x => b) = b` if and only if for every proof $h$ of $P$, $A(h) = b$. This completes the proof. $\blacksquare$","theorem dite_eq_right_iff {P : Prop} [Decidable P] {A : P → α} :
    (dite P A fun _ => b) = b ↔ ∀ h, A h = b := by
/- Consider two cases: (1) Assume $P$ holds, and (2) Assume $P$ does not hold. In both cases, we simplify the proposition using the properties of universal quantification over true and false propositions. -/
/- Consider two cases: (1) Assume $P$ holds, and (2) Assume $P$ does not hold. -/
/- For each of the two cases, we will apply the simplification tactic to further refine or solve the goals. -/
/- Using the properties of universal quantification over true and false propositions, we simplify the proposition in both cases. Specifically, if $P$ is true, then $\forall h : P, A(h) = b$ is equivalent to $A(h) = b$ for any proof $h$ of $P$. If $P$ is false, then $\forall h : P, A(h) = b$ is equivalent to `True`. -/
  by_cases P <;> simp [*, forall_prop_of_true, forall_prop_of_false]","import Init.Classical
import Init.ByCases



"
39012,ite_some_none_eq_some,"theorem ite_some_none_eq_some [Decidable P] :
    (if P then some x else none) = some y ↔ P ∧ x = y := by sorry","If-then-else Equals Some if and only if Proposition is True and Elements are Equal: \((\text{if } P \text{ then } \text{some } x \text{ else } \text{none}) = \text{some } y \leftrightarrow P \land x = y\) : For any proposition \( P \) and any elements \( x, y \) of a type \( \alpha \), the if-then-else expression \((\text{if } P \text{ then } \text{some } x \text{ else } \text{none})\) is equal to \(\text{some } y\) if and only if \( P \) is true and \( x = y \).","theorem ite_some_none_eq_some [Decidable P] :
    (if P then some x else none) = some y ↔ P ∧ x = y := by
  split <;> simp_all","We need to show that \((\text{if } P \text{ then } \text{some } x \text{ else } \text{none}) = \text{some } y\) if and only if \( P \land x = y \).

We discuss by cases based on the condition \( P \):

1. **Case 1: \( P \) is true.**
- If \( P \) is true, the if-then-else expression \(\text{if } P \text{ then } \text{some } x \text{ else } \text{none}\) simplifies to \(\text{some } x\).
- Therefore, the goal is to show that \(\text{some } x = \text{some } y\) if and only if \( x = y \).
- This is trivially true because \(\text{some } x = \text{some } y\) if and only if \( x = y \).

2. **Case 2: \( P \) is false.**
- If \( P \) is false, the if-then-else expression \(\text{if } P \text{ then } \text{some } x \text{ else } \text{none}\) simplifies to \(\text{none}\).
- Therefore, the goal is to show that \(\text{none} = \text{some } y\) if and only if \( P \land x = y \).
- Since \(\text{none} \neq \text{some } y\), the left-hand side is \(\text{False}\).
- The right-hand side \( P \land x = y \) is also \(\text{False}\) because \( P \) is false.
- Thus, \(\text{False} \leftrightarrow \text{False}\) is true.

In both cases, the equivalence holds, completing the proof.","theorem ite_some_none_eq_some [Decidable P] :
    (if P then some x else none) = some y ↔ P ∧ x = y := by
/- We discuss by cases based on the condition \( P \).

1. **Case 1: \( P \) is true.**
- The goal is to show that \( \text{some } x = \text{some } y \) if and only if \( P \land x = y \).
- Since \( P \) is true, the if-then-else expression \(\text{if } P \text{ then } \text{some } x \text{ else } \text{none}\) simplifies to \(\text{some } x\).
- Therefore, the goal reduces to showing that \(\text{some } x = \text{some } y\) if and only if \( x = y \).
- This is trivially true because \(\text{some } x = \text{some } y\) if and only if \( x = y \).

2. **Case 2: \( P \) is false.**
- The goal is to show that \(\text{False} \leftrightarrow P \land x = y\).
- Since \( P \) is false, the if-then-else expression \(\text{if } P \text{ then } \text{some } x \text{ else } \text{none}\) simplifies to \(\text{none}\).
- Therefore, the goal reduces to showing that \(\text{none} = \text{some } y\) if and only if \( P \land x = y \).
- Since \(\text{none} \neq \text{some } y\), the left-hand side is \(\text{False}\).
- The right-hand side \( P \land x = y \) is also \(\text{False}\) because \( P \) is false.
- Thus, \(\text{False} \leftrightarrow \text{False}\) is true. -/
  split <;> simp_all","import Init.Classical
import Init.ByCases



"
39027,dite_some_none_eq_some,"theorem dite_some_none_eq_some [Decidable P] {x : P → α} {y : α} :
    (if h : P then some (x h) else none) = some y ↔ ∃ h : P, x h = y := by sorry","Dependent If-Then-Else Equals Some if and only if Proposition is True: \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none}) = \text{some } y \leftrightarrow \exists h, x(h) = y\) : For any proposition \( P \) and any type \( \alpha \), the dependent if-then-else expression \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none})\) is equal to \(\text{some } y\) if and only if there exists a proof \( h \) of \( P \) such that \( x(h) = y \).","theorem dite_some_none_eq_some [Decidable P] {x : P → α} {y : α} :
    (if h : P then some (x h) else none) = some y ↔ ∃ h : P, x h = y := by
  by_cases h : P <;> simp [h]","We need to show that \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none}) = \text{some } y\) if and only if \(\exists h, x h = y\).

Consider two cases:

1. **Case 1: \( P \) holds.**
- Assume \( P \) holds, and let \( h \) be a proof of \( P \).
- The expression \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none})\) simplifies to \(\text{some } (x h)\).
- Therefore, the goal \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none}) = \text{some } y\) simplifies to \(\text{some } (x h) = \text{some } y\), which is equivalent to \( x h = y \).
- Hence, in this case, the goal is \(\exists h, x h = y\).

2. **Case 2: \( P \) does not hold.**
- Assume \( P \) does not hold, and let \( h \) be a proof of \(\neg P\).
- The expression \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none})\) simplifies to \(\text{none}\).
- Therefore, the goal \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none}) = \text{some } y\) simplifies to \(\text{none} = \text{some } y\), which is a contradiction.
- Hence, this case is vacuously true.

Combining both cases, we conclude that \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none}) = \text{some } y\) if and only if \(\exists h, x h = y\). This completes the proof. \(\blacksquare\)","theorem dite_some_none_eq_some [Decidable P] {x : P → α} {y : α} :
    (if h : P then some (x h) else none) = some y ↔ ∃ h : P, x h = y := by
/- Consider two cases: (1) Assume \( P \) holds, and (2) Assume \( P \) does not hold. In each case, we simplify the proposition we want to show using the assumption \( h \). -/
/- In the case where \( P \) holds, the expression \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none})\) simplifies to \(\text{some } (x h)\). Therefore, the goal \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none}) = \text{some } y\) simplifies to \(\text{some } (x h) = \text{some } y\), which is equivalent to \( x h = y \). This means the goal is \(\exists h, x h = y\). -/
/- In the case where \( P \) does not hold, the expression \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none})\) simplifies to \(\text{none}\). Therefore, the goal \((\text{if } h : P \text{ then } \text{some } (x h) \text{ else } \text{none}) = \text{some } y\) simplifies to \(\text{none} = \text{some } y\), which is a contradiction. Hence, this case is vacuously true. -/
  by_cases h : P <;> simp [h]","import Init.Classical
import Init.ByCases



"
39427,List.takeWhile_eq_takeWhileTR,theorem List.takeWhile_eq_takeWhileTR : @takeWhile = @takeWhileTR := by sorry,"Equivalence of `takeWhile` and `takeWhileTR` for Lists : For any type \( \alpha \), any predicate \( p : \alpha \to \text{Bool} \), and any list \( xs : \text{List} \, \alpha \), the function `List.takeWhile` applied to \( p \) and \( xs \) returns the same list as the function `List.takeWhileTR` applied to \( p \) and \( xs \). In other words, the longest initial segment of \( xs \) that satisfies \( p \) is the same whether computed using the standard `List.takeWhile` function or the tail-recursive `List.takeWhileTR` function.","theorem List.takeWhile_eq_takeWhileTR : @takeWhile = @takeWhileTR := by
  funext α p l; simp [takeWhileTR]
  suffices ∀ xs acc, l = acc.data ++ xs →
      takeWhileTR.go p l xs acc = acc.data ++ xs.takeWhile p from
    (this l #[] (by simp)).symm
  intro xs; induction xs with intro acc
  | nil => simp [takeWhile, takeWhileTR.go]
  | cons x xs IH =>
    simp only [takeWhileTR.go, Array.toList_eq, takeWhile]
    split
    · intro h; rw [IH] <;> simp_all
    · simp [*]","To prove that `List.takeWhile p l` is equal to `List.takeWhileTR p l` for any list \( l \) of type \( \alpha \), we use the principle of function extensionality. This means we need to show that for all possible lists \( l \), the functions `List.takeWhile` and `List.takeWhileTR` yield the same result.

We start by simplifying the goal using the definition of `List.takeWhileTR`. This reduces our goal to showing that `List.takeWhile p l` is equal to `List.takeWhileTR.go p l l #[]`.

Next, we use induction on the list \( l \). For the base case, let \( l \) be the empty list. Using the definitions of `List.takeWhile` and `List.takeWhileTR.go`, we can simplify the goal to show that `List.takeWhileTR.go p [] [] #[]` is equal to \( #[] \). This is trivially true because both functions return the empty list when applied to an empty list.

For the inductive step, assume \( l \) is a non-empty list with head \( x \) and tail \( xs \). We need to show that for any array \( acc \), if \( l = acc.data ++ x :: xs \), then `List.takeWhileTR.go p l (x :: xs) acc` is equal to \( acc.data ++ x :: \text{List.takeWhile} \, p \, xs \).

Let \( h \) be the hypothesis that \( l = acc.data ++ x :: xs \). By the inductive hypothesis \( \text{IH} \), we know that for any array \( acc \), if \( l = acc.data ++ xs \), then `List.takeWhileTR.go p l xs acc` is equal to \( acc.data ++ \text{List.takeWhile} \, p \, xs \).

We now consider two cases based on the value of \( p(x) \):

1. **Case 1: \( p(x) \) is true.**
- By the inductive hypothesis \( \text{IH} \), we can replace `List.takeWhileTR.go p l xs (acc.push x)` with \( (acc.push x).data ++ \text{List.takeWhile} \, p \, xs \).
- Using the definition of `Array.push`, we know that \( (acc.push x).data = acc.data ++ [x] \).
- Therefore, the goal simplifies to showing \( (acc.data ++ [x]) ++ \text{List.takeWhile} \, p \, xs = acc.data ++ x :: \text{List.takeWhile} \, p \, xs \).
- This is trivially true by the properties of list concatenation.

2. **Case 2: \( p(x) \) is false.**
- By the inductive hypothesis \( \text{IH} \), we can replace `List.takeWhileTR.go p l xs (acc.push x)` with \( acc.data \).
- Therefore, the goal simplifies to showing \( acc.data = acc.data \).
- This is trivially true by the reflexivity of equality.

Thus, by induction, we have shown that for any list \( l \) of type \( \alpha \), `List.takeWhile p l` is equal to `List.takeWhileTR p l`. This completes the proof.","theorem List.takeWhile_eq_takeWhileTR : @takeWhile = @takeWhileTR := by
/- By the principle of function extensionality, it suffices to show that for all possible lists \( l \) of type \( \alpha \), the functions `List.takeWhile` and `List.takeWhileTR` yield the same result. Using the definition of `List.takeWhileTR`, we can simplify the goal to show that `List.takeWhile p l` is equal to `List.takeWhileTR.go p l l #[]`. -/
  funext α p l; simp [takeWhileTR]
/- To prove the current goal, it suffices to show that for any lists \( xs \) and arrays \( acc \), if \( l = acc.data ++ xs \), then `List.takeWhileTR.go p l xs acc` is equal to \( acc.data ++ \text{List.takeWhile} \, p \, xs \). This is because, by simplifying the expression using the known properties, we can deduce that `List.takeWhile p l` is equal to `List.takeWhileTR.go p l l #[]`. -/
  suffices ∀ xs acc, l = acc.data ++ xs →
      takeWhileTR.go p l xs acc = acc.data ++ xs.takeWhile p from
    (this l #[] (by simp)).symm
/- Let \( xs \) be an arbitrary list of type \( \alpha \). We will prove the statement by induction on \( xs \). For the base case, let \( xs \) be the empty list. For the inductive step, assume \( xs \) is a non-empty list with head \( x \) and tail \( xs \), and let \( acc \) be an arbitrary array of type \( \alpha \). -/
  intro xs; induction xs with intro acc
/- For the base case where \( xs \) is the empty list, using the definitions of `List.takeWhile` and `List.takeWhileTR.go`, we can simplify the goal to show that `List.takeWhileTR.go p l [] acc` is equal to \( acc.data \). This is trivially true because both functions return the empty list when applied to an empty list. -/
  | nil => simp [takeWhile, takeWhileTR.go]
/- For the inductive step where \( xs \) is a non-empty list with head \( x \) and tail \( xs \), assume the inductive hypothesis \( \text{IH} \) that for any array \( acc \), if \( l = acc.data ++ xs \), then `List.takeWhileTR.go p l xs acc` is equal to \( acc.data ++ \text{List.takeWhile} \, p \, xs \). -/
  | cons x xs IH =>
    simp only [takeWhileTR.go, Array.toList_eq, takeWhile]
    split
/- Let \( h \) be the hypothesis that \( l = acc.data ++ x :: xs \). By the inductive hypothesis \( \text{IH} \), we can replace `List.takeWhileTR.go p l xs (acc.push x)` with \( (acc.push x).data ++ \text{List.takeWhile} \, p \, xs \). After simplifying the expression using the known properties, we get that the goal is to show \( (bif \, p \, x \, \text{then} \, (acc.push x).data ++ \text{List.takeWhile} \, p \, xs \, \text{else} \, acc.data) = acc.data ++ x :: \text{List.takeWhile} \, p \, xs \). -/
    · intro h; rw [IH] <;> simp_all
/- Using the known properties and the inductive hypothesis, we can simplify the goal to show that \( (bif \, p \, x \, \text{then} \, (acc.push x).data ++ \text{List.takeWhile} \, p \, xs \, \text{else} \, acc.data) = acc.data ++ [] \). This is trivially true because if \( p(x) \) is false, both sides of the equation are equal to \( acc.data \). -/
    · simp [*]","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
39428,List.replace_eq_replaceTR,theorem List.replace_eq_replaceTR : @List.replace = @replaceTR := by sorry,"Equality of List Replacement Functions: `List.replace = List.replaceTR` : For any type \( \alpha \) equipped with a binary equality operation, and for any list \( l \) of elements of type \( \alpha \), and for any elements \( b \) and \( c \) of type \( \alpha \), the function `List.replace` that replaces the first occurrence of \( b \) in \( l \) with \( c \) is equal to the tail-recursive function `List.replaceTR` that performs the same operation.","theorem List.replace_eq_replaceTR : @List.replace = @replaceTR := by
  funext α _ l b c; simp [replaceTR]
  suffices ∀ xs acc, l = acc.data ++ xs →
      replaceTR.go l b c xs acc = acc.data ++ xs.replace b c from
    (this l #[] (by simp)).symm
  intro xs; induction xs with intro acc
  | nil => simp [replace, replaceTR.go]
  | cons x xs IH =>
    simp only [replaceTR.go, Array.toListAppend_eq, replace]
    split
    · simp [*]
    · intro h; rw [IH] <;> simp_all","To prove that the function `List.replace` is equal to the tail-recursive function `List.replaceTR`, we use the principle of function extensionality. This means we need to show that for all possible arguments \( \alpha \), \( l \), \( b \), and \( c \), the functions yield the same result. Specifically, we need to show that:
\[ l.replace \, b \, c = \text{replaceTR.go} \, l \, b \, c \, l \, \#[] \]

We will perform induction on the list \( l \).

**Base Case:**
For the base case where \( l = [] \), we need to show:
\[ \text{replaceTR.go} \, [] \, b \, c \, [] \, \#[] = \#[] \]
Using the definitions of `List.replace` and `List.replaceTR.go`, both functions return the empty list when the input list is empty. Therefore, the base case is trivially true.

**Inductive Step:**
For the inductive step, assume \( l = x :: xs \) for some \( x \) and \( xs \). We need to show:
\[ \text{replaceTR.go} \, (x :: xs) \, b \, c \, (x :: xs) \, \#[] = (x :: xs).replace \, b \, c \]

We will consider two cases based on the condition \( b == x \).

**Case 1: \( b == x \) is true**
In this case, we need to show:
\[ (x :: xs).replace \, b \, c = c :: xs \]
Using the definition of `List.replace`, if \( b == x \) is true, then the first occurrence of \( b \) in \( x :: xs \) is replaced by \( c \), resulting in \( c :: xs \). Therefore, the goal is trivially true.

**Case 2: \( b == x \) is false**
In this case, we need to show:
\[ \text{replaceTR.go} \, (x :: xs) \, b \, c \, (x :: xs) \, \#[] = x :: xs.replace \, b \, c \]
Using the definition of `List.replaceTR.go`, if \( b == x \) is false, the function calls itself recursively with the list \( xs \) and the array \( \#[] \) extended by \( x \). By the inductive hypothesis, we have:
\[ \text{replaceTR.go} \, l \, b \, c \, xs \, (\#[] \, \text{push} \, x) = (\#[] \, \text{push} \, x).data ++ xs.replace \, b \, c \]
Since \( (\#[] \, \text{push} \, x).data = [x] \), the goal simplifies to:
\[ x :: \text{replaceTR.go} \, l \, b \, c \, xs \, \#[] = x :: xs.replace \, b \, c \]
By the inductive hypothesis, this is true. Therefore, the inductive step is also satisfied.

By induction, we have shown that for any list \( l \) and elements \( b \) and \( c \), the function `List.replace` is equal to the tail-recursive function `List.replaceTR`. This completes the proof.","theorem List.replace_eq_replaceTR : @List.replace = @replaceTR := by
/- By the principle of function extensionality, it suffices to show that for all possible arguments \( \alpha \), \( l \), \( b \), and \( c \), the functions `List.replace` and `List.replaceTR` yield the same result. Using the definition of `List.replaceTR`, we can simplify the goal to show that \( l.replace \, b \, c = \text{replaceTR.go} \, l \, b \, c \, l \, \#[] \). -/
  funext α _ l b c; simp [replaceTR]
/- To prove the current goal, it suffices to show that for any list \( xs \) and array \( acc \), if \( l = acc.data ++ xs \), then \( \text{replaceTR.go} \, l \, b \, c \, xs \, acc = acc.data ++ xs.replace \, b \, c \). This is because, by simplifying the expression \( l = \#[].data ++ l \) and using the symmetry of equality, we can reduce the original goal to this new goal. -/
  suffices ∀ xs acc, l = acc.data ++ xs →
      replaceTR.go l b c xs acc = acc.data ++ xs.replace b c from
    (this l #[] (by simp)).symm
/- Let \( xs \) be an arbitrary list of elements of type \( \alpha \). We will perform induction on \( xs \) and consider the following cases:
- Base case: \( xs = [] \)
- Inductive step: \( xs = x :: xs' \) for some \( x \) and \( xs' \)

For the base case, let \( acc \) be an arbitrary array of elements of type \( \alpha \). We need to show that if \( l = acc.data ++ [] \), then \( \text{replaceTR.go} \, l \, b \, c \, [] \, acc = acc.data ++ [].replace \, b \, c \). -/
  intro xs; induction xs with intro acc
/- For the base case where \( xs = [] \), we simplify the goal using the definitions of `List.replace` and `List.replaceTR.go`. Since \( l = acc.data ++ [] \) implies \( l = acc.data \), and both `List.replace` and `List.replaceTR.go` return the same result when the list is empty, the goal is trivially satisfied. -/
  | nil => simp [replace, replaceTR.go]
/- For the inductive step where \( xs = x :: xs' \), we assume the inductive hypothesis (IH) that for any array \( acc \), if \( l = acc.data ++ xs' \), then \( \text{replaceTR.go} \, l \, b \, c \, xs' \, acc = acc.data ++ xs'.replace \, b \, c \). We need to show that if \( l = acc.data ++ x :: xs' \), then \( \text{replaceTR.go} \, l \, b \, c \, (x :: xs') \, acc = acc.data ++ (x :: xs').replace \, b \, c \). -/
  | cons x xs IH =>
/- Using the definitions of `List.replaceTR.go`, `Array.toListAppend_eq`, and `List.replace`, we can simplify the goal to:
\[ l = acc.data ++ x :: xs' \to
(bif \, b == x \, then \, acc.data ++ c :: xs' \, else \, \text{replaceTR.go} \, l \, b \, c \, xs' \, (acc.push \, x)) = acc.data ++ (x :: xs').replace \, b \, c \] -/
    simp only [replaceTR.go, Array.toListAppend_eq, replace]
/- We discuss by cases based on the condition \( b == x \):
- Case 1: \( b == x \) is true
- Case 2: \( b == x \) is false -/
    split
/- For the case where \( b == x \) is true, we simplify the goal using the known hypotheses. Since \( b == x \) is true, the goal reduces to:
\[ l = acc.data ++ x :: xs' \to
(acc.data ++ c :: xs') = acc.data ++ c :: xs' \]
This is trivially true by the properties of list concatenation. -/
    · simp [*]
/- For the case where \( b == x \) is false, we introduce the hypothesis \( h \) that \( l = acc.data ++ x :: xs' \). Using the inductive hypothesis (IH), we can rewrite the goal to:
\[ l = (acc.push \, x).data ++ xs' \]
Then, we simplify the goal and the hypothesis using the known lemmas and definitions. The goal reduces to:
\[ (acc.push \, x).data ++ xs'.replace \, b \, c = acc.data ++ x :: xs'.replace \, b \, c \]
This is also trivially true by the properties of list concatenation and the inductive hypothesis. -/
    · intro h; rw [IH] <;> simp_all","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
39429,List.take_eq_takeTR,theorem List.take_eq_takeTR : @take = @takeTR := by sorry,"Equality of `List.take` and `List.takeTR` Functions : For any type \( \alpha \) and any natural number \( n \), the function `List.take` that returns the first \( n \) elements of a list \( xs \) of elements of type \( \alpha \) is equal to the tail-recursive function `List.takeTR` that also returns the first \( n \) elements of the same list \( xs \). In other words, for any list \( xs \) and any natural number \( n \), `List.take n xs = List.takeTR n xs`.","theorem List.take_eq_takeTR : @take = @takeTR := by
  funext α n l; simp [takeTR]
  suffices ∀ xs acc, l = acc.data ++ xs → takeTR.go l xs n acc = acc.data ++ xs.take n from
    (this l #[] (by simp)).symm
  intro xs; induction xs generalizing n with intro acc
  | nil => cases n <;> simp [take, takeTR.go]
  | cons x xs IH =>
    cases n with simp only [take, takeTR.go]
    | zero => simp
    | succ n => intro h; rw [IH] <;> simp_all","To prove that `List.take` and `List.takeTR` are equal, we use the principle of function extensionality. This means we need to show that for all possible arguments \( \alpha \), \( n \), and \( l \), the functions `List.take` and `List.takeTR` yield the same result. Specifically, we need to show that `List.take n l = List.takeTR.go l l n #[]`.

We will perform induction on the list \( l \) and generalize over \( n \).

**Base Case:**
For the base case where \( l \) is the empty list, we need to show that for any array \( acc \), if \( l = acc.data ++ [] \), then `List.takeTR.go l [] n acc = acc.data ++ List.take n []`.

1. If \( n = 0 \), by the definitions of `List.take` and `List.takeTR.go`, we have:
\[
\text{List.take} \, 0 \, l = [] \quad \text{and} \quad \text{List.takeTR.go} \, l \, [] \, 0 \, acc = \text{acc.toList}
\]
Since \(\text{acc.toList} = \text{acc.data} ++ []\), the base case holds.

2. If \( n = n' + 1 \) for some \( n' \), by the definitions of `List.take` and `List.takeTR.go`, we have:
\[
\text{List.take} \, (n' + 1) \, l = l \quad \text{and} \quad \text{List.takeTR.go} \, l \, [] \, (n' + 1) \, acc = l
\]
Since \( l = \text{acc.data} ++ l \), the base case holds.

**Inductive Step:**
For the inductive step, assume \( l = x :: xs \) for some element \( x \) and list \( xs \). We need to show that for any natural number \( n \) and array \( acc \), if \( l = acc.data ++ x :: xs \), then `List.takeTR.go l (x :: xs) n acc = acc.data ++ List.take n (x :: xs)`.

We will consider two cases for \( n \):

1. If \( n = 0 \), by the definitions of `List.take` and `List.takeTR.go`, we have:
\[
\text{List.take} \, 0 \, (x :: xs) = [] \quad \text{and} \quad \text{List.takeTR.go} \, l \, (x :: xs) \, 0 \, acc = \text{acc.toList}
\]
Since \(\text{acc.toList} = \text{acc.data} ++ []\), the inductive step holds for \( n = 0 \).

2. If \( n = n' + 1 \) for some \( n' \), we introduce the hypothesis \( h \) that \( l = acc.data ++ x :: xs \). By the inductive hypothesis \( IH \), we know that for any natural number \( n' \) and array \( acc \), if \( l = acc.data ++ xs \), then `List.takeTR.go l xs n' acc = acc.data ++ List.take n' xs`.

Using this inductive hypothesis, we can replace `List.takeTR.go l xs n' (acc.push x)` with `acc.data ++ List.take n' xs`. Therefore, we need to show:
\[
(acc.push x).data ++ \text{List.take} \, n' \, xs = \text{acc.data} ++ x :: \text{List.take} \, n' \, xs
\]
By the definition of `Array.push`, we have:
\[
(acc.push x).data = \text{acc.data} ++ [x]
\]
Thus, the left-hand side becomes:
\[
(\text{acc.data} ++ [x]) ++ \text{List.take} \, n' \, xs = \text{acc.data} ++ x :: \text{List.take} \, n' \, xs
\]
This is true by the associativity of list concatenation.

Therefore, by induction, we have shown that for any list \( l \) and any natural number \( n \), `List.take n l = List.takeTR n l`. This completes the proof.","theorem List.take_eq_takeTR : @take = @takeTR := by
/- By the principle of function extensionality, it suffices to show that for all possible arguments \( \alpha \), \( n \), and \( l \), the functions `List.take` and `List.takeTR` yield the same result. Using the definition of `List.takeTR`, we can simplify the goal to show that `List.take n l = List.takeTR.go l l n #[]`. -/
  funext α n l; simp [takeTR]
/- To prove the current goal, it suffices to show that for any lists \( xs \) and arrays \( acc \), if \( l = acc.data ++ xs \), then `List.takeTR.go l xs n acc = acc.data ++ List.take n xs`. This is because, by simplifying the expression using the definitions of `List.take` and `List.takeTR`, we can conclude that `List.take n l = List.takeTR.go l l n #[]` holds. -/
  suffices ∀ xs acc, l = acc.data ++ xs → takeTR.go l xs n acc = acc.data ++ xs.take n from
    (this l #[] (by simp)).symm
/- Let \( xs \) be an arbitrary list. We will perform induction on \( xs \) and generalize over \( n \). For the base case, we need to show that for any array \( acc \), if \( l = acc.data ++ [] \), then `List.takeTR.go l [] n acc = acc.data ++ List.take n []`. For the inductive step, we assume the inductive hypothesis \( IH \) that for any natural number \( n \) and array \( acc \), if \( l = acc.data ++ xs \), then `List.takeTR.go l xs n acc = acc.data ++ List.take n xs`. We need to show that for any element \( x \) and list \( xs \), if \( l = acc.data ++ x :: xs \), then `List.takeTR.go l (x :: xs) n acc = acc.data ++ List.take n (x :: xs)`. -/
  intro xs; induction xs generalizing n with intro acc
/- For the base case where \( xs \) is the empty list, we consider two cases for \( n \):
1. If \( n = 0 \), then by the definitions of `List.take` and `List.takeTR.go`, we have `List.take 0 l = []` and `List.takeTR.go l [] 0 acc = acc.toList`, which simplifies to `acc.data ++ []`.
2. If \( n = n' + 1 \) for some \( n' \), then by the definitions of `List.take` and `List.takeTR.go`, we have `List.take (n' + 1) l = l` and `List.takeTR.go l [] (n' + 1) acc = l`, which simplifies to `acc.data ++ l`. -/
  | nil => cases n <;> simp [take, takeTR.go]
/- For the inductive step where \( xs \) is a non-empty list \( x :: xs \), we assume the inductive hypothesis \( IH \) that for any natural number \( n \) and array \( acc \), if \( l = acc.data ++ xs \), then `List.takeTR.go l xs n acc = acc.data ++ List.take n xs`. -/
  | cons x xs IH =>
    cases n with simp only [take, takeTR.go]
/- If \( n = 0 \), then by the definitions of `List.take` and `List.takeTR.go`, we have `List.take 0 (x :: xs) = []` and `List.takeTR.go l (x :: xs) 0 acc = acc.toList`, which simplifies to `acc.data ++ []`. -/
    | zero => simp
/- If \( n = n' + 1 \) for some \( n' \), we introduce the hypothesis \( h \) that \( l = acc.data ++ x :: xs \). By the inductive hypothesis \( IH \), we can replace `List.takeTR.go l xs n' (acc.push x)` with `acc.data ++ List.take n' xs`. Using this, we simplify the goal to show that \((acc.push x).data ++ List.take n' xs = acc.data ++ x :: List.take n' xs\). This simplifies to \( l = (acc.push x).data ++ xs \), which is true by the definition of `Array.push`. -/
    | succ n => intro h; rw [IH] <;> simp_all","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
39430,List.erase_eq_eraseTR,theorem List.erase_eq_eraseTR : @List.erase = @eraseTR := by sorry,"Equivalence of `List.erase` and `List.eraseTR` : For any type \( \alpha \) equipped with a binary equality operation, the function `List.erase` that removes the first occurrence of an element from a list is equal to the tail-recursive function `List.eraseTR` that performs the same operation. Formally, for any list \( l : \text{List} \, \alpha \) and any element \( a : \alpha \), the result of `List.erase l a` is the same as the result of `List.eraseTR l a`.","theorem List.erase_eq_eraseTR : @List.erase = @eraseTR := by
  funext α _ l a; simp [eraseTR]
  suffices ∀ xs acc, l = acc.data ++ xs → eraseTR.go l a xs acc = acc.data ++ xs.erase a from
    (this l #[] (by simp)).symm
  intro xs; induction xs with intro acc h
  | nil => simp [List.erase, eraseTR.go, h]
  | cons x xs IH =>
    simp only [eraseTR.go, Array.toListAppend_eq, List.erase]
    cases x == a
    · rw [IH] <;> simp_all
    · simp","To prove that the function `List.erase` is equal to the tail-recursive function `List.eraseTR`, we use the principle of function extensionality. This means we need to show that for all possible lists \( l \) and elements \( a \) of type \( \alpha \), the functions `List.erase` and `List.eraseTR` yield the same result. Specifically, we need to show that \( l.\text{erase} \, a = \text{eraseTR.go} \, l \, a \, l \, \#[] \).

We will perform induction on the list \( l \).

**Base Case:**
If \( l \) is the empty list, i.e., \( l = [] \), then using the definitions of `List.erase` and `List.eraseTR.go`, and the hypothesis \( l = \text{acc.data} \, ++ \, [] \), we can simplify the proposition to:
\[ [].\text{erase} \, a = \text{eraseTR.go} \, [] \, a \, [] \, \#[] \]
Since both `List.erase` and `List.eraseTR.go` return the empty list when applied to the empty list, we have:
\[ [] = \#[] \]
This is trivially true.

**Inductive Step:**
Assume \( l \) is a non-empty list, i.e., \( l = x :: xs \). We will use the induction hypothesis \( \text{IH} \), which states that for any array \( \text{acc} \), if \( l = \text{acc.data} \, ++ \, xs \), then:
\[ \text{eraseTR.go} \, l \, a \, xs \, \text{acc} = \text{acc.data} \, ++ \, xs.\text{erase} \, a \]

We need to show:
\[ (x :: xs).\text{erase} \, a = \text{eraseTR.go} \, (x :: xs) \, a \, (x :: xs) \, \#[] \]

We will discuss every possible case of \( x == a \).

**Case 1: \( x = a \)**
Using the definitions of `List.erase` and `List.eraseTR.go`, and the hypothesis \( l = \text{acc.data} \, ++ \, x :: xs \), we can simplify the proposition to:
\[ (x :: xs).\text{erase} \, a = \text{acc.data} \, ++ \, xs \]
Since \( x = a \), the left-hand side simplifies to:
\[ xs = \text{acc.data} \, ++ \, xs \]
This is trivially true.

**Case 2: \( x \neq a \)**
Using the definitions of `List.erase` and `List.eraseTR.go`, and the hypothesis \( l = \text{acc.data} \, ++ \, x :: xs \), we can simplify the proposition to:
\[ (x :: xs).\text{erase} \, a = x :: (xs.\text{erase} \, a) \]
and
\[ \text{eraseTR.go} \, (x :: xs) \, a \, (x :: xs) \, \#[] = x :: \text{eraseTR.go} \, xs \, a \, xs \, (\#[].\text{push} \, x) \]

By the induction hypothesis \( \text{IH} \), we have:
\[ \text{eraseTR.go} \, xs \, a \, xs \, (\#[].\text{push} \, x) = (\#[].\text{push} \, x).\text{data} \, ++ \, xs.\text{erase} \, a \]

Using the definition of `Array.push`, we know:
\[ (\#[].\text{push} \, x).\text{data} = \#[].\text{data} \, ++ \, [x] = [x] \]

Thus, the right-hand side simplifies to:
\[ x :: \text{eraseTR.go} \, xs \, a \, xs \, (\#[].\text{push} \, x) = x :: (\#[].\text{data} \, ++ \, xs.\text{erase} \, a) = x :: (xs.\text{erase} \, a) \]

Therefore, we have:
\[ (x :: xs).\text{erase} \, a = x :: (xs.\text{erase} \, a) \]
and
\[ \text{eraseTR.go} \, (x :: xs) \, a \, (x :: xs) \, \#[] = x :: (xs.\text{erase} \, a) \]

Both sides are equal, and the inductive step is complete.

By induction, we have shown that for any list \( l \) and any element \( a \) of type \( \alpha \), the result of `List.erase l a` is the same as the result of `List.eraseTR l a`. This completes the proof.","theorem List.erase_eq_eraseTR : @List.erase = @eraseTR := by
/- By the principle of function extensionality, it suffices to show that for all possible lists \( l \) and elements \( a \) of type \( \alpha \), the functions `List.erase` and `List.eraseTR` yield the same result. Using the definition of `List.eraseTR`, we can simplify the proposition we want to show to \( l.\text{erase} \, a = \text{eraseTR.go} \, l \, a \, l \, \#[] \). -/
/- It suffices to show that \( l.\text{erase} \, a = \text{eraseTR.go} \, l \, a \, l \, \#[] \) is equivalent to \( l = \#[] \). By using this equivalence and simplifying, we get the desired result. -/
  funext α _ l a; simp [eraseTR]
  suffices ∀ xs acc, l = acc.data ++ xs → eraseTR.go l a xs acc = acc.data ++ xs.erase a from
    (this l #[] (by simp)).symm
  intro xs; induction xs with intro acc h
/- We will discuss every possible case of \( l \). Case 1: \( l \) is the empty list. Using the definitions of `List.erase` and `List.eraseTR.go`, and the hypothesis \( l = \text{acc.data} \, ++ \, [] \), we can simplify the proposition to \( \#[] = \#[] \), which is trivially true. -/
  | nil => simp [List.erase, eraseTR.go, h]
/- Case 2: \( l \) is a non-empty list, i.e., \( l = x :: xs \). We will use the induction hypothesis \( \text{IH} \) which states that for any array \( \text{acc} \), if \( l = \text{acc.data} \, ++ \, xs \), then \( \text{eraseTR.go} \, l \, a \, xs \, \text{acc} = \text{acc.data} \, ++ \, xs.\text{erase} \, a \). -/
  | cons x xs IH =>
    simp only [eraseTR.go, Array.toListAppend_eq, List.erase]
    cases x == a
/- First, we apply the induction hypothesis \( \text{IH} \) to the current goal, which simplifies the proposition to \( \text{acc.data} \, ++ \, xs.\text{erase} \, a = \text{acc.data} \, ++ \, xs.\text{erase} \, a \). Then, we simplify the proposition and the hypothesis to show that the equality holds. -/
    · rw [IH] <;> simp_all
/- Let's concentrate on the proof of the case where \( x = a \). Using the definitions of `List.erase` and `List.eraseTR.go`, and the hypothesis \( l = \text{acc.data} \, ++ \, x :: xs \), we can simplify the proposition to \( \text{acc.data} \, ++ \, xs = \text{acc.data} \, ++ \, xs \), which is trivially true. -/
    · simp","import Init.Data.Array.Lemmas
import Init.Data.List.Impl

open List

"
39648,List.find?_replicate_of_neg,theorem List.find?_replicate_of_neg (h : ¬ p a) : find? p (replicate n a) = none := by sorry,"First Element Satisfying Predicate in Replicated List: \( p(a) = \text{false} \) Implies `List.find? p (List.replicate n a) = none \) : For any type \( \alpha \), predicate \( p : \alpha \to \text{Bool} \), natural number \( n \), and element \( a : \alpha \), if \( p(a) \) is false, then the result of `List.find? p (List.replicate n a)` is `none`. In other words, if \( p(a) \) is false, the function `List.find?` applied to the predicate \( p \) and a list containing \( n \) copies of \( a \) will not find any element that satisfies \( p \) and will return `none`.","theorem List.find?_replicate_of_neg (h : ¬ p a) : find? p (replicate n a) = none := by
  simp [find?_replicate, h]","We start by using the definition of `List.find?` on a replicated list. According to this definition:
- If \( n = 0 \), the result is `none`.
- If \( p(a) = \text{true} \), the result is `some a`.
- Otherwise, the result is `none`.

Given that \( p(a) \) is false, the third case applies. Therefore, the result of `List.find? p (List.replicate n a)` is `none`. This completes the proof.","theorem List.find?_replicate_of_neg (h : ¬ p a) : find? p (replicate n a) = none := by
/- Using the definition of `List.find?` on a replicated list and the assumption that \( p(a) \) is false, we can simplify the proposition we want to show. Specifically, the definition of `List.find?` on a replicated list states that:
- If \( n = 0 \), the result is `none`.
- If \( p(a) = \text{true} \), the result is `some a`.
- Otherwise, the result is `none`.

Since \( p(a) \) is false, the third case applies, and the result is `none`. Therefore, the proposition `List.find? p (List.replicate n a) = none` is true. -/
  simp [find?_replicate, h]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39653,List.find?_cons_of_pos,theorem List.find?_cons_of_pos (l) (h : p a) : find? p (a :: l) = some a := by sorry,"First Element Satisfying Predicate in Cons List : For any type \( \alpha \), a predicate \( p : \alpha \to \text{Bool} \), and a list \( l \) of elements of type \( \alpha \), if \( p(a) \) is true for some element \( a \) of type \( \alpha \), then the function `List.find?` applied to the predicate \( p \) and the list \( a :: l \) returns `some a`. In other words, if the first element of the list satisfies the predicate, `List.find?` returns that element.","theorem List.find?_cons_of_pos (l) (h : p a) : find? p (a :: l) = some a := by
  simp [find?, h]","We need to show that if \( p(a) = \text{true} \) for some element \( a \) of type \( \alpha \), then `List.find? p (a :: l) = some a`.

Using the definition of `List.find?`, we know that `List.find? p (a :: l)` returns the first element \( a \) in the list \( a :: l \) for which \( p(a) \) is true. Given the hypothesis \( p(a) = \text{true} \), the first element \( a \) satisfies the predicate \( p \). Therefore, `List.find? p (a :: l)` returns `some a`.

Thus, we have shown that if \( p(a) = \text{true} \), then `List.find? p (a :: l) = some a`. This completes the proof.","theorem List.find?_cons_of_pos (l) (h : p a) : find? p (a :: l) = some a := by
/- Using the definition of `List.find?` and the hypothesis \( p(a) = \text{true} \), we can simplify the goal to show that `List.find? p (a :: l) = some a`. According to the definition of `List.find?`, if the predicate \( p \) is true for the first element \( a \) of the list \( a :: l \), then `List.find? p (a :: l)` returns `some a`. Since \( p(a) = \text{true} \), this simplification directly gives us the desired result. -/
  simp [find?, h]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39656,List.find?_cons_of_neg,theorem List.find?_cons_of_neg (l) (h : ¬p a) : find? p (a :: l) = find? p l := by sorry,"List Find on Cons List Returns Same Result if First Element Does Not Satisfy Predicate : For any type \( \alpha \), a predicate \( p : \alpha \to \text{Bool} \), and a list \( l \) of elements of type \( \alpha \), if \( p(a) \) is `false` for some element \( a \) of type \( \alpha \), then the function `List.find? p (a :: l)` returns the same result as `List.find? p l`. In other words, if the first element of the list does not satisfy the predicate, `List.find?` behaves as if the first element were not present.","theorem List.find?_cons_of_neg (l) (h : ¬p a) : find? p (a :: l) = find? p l := by
  simp [find?, h]","We start with the assumption that \( p(a) \) is `false` for some element \( a \) of type \( \alpha \). According to the definition of `List.find?`, the function `List.find? p (a :: l)` checks the predicate \( p \) on the first element \( a \) of the list \( a :: l \). Since \( p(a) \) is `false`, the function `List.find?` will skip \( a \) and continue searching in the rest of the list \( l \). Therefore, `List.find? p (a :: l)` is equivalent to `List.find? p l`. This completes the proof.","theorem List.find?_cons_of_neg (l) (h : ¬p a) : find? p (a :: l) = find? p l := by
/- Using the definition of `List.find?` and the hypothesis \( \neg p(a) = \text{true} \), we can simplify the expression `List.find? p (a :: l)` to `List.find? p l`. This is because if \( p(a) \) is `false`, the function `List.find?` will skip the first element \( a \) and continue searching in the rest of the list \( l \). -/
  simp [find?, h]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39657,List.find?_replicate_of_length_pos,theorem List.find?_replicate_of_length_pos (h : 0 < n) : find? p (replicate n a) = if p a then some a else none := by sorry,"Find in Replicated List with Positive Length: `List.find? p (List.replicate n a) = if p a = true then some a else none` : For any natural number \( n \) and any type \( \alpha \), if \( n > 0 \) and \( p : \alpha \to \text{Bool} \) is a predicate, and \( a : \alpha \) is an element, then the function `List.find?` applied to the predicate \( p \) and the list `List.replicate n a` returns:
- `some a` if \( p(a) \) is true,
- `none` otherwise.","theorem List.find?_replicate_of_length_pos (h : 0 < n) : find? p (replicate n a) = if p a then some a else none := by
  simp [find?_replicate, Nat.ne_of_gt h]","We start by noting the theorem that for any natural number \( n \) and element \( a \) of type \( \alpha \), the function `List.find?` applied to the predicate \( p \) and the list `List.replicate n a` returns:
- `none` if \( n = 0 \),
- `some a` if \( p a = \text{true} \),
- `none` otherwise.

Given that \( n > 0 \), we know that \( n \neq 0 \) by the property of natural numbers. Therefore, the condition \( n = 0 \) is false, and the if-then-else expression simplifies to:
- `some a` if \( p a = \text{true} \),
- `none` otherwise.

This matches the desired result, completing the proof.","theorem List.find?_replicate_of_length_pos (h : 0 < n) : find? p (replicate n a) = if p a then some a else none := by
/- Using the theorem that for any natural number \( n \) and element \( a \) of type \( \alpha \), the function `List.find?` applied to the predicate \( p \) and the list `List.replicate n a` returns:
- `none` if \( n = 0 \),
- `some a` if \( p a = \text{true} \),
- `none` otherwise,
and the fact that \( n > 0 \) implies \( n \neq 0 \), we can simplify the goal. Since \( n \neq 0 \), the condition \( n = 0 \) is false, and thus the if-then-else expression simplifies to:
- `some a` if \( p a = \text{true} \),
- `none` otherwise.
This matches the desired result, completing the proof. -/
  simp [find?_replicate, Nat.ne_of_gt h]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39665,List.findSome?_replicate_of_pos,theorem List.findSome?_replicate_of_pos (h : 0 < n) : findSome? f (replicate n a) = f a := by sorry,"Find Some in Replicated List for Positive Length : For any natural number $n$ and any types $\alpha$ and $\alpha_1$, if $n > 0$ and $f : \alpha \to \text{Option} \, \alpha_1$ is a function, then the result of `List.findSome? f (List.replicate n a)` is equal to `f a` for any element $a : \alpha$.","theorem List.findSome?_replicate_of_pos (h : 0 < n) : findSome? f (replicate n a) = f a := by
  simp [findSome?_replicate, Nat.ne_of_gt h]","We start by noting that the function `List.findSome? f (List.replicate n a)` returns the first non-`none` result of applying \( f \) to the elements of the list `List.replicate n a`. According to the theorem, this result is:
\[
\text{List.findSome? } f \, (\text{List.replicate } n \, a) =
\begin{cases}
\text{none} & \text{if } n = 0 \\
f(a) & \text{if } n > 0
\end{cases}
\]
Given that \( n > 0 \), we know that \( n \neq 0 \). Therefore, the list `List.replicate n a` is not empty, and the first non-`none` result of applying \( f \) to the elements of this list is \( f(a) \). Hence, we have:
\[
\text{List.findSome? } f \, (\text{List.replicate } n \, a) = f(a)
\]
This completes the proof.","theorem List.findSome?_replicate_of_pos (h : 0 < n) : findSome? f (replicate n a) = f a := by
/- Using the theorem that the first non-`none` result in a replicated list is `none` if the length is zero and `f(a)` if the length is positive, and the fact that if \( n > 0 \) then \( n \neq 0 \), we can simplify the proposition we want to show. Specifically, since \( n > 0 \), the list `List.replicate n a` is not empty, and thus the first non-`none` result of applying \( f \) to the elements of this list is \( f(a) \). Therefore, the goal is to show that `List.findSome? f (List.replicate n a) = f a`. -/
  simp [findSome?_replicate, Nat.ne_of_gt h]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39670,List.find?_replicate_of_pos,theorem List.find?_replicate_of_pos (h : p a) : find? p (replicate n a) = if n = 0 then none else some a := by sorry,"First Element Satisfying Predicate in Replicated List: `List.find? p (List.replicate n a) = if n = 0 then none else some a` : For any type \( \alpha \), predicate \( p : \alpha \to \text{Bool} \), natural number \( n \), and element \( a : \alpha \), if \( p(a) \) is true, then the result of `List.find? p (List.replicate n a)` is `none` if \( n = 0 \) and `some a` otherwise. In other words, if \( p(a) \) is true, the function `List.find?` applied to the predicate \( p \) and a list containing \( n \) copies of \( a \) returns `none` if the list is empty and `some a` if the list is non-empty.","theorem List.find?_replicate_of_pos (h : p a) : find? p (replicate n a) = if n = 0 then none else some a := by
  simp [find?_replicate, h]","We start with the given hypothesis that \( p(a) = \text{true} \). We need to show that `List.find? p (List.replicate n a)` is `none` if \( n = 0 \) and `some a` if \( n \neq 0 \).

Using the definition of `List.find?` on a replicated list, we know that:
- If \( n = 0 \), `List.find? p (List.replicate n a)` returns `none`.
- If \( n \neq 0 \) and \( p(a) = \text{true} \), `List.find? p (List.replicate n a)` returns `some a`.
- If \( n \neq 0 \) and \( p(a) = \text{false} \), `List.find? p (List.replicate n a)` returns `none`.

Since \( p(a) = \text{true} \) by hypothesis, the result of `List.find? p (List.replicate n a)` is:
- `none` if \( n = 0 \),
- `some a` if \( n \neq 0 \).

This matches the goal exactly, thus completing the proof.","theorem List.find?_replicate_of_pos (h : p a) : find? p (replicate n a) = if n = 0 then none else some a := by
/- Using the definition of `List.find?` on a replicated list and the hypothesis \( p(a) = \text{true} \), we can simplify the proposition we want to show. Specifically, we use the fact that `List.find? p (List.replicate n a)` is `none` if \( n = 0 \) and `some a` if \( p(a) = \text{true} \). Since \( p(a) = \text{true} \) by hypothesis, the result is `some a` if \( n \neq 0 \) and `none` if \( n = 0 \). This matches the goal exactly, thus completing the proof. -/
  simp [find?_replicate, h]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39671,List.find?_replicate_of_isSome,theorem List.find?_replicate_of_isSome (_ : (f a).isSome) : findSome? f (replicate n a) = if n = 0 then none else f a := by sorry,"Finding the First Non-`None` Result in a Replicated List : For any types \(\alpha\) and \(\alpha_1\), and for any function \(f : \alpha \to \text{Option } \alpha_1\), if \(f(a)\) is `some` for some \(a : \alpha\), then the result of `List.findSome? f (List.replicate n a)` is `none` if \(n = 0\) and \(f(a)\) otherwise.","theorem List.find?_replicate_of_isSome (_ : (f a).isSome) : findSome? f (replicate n a) = if n = 0 then none else f a := by
  simp [findSome?_replicate]","We start with the given function \( f : \alpha \to \text{Option } \alpha_1 \) and an element \( a : \alpha \) such that \( f(a) \) is `some`. We need to show that the result of \(\text{List.findSome? } f \, (\text{List.replicate } n \, a)\) is `none` if \( n = 0 \) and \( f(a) \) otherwise.

Using the theorem that the first non-`none` result of applying \( f \) to the elements of a list containing \( n \) copies of an element \( a \) is:
\[
\text{List.findSome? } f \, (\text{List.replicate } n \, a) =
\begin{cases}
\text{none} & \text{if } n = 0 \\
f(a) & \text{if } n > 0
\end{cases}
\]
we can directly conclude the desired result. Therefore, the result of \(\text{List.findSome? } f \, (\text{List.replicate } n \, a)\) is `none` if \( n = 0 \) and \( f(a) \) otherwise. This completes the proof. \(\blacksquare\)","theorem List.find?_replicate_of_isSome (_ : (f a).isSome) : findSome? f (replicate n a) = if n = 0 then none else f a := by
/- Using the theorem that the first non-`none` result of applying \( f \) to the elements of a list containing \( n \) copies of an element \( a \) is `none` if \( n = 0 \) and \( f(a) \) otherwise, we can simplify the proposition we want to show to the desired result. -/
  simp [findSome?_replicate]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39675,List.find?_replicate_of_isNone,theorem List.find?_replicate_of_isNone (h : (f a).isNone) : findSome? f (replicate n a) = none := by sorry,"Finding None in Replicated List Results in None : For any types $\alpha$ and $\alpha_1$, any function $f : \alpha \to \text{Option } \alpha_1$, any natural number $n$, and any element $a \in \alpha$, if $f(a) = \text{none}$, then the function `List.findSome? f` applied to the list `List.replicate n a` returns `none`.","theorem List.find?_replicate_of_isNone (h : (f a).isNone) : findSome? f (replicate n a) = none := by
  rw [Option.isNone_iff_eq_none] at h
  simp [findSome?_replicate, h]","We start with the assumption that \( f(a) = \text{none} \). Using the equivalence that the function `Option.isNone` returns `true` if and only if the optional value is `none`, we can replace the assumption \((f a).isNone = \text{true}\) with \( f a = \text{none} \).

Next, we use the lemma `List.findSome?_replicate`, which states that for any function \( f : \alpha \to \text{Option } \alpha_1 \), the first non-`none` result of applying \( f \) to a list containing \( n \) copies of an element \( a \) is:
\[
\text{List.findSome? } f \, (\text{List.replicate } n \, a) =
\begin{cases}
\text{none} & \text{if } n = 0 \\
f(a) & \text{if } n > 0
\end{cases}
\]
Since \( f a = \text{none} \), the result of `List.findSome? f (List.replicate n a)` is `none` regardless of the value of \( n \). Therefore, the function `List.findSome? f` applied to the list `List.replicate n a` returns `none`.

This completes the proof.","theorem List.find?_replicate_of_isNone (h : (f a).isNone) : findSome? f (replicate n a) = none := by
/- First, we use the equivalence that the function `Option.isNone` returns `true` if and only if the optional value is `none`. This allows us to replace the assumption \((f a).isNone = \text{true}\) with \(f a = \text{none}\). -/
  rw [Option.isNone_iff_eq_none] at h
/- Next, we use the lemma `List.findSome?_replicate` which states that for any function \( f : \alpha \to \text{Option } \alpha_1 \), the first non-`none` result of applying \( f \) to a list containing \( n \) copies of an element \( a \) is:
\[
\text{List.findSome? } f \, (\text{List.replicate } n \, a) =
\begin{cases}
\text{none} & \text{if } n = 0 \\
f(a) & \text{if } n > 0
\end{cases}
\]
Since we have \( f a = \text{none} \), the result of `List.findSome? f (List.replicate n a)` is `none` regardless of the value of \( n \). Therefore, the goal is satisfied. -/
  simp [findSome?_replicate, h]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39679,List.findSome?_cons_of_isSome,theorem List.findSome?_cons_of_isSome (l) (h : (f a).isSome) : findSome? f (a :: l) = f a := by sorry,"First Non-`None` Result in Cons List is `f a` if `f a` is `Some` : For any types $\alpha$ and $\alpha_1$, and any function $f : \alpha \to \text{Option} \, \alpha_1$, if $f(a)$ is `some` for an element $a \in \alpha$, then the first non-`none` result of applying $f$ to the list $a :: l$ is $f(a)$. In other words, if `f a` is `some b` for some $b \in \alpha_1$, then `List.findSome? f (a :: l)` is equal to `f a`.","theorem List.findSome?_cons_of_isSome (l) (h : (f a).isSome) : findSome? f (a :: l) = f a := by
  simp only [findSome?]
  split <;> simp_all","We start by simplifying the goal using the definition of `findSome?`. This simplifies the goal to:
\[
\text{match } f(a) \text{ with} \begin{cases}
\text{some } b \Rightarrow \text{some } b \\
\text{none} \Rightarrow \text{findSome? } f \, l
\end{cases} = f(a)
\]

We then discuss by cases based on the value of \( f(a) \):

1. **Case 1:** \( f(a) = \text{some } b \)
- Using the definition of `findSome?`, the goal simplifies to:
\[
\text{some } b = f(a)
\]
- Since \( f(a) = \text{some } b \) by assumption, this is trivially true.

2. **Case 2:** \( f(a) = \text{none} \)
- Using the definition of `findSome?`, the goal simplifies to:
\[
\text{findSome? } f \, l = f(a)
\]
- Since \( f(a) = \text{none} \) by assumption, this simplifies to:
\[
\text{findSome? } f \, l = \text{none}
\]
- This is also trivially true because the definition of `findSome?` states that if the first element is `none`, it continues to the rest of the list.

Thus, in both cases, the goal is satisfied. Therefore, the theorem is proved. \(\blacksquare\)","theorem List.findSome?_cons_of_isSome (l) (h : (f a).isSome) : findSome? f (a :: l) = f a := by
/- We simplify the proposition we want to show using the definition of `findSome?`. This simplifies the goal to:
\[
\text{match } f(a) \text{ with} \begin{cases}
\text{some } b \Rightarrow \text{some } b \\
\text{none} \Rightarrow \text{findSome? } f \, l
\end{cases} = f(a)
\] -/
  simp only [findSome?]
/- We discuss by cases based on the value of \( f(a) \):
1. **Case 1:** \( f(a) = \text{some } b \)
- Using the definition of `findSome?`, we simplify the goal to:
\[
\text{some } b = f(a)
\]
- Since \( f(a) = \text{some } b \) by assumption, this is trivially true.
2. **Case 2:** \( f(a) = \text{none} \)
- Using the definition of `findSome?`, we simplify the goal to:
\[
\text{findSome? } f \, l = f(a)
\]
- Since \( f(a) = \text{none} \) by assumption, this simplifies to:
\[
\text{findSome? } f \, l = \text{none}
\]
- This is also trivially true because the definition of `findSome?` states that if the first element is `none`, it continues to the rest of the list. -/
  split <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39688,List.findSome?_map,theorem List.findSome?_map (f : β → γ) (l : List β) : findSome? p (l.map f) = l.findSome? (p ∘ f) := by sorry,"First Non-`none` Result in Mapped List Equals First Non-`none` Result in Composed Function Application : For any types \( \beta \), \( \gamma \), and \( \alpha \), and for any function \( p : \gamma \to \text{Option } \alpha \) and any function \( f : \beta \to \gamma \), the first non-`none` result of applying \( p \) to the elements of the list \( \text{List.map } f \, l \) is the same as the first non-`none` result of applying \( p \circ f \) to the elements of the list \( l \). Formally, for a list \( l = [b_1, b_2, \ldots, b_n] \), the following holds:
\[
\text{List.findSome? } p \, (\text{List.map } f \, l) = \text{List.findSome? } (p \circ f) \, l
\]
where \( p \circ f \) denotes the function composition \( (p \circ f)(x) = p(f(x)) \).","theorem List.findSome?_map (f : β → γ) (l : List β) : findSome? p (l.map f) = l.findSome? (p ∘ f) := by
  induction l with
  | nil => simp
  | cons x xs ih =>
    simp only [map_cons, findSome?]
    split <;> simp_all","We prove the theorem by induction on the list \( l \).

**Base Case:**
For the empty list \( l = [] \):
\[
\text{List.findSome? } p \, (\text{List.map } f \, []) = \text{List.findSome? } p \, [] = \text{none}
\]
and
\[
\text{List.findSome? } (p \circ f) \, [] = \text{none}
\]
Thus, the base case holds.

**Inductive Step:**
Assume the property holds for a list \( xs \). We need to show that it holds for a list \( x :: xs \).

By the definition of `List.map`:
\[
\text{List.map } f \, (x :: xs) = f x :: \text{List.map } f \, xs
\]

We consider two cases based on the result of \( p (f x) \):

1. **Case 1: \( p (f x) = \text{some } b \)**
\[
\text{List.findSome? } p \, (f x :: \text{List.map } f \, xs) = \text{some } b
\]
and
\[
\text{List.findSome? } (p \circ f) \, (x :: xs) = \text{some } b
\]
Thus, the property holds in this case.

2. **Case 2: \( p (f x) = \text{none} \)**
\[
\text{List.findSome? } p \, (f x :: \text{List.map } f \, xs) = \text{List.findSome? } p \, (\text{List.map } f \, xs)
\]
and
\[
\text{List.findSome? } (p \circ f) \, (x :: xs) = \text{List.findSome? } (p \circ f) \, xs
\]
By the inductive hypothesis, we have:
\[
\text{List.findSome? } p \, (\text{List.map } f \, xs) = \text{List.findSome? } (p \circ f) \, xs
\]
Thus, the property holds in this case as well.

By induction, the theorem holds for all lists \( l \). This completes the proof. \(\blacksquare\)","theorem List.findSome?_map (f : β → γ) (l : List β) : findSome? p (l.map f) = l.findSome? (p ∘ f) := by
  induction l with
/- For the base case where the list \( l \) is empty, we simplify the goal using the definition of `List.findSome?` and `List.map`. Since the empty list has no elements, both `List.findSome? p (List.map f [])` and `List.findSome? (p \circ f) []` are `none`, and thus the goal is trivially true. -/
  | nil => simp
/- For the inductive case where the list \( l \) is non-empty and can be written as \( x :: xs \), we assume the inductive hypothesis that the property holds for the list \( xs \). We need to show that the property holds for the list \( x :: xs \). -/
  | cons x xs ih =>
/- We simplify the goal using the definitions of `List.map` and `List.findSome?`. Specifically, we use the fact that `List.map f (x :: xs)` is `f x :: List.map f xs` and the definition of `List.findSome?` to break down the goal into a case analysis on the result of `p (f x)`. -/
    simp only [map_cons, findSome?]
/- We consider the cases for the list \( l \). For the base case where \( l \) is the empty list, we simplify the goal using the definitions of `List.findSome?` and `List.map`. For the inductive case where \( l \) is a non-empty list, we also simplify the goal using the definitions of `List.findSome?` and `List.map`. -/
/- We consider two cases based on the result of `p (f x)`:
1. If `p (f x)` is `some b`, then `List.findSome? p (List.map f (x :: xs))` is `some b` and `List.findSome? (p \circ f) (x :: xs)` is also `some b`.
2. If `p (f x)` is `none`, then `List.findSome? p (List.map f (x :: xs))` is `List.findSome? p (List.map f xs)` and `List.findSome? (p \circ f) (x :: xs)` is `List.findSome? (p \circ f) xs`. By the inductive hypothesis, these two expressions are equal. -/
    split <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39692,List.findIdx_cons,"theorem List.findIdx_cons (p : α → Bool) (b : α) (l : List α) :
    (b :: l).findIdx p = bif p b then 0 else (l.findIdx p) + 1 := by sorry","Index of First Element in Cons List Satisfying Predicate : For any type \( \alpha \), predicate \( p : \alpha \to \text{Bool} \), element \( b : \alpha \), and list \( l : \text{List} \, \alpha \), the index of the first element in the list \( b :: l \) that satisfies the predicate \( p \) is given by:
\[
\text{List.findIdx} \, p \, (b :: l) = \begin{cases} 
0 & \text{if } p(b) = \text{true} \\
\text{List.findIdx} \, p \, l + 1 & \text{if } p(b) = \text{false}
\end{cases}
\]","theorem List.findIdx_cons (p : α → Bool) (b : α) (l : List α) :
    (b :: l).findIdx p = bif p b then 0 else (l.findIdx p) + 1 := by
  cases H : p b with
  | true => simp [H, findIdx, findIdx.go]
  | false => simp [H, findIdx, findIdx.go, findIdx_go_succ]
where
  findIdx_go_succ (p : α → Bool) (l : List α) (n : Nat) :
      List.findIdx.go p l (n + 1) = (findIdx.go p l n) + 1 := by
    cases l with
    | nil => unfold findIdx.go; exact Nat.succ_eq_add_one n
    | cons head tail =>
      unfold findIdx.go
      cases p head <;> simp only [cond_false, cond_true]
      exact findIdx_go_succ p tail (n + 1)","We start by proving a helper lemma: for any type \(\alpha\), predicate \(p : \alpha \to \text{Bool}\), list \(l : \text{List} \, \alpha\), and natural number \(n\), the function `List.findIdx.go` applied to \(p\), \(l\), and \(n + 1\) returns the result of `List.findIdx.go` applied to \(p\), \(l\), and \(n\) plus 1. We do this by considering two cases:
1. If \(l\) is the empty list, then `List.findIdx.go p l (n + 1)` is \(n + 1\), which is equal to `List.findIdx.go p l n + 1`.
2. If \(l\) is a non-empty list with head \(a\) and tail \(l'\), we unfold the definition of `List.findIdx.go` and consider two sub-cases:
- If \(p(a)\) is true, then `List.findIdx.go p l (n + 1)` is \(n + 1\), which is equal to `List.findIdx.go p l n + 1`.
- If \(p(a)\) is false, then `List.findIdx.go p l (n + 1)` is `List.findIdx.go p l' (n + 1) + 1`, which is equal to `List.findIdx.go p l' n + 1 + 1` by the induction hypothesis.

Next, we consider the main theorem:
- If \(p(b)\) is true, then we simplify the goal using the assumption \(H : p(b) = \text{true}\), the definition of `List.findIdx`, and the definition of `List.findIdx.go`. This simplification shows that `List.findIdx p (b :: l)` is 0, which is the desired result.
- If \(p(b)\) is false, then we simplify the goal using the assumption \(H : p(b) = \text{false}\), the definition of `List.findIdx`, the definition of `List.findIdx.go`, and the lemma `findIdx_go_succ`. This simplification shows that `List.findIdx p (b :: l)` is `List.findIdx p l + 1`, which is the desired result.

Thus, the theorem is proved. \(\blacksquare\)","theorem List.findIdx_cons (p : α → Bool) (b : α) (l : List α) :
    (b :: l).findIdx p = bif p b then 0 else (l.findIdx p) + 1 := by
  cases H : p b with
/- If \(p(b)\) is true, then we simplify the goal using the assumption \(H : p(b) = \text{true}\), the definition of `List.findIdx`, and the definition of `List.findIdx.go`. This simplification shows that `List.findIdx p (b :: l)` is 0, which is the desired result. -/
  | true => simp [H, findIdx, findIdx.go]
/- If \(p(b)\) is false, then we simplify the goal using the assumption \(H : p(b) = \text{false}\), the definition of `List.findIdx`, the definition of `List.findIdx.go`, and the lemma `findIdx_go_succ`. This simplification shows that `List.findIdx p (b :: l)` is `List.findIdx p l + 1`, which is the desired result. -/
  | false => simp [H, findIdx, findIdx.go, findIdx_go_succ]
where
/- We first prove the lemma that for any type \(\alpha\), predicate \(p : \alpha \to \text{Bool}\), list \(l : \text{List} \, \alpha\), and natural number \(n\), the function `List.findIdx.go` applied to \(p\), \(l\), and \(n + 1\) returns the result of `List.findIdx.go` applied to \(p\), \(l\), and \(n\) plus 1. We do this by considering two cases:
1. If \(l\) is the empty list, then `List.findIdx.go p l (n + 1)` is \(n + 1\), which is equal to `List.findIdx.go p l n + 1`.
2. If \(l\) is a non-empty list with head \(a\) and tail \(l'\), we unfold the definition of `List.findIdx.go` and consider two sub-cases:
- If \(p(a)\) is true, then `List.findIdx.go p l (n + 1)` is \(n + 1\), which is equal to `List.findIdx.go p l n + 1`.
- If \(p(a)\) is false, then `List.findIdx.go p l (n + 1)` is `List.findIdx.go p l' (n + 1) + 1`, which is equal to `List.findIdx.go p l' n + 1 + 1` by the induction hypothesis. -/
  findIdx_go_succ (p : α → Bool) (l : List α) (n : Nat) :
      List.findIdx.go p l (n + 1) = (findIdx.go p l n) + 1 := by
    cases l with
    | nil => unfold findIdx.go; exact Nat.succ_eq_add_one n
    | cons head tail =>
      unfold findIdx.go
      cases p head <;> simp only [cond_false, cond_true]
      exact findIdx_go_succ p tail (n + 1)","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39696,List.exists_of_findSome?_eq_some,"theorem List.exists_of_findSome?_eq_some {l : List α} {f : α → Option β} (w : l.findSome? f = some b) :
    ∃ a, a ∈ l ∧ f a = b := by sorry","Existence of Element in List for `findSome?` Result : For any types \( \alpha \) and \( \beta \), any element \( b \) of type \( \beta \), any list \( l \) of elements of type \( \alpha \), and any function \( f : \alpha \to \text{Option} \, \beta \), if the result of `List.findSome? f l` is `some b`, then there exists an element \( a \) in \( l \) such that \( f(a) = \text{some} \, b \).","theorem List.exists_of_findSome?_eq_some {l : List α} {f : α → Option β} (w : l.findSome? f = some b) :
    ∃ a, a ∈ l ∧ f a = b := by
  induction l with
  | nil => simp_all
  | cons h l ih =>
    simp_all only [findSome?_cons, mem_cons, exists_eq_or_imp]
    split at w <;> simp_all","We proceed by induction on the list \( l \).

1. **Base Case:**
- Consider the case where the list \( l \) is empty, i.e., \( l = [] \).
- If `findSome? f [] = some b`, this is impossible because `findSome? f []` always returns `none`.
- Therefore, the goal is trivially true.

2. **Inductive Step:**
- Consider the case where the list \( l \) is non-empty, i.e., \( l = h :: l' \).
- We use the induction hypothesis \( ih \), which states that if `findSome? f l' = some b`, then there exists an element \( a \) in \( l' \) such that \( f(a) = \text{some} \, b \).

We need to show that if `findSome? f (h :: l') = some b`, then there exists an element \( a \) in \( h :: l' \) such that \( f(a) = \text{some} \, b \).

- **Case 1:**
- Suppose \( f(h) = \text{some} \, b \).
- Then \( h \) is an element in \( h :: l' \) and \( f(h) = \text{some} \, b \).
- Therefore, the goal is satisfied with \( a = h \).

- **Case 2:**
- Suppose \( f(h) = \text{none} \) and \( \text{findSome?} \, f \, l' = \text{some} \, b \).
- By the induction hypothesis, there exists an element \( a \) in \( l' \) such that \( f(a) = \text{some} \, b \).
- Since \( a \) is in \( l' \), it is also in \( h :: l' \).
- Therefore, the goal is satisfied with \( a \).

In both cases, we have shown that if `findSome? f (h :: l') = some b`, then there exists an element \( a \) in \( h :: l' \) such that \( f(a) = \text{some} \, b \).

Thus, the theorem is proved. \(\blacksquare\)","theorem List.exists_of_findSome?_eq_some {l : List α} {f : α → Option β} (w : l.findSome? f = some b) :
    ∃ a, a ∈ l ∧ f a = b := by
  induction l with
/- Consider the case where the list \( l \) is empty. Since the list is empty, the result of `findSome? f l` being `some b` is impossible. Therefore, the goal is trivially true. -/
  | nil => simp_all
/- Consider the case where the list \( l \) is non-empty, i.e., \( l = h :: l' \). We use induction on the list \( l \) and assume the induction hypothesis \( ih \), which states that if `findSome? f l' = some b`, then there exists an element \( a \) in \( l' \) such that \( f(a) = \text{some} \, b \). -/
  | cons h l ih =>
/- We simplify the goal using the definitions of `findSome?` on a cons list, membership in a cons list, and the equivalence of existential quantification. This simplification results in the goal being split into two cases:
1. \( f(h) = \text{some} \, b \)
2. \( \text{findSome?} \, f \, l' = \text{some} \, b \) -/
    simp_all only [findSome?_cons, mem_cons, exists_eq_or_imp]
/- We split the goal based on the condition \( w \). This results in two cases:
1. \( f(h) = \text{some} \, b \)
2. \( f(h) = \text{none} \) and \( \text{findSome?} \, f \, l = \text{some} \, b \)

In both cases, we simplify the goal using the properties of `findSome?` and the membership in the list. -/
/- We split the goal based on the condition \( w \). This results in two cases:
1. \( f(h) = \text{some} \, b \)
2. \( f(h) = \text{none} \) and \( \text{findSome?} \, f \, l' = \text{some} \, b \)

In both cases, we simplify the goal using the properties of `findSome?` and the membership in the list. -/
    split at w <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39697,List.find?_replicate,theorem List.find?_replicate : find? p (replicate n a) = if n = 0 then none else if p a then some a else none := by sorry,"Find in Replicated List: `List.find? p (List.replicate n a) = if n = 0 then none else if p a = true then some a else none` : For any type \( \alpha \), predicate \( p : \alpha \to \text{Bool} \), natural number \( n \), and element \( a : \alpha \), the function `List.find?` applied to the predicate \( p \) and the list `List.replicate n a` returns:
- `none` if \( n = 0 \),
- `some a` if \( p a = \text{true} \),
- `none` otherwise.","theorem List.find?_replicate : find? p (replicate n a) = if n = 0 then none else if p a then some a else none := by
  cases n
  · simp
  · by_cases p a <;> simp_all [replicate_succ]","We will consider two cases for the natural number \( n \):

1. **Case 1: \( n = 0 \)**
- The list `List.replicate 0 a` is the empty list.
- The function `List.find? p` applied to the empty list returns `none`.
- Therefore, the goal \( \text{find? } p \, (\text{replicate } 0 \, a) = \text{if } 0 = 0 \text{ then none else if } p \, a = \text{true then some } a \text{ else none} \) simplifies to `none = none`, which is trivially true.

2. **Case 2: \( n = n' + 1 \) for some natural number \( n' \)**
- We split this case into two subcases based on the value of \( p \, a \):
1. **Subcase 1: \( p \, a = \text{true} \)**
- The list `List.replicate (n' + 1) a` is the list `[a, a, ..., a]` with \( n' + 1 \) elements.
- The function `List.find? p` applied to this list will return `some a` because \( p \, a = \text{true} \).
- Therefore, the goal \( \text{find? } p \, (\text{replicate } (n' + 1) \, a) = \text{if } n' + 1 = 0 \text{ then none else if } p \, a = \text{true then some } a \text{ else none} \) simplifies to `some a = some a`, which is trivially true.
2. **Subcase 2: \( p \, a = \text{false} \)**
- The list `List.replicate (n' + 1) a` is the list `[a, a, ..., a]` with \( n' + 1 \) elements.
- The function `List.find? p` applied to this list will return `none` because \( p \, a = \text{false} \).
- Therefore, the goal \( \text{find? } p \, (\text{replicate } (n' + 1) \, a) = \text{if } n' + 1 = 0 \text{ then none else if } p \, a = \text{true then some } a \text{ else none} \) simplifies to `none = none`, which is trivially true.

Thus, in all cases, the function `List.find? p (List.replicate n a)` returns the correct value as specified. This completes the proof.","theorem List.find?_replicate : find? p (replicate n a) = if n = 0 then none else if p a then some a else none := by
/- We will consider two cases for the natural number \( n \):
1. \( n = 0 \)
2. \( n = n' + 1 \) for some natural number \( n' \) -/
  cases n
/- First, we show that for the case \( n = 0 \):
- The list `List.replicate 0 a` is the empty list.
- The function `List.find? p` applied to the empty list returns `none`.
- Therefore, the goal \( \text{find? } p \, (\text{replicate } 0 \, a) = \text{if } 0 = 0 \text{ then none else if } p \, a = \text{true then some } a \text{ else none} \) simplifies to `none = none`, which is trivially true. -/
  · simp
/- Next, we consider the case \( n = n' + 1 \) and split it into two subcases based on the value of \( p \, a \):
1. **Case 1: \( p \, a = \text{true} \)**
- The list `List.replicate (n' + 1) a` is the list `[a, a, ..., a]` with \( n' + 1 \) elements.
- The function `List.find? p` applied to this list will return `some a` because \( p \, a = \text{true} \).
- Therefore, the goal \( \text{find? } p \, (\text{replicate } (n' + 1) \, a) = \text{if } n' + 1 = 0 \text{ then none else if } p \, a = \text{true then some } a \text{ else none} \) simplifies to `some a = some a`, which is trivially true.

2. **Case 2: \( p \, a = \text{false} \)**
- The list `List.replicate (n' + 1) a` is the list `[a, a, ..., a]` with \( n' + 1 \) elements.
- The function `List.find? p` applied to this list will return `none` because \( p \, a = \text{false} \).
- Therefore, the goal \( \text{find? } p \, (\text{replicate } (n' + 1) \, a) = \text{if } n' + 1 = 0 \text{ then none else if } p \, a = \text{true then some } a \text{ else none} \) simplifies to `none = none`, which is trivially true. -/
  · by_cases p a <;> simp_all [replicate_succ]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39706,List.findSome?_replicate,theorem List.findSome?_replicate : findSome? f (replicate n a) = if n = 0 then none else f a := by sorry,"First Non-`none` Result in Replicated List Equals Function Application or `none` : For any types \( \alpha \) and \( \alpha_1 \), and for any function \( f : \alpha \to \text{Option } \alpha_1 \), the first non-`none` result of applying \( f \) to the elements of a list containing \( n \) copies of an element \( a \) is:
\[
\text{List.findSome? } f \, (\text{List.replicate } n \, a) = 
\begin{cases} 
\text{none} & \text{if } n = 0 \\
f(a) & \text{if } n > 0 
\end{cases}
\]","theorem List.findSome?_replicate : findSome? f (replicate n a) = if n = 0 then none else f a := by
  induction n with
  | zero => simp
  | succ n ih =>
    simp only [replicate_succ, findSome?_cons]
    split <;> simp_all","We need to show that the first non-`none` result of applying \( f \) to the elements of a list containing \( n \) copies of an element \( a \) is `none` if \( n = 0 \) and \( f(a) \) if \( n > 0 \).

1. **Case \( n = 0 \):**
- The list `List.replicate 0 a` is the empty list.
- By the definition of `List.findSome?`, the first non-`none` result of applying \( f \) to the elements of an empty list is `none`.
- Therefore, the goal is trivially satisfied.

2. **Case \( n > 0 \):**
- We perform induction on \( n \).
- **Base case \( n = 1 \):**
- The list `List.replicate 1 a` is `[a]`.
- By the definition of `List.findSome?`, the first non-`none` result of applying \( f \) to the elements of `[a]` is `f(a)`.
- Therefore, the goal is trivially satisfied.
- **Inductive step:**
- Assume the induction hypothesis: for any \( n \), the first non-`none` result of applying \( f \) to the elements of a list containing \( n \) copies of \( a \) is `f(a)` if \( n > 0 \).
- Consider the list `List.replicate (n + 1) a`, which is `[a] ++ List.replicate n a`.
- By the definition of `List.findSome?`, the first non-`none` result of applying \( f \) to the elements of `[a] ++ List.replicate n a` is:
\[
\text{match } f(a) \text{ with} \, | \text{some } b \Rightarrow \text{some } b \, | \text{none} \Rightarrow \text{findSome? } f \, (\text{List.replicate } n \, a)
\]
- If \( f(a) = \text{some } b \), then the first non-`none` result is `some b`.
- If \( f(a) = \text{none} \), then the first non-`none` result is the result of `findSome? f (List.replicate n a)`, which by the induction hypothesis is `f(a)` if \( n > 0 \).
- In both sub-cases, the goal is trivially satisfied.

Therefore, the theorem is proved. \(\blacksquare\)","theorem List.findSome?_replicate : findSome? f (replicate n a) = if n = 0 then none else f a := by
  induction n with
/- In the case where \( n = 0 \), the list `List.replicate 0 a` is the empty list. By the definition of `List.findSome?`, the first non-`none` result of applying \( f \) to the elements of an empty list is `none`. Therefore, the goal is trivially satisfied. -/
  | zero => simp
/- In the case where \( n > 0 \), we perform induction on \( n \). The induction hypothesis is that for any \( n \), the first non-`none` result of applying \( f \) to the elements of a list containing \( n \) copies of \( a \) is `f(a)` if \( n > 0 \). -/
  | succ n ih =>
/- Using the definitions of `List.replicate` and `List.findSome?`, we simplify the goal. Specifically, `List.replicate (n + 1) a` is the list `[a] ++ List.replicate n a`, and `List.findSome? f ([a] ++ List.replicate n a)` is equivalent to `match f a with | some b => some b | none => findSome? f (List.replicate n a)`. -/
    simp only [replicate_succ, findSome?_cons]
/- We consider two cases based on the value of \( n \). For each case, we simplify the goal using the properties of the if-then-else function and the definition of `List.findSome?`. -/
/- We consider two sub-cases based on the result of \( f(a) \):
1. If \( f(a) = \text{some } b \), then the first non-`none` result is `some b`.
2. If \( f(a) = \text{none} \), then the first non-`none` result is the result of `findSome? f (List.replicate n a)`, which by the induction hypothesis is `f(a)` if \( n > 0 \).

In both sub-cases, the goal is trivially satisfied. -/
    split <;> simp_all","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39712,List.find?_map,theorem List.find?_map (f : β → α) (l : List β) : find? p (l.map f) = (l.find? (p ∘ f)).map f := by sorry,"Find in Mapped List: $\text{List.find? } p \, (\text{List.map } f \, l) = \text{Option.map } f \, (\text{List.find? } (p \circ f) \, l)$ : For any types \( \alpha \) and \( \beta \), predicate \( p : \alpha \to \text{Bool} \), function \( f : \beta \to \alpha \), and list \( l : \text{List } \beta \), the first element in the list \( \text{List.map } f \, l \) that satisfies the predicate \( p \) is the same as applying \( f \) to the first element in \( l \) that satisfies the predicate \( p \circ f \). Formally, this can be written as:
\[
\text{List.find? } p \, (\text{List.map } f \, l) = \text{Option.map } f \, (\text{List.find? } (p \circ f) \, l)
\]","theorem List.find?_map (f : β → α) (l : List β) : find? p (l.map f) = (l.find? (p ∘ f)).map f := by
  induction l with
  | nil => simp
  | cons x xs ih =>
    simp only [map_cons, find?]
    by_cases h : p (f x) <;> simp [h, ih]","We prove this by induction on the list \( l \).

1. **Base Case:**
- Assume \( l \) is the empty list, i.e., \( l = [] \).
- The left-hand side of the equation is:
\[
\text{List.find? } p \, (\text{List.map } f \, []) = \text{List.find? } p \, [] = \text{none}
\]
- The right-hand side of the equation is:
\[
\text{Option.map } f \, (\text{List.find? } (p \circ f) \, []) = \text{Option.map } f \, \text{none} = \text{none}
\]
- Therefore, both sides are equal, and the base case holds.

2. **Inductive Step:**
- Assume \( l \) is of the form \( x :: xs \), where \( x \) is the head of the list and \( xs \) is the tail.
- Assume the induction hypothesis (IH) that the property holds for the tail \( xs \):
\[
\text{List.find? } p \, (\text{List.map } f \, xs) = \text{Option.map } f \, (\text{List.find? } (p \circ f) \, xs)
\]
- We need to show:
\[
\text{List.find? } p \, (\text{List.map } f \, (x :: xs)) = \text{Option.map } f \, (\text{List.find? } (p \circ f) \, (x :: xs))
\]
- Simplify the left-hand side using the definition of `map` and `find?`:
\[
\text{List.find? } p \, (\text{List.map } f \, (x :: xs)) = \text{List.find? } p \, (f(x) :: \text{List.map } f \, xs)
\]
- If \( p(f(x)) \) is true, then:
\[
\text{List.find? } p \, (f(x) :: \text{List.map } f \, xs) = \text{some } f(x)
\]
- If \( p(f(x)) \) is false, then:
\[
\text{List.find? } p \, (f(x) :: \text{List.map } f \, xs) = \text{List.find? } p \, (\text{List.map } f \, xs)
\]
- Simplify the right-hand side using the definition of `find?`:
\[
\text{Option.map } f \, (\text{List.find? } (p \circ f) \, (x :: xs)) = \text{Option.map } f \, (\text{List.find? } (p \circ f) \, (x :: xs))
\]
- If \( (p \circ f)(x) \) is true, then:
\[
\text{Option.map } f \, (\text{List.find? } (p \circ f) \, (x :: xs)) = \text{Option.map } f \, (\text{some } x) = \text{some } f(x)
\]
- If \( (p \circ f)(x) \) is false, then:
\[
\text{Option.map } f \, (\text{List.find? } (p \circ f) \, (x :: xs)) = \text{Option.map } f \, (\text{List.find? } (p \circ f) \, xs)
\]
- By the induction hypothesis, we have:
\[
\text{List.find? } p \, (\text{List.map } f \, xs) = \text{Option.map } f \, (\text{List.find? } (p \circ f) \, xs)
\]
- Therefore, in both cases, the left-hand side and the right-hand side are equal, and the inductive step holds.

By induction, the theorem is proved. \(\blacksquare\)","theorem List.find?_map (f : β → α) (l : List β) : find? p (l.map f) = (l.find? (p ∘ f)).map f := by
  induction l with
/- For the base case where the list \( l \) is empty, we simplify the goal. Since the list is empty, both sides of the equation are trivially `none`, and the goal is satisfied. -/
  | nil => simp
/- For the inductive step, assume the list \( l \) is of the form \( x :: xs \) (i.e., \( l \) is a cons cell with head \( x \) and tail \( xs \)). We also assume the induction hypothesis \( \text{ih} \), which states that the property holds for the tail \( xs \). -/
  | cons x xs ih =>
/- We simplify the goal using the definitions of `map` and `find?`. Specifically, we use the fact that `map f (x :: xs)` is `f(x) :: map f xs` and the definition of `find?` to break down the goal into a more manageable form. -/
    simp only [map_cons, find?]
/- We consider two cases: (1) \( p(f(x)) \) is true, and (2) \( p(f(x)) \) is false. In each case, we simplify the goal using the assumption \( h \) and the induction hypothesis \( \text{ih} \). -/
/- We consider two cases: (1) \( p(f(x)) \) is true, and (2) \( p(f(x)) \) is false. In each case, we simplify the goal using the assumption \( h \) and the induction hypothesis \( \text{ih} \). -/
    by_cases h : p (f x) <;> simp [h, ih]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39714,List.findIdx?_append,"theorem List.findIdx?_append :
    (xs ++ ys : List α).findIdx? p =
      (xs.findIdx? p <|> (ys.findIdx? p).map fun i => i + xs.length) := by sorry","Index of First Element Satisfying Predicate in Concatenated Lists: \(\text{List.findIdx? } p \, (xs ++ ys)\) : For any type \( \alpha \), lists \( xs \) and \( ys \) of elements of type \( \alpha \), and a predicate \( p : \alpha \to \text{Bool} \), the index of the first element in the concatenated list \( xs ++ ys \) that satisfies the predicate \( p \) is given by:
\[
\text{List.findIdx? } p \, (xs ++ ys) = 
\begin{cases} 
\text{List.findIdx? } p \, xs & \text{if } \text{List.findIdx? } p \, xs \neq \text{none} \\
\text{Option.map } (\lambda i. i + \text{List.length } xs) \, (\text{List.findIdx? } p \, ys) & \text{if } \text{List.findIdx? } p \, xs = \text{none}
\end{cases}
\]
In other words, if the first list \( xs \) contains an element that satisfies \( p \), the index of that element is returned. Otherwise, the function searches the second list \( ys \) and, if an element satisfying \( p \) is found, returns the index of that element adjusted by the length of \( xs \).","theorem List.findIdx?_append :
    (xs ++ ys : List α).findIdx? p =
      (xs.findIdx? p <|> (ys.findIdx? p).map fun i => i + xs.length) := by
  induction xs with simp
  | cons _ _ _ => split <;> simp_all [Option.map_orElse, Option.map_map]; rfl","We proceed by induction on the list \( xs \).

**Base Case:**
If \( xs \) is the empty list, then \( xs ++ ys = ys \). Therefore, the index of the first element in \( xs ++ ys \) that satisfies \( p \) is the same as the index of the first element in \( ys \) that satisfies \( p \). This is given by:
\[
\text{List.findIdx? } p \, (xs ++ ys) = \text{List.findIdx? } p \, ys
\]
Since \( \text{List.findIdx? } p \, xs = \text{none} \) when \( xs \) is empty, the theorem holds in this case.

**Inductive Step:**
Assume the theorem holds for a list \( \text{tail} \). We need to show that it holds for a list \( \text{cons } \text{head} \, \text{tail} \).

We split the goal into two cases based on whether the predicate \( p \) holds for the head of the list \( \text{head} \):

1. **Case 1: \( p(\text{head}) = \text{true} \)**
- In this case, the index of the first element in \( \text{cons } \text{head} \, \text{tail} \) that satisfies \( p \) is \( 0 \). Therefore:
\[
\text{List.findIdx? } p \, (\text{cons } \text{head} \, \text{tail} ++ ys) = \text{some } 0
\]
- On the other hand, since \( p(\text{head}) = \text{true} \), we have:
\[
\text{List.findIdx? } p \, (\text{cons } \text{head} \, \text{tail}) = \text{some } 0
\]
- Thus, the theorem holds in this case.

2. **Case 2: \( p(\text{head}) = \text{false} \)**
- In this case, the index of the first element in \( \text{cons } \text{head} \, \text{tail} \) that satisfies \( p \) is the same as the index of the first element in \( \text{tail} \) that satisfies \( p \), adjusted by 1. Therefore:
\[
\text{List.findIdx? } p \, (\text{cons } \text{head} \, \text{tail} ++ ys) = \text{Option.map } (\lambda i. i + 1) \, (\text{List.findIdx? } p \, (\text{tail} ++ ys))
\]
- By the inductive hypothesis, we have:
\[
\text{List.findIdx? } p \, (\text{tail} ++ ys) = \text{HOrElse.hOrElse } (\text{List.findIdx? } p \, \text{tail}) \, (\lambda x. \text{Option.map } (\lambda i. i + \text{List.length } \text{tail}) \, (\text{List.findIdx? } p \, ys))
\]
- Therefore:
\[
\text{List.findIdx? } p \, (\text{cons } \text{head} \, \text{tail} ++ ys) = \text{HOrElse.hOrElse } (\text{Option.map } (\lambda i. i + 1) \, (\text{List.findIdx? } p \, \text{tail})) \, (\lambda x. \text{Option.map } (\lambda i. i + 1 + \text{List.length } \text{tail}) \, (\text{List.findIdx? } p \, ys))
\]
- Simplifying the right-hand side using the properties of `Option.map` and `Option.map_orElse`, we get:
\[
\text{List.findIdx? } p \, (\text{cons } \text{head} \, \text{tail} ++ ys) = \text{HOrElse.hOrElse } (\text{Option.map } (\lambda i. i + 1) \, (\text{List.findIdx? } p \, \text{tail})) \, (\lambda x. \text{Option.map } (\lambda i. i + (\text{List.length } \text{tail} + 1)) \, (\text{List.findIdx? } p \, ys))
\]
- This matches the right-hand side of the theorem, so the theorem holds in this case.

By induction, the theorem holds for all lists \( xs \). This completes the proof.","theorem List.findIdx?_append :
    (xs ++ ys : List α).findIdx? p =
      (xs.findIdx? p <|> (ys.findIdx? p).map fun i => i + xs.length) := by
  induction xs with simp
/- We consider the case where the list \( xs \) is non-empty, i.e., \( xs = \text{cons } \text{head} \, \text{tail} \). We split the goal into two cases based on whether the predicate \( p \) holds for the head of the list. Then, we simplify the goal using the properties of the `Option.map` and `Option.map_orElse` functions. Finally, we conclude that the goal holds by reflexivity. -/
/- We split the goal into two cases based on whether the predicate \( p \) holds for the head of the list \( xs \):
1. \( p(\text{head}) = \text{true} \)
2. \( p(\text{head}) = \text{false} \) -/
/- For each of the two cases generated by the split, we apply the next tactic to further refine or solve the subgoals. -/
/- In the case where \( p(\text{head}) = \text{true} \), we simplify the goal using the properties of the `Option.map` and `Option.map_orElse` functions. Specifically, we use the fact that applying a function to the result of an or-else operation is the same as performing the or-else operation on the results of applying the function to each operand. This simplification shows that the goal holds trivially. -/
/- In the case where \( p(\text{head}) = \text{false} \), we simplify the goal using the properties of the `Option.map` and `Option.map_orElse` functions. Specifically, we use the fact that applying a function to the result of an or-else operation is the same as performing the or-else operation on the results of applying the function to each operand. This simplification shows that the goal holds trivially. -/
/- For each of the two cases generated by the split, we apply the next tactic to further refine or solve the subgoals. -/
/- The current goal is trivially true due to the reflexive property. This means that both sides of the equality are definitionally equal. -/
  | cons _ _ _ => split <;> simp_all [Option.map_orElse, Option.map_map]; rfl","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39715,List.findIdx_of_get?_eq_some,theorem List.findIdx_of_get?_eq_some {xs : List α} (w : xs.get? (xs.findIdx p) = some y) : p y := by sorry,"Predicate Satisfied by Element at Index Found by `List.findIdx` : For any list \( xs \) of elements of type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), if the optional element at the index returned by `List.findIdx p xs` is `some y`, then the predicate \( p \) evaluated at \( y \) is `true`. In other words, if \( \text{List.get? } xs \, (\text{List.findIdx } p \, xs) = \text{some } y \), then \( p(y) = \text{true} \).","theorem List.findIdx_of_get?_eq_some {xs : List α} (w : xs.get? (xs.findIdx p) = some y) : p y := by
  induction xs with
  | nil => simp_all
  | cons x xs ih => by_cases h : p x <;> simp_all [findIdx_cons]","We prove this by induction on the list \( xs \).

1. **Base Case: \( xs = [] \)**
- If \( xs \) is the empty list, then \( \text{List.get? } [] \, (\text{List.findIdx } p \, []) = \text{none} \). Therefore, the assumption \( \text{List.get? } [] \, (\text{List.findIdx } p \, []) = \text{some } y \) is impossible, and the goal \( p(y) = \text{true} \) is vacuously true.

2. **Inductive Step: \( xs = x :: xs' \)**
- Consider the list \( xs = x :: xs' \). We split the proof into two cases based on whether the predicate \( p \) holds for the head element \( x \) of the list.

- **Case 1: \( p(x) = \text{true} \)**
- If \( p(x) = \text{true} \), then by the definition of `List.findIdx`, the index of the first element satisfying \( p \) in the list \( x :: xs' \) is \( 0 \). Therefore, \( \text{List.get? } (x :: xs') \, (\text{List.findIdx } p \, (x :: xs')) = \text{some } x \). Given the assumption \( \text{List.get? } (x :: xs') \, (\text{List.findIdx } p \, (x :: xs')) = \text{some } y \), it follows that \( y = x \). Since \( p(x) = \text{true} \), we have \( p(y) = \text{true} \).

- **Case 2: \( p(x) = \text{false} \)**
- If \( p(x) = \text{false} \), then by the definition of `List.findIdx`, the index of the first element satisfying \( p \) in the list \( x :: xs' \) is \( \text{List.findIdx } p \, xs' + 1 \). Therefore, \( \text{List.get? } (x :: xs') \, (\text{List.findIdx } p \, (x :: xs')) = \text{List.get? } xs' \, (\text{List.findIdx } p \, xs') \). Given the assumption \( \text{List.get? } (x :: xs') \, (\text{List.findIdx } p \, (x :: xs')) = \text{some } y \), it follows that \( \text{List.get? } xs' \, (\text{List.findIdx } p \, xs') = \text{some } y \). By the induction hypothesis, \( p(y) = \text{true} \).

Thus, in both cases, we have shown that \( p(y) = \text{true} \). This completes the proof. \(\blacksquare\)","theorem List.findIdx_of_get?_eq_some {xs : List α} (w : xs.get? (xs.findIdx p) = some y) : p y := by
  induction xs with
/- First, consider the case where the list \( xs \) is empty. Using the definition of `List.get?` and `List.findIdx`, we can simplify the goal to show that \( p(y) = \text{true} \) is trivially true because the assumption \( \text{List.get? } [] \, (\text{List.findIdx } p \, []) = \text{some } y \) is impossible. Therefore, the goal is vacuously true. -/
  | nil => simp_all
/- Next, consider the case where the list \( xs \) is non-empty, i.e., \( xs = x :: xs' \). We split the proof into two cases based on whether the predicate \( p \) holds for the head element \( x \) of the list.

1. **Case 1: \( p(x) = \text{true} \)**
- If \( p(x) = \text{true} \), then by the definition of `List.findIdx`, the index of the first element satisfying \( p \) in the list \( x :: xs' \) is \( 0 \). Therefore, \( \text{List.get? } (x :: xs') \, (\text{List.findIdx } p \, (x :: xs')) = \text{some } x \). Given the assumption \( \text{List.get? } (x :: xs') \, (\text{List.findIdx } p \, (x :: xs')) = \text{some } y \), it follows that \( y = x \). Since \( p(x) = \text{true} \), we have \( p(y) = \text{true} \).

2. **Case 2: \( p(x) = \text{false} \)**
- If \( p(x) = \text{false} \), then by the definition of `List.findIdx`, the index of the first element satisfying \( p \) in the list \( x :: xs' \) is \( \text{List.findIdx } p \, xs' + 1 \). Therefore, \( \text{List.get? } (x :: xs') \, (\text{List.findIdx } p \, (x :: xs')) = \text{List.get? } xs' \, (\text{List.findIdx } p \, xs') \). Given the assumption \( \text{List.get? } (x :: xs') \, (\text{List.findIdx } p \, (x :: xs')) = \text{some } y \), it follows that \( \text{List.get? } xs' \, (\text{List.findIdx } p \, xs') = \text{some } y \). By the induction hypothesis, \( p(y) = \text{true} \). -/
  | cons x xs ih => by_cases h : p x <;> simp_all [findIdx_cons]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
39872,List.find?_eq_none,"theorem List.find?_eq_none : find? p l = none ↔ ∀ x ∈ l, ¬ p x := by sorry","List Find Returns None if and Only if No Element Satisfies Predicate : For any list \( l \) of elements of type \( \alpha \) and any predicate \( p : \alpha \to \text{Bool} \), the function `List.find? p l` returns `none` if and only if for every element \( x \) in \( l \), \( p(x) \) is `false`. In other words, `List.find? p l = none` if and only if \( \forall x \in l, \neg p(x) \).","theorem List.find?_eq_none : find? p l = none ↔ ∀ x ∈ l, ¬ p x := by
  induction l <;> simp [find?_cons]; split <;> simp [*]","We prove the theorem by induction on the list \( l \).

- **Base Case:** Consider the empty list \( l = [] \). We need to show that `List.find? p [] = none` if and only if for every element \( x \) in \( [] \), \( p(x) \) is `false`. Since the empty list contains no elements, the right-hand side of the equivalence is vacuously true. Therefore, `List.find? p [] = none` is true.

- **Inductive Step:** Assume the property holds for the list \( l \), i.e., `List.find? p l = none` if and only if for every element \( x \) in \( l \), \( p(x) \) is `false`. We need to show that `List.find? p (a :: l) = none` if and only if for every element \( x \) in \( a :: l \), \( p(x) \) is `false`.

- If \( p(a) \) is `true`, then `List.find? p (a :: l) = some a`, which means `List.find? p (a :: l) ≠ none`. Therefore, the left-hand side of the equivalence is false, and the right-hand side is also false because \( p(a) \) is `true`.
- If \( p(a) \) is `false`, then `List.find? p (a :: l) = List.find? p l`. By the induction hypothesis, `List.find? p l = none` if and only if for every element \( x \) in \( l \), \( p(x) \) is `false`. Therefore, `List.find? p (a :: l) = none` if and only if for every element \( x \) in \( a :: l \), \( p(x) \) is `false`.

This completes the proof.","theorem List.find?_eq_none : find? p l = none ↔ ∀ x ∈ l, ¬ p x := by
/- We proceed by induction on the list \( l \).

- **Base Case:** For the empty list \( l = [] \), we need to show that `List.find? p [] = none` if and only if for every element \( x \) in \( [] \), \( p(x) \) is `false`. Since the empty list contains no elements, the right-hand side of the equivalence is vacuously true. Therefore, `List.find? p [] = none` is true.

- **Inductive Step:** Assume the property holds for the list \( l \), i.e., `List.find? p l = none` if and only if for every element \( x \) in \( l \), \( p(x) \) is `false`. We need to show that `List.find? p (a :: l) = none` if and only if for every element \( x \) in \( a :: l \), \( p(x) \) is `false`.

- If \( p(a) \) is `true`, then `List.find? p (a :: l) = some a`, which means `List.find? p (a :: l) ≠ none`. Therefore, the left-hand side of the equivalence is false, and the right-hand side is also false because \( p(a) \) is `true`.
- If \( p(a) \) is `false`, then `List.find? p (a :: l) = List.find? p l`. By the induction hypothesis, `List.find? p l = none` if and only if for every element \( x \) in \( l \), \( p(x) \) is `false`. Therefore, `List.find? p (a :: l) = none` if and only if for every element \( x \) in \( a :: l \), \( p(x) \) is `false`. -/
  induction l <;> simp [find?_cons]; split <;> simp [*]","import Init.Data.List.Lemmas
import Init.Data.List.Find

open List
open Nat
"
40339,List.append_cons,theorem List.append_cons (as : List α) (b : α) (bs : List α) : as ++ b :: bs = as ++ [b] ++ bs := by sorry,"Appending a Cons List is Equivalent to Appending a Singleton List and Another List : For any type \( \alpha \), any list \( as \) of elements of type \( \alpha \), any element \( b \) of type \( \alpha \), and any list \( bs \) of elements of type \( \alpha \), the following equality holds:
\[ as \oplus (b :: bs) = as \oplus [b] \oplus bs \]
where \( \oplus \) denotes the append operation, and \( b :: bs \) and \( [b] \) denote the list with \( b \) as the head and \( bs \) as the tail, and the singleton list containing \( b \), respectively.","theorem List.append_cons (as : List α) (b : α) (bs : List α) : as ++ b :: bs = as ++ [b] ++ bs := by
  simp","We need to show that for any type \( \alpha \), any list \( as \) of elements of type \( \alpha \), any element \( b \) of type \( \alpha \), and any list \( bs \) of elements of type \( \alpha \), the following equality holds:
\[ as \oplus (b :: bs) = as \oplus [b] \oplus bs \]

To prove this, we simplify the proposition using the properties of the append operation and the definition of the cons operation. The left-hand side \( as \oplus (b :: bs) \) can be expanded as:
\[ as \oplus (b :: bs) = (as \oplus [b]) \oplus bs \]

The right-hand side \( as \oplus [b] \oplus bs \) is already in the form:
\[ as \oplus [b] \oplus bs \]

Since both sides of the equation are equivalent, we have:
\[ as \oplus (b :: bs) = as \oplus [b] \oplus bs \]

Thus, the proposition holds, and the proof is complete.","theorem List.append_cons (as : List α) (b : α) (bs : List α) : as ++ b :: bs = as ++ [b] ++ bs := by
/- Simplify the proposition we want to show, which is \( as \oplus (b :: bs) = as \oplus [b] \oplus bs \). Using the properties of the append operation and the definition of the cons operation, we can see that both sides of the equation are equivalent. Therefore, the proposition holds. -/
  simp","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40346,List.getLastD_cons,theorem List.getLastD_cons (a b l) : @getLastD α (b::l) a = getLastD l b := by sorry,"Last Element of Cons List with Fallback Equals Last Element of Tail with New Fallback : For any type \( \alpha \), and for any elements \( a, b \in \alpha \) and list \( l \) of elements of type \( \alpha \), the last element of the list \( b :: l \) with fallback \( a \) is equal to the last element of the list \( l \) with fallback \( b \). In other words, \((b :: l). \text{getLastD}(a) = l. \text{getLastD}(b)\).","theorem List.getLastD_cons (a b l) : @getLastD α (b::l) a = getLastD l b := by
  cases l <;> rfl","We will consider every possible case of the list \( l \).

**Case 1:**
If \( l \) is the empty list \( \text{nil} \), then the list \( b :: \text{nil} \) is a list with a single element \( b \). The last element of \( b :: \text{nil} \) with fallback \( a \) is \( b \). Similarly, the last element of \( \text{nil} \) with fallback \( b \) is \( b \). Therefore, \((b :: \text{nil}).\text{getLastD}(a) = \text{nil}.\text{getLastD}(b)\) holds trivially.

**Case 2:**
If \( l \) is a non-empty list \( \text{head} :: \text{tail} \), then the list \( b :: \text{head} :: \text{tail} \) has \( b \) as the first element and \(\text{head} :: \text{tail}\) as the rest. The last element of \( b :: \text{head} :: \text{tail} \) with fallback \( a \) is the same as the last element of \(\text{head} :: \text{tail}\) with fallback \( b \). Therefore, \((b :: \text{head} :: \text{tail}).\text{getLastD}(a) = (\text{head} :: \text{tail}).\text{getLastD}(b)\) holds trivially.

In both cases, the equality holds, thus completing the proof.","theorem List.getLastD_cons (a b l) : @getLastD α (b::l) a = getLastD l b := by
  cases l <;> rfl","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40347,List.isPrefixOf_nil_left,theorem List.isPrefixOf_nil_left [BEq α] : isPrefixOf ([] : List α) l = true := by sorry,"Empty List is a Prefix of Any List : For any list \( l \) of elements of type \( \alpha \), the empty list is a prefix of \( l \). Formally, this is expressed as \(\text{nil} \text{ isPrefixOf } l = \text{true}\).","theorem List.isPrefixOf_nil_left [BEq α] : isPrefixOf ([] : List α) l = true := by
  simp [isPrefixOf]","To prove that the empty list is a prefix of any list \( l \), we use the definition of the `isPrefixOf` function. According to the definition:
- If the first list is the empty list, `isPrefixOf` returns `true` for any second list.
- If the first list is non-empty and the second list is empty, `isPrefixOf` returns `false`.
- If both lists are non-empty, `isPrefixOf` returns `true` if the first elements of both lists are equal and the rest of the first list is a prefix of the rest of the second list.

Since the empty list is the first list in our case, the definition directly states that `isPrefixOf` returns `true` for any list \( l \). Therefore, the proposition \(\text{nil} \text{ isPrefixOf } l = \text{true}\) is trivially true. This completes the proof.","theorem List.isPrefixOf_nil_left [BEq α] : isPrefixOf ([] : List α) l = true := by
/- Using the definition of `isPrefixOf`, we simplify the proposition we want to show. The definition of `isPrefixOf` states that the empty list is a prefix of any list `l`, which is `true` by definition. Therefore, the proposition `nil.isPrefixOf l = true` is trivially true. -/
  simp [isPrefixOf]","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40349,List.isSuffixOf_nil_left,theorem List.isSuffixOf_nil_left [BEq α] : isSuffixOf ([] : List α) l = true := by sorry,"Empty List is a Suffix of Any List : For any list \( l \) of elements of type \( \alpha \), the empty list \( \text{nil} \) is a suffix of \( l \). This is expressed as \( \text{nil}. \text{isSuffixOf } l = \text{true} \).","theorem List.isSuffixOf_nil_left [BEq α] : isSuffixOf ([] : List α) l = true := by
  simp [isSuffixOf]","To prove that the empty list `nil` is a suffix of any list `l`, we use the definition of `isSuffixOf`. According to the definition, a list `xs` is a suffix of `ys` if there exists a list `zs` such that `ys = zs ++ xs`. For the empty list `nil`, this condition is always satisfied because for any list `l`, we have `l = l ++ nil`. Therefore, the empty list `nil` is a suffix of any list `l`, and the proposition `nil.isSuffixOf l = true` holds. This completes the proof.","theorem List.isSuffixOf_nil_left [BEq α] : isSuffixOf ([] : List α) l = true := by
/- Using the definition of `isSuffixOf`, we simplify the proposition that the empty list `nil` is a suffix of any list `l` to `true`. This is because the definition of `isSuffixOf` states that a list `xs` is a suffix of `ys` if there exists a list `zs` such that `ys = zs ++ xs`. For the empty list `nil`, this condition is always satisfied since `l = l ++ nil` for any list `l`. -/
  simp [isSuffixOf]","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40352,List.zip_nil_right,theorem List.zip_nil_right : zip (l : List α) ([] : List β)  = [] := by sorry,"Zip with Empty List on the Right Results in Empty List : For any lists $l$ of elements of type $\alpha$ and the empty list `nil` of elements of type $\beta$, the zip operation `l.zip nil` results in the empty list `nil`. In other words, if one of the lists is empty, the result of the zip operation is also an empty list.","theorem List.zip_nil_right : zip (l : List α) ([] : List β)  = [] := by
  simp [zip, zipWith]","To prove that `l.zip nil = nil`, we use the definition of the `zip` operation. The `zip` operation is defined as `zip l₁ l₂ = zipWith (λ x y, (x, y)) l₁ l₂`, which pairs corresponding elements from two lists `l₁` and `l₂` until the end of the shorter list.

Given the definition of `zipWith`, we know that `zipWith f l₁ l₂` results in the empty list `nil` if either `l₁` or `l₂` is empty. In our case, `l₂` is the empty list `nil`. Therefore, `zipWith (λ x y, (x, y)) l nil` results in the empty list `nil`.

Thus, `l.zip nil = nil`. This completes the proof.","theorem List.zip_nil_right : zip (l : List α) ([] : List β)  = [] := by
  simp [zip, zipWith]","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
variable (R : α → α → Prop)
variable {R}
"
40354,List.append_assoc,theorem List.append_assoc (as bs cs : List α) : (as ++ bs) ++ cs = as ++ (bs ++ cs) := by sorry,"Associativity of List Append: \((\text{as} \oplus \text{bs}) \oplus \text{cs} = \text{as} \oplus (\text{bs} \oplus \text{cs})\) : For any type \( \alpha \) and any lists \( \text{as}, \text{bs}, \text{cs} \) of elements of type \( \alpha \), the append operation is associative, i.e., \((\text{as} \oplus \text{bs}) \oplus \text{cs} = \text{as} \oplus (\text{bs} \oplus \text{cs})\), where \( \oplus \) denotes the append operation.","theorem List.append_assoc (as bs cs : List α) : (as ++ bs) ++ cs = as ++ (bs ++ cs) := by
  induction as with
  | nil => rfl
  | cons a as ih => simp [ih]","We prove the associativity of the append operation by induction on the list `as`.

1. **Base Case:**
- Consider the case where `as` is the empty list, i.e., `as = nil`.
- The goal is to show that `nil ++ bs ++ cs = nil ++ (bs ++ cs)`.
- Since the empty list `nil` appended to any list is the list itself, both sides of the equation are equal to `bs ++ cs`.
- Therefore, the equality holds trivially due to the reflexive property.

2. **Inductive Case:**
- Consider the case where `as` is a non-empty list, i.e., `as = a :: as'` for some element `a` and list `as'`.
- The goal is to show that `a :: as' ++ bs ++ cs = a :: (as' ++ (bs ++ cs))`.
- By the inductive hypothesis, we know that `as' ++ bs ++ cs = as' ++ (bs ++ cs)`.
- Using this hypothesis, we can simplify the left-hand side of the goal to `a :: (as' ++ bs ++ cs)`, which is equal to `a :: (as' ++ (bs ++ cs))` by the definition of the append operation.
- Therefore, the equality holds.

By induction, the associativity of the append operation is proven for all lists `as`, `bs`, and `cs`. This completes the proof.","theorem List.append_assoc (as bs cs : List α) : (as ++ bs) ++ cs = as ++ (bs ++ cs) := by
  induction as with
/- First, consider the base case where the list `as` is empty. The goal is to show that `nil ++ bs ++ cs = nil ++ (bs ++ cs)`. Since the empty list `nil` appended to any list is the list itself, both sides of the equation are equal to `bs ++ cs`. Therefore, the equality holds trivially due to the reflexive property. -/
  | nil => rfl
/- Next, consider the inductive case where `as` is a non-empty list, i.e., `as = a :: as'` for some element `a` and list `as'`. The goal is to show that `a :: as' ++ bs ++ cs = a :: (as' ++ (bs ++ cs))`. By the inductive hypothesis, we know that `as' ++ bs ++ cs = as' ++ (bs ++ cs)`. Using this hypothesis, we can simplify the left-hand side of the goal to `a :: (as' ++ bs ++ cs)`, which is equal to `a :: (as' ++ (bs ++ cs))` by the definition of the append operation. Therefore, the equality holds. -/
  | cons a as ih => simp [ih]","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40355,List.length_replicate,theorem List.length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by sorry,"Length of Replicated List Equals the Replication Count : For any natural number \( n \) and any element \( a \) of type \( \alpha \), the length of the list created by replicating \( a \) \( n \) times is equal to \( n \). In other words, \(\text{length}(\text{replicate}(n, a)) = n\).","theorem List.length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
  induction n with
  | zero => simp
  | succ n ih => simp only [ih, replicate_succ, length_cons, Nat.succ_eq_add_one]","We prove this by induction on \( n \).

**Base Case:**
Consider \( n = 0 \). We need to show that the length of the list created by replicating \( a \) zero times is zero. By the definition of `replicate`, \(\text{replicate}(0, a)\) is the empty list \([]\). The length of the empty list is \(0\). Therefore, \(\text{length}(\text{replicate}(0, a)) = 0\).

**Inductive Step:**
Assume that for some natural number \( k \), the length of the list created by replicating \( a \) \( k \) times is \( k \). That is, \(\text{length}(\text{replicate}(k, a)) = k\). We need to show that the length of the list created by replicating \( a \) \( k + 1 \) times is \( k + 1 \). By the definition of `replicate`, \(\text{replicate}(k + 1, a)\) is the list \( a :: \text{replicate}(k, a) \). The length of this list is:
\[
\text{length}(a :: \text{replicate}(k, a)) = 1 + \text{length}(\text{replicate}(k, a)) = 1 + k = k + 1
\]
Thus, the inductive step holds.

By the principle of mathematical induction, the theorem is true for all natural numbers \( n \). Therefore, \(\text{length}(\text{replicate}(n, a)) = n\). This completes the proof.","theorem List.length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
  induction n with
/- First, consider the base case where \( n = 0 \). We need to show that the length of the list created by replicating \( a \) zero times is zero. By simplifying the expression, we get \(\text{length}(\text{replicate}(0, a)) = 0\), which is trivially true. -/
  | zero => simp
/- Next, consider the inductive step where \( n = k + 1 \) for some natural number \( k \). Assume that the length of the list created by replicating \( a \) \( k \) times is \( k \). We need to show that the length of the list created by replicating \( a \) \( k + 1 \) times is \( k + 1 \). Using the inductive hypothesis and the definitions of `replicate`, `length`, and the successor function, we can simplify the expression as follows:
\[
\text{length}(\text{replicate}(k + 1, a)) = \text{length}(a :: \text{replicate}(k, a)) = 1 + \text{length}(\text{replicate}(k, a)) = 1 + k = k + 1
\]
Thus, the inductive step holds. -/
  | succ n ih => simp only [ih, replicate_succ, length_cons, Nat.succ_eq_add_one]","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40357,List.append_nil,theorem List.append_nil (as : List α) : as ++ [] = as := by sorry,"Appending Empty List is Identity for Lists : For any list \( \text{as} \) of elements of type \( \alpha \), appending the empty list \( \text{nil} \) to \( \text{as} \) results in the list \( \text{as} \) itself. Formally, \( \text{as} \) ++ \( \text{nil} \) = \( \text{as} \).","theorem List.append_nil (as : List α) : as ++ [] = as := by
  induction as with
  | nil => rfl
  | cons a as ih =>
    simp_all only [HAppend.hAppend, Append.append, List.append]","We prove this by induction on the list \( \text{as} \).

1. **Base Case:**
- Consider the empty list \( \text{nil} \).
- The goal is to show that \( \text{nil} \) ++ \( \text{nil} \) = \( \text{nil} \).
- This is trivially true because appending the empty list to the empty list results in the empty list.

2. **Inductive Step:**
- Assume that for any list \( \text{as} \), appending the empty list to \( \text{as} \) results in \( \text{as} \) (inductive hypothesis).
- We need to show that for any element \( a \) and list \( \text{as} \), appending the empty list to \( a :: \text{as} \) results in \( a :: \text{as} \).
- By the definition of list concatenation, \( a :: \text{as} \) ++ \( \text{nil} \) = \( a :: (\text{as} ++ \text{nil}) \).
- By the inductive hypothesis, \( \text{as} ++ \text{nil} = \text{as} \).
- Therefore, \( a :: (\text{as} ++ \text{nil}) = a :: \text{as} \).

By induction, the theorem holds for all lists \( \text{as} \). This completes the proof.","theorem List.append_nil (as : List α) : as ++ [] = as := by
  induction as with
/- For the base case where the list is empty, the goal is trivially true because appending the empty list to the empty list results in the empty list. -/
  | nil => rfl
/- For the inductive step, assume that appending the empty list to a list `as` results in `as` (inductive hypothesis). We need to show that appending the empty list to a list `a :: as` results in `a :: as`. -/
  | cons a as ih =>
/- Using the definitions of `HAppend.hAppend`, `Append.append`, and `List.append`, we can simplify the goal to show that appending the empty list to any list `as` results in the list `as` itself. -/
/- Using the definitions of `HAppend.hAppend`, `Append.append`, and `List.append`, we can simplify the goal to show that appending the empty list to `a :: as` results in `a :: as`. By the inductive hypothesis, this simplifies to `a :: as`, which is what we needed to show. -/
    simp_all only [HAppend.hAppend, Append.append, List.append]","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40358,List.mem_append_of_mem_right,theorem List.mem_append_of_mem_right {b : α} {bs : List α} (as : List α) : b ∈ bs → b ∈ as ++ bs := by sorry,"Membership in Right List Implies Membership in Appended List : For any type \( \alpha \), any element \( b \) of type \( \alpha \), and any lists \( as \) and \( bs \) of elements of type \( \alpha \), if \( b \) is a member of \( bs \), then \( b \) is also a member of the list \( as ++ bs \).","theorem List.mem_append_of_mem_right {b : α} {bs : List α} (as : List α) : b ∈ bs → b ∈ as ++ bs := by
  intro h
  induction as with
  | nil  => simp [h]
  | cons => apply Mem.tail; assumption","Let \( h \) be the hypothesis that \( b \in bs \). We need to show that \( b \in as ++ bs \).

1. **Case 1: \( as \) is the empty list.**
- If \( as = \text{nil} \), then \( as ++ bs = \text{nil} ++ bs = bs \).
- Since \( b \in bs \) by hypothesis \( h \), it follows that \( b \in bs \).
- Therefore, \( b \in \text{nil} ++ bs \).

2. **Case 2: \( as \) is a non-empty list.**
- Let \( as = \text{head} :: \text{tail} \).
- We need to show that \( b \in \text{head} :: \text{tail} ++ bs \).
- By the theorem that if \( b \in \text{tail} ++ bs \), then \( b \in \text{head} :: \text{tail} ++ bs \), it suffices to show that \( b \in \text{tail} ++ bs \).
- By the induction hypothesis, since \( b \in bs \) by hypothesis \( h \), it follows that \( b \in \text{tail} ++ bs \).
- Therefore, \( b \in \text{head} :: \text{tail} ++ bs \).

In both cases, we have shown that \( b \in as ++ bs \). This completes the proof.","theorem List.mem_append_of_mem_right {b : α} {bs : List α} (as : List α) : b ∈ bs → b ∈ as ++ bs := by
/- Let \( h \) be the hypothesis that \( b \in bs \). We need to show that \( b \in as ++ bs \). -/
  intro h
  induction as with
/- Consider the case where \( as \) is the empty list. Using the hypothesis \( h \) that \( b \in bs \), we can simplify the goal to show that \( b \in \text{nil} ++ bs \). Since the concatenation of the empty list with any list \( bs \) is just \( bs \), it follows that \( b \in bs \). This completes the proof for this case. -/
  | nil  => simp [h]
/- Consider the case where \( as \) is a non-empty list, say \( as = \text{head} :: \text{tail} \). To show that \( b \in \text{head} :: \text{tail} ++ bs \), we use the theorem that if \( b \in \text{tail} ++ bs \), then \( b \in \text{head} :: \text{tail} ++ bs \). Since we have the hypothesis \( h \) that \( b \in bs \), and by the induction hypothesis, \( b \in \text{tail} ++ bs \), it follows that \( b \in \text{head} :: \text{tail} ++ bs \). This completes the proof for this case. -/
  | cons => apply Mem.tail; assumption","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40360,List.erase_cons,"theorem List.erase_cons [BEq α] (a b : α) (l : List α) :
    (b :: l).erase a = if b == a then l else b :: l.erase a := by sorry","Erase First Occurrence of Element from Cons List : For any type \(\alpha\) with a decidable equality instance, and for any elements \(a, b \in \alpha\) and list \(l\) of elements of type \(\alpha\), the list \((b :: l)\) with the first occurrence of \(a\) erased is given by:
\[
(b :: l). \text{erase } a = 
\begin{cases} 
l & \text{if } b = a \\
b :: (l. \text{erase } a) & \text{if } b \neq a 
\end{cases}
\]","theorem List.erase_cons [BEq α] (a b : α) (l : List α) :
    (b :: l).erase a = if b == a then l else b :: l.erase a := by
  simp only [List.erase]; split <;> simp_all","To prove the theorem, we start by simplifying the expression \((b :: l). \text{erase } a\) using the definition of the `erase` function. This simplification splits the problem into two cases based on whether \(b\) is equal to \(a\) or not.

1. **Case 1: \(b = a\)**

If \(b = a\), then the first element of the list \((b :: l)\) is \(a\). According to the definition of `erase`, the first occurrence of \(a\) is removed, leaving the list \(l\). Therefore, we have:
\[
(b :: l). \text{erase } a = l
\]

2. **Case 2: \(b \neq a\)**

If \(b \neq a\), then the first element of the list \((b :: l)\) is not \(a\). According to the definition of `erase`, the first element \(b\) remains in the list, and we need to erase the first occurrence of \(a\) from the rest of the list \(l\). Therefore, we have:
\[
(b :: l). \text{erase } a = b :: (l. \text{erase } a)
\]

In both cases, the simplified expressions match the desired results. Hence, the theorem is proved. \(\blacksquare\)","theorem List.erase_cons [BEq α] (a b : α) (l : List α) :
    (b :: l).erase a = if b == a then l else b :: l.erase a := by
/- First, we simplify the expression \((b :: l). \text{erase } a\) using the definition of the `erase` function. This simplification splits the goal into two cases based on whether \(b\) is equal to \(a\) or not. In each case, we further simplify the expression to match the desired result. -/
  simp only [List.erase]; split <;> simp_all","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
variable (R : α → α → Prop)
variable {R}
"
40364,List.mem_append_of_mem_left,theorem List.mem_append_of_mem_left {a : α} {as : List α} (bs : List α) : a ∈ as → a ∈ as ++ bs := by sorry,"Membership in Left List Implies Membership in Appended List : For any type \( \alpha \), any element \( a \) of type \( \alpha \), and any lists \( as \) and \( bs \) of elements of type \( \alpha \), if \( a \) is a member of \( as \), then \( a \) is also a member of the list \( as ++ bs \).","theorem List.mem_append_of_mem_left {a : α} {as : List α} (bs : List α) : a ∈ as → a ∈ as ++ bs := by
  intro h
  induction h with
  | head => apply Mem.head
  | tail => apply Mem.tail; assumption","We start by letting \( h \) be the hypothesis that \( a \in as \). We need to show that \( a \in as ++ bs \).

1. **Case 1: \( a \) is the head of the list \( as \).**
- By the property that an element is a member of a list if it is the head of the list, \( a \in a :: as \).
- Therefore, \( a \in a :: as ++ bs \).

2. **Case 2: \( a \) is a member of the tail of the list \( as \).**
- By the induction hypothesis, \( a \in as \) implies \( a \in as ++ bs \).
- Since \( a \in as \) and \( as \) is the tail of \( as \), we have \( a \in as ++ bs \).
- By the property that if an element is in a list, it is also in the list obtained by adding an element to the front, \( a \in b :: as ++ bs \).

Thus, in both cases, we have shown that \( a \in as ++ bs \). This completes the proof.","theorem List.mem_append_of_mem_left {a : α} {as : List α} (bs : List α) : a ∈ as → a ∈ as ++ bs := by
/- Let \( h \) be the hypothesis that \( a \in as \). We need to show that \( a \in as ++ bs \). -/
  intro h
  induction h with
/- Consider the case where \( a \) is the head of the list \( as \). By the property that an element is a member of a list if it is the head of the list, \( a \in a :: as \). Therefore, \( a \in a :: as ++ bs \). -/
  | head => apply Mem.head
/- Consider the case where \( a \) is a member of the tail of the list \( as \). By the induction hypothesis, \( a \in as \) implies \( a \in as ++ bs \). Since \( a \in as \) and \( as \) is the tail of \( as \), we have \( a \in as ++ bs \). By the property that if an element is in a list, it is also in the list obtained by adding an element to the front, \( a \in b :: as ++ bs \). -/
  | tail => apply Mem.tail; assumption","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40366,List.drop_nil,theorem List.drop_nil : ([] : List α).drop i = [] := by sorry,"Dropping Elements from Empty List Results in Empty List : For any type $\alpha$ and any natural number $i$, dropping the first $i$ elements from the empty list of type $\alpha$ results in the empty list, i.e., $\text{drop}(i, \text{nil}) = \text{nil}$.","theorem List.drop_nil : ([] : List α).drop i = [] := by
  cases i <;> rfl","We need to show that for any natural number $i$, $\text{drop}(i, \text{nil}) = \text{nil}$. We will consider two cases for $i$:

1. **Case 1: $i = 0$**
- By the definition of the `drop` function, $\text{drop}(0, \text{nil})$ does not remove any elements from the empty list. Therefore, $\text{drop}(0, \text{nil}) = \text{nil}$.

2. **Case 2: $i = n + 1$ for some natural number $n$**
- By the definition of the `drop` function, $\text{drop}(n + 1, \text{nil})$ removes the first $n + 1$ elements from the empty list. Since the empty list has no elements, removing any number of elements from it results in the empty list. Therefore, $\text{drop}(n + 1, \text{nil}) = \text{nil}$.

In both cases, we have shown that $\text{drop}(i, \text{nil}) = \text{nil}$. This completes the proof. $\blacksquare$","theorem List.drop_nil : ([] : List α).drop i = [] := by
/- We will consider every possible case for the natural number $i$. Specifically, we consider two cases: $i = 0$ and $i = n + 1$ for some natural number $n$. For each case, we will show that dropping the first $i$ elements from the empty list results in the empty list. -/
/- We will discuss every possible case of $i$. Case 1: $i = 0$. Case 2: $i = n + 1$ for some natural number $n$. -/
/- For the case $i = 0$, the equality $\text{drop}(0, \text{nil}) = \text{nil}$ holds trivially by the definition of the `drop` function, which does not remove any elements when $i = 0$. -/
/- For the case $i = n + 1$, the equality $\text{drop}(n + 1, \text{nil}) = \text{nil}$ holds trivially by the definition of the `drop` function, which removes the first $n + 1$ elements from the empty list, resulting in the empty list. -/
  cases i <;> rfl","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40368,List.concat_eq_append,theorem List.concat_eq_append (as : List α) (a : α) : as.concat a = as ++ [a] := by sorry,"Concatenation of an Element to a List Equals Appending a Singleton List : For any list \( as \) of elements of type \( \alpha \) and any element \( a \) of type \( \alpha \), the concatenation of \( a \) to the end of \( as \) is equal to the list obtained by appending \( a \) to \( as \) as a singleton list, i.e., \( as.concat(a) = as ++ [a] \).","theorem List.concat_eq_append (as : List α) (a : α) : as.concat a = as ++ [a] := by
  induction as <;> simp [concat, *]","We prove this by induction on the list \( as \).

1. **Base Case:**
- Consider the empty list \( \text{nil} \).
- We need to show that \( \text{nil.concat}(a) = \text{nil} ++ [a] \).
- By the definition of `concat`, \( \text{nil.concat}(a) = [a] \).
- By the definition of list concatenation, \( \text{nil} ++ [a] = [a] \).
- Therefore, \( \text{nil.concat}(a) = \text{nil} ++ [a] \).

2. **Inductive Step:**
- Assume the property holds for a list \( \text{tail} \), i.e., \( \text{tail.concat}(a) = \text{tail} ++ [a] \).
- Consider a non-empty list \( \text{head} :: \text{tail} \).
- We need to show that \( (\text{head} :: \text{tail}).concat(a) = \text{head} :: (\text{tail} ++ [a]) \).
- By the definition of `concat`, \( (\text{head} :: \text{tail}).concat(a) = \text{head} :: (\text{tail.concat}(a)) \).
- By the inductive hypothesis, \( \text{tail.concat}(a) = \text{tail} ++ [a] \).
- Therefore, \( \text{head} :: (\text{tail.concat}(a)) = \text{head} :: (\text{tail} ++ [a]) \).

Since both the base case and the inductive step hold, by induction, the property \( as.concat(a) = as ++ [a] \) holds for all lists \( as \) and elements \( a \). This completes the proof.","theorem List.concat_eq_append (as : List α) (a : α) : as.concat a = as ++ [a] := by
/- We perform induction on the list \( as \). This breaks down the proof into two cases: the base case where \( as \) is the empty list \( \text{nil} \), and the inductive step where \( as \) is a non-empty list \( \text{head} :: \text{tail} \). -/
/- For the base case, we need to show that \( \text{nil.concat}(a) = \text{nil} ++ [a] \). Using the definition of `concat` and the properties of list concatenation, we simplify the left-hand side to \( [a] \) and the right-hand side to \( [a] \). Since both sides are equal, the base case holds. -/
/- For the inductive step, we assume that the property holds for the tail of the list, i.e., \( \text{tail.concat}(a) = \text{tail} ++ [a] \). We need to show that \( (\text{head} :: \text{tail}).concat(a) = \text{head} :: (\text{tail} ++ [a]) \). Using the definition of `concat` and the inductive hypothesis, we simplify the left-hand side to \( \text{head} :: (\text{tail.concat}(a)) \), which by the inductive hypothesis is \( \text{head} :: (\text{tail} ++ [a]) \). Since both sides are equal, the inductive step holds. -/
  induction as <;> simp [concat, *]","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40375,List.length_append,theorem List.length_append (as bs : List α) : (as ++ bs).length = as.length + bs.length := by sorry,"Length of Concatenated Lists: \(\text{length}(\text{as} \oplus \text{bs}) = \text{length}(\text{as}) + \text{length}(\text{bs})\) : For any type \( \alpha \) and any lists \( \text{as} \) and \( \text{bs} \) of elements of type \( \alpha \), the length of the concatenated list \( \text{as} \oplus \text{bs} \) is equal to the sum of the lengths of \( \text{as} \) and \( \text{bs} \). Formally, \( \text{length}(\text{as} \oplus \text{bs}) = \text{length}(\text{as}) + \text{length}(\text{bs}) \).","theorem List.length_append (as bs : List α) : (as ++ bs).length = as.length + bs.length := by
  induction as with
  | nil => simp
  | cons _ as ih => simp [ih, Nat.succ_add]","We prove this by induction on the list \(\text{as}\).

1. **Base Case:**
- Consider the case where \(\text{as}\) is the empty list \([]\).
- We need to show that \(\text{length}([] \oplus \text{bs}) = \text{length}([]) + \text{length}(\text{bs})\).
- Simplifying the left-hand side, we get \(\text{length}(\text{bs})\).
- Simplifying the right-hand side, we get \(0 + \text{length}(\text{bs})\), which is \(\text{length}(\text{bs})\).
- Therefore, \(\text{length}([] \oplus \text{bs}) = \text{length}(\text{bs})\), and the base case is proved.

2. **Inductive Step:**
- Assume the inductive hypothesis: for any list \(\text{as}'\), \(\text{length}(\text{as}' \oplus \text{bs}) = \text{length}(\text{as}') + \text{length}(\text{bs})\).
- Consider the case where \(\text{as}\) is of the form \(a :: \text{as}'\) (i.e., \(\text{as}\) is a non-empty list with head \(a\) and tail \(\text{as}'\)).
- We need to show that \(\text{length}((a :: \text{as}') \oplus \text{bs}) = \text{length}(a :: \text{as}') + \text{length}(\text{bs})\).
- By the definition of list concatenation, \((a :: \text{as}') \oplus \text{bs} = a :: (\text{as}' \oplus \text{bs})\).
- By the definition of list length, \(\text{length}(a :: (\text{as}' \oplus \text{bs})) = \text{length}(\text{as}' \oplus \text{bs}) + 1\).
- By the inductive hypothesis, \(\text{length}(\text{as}' \oplus \text{bs}) = \text{length}(\text{as}') + \text{length}(\text{bs})\).
- Therefore, \(\text{length}(a :: (\text{as}' \oplus \text{bs})) = (\text{length}(\text{as}') + \text{length}(\text{bs})) + 1\).
- By the property of natural number addition, \((\text{length}(\text{as}') + \text{length}(\text{bs})) + 1 = \text{length}(\text{as}') + (\text{length}(\text{bs}) + 1)\).
- By the definition of list length, \(\text{length}(a :: \text{as}') = \text{length}(\text{as}') + 1\).
- Therefore, \(\text{length}((a :: \text{as}') \oplus \text{bs}) = \text{length}(a :: \text{as}') + \text{length}(\text{bs})\).
- This completes the inductive step.

By induction, the theorem is proved. \(\blacksquare\)","theorem List.length_append (as bs : List α) : (as ++ bs).length = as.length + bs.length := by
  induction as with
/- First, consider the base case where the list `as` is empty. We need to show that the length of the concatenated list `[] ++ bs` is equal to the sum of the lengths of `[]` and `bs`. Simplifying the expression, we get that the length of `[] ++ bs` is the length of `bs`, and the length of `[]` is \(0\). Therefore, the length of `[] ++ bs` is \(0 + \text{length}(bs)\), which is \(\text{length}(bs)\). This completes the base case. -/
  | nil => simp
/- Next, consider the inductive case where the list `as` is of the form `a :: as'` (i.e., `as` is a non-empty list with head `a` and tail `as'`). We need to show that the length of the concatenated list `(a :: as') ++ bs` is equal to the sum of the lengths of `a :: as'` and `bs`. By the inductive hypothesis, we know that the length of `as' ++ bs` is equal to the sum of the lengths of `as'` and `bs`. Simplifying the expression, we get that the length of `(a :: as') ++ bs` is the length of `a :: (as' ++ bs)`, which is the length of `as' ++ bs` plus \(1\). Using the inductive hypothesis, this is \(\text{length}(as') + \text{length}(bs) + 1\). By the property of natural number addition, this is equal to \(\text{length}(a :: as') + \text{length}(bs)\), which is \((\text{length}(as') + 1) + \text{length}(bs)\). Therefore, the length of `(a :: as') ++ bs` is \(\text{length}(a :: as') + \text{length}(bs)\). This completes the inductive step. -/
  | cons _ as ih => simp [ih, Nat.succ_add]","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40378,List.length_concat,theorem List.length_concat (as : List α) (a : α) : (concat as a).length = as.length + 1 := by sorry,"Length of Concatenated List: \(\text{length}(as \cdot a) = \text{length}(as) + 1\) : For any type \(\alpha\) and any list \(as : \text{List}(\alpha)\), and any element \(a : \alpha\), the length of the list obtained by appending \(a\) to the end of \(as\) is equal to the length of \(as\) plus 1. In other words, if \(as\) is a list and \(a\) is an element, then \(\text{length}(as \cdot a) = \text{length}(as) + 1\).","theorem List.length_concat (as : List α) (a : α) : (concat as a).length = as.length + 1 := by
  induction as with
  | nil => rfl
  | cons _ xs ih => simp [concat, ih]","We prove this by induction on the list \(as\).

**Base Case:**
Consider the case where \(as\) is the empty list \(\text{nil}\). The length of the list obtained by appending \(a\) to the end of \(\text{nil}\) is:
\[
\text{length}(\text{nil} \cdot a) = \text{length}(\text{cons}(a, \text{nil})) = 1
\]
On the other hand, the length of \(\text{nil}\) is \(0\), and adding 1 to it gives:
\[
\text{length}(\text{nil}) + 1 = 0 + 1 = 1
\]
Thus, the equality \(\text{length}(\text{nil} \cdot a) = \text{length}(\text{nil}) + 1\) holds.

**Inductive Step:**
Assume the statement holds for some list \(xs\), i.e., \(\text{length}(xs \cdot a) = \text{length}(xs) + 1\). We need to show that the statement holds for the list \(\text{cons}(x, xs)\) for some element \(x\). The length of the list obtained by appending \(a\) to the end of \(\text{cons}(x, xs)\) is:
\[
\text{length}((\text{cons}(x, xs)) \cdot a) = \text{length}(\text{cons}(x, (xs \cdot a)))
\]
By the definition of `length`, this is:
\[
\text{length}(\text{cons}(x, (xs \cdot a))) = \text{length}(xs \cdot a) + 1
\]
By the inductive hypothesis, we have:
\[
\text{length}(xs \cdot a) = \text{length}(xs) + 1
\]
Substituting this into the previous equation, we get:
\[
\text{length}(\text{cons}(x, (xs \cdot a))) = (\text{length}(xs) + 1) + 1 = \text{length}(xs) + 2
\]
On the other hand, the length of \(\text{cons}(x, xs)\) is:
\[
\text{length}(\text{cons}(x, xs)) = \text{length}(xs) + 1
\]
Adding 1 to this, we get:
\[
\text{length}(\text{cons}(x, xs)) + 1 = (\text{length}(xs) + 1) + 1 = \text{length}(xs) + 2
\]
Thus, the equality \(\text{length}((\text{cons}(x, xs)) \cdot a) = \text{length}(\text{cons}(x, xs)) + 1\) holds.

By induction, the theorem is proved. \(\blacksquare\)","theorem List.length_concat (as : List α) (a : α) : (concat as a).length = as.length + 1 := by
  induction as with
/- First, consider the base case where the list \( as \) is the empty list \( \text{nil} \). The length of the list obtained by appending \( a \) to the end of \( \text{nil} \) is \( \text{length}(\text{nil} \cdot a) \). By the definition of `concat`, this is \( \text{length}(\text{cons}(a, \text{nil})) \), which is \( 1 \). On the other hand, the length of \( \text{nil} \) is \( 0 \), and adding 1 to it gives \( 0 + 1 = 1 \). Therefore, the equality \( \text{length}(\text{nil} \cdot a) = \text{length}(\text{nil}) + 1 \) holds trivially. -/
  | nil => rfl
/- Next, consider the inductive case where the list \( as \) is of the form \( \text{cons}(x, xs) \) for some element \( x \) and list \( xs \). We need to show that the length of the list obtained by appending \( a \) to the end of \( \text{cons}(x, xs) \) is \( \text{length}(\text{cons}(x, xs)) + 1 \). By the definition of `concat`, we have:
\[
\text{length}((\text{cons}(x, xs)) \cdot a) = \text{length}(\text{cons}(x, (xs \cdot a)))
\]
By the definition of `length`, this is:
\[
\text{length}(\text{cons}(x, (xs \cdot a))) = \text{length}(xs \cdot a) + 1
\]
By the inductive hypothesis, we know that:
\[
\text{length}(xs \cdot a) = \text{length}(xs) + 1
\]
Substituting this into the previous equation, we get:
\[
\text{length}(\text{cons}(x, (xs \cdot a))) = (\text{length}(xs) + 1) + 1 = \text{length}(xs) + 2
\]
On the other hand, the length of \( \text{cons}(x, xs) \) is:
\[
\text{length}(\text{cons}(x, xs)) = \text{length}(xs) + 1
\]
Adding 1 to this, we get:
\[
\text{length}(\text{cons}(x, xs)) + 1 = (\text{length}(xs) + 1) + 1 = \text{length}(xs) + 2
\]
Thus, the equality \( \text{length}((\text{cons}(x, xs)) \cdot a) = \text{length}(\text{cons}(x, xs)) + 1 \) holds. -/
  | cons _ xs ih => simp [concat, ih]","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
40383,List.reverseAux_reverseAux,theorem List.reverseAux_reverseAux (as bs cs : List α) : reverseAux (reverseAux as bs) cs = reverseAux bs (reverseAux (reverseAux as []) cs) := by sorry,"List Reversal Auxiliary Function Identity : For any lists \( \text{as}, \text{bs}, \text{cs} \) of elements of type \( \alpha \), the following equality holds:
\[
(\text{as}.\text{reverseAux}(\text{bs})).\text{reverseAux}(\text{cs}) = \text{bs}.\text{reverseAux}((\text{as}.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))
\]
Here, \(\text{reverseAux}\) is an auxiliary function for reversing a list. Specifically, \(\text{reverseAux} \, l \, r\) reverses the list \( l \) and appends the result to the list \( r \).","theorem List.reverseAux_reverseAux (as bs cs : List α) : reverseAux (reverseAux as bs) cs = reverseAux bs (reverseAux (reverseAux as []) cs) := by
  induction as generalizing bs cs with
  | nil => rfl
  | cons a as ih => simp [reverseAux, ih (a::bs), ih [a]]","We prove this by induction on the list `as`.

**Base Case:**
Consider the case where `as` is the empty list, i.e., `as = nil`. The left-hand side of the goal is:
\[
(\text{nil}.\text{reverseAux}(\text{bs})).\text{reverseAux}(\text{cs})
\]
Since the empty list reversed is still the empty list, this simplifies to:
\[
\text{bs}.\text{reverseAux}(\text{cs})
\]

The right-hand side of the goal is:
\[
\text{bs}.\text{reverseAux}((\text{nil}.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))
\]
Again, since the empty list reversed is the empty list, this simplifies to:
\[
\text{bs}.\text{reverseAux}(\text{cs})
\]

Both sides are equal, so the base case holds trivially due to the reflexive property.

**Inductive Step:**
Assume the statement holds for a list `as`, i.e., for any lists `bs` and `cs`:
\[
(\text{as}.\text{reverseAux}(\text{bs})).\text{reverseAux}(\text{cs}) = \text{bs}.\text{reverseAux}((\text{as}.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))
\]

We need to show that the statement holds for the list `a :: as`, i.e., for any lists `bs` and `cs`:
\[
((a :: as).\text{reverseAux}(\text{bs})).\text{reverseAux}(\text{cs}) = \text{bs}.\text{reverseAux}(((a :: as).\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))
\]

Using the definition of `reverseAux`, we have:
\[
(a :: as).\text{reverseAux}(\text{bs}) = (as.\text{reverseAux}(a :: \text{bs}))
\]
\[
(a :: as).\text{reverseAux}(\text{nil}) = (as.\text{reverseAux}(a :: \text{nil}))
\]

Substituting these into the goal, we get:
\[
((as.\text{reverseAux}(a :: \text{bs})).\text{reverseAux}(\text{cs}) = \text{bs}.\text{reverseAux}((as.\text{reverseAux}(a :: \text{nil})).\text{reverseAux}(\text{cs}))
\]

By the inductive hypothesis, we know:
\[
(as.\text{reverseAux}(a :: \text{bs})).\text{reverseAux}(\text{cs}) = (a :: \text{bs}).\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))
\]
\[
(as.\text{reverseAux}(a :: \text{nil})).\text{reverseAux}(\text{cs}) = (a :: \text{nil}).\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))
\]

Simplifying these, we get:
\[
(a :: \text{bs}).\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))
\]
\[
(a :: \text{nil}).\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))
\]

Since \((a :: \text{nil}) = [a]\), we have:
\[
(a :: \text{bs}).\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))
\]
\[
[a].\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))
\]

Both sides are now equal, and the inductive step is complete.

By induction, the theorem holds for all lists `as`, `bs`, and `cs`. This completes the proof.","theorem List.reverseAux_reverseAux (as bs cs : List α) : reverseAux (reverseAux as bs) cs = reverseAux bs (reverseAux (reverseAux as []) cs) := by
  induction as generalizing bs cs with
/- First, consider the base case where the list `as` is empty. In this case, the left-hand side of the goal is \((\text{nil}.\text{reverseAux}(\text{bs})).\text{reverseAux}(\text{cs})\), and the right-hand side is \(\text{bs}.\text{reverseAux}((\text{nil}.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))\). Since the empty list reversed is still the empty list, both sides simplify to \(\text{bs}.\text{reverseAux}(\text{cs})\). Therefore, the equality holds trivially due to the reflexive property. -/
  | nil => rfl
/- Next, consider the inductive case where the list `as` is non-empty, specifically of the form `a :: as`. We need to show that \(((a :: as).\text{reverseAux}(\text{bs})).\text{reverseAux}(\text{cs}) = \text{bs}.\text{reverseAux}(((a :: as).\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))\).

Using the definition of `reverseAux`, we have:
- \((a :: as).\text{reverseAux}(\text{bs}) = (as.\text{reverseAux}(a :: \text{bs}))\)
- \((a :: as).\text{reverseAux}(\text{nil}) = (as.\text{reverseAux}(a :: \text{nil}))\)

Substituting these into the goal, we get:
- \(((as.\text{reverseAux}(a :: \text{bs})).\text{reverseAux}(\text{cs})\)
- \(\text{bs}.\text{reverseAux}((as.\text{reverseAux}(a :: \text{nil})).\text{reverseAux}(\text{cs}))\)

By the inductive hypothesis, we know:
- \((as.\text{reverseAux}(a :: \text{bs})).\text{reverseAux}(\text{cs}) = (a :: \text{bs}).\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))\)
- \((as.\text{reverseAux}(a :: \text{nil})).\text{reverseAux}(\text{cs}) = (a :: \text{nil}).\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))\)

Simplifying these, we get:
- \((a :: \text{bs}).\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))\)
- \((a :: \text{nil}).\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))\)

Since \((a :: \text{nil}) = [a]\), we have:
- \((a :: \text{bs}).\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))\)
- \([a].\text{reverseAux}((as.\text{reverseAux}(\text{nil})).\text{reverseAux}(\text{cs}))\)

Both sides are now equal, and the goal is satisfied. -/
  | cons a as ih => simp [reverseAux, ih (a::bs), ih [a]]","import Init.SimpLemmas
import Init.Data.Nat.Basic
import Init.Data.List.Notation
import Init.Data.List.Basic

open List
open Decidable List
variable {α : Type u} {β : Type v} {γ : Type w}
"
42233,Nat.pos_of_isPowerOfTwo,theorem Nat.pos_of_isPowerOfTwo (h : isPowerOfTwo n) : n > 0 := by sorry,"Power of Two is Positive in Natural Numbers: \( n > 0 \) if \( n \) is a Power of Two : For any natural number \( n \), if \( n \) is a power of 2, then \( n \) is strictly greater than 0, i.e., \( n > 0 \).","theorem Nat.pos_of_isPowerOfTwo (h : isPowerOfTwo n) : n > 0 := by
  have ⟨k, h⟩ := h
  rw [h]
  apply Nat.pos_pow_of_pos
  decide","We start by noting that if \( n \) is a power of 2, there exists a natural number \( k \) such that \( n = 2^k \). To prove that \( n > 0 \), we need to show that \( 2^k > 0 \).

Using the theorem that for any natural number \( n \) such that \( n > 0 \) and any natural number \( m \), \( n^m > 0 \), we can apply this theorem with \( n = 2 \) and \( m = k \). Therefore, it suffices to show that \( 0 < 2 \).

The inequality \( 0 < 2 \) is a known fact and is trivially true. Hence, \( 2^k > 0 \), and thus \( n > 0 \). This completes the proof.","theorem Nat.pos_of_isPowerOfTwo (h : isPowerOfTwo n) : n > 0 := by
/- Since \( n \) is a power of 2, there exists a natural number \( k \) such that \( n = 2^k \). We denote this \( k \) and the equality \( n = 2^k \) as \( h \). -/
  have ⟨k, h⟩ := h
/- Using the equality \( n = 2^k \) (denoted by \( h \)), we can replace \( n \) with \( 2^k \) in the goal. Therefore, to show \( n > 0 \), it suffices to show \( 2^k > 0 \). -/
  rw [h]
/- To prove \( 2^k > 0 \), we use the theorem that for any natural number \( n \) such that \( n > 0 \) and any natural number \( m \), \( n^m > 0 \). In our case, \( n = 2 \) and \( m = k \). Therefore, it suffices to show that \( 0 < 2 \). -/
  apply Nat.pos_pow_of_pos
/- The inequality \( 0 < 2 \) is a known fact and is trivially true. This completes the proof. -/
  decide","import Init.Data.Nat.Linear
import Init.Data.Nat.Power2

open Nat

"
42245,Nat.isPowerOfTwo_nextPowerOfTwo,theorem Nat.isPowerOfTwo_nextPowerOfTwo (n : Nat) : n.nextPowerOfTwo.isPowerOfTwo := by sorry,"Next Power of Two is a Power of Two in Natural Numbers: \( \text{nextPowerOfTwo}(n) \) is a Power of Two : For any natural number \( n \), the smallest power of 2 that is greater than or equal to \( n \), denoted as \( \text{nextPowerOfTwo}(n) \), is itself a power of 2. In other words, there exists a natural number \( k \) such that \( \text{nextPowerOfTwo}(n) = 2^k \).","theorem Nat.isPowerOfTwo_nextPowerOfTwo (n : Nat) : n.nextPowerOfTwo.isPowerOfTwo := by
  apply isPowerOfTwo_go
  apply one_isPowerOfTwo
where
  isPowerOfTwo_go (power : Nat) (h₁ : power > 0) (h₂ : power.isPowerOfTwo) : (nextPowerOfTwo.go n power h₁).isPowerOfTwo := by
    unfold nextPowerOfTwo.go
    split
    . exact isPowerOfTwo_go (power*2) (Nat.mul_pos h₁ (by decide)) (Nat.mul2_isPowerOfTwo_of_isPowerOfTwo h₂)
    . assumption
  termination_by n - power
  decreasing_by simp_wf; apply nextPowerOfTwo_dec <;> assumption","To prove that \( \text{nextPowerOfTwo}(n) \) is a power of 2, we use the theorem that if \( \text{power} \) is a positive power of 2, then the result of the function `Nat.nextPowerOfTwo.go` applied to \( n \) and \( \text{power} \) is also a power of 2. This reduces our goal to showing that 1 is a power of 2.

Next, we use the theorem that 1 is a power of 2, i.e., \( 1 = 2^0 \). This completes the proof that 1 is a power of 2.

To ensure that the function `Nat.nextPowerOfTwo.go` is well-founded, we unfold the recursive definitions to simplify the goal. We then apply the theorem `nextPowerOfTwo_dec` to show that the function decreases, and use the assumptions to close the remaining subgoals.

Thus, we have shown that \( \text{nextPowerOfTwo}(n) \) is a power of 2 for any natural number \( n \). This completes the proof. \(\blacksquare\)","theorem Nat.isPowerOfTwo_nextPowerOfTwo (n : Nat) : n.nextPowerOfTwo.isPowerOfTwo := by
/- To prove that \( \text{nextPowerOfTwo}(n) \) is a power of 2, we use the theorem that if \( \text{power} \) is a positive power of 2, then the result of the function `Nat.nextPowerOfTwo.go` applied to \( n \) and \( \text{power} \) is also a power of 2. This reduces our goal to showing that 1 is a power of 2. -/
  apply isPowerOfTwo_go
/- To show that 1 is a power of 2, we use the theorem that 1 is a power of 2, i.e., \( 1 = 2^0 \). This completes the proof that 1 is a power of 2. -/
  apply one_isPowerOfTwo
where
  isPowerOfTwo_go (power : Nat) (h₁ : power > 0) (h₂ : power.isPowerOfTwo) : (nextPowerOfTwo.go n power h₁).isPowerOfTwo := by
    unfold nextPowerOfTwo.go
    split
    . exact isPowerOfTwo_go (power*2) (Nat.mul_pos h₁ (by decide)) (Nat.mul2_isPowerOfTwo_of_isPowerOfTwo h₂)
    . assumption
  termination_by n - power
/- To ensure that the function `Nat.nextPowerOfTwo.go` is well-founded, we unfold the recursive definitions to simplify the goal. We then apply the theorem `nextPowerOfTwo_dec` to show that the function decreases, and use the assumptions to close the remaining subgoals. -/
  decreasing_by simp_wf; apply nextPowerOfTwo_dec <;> assumption","import Init.Data.Nat.Linear
import Init.Data.Nat.Power2

open Nat

"
43310,Nat.SOM.Poly.mulMon_denote,theorem Nat.SOM.Poly.mulMon_denote (ctx : Context) (p : Poly) (k : Nat) (m : Mon) : (p.mulMon k m).denote ctx = p.denote ctx * k * m.denote ctx := by sorry,"Evaluation of Polynomial-Monomial Multiplication: \(\text{denote}(\text{ctx}, p \cdot (k, m)) = \text{denote}(\text{ctx}, p) \cdot k \cdot \text{denote}(\text{ctx}, m)\) : For any context \( \text{ctx} \) of type `Nat.Linear.Context`, any polynomial \( p \) over the semiring of natural numbers with a specific structure, any natural number \( k \), and any monomial \( m \) of type `Nat.SOM.Mon`, the evaluation of the polynomial obtained by multiplying \( p \) by the monomial \( (k, m) \) in the context \( \text{ctx} \) is equal to the product of the evaluation of \( p \) in \( \text{ctx} \), the natural number \( k \), and the evaluation of \( m \) in \( \text{ctx} \). Mathematically, this can be expressed as:
\[
\text{denote}(\text{ctx}, p \cdot (k, m)) = \text{denote}(\text{ctx}, p) \cdot k \cdot \text{denote}(\text{ctx}, m)
\]","theorem Nat.SOM.Poly.mulMon_denote (ctx : Context) (p : Poly) (k : Nat) (m : Mon) : (p.mulMon k m).denote ctx = p.denote ctx * k * m.denote ctx := by
  simp [mulMon, go]; simp!
where
  go (p : Poly) (acc : Poly) : (mulMon.go k m p acc).denote ctx = acc.denote ctx + p.denote ctx * k * m.denote ctx := by
   match p with
   | [] => simp!
   | (k', m') :: p =>
     simp! [go p, Nat.left_distrib, denote_insertSorted, Mon.mul_denote, Nat.mul_assoc, Nat.mul_comm, Nat.mul_left_comm, Nat.add_assoc]","To prove the theorem, we start by simplifying the goal using the definitions of `mulMon` and `go`. The definition of `mulMon` specifies how the multiplication of a polynomial by a monomial is performed, and the definition of `go` provides the necessary steps to evaluate the resulting polynomial in the context \( \text{ctx} \).

After applying these definitions, the goal reduces to showing that:
\[
\text{denote}(\text{ctx}, p \cdot (k, m)) = \text{denote}(\text{ctx}, p) \cdot k \cdot \text{denote}(\text{ctx}, m)
\]

By the definition of `mulMon`, the polynomial \( p \cdot (k, m) \) is constructed by multiplying each term of \( p \) by \( k \) and then by the monomial \( m \). The evaluation of this polynomial in the context \( \text{ctx} \) is then the sum of the evaluations of these terms.

Using the properties of polynomial and monomial evaluation, we can see that:
\[
\text{denote}(\text{ctx}, p \cdot (k, m)) = \text{denote}(\text{ctx}, p) \cdot k \cdot \text{denote}(\text{ctx}, m)
\]

Thus, the theorem is proved. This completes the proof.","theorem Nat.SOM.Poly.mulMon_denote (ctx : Context) (p : Poly) (k : Nat) (m : Mon) : (p.mulMon k m).denote ctx = p.denote ctx * k * m.denote ctx := by
/- We start by simplifying the goal using the definitions of `mulMon` and `go`. After simplification, the goal reduces to showing that the evaluation of the polynomial obtained by multiplying \( p \) by the monomial \( (k, m) \) in the context \( \text{ctx} \) is equal to the product of the evaluation of \( p \) in \( \text{ctx} \), the natural number \( k \), and the evaluation of \( m \) in \( \text{ctx} \). -/
  simp [mulMon, go]; simp!
where
  go (p : Poly) (acc : Poly) : (mulMon.go k m p acc).denote ctx = acc.denote ctx + p.denote ctx * k * m.denote ctx := by
   match p with
   | [] => simp!
   | (k', m') :: p =>
     simp! [go p, Nat.left_distrib, denote_insertSorted, Mon.mul_denote, Nat.mul_assoc, Nat.mul_comm, Nat.mul_left_comm, Nat.add_assoc]","import Init.Data.Nat.Linear
import Init.Data.List.BasicAux
import Init.Data.Nat.SOM

open Nat
open SOM
open Poly
open Linear (Var hugeFuel Context Var.denote)
"
43313,Nat.SOM.Poly.mul_denote,theorem Nat.SOM.Poly.mul_denote (ctx : Context) (p₁ p₂ : Poly) : (p₁.mul p₂).denote ctx = p₁.denote ctx * p₂.denote ctx := by sorry,"Evaluation of Polynomial Multiplication: \(\text{denote}(\text{ctx}, p_1 \cdot p_2) = \text{denote}(\text{ctx}, p_1) \cdot \text{denote}(\text{ctx}, p_2)\) : For any context \( \text{ctx} \) of type `Nat.Linear.Context` and any two polynomials \( p_1 \) and \( p_2 \) over the semiring of natural numbers with a specific structure, the evaluation of the product polynomial \( p_1 \cdot p_2 \) in the context \( \text{ctx} \) is equal to the product of the evaluations of \( p_1 \) and \( p_2 \) in the same context. Mathematically, this can be expressed as:
\[
\text{denote}(\text{ctx}, p_1 \cdot p_2) = \text{denote}(\text{ctx}, p_1) \cdot \text{denote}(\text{ctx}, p_2)
\]","theorem Nat.SOM.Poly.mul_denote (ctx : Context) (p₁ p₂ : Poly) : (p₁.mul p₂).denote ctx = p₁.denote ctx * p₂.denote ctx := by
  simp [mul, go]; simp!
where
  go (p₁ : Poly) (acc : Poly) : (mul.go p₂ p₁ acc).denote ctx = acc.denote ctx + p₁.denote ctx * p₂.denote ctx := by
    match p₁ with
    | [] => simp!
    | (k, m) :: p₁ =>
      simp! [go p₁, Nat.left_distrib, add_denote, mulMon_denote,
             Nat.add_assoc, Nat.add_comm, Nat.add_left_comm,
             Nat.mul_assoc, Nat.mul_comm, Nat.mul_left_comm]","To prove the theorem, we start by simplifying the goal using the definitions of polynomial multiplication and the evaluation function. Specifically, we use the definitions of `mul` and `go` to simplify the expression. After simplification, the goal reduces to showing that the evaluation of the product polynomial \( p_1 \cdot p_2 \) in the context \( \text{ctx} \) is equal to the product of the evaluations of \( p_1 \) and \( p_2 \) in the same context. This simplification is straightforward and follows directly from the definitions. Therefore, the theorem holds.

\[
\text{denote}(\text{ctx}, p_1 \cdot p_2) = \text{denote}(\text{ctx}, p_1) \cdot \text{denote}(\text{ctx}, p_2)
\]

This completes the proof.","theorem Nat.SOM.Poly.mul_denote (ctx : Context) (p₁ p₂ : Poly) : (p₁.mul p₂).denote ctx = p₁.denote ctx * p₂.denote ctx := by
/- First, we simplify the goal using the definitions of polynomial multiplication (`mul`) and the evaluation function (`go`). After simplification, the goal reduces to showing that the evaluation of the product polynomial \( p_1 \cdot p_2 \) in the context \( \text{ctx} \) is equal to the product of the evaluations of \( p_1 \) and \( p_2 \) in the same context. This simplification is straightforward and follows from the definitions. -/
  simp [mul, go]; simp!
where
  go (p₁ : Poly) (acc : Poly) : (mul.go p₂ p₁ acc).denote ctx = acc.denote ctx + p₁.denote ctx * p₂.denote ctx := by
    match p₁ with
    | [] => simp!
    | (k, m) :: p₁ =>
      simp! [go p₁, Nat.left_distrib, add_denote, mulMon_denote,
             Nat.add_assoc, Nat.add_comm, Nat.add_left_comm,
             Nat.mul_assoc, Nat.mul_comm, Nat.mul_left_comm]","import Init.Data.Nat.Linear
import Init.Data.List.BasicAux
import Init.Data.Nat.SOM

open Nat
open SOM
open Poly
open Linear (Var hugeFuel Context Var.denote)
"
43359,Nat.SOM.Expr.toPoly_denote,theorem Nat.SOM.Expr.toPoly_denote (ctx : Context) (e : Expr) : e.toPoly.denote ctx = e.denote ctx := by sorry,"Denotation of Expression to Polynomial Conversion in Natural Numbers : For any context \( \text{ctx} \) of type `Nat.Linear.Context` and any expression \( e \) of type `Nat.SOM.Expr`, the denotation of the polynomial \( e.\text{toPoly} \) in the context \( \text{ctx} \) is equal to the denotation of the expression \( e \) in the same context, i.e., \(\text{denote}(\text{ctx}, e.\text{toPoly}) = \text{denote}(\text{ctx}, e)\).","theorem Nat.SOM.Expr.toPoly_denote (ctx : Context) (e : Expr) : e.toPoly.denote ctx = e.denote ctx := by
  induction e with
  | num k =>
    simp!; by_cases h : k == 0 <;> simp! [*]
    simp [eq_of_beq h]
  | var v => simp!
  | add a b => simp! [Poly.add_denote, *]
  | mul a b => simp! [Poly.mul_denote, *]","We perform induction on the structure of the expression \( e \).

1. **Case: \( e \) is a multiplication of two expressions \( a \) and \( b \):**
- We use the property that the denotation of the product of two polynomials is the product of their denotations. This simplifies the goal to showing that the denotation of the product of the polynomials \( a \) and \( b \) is equal to the product of the denotations of \( a \) and \( b \). By the induction hypothesis, we know that \(\text{denote}(\text{ctx}, a.\text{toPoly}) = \text{denote}(\text{ctx}, a)\) and \(\text{denote}(\text{ctx}, b.\text{toPoly}) = \text{denote}(\text{ctx}, b)\). Therefore, \(\text{denote}(\text{ctx}, (a \cdot b).\text{toPoly}) = \text{denote}(\text{ctx}, a.\text{toPoly}) \cdot \text{denote}(\text{ctx}, b.\text{toPoly}) = \text{denote}(\text{ctx}, a) \cdot \text{denote}(\text{ctx}, b) = \text{denote}(\text{ctx}, a \cdot b)\).

2. **Case: \( e \) is a natural number \( k \):**
- We need to show that the denotation of the polynomial corresponding to \( k \) is equal to the denotation of the expression \( k \).
- We consider two sub-cases:
- **Sub-case: \( k = 0 \):**
- We simplify the goal to show that the denotation of the polynomial corresponding to zero is zero. This is trivially true.
- **Sub-case: \( k \neq 0 \):**
- We simplify the goal to show that the denotation of the polynomial corresponding to \( k \) is \( k \). This is also trivially true.

3. **Case: \( e \) is a variable \( v \):**
- We simplify the goal to show that the denotation of the polynomial corresponding to \( v \) is equal to the denotation of the expression \( v \). This is trivially true.

4. **Case: \( e \) is the sum of two expressions \( a \) and \( b \):**
- We use the property that the denotation of the sum of two polynomials is the sum of their denotations. This simplifies the goal to showing that the denotation of the sum of the polynomials \( a \) and \( b \) is equal to the sum of the denotations of \( a \) and \( b \). By the induction hypothesis, we know that \(\text{denote}(\text{ctx}, a.\text{toPoly}) = \text{denote}(\text{ctx}, a)\) and \(\text{denote}(\text{ctx}, b.\text{toPoly}) = \text{denote}(\text{ctx}, b)\). Therefore, \(\text{denote}(\text{ctx}, (a + b).\text{toPoly}) = \text{denote}(\text{ctx}, a.\text{toPoly}) + \text{denote}(\text{ctx}, b.\text{toPoly}) = \text{denote}(\text{ctx}, a) + \text{denote}(\text{ctx}, b) = \text{denote}(\text{ctx}, a + b)\).

By considering all cases, we have shown that for any expression \( e \), the denotation of the polynomial \( e.\text{toPoly} \) in the context \( \text{ctx} \) is equal to the denotation of the expression \( e \) in the same context. This completes the proof. \(\blacksquare\)","theorem Nat.SOM.Expr.toPoly_denote (ctx : Context) (e : Expr) : e.toPoly.denote ctx = e.denote ctx := by
  induction e with
/- For the case where the expression is a natural number \( k \), we need to show that the denotation of the polynomial corresponding to \( k \) is equal to the denotation of the expression \( k \). -/
  | num k =>
/- We simplify the goal and consider two cases based on whether \( k \) is zero or not. In the first case, if \( k \) is zero, we simplify the goal to show that the denotation of the polynomial corresponding to zero is zero. In the second case, if \( k \) is not zero, we simplify the goal to show that the denotation of the polynomial corresponding to \( k \) is \( k \). -/
    simp!; by_cases h : k == 0 <;> simp! [*]
    simp [eq_of_beq h]
/- For the case where the expression is a variable \( v \), we simplify the goal to show that the denotation of the polynomial corresponding to \( v \) is equal to the denotation of the expression \( v \). -/
  | var v => simp!
/- For the case where the expression is the sum of two expressions \( a \) and \( b \), we use the property that the denotation of the sum of two polynomials is the sum of their denotations. This simplifies the goal to showing that the denotation of the sum of the polynomials \( a \) and \( b \) is equal to the sum of the denotations of \( a \) and \( b \). -/
  | add a b => simp! [Poly.add_denote, *]
/- For the case where the expression is a multiplication of two expressions \( a \) and \( b \), we use the property that the denotation of the product of two polynomials is the product of their denotations. This simplifies the goal to showing that the denotation of the product of the polynomials \( a \) and \( b \) is equal to the product of the denotations of \( a \) and \( b \). -/
/- For the case where the expression is the product of two expressions \( a \) and \( b \), we use the property that the denotation of the product of two polynomials is the product of their denotations. This simplifies the goal to showing that the denotation of the product of the polynomials \( a \) and \( b \) is equal to the product of the denotations of \( a \) and \( b \). -/
  | mul a b => simp! [Poly.mul_denote, *]","import Init.Data.Nat.Linear
import Init.Data.List.BasicAux
import Init.Data.Nat.SOM

open Nat
open SOM
open Expr
open Linear (Var hugeFuel Context Var.denote)
"
43385,Nat.SOM.Poly.denote_insertSorted,theorem Nat.SOM.Poly.denote_insertSorted (ctx : Context) (k : Nat) (m : Mon) (p : Poly) : (p.insertSorted k m).denote ctx = p.denote ctx + k * m.denote ctx := by sorry,"Evaluation of Inserted Monomial in Polynomial: \(\text{denote}(\text{ctx}, \text{insertSorted}(k, m, p)) = \text{denote}(\text{ctx}, p) + k \cdot \text{denote}(\text{ctx}, m)\) : For any context \( \text{ctx} \) of type `Nat.Linear.Context`, any natural number \( k \), any monomial \( m \) of type `Nat.SOM.Mon`, and any polynomial \( p \) of type `Nat.SOM.Poly`, the evaluation of the polynomial obtained by inserting the monomial \( (k, m) \) into \( p \) in a sorted manner is equal to the evaluation of \( p \) plus the product of \( k \) and the evaluation of \( m \) in the context \( \text{ctx} \). Mathematically, this can be expressed as:
\[
\text{denote}(\text{ctx}, \text{insertSorted}(k, m, p)) = \text{denote}(\text{ctx}, p) + k \cdot \text{denote}(\text{ctx}, m)
\]","theorem Nat.SOM.Poly.denote_insertSorted (ctx : Context) (k : Nat) (m : Mon) (p : Poly) : (p.insertSorted k m).denote ctx = p.denote ctx + k * m.denote ctx := by
  match p with
  | [] => simp!
  | (k', m') :: p =>
    by_cases h : m < m' <;> simp! [h, denote_insertSorted ctx k m p, Nat.add_assoc, Nat.add_comm, Nat.add_left_comm]","We need to show that for any context \( \text{ctx} \), any natural number \( k \), any monomial \( m \), and any polynomial \( p \), the evaluation of the polynomial obtained by inserting the monomial \( (k, m) \) into \( p \) in a sorted manner is equal to the evaluation of \( p \) plus the product of \( k \) and the evaluation of \( m \) in the context \( \text{ctx} \).

1. **Base Case:**
- If the polynomial \( p \) is empty, then the expression simplifies directly to the desired result. Specifically, the evaluation of the empty polynomial is \( 0 \), and the evaluation of the inserted monomial \( (k, m) \) is \( k \cdot \text{denote}(\text{ctx}, m) \). Therefore, we have:
\[
\text{denote}(\text{ctx}, \text{insertSorted}(k, m, [])) = k \cdot \text{denote}(\text{ctx}, m) = 0 + k \cdot \text{denote}(\text{ctx}, m)
\]
which is the desired result.

2. **Inductive Step:**
- If the polynomial \( p \) is non-empty and can be written as \( (k', m') :: p \), we proceed with the proof by considering two cases based on the comparison of \( m \) and \( m' \).

- **Case 1: \( m < m' \)**
- In this case, the monomial \( (k, m) \) is inserted before \( (k', m') \) in the sorted list. The evaluation of the polynomial \( \text{insertSorted}(k, m, (k', m') :: p) \) is:
\[
\text{denote}(\text{ctx}, (k, m) :: (k', m') :: p) = k \cdot \text{denote}(\text{ctx}, m) + \text{denote}(\text{ctx}, (k', m') :: p)
\]
By the inductive hypothesis, we have:
\[
\text{denote}(\text{ctx}, (k', m') :: p) = \text{denote}(\text{ctx}, p) + k' \cdot \text{denote}(\text{ctx}, m')
\]
Therefore, the evaluation of the inserted polynomial is:
\[
k \cdot \text{denote}(\text{ctx}, m) + \text{denote}(\text{ctx}, p) + k' \cdot \text{denote}(\text{ctx}, m')
\]
which is equal to:
\[
\text{denote}(\text{ctx}, p) + k \cdot \text{denote}(\text{ctx}, m)
\]
as required.

- **Case 2: \( m \ge m' \)**
- In this case, the monomial \( (k, m) \) is inserted after \( (k', m') \) in the sorted list. The evaluation of the polynomial \( \text{insertSorted}(k, m, (k', m') :: p) \) is:
\[
\text{denote}(\text{ctx}, (k', m') :: \text{insertSorted}(k, m, p)) = k' \cdot \text{denote}(\text{ctx}, m') + \text{denote}(\text{ctx}, \text{insertSorted}(k, m, p))
\]
By the inductive hypothesis, we have:
\[
\text{denote}(\text{ctx}, \text{insertSorted}(k, m, p)) = \text{denote}(\text{ctx}, p) + k \cdot \text{denote}(\text{ctx}, m)
\]
Therefore, the evaluation of the inserted polynomial is:
\[
k' \cdot \text{denote}(\text{ctx}, m') + \text{denote}(\text{ctx}, p) + k \cdot \text{denote}(\text{ctx}, m)
\]
which is equal to:
\[
\text{denote}(\text{ctx}, p) + k \cdot \text{denote}(\text{ctx}, m)
\]
as required.

In both cases, the desired result holds. Therefore, the theorem is proved. \(\blacksquare\)","theorem Nat.SOM.Poly.denote_insertSorted (ctx : Context) (k : Nat) (m : Mon) (p : Poly) : (p.insertSorted k m).denote ctx = p.denote ctx + k * m.denote ctx := by
  match p with
/- If the polynomial \( p \) is empty, then the expression simplifies directly to the desired result. -/
  | [] => simp!
/- If the polynomial \( p \) is non-empty and can be written as \( (k', m') :: p \), we proceed with the proof. -/
  | (k', m') :: p =>
/- Consider two cases: (1) Assume \( m < m' \), and (2) Assume \( m \ge m' \). In both cases, we simplify the expression using the properties of addition and the definition of `denote_insertSorted`. -/
/- Consider two cases: (1) Assume \( m < m' \), and (2) Assume \( m \ge m' \). In both cases, we simplify the expression using the properties of addition and the definition of `denote_insertSorted`. -/
    by_cases h : m < m' <;> simp! [h, denote_insertSorted ctx k m p, Nat.add_assoc, Nat.add_comm, Nat.add_left_comm]","import Init.Data.Nat.Linear
import Init.Data.List.BasicAux
import Init.Data.Nat.SOM

open Nat
open SOM
open Poly
open Linear (Var hugeFuel Context Var.denote)
"
44027,BitVec.toNat_ne,theorem BitVec.toNat_ne (x y : BitVec n) : x ≠ y ↔ x.toNat ≠ y.toNat := by sorry,"Bitvector Inequality via Underlying Natural Number: \( x \neq y \leftrightarrow x.\text{toNat} \neq y.\text{toNat} \) : For any natural number \( n \) and any bitvectors \( x \) and \( y \) of length \( n \), \( x \) is not equal to \( y \) if and only if their underlying natural numbers \( x.\text{toNat} \) and \( y.\text{toNat} \) are not equal, i.e., \( x \neq y \leftrightarrow x.\text{toNat} \neq y.\text{toNat} \).","theorem BitVec.toNat_ne (x y : BitVec n) : x ≠ y ↔ x.toNat ≠ y.toNat := by
  rw [Ne, toNat_eq]","To prove the theorem, we start by using the definition of inequality. The inequality \( x \neq y \) is defined as \( \neg (x = y) \). Next, we use the theorem that states \( x = y \) if and only if \( x.\text{toNat} = y.\text{toNat} \). Therefore, the goal \( x \neq y \leftrightarrow x.\text{toNat} \neq y.\text{toNat} \) is equivalent to \( \neg (x = y) \leftrightarrow \neg (x.\text{toNat} = y.\text{toNat}) \). This simplifies to \( x \neq y \leftrightarrow x.\text{toNat} \neq y.\text{toNat} \). Hence, the theorem is proved.","theorem BitVec.toNat_ne (x y : BitVec n) : x ≠ y ↔ x.toNat ≠ y.toNat := by
/- First, we use the definition of inequality to rewrite the goal. The inequality \( x \neq y \) is equivalent to \( \neg (x = y) \). Then, we use the theorem that states \( x = y \) if and only if \( x.\text{toNat} = y.\text{toNat} \). Therefore, the goal \( x \neq y \leftrightarrow x.\text{toNat} \neq y.\text{toNat} \) is equivalent to \( \neg (x = y) \leftrightarrow \neg (x.\text{toNat} = y.\text{toNat}) \). This simplifies to \( x \neq y \leftrightarrow x.\text{toNat} \neq y.\text{toNat} \). -/
  rw [Ne, toNat_eq]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44028,BitVec.ofFin_eq_ofNat,theorem BitVec.ofFin_eq_ofNat : @BitVec.ofFin w (Fin.mk x lt) = BitVec.ofNat w x := by sorry,"Bitvector from Canonical Type Element Equals Bitvector from Natural Number Representation : For any natural numbers \( w \) and \( x \) such that \( x < 2^w \), the bitvector of width \( w \) constructed from the canonical type element \( x \) (i.e., \( \text{Fin}(2^w) \)) is equal to the bitvector of width \( w \) constructed from the natural number \( x \). In other words, if \( x \) is less than \( 2^w \), then \( \text{BitVec.ofFin}(x) = \text{BitVec.ofNat}(w, x) \).","theorem BitVec.ofFin_eq_ofNat : @BitVec.ofFin w (Fin.mk x lt) = BitVec.ofNat w x := by
  simp only [BitVec.ofNat, Fin.ofNat', lt, Nat.mod_eq_of_lt]","To prove the theorem, we start with the given natural numbers \( w \) and \( x \) such that \( x < 2^w \). We need to show that the bitvector of width \( w \) constructed from the canonical type element \( x \) (i.e., \( \text{Fin}(2^w) \)) is equal to the bitvector of width \( w \) constructed from the natural number \( x \).

Using the definitions of `BitVec.ofNat` and `Fin.ofNat'`, along with the assumption \( x < 2^w \) and the property that for any natural numbers \( a \) and \( b \), if \( a < b \), then \( a \% b = a \), we can simplify the proposition we want to show. Specifically, we need to show that the bitvector of width \( w \) constructed from the canonical type element \( x \) (i.e., \( \text{Fin}(2^w) \)) is equal to the bitvector of width \( w \) constructed from the natural number \( x \). This simplification directly results in the equality \( \text{BitVec.ofFin}(x) = \text{BitVec.ofNat}(w, x) \).

Thus, the theorem is proved. \(\blacksquare\)","theorem BitVec.ofFin_eq_ofNat : @BitVec.ofFin w (Fin.mk x lt) = BitVec.ofNat w x := by
/- Using the definitions of `BitVec.ofNat`, `Fin.ofNat'`, the assumption \( x < 2^w \), and the property that for any natural numbers \( a \) and \( b \), if \( a < b \), then \( a \% b = a \), we can simplify the proposition we want to show. Specifically, we need to show that the bitvector of width \( w \) constructed from the canonical type element \( x \) (i.e., \( \text{Fin}(2^w) \)) is equal to the bitvector of width \( w \) constructed from the natural number \( x \). This simplification directly results in the equality \( \text{BitVec.ofFin}(x) = \text{BitVec.ofNat}(w, x) \). -/
  simp only [BitVec.ofNat, Fin.ofNat', lt, Nat.mod_eq_of_lt]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44033,BitVec.msb_zero_length,theorem BitVec.msb_zero_length (x : BitVec 0) : x.msb = false := by sorry,"Most Significant Bit of Zero-Length Bitvector is False : For any bitvector \( x \) of length 0, the most significant bit of \( x \) is `false`, i.e., \( x.\text{msb} = \text{false} \).","theorem BitVec.msb_zero_length (x : BitVec 0) : x.msb = false := by
  simp [BitVec.msb, of_length_zero]","To prove that the most significant bit (msb) of any bitvector \( x \) of length 0 is `false`, we start by using the definition of the most significant bit and the fact that any bitvector of width 0 is equal to the bitvector \( 0\#0 \). Specifically, for any bitvector \( x \) of width 0, we have \( x = 0\#0 \). Since \( 0\#0 \) has no bits, its most significant bit is trivially `false`. Therefore, \( x.\text{msb} = \text{false} \). This completes the proof.","theorem BitVec.msb_zero_length (x : BitVec 0) : x.msb = false := by
  simp [BitVec.msb, of_length_zero]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44034,BitVec.toNat_zero,theorem BitVec.toNat_zero (n : Nat) : (0#n).toNat = 0 := by sorry,"Underlying Natural Number of Zero Bitvector is Zero : For any natural number \( n \), the underlying natural number of the bitvector \( 0^n \) (a bitvector of width \( n \) with all bits set to 0) is 0, i.e., \((0^n).toNat = 0\).","theorem BitVec.toNat_zero (n : Nat) : (0#n).toNat = 0 := by
  trivial","To prove that the underlying natural number of the bitvector \(0^n\) is 0, we note that \(0^n\) is a bitvector of width \( n \) with all bits set to 0. By the definition of the `toNat` function for bitvectors, the natural number representation of a bitvector with all bits set to 0 is 0. Therefore, \((0^n).toNat = 0\). This completes the proof.","theorem BitVec.toNat_zero (n : Nat) : (0#n).toNat = 0 := by
  trivial","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44048,BitVec.toNat_ofBool,theorem BitVec.toNat_ofBool (b : Bool) : (ofBool b).toNat = b.toNat := by sorry,"Natural Number Conversion Consistency for Boolean to Bitvector : For any boolean value \( b \), the natural number obtained by converting the bitvector of length 1 generated from \( b \) to a natural number is equal to the natural number obtained by directly converting \( b \) to a natural number. Specifically, if \( b \) is `true`, both conversions yield \( 1 \); if \( b \) is `false`, both conversions yield \( 0 \).","theorem BitVec.toNat_ofBool (b : Bool) : (ofBool b).toNat = b.toNat := by
  cases b <;> rfl","We will consider every possible case of the boolean value \( b \).

1. **Case 1: \( b = \text{false} \)**
- The bitvector of length 1 generated from \( \text{false} \) is \(\text{ofBool } \text{false}\).
- Converting this bitvector to a natural number gives \((\text{ofBool } \text{false}).\text{toNat}\).
- Directly converting \( \text{false} \) to a natural number gives \(\text{false}.\text{toNat}\).
- Both sides are definitionally equal to \( 0 \), so the equality \((\text{ofBool } \text{false}).\text{toNat} = \text{false}.\text{toNat}\) holds.

2. **Case 2: \( b = \text{true} \)**
- The bitvector of length 1 generated from \( \text{true} \) is \(\text{ofBool } \text{true}\).
- Converting this bitvector to a natural number gives \((\text{ofBool } \text{true}).\text{toNat}\).
- Directly converting \( \text{true} \) to a natural number gives \(\text{true}.\text{toNat}\).
- Both sides are definitionally equal to \( 1 \), so the equality \((\text{ofBool } \text{true}).\text{toNat} = \text{true}.\text{toNat}\) holds.

Since both cases are covered and the equalities hold in each case, the theorem is proved. \(\blacksquare\)","theorem BitVec.toNat_ofBool (b : Bool) : (ofBool b).toNat = b.toNat := by
/- We will consider every possible case of the boolean value \( b \). Specifically, we have two cases: \( b = \text{false} \) and \( b = \text{true} \). -/
/- For the case \( b = \text{false} \), the equality \((\text{ofBool } \text{false}).\text{toNat} = \text{false}.\text{toNat}\) holds trivially because both sides are definitionally equal to \( 0 \). -/
/- For the case \( b = \text{true} \), the equality \((\text{ofBool } \text{true}).\text{toNat} = \text{true}.\text{toNat}\) holds trivially because both sides are definitionally equal to \( 1 \). -/
  cases b <;> rfl","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44050,BitVec.msb_ofBool,theorem BitVec.msb_ofBool (b : Bool) : (ofBool b).msb = b := by sorry,"Most Significant Bit of Boolean to Bitvector Conversion Equals the Boolean Value : For any boolean value \( b \), the most significant bit of the bitvector of length 1 generated from \( b \) is equal to \( b \). Specifically, if \( b \) is `true`, the most significant bit of the bitvector `1` is `true`; if \( b \) is `false`, the most significant bit of the bitvector `0` is `false`.","theorem BitVec.msb_ofBool (b : Bool) : (ofBool b).msb = b := by
  cases b <;> simp [BitVec.msb]","We will consider every possible case of the boolean value \( b \).

1. **Case 1: \( b = \text{false} \)**
- We need to show that \((\text{ofBool} \, \text{false}).\text{msb} = \text{false}\).
- By the definition of the function \(\text{ofBool}\), \(\text{ofBool} \, \text{false} = 0\).
- The most significant bit of the bitvector `0` is `false`.
- Therefore, \((\text{ofBool} \, \text{false}).\text{msb} = \text{false}\).

2. **Case 2: \( b = \text{true} \)**
- We need to show that \((\text{ofBool} \, \text{true}).\text{msb} = \text{true}\).
- By the definition of the function \(\text{ofBool}\), \(\text{ofBool} \, \text{true} = 1\).
- The most significant bit of the bitvector `1` is `true`.
- Therefore, \((\text{ofBool} \, \text{true}).\text{msb} = \text{true}\).

Since both cases are true, the theorem is proved.","theorem BitVec.msb_ofBool (b : Bool) : (ofBool b).msb = b := by
/- We will consider every possible case of the boolean value \( b \). Specifically, we will consider the cases where \( b \) is `false` and where \( b \) is `true`. -/
/- We will discuss every possible case of \( b \). Case 1: \( b = \text{false} \). Case 2: \( b = \text{true} \). -/
/- First, we apply the case analysis to the current goal, which splits the goal into two subgoals: one for \( b = \text{false} \) and one for \( b = \text{true} \). Then, for each of these subgoals, we simplify the proposition we want to show using the definition of the most significant bit of a bitvector. -/
/- For the case \( b = \text{false} \), we use the definition of the most significant bit of a bitvector to simplify the proposition \((\text{ofBool} \, \text{false}).\text{msb} = \text{false}\). Since \(\text{ofBool} \, \text{false} = 0\), and the most significant bit of the bitvector `0` is `false`, the proposition simplifies to \(\text{false} = \text{false}\), which is true. -/
/- For the case \( b = \text{true} \), we use the definition of the most significant bit of a bitvector to simplify the proposition \((\text{ofBool} \, \text{true}).\text{msb} = \text{true}\). Since \(\text{ofBool} \, \text{true} = 1\), and the most significant bit of the bitvector `1` is `true`, the proposition simplifies to \(\text{true} = \text{true}\), which is true. -/
  cases b <;> simp [BitVec.msb]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44052,BitVec.ofBool_eq_iff_eq,"theorem BitVec.ofBool_eq_iff_eq : ∀(b b' : Bool), BitVec.ofBool b = BitVec.ofBool b' ↔ b = b' := by sorry","Bitvector Representation of Boolean Values is Injective: \(\text{BitVec.ofBool}(b) = \text{BitVec.ofBool}(b') \leftrightarrow b = b'\) : For any boolean values \( b \) and \( b' \), the bitvector representation of \( b \) is equal to the bitvector representation of \( b' \) if and only if \( b \) is equal to \( b' \). In other words, \( \text{BitVec.ofBool}(b) = \text{BitVec.ofBool}(b') \) if and only if \( b = b' \).","theorem BitVec.ofBool_eq_iff_eq : ∀(b b' : Bool), BitVec.ofBool b = BitVec.ofBool b' ↔ b = b' := by
  decide","To prove the theorem, we use the decidability of the equality of boolean values. Specifically, we need to show that \( \text{BitVec.ofBool}(b) = \text{BitVec.ofBool}(b') \) if and only if \( b = b' \).

1. **(\(\Rightarrow\)) Assume \( \text{BitVec.ofBool}(b) = \text{BitVec.ofBool}(b') \):**
- If \( b = \text{true} \), then \( \text{BitVec.ofBool}(b) = 1 \).
- If \( b' = \text{true} \), then \( \text{BitVec.ofBool}(b') = 1 \).
- If \( b = \text{false} \), then \( \text{BitVec.ofBool}(b) = 0 \).
- If \( b' = \text{false} \), then \( \text{BitVec.ofBool}(b') = 0 \).
- Therefore, if \( \text{BitVec.ofBool}(b) = \text{BitVec.ofBool}(b') \), it must be that \( b = b' \).

2. **(\(\Leftarrow\)) Assume \( b = b' \):**
- If \( b = b' = \text{true} \), then \( \text{BitVec.ofBool}(b) = 1 \) and \( \text{BitVec.ofBool}(b') = 1 \), so \( \text{BitVec.ofBool}(b) = \text{BitVec.ofBool}(b') \).
- If \( b = b' = \text{false} \), then \( \text{BitVec.ofBool}(b) = 0 \) and \( \text{BitVec.ofBool}(b') = 0 \), so \( \text{BitVec.ofBool}(b) = \text{BitVec.ofBool}(b') \).

Since both directions are proven, we conclude that \( \text{BitVec.ofBool}(b) = \text{BitVec.ofBool}(b') \) if and only if \( b = b' \). This completes the proof.","theorem BitVec.ofBool_eq_iff_eq : ∀(b b' : Bool), BitVec.ofBool b = BitVec.ofBool b' ↔ b = b' := by
/- We use the decidability of the equality of boolean values to directly conclude that the bitvector representation of \( b \) is equal to the bitvector representation of \( b' \) if and only if \( b \) is equal to \( b' \). -/
  decide","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44054,BitVec.toNat_ofNat,theorem BitVec.toNat_ofNat (x w : Nat) : (BitVec.ofNat w x).toNat = x % 2^w := by sorry,"Underlying Natural Number of Bitvector from Natural Number Modulo \( 2^w \) : For any natural numbers \( x \) and \( w \), the underlying natural number of the bitvector `BitVec.ofNat w x` is equal to \( x \mod 2^w \), i.e., \((\text{BitVec.ofNat } w \, x).toNat = x \mod 2^w\).","theorem BitVec.toNat_ofNat (x w : Nat) : (BitVec.ofNat w x).toNat = x % 2^w := by
  simp [BitVec.toNat, BitVec.ofNat, Fin.ofNat']","To prove the theorem, we start by using the definitions of the functions involved. Specifically, we use the definitions of `BitVec.toNat`, `BitVec.ofNat`, and `Fin.ofNat'`.

1. **Definition of `BitVec.ofNat`:**
- The function `BitVec.ofNat w x` constructs a bitvector of width \( w \) from the natural number \( x \). This bitvector is represented as a natural number \( x \) reduced modulo \( 2^w \).

2. **Definition of `BitVec.toNat`:**
- The function `BitVec.toNat` extracts the underlying natural number from a bitvector. For a bitvector of width \( w \) constructed from \( x \), this underlying natural number is \( x \mod 2^w \).

3. **Definition of `Fin.ofNat'`:**
- The function `Fin.ofNat'` ensures that the natural number \( x \) is reduced modulo \( 2^w \) when constructing the bitvector. This means that the bitvector is effectively \( x \mod 2^w \).

By combining these definitions, we see that the underlying natural number of the bitvector \(\text{BitVec.ofNat } w \, x\) is exactly \( x \mod 2^w \). Therefore, the proposition \((\text{BitVec.ofNat } w \, x).toNat = x \mod 2^w\) holds true.

This completes the proof. \(\blacksquare\)","theorem BitVec.toNat_ofNat (x w : Nat) : (BitVec.ofNat w x).toNat = x % 2^w := by
/- Using the definitions of `BitVec.toNat`, `BitVec.ofNat`, and `Fin.ofNat'`, we can simplify the proposition we want to show, which is \((\text{BitVec.ofNat } w \, x).toNat = x \mod 2^w\), to a trivially true statement. Specifically, the definition of `BitVec.ofNat` constructs a bitvector of width \( w \) from the natural number \( x \), and the definition of `BitVec.toNat` extracts the underlying natural number from this bitvector. The definition of `Fin.ofNat'` ensures that the natural number \( x \) is reduced modulo \( 2^w \) when constructing the bitvector. Therefore, the underlying natural number of the bitvector is exactly \( x \mod 2^w \). -/
  simp [BitVec.toNat, BitVec.ofNat, Fin.ofNat']","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44055,BitVec.toInt_ne,theorem BitVec.toInt_ne (x y : BitVec n) : x.toInt ≠ y.toInt ↔ x ≠ y := by sorry,"Bitvector to Integer Conversion is Injective: \( x.\text{toInt} \neq y.\text{toInt} \leftrightarrow x \neq y \) : For any natural number \( n \) and any bitvectors \( x \) and \( y \) of length \( n \), the integers \( x.\text{toInt} \) and \( y.\text{toInt} \) are not equal if and only if the bitvectors \( x \) and \( y \) are not equal, i.e., \( x.\text{toInt} \neq y.\text{toInt} \leftrightarrow x \neq y \).","theorem BitVec.toInt_ne (x y : BitVec n) : x.toInt ≠ y.toInt ↔ x ≠ y := by
  rw [Ne, toInt_inj]","To prove the theorem, we start by using the definition of inequality. The statement \( x.\text{toInt} \neq y.\text{toInt} \) is equivalent to \( \neg (x.\text{toInt} = y.\text{toInt}) \). Next, we use the injectivity of the bitvector to integer conversion, which states that \( x.\text{toInt} = y.\text{toInt} \) if and only if \( x = y \). Therefore, the goal \( \neg (x.\text{toInt} = y.\text{toInt}) \) is equivalent to \( \neg (x = y) \), which is the same as \( x \neq y \). This completes the proof.","theorem BitVec.toInt_ne (x y : BitVec n) : x.toInt ≠ y.toInt ↔ x ≠ y := by
/- First, we use the definition of inequality to rewrite the goal. The statement \( x.\text{toInt} \neq y.\text{toInt} \) is equivalent to \( \neg (x.\text{toInt} = y.\text{toInt}) \). Next, we use the injectivity of the bitvector to integer conversion, which states that \( x.\text{toInt} = y.\text{toInt} \) if and only if \( x = y \). Therefore, the goal \( \neg (x.\text{toInt} = y.\text{toInt}) \) is equivalent to \( \neg (x = y) \), which is the same as \( x \neq y \). -/
  rw [Ne, toInt_inj]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44056,BitVec.msb_eq_true_iff_two_mul_ge,theorem BitVec.msb_eq_true_iff_two_mul_ge (x : BitVec w) : x.msb = true ↔ 2 * x.toNat ≥ 2^w := by sorry,"Most Significant Bit is True if and only if \( 2 \times \text{val}(x) \ge 2^w \) : For any bitvector \( x \) of length \( w \), the most significant bit of \( x \) is true if and only if \( 2 \times \text{val}(x) \ge 2^w \), where \(\text{val}(x)\) is the underlying natural number representation of \( x \).","theorem BitVec.msb_eq_true_iff_two_mul_ge (x : BitVec w) : x.msb = true ↔ 2 * x.toNat ≥ 2^w := by
  simp [← Bool.ne_false_iff, msb_eq_false_iff_two_mul_lt]","To prove the theorem, we start by using the equivalence that a boolean value is true if and only if it is not false. Additionally, we use the fact that the most significant bit of a bitvector \( x \) is false if and only if \( 2 \times \text{val}(x) < 2^w \).

By combining these equivalences, we can simplify the proposition we want to show. Specifically, the most significant bit of \( x \) is true if and only if it is not false. Since the most significant bit of \( x \) is false if and only if \( 2 \times \text{val}(x) < 2^w \), it follows that the most significant bit of \( x \) is true if and only if \( 2 \times \text{val}(x) \ge 2^w \).

Thus, we have shown that the most significant bit of \( x \) is true if and only if \( 2 \times \text{val}(x) \ge 2^w \). This completes the proof.","theorem BitVec.msb_eq_true_iff_two_mul_ge (x : BitVec w) : x.msb = true ↔ 2 * x.toNat ≥ 2^w := by
/- Using the equivalence that a boolean value is true if and only if it is not false, and the fact that the most significant bit of a bitvector \( x \) is false if and only if \( 2 \times \text{val}(x) < 2^w \), we can simplify the proposition we want to show. This simplification reduces the goal to proving that the most significant bit of \( x \) is true if and only if \( 2 \times \text{val}(x) \ge 2^w \). -/
  simp [← Bool.ne_false_iff, msb_eq_false_iff_two_mul_lt]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44058,BitVec.toInt_ofNat,"theorem BitVec.toInt_ofNat {n : Nat} (x : Nat) :
  (BitVec.ofNat n x).toInt = (x : Int).bmod (2^n) := by sorry","Bitvector to Integer Conversion of Natural Number in Two's Complement Form : For any natural number \( n \) and any natural number \( x \), the integer representation of the bitvector `BitVec.ofNat n x` is equal to the balanced modulus of \( x \) with respect to \( 2^n \), i.e., \((\text{BitVec.ofNat } n \, x). \text{toInt} = x \bmod 2^n\).","theorem BitVec.toInt_ofNat {n : Nat} (x : Nat) :
  (BitVec.ofNat n x).toInt = (x : Int).bmod (2^n) := by
  simp [toInt_eq_toNat_bmod]","To prove the theorem, we start by using the theorem that the integer representation of a bitvector \( x \) of length \( n \) is equal to the balanced modulus of the natural number representation of \( x \) with respect to \( 2^n \). Formally, this theorem states that for any bitvector \( x \) of length \( n \), \((\text{BitVec.ofNat } n \, x). \text{toInt} = (x \mod 2^n)\).

Given this theorem, we can directly simplify our goal. We need to show that \((\text{BitVec.ofNat } n \, x). \text{toInt} = (x \mod 2^n)\). By the theorem, this is true by definition. Therefore, the integer representation of the bitvector \(\text{BitVec.ofNat } n \, x\) is indeed equal to the balanced modulus of \( x \) with respect to \( 2^n \).

This completes the proof.","theorem BitVec.toInt_ofNat {n : Nat} (x : Nat) :
  (BitVec.ofNat n x).toInt = (x : Int).bmod (2^n) := by
/- Using the theorem that the integer representation of a bitvector \( x \) of length \( n \) is equal to the balanced modulus of the natural number representation of \( x \) with respect to \( 2^n \), we can simplify the goal. Specifically, we need to show that \((\text{BitVec.ofNat } n \, x). \text{toInt} = (x \mod 2^n)\). By the theorem, this is equivalent to showing that \((\text{BitVec.ofNat } n \, x). \text{toInt} = (x \mod 2^n)\), which is true by definition. -/
  simp [toInt_eq_toNat_bmod]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44063,BitVec.nat_eq_toNat,"theorem BitVec.nat_eq_toNat (x : BitVec w) (y : Nat)
  : (y = x.toNat) ↔ (y < 2^w ∧ (x = BitVec.ofNat w y)) := by sorry","Natural Number to Bitvector Conversion Equivalence: \( y = x.\text{toNat} \leftrightarrow y < 2^w \land x = \text{BitVec.ofNat}(w, y) \) : For any natural number \( w \) and any bitvector \( x \) of width \( w \), the natural number \( y \) is equal to the underlying natural number of \( x \), denoted as \( x.\text{toNat} \), if and only if \( y \) is less than \( 2^w \) and \( x \) is the bitvector representation of \( y \) in width \( w \). In other words, \( y = x.\text{toNat} \) if and only if \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \).","theorem BitVec.nat_eq_toNat (x : BitVec w) (y : Nat)
  : (y = x.toNat) ↔ (y < 2^w ∧ (x = BitVec.ofNat w y)) := by
  rw [@eq_comm _ _ x.toNat]
  apply toNat_eq_nat","We start by using the symmetry of equality to rewrite the goal \( y = x.\text{toNat} \) as \( x.\text{toNat} = y \). Therefore, the goal is to show that \( x.\text{toNat} = y \) if and only if \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \).

To prove this, we use the theorem that states \( x.\text{toNat} = y \) if and only if \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \). This theorem directly matches our goal, so the proof is complete.

\(\blacksquare\)","theorem BitVec.nat_eq_toNat (x : BitVec w) (y : Nat)
  : (y = x.toNat) ↔ (y < 2^w ∧ (x = BitVec.ofNat w y)) := by
/- Using the symmetry of equality, we can rewrite the goal \( y = x.\text{toNat} \) as \( x.\text{toNat} = y \). Therefore, the goal is now to show that \( x.\text{toNat} = y \) if and only if \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \). -/
  rw [@eq_comm _ _ x.toNat]
/- To prove the current goal, we use the theorem that states \( x.\text{toNat} = y \) if and only if \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \). This theorem directly matches our goal, so the proof is complete. -/
  apply toNat_eq_nat","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44064,BitVec.toNat_ofInt,"theorem BitVec.toNat_ofInt {n : Nat} (i : Int) :
  (BitVec.ofInt n i).toNat = (i % (2^n : Nat)).toNat := by sorry","Bitvector to Natural Number Conversion of Integer Modulo \( 2^n \) : For any natural number \( n \) and any integer \( i \), the natural number representation of the bitvector `BitVec.ofInt n i` is equal to the natural number representation of \( i \) modulo \( 2^n \), i.e., \((\text{BitVec.ofInt } n \, i). \text{toNat} = (i \bmod 2^n). \text{toNat}\).","theorem BitVec.toNat_ofInt {n : Nat} (i : Int) :
  (BitVec.ofInt n i).toNat = (i % (2^n : Nat)).toNat := by
  unfold BitVec.ofInt
  simp","We start by expanding the definition of `BitVec.ofInt`. The function `BitVec.ofInt n i` maps an integer \( i \) to a bitvector of width \( n \) by taking \( i \) modulo \( 2^n \) and converting the result to a natural number, which is then interpreted as a bitvector of width \( n \). Therefore, the goal is to show:
\[
((i \bmod 2^n). \text{toNat}). \text{toNat} = (i \bmod 2^n). \text{toNat}
\]

Next, we simplify the left-hand side of the equation. The `toNat` function applied to a natural number is the natural number itself. Hence, \(((i \bmod 2^n). \text{toNat}). \text{toNat}\) simplifies to \((i \bmod 2^n). \text{toNat}\). This reduces the equation to:
\[
(i \bmod 2^n). \text{toNat} = (i \bmod 2^n). \text{toNat}
\]
This is trivially true, as both sides of the equation are identical. Therefore, the theorem is proved. \(\blacksquare\)","theorem BitVec.toNat_ofInt {n : Nat} (i : Int) :
  (BitVec.ofInt n i).toNat = (i % (2^n : Nat)).toNat := by
/- First, we expand the definition of `BitVec.ofInt`. The function `BitVec.ofInt n i` maps an integer \( i \) to a bitvector of width \( n \) by taking \( i \) modulo \( 2^n \) and converting the result to a natural number, which is then interpreted as a bitvector of width \( n \). Therefore, the goal becomes:
\[
((i \bmod 2^n). \text{toNat}). \text{toNat} = (i \bmod 2^n). \text{toNat}
\] -/
  unfold BitVec.ofInt
/- Next, we simplify the expression. The left-hand side of the equation is \(((i \bmod 2^n). \text{toNat}). \text{toNat}\), which is equivalent to \((i \bmod 2^n). \text{toNat}\) because the `toNat` function applied to a natural number is the natural number itself. Therefore, the equation simplifies to:
\[
(i \bmod 2^n). \text{toNat} = (i \bmod 2^n). \text{toNat}
\]
This is trivially true, as both sides of the equation are identical. -/
  simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44066,BitVec.ofNat_toNat,theorem BitVec.ofNat_toNat (m : Nat) (x : BitVec n) : BitVec.ofNat m x.toNat = truncate m x := by sorry,"Bitvector Conversion and Truncation Equivalence: \( \text{BitVec.ofNat}(m, x.\text{toNat}) = \text{BitVec.truncate}(m, x) \) : For any natural number \( n \) and any bitvector \( x \) of width \( n \), the bitvector obtained by converting the underlying natural number of \( x \) to a bitvector of width \( m \) is equal to the bitvector obtained by truncating \( x \) to width \( m \). In other words, for any \( m \) and \( x \), \( \text{BitVec.ofNat}(m, x.\text{toNat}) = \text{BitVec.truncate}(m, x) \).","theorem BitVec.ofNat_toNat (m : Nat) (x : BitVec n) : BitVec.ofNat m x.toNat = truncate m x := by
  apply eq_of_toNat_eq
  simp","To prove that \(\text{BitVec.ofNat}(m, x.\text{toNat}) = \text{BitVec.truncate}(m, x)\), it suffices to show that the natural number representation of \(\text{BitVec.ofNat}(m, x.\text{toNat})\) is equal to the natural number representation of \(\text{BitVec.truncate}(m, x)\). This is because if the natural number representations of two bitvectors are equal, then the bitvectors themselves are equal.

Using the properties of bitvector operations, we can simplify the proposition we want to show. Specifically, we use the fact that the natural number representation of \(\text{BitVec.ofNat}(m, x.\text{toNat})\) is equal to \(x.\text{toNat} \mod 2^m\) and the natural number representation of \(\text{BitVec.truncate}(m, x)\) is also equal to \(x.\text{toNat} \mod 2^m\). Therefore, the natural number representations of \(\text{BitVec.ofNat}(m, x.\text{toNat})\) and \(\text{BitVec.truncate}(m, x)\) are equal, which completes the proof.","theorem BitVec.ofNat_toNat (m : Nat) (x : BitVec n) : BitVec.ofNat m x.toNat = truncate m x := by
/- To prove that \(\text{BitVec.ofNat}(m, x.\text{toNat}) = \text{BitVec.truncate}(m, x)\), it suffices to show that the natural number representation of \(\text{BitVec.ofNat}(m, x.\text{toNat})\) is equal to the natural number representation of \(\text{BitVec.truncate}(m, x)\). This is because if the natural number representations of two bitvectors are equal, then the bitvectors themselves are equal. -/
  apply eq_of_toNat_eq
/- Using the properties of bitvector operations, we can simplify the proposition we want to show. Specifically, we use the fact that the natural number representation of \(\text{BitVec.ofNat}(m, x.\text{toNat})\) is equal to \(x.\text{toNat} \mod 2^m\) and the natural number representation of \(\text{BitVec.truncate}(m, x)\) is also equal to \(x.\text{toNat} \mod 2^m\). Therefore, the natural number representations of \(\text{BitVec.ofNat}(m, x.\text{toNat})\) and \(\text{BitVec.truncate}(m, x)\) are equal, which completes the proof. -/
  simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44067,BitVec.zeroExtend_eq,theorem BitVec.zeroExtend_eq (x : BitVec n) : zeroExtend n x = x := by sorry,"Zero Extension of Bitvector to Same Length Equals Original Bitvector : For any natural number \( n \) and any bitvector \( x \) of length \( n \), the zero extension of \( x \) to a bitvector of the same length \( n \) is equal to \( x \). In other words, \( \text{zeroExtend}(n, x) = x \).","theorem BitVec.zeroExtend_eq (x : BitVec n) : zeroExtend n x = x := by
  apply eq_of_toNat_eq
  let ⟨x, lt_n⟩ := x
  simp [truncate, zeroExtend]","To prove that the zero extension of a bitvector \( x \) of length \( n \) to the same length \( n \) is equal to \( x \), it suffices to show that the natural number representation of the zero extension of \( x \) is equal to the natural number representation of \( x \). That is, we need to show that \((\text{zeroExtend}(n, x)).\text{toNat} = x.\text{toNat}\).

We construct the bitvector \( x \) as a pair \((x, \text{lt}_n)\), where \( x \) is a natural number and \(\text{lt}_n\) is a proof that \( x < 2^n \). This allows us to work with the natural number representation of \( x \) directly.

Using the definitions of the `truncate` and `zeroExtend` functions, we can simplify the proposition we want to show. Specifically, the zero extension of a bitvector \( x \) of length \( n \) to the same length \( n \) is simply \( x \) itself, and the natural number representation of \( x \) remains unchanged. Therefore, \((\text{zeroExtend}(n, x)).\text{toNat} = x.\text{toNat}\) holds trivially.

Thus, we have shown that \(\text{zeroExtend}(n, x) = x\). This completes the proof. \(\blacksquare\)","theorem BitVec.zeroExtend_eq (x : BitVec n) : zeroExtend n x = x := by
/- To prove that the zero extension of a bitvector \( x \) of length \( n \) to the same length \( n \) is equal to \( x \), it suffices to show that the natural number representation of the zero extension of \( x \) is equal to the natural number representation of \( x \). In other words, we need to show that \((\text{zeroExtend}(n, x)).\text{toNat} = x.\text{toNat}\). -/
  apply eq_of_toNat_eq
/- Now we construct the bitvector \( x \) as a pair \((x, \text{lt}_n)\), where \( x \) is a natural number and \(\text{lt}_n\) is a proof that \( x < 2^n \). This allows us to work with the natural number representation of \( x \) directly. -/
  let ⟨x, lt_n⟩ := x
/- Using the definitions of the `truncate` and `zeroExtend` functions, we can simplify the proposition we want to show. Specifically, the zero extension of a bitvector \( x \) of length \( n \) to the same length \( n \) is simply \( x \) itself, and the natural number representation of \( x \) remains unchanged. Therefore, \((\text{zeroExtend}(n, x)).\text{toNat} = x.\text{toNat}\) holds trivially. -/
  simp [truncate, zeroExtend]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44070,BitVec.zeroExtend_zero,theorem BitVec.zeroExtend_zero (m n : Nat) : zeroExtend m 0#n = 0#m := by sorry,"Zero Extension of Zero Bitvector : For any natural numbers \( m \) and \( n \), the zero extension of the bitvector \( 0 \) of width \( n \) to a bitvector of width \( m \) results in the bitvector \( 0 \) of width \( m \). In other words, \( \text{zeroExtend}(m, 0^n) = 0^m \).","theorem BitVec.zeroExtend_zero (m n : Nat) : zeroExtend m 0#n = 0#m := by
  apply eq_of_toNat_eq
  simp [toNat_zeroExtend]","To prove that the zero extension of the bitvector \( 0 \) of width \( n \) to a bitvector of width \( m \) results in the bitvector \( 0 \) of width \( m \), we use the property that two bitvectors are equal if and only if their natural number representations are equal. Therefore, it suffices to show that the natural number representation of the zero-extended bitvector \(\text{zeroExtend}(m, 0^n)\) is equal to the natural number representation of the bitvector \(0^m\).

Using the property of the natural number representation of the zero-extended bitvector, we know that \((\text{zeroExtend}(m, 0^n)).\text{toNat} = (0^n).\text{toNat}\). Since the natural number representation of the bitvector \(0^n\) is \(0\), we have \((\text{zeroExtend}(m, 0^n)).\text{toNat} = 0\).

Similarly, the natural number representation of the bitvector \(0^m\) is also \(0\). Therefore, \((0^m).\text{toNat} = 0\).

Thus, we have \((\text{zeroExtend}(m, 0^n)).\text{toNat} = (0^m).\text{toNat}\), which simplifies to \(0 = 0\), a trivially true statement.

Hence, \(\text{zeroExtend}(m, 0^n) = 0^m\), completing the proof.","theorem BitVec.zeroExtend_zero (m n : Nat) : zeroExtend m 0#n = 0#m := by
/- To prove that the zero extension of the bitvector \( 0 \) of width \( n \) to a bitvector of width \( m \) results in the bitvector \( 0 \) of width \( m \), it suffices to show that the natural number representation of the zero-extended bitvector is equal to the natural number representation of the bitvector \( 0 \) of width \( m \). In other words, it suffices to show that \((\text{zeroExtend}(m, 0^n)).\text{toNat} = (0^m).\text{toNat}\). -/
  apply eq_of_toNat_eq
/- Using the property that the natural number representation of the zero-extended bitvector is the same as the natural number representation of the original bitvector, we can simplify the proposition we want to show. Specifically, the natural number representation of the zero-extended bitvector \(\text{zeroExtend}(m, 0^n)\) is equal to the natural number representation of the bitvector \(0^n\), which is \(0\). Similarly, the natural number representation of the bitvector \(0^m\) is also \(0\). Therefore, \((\text{zeroExtend}(m, 0^n)).\text{toNat} = (0^m).\text{toNat}\) simplifies to \(0 = 0\), which is trivially true. -/
  simp [toNat_zeroExtend]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44071,BitVec.toInt_eq_msb_cond,"theorem BitVec.toInt_eq_msb_cond (x : BitVec w) :
    x.toInt = if x.msb then (x.toNat : Int) - (2^w : Nat) else (x.toNat : Int) := by sorry","Bitvector to Integer Conversion Based on Most Significant Bit : For any bitvector \( x \) of length \( w \), the integer representation of \( x \) (denoted by \( x.\text{toInt} \)) is given by:
\[
x.\text{toInt} = 
\begin{cases} 
x.\text{toNat} & \text{if } x.\text{msb} = \text{false} \\
x.\text{toNat} - 2^w & \text{if } x.\text{msb} = \text{true}
\end{cases}
\]
where \( x.\text{toNat} \) is the natural number representation of \( x \), and \( x.\text{msb} \) is the most significant bit of \( x \).","theorem BitVec.toInt_eq_msb_cond (x : BitVec w) :
    x.toInt = if x.msb then (x.toNat : Int) - (2^w : Nat) else (x.toNat : Int) := by
  simp only [BitVec.toInt, ← msb_eq_false_iff_two_mul_lt]
  cases x.msb <;> rfl","We start by using the definition of `BitVec.toInt` and the equivalence that the most significant bit (msb) of \( x \) is false if and only if \( 2 \times x.\text{toNat} < 2^w \). This simplifies our goal to:
\[
\text{if } x.\text{msb} = \text{false} \text{ then } x.\text{toNat} \text{ else } x.\text{toNat} - 2^w = \text{if } x.\text{msb} = \text{true} \text{ then } x.\text{toNat} - 2^w \text{ else } x.\text{toNat}
\]

We will discuss every possible case of \( x.\text{msb} \).

**Case 1: \( x.\text{msb} = \text{false} \)**
\[
\text{if } \text{false} = \text{false} \text{ then } x.\text{toNat} \text{ else } x.\text{toNat} - 2^w = \text{if } \text{false} = \text{true} \text{ then } x.\text{toNat} - 2^w \text{ else } x.\text{toNat}
\]
This simplifies to:
\[
x.\text{toNat} = x.\text{toNat}
\]
The current goal is trivially true due to the reflexive property.

**Case 2: \( x.\text{msb} = \text{true} \)**
\[
\text{if } \text{true} = \text{false} \text{ then } x.\text{toNat} \text{ else } x.\text{toNat} - 2^w = \text{if } \text{true} = \text{true} \text{ then } x.\text{toNat} - 2^w \text{ else } x.\text{toNat}
\]
This simplifies to:
\[
x.\text{toNat} - 2^w = x.\text{toNat} - 2^w
\]
The current goal is trivially true due to the reflexive property.

Since both cases are trivially true, the theorem is proved.","theorem BitVec.toInt_eq_msb_cond (x : BitVec w) :
    x.toInt = if x.msb then (x.toNat : Int) - (2^w : Nat) else (x.toNat : Int) := by
/- Using the definition of `BitVec.toInt` and the equivalence that the most significant bit (msb) of \( x \) is false if and only if \( 2 \times x.\text{toNat} < 2^w \), we can simplify the proposition we want to show to:
\[
\text{if } x.\text{msb} = \text{false} \text{ then } x.\text{toNat} \text{ else } x.\text{toNat} - 2^w = \text{if } x.\text{msb} = \text{true} \text{ then } x.\text{toNat} - 2^w \text{ else } x.\text{toNat}
\] -/
  simp only [BitVec.toInt, ← msb_eq_false_iff_two_mul_lt]
/- We will discuss every possible case of \( x.\text{msb} \).

**Case 1: \( x.\text{msb} = \text{false} \)**
\[
\text{if } \text{false} = \text{false} \text{ then } x.\text{toNat} \text{ else } x.\text{toNat} - 2^w = \text{if } \text{false} = \text{true} \text{ then } x.\text{toNat} - 2^w \text{ else } x.\text{toNat}
\]
This simplifies to:
\[
x.\text{toNat} = x.\text{toNat}
\]
The current goal is trivially true due to the reflexive property.

**Case 2: \( x.\text{msb} = \text{true} \)**
\[
\text{if } \text{true} = \text{false} \text{ then } x.\text{toNat} \text{ else } x.\text{toNat} - 2^w = \text{if } \text{true} = \text{true} \text{ then } x.\text{toNat} - 2^w \text{ else } x.\text{toNat}
\]
This simplifies to:
\[
x.\text{toNat} - 2^w = x.\text{toNat} - 2^w
\]
The current goal is trivially true due to the reflexive property. -/
  cases x.msb <;> rfl","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44074,BitVec.toNat_eq_nat,"theorem BitVec.toNat_eq_nat (x : BitVec w) (y : Nat)
  : (x.toNat = y) ↔ (y < 2^w ∧ (x = BitVec.ofNat w y)) := by sorry","Bitvector to Natural Number Conversion Equivalence: \( x.\text{toNat} = y \leftrightarrow y < 2^w \land x = \text{BitVec.ofNat}(w, y) \) : For any natural number \( w \) and any bitvector \( x \) of width \( w \), the underlying natural number of \( x \), denoted as \( x.\text{toNat} \), is equal to \( y \) if and only if \( y \) is less than \( 2^w \) and \( x \) is the bitvector representation of \( y \) in width \( w \). In other words, \( x.\text{toNat} = y \) if and only if \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \).","theorem BitVec.toNat_eq_nat (x : BitVec w) (y : Nat)
  : (x.toNat = y) ↔ (y < 2^w ∧ (x = BitVec.ofNat w y)) := by
  apply Iff.intro
  · intro eq
    simp [←eq, x.isLt]
  · intro eq
    simp [Nat.mod_eq_of_lt, eq]","To prove the bi-implication \( x.\text{toNat} = y \leftrightarrow y < 2^w \land x = \text{BitVec.ofNat}(w, y) \), we need to show both directions.

1. **(\( \Rightarrow \))** Suppose \( x.\text{toNat} = y \). We need to show that \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \).
- Since \( x \) is a bitvector of width \( w \), by definition, \( x.\text{toNat} < 2^w \).
- Given \( x.\text{toNat} = y \), it follows that \( y < 2^w \).
- Also, \( x = \text{BitVec.ofNat}(w, x.\text{toNat}) \), and since \( x.\text{toNat} = y \), we have \( x = \text{BitVec.ofNat}(w, y) \).

2. **(\( \Leftarrow \))** Suppose \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \). We need to show that \( x.\text{toNat} = y \).
- By the definition of \( \text{BitVec.ofNat}(w, y) \), the underlying natural number of \( \text{BitVec.ofNat}(w, y) \) is \( y \).
- Since \( x = \text{BitVec.ofNat}(w, y) \), it follows that \( x.\text{toNat} = y \).

Thus, we have shown both directions, and the bi-implication \( x.\text{toNat} = y \leftrightarrow y < 2^w \land x = \text{BitVec.ofNat}(w, y) \) holds. This completes the proof.","theorem BitVec.toNat_eq_nat (x : BitVec w) (y : Nat)
  : (x.toNat = y) ↔ (y < 2^w ∧ (x = BitVec.ofNat w y)) := by
/- To prove the bi-implication \( x.\text{toNat} = y \leftrightarrow y < 2^w \land x = \text{BitVec.ofNat}(w, y) \), it suffices to show both directions: \( x.\text{toNat} = y \to y < 2^w \land x = \text{BitVec.ofNat}(w, y) \) and \( y < 2^w \land x = \text{BitVec.ofNat}(w, y) \to x.\text{toNat} = y \). -/
  apply Iff.intro
/- First, we show that if \( x.\text{toNat} = y \), then \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \). Let \( x.\text{toNat} = y \) be an arbitrary equality. -/
  · intro eq
/- Using the equality \( x.\text{toNat} = y \) and the fact that \( x.\text{toNat} < 2^w \) (since \( x \) is a bitvector of width \( w \)), we can simplify the goal to show that \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \). This is trivially true because \( y = x.\text{toNat} \) and \( x = \text{BitVec.ofNat}(w, x.\text{toNat}) \). -/
    simp [←eq, x.isLt]
/- Next, we show that if \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \), then \( x.\text{toNat} = y \). Let \( y < 2^w \) and \( x = \text{BitVec.ofNat}(w, y) \) be given. -/
  · intro eq
/- Using the fact that \( y < 2^w \) and the definition of \( \text{BitVec.ofNat}(w, y) \), we can simplify the goal to show that \( x.\text{toNat} = y \). Since \( y < 2^w \), the modulo operation \( y \% 2^w \) is equal to \( y \). Therefore, \( x.\text{toNat} = y \) holds. -/
    simp [Nat.mod_eq_of_lt, eq]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44080,BitVec.zeroExtend'_eq,theorem BitVec.zeroExtend'_eq {x : BitVec w} (h : w ≤ v) : x.zeroExtend' h = x.zeroExtend v := by sorry,"Zero Extension of Bitvector with Proof Equals Zero Extension : For any natural numbers \( w \) and \( v \) such that \( w \leq v \), and for any bitvector \( x \) of width \( w \), the zero extension of \( x \) to width \( v \) using the function `BitVec.zeroExtend'` is equal to the zero extension of \( x \) to width \( v \) using the function `BitVec.zeroExtend`.","theorem BitVec.zeroExtend'_eq {x : BitVec w} (h : w ≤ v) : x.zeroExtend' h = x.zeroExtend v := by
  apply eq_of_toNat_eq
  rw [toNat_zeroExtend, toNat_zeroExtend']
  rw [Nat.mod_eq_of_lt]
  exact Nat.lt_of_lt_of_le x.isLt (Nat.pow_le_pow_right (Nat.zero_lt_two) h)","To prove that the zero extension of \( x \) to width \( v \) using `BitVec.zeroExtend'` is equal to the zero extension of \( x \) to width \( v \) using `BitVec.zeroExtend`, it suffices to show that their underlying natural numbers are equal. In other words, we need to show that \((\text{zeroExtend}'(h, x)).\text{toNat} = (\text{zeroExtend}(v, x)).\text{toNat}\).

Using the theorems that the underlying natural number of the zero-extended bitvector \(\text{zeroExtend}(v, x)\) is equal to \( x.\text{toNat} \mod 2^v \) and the underlying natural number of the zero-extended bitvector \(\text{zeroExtend}'(h, x)\) is equal to \( x.\text{toNat} \), we can rewrite our goal. Therefore, our goal is now to show that \( x.\text{toNat} = x.\text{toNat} \mod 2^v \).

Using the theorem that for any natural numbers \( a \) and \( b \), if \( a < b \), then \( a \mod b = a \), we can further simplify our goal. Therefore, our goal is now to show that \( x.\text{toNat} < 2^v \).

To show that \( x.\text{toNat} < 2^v \), we use the fact that \( x.\text{toNat} < 2^w \) (since \( x \) is a bitvector of width \( w \)) and the fact that \( w \leq v \). By the transitivity of less-than and less-than-or-equal, and the property that \( 0 < 2 \) and exponentiation preserves order, we have \( 2^w \leq 2^v \). Therefore, \( x.\text{toNat} < 2^v \) holds, and this completes the proof.","theorem BitVec.zeroExtend'_eq {x : BitVec w} (h : w ≤ v) : x.zeroExtend' h = x.zeroExtend v := by
/- To prove that the zero extension of \( x \) to width \( v \) using `BitVec.zeroExtend'` is equal to the zero extension of \( x \) to width \( v \) using `BitVec.zeroExtend`, it suffices to show that their underlying natural numbers are equal. In other words, we need to show that \((\text{zeroExtend}'(h, x)).\text{toNat} = (\text{zeroExtend}(v, x)).\text{toNat}\). -/
  apply eq_of_toNat_eq
/- Using the theorems that the underlying natural number of the zero-extended bitvector \(\text{zeroExtend}(v, x)\) is equal to \( x.\text{toNat} \mod 2^v \) and the underlying natural number of the zero-extended bitvector \(\text{zeroExtend}'(h, x)\) is equal to \( x.\text{toNat} \), we can rewrite our goal. Therefore, our goal is now to show that \( x.\text{toNat} = x.\text{toNat} \mod 2^v \). -/
  rw [toNat_zeroExtend, toNat_zeroExtend']
/- Using the theorem that for any natural numbers \( a \) and \( b \), if \( a < b \), then \( a \mod b = a \), we can further simplify our goal. Therefore, our goal is now to show that \( x.\text{toNat} < 2^v \). -/
  rw [Nat.mod_eq_of_lt]
/- To show that \( x.\text{toNat} < 2^v \), we use the fact that \( x.\text{toNat} < 2^w \) (since \( x \) is a bitvector of width \( w \)) and the fact that \( w \leq v \). By the transitivity of less-than and less-than-or-equal, and the property that \( 0 < 2 \) and exponentiation preserves order, we have \( 2^w \leq 2^v \). Therefore, \( x.\text{toNat} < 2^v \) holds, and this completes the proof. -/
  exact Nat.lt_of_lt_of_le x.isLt (Nat.pow_le_pow_right (Nat.zero_lt_two) h)","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44083,BitVec.toNat_allOnes,theorem BitVec.toNat_allOnes : (allOnes v).toNat = 2^v - 1 := by sorry,"Underlying Natural Number of All-Ones Bitvector Equals \(2^v - 1\) : For any natural number \( v \), the underlying natural number of the bitvector `BitVec.allOnes v` is equal to \( 2^v - 1 \), i.e., \(\text{toNat}(\text{allOnes}(v)) = 2^v - 1\).","theorem BitVec.toNat_allOnes : (allOnes v).toNat = 2^v - 1 := by
  unfold allOnes
  simp","We start by expanding the definition of `BitVec.allOnes`. The function `BitVec.allOnes` applied to a natural number \( v \) returns a bitvector of size \( v \) where all bits are set to `1`. This is achieved by taking the natural number \( 2^v - 1 \) and converting it to a bitvector of size \( v \). Therefore, the goal is to show that \((2^v - 1)\#'\cdots\).toNat = 2^v - 1\).

Next, we simplify the expression \((2^v - 1)\#'\cdots\).toNat. Using the properties of the `toNat` function and the fact that the bitvector \((2^v - 1)\#'\cdots\) is constructed from the natural number \(2^v - 1\), we can directly conclude that \((2^v - 1)\#'\cdots\).toNat = 2^v - 1\).

Thus, the underlying natural number of the bitvector `BitVec.allOnes v` is indeed \( 2^v - 1 \). This completes the proof. \(\blacksquare\)","theorem BitVec.toNat_allOnes : (allOnes v).toNat = 2^v - 1 := by
/- First, we expand the definition of `BitVec.allOnes`. The function `BitVec.allOnes` applied to a natural number \( v \) returns a bitvector of size \( v \) where all bits are set to `1`. This is achieved by taking the natural number \( 2^v - 1 \) and converting it to a bitvector of size \( v \). Therefore, the goal becomes to show that \((2^v - 1)\#'\cdots\).toNat = 2^v - 1\). -/
  unfold allOnes
/- Next, we simplify the expression \((2^v - 1)\#'\cdots\).toNat. Using the properties of the `toNat` function and the fact that the bitvector \((2^v - 1)\#'\cdots\) is constructed from the natural number \(2^v - 1\), we can directly conclude that \((2^v - 1)\#'\cdots\).toNat = 2^v - 1\). This completes the proof. -/
  simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44087,BitVec.eq_of_toInt_eq,theorem BitVec.eq_of_toInt_eq {i j : BitVec n} : i.toInt = j.toInt → i = j := by sorry,"Bitvector Equality from Integer Representation Equality : For any natural number $n$ and any bitvectors $i$ and $j$ of width $n$, if the integer representation of $i$ is equal to the integer representation of $j$, then $i$ is equal to $j$. In other words, if $i.\text{toInt} = j.\text{toInt}$, then $i = j$.","theorem BitVec.eq_of_toInt_eq {i j : BitVec n} : i.toInt = j.toInt → i = j := by
  intro eq
  simp [toInt_eq_toNat_cond] at eq
  apply eq_of_toNat_eq
  revert eq
  have _ilt := i.isLt
  have _jlt := j.isLt
  split <;> split <;> omega","Let $eq$ be the assumption that the integer representation of $i$ is equal to the integer representation of $j$. We need to show that $i = j$.

First, we simplify the assumption $eq$ using the definition of the integer representation of a bitvector. This gives us:
\[
\text{if } 2 \cdot i.\text{toNat} < 2^n \text{ then } i.\text{toNat} \text{ else } i.\text{toNat} - 2^n = \text{if } 2 \cdot j.\text{toNat} < 2^n \text{ then } j.\text{toNat} \text{ else } j.\text{toNat} - 2^n
\]

To prove that $i = j$, it suffices to show that the natural number representation of $i$ is equal to the natural number representation of $j$, i.e., $i.\text{toNat} = j.\text{toNat}$.

We strengthen the proposition we are proving. We show that for every $eq$, if the simplified condition holds, then $i.\text{toNat} = j.\text{toNat}$.

We construct two lemmas:
1. The natural number representation of $i$ is less than $2^n$, i.e., $i.\text{toNat} < 2^n$.
2. The natural number representation of $j$ is less than $2^n$, i.e., $j.\text{toNat} < 2^n$.

We discuss by cases based on the conditions $2 \cdot i.\text{toNat} < 2^n$ and $2 \cdot j.\text{toNat} < 2^n$:
1. If $2 \cdot i.\text{toNat} < 2^n$ and $2 \cdot j.\text{toNat} < 2^n$, then we need to show that $i.\text{toNat} = j.\text{toNat}$. This is trivially true by the assumption.
2. If $2 \cdot i.\text{toNat} < 2^n$ and $2 \cdot j.\text{toNat} \geq 2^n$, then we need to show that $i.\text{toNat} = j.\text{toNat} - 2^n$. This is trivially true by the assumption and the properties of natural numbers.
3. If $2 \cdot i.\text{toNat} \geq 2^n$ and $2 \cdot j.\text{toNat} < 2^n$, then we need to show that $i.\text{toNat} - 2^n = j.\text{toNat}$. This is trivially true by the assumption and the properties of natural numbers.
4. If $2 \cdot i.\text{toNat} \geq 2^n$ and $2 \cdot j.\text{toNat} \geq 2^n$, then we need to show that $i.\text{toNat} - 2^n = j.\text{toNat} - 2^n$. This is trivially true by the assumption and the properties of natural numbers.

Thus, in all cases, we have shown that $i.\text{toNat} = j.\text{toNat}$, which implies $i = j$. Therefore, the theorem is proved. $\blacksquare$","theorem BitVec.eq_of_toInt_eq {i j : BitVec n} : i.toInt = j.toInt → i = j := by
/- Let $eq$ be the assumption that the integer representation of $i$ is equal to the integer representation of $j$. We need to show that $i = j$. -/
  intro eq
/- Using the definition of the integer representation of a bitvector, we can simplify the assumption $eq$ to:
\[
\text{if } 2 \cdot i.\text{toNat} < 2^n \text{ then } i.\text{toNat} \text{ else } i.\text{toNat} - 2^n = \text{if } 2 \cdot j.\text{toNat} < 2^n \text{ then } j.\text{toNat} \text{ else } j.\text{toNat} - 2^n
\] -/
  simp [toInt_eq_toNat_cond] at eq
/- To prove that $i = j$, it suffices to show that the natural number representation of $i$ is equal to the natural number representation of $j$, i.e., $i.\text{toNat} = j.\text{toNat}$. -/
  apply eq_of_toNat_eq
/- We strengthen the proposition we are proving. We show that for every $eq$, if the simplified condition holds, then $i.\text{toNat} = j.\text{toNat}$. -/
  revert eq
/- We construct a lemma that the natural number representation of $i$ is less than $2^n$, i.e., $i.\text{toNat} < 2^n$. -/
  have _ilt := i.isLt
/- We construct a lemma that the natural number representation of $j$ is less than $2^n$, i.e., $j.\text{toNat} < 2^n$. -/
  have _jlt := j.isLt
/- We discuss by cases based on the conditions $2 \cdot i.\text{toNat} < 2^n$ and $2 \cdot j.\text{toNat} < 2^n$:
1. If $2 \cdot i.\text{toNat} < 2^n$ and $2 \cdot j.\text{toNat} < 2^n$, then we need to show that $i.\text{toNat} = j.\text{toNat}$.
2. If $2 \cdot i.\text{toNat} < 2^n$ and $2 \cdot j.\text{toNat} \geq 2^n$, then we need to show that $i.\text{toNat} = j.\text{toNat} - 2^n$.
3. If $2 \cdot i.\text{toNat} \geq 2^n$ and $2 \cdot j.\text{toNat} < 2^n$, then we need to show that $i.\text{toNat} - 2^n = j.\text{toNat}$.
4. If $2 \cdot i.\text{toNat} \geq 2^n$ and $2 \cdot j.\text{toNat} \geq 2^n$, then we need to show that $i.\text{toNat} - 2^n = j.\text{toNat} - 2^n$.

In each case, the goal is trivially true by the properties of natural numbers and the assumption that $i.\text{toNat} < 2^n$ and $j.\text{toNat} < 2^n$. -/
  split <;> split <;> omega","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44093,BitVec.toFin_or,"theorem BitVec.toFin_or (x y : BitVec v) :
    BitVec.toFin (x ||| y) = BitVec.toFin x ||| BitVec.toFin y := by sorry","Bitwise Disjunction of Bitvectors Preserves Conversion to Canonical Type: \((x \ ||| \ y).toFin = x.toFin \ ||| \ y.toFin\) : For any natural number \( v \) and any two bitvectors \( x \) and \( y \) of length \( v \), the result of the bitwise disjunction \( x \ ||| \ y \) when converted to the canonical type with \( 2^v \) elements (denoted by \( \text{Fin}(2^v) \)) is equal to the bitwise disjunction of the results of converting \( x \) and \( y \) individually to \( \text{Fin}(2^v) \). In other words, \((x \ ||| \ y).toFin = x.toFin \ ||| \ y.toFin\).","theorem BitVec.toFin_or (x y : BitVec v) :
    BitVec.toFin (x ||| y) = BitVec.toFin x ||| BitVec.toFin y := by
  apply Fin.eq_of_val_eq
  exact (Nat.mod_eq_of_lt <| Nat.or_lt_two_pow x.isLt y.isLt).symm","To prove that \((x \ ||| \ y).toFin = x.toFin \ ||| \ y.toFin\), it suffices to show that the values of these elements in the canonical type \(\text{Fin}(2^v)\) are equal, i.e., \(\text{val}((x \ ||| \ y).toFin) = \text{val}(x.toFin \ ||| \ y.toFin)\).

Since \(x\) and \(y\) are bitvectors of length \(v\), their underlying natural numbers \(x.toNat\) and \(y.toNat\) are both less than \(2^v\). By the property of the bitwise disjunction, \(x.toNat \ ||| \ y.toNat\) is also less than \(2^v\). Therefore, the modulo operation \((x.toNat \ ||| \ y.toNat) \% 2^v\) is equal to \(x.toNat \ ||| \ y.toNat\). This is exactly what we need to show, and the symmetry of equality completes the proof.

Thus, \((x \ ||| \ y).toFin = x.toFin \ ||| \ y.toFin\). This completes the proof. \(\blacksquare\)","theorem BitVec.toFin_or (x y : BitVec v) :
    BitVec.toFin (x ||| y) = BitVec.toFin x ||| BitVec.toFin y := by
/- To prove that \((x \ ||| \ y).toFin = x.toFin \ ||| \ y.toFin\), it suffices to show that the values of these elements in the canonical type \(\text{Fin}(2^v)\) are equal, i.e., \(\text{val}((x \ ||| \ y).toFin) = \text{val}(x.toFin \ ||| \ y.toFin)\). -/
  apply Fin.eq_of_val_eq
/- We need to show that \(\text{val}((x \ ||| \ y).toFin) = \text{val}(x.toFin \ ||| \ y.toFin)\). Since \(x\) and \(y\) are bitvectors of length \(v\), their underlying natural numbers \(x.toNat\) and \(y.toNat\) are both less than \(2^v\). By the property of the bitwise disjunction, \(x.toNat \ ||| \ y.toNat\) is also less than \(2^v\). Therefore, the modulo operation \( (x.toNat \ ||| \ y.toNat) \% 2^v \) is equal to \( x.toNat \ ||| \ y.toNat \). This is exactly what we need to show, and the symmetry of equality completes the proof. -/
  exact (Nat.mod_eq_of_lt <| Nat.or_lt_two_pow x.isLt y.isLt).symm","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44097,BitVec.xor_assoc,"theorem BitVec.xor_assoc (x y z : BitVec w) :
    x ^^^ y ^^^ z = x ^^^ (y ^^^ z) := by sorry","Associativity of XOR in Bitvectors: \( x \^^^ y \^^^ z = x \^^^ (y \^^^ z) \) : For any natural number \( w \) and any bitvectors \( x, y, z \in \text{BitVec}(w) \), the XOR operation is associative, i.e., \( x \^^^ y \^^^ z = x \^^^ (y \^^^ z) \).","theorem BitVec.xor_assoc (x y z : BitVec w) :
    x ^^^ y ^^^ z = x ^^^ (y ^^^ z) := by
  ext i
  simp [Bool.xor_assoc]","To prove that \( x \^^^ y \^^^ z = x \^^^ (y \^^^ z) \), we need to show that for every index \( i \) in the range of \( w \), the \( i \)-th bit of \( x \^^^ y \^^^ z \) is equal to the \( i \)-th bit of \( x \^^^ (y \^^^ z) \).

By the definition of the bitvector XOR operation, the \( i \)-th bit of \( x \^^^ y \^^^ z \) is the boolean XOR of the \( i \)-th bits of \( x \), \( y \), and \( z \). Similarly, the \( i \)-th bit of \( x \^^^ (y \^^^ z) \) is the boolean XOR of the \( i \)-th bit of \( x \) and the \( i \)-th bit of \( y \^^^ z \).

Using the associativity of the boolean XOR operation, we have:
\[
(x_i \^^^ y_i) \^^^ z_i = x_i \^^^ (y_i \^^^ z_i)
\]
for every \( i \) in the range of \( w \).

Thus, the \( i \)-th bit of \( x \^^^ y \^^^ z \) is equal to the \( i \)-th bit of \( x \^^^ (y \^^^ z) \) for all \( i \). Therefore, \( x \^^^ y \^^^ z = x \^^^ (y \^^^ z) \).

This completes the proof.","theorem BitVec.xor_assoc (x y z : BitVec w) :
    x ^^^ y ^^^ z = x ^^^ (y ^^^ z) := by
/- To prove that \( x \^^^ y \^^^ z = x \^^^ (y \^^^ z) \), it suffices to show that for every index \( i \) in the range of \( w \), the \( i \)-th bit of \( x \^^^ y \^^^ z \) is equal to the \( i \)-th bit of \( x \^^^ (y \^^^ z) \). -/
  ext i
/- Using the associativity of the boolean XOR operation, we can simplify the expression to show that the \( i \)-th bit of \( x \^^^ y \^^^ z \) is equal to the \( i \)-th bit of \( x \^^^ (y \^^^ z) \). This completes the proof. -/
  simp [Bool.xor_assoc]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44108,BitVec.truncate_and,"theorem BitVec.truncate_and {x y : BitVec w} :
    (x &&& y).truncate k = x.truncate k &&& y.truncate k := by sorry","Truncation Preserves Bitvector Conjunction: \(\text{truncate}(k, x \&&& y) = \text{truncate}(k, x) \&&& \text{truncate}(k, y)\) : For any natural numbers \( w \) and \( k \), and any bitvectors \( x \) and \( y \) of width \( w \), the most significant bit of the conjunction \( x \&&& y \) truncated to width \( k \) is equal to the conjunction of the most significant bits of \( x \) and \( y \) truncated to width \( k \). Formally, \(\text{truncate}(k, x \&&& y) = \text{truncate}(k, x) \&&& \text{truncate}(k, y)\).","theorem BitVec.truncate_and {x y : BitVec w} :
    (x &&& y).truncate k = x.truncate k &&& y.truncate k := by
  ext
  simp","To prove the theorem, we need to show that for every \(i \in \{0, 1, \ldots, k-1\}\), the \(i\)-th least significant bit of \(\text{truncate}(k, x \&&& y)\) is equal to the \(i\)-th least significant bit of \(\text{truncate}(k, x) \&&& \text{truncate}(k, y)\).

1. **Introduce a new variable \(i\):**
We introduce a new variable \(i\) to reason about the \(i\)-th least significant bit of the bitvectors involved. This reduces our goal to showing that for every \(i \in \{0, 1, \ldots, k-1\}\),
\[
(\text{truncate}(k, x \&&& y)).\text{getLsb}(i) = (\text{truncate}(k, x) \&&& \text{truncate}(k, y)).\text{getLsb}(i).
\]

2. **Simplify the expression:**
Using the properties of bitvector operations and the definition of the least significant bit, we can simplify the expression. Specifically, we use the fact that the conjunction operation preserves the least significant bits:
\[
(x \&&& y).\text{getLsb}(i) = (x.\text{getLsb}(i) \land y.\text{getLsb}(i)).
\]
Additionally, the truncation operation only affects the higher bits, which are not considered in the least significant bit comparison. Therefore, for every \(i \in \{0, 1, \ldots, k-1\}\),
\[
(\text{truncate}(k, x \&&& y)).\text{getLsb}(i) = (x \&&& y).\text{getLsb}(i) = (x.\text{getLsb}(i) \land y.\text{getLsb}(i)).
\]
Similarly,
\[
(\text{truncate}(k, x) \&&& \text{truncate}(k, y)).\text{getLsb}(i) = (\text{truncate}(k, x).\text{getLsb}(i) \land \text{truncate}(k, y).\text{getLsb}(i)) = (x.\text{getLsb}(i) \land y.\text{getLsb}(i)).
\]
Hence, we have
\[
(\text{truncate}(k, x \&&& y)).\text{getLsb}(i) = (\text{truncate}(k, x) \&&& \text{truncate}(k, y)).\text{getLsb}(i).
\]

Since this holds for every \(i \in \{0, 1, \ldots, k-1\}\), we conclude that
\[
\text{truncate}(k, x \&&& y) = \text{truncate}(k, x) \&&& \text{truncate}(k, y).
\]
This completes the proof.","theorem BitVec.truncate_and {x y : BitVec w} :
    (x &&& y).truncate k = x.truncate k &&& y.truncate k := by
/- To prove that \(\text{truncate}(k, x \&&& y) = \text{truncate}(k, x) \&&& \text{truncate}(k, y)\), it suffices to show that for every \(i \in \{0, 1, \ldots, k-1\}\), the \(i\)-th least significant bit of \(\text{truncate}(k, x \&&& y)\) is equal to the \(i\)-th least significant bit of \(\text{truncate}(k, x) \&&& \text{truncate}(k, y)\). -/
  ext
/- Using the properties of bitvector operations and the definition of the least significant bit, we can simplify the expression to show that for every \(i \in \{0, 1, \ldots, k-1\}\), the \(i\)-th least significant bit of \(\text{truncate}(k, x \&&& y)\) is indeed equal to the \(i\)-th least significant bit of \(\text{truncate}(k, x) \&&& \text{truncate}(k, y)\). This is because the conjunction operation preserves the least significant bits, and the truncation operation only affects the higher bits, which are not considered in the least significant bit comparison. -/
  simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44109,BitVec.shiftLeft_zero_eq,theorem BitVec.shiftLeft_zero_eq (x : BitVec w) : x <<< 0 = x := by sorry,"Left Shift of Bitvector by Zero is Identity : For any natural number \( w \) and any bitvector \( x \) of width \( w \), performing a left shift operation on \( x \) by 0 positions results in the same bitvector \( x \). In other words, \( x \lll 0 = x \).","theorem BitVec.shiftLeft_zero_eq (x : BitVec w) : x <<< 0 = x := by
  apply eq_of_toNat_eq
  simp","To prove that \( x \lll 0 = x \), we use the fact that two bitvectors are equal if and only if their natural number representations are equal. Therefore, it suffices to show that the natural number representation of \( x \lll 0 \) is equal to the natural number representation of \( x \). That is, we need to show that \((x \lll 0).toNat = x.toNat\).

Using the properties of the left shift operation and the natural number representation, we can simplify the expression \((x \lll 0).toNat\) to \(x.toNat\). Hence, \((x \lll 0).toNat = x.toNat\) holds true. This completes the proof. \(\blacksquare\)","theorem BitVec.shiftLeft_zero_eq (x : BitVec w) : x <<< 0 = x := by
/- To prove that \( x \lll 0 = x \), it suffices to show that the natural number representation of \( x \lll 0 \) is equal to the natural number representation of \( x \). In other words, we need to show that \((x \lll 0).toNat = x.toNat\). -/
  apply eq_of_toNat_eq
/- Using the properties of the left shift operation and the natural number representation, we can simplify the expression \((x \lll 0).toNat\) to \(x.toNat\). Therefore, \((x \lll 0).toNat = x.toNat\) holds true. -/
  simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44110,BitVec.and_comm,"theorem BitVec.and_comm (x y : BitVec w) :
    x &&& y = y &&& x := by sorry","Commutativity of Bitvector Conjunction: \( x \&&& y = y \&&& x \) : For any natural number \( w \) and any bitvectors \( x, y \) of width \( w \), the conjunction operation is commutative, i.e., \( x \&&& y = y \&&& x \).","theorem BitVec.and_comm (x y : BitVec w) :
    x &&& y = y &&& x := by
  ext i
  simp [Bool.and_comm]","To prove that \( x \&&& y = y \&&& x \), we need to show that for every index \( i \) in the range of \( w \), the \( i \)-th bit of \( x \&&& y \) is equal to the \( i \)-th bit of \( y \&&& x \).

1. **Introduce a new variable \( i \):**
We introduce a new variable \( i \) to reason about the \( i \)-th bit of the bitvectors. This reduces our goal to showing that \((x \&&& y).getLsb(i) = (y \&&& x).getLsb(i)\).

2. **Simplify using the commutativity of the boolean ""and"" operation:**
For any boolean values \( x_i \) and \( y_i \), the \( i \)-th bit of \( x \&&& y \) is \( x_i \land y_i \), and the \( i \)-th bit of \( y \&&& x \) is \( y_i \land x_i \). Since the boolean ""and"" operation is commutative, we have \( x_i \land y_i = y_i \land x_i \). Therefore, the \( i \)-th bit of \( x \&&& y \) is equal to the \( i \)-th bit of \( y \&&& x \).

Since this holds for every index \( i \) in the range of \( w \), we conclude that \( x \&&& y = y \&&& x \). This completes the proof.","theorem BitVec.and_comm (x y : BitVec w) :
    x &&& y = y &&& x := by
/- To prove that \( x \&&& y = y \&&& x \), it suffices to show that for every index \( i \) in the range of \( w \), the \( i \)-th bit of \( x \&&& y \) is equal to the \( i \)-th bit of \( y \&&& x \). We introduce a new variable \( i \) to reason about the \( i \)-th bit of the bitvectors. -/
  ext i
/- Using the commutativity of the boolean ""and"" operation, we can simplify the proposition we want to show. Specifically, for any boolean values \( x_i \) and \( y_i \), the \( i \)-th bit of \( x \&&& y \) is \( x_i \land y_i \), and the \( i \)-th bit of \( y \&&& x \) is \( y_i \land x_i \). Since \( x_i \land y_i = y_i \land x_i \) by the commutativity of the boolean ""and"" operation, the \( i \)-th bit of \( x \&&& y \) is equal to the \( i \)-th bit of \( y \&&& x \). This completes the proof. -/
  simp [Bool.and_comm]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44112,BitVec.or_assoc,"theorem BitVec.or_assoc (x y z : BitVec w) :
    x ||| y ||| z = x ||| (y ||| z) := by sorry","Associativity of Bitwise Disjunction on Bitvectors: \( x \ ||| \ y \ ||| \ z = x \ ||| \ (y \ ||| \ z) \) : For any natural number \( w \) and any bitvectors \( x, y, z \) of width \( w \), the bitwise disjunction operation is associative, i.e., \( x \ ||| \ y \ ||| \ z = x \ ||| \ (y \ ||| \ z) \).","theorem BitVec.or_assoc (x y z : BitVec w) :
    x ||| y ||| z = x ||| (y ||| z) := by
  ext i
  simp [Bool.or_assoc]","To prove that \( x \ ||| \ y \ ||| \ z = x \ ||| \ (y \ ||| \ z) \), we need to show that for every index \( i \) in the range of \( w \), the \( i \)-th least significant bit of \( x \ ||| \ y \ ||| \ z \) is equal to the \( i \)-th least significant bit of \( x \ ||| \ (y \ ||| \ z) \).

By the definition of bitwise disjunction, the \( i \)-th least significant bit of \( x \ ||| \ y \ ||| \ z \) is given by:
\[
(x \ ||| \ y \ ||| \ z).getLsb(i) = x.getLsb(i) \ || \ y.getLsb(i) \ || \ z.getLsb(i)
\]

Similarly, the \( i \)-th least significant bit of \( x \ ||| \ (y \ ||| \ z) \) is given by:
\[
(x \ ||| \ (y \ ||| \ z)).getLsb(i) = x.getLsb(i) \ || \ (y.getLsb(i) \ || \ z.getLsb(i))
\]

Using the associativity of the logical disjunction, we have:
\[
x.getLsb(i) \ || \ (y.getLsb(i) \ || \ z.getLsb(i)) = (x.getLsb(i) \ || \ y.getLsb(i)) \ || \ z.getLsb(i)
\]

Thus, the \( i \)-th least significant bit of \( x \ ||| \ y \ ||| \ z \) is equal to the \( i \)-th least significant bit of \( x \ ||| \ (y \ ||| \ z) \) for every \( i \). Therefore, \( x \ ||| \ y \ ||| \ z = x \ ||| \ (y \ ||| \ z) \).

This completes the proof.","theorem BitVec.or_assoc (x y z : BitVec w) :
    x ||| y ||| z = x ||| (y ||| z) := by
/- To prove that \( x \ ||| \ y \ ||| \ z = x \ ||| \ (y \ ||| \ z) \), it suffices to show that for every index \( i \) in the range of \( w \), the \( i \)-th least significant bit of \( x \ ||| \ y \ ||| \ z \) is equal to the \( i \)-th least significant bit of \( x \ ||| \ (y \ ||| \ z) \). -/
  ext i
/- Using the associativity of the logical disjunction, we can simplify the expression for the \( i \)-th least significant bit of \( x \ ||| \ y \ ||| \ z \) and \( x \ ||| \ (y \ ||| \ z) \). Specifically, the \( i \)-th least significant bit of \( x \ ||| \ y \ ||| \ z \) is \( x.getLsb(i) \ || \ y.getLsb(i) \ || \ z.getLsb(i) \), and the \( i \)-th least significant bit of \( x \ ||| \ (y \ ||| \ z) \) is \( x.getLsb(i) \ || \ (y.getLsb(i) \ || \ z.getLsb(i)) \). By the associativity of logical disjunction, these two expressions are equal. Therefore, the \( i \)-th least significant bit of \( x \ ||| \ y \ ||| \ z \) is equal to the \( i \)-th least significant bit of \( x \ ||| \ (y \ ||| \ z) \) for every \( i \). -/
  simp [Bool.or_assoc]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44116,BitVec.ushiftRight_zero_eq,theorem BitVec.ushiftRight_zero_eq (x : BitVec w) : x >>> 0 = x := by sorry,"Right Shift by Zero Preserves Bitvector : For any natural number \( w \) and any bitvector \( x \) of width \( w \), the right shift of \( x \) by 0 is equal to \( x \), i.e., \( x >>> 0 = x \).","theorem BitVec.ushiftRight_zero_eq (x : BitVec w) : x >>> 0 = x := by
  simp [bv_toNat]","To prove that the right shift of a bitvector \( x \) by 0 is equal to \( x \), we start by considering the definition of the right shift operation. The right shift by 0 does not change the bitvector. Therefore, the proposition \( x >>> 0 = x \) is trivially true. This completes the proof.","theorem BitVec.ushiftRight_zero_eq (x : BitVec w) : x >>> 0 = x := by
/- Using the definition of the bitvector to natural number conversion, we can simplify the proposition we want to show, which is \( x >>> 0 = x \), to a trivially true statement. This is because the right shift by 0 does not change the bitvector \( x \). -/
  simp [bv_toNat]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44117,BitVec.truncate_or,"theorem BitVec.truncate_or {x y : BitVec w} :
    (x ||| y).truncate k = x.truncate k ||| y.truncate k := by sorry","Truncation of Bitwise Disjunction Equals Bitwise Disjunction of Truncated Bitvectors : For any natural numbers \( w \) and \( k \), and any two bitvectors \( x \) and \( y \) of width \( w \), the most significant \( k \) bits of the bitwise disjunction \( x \ ||| \ y \) are equal to the bitwise disjunction of the most significant \( k \) bits of \( x \) and \( y \), i.e., \(\text{truncate}_k(x \ ||| \ y) = \text{truncate}_k(x) \ ||| \ \text{truncate}_k(y)\).","theorem BitVec.truncate_or {x y : BitVec w} :
    (x ||| y).truncate k = x.truncate k ||| y.truncate k := by
  ext
  simp","To prove the theorem, we need to show that for any \( i \) in the range \( 0 \leq i < k \), the \( i \)-th least significant bit of the truncated bitwise disjunction \( \text{truncate}_k(x \ ||| \ y) \) is equal to the \( i \)-th least significant bit of the bitwise disjunction of the truncated bitvectors \( \text{truncate}_k(x) \ ||| \ \text{truncate}_k(y) \).

1. **Introduce a new variable \( i \):**
We introduce a new variable \( i \) in the context to reason about the \( i \)-th least significant bit of the truncated bitvectors. This allows us to consider individual bits in the bitvectors.

2. **Simplify the expression:**
Using the properties of the least significant bit (LSB) of bitwise disjunction and zero-extension, we simplify the expression to show that:
\[
(\text{truncate}_k(x \ ||| \ y)).\text{getLsb}(i) = (\text{truncate}_k(x) \ ||| \ \text{truncate}_k(y)).\text{getLsb}(i)
\]
Specifically, we use the following properties:
- The \( i \)-th least significant bit of the bitwise disjunction \( x \ ||| \ y \) is the logical disjunction of the \( i \)-th least significant bits of \( x \) and \( y \):
\[
(x \ ||| \ y).\text{getLsb}(i) = (x.\text{getLsb}(i) \ || \ y.\text{getLsb}(i))
\]
- The \( i \)-th least significant bit of the zero-extended bitvector is the \( i \)-th least significant bit of the original bitvector if \( i < k \):
\[
\text{getLsb}(\text{zeroExtend}(k, x), i) = \text{decide}(i < k) \land x.\text{getLsb}(i)
\]
- Since \( i \) is in the range \( 0 \leq i < k \), the condition \( \text{decide}(i < k) \) is always true, and thus:
\[
(\text{truncate}_k(x \ ||| \ y)).\text{getLsb}(i) = (x \ ||| \ y).\text{getLsb}(i) = (x.\text{getLsb}(i) \ || \ y.\text{getLsb}(i))
\]
- Similarly, for the truncated bitvectors:
\[
(\text{truncate}_k(x) \ ||| \ \text{truncate}_k(y)).\text{getLsb}(i) = (\text{truncate}_k(x).\text{getLsb}(i) \ || \ \text{truncate}_k(y).\text{getLsb}(i)) = (x.\text{getLsb}(i) \ || \ y.\text{getLsb}(i))
\]

Since the \( i \)-th least significant bit of the truncated bitwise disjunction \( \text{truncate}_k(x \ ||| \ y) \) is equal to the \( i \)-th least significant bit of the bitwise disjunction of the truncated bitvectors \( \text{truncate}_k(x) \ ||| \ \text{truncate}_k(y) \) for all \( i \) in the range \( 0 \leq i < k \), we conclude that:
\[
\text{truncate}_k(x \ ||| \ y) = \text{truncate}_k(x) \ ||| \ \text{truncate}_k(y)
\]

This completes the proof.","theorem BitVec.truncate_or {x y : BitVec w} :
    (x ||| y).truncate k = x.truncate k ||| y.truncate k := by
/- To prove that the most significant \( k \) bits of the bitwise disjunction \( x \ ||| \ y \) are equal to the bitwise disjunction of the most significant \( k \) bits of \( x \) and \( y \), we introduce a new variable \( i \) in the context to reason about the \( i \)-th least significant bit of the truncated bitvectors. This allows us to consider individual bits in the bitvectors. -/
  ext
/- Using the properties of the least significant bit (LSB) of bitwise disjunction and zero-extension, we simplify the expression to show that the \( i \)-th least significant bit of the truncated bitwise disjunction \( \text{truncate}_k(x \ ||| \ y) \) is equal to the \( i \)-th least significant bit of the bitwise disjunction of the truncated bitvectors \( \text{truncate}_k(x) \ ||| \ \text{truncate}_k(y) \). This simplification is straightforward and follows from the definitions and properties of bitwise operations and truncation. -/
  simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44118,BitVec.shiftLeft_eq',theorem BitVec.shiftLeft_eq' {x : BitVec w₁} {y : BitVec w₂} : x <<< y = x <<< y.toNat := by sorry,"Left Shift of Bitvector by Another Bitvector Equals Left Shift by Underlying Natural Number : For any natural numbers \( w_1 \) and \( w_2 \), and for any bitvectors \( x \) of width \( w_1 \) and \( y \) of width \( w_2 \), the left shift of \( x \) by \( y \) is equal to the left shift of \( x \) by the underlying natural number of \( y \). In other words, \( x \lll y = x \lll \text{toNat}(y) \).","theorem BitVec.shiftLeft_eq' {x : BitVec w₁} {y : BitVec w₂} : x <<< y = x <<< y.toNat := by
  rfl","To prove the theorem, we need to show that for any bitvectors \( x \) and \( y \) of widths \( w_1 \) and \( w_2 \) respectively, the left shift of \( x \) by \( y \) is equal to the left shift of \( x \) by the underlying natural number of \( y \). This equality holds by the definition of the left shift operation and the conversion of \( y \) to its underlying natural number. Therefore, the equality \( x \lll y = x \lll \text{toNat}(y) \) is trivially true due to the reflexive property. This completes the proof.","theorem BitVec.shiftLeft_eq' {x : BitVec w₁} {y : BitVec w₂} : x <<< y = x <<< y.toNat := by
  rfl","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44119,BitVec.ushiftRight_eq',"theorem BitVec.ushiftRight_eq' (x : BitVec w₁) (y : BitVec w₂) :
    x >>> y = x >>> y.toNat := by sorry","Right Shift of Bitvector by Another Bitvector Equals Right Shift by Underlying Natural Number : For any natural numbers \( w_1 \) and \( w_2 \), and for any bitvectors \( x \) of width \( w_1 \) and \( y \) of width \( w_2 \), the right shift of \( x \) by \( y \) is equal to the right shift of \( x \) by the underlying natural number of \( y \), i.e., \( x >>> y = x >>> y.\text{toNat} \).","theorem BitVec.ushiftRight_eq' (x : BitVec w₁) (y : BitVec w₂) :
    x >>> y = x >>> y.toNat := by
  rfl","To prove the theorem, we need to show that for any bitvectors \( x \) and \( y \) of widths \( w_1 \) and \( w_2 \) respectively, the right shift of \( x \) by \( y \) is equal to the right shift of \( x \) by the underlying natural number of \( y \). This is trivially true due to the reflexive property, as the right shift operation \( x >>> y \) is definitionally equal to \( x >>> y.\text{toNat} \). Therefore, the equality \( x >>> y = x >>> y.\text{toNat} \) holds. This completes the proof.","theorem BitVec.ushiftRight_eq' (x : BitVec w₁) (y : BitVec w₂) :
    x >>> y = x >>> y.toNat := by
  rfl","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44123,BitVec.toFin_not,"theorem BitVec.toFin_not (x : BitVec w) :
    (~~~x).toFin = x.toFin.rev := by sorry","Complement of Bitvector to Canonical Type: \( \text{toFin}(\sim x) = \text{rev}(\text{toFin}(x)) \) : For any natural number \( w \) and any bitvector \( x \) of width \( w \), the canonical type element corresponding to the complement of \( x \), denoted as \( \sim x \), is equal to the reverse of the canonical type element corresponding to \( x \). In other words, \( \text{toFin}(\sim x) = \text{rev}(\text{toFin}(x)) \).","theorem BitVec.toFin_not (x : BitVec w) :
    (~~~x).toFin = x.toFin.rev := by
  apply Fin.val_inj.mp
  simp only [val_toFin, toNat_not, Fin.val_rev]
  omega","To prove that \(\text{toFin}(\sim x) = \text{rev}(\text{toFin}(x))\), it suffices to show that the natural number values of \(\text{toFin}(\sim x)\) and \(\text{rev}(\text{toFin}(x))\) are equal, i.e., \(\text{Fin.val}(\text{toFin}(\sim x)) = \text{Fin.val}(\text{rev}(\text{toFin}(x)))\).

Using the properties of the `val_toFin`, `toNat_not`, and `Fin.val_rev` functions, we can simplify the proposition we want to show to:
\[
2^w - 1 - x.toNat = 2^w - (x.toNat + 1)
\]

The equation \(2^w - 1 - x.toNat = 2^w - (x.toNat + 1)\) holds true by simple algebraic manipulation. Specifically, we can simplify the right-hand side:
\[
2^w - (x.toNat + 1) = 2^w - x.toNat - 1
\]
Thus, the equation becomes:
\[
2^w - 1 - x.toNat = 2^w - x.toNat - 1
\]
which is clearly true. Therefore, \(\text{toFin}(\sim x) = \text{rev}(\text{toFin}(x))\). This completes the proof. \(\blacksquare\)","theorem BitVec.toFin_not (x : BitVec w) :
    (~~~x).toFin = x.toFin.rev := by
/- To prove that \((\sim x).toFin = x.toFin.rev\), it suffices to show that the natural number values of \((\sim x).toFin\) and \(x.toFin.rev\) are equal, i.e., \(\text{Fin.val}((\sim x).toFin) = \text{Fin.val}(x.toFin.rev)\). -/
  apply Fin.val_inj.mp
/- Using the properties of the `val_toFin`, `toNat_not`, and `Fin.val_rev` functions, we can simplify the proposition we want to show to:
\[
2^w - 1 - x.toNat = 2^w - (x.toNat + 1)
\] -/
  simp only [val_toFin, toNat_not, Fin.val_rev]
/- The equation \(2^w - 1 - x.toNat = 2^w - (x.toNat + 1)\) holds true by simple algebraic manipulation. Specifically, we can simplify the right-hand side:
\[
2^w - (x.toNat + 1) = 2^w - x.toNat - 1
\]
Thus, the equation becomes:
\[
2^w - 1 - x.toNat = 2^w - x.toNat - 1
\]
which is clearly true. This completes the proof. -/
  omega","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44124,BitVec.truncate_xor,"theorem BitVec.truncate_xor {x y : BitVec w} :
    (x ^^^ y).truncate k = x.truncate k ^^^ y.truncate k := by sorry","Truncation Preserves XOR Operation in Bitvectors : For any natural numbers \( w \) and \( k \), and for any bitvectors \( x, y \in \text{BitVec}(w) \), the bitvector obtained by truncating the result of the XOR operation between \( x \) and \( y \) to length \( k \) is equal to the XOR of the bitvectors obtained by truncating \( x \) and \( y \) to length \( k \). In other words, \(\text{truncate}_k(x \^^^ y) = \text{truncate}_k(x) \^^^ \text{truncate}_k(y)\).","theorem BitVec.truncate_xor {x y : BitVec w} :
    (x ^^^ y).truncate k = x.truncate k ^^^ y.truncate k := by
  ext
  simp","To prove the theorem, we need to show that for every \( i \in \{0, 1, \ldots, k-1\} \), the \( i \)-th least significant bit of \(\text{truncate}_k(x \^^^ y)\) is equal to the \( i \)-th least significant bit of \(\text{truncate}_k(x) \^^^ \text{truncate}_k(y)\).

1. **Step 1:**
We introduce a new variable \( i \) to reason about the \( i \)-th least significant bit of the bitvectors involved. This reduces our goal to showing:
\[
(\text{truncate}_k(x \^^^ y)).\text{getLsb}(i) = (\text{truncate}_k(x) \^^^ \text{truncate}_k(y)).\text{getLsb}(i)
\]

2. **Step 2:**
Using the properties of the least significant bit (LSB) and the XOR operation, we can simplify the expression. Specifically, the \( i \)-th least significant bit of \(\text{truncate}_k(x \^^^ y)\) is equal to the \( i \)-th least significant bit of \( x \^^^ y \) for \( i < k \). Similarly, the \( i \)-th least significant bit of \(\text{truncate}_k(x) \^^^ \text{truncate}_k(y)\) is equal to the \( i \)-th least significant bit of \( x \^^^ y \) for \( i < k \). Therefore, the two expressions are equal.

Since the \( i \)-th least significant bit of \(\text{truncate}_k(x \^^^ y)\) is equal to the \( i \)-th least significant bit of \(\text{truncate}_k(x) \^^^ \text{truncate}_k(y)\) for every \( i \in \{0, 1, \ldots, k-1\} \), we conclude that:
\[
\text{truncate}_k(x \^^^ y) = \text{truncate}_k(x) \^^^ \text{truncate}_k(y)
\]

This completes the proof.","theorem BitVec.truncate_xor {x y : BitVec w} :
    (x ^^^ y).truncate k = x.truncate k ^^^ y.truncate k := by
/- To prove that \(\text{truncate}_k(x \^^^ y) = \text{truncate}_k(x) \^^^ \text{truncate}_k(y)\), it suffices to show that for every \( i \in \{0, 1, \ldots, k-1\} \), the \( i \)-th least significant bit of \(\text{truncate}_k(x \^^^ y)\) is equal to the \( i \)-th least significant bit of \(\text{truncate}_k(x) \^^^ \text{truncate}_k(y)\). -/
  ext
/- Using the properties of the least significant bit (LSB) and the XOR operation, we can simplify the expression to show that the \( i \)-th least significant bit of \(\text{truncate}_k(x \^^^ y)\) is indeed equal to the \( i \)-th least significant bit of \(\text{truncate}_k(x) \^^^ \text{truncate}_k(y)\). This simplification is straightforward and follows from the definitions and properties of the bitvector operations. -/
  simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44125,BitVec.shiftLeft_shiftLeft',"theorem BitVec.shiftLeft_shiftLeft' {x : BitVec w₁} {y : BitVec w₂} {z : BitVec w₃} :
    x <<< y <<< z = x <<< (y.toNat + z.toNat) := by sorry","Left Shift of Bitvectors is Associative with Natural Number Addition : For any natural numbers \( w_1, w_2, \) and \( w_3 \), and for any bitvectors \( x \) of width \( w_1 \), \( y \) of width \( w_2 \), and \( z \) of width \( w_3 \), the left shift of \( x \) by \( y \) bits, followed by a left shift of the result by \( z \) bits, is equal to the left shift of \( x \) by the sum of the underlying natural numbers of \( y \) and \( z \) bits. In other words, \( (x \lll y) \lll z = x \lll (y + z) \).","theorem BitVec.shiftLeft_shiftLeft' {x : BitVec w₁} {y : BitVec w₂} {z : BitVec w₃} :
    x <<< y <<< z = x <<< (y.toNat + z.toNat) := by
  simp [shiftLeft_add]","To prove the theorem, we use the property of left shift operations on bitvectors. Specifically, we use the fact that for any bitvector \( x \) of width \( w \) and any natural numbers \( n \) and \( m \), the left shift of \( x \) by \( n + m \) is equivalent to performing the left shift sequentially by \( n \) and then by \( m \). Formally, this property is stated as:
\[ x \lll (n + m) = (x \lll n) \lll m. \]

Given the bitvectors \( x \) of width \( w_1 \), \( y \) of width \( w_2 \), and \( z \) of width \( w_3 \), we need to show:
\[ (x \lll y) \lll z = x \lll (y.toNat + z.toNat). \]

By applying the property of left shift operations, we can rewrite the left-hand side of the equation as:
\[ (x \lll y) \lll z = x \lll (y.toNat + z.toNat). \]

Thus, the left shift of \( x \) by \( y \) bits, followed by a left shift of the result by \( z \) bits, is indeed equal to the left shift of \( x \) by the sum of the underlying natural numbers of \( y \) and \( z \) bits. This completes the proof.","theorem BitVec.shiftLeft_shiftLeft' {x : BitVec w₁} {y : BitVec w₂} {z : BitVec w₃} :
    x <<< y <<< z = x <<< (y.toNat + z.toNat) := by
/- Using the property that the left shift of a bitvector by the sum of two natural numbers is equivalent to performing the left shift sequentially by each of the natural numbers, we can simplify the proposition we want to show. Specifically, we use the fact that for any bitvector \( x \) of width \( w \) and any natural numbers \( n \) and \( m \), \( x \lll (n + m) = (x \lll n) \lll m \). Applying this property, we get that \( x \lll y \lll z = x \lll (y.toNat + z.toNat) \). -/
  simp [shiftLeft_add]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44133,BitVec.shiftLeft_shiftLeft,"theorem BitVec.shiftLeft_shiftLeft {w : Nat} (x : BitVec w) (n m : Nat) :
    (x <<< n) <<< m = x <<< (n + m) := by sorry","Double Left Shift of Bitvector Equals Single Left Shift by Sum of Shifts : For any natural number \( w \) and any bitvector \( x \) of width \( w \), and for any natural numbers \( n \) and \( m \), the left shift operation applied twice, i.e., \( (x \lll n) \lll m \), is equal to the left shift operation applied once with the sum of the shifts, i.e., \( x \lll (n + m) \). This can be written as:
\[ (x \lll n) \lll m = x \lll (n + m) \]","theorem BitVec.shiftLeft_shiftLeft {w : Nat} (x : BitVec w) (n m : Nat) :
    (x <<< n) <<< m = x <<< (n + m) := by
  rw [shiftLeft_add]","To prove the theorem, we use the property of the left shift operation on bitvectors. Specifically, we use the theorem that states for any natural number \( w \), any bitvector \( x \) of width \( w \), and any natural numbers \( n \) and \( m \), the left shift operation on \( x \) by \( n + m \) is equal to the left shift operation on \( x \) by \( n \) followed by the left shift operation by \( m \). Mathematically, this is expressed as:
\[ x \lll (n + m) = (x \lll n) \lll m \]

Using this property, we can rewrite the goal \( (x \lll n) \lll m = x \lll (n + m) \) as:
\[ (x \lll n) \lll m = (x \lll n) \lll m \]

This is a trivial equality, as it states that a value is equal to itself. Therefore, the theorem is proved.

\(\blacksquare\)","theorem BitVec.shiftLeft_shiftLeft {w : Nat} (x : BitVec w) (n m : Nat) :
    (x <<< n) <<< m = x <<< (n + m) := by
/- Since the theorem `BitVec.shiftLeft_add` shows that the left shift operation on \( x \) by \( n + m \) is equivalent to the left shift operation on \( x \) by \( n \) followed by the left shift operation by \( m \), we can replace \( x \lll (n + m) \) with \( (x \lll n) \lll m \). Therefore, our goal \( (x \lll n) \lll m = x \lll (n + m) \) is equivalent to \( (x \lll n) \lll m = (x \lll n) \lll m \), which is trivially true by the properties of equality. -/
  rw [shiftLeft_add]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44134,BitVec.sshiftRight_eq,"theorem BitVec.sshiftRight_eq {x : BitVec n} {i : Nat} :
    x.sshiftRight i = BitVec.ofInt n (x.toInt >>> i) := by sorry","Arithmetic Right Shift of Bitvector Equals Conversion of Right Shifted Integer : For any natural number \( n \), any bitvector \( x \) of width \( n \), and any natural number \( i \), the arithmetic right shift of \( x \) by \( i \) positions, denoted as \( x \gg i \), is equal to the bitvector obtained by converting the integer result of the right shift operation \( x.\text{toInt} \gg i \) back to a bitvector of width \( n \). Formally, \( x.\text{sshiftRight} \, i = \text{BitVec.ofInt} \, n \, (x.\text{toInt} \gg i) \).","theorem BitVec.sshiftRight_eq {x : BitVec n} {i : Nat} :
    x.sshiftRight i = BitVec.ofInt n (x.toInt >>> i) := by
  apply BitVec.eq_of_toInt_eq
  simp [BitVec.sshiftRight]","To prove the theorem, we start by noting that to show \( x.\text{sshiftRight} \, i = \text{BitVec.ofInt} \, n \, (x.\text{toInt} \gg i) \), it suffices to show that the integer representation of \( x.\text{sshiftRight} \, i \) is equal to the integer representation of \( \text{BitVec.ofInt} \, n \, (x.\text{toInt} \gg i) \). This is because if the integer representations of two bitvectors are equal, then the bitvectors themselves are equal.

Next, we use the definition of the arithmetic right shift operation on bitvectors. The arithmetic right shift of a bitvector \( x \) by \( i \) positions, \( x.\text{sshiftRight} \, i \), is defined as the bitvector obtained by converting the integer result of the right shift operation \( x.\text{toInt} \gg i \) back to a bitvector of width \( n \). Therefore, the integer representation of \( x.\text{sshiftRight} \, i \) is exactly \( x.\text{toInt} \gg i \).

Similarly, the integer representation of \( \text{BitVec.ofInt} \, n \, (x.\text{toInt} \gg i) \) is also \( x.\text{toInt} \gg i \). Since both integer representations are equal, we conclude that \( x.\text{sshiftRight} \, i = \text{BitVec.ofInt} \, n \, (x.\text{toInt} \gg i) \).

This completes the proof.","theorem BitVec.sshiftRight_eq {x : BitVec n} {i : Nat} :
    x.sshiftRight i = BitVec.ofInt n (x.toInt >>> i) := by
/- To prove that \( x.\text{sshiftRight} \, i = \text{BitVec.ofInt} \, n \, (x.\text{toInt} \gg i) \), it suffices to show that the integer representation of \( x.\text{sshiftRight} \, i \) is equal to the integer representation of \( \text{BitVec.ofInt} \, n \, (x.\text{toInt} \gg i) \). This is because if the integer representations of two bitvectors are equal, then the bitvectors themselves are equal. -/
  apply BitVec.eq_of_toInt_eq
/- Using the definition of the arithmetic right shift operation on bitvectors, we can simplify the proposition we want to show. The arithmetic right shift of a bitvector \( x \) by \( i \) positions, \( x.\text{sshiftRight} \, i \), is defined as the bitvector obtained by converting the integer result of the right shift operation \( x.\text{toInt} \gg i \) back to a bitvector of width \( n \). Therefore, the integer representation of \( x.\text{sshiftRight} \, i \) is exactly \( x.\text{toInt} \gg i \). This matches the integer representation of \( \text{BitVec.ofInt} \, n \, (x.\text{toInt} \gg i) \), which is also \( x.\text{toInt} \gg i \). Hence, the integer representations are equal, and the proof is complete. -/
  simp [BitVec.sshiftRight]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44136,BitVec.shiftRight_shiftRight,"theorem BitVec.shiftRight_shiftRight {w : Nat} (x : BitVec w) (n m : Nat) :
    (x >>> n) >>> m = x >>> (n + m) := by sorry","Right Shift Composition: \( x >>> n >>> m = x >>> (n + m) \) : For any natural number \( w \) and any bitvector \( x \) of width \( w \), and for any natural numbers \( n \) and \( m \), the right shift operation applied twice, i.e., \( x >>> n >>> m \), is equal to the right shift operation applied once with the sum of \( n \) and \( m \), i.e., \( x >>> (n + m) \).","theorem BitVec.shiftRight_shiftRight {w : Nat} (x : BitVec w) (n m : Nat) :
    (x >>> n) >>> m = x >>> (n + m) := by
  rw [shiftRight_add]","We start with the goal of proving that \( x \>>> n \>>> m = x \>>> (n + m) \). By the theorem that states the right shift of a bitvector \( x \) by \( n + m \) is equivalent to the right shift of \( x \) by \( n \) followed by the right shift of the result by \( m \), we can rewrite the right-hand side of our goal. Specifically, we have:
\[
x \>>> (n + m) = (x \>>> n) \>>> m
\]
Thus, the goal \( x \>>> n \>>> m = x \>>> (n + m) \) becomes:
\[
x \>>> n \>>> m = (x \>>> n) \>>> m
\]
This is trivially true by the properties of equality, as both sides of the equation are identical. Therefore, we have shown that:
\[
x \>>> n \>>> m = x \>>> (n + m)
\]
This completes the proof.","theorem BitVec.shiftRight_shiftRight {w : Nat} (x : BitVec w) (n m : Nat) :
    (x >>> n) >>> m = x >>> (n + m) := by
/- Since the theorem \( \text{BitVec.shiftRight_add} \) shows that the right shift of a bitvector \( x \) by \( n + m \) is equivalent to the right shift of \( x \) by \( n \) followed by the right shift of the result by \( m \), we can replace \( x \>>> (n + m) \) with \( (x \>>> n) \>>> m \) in our goal. Therefore, the goal \( x \>>> n \>>> m = x \>>> (n + m) \) is equivalent to \( x \>>> n \>>> m = x \>>> n \>>> m \), which is trivially true by the properties of equality. -/
  rw [shiftRight_add]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44137,BitVec.shiftRight_add,"theorem BitVec.shiftRight_add {w : Nat} (x : BitVec w) (n m : Nat) :
    x >>> (n + m) = (x >>> n) >>> m := by sorry","Right Shift of Bitvector by Sum of Two Natural Numbers : For any natural number \( w \), any bitvector \( x \) of width \( w \), and any natural numbers \( n \) and \( m \), the right shift of \( x \) by \( n + m \) is equal to the right shift of \( x \) by \( n \) followed by the right shift of the result by \( m \). In other words, \( x \>>> (n + m) = (x \>>> n) \>>> m \).","theorem BitVec.shiftRight_add {w : Nat} (x : BitVec w) (n m : Nat) :
    x >>> (n + m) = (x >>> n) >>> m := by
  ext i
  simp [Nat.add_assoc n m i]","To prove the theorem, we need to show that for every index \( i \) in the bitvector \( x \), the least significant bit (LSB) of \( x \>>> (n + m) \) at position \( i \) is equal to the LSB of \( (x \>>> n) \>>> m \) at position \( i \).

1. **Introduce a new variable \( i \) into the context:**
We introduce a new variable \( i \) to reason about the individual bits of the bitvector \( x \). This allows us to consider the LSB of \( x \>>> (n + m) \) and \( (x \>>> n) \>>> m \) at position \( i \).

2. **Simplify using the associativity of addition:**
Using the associativity of addition, we can rewrite the expression \( (x \>>> (n + m)).\text{getLsb}(i) \) as \( (x \>>> n \>>> m).\text{getLsb}(i) \). This simplification shows that the LSB of \( x \>>> (n + m) \) at position \( i \) is indeed equal to the LSB of \( (x \>>> n) \>>> m \) at position \( i \).

Since this holds for every index \( i \) in the bitvector \( x \), we conclude that \( x \>>> (n + m) = (x \>>> n) \>>> m \). This completes the proof.","theorem BitVec.shiftRight_add {w : Nat} (x : BitVec w) (n m : Nat) :
    x >>> (n + m) = (x >>> n) >>> m := by
/- To prove that \( x \>>> (n + m) = x \>>> n \>>> m \), it suffices to show that for every index \( i \) in the bitvector \( x \), the least significant bit (LSB) of \( x \>>> (n + m) \) at position \( i \) is equal to the LSB of \( (x \>>> n) \>>> m \) at position \( i \). -/
  ext i
/- Using the associativity of addition, we can simplify the expression \( (x \>>> (n + m)).\text{getLsb}(i) \) to \( (x \>>> n \>>> m).\text{getLsb}(i) \). This simplification shows that the LSB of \( x \>>> (n + m) \) at position \( i \) is indeed equal to the LSB of \( (x \>>> n) \>>> m \) at position \( i \). -/
  simp [Nat.add_assoc n m i]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44138,BitVec.add_zero,theorem BitVec.add_zero (x : BitVec n) : x + 0#n = x := by sorry,"Zero Bitvector Addition Identity: \( x + 0#n = x \) : For any natural number \( n \) and any bitvector \( x \) of width \( n \), adding the zero bitvector \( 0#n \) to \( x \) results in \( x \), i.e., \( x + 0#n = x \).","theorem BitVec.add_zero (x : BitVec n) : x + 0#n = x := by
  simp [add_def]","To prove that \( x + 0#n = x \) for any bitvector \( x \) of width \( n \), we use the definition of bitvector addition. According to the definition, adding the zero bitvector \( 0#n \) to any bitvector \( x \) of width \( n \) results in the original bitvector \( x \). Therefore, the proposition \( x + 0#n = x \) holds true. This completes the proof.","theorem BitVec.add_zero (x : BitVec n) : x + 0#n = x := by
  simp [add_def]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44139,BitVec.toNat_cons,"theorem BitVec.toNat_cons (b : Bool) (x : BitVec w) :
    (cons b x).toNat = (b.toNat <<< w) ||| x.toNat := by sorry","Natural Number Representation of Cons Operation in Bitvectors: \((\text{BitVec.cons}(b, x)).\text{toNat} = b.\text{toNat} \<<< w \ ||| x.\text{toNat}\) : For any natural number \( w \), any boolean \( b \), and any bitvector \( x \) of width \( w \), the natural number representation of the bitvector obtained by prepending \( b \) to \( x \) is equal to the natural number representation of \( b \) shifted left by \( w \) positions, bitwise ORed with the natural number representation of \( x \). In other words, \((\text{BitVec.cons}(b, x)).\text{toNat} = b.\text{toNat} \<<< w \ ||| x.\text{toNat}\).","theorem BitVec.toNat_cons (b : Bool) (x : BitVec w) :
    (cons b x).toNat = (b.toNat <<< w) ||| x.toNat := by
  let ⟨x, _⟩ := x
  simp [cons, toNat_append, toNat_ofBool]","We start by decomposing the bitvector \( x \) of width \( w \) into its underlying natural number representation \( x \) and the proof that \( x < 2^w \). Let \( x \) denote the natural number representation of the bitvector \( x \).

Next, we use the definitions of the `BitVec.cons` function, the `toNat_append` function, and the `toNat_ofBool` function to simplify the expression \((\text{BitVec.cons}(b, x)).\text{toNat}\). According to these definitions:
- `BitVec.cons` prepends a single bit \( b \) to the front of the bitvector \( x \).
- `toNat_append` converts the concatenated bitvector to a natural number.
- `toNat_ofBool` converts the boolean \( b \) to a natural number.

By these definitions, the natural number representation of the bitvector obtained by prepending \( b \) to \( x \) is equal to the natural number representation of \( b \) shifted left by \( w \) positions, bitwise ORed with the natural number representation of \( x \). Therefore, we have:
\[
(\text{BitVec.cons}(b, x)).\text{toNat} = b.\text{toNat} \<<< w \ ||| x.\text{toNat}
\]

This completes the proof.","theorem BitVec.toNat_cons (b : Bool) (x : BitVec w) :
    (cons b x).toNat = (b.toNat <<< w) ||| x.toNat := by
/- We decompose the bitvector \( x \) of width \( w \) into its underlying natural number representation \( x \) and the proof that \( x < 2^w \). Let \( x \) denote the natural number representation of the bitvector \( x \). -/
  let ⟨x, _⟩ := x
/- Using the definitions of `BitVec.cons`, `toNat_append`, and `toNat_ofBool`, we simplify the expression \((\text{BitVec.cons}(b, x)).\text{toNat}\) to \( b.\text{toNat} \<<< w \ ||| x.\text{toNat} \). Specifically, the natural number representation of the bitvector obtained by prepending \( b \) to \( x \) is equal to the natural number representation of \( b \) shifted left by \( w \) positions, bitwise ORed with the natural number representation of \( x \). -/
  simp [cons, toNat_append, toNat_ofBool]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44142,BitVec.msb_cons,theorem BitVec.msb_cons : (cons a x).msb = a := by sorry,"Most Significant Bit of Prepended Bitvector : For any boolean value \( a \) and any bitvector \( x \) of width \( w \), the most significant bit of the bitvector obtained by prepending \( a \) to \( x \) is equal to \( a \). In other words, the most significant bit of the bitvector \( \text{BitVec.cons}(a, x) \) is \( a \).","theorem BitVec.msb_cons : (cons a x).msb = a := by
  simp [cons, msb_cast, msb_append]","To prove that the most significant bit of the bitvector obtained by prepending \( a \) to \( x \) is \( a \), we use the following properties and definitions:
1. **Most Significant Bit Preservation under Bitvector Cast:**
\[
\text{if } w = v, \text{ then } \text{msb}(\text{cast}(h, x)) = \text{msb}(x)
\]
This property states that the most significant bit of a bitvector cast to the same width is the same as the most significant bit of the original bitvector.
2. **Most Significant Bit of Concatenated Bitvectors:**
\[
\text{msb}(x \mathbin{\|} y) = \begin{cases}
y.\text{msb} & \text{if } w = 0 \\
x.\text{msb} & \text{otherwise}
\end{cases}
\]
This property states that the most significant bit of the concatenation of two bitvectors is the most significant bit of the first bitvector if the first bitvector is non-empty, otherwise it is the most significant bit of the second bitvector.
3. **Definition of Prepending a Boolean Value:**
The operation \( \text{BitVec.cons}(a, x) \) prepends the boolean value \( a \) to the bitvector \( x \).

Using these properties, we can simplify the expression \( \text{msb}(\text{BitVec.cons}(a, x)) \):
- By the definition of \( \text{BitVec.cons}(a, x) \), this is equivalent to the most significant bit of the bitvector obtained by concatenating a bitvector of width 1 containing \( a \) with \( x \).
- Since the bitvector of width 1 containing \( a \) is non-empty, the most significant bit of the concatenated bitvector is the most significant bit of the bitvector of width 1 containing \( a \), which is \( a \).

Therefore, we have:
\[
\text{msb}(\text{BitVec.cons}(a, x)) = a
\]

This completes the proof.","theorem BitVec.msb_cons : (cons a x).msb = a := by
/- Using the definitions and properties of bitvector concatenation and the most significant bit, we can simplify the proposition we want to show. Specifically, we use the following properties:
1. The most significant bit of a bitvector cast to the same width is the same as the most significant bit of the original bitvector.
2. The most significant bit of the concatenation of two bitvectors is the most significant bit of the first bitvector if the first bitvector is non-empty, otherwise it is the most significant bit of the second bitvector.
3. The definition of prepending a boolean value to a bitvector.

By applying these properties, we can directly conclude that the most significant bit of the bitvector obtained by prepending \( a \) to \( x \) is \( a \). -/
  simp [cons, msb_cast, msb_append]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44145,BitVec.add_comm,theorem BitVec.add_comm (x y : BitVec n) : x + y = y + x := by sorry,"Commutativity of Addition on Bitvectors: \( x + y = y + x \) : For any natural number \( n \) and any two bitvectors \( x \) and \( y \) of width \( n \), the addition operation is commutative, i.e., \( x + y = y + x \).","theorem BitVec.add_comm (x y : BitVec n) : x + y = y + x := by
  simp [add_def, Nat.add_comm]","To prove that the addition of bitvectors is commutative, we start by using the definition of bitvector addition. The addition of bitvectors is defined in terms of the addition of natural numbers. Since the addition of natural numbers is commutative, i.e., for any natural numbers \( a \) and \( b \), \( a + b = b + a \), it follows that the addition of bitvectors is also commutative. Therefore, for any bitvectors \( x \) and \( y \) of width \( n \), we have \( x + y = y + x \). This completes the proof.","theorem BitVec.add_comm (x y : BitVec n) : x + y = y + x := by
/- Using the definition of addition for bitvectors and the commutativity of addition for natural numbers, we can simplify the proposition \( x + y = y + x \) to show that it holds true. Specifically, the definition of bitvector addition and the commutativity of natural number addition together imply that the addition of bitvectors is commutative. -/
  simp [add_def, Nat.add_comm]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44151,BitVec.sub_def,theorem BitVec.sub_def {n} (x y : BitVec n) : x - y = .ofNat n ((2^n - y.toNat) + x.toNat) := by sorry,"Subtraction of Bitvectors: \( x - y = \text{BitVec.ofNat}(n, (2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n) \) : For any natural number \( n \) and any bitvectors \( x, y \) of width \( n \), the subtraction \( x - y \) is defined as the bitvector of width \( n \) corresponding to the natural number \((2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n\). In other words, \( x - y = \text{BitVec.ofNat}(n, (2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n) \).","theorem BitVec.sub_def {n} (x y : BitVec n) : x - y = .ofNat n ((2^n - y.toNat) + x.toNat) := by
  rfl","To prove the theorem, we need to show that the subtraction \( x - y \) of two bitvectors \( x \) and \( y \) of width \( n \) is equal to the bitvector of width \( n \) corresponding to the natural number \((2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n\).

By the definition of bitvector subtraction, \( x - y \) is defined as \(\text{BitVec.ofNat}(n, (2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n)\). Therefore, the equality \( x - y = \text{BitVec.ofNat}(n, (2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n) \) holds by definition. This completes the proof.","theorem BitVec.sub_def {n} (x y : BitVec n) : x - y = .ofNat n ((2^n - y.toNat) + x.toNat) := by
  rfl","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44155,BitVec.zero_add,theorem BitVec.zero_add (x : BitVec n) : 0#n + x = x := by sorry,"Zero Bitvector Addition Identity : For any natural number \( n \) and any bitvector \( x \) of width \( n \), adding the zero bitvector \( 0#n \) to \( x \) results in \( x \), i.e., \( 0#n + x = x \).","theorem BitVec.zero_add (x : BitVec n) : 0#n + x = x := by
  simp [add_def]","To prove the theorem, we start by using the definition of bitvector addition. According to the definition, adding the zero bitvector \( 0#n \) to any bitvector \( x \) of width \( n \) should result in \( x \). Formally, we need to show that \( 0#n + x = x \).

By the definition of bitvector addition, the zero bitvector \( 0#n \) is a bitvector of length \( n \) where all bits are zero. When we add \( 0#n \) to \( x \), each bit of \( x \) remains unchanged because adding zero to any bit does not change the bit. Therefore, the result of the addition is \( x \).

Thus, we have shown that \( 0#n + x = x \). This completes the proof. \(\blacksquare\)","theorem BitVec.zero_add (x : BitVec n) : 0#n + x = x := by
  simp [add_def]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44158,BitVec.mul_def,theorem BitVec.mul_def {n} {x y : BitVec n} : x * y = (ofFin <| x.toFin * y.toFin) := by sorry,"Definition of Bitvector Multiplication: \( x * y = \text{BitVec.ofFin}(x.\text{toFin} * y.\text{toFin}) \) : For any natural number \( n \) and any two bitvectors \( x \) and \( y \) of width \( n \), the product \( x * y \) is defined as the bitvector corresponding to the product of their underlying finite type elements, i.e., \( x * y = \text{BitVec.ofFin}(x.\text{toFin} * y.\text{toFin}) \).","theorem BitVec.mul_def {n} {x y : BitVec n} : x * y = (ofFin <| x.toFin * y.toFin) := by
  rfl","To prove the theorem, we need to show that for any natural number \( n \) and any two bitvectors \( x \) and \( y \) of width \( n \), the product \( x * y \) is equal to the bitvector corresponding to the product of their underlying finite type elements. This is expressed as \( x * y = \{ \text{toFin} := x.\text{toFin} * y.\text{toFin} \} \).

The equality \( x * y = \{ \text{toFin} := x.\text{toFin} * y.\text{toFin} \} \) holds by definition, and it is trivially true due to the reflexive property. Therefore, the theorem is proved.","theorem BitVec.mul_def {n} {x y : BitVec n} : x * y = (ofFin <| x.toFin * y.toFin) := by
  rfl","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44159,BitVec.mul_comm,theorem BitVec.mul_comm (x y : BitVec w) : x * y = y * x := by sorry,"Commutativity of Bitvector Multiplication: \( x * y = y * x \) : For any natural number \( w \), and for any two bitvectors \( x \) and \( y \) of width \( w \), the product \( x * y \) is equal to the product \( y * x \). In other words, bitvector multiplication is commutative.","theorem BitVec.mul_comm (x y : BitVec w) : x * y = y * x := by
  apply eq_of_toFin_eq; simpa using Fin.mul_comm ..","To prove that \( x * y = y * x \) for any bitvectors \( x \) and \( y \) of width \( w \), we use the fact that two bitvectors are equal if and only if their corresponding finite representations are equal. Specifically, we need to show that the finite representation of \( x * y \) is equal to the finite representation of \( y * x \).

By the commutativity of multiplication in the finite type, we know that the finite representation of \( x * y \) is equal to the finite representation of \( y * x \). Therefore, \( x * y = y * x \). This completes the proof.","theorem BitVec.mul_comm (x y : BitVec w) : x * y = y * x := by
/- To prove that \( x * y = y * x \), we use the fact that two bitvectors are equal if and only if their corresponding finite representations are equal. We then simplify the goal using the commutativity of multiplication in the finite representation. Specifically, we use the commutativity of multiplication in the finite type to show that the finite representation of \( x * y \) is equal to the finite representation of \( y * x \). -/
  apply eq_of_toFin_eq; simpa using Fin.mul_comm ..","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44160,BitVec.add_assoc,theorem BitVec.add_assoc (x y z : BitVec n) : x + y + z = x + (y + z) := by sorry,"Associativity of Addition on Bitvectors of Width \( n \) : For any natural number \( n \) and any bitvectors \( x, y, z \) of width \( n \), the addition operation on bitvectors is associative, i.e., \((x + y) + z = x + (y + z)\).","theorem BitVec.add_assoc (x y z : BitVec n) : x + y + z = x + (y + z) := by
  apply eq_of_toNat_eq ; simp [Nat.add_assoc]","To prove the associativity of addition on bitvectors of width \( n \), we need to show that \((x + y) + z = x + (y + z)\) for any bitvectors \( x, y, z \) of width \( n \).

1. **Step 1:**
To prove that \((x + y) + z = x + (y + z)\), it suffices to show that the natural number representation of \((x + y) + z\) is equal to the natural number representation of \(x + (y + z)\). This is because the equality of bitvectors is determined by the equality of their natural number representations.

2. **Step 2:**
Using the associativity of addition on natural numbers, we know that for any natural numbers \(a, b, c\), \((a + b) + c = a + (b + c)\). Therefore, the natural number representation of \((x + y) + z\) is equal to the natural number representation of \(x + (y + z)\).

Thus, we have shown that \((x + y) + z = x + (y + z)\) for any bitvectors \( x, y, z \) of width \( n \). This completes the proof.","theorem BitVec.add_assoc (x y z : BitVec n) : x + y + z = x + (y + z) := by
/- To prove that \((x + y) + z = x + (y + z)\), it suffices to show that the natural number representation of \((x + y) + z\) is equal to the natural number representation of \(x + (y + z)\). This is because the equality of bitvectors is determined by the equality of their natural number representations. Using the associativity of addition on natural numbers, we can simplify the expression to show that the natural number representations are indeed equal. -/
  apply eq_of_toNat_eq ; simp [Nat.add_assoc]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44161,BitVec.toNat_cons',"theorem BitVec.toNat_cons' {x : BitVec w} :
    (cons a x).toNat = (a.toNat <<< w) + x.toNat := by sorry","Natural Number Representation of Prepend Operation in Bitvectors: \((\text{BitVec.cons}(a, x)).\text{toNat} = a.\text{toNat} \<<< w + x.\text{toNat}\) : For any natural number \( w \), any boolean \( a \), and any bitvector \( x \) of width \( w \), the natural number representation of the bitvector obtained by prepending \( a \) to \( x \) is equal to the natural number representation of \( a \) shifted left by \( w \) positions, plus the natural number representation of \( x \). In other words, \((\text{BitVec.cons}(a, x)).\text{toNat} = a.\text{toNat} \<<< w + x.\text{toNat}\).","theorem BitVec.toNat_cons' {x : BitVec w} :
    (cons a x).toNat = (a.toNat <<< w) + x.toNat := by
  simp [cons, Nat.shiftLeft_eq, Nat.mul_comm _ (2^w), Nat.mul_add_lt_is_or, x.isLt]","To prove the theorem, we start with the goal of showing that the natural number representation of the bitvector obtained by prepending \( a \) to \( x \) is equal to the natural number representation of \( a \) shifted left by \( w \) positions, plus the natural number representation of \( x \). We use the following properties and definitions:

1. **Left Shift and Multiplication:**
\[
a \<<< w = a \cdot 2^w
\]
This property states that the left shift of a natural number \( a \) by \( w \) positions is equivalent to multiplying \( a \) by \( 2^w \).

2. **Commutativity of Multiplication:**
\[
a \cdot 2^w = 2^w \cdot a
\]
This property states that the product of \( a \) and \( 2^w \) is the same as the product of \( 2^w \) and \( a \).

3. **Natural Number Representation of Bitvector:**
\[
x.\text{toNat} < 2^w
\]
This property states that the natural number representation of a bitvector \( x \) of length \( w \) is strictly less than \( 2^w \).

4. **Multiplication and Addition Identity:**
\[
2^w \cdot a + x.\text{toNat} = 2^w \cdot a \ ||| \ x.\text{toNat}
\]
This property states that for any natural numbers \( a \) and \( x.\text{toNat} \) such that \( x.\text{toNat} < 2^w \), the sum \( 2^w \cdot a + x.\text{toNat} \) is equal to the disjunction-like operation \( 2^w \cdot a \ ||| \ x.\text{toNat} \).

Using these properties, we can simplify the goal:
\[
(\text{BitVec.cons}(a, x)).\text{toNat} = a.\text{toNat} \<<< w + x.\text{toNat}
\]
By substituting the left shift property and the commutativity of multiplication, we get:
\[
(\text{BitVec.cons}(a, x)).\text{toNat} = a.\text{toNat} \cdot 2^w + x.\text{toNat}
\]
Since \( x.\text{toNat} < 2^w \), we can use the multiplication and addition identity to conclude:
\[
a.\text{toNat} \cdot 2^w + x.\text{toNat} = 2^w \cdot a \ ||| \ x.\text{toNat}
\]
Thus, we have:
\[
(\text{BitVec.cons}(a, x)).\text{toNat} = a.\text{toNat} \<<< w + x.\text{toNat}
\]
This completes the proof.","theorem BitVec.toNat_cons' {x : BitVec w} :
    (cons a x).toNat = (a.toNat <<< w) + x.toNat := by
/- Using the definitions and properties of bitvector concatenation, left shift, and natural number multiplication, we simplify the goal. Specifically, we use the fact that the left shift of a natural number \( a \) by \( w \) positions is equivalent to multiplying \( a \) by \( 2^w \), the commutativity of multiplication, and the property that the natural number representation of a bitvector \( x \) of length \( w \) is less than \( 2^w \). After simplification, we get the desired equality:
\[
(\text{BitVec.cons}(a, x)).\text{toNat} = a.\text{toNat} \<<< w + x.\text{toNat}
\] -/
  simp [cons, Nat.shiftLeft_eq, Nat.mul_comm _ (2^w), Nat.mul_add_lt_is_or, x.isLt]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44163,BitVec.toNat_sub',"theorem BitVec.toNat_sub' {n} (x y : BitVec n) :
    (x - y).toNat = ((x.toNat + (2^n - y.toNat)) % 2^n) := by sorry","Natural Number Representation of Bitvector Subtraction : For any natural number \( n \) and any bitvectors \( x \) and \( y \) of width \( n \), the natural number representation of the bitvector \( x - y \) is given by \((x.toNat + (2^n - y.toNat)) \mod 2^n\).","theorem BitVec.toNat_sub' {n} (x y : BitVec n) :
    (x - y).toNat = ((x.toNat + (2^n - y.toNat)) % 2^n) := by
  rw [toNat_sub, Nat.add_comm]","We start by using the theorem that the natural number representation of the bitvector subtraction \( x - y \) is given by \((2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n\). This transforms our goal into showing that:
\[
(2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n = (x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n
\]
Next, we use the commutativity of addition, which states that for any natural numbers \( a \) and \( b \), \( a + b = b + a \). Applying this property, we can rewrite the left-hand side of the equation as:
\[
(2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n = (x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n
\]
Since both sides of the equation are now identical, the equality holds. Therefore, the natural number representation of the bitvector \( x - y \) is indeed \((x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n\). This completes the proof. \(\blacksquare\)","theorem BitVec.toNat_sub' {n} (x y : BitVec n) :
    (x - y).toNat = ((x.toNat + (2^n - y.toNat)) % 2^n) := by
/- First, we use the theorem that the natural number representation of the bitvector subtraction \( x - y \) is given by \((2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n\). This transforms our goal into showing that \((2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n = (x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n\). Next, we use the commutativity of addition to rewrite the left-hand side of the equation, which gives us \((x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n = (x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n\). -/
  rw [toNat_sub, Nat.add_comm]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44166,BitVec.toNat_neg,theorem BitVec.toNat_neg (x : BitVec n) : (- x).toNat = (2^n - x.toNat) % 2^n := by sorry,"Negation of Bitvector to Natural Number Conversion Modulo \( 2^n \) : For any natural number \( n \) and any bitvector \( x \) of width \( n \), the negation of \( x \), denoted as \( -x \), when converted to a natural number using the `toNat` function, is equal to \((2^n - x.toNat) \mod 2^n\). In other words, \((-x).toNat = (2^n - x.toNat) \mod 2^n\).","theorem BitVec.toNat_neg (x : BitVec n) : (- x).toNat = (2^n - x.toNat) % 2^n := by
  simp [Neg.neg, BitVec.neg]","To prove the theorem, we start by considering the definitions of the negation of a bitvector and the `toNat` function. The negation of a bitvector \( -x \) is defined such that when converted to a natural number, it is equivalent to \((2^n - x.toNat) \mod 2^n\). This is a direct consequence of the definition of the negation operation for bitvectors and the `toNat` function. Therefore, the goal \((-x).toNat = (2^n - x.toNat) \mod 2^n\) is trivially true by these definitions. This completes the proof.","theorem BitVec.toNat_neg (x : BitVec n) : (- x).toNat = (2^n - x.toNat) % 2^n := by
/- Using the definitions of negation for bitvectors and the `toNat` function, we simplify the goal. Specifically, the negation of a bitvector \( -x \) is defined such that when converted to a natural number, it is equivalent to \((2^n - x.toNat) \mod 2^n\). Therefore, the goal \((-x).toNat = (2^n - x.toNat) \mod 2^n\) is trivially true by the definition of negation and the `toNat` function for bitvectors. -/
  simp [Neg.neg, BitVec.neg]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44167,BitVec.ofInt_add,"theorem BitVec.ofInt_add {n} (x y : Int) : BitVec.ofInt n (x + y) =
    BitVec.ofInt n x + BitVec.ofInt n y := by sorry","Addition of Bitvector Representations of Integers Modulo \( 2^n \) : For any natural number \( n \) and any integers \( x \) and \( y \), the bitvector representation of the sum \( x + y \) modulo \( 2^n \) is equal to the sum of the bitvector representations of \( x \) and \( y \) modulo \( 2^n \). In other words, \(\text{BitVec.ofInt}(n, x + y) = \text{BitVec.ofInt}(n, x) + \text{BitVec.ofInt}(n, y)\).","theorem BitVec.ofInt_add {n} (x y : Int) : BitVec.ofInt n (x + y) =
    BitVec.ofInt n x + BitVec.ofInt n y := by
  apply eq_of_toInt_eq
  simp","To prove the theorem, we start by noting that the bitvector representation of an integer \( z \) modulo \( 2^n \) is a bitvector of width \( n \) that represents \( z \mod 2^n \). We need to show that \(\text{BitVec.ofInt}(n, x + y) = \text{BitVec.ofInt}(n, x) + \text{BitVec.ofInt}(n, y)\).

1. **Step 1:**
To prove that the bitvector representation of the sum \( x + y \) modulo \( 2^n \) is equal to the sum of the bitvector representations of \( x \) and \( y \) modulo \( 2^n \), it suffices to show that the integer representation of \(\text{BitVec.ofInt}(n, x + y)\) is equal to the integer representation of \(\text{BitVec.ofInt}(n, x) + \text{BitVec.ofInt}(n, y)\). This is because if the integer representations are equal, then the bitvectors themselves are equal.

2. **Step 2:**
Using the properties of the integer representation of bitvectors and the properties of addition, we can simplify the proposition we want to show to the equality of the integer representations, which is trivially true. Specifically, the integer representation of \(\text{BitVec.ofInt}(n, x + y)\) is \( (x + y) \mod 2^n \), and the integer representation of \(\text{BitVec.ofInt}(n, x) + \text{BitVec.ofInt}(n, y)\) is \((x \mod 2^n) + (y \mod 2^n) \mod 2^n\). Since \((x + y) \mod 2^n = (x \mod 2^n + y \mod 2^n) \mod 2^n\), the equality holds.

Therefore, we have shown that \(\text{BitVec.ofInt}(n, x + y) = \text{BitVec.ofInt}(n, x) + \text{BitVec.ofInt}(n, y)\). This completes the proof. \(\blacksquare\)","theorem BitVec.ofInt_add {n} (x y : Int) : BitVec.ofInt n (x + y) =
    BitVec.ofInt n x + BitVec.ofInt n y := by
/- To prove that the bitvector representation of the sum \( x + y \) modulo \( 2^n \) is equal to the sum of the bitvector representations of \( x \) and \( y \) modulo \( 2^n \), it suffices to show that the integer representation of \(\text{BitVec.ofInt}(n, x + y)\) is equal to the integer representation of \(\text{BitVec.ofInt}(n, x) + \text{BitVec.ofInt}(n, y)\). -/
  apply eq_of_toInt_eq
/- Using the properties of the integer representation of bitvectors and the properties of addition, we can simplify the proposition we want to show to the equality of the integer representations, which is trivially true. -/
  simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44168,BitVec.neg_zero,theorem BitVec.neg_zero (n:Nat) : -BitVec.ofNat n 0 = BitVec.ofNat n 0 := by sorry,"Negation of Zero Bitvector is Zero: \(-0_n = 0_n\) : For any natural number \( n \), the negation of the zero bitvector of width \( n \) is equal to the zero bitvector of width \( n \), i.e., \(-0_n = 0_n\).","theorem BitVec.neg_zero (n:Nat) : -BitVec.ofNat n 0 = BitVec.ofNat n 0 := by
  apply eq_of_toNat_eq ; simp","To prove that \(-0_n = 0_n\), we use the fact that two bitvectors are equal if and only if their natural number representations are equal. Therefore, it suffices to show that the natural number representation of \(-0_n\) is equal to the natural number representation of \(0_n\). In other words, we need to show that \((-0_n).\text{toNat} = (0_n).\text{toNat}\).

Since \(0_n\) is the zero bitvector of width \( n \), its natural number representation is \(0\). The negation of \(0_n\) is also a bitvector of width \( n \), and its natural number representation is also \(0\). Therefore, \((-0_n).\text{toNat} = 0\) and \((0_n).\text{toNat} = 0\).

Thus, \((-0_n).\text{toNat} = (0_n).\text{toNat}\), which implies that \(-0_n = 0_n\).

This completes the proof.","theorem BitVec.neg_zero (n:Nat) : -BitVec.ofNat n 0 = BitVec.ofNat n 0 := by
  apply eq_of_toNat_eq ; simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44171,BitVec.mul_assoc,theorem BitVec.mul_assoc (x y z : BitVec w) : x * y * z = x * (y * z) := by sorry,"Associativity of Bitvector Multiplication: \((x * y) * z = x * (y * z)\) : For any natural number \( w \) and any bitvectors \( x, y, z \) of width \( w \), the multiplication operation is associative, i.e., \((x * y) * z = x * (y * z)\).","theorem BitVec.mul_assoc (x y z : BitVec w) : x * y * z = x * (y * z) := by
  apply eq_of_toFin_eq; simpa using Fin.mul_assoc ..","To prove the associativity of bitvector multiplication, we need to show that \((x * y) * z = x * (y * z)\) for any bitvectors \( x, y, z \) of width \( w \).

We start by considering the corresponding finite field elements of these bitvectors. Specifically, we use the function \(\text{toFin}\) to map the bitvectors \( x, y, z \) to elements in the finite field \(\mathbb{F}_{2^w}\). The associativity of multiplication in the finite field \(\mathbb{F}_{2^w}\) is a well-known property, which states that for any elements \( a, b, c \in \mathbb{F}_{2^w} \), \((a * b) * c = a * (b * c)\).

Thus, we have:
\[
(\text{toFin } x) * (\text{toFin } y) * (\text{toFin } z) = \text{toFin } x * (\text{toFin } y * \text{toFin } z)
\]

By the definition of the \(\text{toFin}\) function and the properties of bitvector multiplication, this equality implies:
\[
(x * y) * z = x * (y * z)
\]

Therefore, the multiplication operation on bitvectors is associative. This completes the proof.","theorem BitVec.mul_assoc (x y z : BitVec w) : x * y * z = x * (y * z) := by
/- To prove that \((x * y) * z = x * (y * z)\), it suffices to show that the corresponding finite field elements satisfy the same equality. Specifically, we use the fact that the multiplication of finite field elements is associative, i.e., \((\text{toFin } x) * (\text{toFin } y) * (\text{toFin } z) = \text{toFin } x * (\text{toFin } y * \text{toFin } z)\). After simplifying this expression using the associativity of multiplication in the finite field, we get the desired result. -/
  apply eq_of_toFin_eq; simpa using Fin.mul_assoc ..","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44173,BitVec.one_mul,theorem BitVec.one_mul (x : BitVec w) : 1#w * x = x := by sorry,"Multiplication by One on Bitvectors of Fixed Width: \( 1 * x = x \) : For any natural number \( w \) and any bitvector \( x \) of width \( w \), the product of the bitvector \( 1 \) of width \( w \) and \( x \) is equal to \( x \), i.e., \( 1 * x = x \).","theorem BitVec.one_mul (x : BitVec w) : 1#w * x = x := by
  rw [BitVec.mul_comm, BitVec.mul_one]","To prove that for any natural number \( w \) and any bitvector \( x \) of width \( w \), the product \( 1 \# w * x \) is equal to \( x \), we proceed as follows:

1. **Commutativity of Multiplication:**
By the commutativity of multiplication in the context of bitvectors, we have:
\[
1 \# w * x = x * 1 \# w
\]

2. **Multiplicative Identity:**
Using the property of the multiplicative identity, we know that:
\[
x * 1 \# w = x
\]

3. **Conclusion:**
Combining these two steps, we get:
\[
1 \# w * x = x
\]
This completes the proof.

Thus, for any bitvector \( x \) of width \( w \), the product \( 1 \# w * x \) is indeed equal to \( x \).","theorem BitVec.one_mul (x : BitVec w) : 1#w * x = x := by
/- First, we use the commutativity of multiplication to rewrite the goal \( 1 \# w * x = x \) as \( x * 1 \# w = x \). Then, we use the property of the multiplicative identity to simplify \( x * 1 \# w \) to \( x \). Therefore, the goal \( x * 1 \# w = x \) is equivalent to \( x = x \), which is trivially true. -/
  rw [BitVec.mul_comm, BitVec.mul_one]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44175,BitVec.rotateLeft_mod_eq_rotateLeft,"theorem BitVec.rotateLeft_mod_eq_rotateLeft {x : BitVec w} {r : Nat} :
    x.rotateLeft (r % w) = x.rotateLeft r := by sorry","Left Rotation of Bitvector is Invariant under Modulo Width : For any natural number \( w \) and any bitvector \( x \) of width \( w \), and for any natural number \( r \), the left rotation of \( x \) by \( r \mod w \) is equal to the left rotation of \( x \) by \( r \). In other words, \( x.\text{rotateLeft}(r \mod w) = x.\text{rotateLeft}(r) \).","theorem BitVec.rotateLeft_mod_eq_rotateLeft {x : BitVec w} {r : Nat} :
    x.rotateLeft (r % w) = x.rotateLeft r := by
  simp only [rotateLeft, Nat.mod_mod]","To prove the theorem, we start by using the definition of the left rotation operation and the property of the modulo operation. Specifically, we use the fact that for any natural numbers \( a \) and \( n \), the identity \((a \% n) \% n = a \% n\) holds. This means that the expression \( r \% w \) is equivalent to \( r \) when taken modulo \( w \). Therefore, the left rotation of \( x \) by \( r \% w \) is the same as the left rotation of \( x \) by \( r \). Hence, we have:
\[
x.\text{rotateLeft}(r \% w) = x.\text{rotateLeft}(r)
\]
This completes the proof.","theorem BitVec.rotateLeft_mod_eq_rotateLeft {x : BitVec w} {r : Nat} :
    x.rotateLeft (r % w) = x.rotateLeft r := by
/- Using the definition of the left rotation operation and the property of modulo operation, we can simplify the proposition we want to show. Specifically, we use the fact that for any natural numbers \( a \) and \( n \), the identity \((a \% n) \% n = a \% n\) holds. This simplification shows that the left rotation of \( x \) by \( r \% w \) is equal to the left rotation of \( x \) by \( r \). -/
  simp only [rotateLeft, Nat.mod_mod]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44176,BitVec.ofNat_lt_ofNat,theorem BitVec.ofNat_lt_ofNat {n} (x y : Nat) : BitVec.ofNat n x < BitVec.ofNat n y ↔ x % 2^n < y % 2^n := by sorry,"Bitvector Strict Inequality from Natural Number Modulo Comparison : For any natural number \( n \) and any two natural numbers \( x \) and \( y \), the bitvector \( \text{BitVec.ofNat } n \, x \) is strictly less than the bitvector \( \text{BitVec.ofNat } n \, y \) if and only if \( x \mod 2^n \) is strictly less than \( y \mod 2^n \). In other words, \( \text{BitVec.ofNat } n \, x < \text{BitVec.ofNat } n \, y \) if and only if \( x \% 2^n < y \% 2^n \).","theorem BitVec.ofNat_lt_ofNat {n} (x y : Nat) : BitVec.ofNat n x < BitVec.ofNat n y ↔ x % 2^n < y % 2^n := by
  simp [lt_def]","To prove the theorem, we start by using the definition of the less-than relation on bitvectors. The less-than relation on bitvectors of width \( n \) is defined in terms of the modulo operation. Specifically, the statement \( \text{BitVec.ofNat } n \, x < \text{BitVec.ofNat } n \, y \) is equivalent to \( x \% 2^n < y \% 2^n \).

Thus, the original statement \( \text{BitVec.ofNat } n \, x < \text{BitVec.ofNat } n \, y \) is true if and only if \( x \% 2^n < y \% 2^n \). This completes the proof.","theorem BitVec.ofNat_lt_ofNat {n} (x y : Nat) : BitVec.ofNat n x < BitVec.ofNat n y ↔ x % 2^n < y % 2^n := by
/- Using the definition of the less-than relation on bitvectors, we simplify the proposition we want to show. Specifically, the less-than relation on bitvectors of width \( n \) is defined in terms of the modulo operation. Therefore, the statement \( \text{BitVec.ofNat } n \, x < \text{BitVec.ofNat } n \, y \) is equivalent to \( x \% 2^n < y \% 2^n \). -/
  simp [lt_def]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44180,BitVec.rotateRight_mod_eq_rotateRight,"theorem BitVec.rotateRight_mod_eq_rotateRight {x : BitVec w} {r : Nat} :
    x.rotateRight (r % w) = x.rotateRight r := by sorry","Right Rotation of Bitvector is Invariant Under Modulo Bitwidth: \( x.\text{rotateRight}(r \% w) = x.\text{rotateRight}(r) \) : For any natural number \( w \) and any bitvector \( x \) of width \( w \), and for any natural number \( r \), the right rotation of \( x \) by \( r \% w \) positions is equal to the right rotation of \( x \) by \( r \) positions, i.e., \( x.\text{rotateRight}(r \% w) = x.\text{rotateRight}(r) \).","theorem BitVec.rotateRight_mod_eq_rotateRight {x : BitVec w} {r : Nat} :
    x.rotateRight (r % w) = x.rotateRight r := by
  simp only [rotateRight, Nat.mod_mod]","To prove the theorem, we start by using the definition of the right rotation operation and the property of the modulo operation. Specifically, we use the fact that for any natural numbers \( a \) and \( n \), the identity \((a \% n) \% n = a \% n\) holds. This means that the right rotation of \( x \) by \( r \% w \) positions is the same as the right rotation of \( x \) by \( r \) positions. Therefore, we have:
\[
x.\text{rotateRight}(r \% w) = x.\text{rotateRight}(r)
\]
This completes the proof.","theorem BitVec.rotateRight_mod_eq_rotateRight {x : BitVec w} {r : Nat} :
    x.rotateRight (r % w) = x.rotateRight r := by
/- Using the definition of the right rotation operation and the property of modulo operation, we can simplify the proposition we want to show. Specifically, we use the fact that for any natural numbers \( a \) and \( n \), the identity \((a \% n) \% n = a \% n\) holds. This simplification shows that the right rotation of \( x \) by \( r \% w \) positions is equal to the right rotation of \( x \) by \( r \) positions. -/
  simp only [rotateRight, Nat.mod_mod]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44181,BitVec.negOne_eq_allOnes,theorem BitVec.negOne_eq_allOnes : -1#w = allOnes w := by sorry,"Negation of One in Bitvector Equals All Ones: \(-1_w = \text{allOnes}(w)\) : For any natural number \( w \), the negation of the bitvector \( 1 \) of width \( w \), denoted as \( -1_w \), is equal to the bitvector of width \( w \) where all bits are set to 1, i.e., \( -1_w = \text{allOnes}(w) \).","theorem BitVec.negOne_eq_allOnes : -1#w = allOnes w := by
  apply eq_of_toNat_eq
  if g : w = 0 then
    simp [g]
  else
    have q : 1 < 2^w := by simp [g]
    have r : (2^w - 1) < 2^w := by omega
    simp [Nat.mod_eq_of_lt q, Nat.mod_eq_of_lt r]","To prove that \(-1_w = \text{allOnes}(w)\), it suffices to show that the natural number representation of \(-1_w\) is equal to the natural number representation of \(\text{allOnes}(w)\). In other words, we need to show that \((-1_w).\text{toNat} = (\text{allOnes}(w)).\text{toNat}\).

We establish two intermediate results:
1. \(1 < 2^w\), which is true because \(2^w\) is always greater than 1 for any natural number \(w\).
2. \(2^w - 1 < 2^w\), which is true because \(2^w - 1\) is always less than \(2^w\).

Using these results, we can simplify the natural number representations:
- The natural number representation of \(-1_w\) is \((2^w - 1) \mod 2^w\), which simplifies to \(2^w - 1\) because \(2^w - 1 < 2^w\).
- The natural number representation of \(\text{allOnes}(w)\) is also \(2^w - 1\).

Thus, \((-1_w).\text{toNat} = 2^w - 1\) and \((\text{allOnes}(w)).\text{toNat} = 2^w - 1\), which means \((-1_w).\text{toNat} = (\text{allOnes}(w)).\text{toNat}\).

Therefore, \(-1_w = \text{allOnes}(w)\). This completes the proof.","theorem BitVec.negOne_eq_allOnes : -1#w = allOnes w := by
/- To prove that \(-1_w = \text{allOnes}(w)\), it suffices to show that the natural number representation of \(-1_w\) is equal to the natural number representation of \(\text{allOnes}(w)\). In other words, we need to show that \((-1_w).\text{toNat} = (\text{allOnes}(w)).\text{toNat}\). -/
  apply eq_of_toNat_eq
  if g : w = 0 then
    simp [g]
/- We need to show that \((-1_w).\text{toNat} = (\text{allOnes}(w)).\text{toNat}\). To do this, we first establish two intermediate results:
1. \(1 < 2^w\), which is true because \(2^w\) is always greater than 1 for any natural number \(w\).
2. \(2^w - 1 < 2^w\), which is true because \(2^w - 1\) is always less than \(2^w\).

Using these results, we can simplify the natural number representations:
- The natural number representation of \(-1_w\) is \((2^w - 1) \mod 2^w\), which simplifies to \(2^w - 1\) because \(2^w - 1 < 2^w\).
- The natural number representation of \(\text{allOnes}(w)\) is also \(2^w - 1\).

Thus, \((-1_w).\text{toNat} = 2^w - 1\) and \((\text{allOnes}(w)).\text{toNat} = 2^w - 1\), which means \((-1_w).\text{toNat} = (\text{allOnes}(w)).\text{toNat}\). -/
  else
    have q : 1 < 2^w := by simp [g]
    have r : (2^w - 1) < 2^w := by omega
    simp [Nat.mod_eq_of_lt q, Nat.mod_eq_of_lt r]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44182,BitVec.ofNat_le_ofNat,theorem BitVec.ofNat_le_ofNat {n} (x y : Nat) : (BitVec.ofNat n x) ≤ (BitVec.ofNat n y) ↔ x % 2^n ≤ y % 2^n := by sorry,"Bitvector Less-Than or Equal Relation via Modulo: \( \text{BitVec.ofNat } n \, x \leq \text{BitVec.ofNat } n \, y \leftrightarrow x \% 2^n \leq y \% 2^n \) : For any natural number \( n \) and any two natural numbers \( x \) and \( y \), the bitvector \( \text{BitVec.ofNat } n \, x \) is less than or equal to the bitvector \( \text{BitVec.ofNat } n \, y \) if and only if \( x \mod 2^n \) is less than or equal to \( y \mod 2^n \). In other words, \( \text{BitVec.ofNat } n \, x \leq \text{BitVec.ofNat } n \, y \) if and only if \( x \% 2^n \leq y \% 2^n \).","theorem BitVec.ofNat_le_ofNat {n} (x y : Nat) : (BitVec.ofNat n x) ≤ (BitVec.ofNat n y) ↔ x % 2^n ≤ y % 2^n := by
  simp [le_def]","To prove the theorem, we start by using the definition of the less-than-or-equal-to relation on bitvectors. Specifically, we need to show that \( \text{BitVec.ofNat } n \, x \leq \text{BitVec.ofNat } n \, y \) if and only if \( x \% 2^n \leq y \% 2^n \).

1. **Simplification:**
Using the definition of the less-than-or-equal-to relation, we simplify the proposition we want to show. The goal is to prove that \( \text{BitVec.ofNat } n \, x \leq \text{BitVec.ofNat } n \, y \) if and only if \( x \% 2^n \leq y \% 2^n \). This simplification is straightforward and follows from the definition of the less-than-or-equal-to relation on bitvectors.

2. **Conclusion:**
After simplification, the proposition is trivially true. Therefore, we have shown that \( \text{BitVec.ofNat } n \, x \leq \text{BitVec.ofNat } n \, y \) if and only if \( x \% 2^n \leq y \% 2^n \).

This completes the proof.","theorem BitVec.ofNat_le_ofNat {n} (x y : Nat) : (BitVec.ofNat n x) ≤ (BitVec.ofNat n y) ↔ x % 2^n ≤ y % 2^n := by
/- Using the definition of the less-than-or-equal-to relation, we simplify the proposition we want to show. The goal is to prove that \( \text{BitVec.ofNat } n \, x \leq \text{BitVec.ofNat } n \, y \) if and only if \( x \% 2^n \leq y \% 2^n \). This simplification is straightforward and follows from the definition of the less-than-or-equal-to relation on bitvectors. -/
  simp [le_def]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44184,BitVec.eq_sub_iff_add_eq,theorem BitVec.eq_sub_iff_add_eq {x y z : BitVec w} : x = z - y ↔ x + y = z := by sorry,"Equivalence of Subtraction and Addition in Bitvectors: \( x = z - y \leftrightarrow x + y = z \) : For any natural number \( w \) and bitvectors \( x, y, z \) of width \( w \), the equation \( x = z - y \) holds if and only if \( x + y = z \).","theorem BitVec.eq_sub_iff_add_eq {x y z : BitVec w} : x = z - y ↔ x + y = z := by
  apply Iff.intro <;> intro h
  · simp [h, sub_add_cancel]
  · simp [←h, add_sub_cancel]","To prove the equivalence \( x = z - y \leftrightarrow x + y = z \), we need to show both directions:

1. **(\( x = z - y \to x + y = z \))**:
- Assume \( x = z - y \).
- Using the property that subtraction and addition cancel each other in additive groups (i.e., \( a - b + b = a \)), we have:
\[
x + y = (z - y) + y = z
\]
- Therefore, \( x + y = z \).

2. **(\( x + y = z \to x = z - y \))**:
- Assume \( x + y = z \).
- Using the property that addition and subtraction cancel in additive commutative groups (i.e., \( a + (b - a) = b \)), we have:
\[
x = z - y = (x + y) - y = x
\]
- Therefore, \( x = z - y \).

Since both directions are proven, we conclude that \( x = z - y \leftrightarrow x + y = z \). This completes the proof.","theorem BitVec.eq_sub_iff_add_eq {x y z : BitVec w} : x = z - y ↔ x + y = z := by
/- To prove the equivalence \( x = z - y \leftrightarrow x + y = z \), it suffices to show both directions: \( x = z - y \to x + y = z \) and \( x + y = z \to x = z - y \). We introduce the hypothesis \( h \) for each direction. -/
  apply Iff.intro <;> intro h
/- First, we show that if \( x = z - y \), then \( x + y = z \). Using the hypothesis \( h : x = z - y \) and the property that subtraction and addition cancel each other in additive groups (i.e., \( a - b + b = a \)), we can simplify the goal to \( x + y = z \). Since \( x = z - y \), substituting \( x \) in the equation \( x + y = z \) gives \( (z - y) + y = z \), which simplifies to \( z = z \), which is true. Therefore, \( x + y = z \). -/
  · simp [h, sub_add_cancel]
/- Next, we show that if \( x + y = z \), then \( x = z - y \). Using the hypothesis \( h : x + y = z \) and the property that addition and subtraction cancel in additive commutative groups (i.e., \( a + (b - a) = b \)), we can simplify the goal to \( x = z - y \). Since \( x + y = z \), substituting \( z \) in the equation \( x = z - y \) gives \( x = (x + y) - y \), which simplifies to \( x = x \), which is true. Therefore, \( x = z - y \). -/
  · simp [←h, add_sub_cancel]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44186,BitVec.BitVec.mul_zero,theorem BitVec.BitVec.mul_zero {x : BitVec w} : x * 0#w = 0#w := by sorry,"Multiplication by Zero Bitvector Results in Zero Bitvector : For any natural number \( w \) and any bitvector \( x \) of width \( w \), the product of \( x \) and the zero bitvector of width \( w \) is the zero bitvector of width \( w \). In other words, \( x * 0_w = 0_w \).","theorem BitVec.BitVec.mul_zero {x : BitVec w} : x * 0#w = 0#w := by
  apply eq_of_toNat_eq
  simp [toNat_mul]","To prove that \( x * 0_w = 0_w \), we use the fact that two bitvectors are equal if and only if their natural number representations are equal. Therefore, it suffices to show that the natural number representation of \( x * 0_w \) is equal to the natural number representation of \( 0_w \).

We start by noting that the natural number representation of the product of two bitvectors is the product of their natural number representations. Thus, \((x * 0_w).\text{toNat} = x.\text{toNat} * 0\). Since the product of any natural number with 0 is 0, we have \( x.\text{toNat} * 0 = 0 \). Therefore, \((x * 0_w).\text{toNat} = 0\).

The natural number representation of the zero bitvector \( 0_w \) is 0, so \((0_w).\text{toNat} = 0\). Hence, \((x * 0_w).\text{toNat} = (0_w).\text{toNat}\).

By the property of bitvector equality, if the natural number representations of two bitvectors are equal, then the bitvectors themselves are equal. Therefore, \( x * 0_w = 0_w \).

This completes the proof.","theorem BitVec.BitVec.mul_zero {x : BitVec w} : x * 0#w = 0#w := by
/- To prove that \( x * 0_w = 0_w \), it suffices to show that the natural number representation of \( x * 0_w \) is equal to the natural number representation of \( 0_w \). In other words, we need to show that \((x * 0_w).\text{toNat} = (0_w).\text{toNat}\). -/
  apply eq_of_toNat_eq
/- Using the property that the natural number representation of the product of two bitvectors is the product of their natural number representations, we can simplify the proposition we want to show. Specifically, \((x * 0_w).\text{toNat} = x.\text{toNat} * 0\). Since the product of any natural number with 0 is 0, we have \( x.\text{toNat} * 0 = 0 \). Therefore, \((x * 0_w).\text{toNat} = 0\). Since the natural number representation of \( 0_w \) is 0, we have \((0_w).\text{toNat} = 0\). Thus, \((x * 0_w).\text{toNat} = (0_w).\text{toNat}\). -/
  simp [toNat_mul]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec
open BitVec

"
44187,BitVec.sub_toAdd,theorem BitVec.sub_toAdd {n} (x y : BitVec n) : x - y = x + - y := by sorry,"Subtraction as Addition of Negation in Bitvectors of Specified Width : For any natural number \( n \) and any bitvectors \( x \) and \( y \) of width \( n \), the subtraction of \( y \) from \( x \) is equal to the addition of \( x \) and the negation of \( y \), i.e., \( x - y = x + (-y) \).","theorem BitVec.sub_toAdd {n} (x y : BitVec n) : x - y = x + - y := by
  apply eq_of_toNat_eq
  simp
  rw [Nat.add_comm]","To prove that \( x - y = x + (-y) \), we start by showing that the natural number representation of \( x - y \) is equal to the natural number representation of \( x + (-y) \). This means we need to show:
\[
(x - y).\text{toNat} = (x + (-y)).\text{toNat}
\]

Using the properties of natural number addition and the definition of bitvector negation, we can simplify the left-hand side and the right-hand side. Specifically, we have:
\[
(x - y).\text{toNat} = (2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n
\]
and
\[
(x + (-y)).\text{toNat} = (x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n
\]

By the commutativity of addition in natural numbers, we know that:
\[
2^n - y.\text{toNat} + x.\text{toNat} = x.\text{toNat} + (2^n - y.\text{toNat})
\]

Thus, the simplified goal is:
\[
(x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n = (x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n
\]

This is trivially true by the properties of equality. Therefore, we have shown that:
\[
(x - y).\text{toNat} = (x + (-y)).\text{toNat}
\]

By the theorem that if the natural number representation of two bitvectors is equal, then the bitvectors themselves are equal, we conclude that:
\[
x - y = x + (-y)
\]

This completes the proof.","theorem BitVec.sub_toAdd {n} (x y : BitVec n) : x - y = x + - y := by
/- To prove that \( x - y = x + (-y) \), it suffices to show that the natural number representation of \( x - y \) is equal to the natural number representation of \( x + (-y) \), i.e., \( (x - y).\text{toNat} = (x + (-y)).\text{toNat} \). -/
  apply eq_of_toNat_eq
/- Using the properties of natural number addition and the definition of bitvector negation, we can simplify the proposition we want to show to:
\[
(2^n - y.\text{toNat} + x.\text{toNat}) \mod 2^n = (x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n
\] -/
  simp
/- Since the commutativity of addition in natural numbers shows that \( a + b = b + a \), we can replace \( 2^n - y.\text{toNat} + x.\text{toNat} \) with \( x.\text{toNat} + (2^n - y.\text{toNat}) \). Therefore, the goal is now:
\[
(x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n = (x.\text{toNat} + (2^n - y.\text{toNat})) \mod 2^n
\]
This is trivially true by the properties of equality. -/
  rw [Nat.add_comm]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44188,BitVec.mul_one,theorem BitVec.mul_one (x : BitVec w) : x * 1#w = x := by sorry,"Multiplication by One on Bitvectors of Fixed Width : For any natural number \( w \) and any bitvector \( x \) of width \( w \), the product of \( x \) and the bitvector \( 1 \) of width \( w \) is equal to \( x \), i.e., \( x * 1 = x \).","theorem BitVec.mul_one (x : BitVec w) : x * 1#w = x := by
  cases w
  · apply Subsingleton.elim
  · apply eq_of_toNat_eq; simp [Nat.mod_eq_of_lt]","We will consider every possible case of the natural number \( w \).

1. **Case 1: \( w = 0 \)**
- The type of bitvectors of width 0 is a subsingleton, meaning that any two elements of this type are equal.
- Therefore, for any bitvector \( x \) of width 0, \( x * 1#0 = x \) holds trivially.

2. **Case 2: \( w = n + 1 \) for some natural number \( n \)**
- We need to show that \( x * 1#(n + 1) = x \).
- To do this, we use the theorem that if the natural number representation of two bitvectors of the same width are equal, then the bitvectors themselves are equal.
- Thus, it suffices to show that the natural number representation of \( x * 1#(n + 1) \) is equal to the natural number representation of \( x \).
- Using the property of natural numbers, we simplify the expression to show that \( (x * 1#(n + 1)).\text{toNat} = x.\text{toNat} \).

Since both cases are covered, we conclude that for any natural number \( w \) and any bitvector \( x \) of width \( w \), \( x * 1 = x \). This completes the proof.","theorem BitVec.mul_one (x : BitVec w) : x * 1#w = x := by
/- We will consider every possible case of the natural number \( w \). Case 1: \( w = 0 \). Case 2: \( w = n + 1 \) for some natural number \( n \). -/
  cases w
/- For the case \( w = 0 \), we use the fact that the type of bitvectors of width 0 is a subsingleton. This means that any two elements of this type are equal. Therefore, \( x * 1#0 = x \) holds trivially. -/
  · apply Subsingleton.elim
/- For the case \( w = n + 1 \), we need to show that \( x * 1#(n + 1) = x \). To do this, we use the theorem that if the natural number representation of two bitvectors of the same width are equal, then the bitvectors themselves are equal. Thus, it suffices to show that the natural number representation of \( x * 1#(n + 1) \) is equal to the natural number representation of \( x \). Using the property of natural numbers, we simplify the expression to show that \( (x * 1#(n + 1)).\text{toNat} = x.\text{toNat} \). -/
  · apply eq_of_toNat_eq; simp [Nat.mod_eq_of_lt]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44189,BitVec.sub_add_cancel,theorem BitVec.sub_add_cancel (x y : BitVec w) : x - y + y = x := by sorry,"Subtraction and Addition Cancellation: \( x - y + y = x \) : For any natural number \( w \) and any bitvectors \( x, y \) of width \( w \), the expression \( x - y + y \) is equal to \( x \), i.e., \( x - y + y = x \).","theorem BitVec.sub_add_cancel (x y : BitVec w) : x - y + y = x := by
  rw [sub_toAdd, BitVec.add_assoc, BitVec.add_comm _ y,
      ← BitVec.add_assoc, ← sub_toAdd, add_sub_cancel]","To prove that \( x - y + y = x \), we start by using the property that subtraction can be expressed as addition of the negation:
\[ x - y = x + (-y). \]
Thus, the goal \( x - y + y = x \) can be rewritten as:
\[ x + (-y) + y = x. \]

Next, we use the associativity of addition:
\[ x + ((-y) + y) = x. \]

We then use the commutativity of addition:
\[ x + (y + (-y)) = x. \]

Using the associativity of addition again:
\[ x + y + (-y) = x. \]

We use the property that subtraction can be expressed as addition of the negation in reverse:
\[ x + y - y = x. \]

Finally, we use the property that addition and subtraction cancel each other out in an additive commutative group:
\[ x + (y - y) = x. \]

This simplifies to:
\[ x = x, \]
which is trivially true. Therefore, we have shown that \( x - y + y = x \). This completes the proof. \(\blacksquare\)","theorem BitVec.sub_add_cancel (x y : BitVec w) : x - y + y = x := by
/- We start by rewriting the goal using several properties of bitvectors and addition. First, we use the property that subtraction can be expressed as addition of the negation, i.e., \( x - y = x + (-y) \). This transforms the goal \( x - y + y = x \) into \( x + (-y) + y = x \).

Next, we use the associativity of addition, \( a + (b + c) = (a + b) + c \), to rewrite \( x + (-y) + y \) as \( x + ((-y) + y) \).

Then, we use the commutativity of addition, \( a + b = b + a \), to rewrite \( (-y) + y \) as \( y + (-y) \). This gives us \( x + (y + (-y)) \).

We use the associativity of addition again to rewrite \( x + (y + (-y)) \) as \( x + y + (-y) \).

Next, we use the property that subtraction can be expressed as addition of the negation in reverse, i.e., \( x + y - y = x + (y + (-y)) \). This simplifies to \( x + y - y \).

Finally, we use the property that addition and subtraction cancel each other out in an additive commutative group, i.e., \( a + (b - a) = b \). This simplifies \( x + y - y \) to \( x \).

Thus, the goal \( x - y + y = x \) is equivalent to \( x = x \), which is trivially true. -/
  rw [sub_toAdd, BitVec.add_assoc, BitVec.add_comm _ y,
      ← BitVec.add_assoc, ← sub_toAdd, add_sub_cancel]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44190,BitVec.toNat_not,theorem BitVec.toNat_not {x : BitVec v} : (~~~x).toNat = 2^v - 1 - x.toNat := by sorry,"Complement of Bitvector to Natural Number: \( \text{toNat}(\sim x) = 2^v - 1 - \text{toNat}(x) \) : For any natural number \( v \) and any bitvector \( x \) of width \( v \), the underlying natural number of the complement of \( x \), denoted as \( \sim x \), is equal to \( 2^v - 1 - \text{toNat}(x) \). In other words, \( \text{toNat}(\sim x) = 2^v - 1 - \text{toNat}(x) \).","theorem BitVec.toNat_not {x : BitVec v} : (~~~x).toNat = 2^v - 1 - x.toNat := by
  rw [Nat.sub_sub, Nat.add_comm, not_def, toNat_xor]
  apply Nat.eq_of_testBit_eq
  intro i
  simp only [toNat_allOnes, Nat.testBit_xor, Nat.testBit_two_pow_sub_one]
  match h : BitVec.toNat x with
  | 0 => simp
  | y+1 =>
    rw [Nat.succ_eq_add_one] at h
    rw [← h]
    rw [Nat.testBit_two_pow_sub_succ (isLt _)]
    · cases w : decide (i < v)
      · simp at w
        simp [w]
        rw [Nat.testBit_lt_two_pow]
        calc BitVec.toNat x < 2 ^ v := isLt _
          _ ≤ 2 ^ i := Nat.pow_le_pow_of_le_right Nat.zero_lt_two w
      · simp","We start by using the identity \( a - b - c = a - (b + c) \) to rewrite the goal as \((\sim x).toNat = 2^v - (1 + x.toNat)\). Then, we use the commutativity of addition \( a + b = b + a \) to rewrite \( 1 + x.toNat \) as \( x.toNat + 1 \). Next, we use the definition of the complement of a bitvector, which states that \(\sim x = \text{allOnes}(v) \^^^ x\). Finally, we use the property that the underlying natural number of the XOR of two bitvectors is the XOR of their underlying natural numbers, i.e., \((x \^^^ y).toNat = x.toNat \^^^ y.toNat\). This simplifies our goal to \((\text{allOnes}(v).toNat \^^^ x.toNat) = 2^v - (x.toNat + 1)\).

To prove this, it suffices to show that for all natural numbers \( i \), the \( i \)-th bit of \((\text{allOnes}(v).toNat \^^^ x.toNat)\) is equal to the \( i \)-th bit of \( 2^v - (x.toNat + 1) \). This is because two natural numbers are equal if and only if they have the same bits at every position.

Let \( i \) be an arbitrary natural number. We need to show that the \( i \)-th bit of \((\text{allOnes}(v).toNat \^^^ x.toNat)\) is equal to the \( i \)-th bit of \( 2^v - (x.toNat + 1) \).

Using the properties that \(\text{allOnes}(v).toNat = 2^v - 1\), the \( i \)-th bit of the XOR of two natural numbers is the XOR of their \( i \)-th bits, and the \( i \)-th bit of \( 2^v - 1 \) is 1 if and only if \( i < v \), we simplify the goal to \((\text{decide}(i < v) \oplus x.toNat.testBit(i)) = (2^v - (x.toNat + 1)).testBit(i)\).

We consider two cases:
1. **Case 1: \( \text{decide}(i < v) = \text{false} \)**:
- This means \( v \le i \).
- Using the property that if \( x < 2^i \), then the \( i \)-th bit of \( x \) is false, we need to show \( x.toNat < 2^i \).
- We use the fact that the underlying natural number of a bitvector \( x \) of width \( v \) is less than \( 2^v \) and the property that if \( v \le i \), then \( 2^v \le 2^i \) to show that \( x.toNat < 2^i \).

2. **Case 2: \( \text{decide}(i < v) = \text{true} \)**:
- This means \( i < v \).
- Using the property that the \( i \)-th bit of \( 2^v - (x + 1) \) is 1 if and only if \( i < v \) and the \( i \)-th bit of \( x \) is 0, we simplify the goal to a trivial equality.

In both cases, the goal is satisfied, completing the proof. Therefore, we have shown that \( \text{toNat}(\sim x) = 2^v - 1 - \text{toNat}(x) \).","theorem BitVec.toNat_not {x : BitVec v} : (~~~x).toNat = 2^v - 1 - x.toNat := by
/- First, we use the identity \( a - b - c = a - (b + c) \) to rewrite the goal as \((\sim x).toNat = 2^v - (1 + x.toNat)\). Then, we use the commutativity of addition \( a + b = b + a \) to rewrite \( 1 + x.toNat \) as \( x.toNat + 1 \). Next, we use the definition of the complement of a bitvector, which states that \(\sim x = \text{allOnes}(v) \^^^ x\). Finally, we use the property that the underlying natural number of the XOR of two bitvectors is the XOR of their underlying natural numbers, i.e., \((x \^^^ y).toNat = x.toNat \^^^ y.toNat\). This simplifies our goal to \((\text{allOnes}(v).toNat \^^^ x.toNat) = 2^v - (x.toNat + 1)\). -/
  rw [Nat.sub_sub, Nat.add_comm, not_def, toNat_xor]
/- To prove that \((\text{allOnes}(v).toNat \^^^ x.toNat) = 2^v - (x.toNat + 1)\), it suffices to show that for all natural numbers \( i \), the \( i \)-th bit of \((\text{allOnes}(v).toNat \^^^ x.toNat)\) is equal to the \( i \)-th bit of \( 2^v - (x.toNat + 1) \). This is because two natural numbers are equal if and only if they have the same bits at every position. -/
  apply Nat.eq_of_testBit_eq
/- Let \( i \) be an arbitrary natural number. We need to show that the \( i \)-th bit of \((\text{allOnes}(v).toNat \^^^ x.toNat)\) is equal to the \( i \)-th bit of \( 2^v - (x.toNat + 1) \). -/
  intro i
/- Using the properties that \(\text{allOnes}(v).toNat = 2^v - 1\), the \( i \)-th bit of the XOR of two natural numbers is the XOR of their \( i \)-th bits, and the \( i \)-th bit of \( 2^v - 1 \) is 1 if and only if \( i < v \), we simplify the goal to \((\text{decide}(i < v) \oplus x.toNat.testBit(i)) = (2^v - (x.toNat + 1)).testBit(i)\). -/
  simp only [toNat_allOnes, Nat.testBit_xor, Nat.testBit_two_pow_sub_one]
  match h : BitVec.toNat x with
/- We consider the case where \( i = 0 \). Using the properties of the test bit function and the fact that \( 0 < v \), we simplify the goal to a trivial equality. -/
  | 0 => simp
/- We consider the case where \( i = y + 1 \). We need to show that \((\text{decide}(i < v) \oplus x.toNat.testBit(i)) = (2^v - (x.toNat + 1)).testBit(i)\). -/
  | y+1 =>
/- We use the fact that the successor of a natural number \( y \) is equal to \( y + 1 \) to rewrite the hypothesis \( x.toNat = y + 1 \) as \( x.toNat = y + 1 \). -/
    rw [Nat.succ_eq_add_one] at h
/- We substitute \( x.toNat = y + 1 \) into the goal, simplifying it to \((\text{decide}(i < v) \oplus (y + 1).testBit(i)) = (2^v - (y + 1 + 1)).testBit(i)\). -/
    rw [← h]
/- We use the property that the \( i \)-th bit of \( 2^v - (x + 1) \) is 1 if and only if \( i < v \) and the \( i \)-th bit of \( x \) is 0 to rewrite the goal to \((\text{decide}(i < v) \oplus x.toNat.testBit(i)) = (\text{decide}(i < v) \land \neg x.toNat.testBit(i))\). -/
    rw [Nat.testBit_two_pow_sub_succ (isLt _)]
/- We consider two cases: \( \text{decide}(i < v) = \text{false} \) and \( \text{decide}(i < v) = \text{true} \). -/
    · cases w : decide (i < v)
/- In the case where \( \text{decide}(i < v) = \text{false} \), we simplify the hypothesis \( w \) to \( v \le i \). -/
      · simp at w
/- Using the hypothesis \( v \le i \), we simplify the goal to \( x.toNat.testBit(i) = \text{false} \). -/
        simp [w]
/- We use the property that if \( x < 2^i \), then the \( i \)-th bit of \( x \) is false to rewrite the goal to \( x.toNat < 2^i \). -/
        rw [Nat.testBit_lt_two_pow]
/- We use the fact that the underlying natural number of a bitvector \( x \) of width \( v \) is less than \( 2^v \) and the property that if \( v \le i \), then \( 2^v \le 2^i \) to show that \( x.toNat < 2^i \). This completes the proof for the case \( \text{decide}(i < v) = \text{false} \). -/
        calc BitVec.toNat x < 2 ^ v := isLt _
          _ ≤ 2 ^ i := Nat.pow_le_pow_of_le_right Nat.zero_lt_two w
/- In the case where \( \text{decide}(i < v) = \text{true} \), we simplify the goal to a trivial equality. -/
      · simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44191,BitVec.rotateRight_eq_rotateRightAux_of_lt,"theorem BitVec.rotateRight_eq_rotateRightAux_of_lt {x : BitVec w} {r : Nat} (hr : r < w) :
    x.rotateRight r = x.rotateRightAux r := by sorry","Right Rotation of Bitvector Equals Auxiliary Right Rotation for Small Rotation Amounts: \( x.\text{rotateRight}(r) = x.\text{rotateRightAux}(r) \) for \( r < w \) : For any natural number \( w \) and any bitvector \( x \) of width \( w \), if the rotation amount \( r \) is less than the bitwidth \( w \), then the right rotation of \( x \) by \( r \) positions using the `rotateRight` function is equal to the right rotation of \( x \) by \( r \) positions using the `rotateRightAux` function, i.e., \( x.\text{rotateRight}(r) = x.\text{rotateRightAux}(r) \).","theorem BitVec.rotateRight_eq_rotateRightAux_of_lt {x : BitVec w} {r : Nat} (hr : r < w) :
    x.rotateRight r = x.rotateRightAux r := by
  simp only [rotateRight, Nat.mod_eq_of_lt hr]","We start by noting that the right rotation of a bitvector \( x \) of width \( w \) by \( r \) positions using the `rotateRight` function is defined in terms of the modulo operation. Specifically, the rotation amount \( r \) is taken modulo \( w \) to ensure it is within the range of the bitwidth. Given that \( r < w \), we have \( r \% w = r \).

Using the definition of `rotateRight` and the fact that for any natural numbers \(a\) and \(b\), if \(a < b\), then \(a \% b = a\), we can simplify the expression \(x.\text{rotateRight}(r)\) to \(x.\text{rotateRightAux}(r)\). This is because the modulo operation does not change \(r\) when \(r < w\).

Therefore, the right rotation of \( x \) by \( r \) positions using the `rotateRight` function is exactly the same as the right rotation of \( x \) by \( r \) positions using the `rotateRightAux` function. This completes the proof.","theorem BitVec.rotateRight_eq_rotateRightAux_of_lt {x : BitVec w} {r : Nat} (hr : r < w) :
    x.rotateRight r = x.rotateRightAux r := by
/- Using the definition of `rotateRight` and the fact that for any natural numbers \(a\) and \(b\), if \(a < b\), then \(a \% b = a\), we can simplify the proposition we want to show to \(x.\text{rotateRight}(r) = x.\text{rotateRightAux}(r)\). Since \(r < w\), we have \(r \% w = r\). Therefore, the right rotation of \(x\) by \(r\) positions using the `rotateRight` function is equivalent to the right rotation of \(x\) by \(r\) positions using the `rotateRightAux` function. -/
  simp only [rotateRight, Nat.mod_eq_of_lt hr]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44193,BitVec.ofNat_sub_ofNat,theorem BitVec.ofNat_sub_ofNat {n} (x y : Nat) : BitVec.ofNat n x - BitVec.ofNat n y = .ofNat n ((2^n - y % 2^n) + x) := by sorry,"Subtraction of Bitvector Representations of Natural Numbers : For any natural number \( n \) and any natural numbers \( x \) and \( y \), the subtraction of the bitvector representation of \( y \) from the bitvector representation of \( x \) of width \( n \) is equal to the bitvector representation of \( 2^n - (y \mod 2^n) + x \) of width \( n \). In other words, \( \text{BitVec.ofNat}(n, x) - \text{BitVec.ofNat}(n, y) = \text{BitVec.ofNat}(n, 2^n - (y \mod 2^n) + x) \).","theorem BitVec.ofNat_sub_ofNat {n} (x y : Nat) : BitVec.ofNat n x - BitVec.ofNat n y = .ofNat n ((2^n - y % 2^n) + x) := by
  apply eq_of_toNat_eq ; simp [BitVec.ofNat]","To prove the theorem, we need to show that the natural number representation of the left-hand side of the equation is equal to the natural number representation of the right-hand side. This is because the function `BitVec.ofNat` is injective, meaning that if two bitvector representations are equal, their natural number representations must also be equal.

1. **Step 1:**
We start with the goal of proving:
\[
\text{BitVec.ofNat}(n, x) - \text{BitVec.ofNat}(n, y) = \text{BitVec.ofNat}(n, 2^n - (y \mod 2^n) + x)
\]
To achieve this, it suffices to show that the natural number representation of the left-hand side is equal to the natural number representation of the right-hand side. This is because the function `BitVec.ofNat` is injective.

2. **Step 2:**
Using the definition of `BitVec.ofNat`, we simplify the expression. The natural number representation of a bitvector is the natural number that the bitvector represents. Therefore, we need to show:
\[
\text{toNat}(\text{BitVec.ofNat}(n, x) - \text{BitVec.ofNat}(n, y)) = \text{toNat}(\text{BitVec.ofNat}(n, 2^n - (y \mod 2^n) + x))
\]

3. **Step 3:**
By the properties of the `BitVec.ofNat` function and the definition of subtraction in bitvectors, we know that:
\[
\text{toNat}(\text{BitVec.ofNat}(n, x) - \text{BitVec.ofNat}(n, y)) = (x - y) \mod 2^n
\]
and
\[
\text{toNat}(\text{BitVec.ofNat}(n, 2^n - (y \mod 2^n) + x)) = (2^n - (y \mod 2^n) + x) \mod 2^n
\]

4. **Step 4:**
We need to show that:
\[
(x - y) \mod 2^n = (2^n - (y \mod 2^n) + x) \mod 2^n
\]

5. **Step 5:**
Simplifying the right-hand side, we get:
\[
(2^n - (y \mod 2^n) + x) \mod 2^n = (2^n - y + x) \mod 2^n
\]
Since \( 2^n \mod 2^n = 0 \), this simplifies to:
\[
(2^n - y + x) \mod 2^n = (x - y) \mod 2^n
\]

6. **Conclusion:**
Therefore, we have shown that:
\[
\text{toNat}(\text{BitVec.ofNat}(n, x) - \text{BitVec.ofNat}(n, y)) = \text{toNat}(\text{BitVec.ofNat}(n, 2^n - (y \mod 2^n) + x))
\]
Since `BitVec.ofNat` is injective, this implies:
\[
\text{BitVec.ofNat}(n, x) - \text{BitVec.ofNat}(n, y) = \text{BitVec.ofNat}(n, 2^n - (y \mod 2^n) + x)
\]
This completes the proof.","theorem BitVec.ofNat_sub_ofNat {n} (x y : Nat) : BitVec.ofNat n x - BitVec.ofNat n y = .ofNat n ((2^n - y % 2^n) + x) := by
/- To prove that \( \text{BitVec.ofNat}(n, x) - \text{BitVec.ofNat}(n, y) = \text{BitVec.ofNat}(n, 2^n - (y \mod 2^n) + x) \), it suffices to show that the natural number representation of the left-hand side is equal to the natural number representation of the right-hand side. This is because the function `BitVec.ofNat` is injective, meaning that if two bitvector representations are equal, their natural number representations must also be equal. After simplifying the expression using the definition of `BitVec.ofNat`, we need to show that the natural number representation of the left-hand side is equal to the natural number representation of the right-hand side. -/
  apply eq_of_toNat_eq ; simp [BitVec.ofNat]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44195,BitVec.twoPow_zero,theorem BitVec.twoPow_zero {w : Nat} : twoPow w 0 = 1#w := by sorry,"Bitvector with 0-th Bit Set to 1 is \( 1 \) in Bitvector of Width \( w \) : For any natural number \( w \), the bitvector of width \( w \) with the 0-th bit set to 1 is equal to the bitvector \( 1 \) of width \( w \), i.e., \(\text{twoPow}(w, 0) = 1_w\).","theorem BitVec.twoPow_zero {w : Nat} : twoPow w 0 = 1#w := by
  apply eq_of_toNat_eq
  simp","To prove that the bitvector \(\text{twoPow}(w, 0)\) is equal to the bitvector \(1_w\), we use the fact that two bitvectors are equal if and only if their natural number representations are equal. Therefore, it suffices to show that \((\text{twoPow}(w, 0)).\text{toNat} = (1_w).\text{toNat}\).

The natural number representation of \(\text{twoPow}(w, 0)\) is \(2^0 = 1\). Similarly, the natural number representation of \(1_w\) is also \(1\). Hence, \((\text{twoPow}(w, 0)).\text{toNat} = (1_w).\text{toNat}\).

Since the natural number representations are equal, we conclude that \(\text{twoPow}(w, 0) = 1_w\). This completes the proof.","theorem BitVec.twoPow_zero {w : Nat} : twoPow w 0 = 1#w := by
/- To prove that the bitvector \(\text{twoPow}(w, 0)\) is equal to the bitvector \(1_w\), it suffices to show that their natural number representations are equal, i.e., \((\text{twoPow}(w, 0)).\text{toNat} = (1_w).\text{toNat}\). -/
  apply eq_of_toNat_eq
/- Simplify the proposition we want to show, we get that \((\text{twoPow}(w, 0)).\text{toNat} = (1_w).\text{toNat}\) is true. This is because the natural number representation of \(\text{twoPow}(w, 0)\) is \(2^0 = 1\), and the natural number representation of \(1_w\) is also \(1\). -/
  simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44203,BitVec.replicate_zero_eq,theorem BitVec.replicate_zero_eq {x : BitVec w} : x.replicate 0 = 0#0 := by sorry,"Replication of Bitvector Zero Times Equals Zero Bitvector : For any natural number \( w \) and any bitvector \( x \) of width \( w \), the replication of \( x \) zero times results in the zero bitvector of width 0, i.e., \(\text{replicate}(0, x) = 0\#0\).","theorem BitVec.replicate_zero_eq {x : BitVec w} : x.replicate 0 = 0#0 := by
  simp [replicate]","To prove the theorem, we start by considering the definition of the replication function. The replication function \(\text{replicate}(n, x)\) takes a natural number \( n \) and a bitvector \( x \) of width \( w \), and produces a new bitvector by repeating \( x \) \( n \) times. When \( n = 0 \), the replication function should produce the zero bitvector of width 0, denoted as \( 0\#0 \).

Using the definition of the replication function, we can simplify the proposition \(\text{replicate}(0, x) = 0\#0\). By the definition, replicating \( x \) zero times results in the zero bitvector of width 0. Therefore, the proposition \(\text{replicate}(0, x) = 0\#0\) holds true.

This completes the proof. \(\blacksquare\)","theorem BitVec.replicate_zero_eq {x : BitVec w} : x.replicate 0 = 0#0 := by
/- Using the definition of the replication function, we can simplify the proposition we want to show, which is that the replication of \( x \) zero times results in the zero bitvector of width 0. This simplification directly shows that \(\text{replicate}(0, x) = 0\#0\). -/
  simp [replicate]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44205,BitVec.sub_self,theorem BitVec.sub_self (x : BitVec n) : x - x = 0#n := by sorry,"Subtraction of Bitvector by Itself is Zero Bitvector in Bitvectors of Specified Width : For any natural number \( n \) and any bitvector \( x \) of width \( n \), the subtraction of \( x \) from itself results in the zero bitvector of width \( n \), i.e., \( x - x = 0#n \).","theorem BitVec.sub_self (x : BitVec n) : x - x = 0#n := by
  apply eq_of_toNat_eq
  simp only [toNat_sub]
  rw [Nat.add_comm, Nat.add_sub_of_le]
  · simp
  · exact Nat.le_of_lt x.isLt","To prove that \( x - x = 0#n \), it suffices to show that the natural number representation of \( x - x \) is equal to the natural number representation of \( 0#n \), i.e., \( (x - x).\text{toNat} = (0#n).\text{toNat} \).

Using the theorem that the natural number representation of the subtraction of two bitvectors is the result of the subtraction of their natural number representations modulo \( 2^n \), we can simplify the proposition we want to show to:
\[
(x - x).\text{toNat} = (2^n - x.\text{toNat} + x.\text{toNat}) \mod 2^n
\]

Since the commutativity of addition in natural numbers and the identity \( a + (b - a) = b \) for \( a \leq b \) hold, we can rewrite the goal as:
\[
2^n \mod 2^n = (0#n).\text{toNat}
\]
and we need to show that \( x.\text{toNat} \leq 2^n \).

First, we show that \( 2^n \mod 2^n = 0 \). This is trivial because any number modulo itself is zero. Therefore, the goal is now to show that \( x.\text{toNat} \leq 2^n \).

The current goal \( x.\text{toNat} \leq 2^n \) is exactly proved by the fact that the natural number representation of any bitvector \( x \) of width \( n \) is strictly less than \( 2^n \), i.e., \( x.\text{toNat} < 2^n \). Since \( a < b \) implies \( a \leq b \), this completes the proof.","theorem BitVec.sub_self (x : BitVec n) : x - x = 0#n := by
/- To prove that \( x - x = 0#n \), it suffices to show that the natural number representation of \( x - x \) is equal to the natural number representation of \( 0#n \), i.e., \( (x - x).\text{toNat} = (0#n).\text{toNat} \). -/
  apply eq_of_toNat_eq
/- Using the theorem that the natural number representation of the subtraction of two bitvectors is the result of the subtraction of their natural number representations modulo \( 2^n \), we can simplify the proposition we want to show to:
\[
(x - x).\text{toNat} = (2^n - x.\text{toNat} + x.\text{toNat}) \mod 2^n
\] -/
  simp only [toNat_sub]
/- Since the commutativity of addition in natural numbers and the identity \( a + (b - a) = b \) for \( a \leq b \) hold, we can rewrite the goal as:
\[
2^n \mod 2^n = (0#n).\text{toNat}
\]
and we need to show that \( x.\text{toNat} \leq 2^n \). -/
  rw [Nat.add_comm, Nat.add_sub_of_le]
/- First, we show that \( 2^n \mod 2^n = 0 \). This is trivial because any number modulo itself is zero. Therefore, the goal is now to show that \( x.\text{toNat} \leq 2^n \). -/
  · simp
/- The current goal \( x.\text{toNat} \leq 2^n \) is exactly proved by the fact that the natural number representation of any bitvector \( x \) of width \( n \) is strictly less than \( 2^n \), i.e., \( x.\text{toNat} < 2^n \). Since \( a < b \) implies \( a \leq b \), this completes the proof. -/
  · exact Nat.le_of_lt x.isLt","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44206,BitVec.lt_of_le_ne,theorem BitVec.lt_of_le_ne (x y : BitVec n) (h1 : x <= y) (h2 : ¬ x = y) : x < y := by sorry,"Strict Inequality from Non-Equality and Less-Than-or-Equal in Bitvectors of Specified Width : For any natural number \( n \) and any two bitvectors \( x \) and \( y \) of width \( n \), if \( x \leq y \) and \( x \neq y \), then \( x < y \).","theorem BitVec.lt_of_le_ne (x y : BitVec n) (h1 : x <= y) (h2 : ¬ x = y) : x < y := by
  revert h1 h2
  let ⟨x, lt⟩ := x
  let ⟨y, lt⟩ := y
  simp
  exact Nat.lt_of_le_of_ne","We start by strengthening the proposition we are proving. We show that for any bitvectors \( x \) and \( y \) of width \( n \), if \( x \leq y \) and \( x \neq y \), then \( x < y \).

1. **Construct the natural numbers and their bounds:**
- Let \( x \) and \( \text{lt}_x \) denote the natural number and the proof that \( x < 2^n \) from the bitvector \( x \).
- Let \( y \) and \( \text{lt}_y \) denote the natural number and the proof that \( y < 2^n \) from the bitvector \( y \).

2. **Simplify the goal:**
- Using the definitions and properties of bitvectors and natural numbers, we simplify the proposition we want to show. The goal reduces to proving that if \( x \leq y \) and \( x \neq y \), then \( x < y \).

3. **Apply the theorem:**
- The theorem states that for any natural numbers \( x \) and \( y \), if \( x \leq y \) and \( x \neq y \), then \( x < y \). This theorem directly proves our goal.

Therefore, we have shown that if \( x \leq y \) and \( x \neq y \), then \( x < y \). This completes the proof. \(\blacksquare\)","theorem BitVec.lt_of_le_ne (x y : BitVec n) (h1 : x <= y) (h2 : ¬ x = y) : x < y := by
/- We strengthen the proposition we are proving. We show that for any bitvectors \( x \) and \( y \) of width \( n \), if \( x \leq y \) and \( x \neq y \), then \( x < y \). -/
  revert h1 h2
/- Now we construct the natural number \( x \) and the proof \( \text{lt} \) that \( x < 2^n \) from the bitvector \( x \). Let \( x \) and \( \text{lt} \) denote the natural number and the proof, respectively, in the construction. -/
  let ⟨x, lt⟩ := x
/- Now we construct the natural number \( y \) and the proof \( \text{lt} \) that \( y < 2^n \) from the bitvector \( y \). Let \( y \) and \( \text{lt} \) denote the natural number and the proof, respectively, in the construction. -/
  let ⟨y, lt⟩ := y
/- Using the definitions and properties of bitvectors and natural numbers, we simplify the proposition we want to show. The goal reduces to proving that if \( x \leq y \) and \( x \neq y \), then \( x < y \). -/
  simp
/- The current goal is exactly proved by the theorem that for any natural numbers \( x \) and \( y \), if \( x \leq y \) and \( x \neq y \), then \( x < y \). -/
  exact Nat.lt_of_le_of_ne","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44210,BitVec.rotateLeft_eq_rotateLeftAux_of_lt,"theorem BitVec.rotateLeft_eq_rotateLeftAux_of_lt {x : BitVec w} {r : Nat} (hr : r < w) :
    x.rotateLeft r = x.rotateLeftAux r := by sorry","Left Rotation of Bitvector Equals Auxiliary Left Rotation when Rotation Amount is Less Than Bitwidth : For any natural number \( w \) and any bitvector \( x \) of width \( w \), if the rotation amount \( r \) is less than \( w \), then the left rotation of \( x \) by \( r \) positions, denoted as \( x \lll r \), is equal to the result of the auxiliary function `rotateLeftAux` applied to \( x \) and \( r \), i.e., \( x \lll r = x \lll r \lor \lor x \ggg (w - r) \).","theorem BitVec.rotateLeft_eq_rotateLeftAux_of_lt {x : BitVec w} {r : Nat} (hr : r < w) :
    x.rotateLeft r = x.rotateLeftAux r := by
  simp only [rotateLeft, Nat.mod_eq_of_lt hr]","To prove the theorem, we start with the given conditions: \( w \) is a natural number, \( x \) is a bitvector of width \( w \), and \( r \) is a natural number such that \( r < w \).

1. **Simplification using Definitions and Properties:**
- We use the definition of the `rotateLeft` function and the property of the modulo operation for natural numbers. Specifically, for any natural numbers \(a\) and \(b\), if \(a < b\), then \(a \% b = a\).
- Given \( r < w \), we have \( r \% w = r \).
- Therefore, the left rotation of \( x \) by \( r \) positions, \( x \lll r \), can be simplified using the definition of `rotateLeft` and the modulo property.

2. **Equivalence to Auxiliary Function:**
- The definition of `rotateLeft` for a bitvector \( x \) of width \( w \) and rotation amount \( r \) is \( x \lll r = x \lll r \lor \lor x \ggg (w - r) \).
- Since \( r < w \), the expression \( x \lll r \) is exactly the same as \( x \lll r \lor \lor x \ggg (w - r) \).

3. **Conclusion:**
- Thus, we have shown that \( x \lll r = x \lll r \lor \lor x \ggg (w - r) \), which is the result of the auxiliary function `rotateLeftAux` applied to \( x \) and \( r \).

Therefore, the theorem is proved. \(\blacksquare\)","theorem BitVec.rotateLeft_eq_rotateLeftAux_of_lt {x : BitVec w} {r : Nat} (hr : r < w) :
    x.rotateLeft r = x.rotateLeftAux r := by
/- Using the definition of `rotateLeft` and the fact that for any natural numbers \(a\) and \(b\), if \(a < b\), then \(a \% b = a\), we can simplify the proposition we want to show to \(x \lll r = x \lll r \lor \lor x \ggg (w - r)\). This simplification is valid because the rotation amount \(r\) is less than the bitwidth \(w\). -/
  simp only [rotateLeft, Nat.mod_eq_of_lt hr]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44211,BitVec.ofInt_mul,"theorem BitVec.ofInt_mul {n} (x y : Int) : BitVec.ofInt n (x * y) =
    BitVec.ofInt n x * BitVec.ofInt n y := by sorry","Multiplication of Bitvectors from Integers Modulo \( 2^n \) : For any natural number \( n \) and any integers \( x \) and \( y \), the bitvector of width \( n \) obtained by taking the product \( x * y \) modulo \( 2^n \) is equal to the product of the bitvectors of width \( n \) obtained by taking \( x \) and \( y \) modulo \( 2^n \), i.e., \(\text{BitVec.ofInt}(n, x * y) = \text{BitVec.ofInt}(n, x) * \text{BitVec.ofInt}(n, y)\).","theorem BitVec.ofInt_mul {n} (x y : Int) : BitVec.ofInt n (x * y) =
    BitVec.ofInt n x * BitVec.ofInt n y := by
  apply eq_of_toInt_eq
  simp","To prove the theorem, we start by noting that the bitvector equality \(\text{BitVec.ofInt}(n, x * y) = \text{BitVec.ofInt}(n, x) * \text{BitVec.ofInt}(n, y)\) can be reduced to showing that the integer representations of these bitvectors are equal. This is because if the integer representations of two bitvectors are equal, then the bitvectors themselves are equal.

We need to show that:
\[
(\text{BitVec.ofInt}(n, x * y)).\text{toInt} = (\text{BitVec.ofInt}(n, x) * \text{BitVec.ofInt}(n, y)).\text{toInt}
\]

Using the properties of the balanced modulus and the definition of the integer representation of bitvectors, we can simplify the left-hand side and the right-hand side. Specifically, we use the fact that for any integers \( x \) and \( y \), and any natural number \( n \), the balanced modulus of the product \( x \cdot y \) with respect to \( n \) is equal to the balanced modulus of the product \( (x \bmod n) \cdot y \) with respect to \( n \). This simplification shows that:
\[
(x * y) \bmod 2^n = (x \bmod 2^n) * (y \bmod 2^n) \bmod 2^n
\]

Thus, the integer representation of \(\text{BitVec.ofInt}(n, x * y)\) is equal to the integer representation of \(\text{BitVec.ofInt}(n, x) * \text{BitVec.ofInt}(n, y)\). Therefore, we have:
\[
(\text{BitVec.ofInt}(n, x * y)).\text{toInt} = (\text{BitVec.ofInt}(n, x) * \text{BitVec.ofInt}(n, y)).\text{toInt}
\]

This completes the proof. Hence, \(\text{BitVec.ofInt}(n, x * y) = \text{BitVec.ofInt}(n, x) * \text{BitVec.ofInt}(n, y)\).","theorem BitVec.ofInt_mul {n} (x y : Int) : BitVec.ofInt n (x * y) =
    BitVec.ofInt n x * BitVec.ofInt n y := by
/- To prove that \(\text{BitVec.ofInt}(n, x * y) = \text{BitVec.ofInt}(n, x) * \text{BitVec.ofInt}(n, y)\), it suffices to show that the integer representation of \(\text{BitVec.ofInt}(n, x * y)\) is equal to the integer representation of \(\text{BitVec.ofInt}(n, x) * \text{BitVec.ofInt}(n, y)\). This is because if the integer representations of two bitvectors are equal, then the bitvectors themselves are equal. -/
  apply eq_of_toInt_eq
/- Using the properties of the balanced modulus and the definition of the integer representation of bitvectors, we can simplify the proposition we want to show. Specifically, we use the fact that for any integers \( x \) and \( y \), and any natural number \( n \), the balanced modulus of the product \( x \cdot y \) with respect to \( n \) is equal to the balanced modulus of the product \( (x \bmod n) \cdot y \) with respect to \( n \). This simplification shows that the integer representation of \(\text{BitVec.ofInt}(n, x * y)\) is indeed equal to the integer representation of \(\text{BitVec.ofInt}(n, x) * \text{BitVec.ofInt}(n, y)\). -/
  simp","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44213,BitVec.replicate_succ_eq,"theorem BitVec.replicate_succ_eq {x : BitVec w} :
    x.replicate (n + 1) =
    (x ++ replicate n x).cast (by rw [Nat.mul_succ]; omega) := by sorry","Replication of Bitvector by Successor: \( \text{replicate}(n + 1, x) = x ++ \text{replicate}(n, x) \) : For any natural numbers \( w \) and \( n \), and for any bitvector \( x \) of width \( w \), the bitvector obtained by replicating \( x \) \( n + 1 \) times is equal to the bitvector obtained by concatenating \( x \) with the bitvector obtained by replicating \( x \) \( n \) times, cast to the appropriate width \( w \cdot (n + 1) \).","theorem BitVec.replicate_succ_eq {x : BitVec w} :
    x.replicate (n + 1) =
    (x ++ replicate n x).cast (by rw [Nat.mul_succ]; omega) := by
  simp [replicate]","We need to show that for any natural numbers \( w \) and \( n \), and for any bitvector \( x \) of width \( w \), the bitvector obtained by replicating \( x \) \( n + 1 \) times is equal to the bitvector obtained by concatenating \( x \) with the bitvector obtained by replicating \( x \) \( n \) times, cast to the appropriate width \( w \cdot (n + 1) \).

By the definition of the `replicate` function, \(\text{replicate}(n + 1, x)\) is defined as the concatenation of \( x \) with \( n \) copies of \( x \), cast to the appropriate width \( w \cdot (n + 1) \). This means:
\[
\text{replicate}(n + 1, x) = \text{cast} \cdots (x ++ \text{replicate}(n, x))
\]
Thus, the goal is trivially true by the definition of `replicate`.

This completes the proof.","theorem BitVec.replicate_succ_eq {x : BitVec w} :
    x.replicate (n + 1) =
    (x ++ replicate n x).cast (by rw [Nat.mul_succ]; omega) := by
/- Using the definition of the `replicate` function, we can simplify the proposition we want to show. The `replicate` function for a bitvector \( x \) of width \( w \) and a natural number \( n + 1 \) is defined as the concatenation of \( x \) with \( n \) copies of \( x \), cast to the appropriate width \( w \cdot (n + 1) \). Therefore, the goal \( \text{replicate}(n + 1, x) = \text{cast} \cdots (x ++ \text{replicate}(n, x)) \) is trivially true by the definition of `replicate`. -/
  simp [replicate]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44215,BitVec.BitVec.mul_add,"theorem BitVec.BitVec.mul_add {x y z : BitVec w} :
    x * (y + z) = x * y + x * z := by sorry","Distributive Property of Multiplication over Addition for Bitvectors of Fixed Width : For any natural number \( w \) and any bitvectors \( x, y, z \) of width \( w \), the multiplication of \( x \) with the sum of \( y \) and \( z \) is equal to the sum of the products \( x * y \) and \( x * z \). In other words, \( x * (y + z) = x * y + x * z \).","theorem BitVec.BitVec.mul_add {x y z : BitVec w} :
    x * (y + z) = x * y + x * z := by
  apply eq_of_toNat_eq
  simp only [toNat_mul, toNat_add, Nat.add_mod_mod, Nat.mod_add_mod]
  rw [Nat.mul_mod, Nat.mod_mod (y.toNat + z.toNat),
    ← Nat.mul_mod, Nat.mul_add]","To prove that \( x * (y + z) = x * y + x * z \), it suffices to show that the natural number representation of \( x * (y + z) \) is equal to the natural number representation of \( x * y + x * z \). In other words, we need to show that:
\[ (x * (y + z)).\text{toNat} = (x * y + x * z).\text{toNat} \]

Using the properties of the natural number representation of bitvectors, we can simplify the proposition we want to show. Specifically, we use the following properties:
- The natural number representation of the product of two bitvectors is the product of their natural number representations modulo \( 2^w \).
- The natural number representation of the sum of two bitvectors is the sum of their natural number representations modulo \( 2^w \).
- The modulo operation distributes over addition with modulo.
- The modulo operation applied to the sum of a natural number and the modulo of another natural number is the same as the modulo operation applied to the sum of the two natural numbers.

After simplification, we get:
\[ x.\text{toNat} * ((y.\text{toNat} + z.\text{toNat}) \% 2^w) \% 2^w = (x.\text{toNat} * y.\text{toNat} + x.\text{toNat} * z.\text{toNat}) \% 2^w \]

We use the following identities to further simplify the goal:
- The product of two natural numbers modulo \( n \) is equal to the product of their modulo \( n \) values modulo \( n \).
- The modulo operation applied to a natural number modulo \( n \) is the same as the natural number modulo \( n \).
- The product of a natural number and the sum of two natural numbers modulo \( n \) is equal to the sum of the products of the natural number and each of the two natural numbers modulo \( n \).

Applying these identities step by step, we get:
1. \( x.\text{toNat} * ((y.\text{toNat} + z.\text{toNat}) \% 2^w) \% 2^w = x.\text{toNat} \% 2^w * ((y.\text{toNat} + z.\text{toNat}) \% 2^w \% 2^w) \% 2^w \)
2. \( x.\text{toNat} \% 2^w * ((y.\text{toNat} + z.\text{toNat}) \% 2^w \% 2^w) \% 2^w = x.\text{toNat} \% 2^w * ((y.\text{toNat} + z.\text{toNat}) \% 2^w) \% 2^w \)
3. \( x.\text{toNat} \% 2^w * ((y.\text{toNat} + z.\text{toNat}) \% 2^w) \% 2^w = x.\text{toNat} * (y.\text{toNat} + z.\text{toNat}) \% 2^w \)
4. \( x.\text{toNat} * (y.\text{toNat} + z.\text{toNat}) \% 2^w = (x.\text{toNat} * y.\text{toNat} + x.\text{toNat} * z.\text{toNat}) \% 2^w \)

Since the left-hand side and the right-hand side are now identical, the goal is trivially true. Therefore, we have shown that:
\[ x * (y + z) = x * y + x * z \]

This completes the proof.","theorem BitVec.BitVec.mul_add {x y z : BitVec w} :
    x * (y + z) = x * y + x * z := by
/- To prove that \( x * (y + z) = x * y + x * z \), it suffices to show that the natural number representation of \( x * (y + z) \) is equal to the natural number representation of \( x * y + x * z \). In other words, we need to show that \( (x * (y + z)).\text{toNat} = (x * y + x * z).\text{toNat} \). -/
  apply eq_of_toNat_eq
/- Using the properties of the natural number representation of bitvectors, we can simplify the proposition we want to show. Specifically, we use the following properties:
- The natural number representation of the product of two bitvectors is the product of their natural number representations modulo \( 2^w \).
- The natural number representation of the sum of two bitvectors is the sum of their natural number representations modulo \( 2^w \).
- The modulo operation distributes over addition with modulo.
- The modulo operation applied to the sum of a natural number and the modulo of another natural number is the same as the modulo operation applied to the sum of the two natural numbers.

After simplification, we get:
\[ x.\text{toNat} * ((y.\text{toNat} + z.\text{toNat}) \% 2^w) \% 2^w = (x.\text{toNat} * y.\text{toNat} + x.\text{toNat} * z.\text{toNat}) \% 2^w \] -/
  simp only [toNat_mul, toNat_add, Nat.add_mod_mod, Nat.mod_add_mod]
/- We use the following identities to further simplify the goal:
- The product of two natural numbers modulo \( n \) is equal to the product of their modulo \( n \) values modulo \( n \).
- The modulo operation applied to a natural number modulo \( n \) is the same as the natural number modulo \( n \).
- The product of a natural number and the sum of two natural numbers modulo \( n \) is equal to the sum of the products of the natural number and each of the two natural numbers modulo \( n \).

Applying these identities step by step, we get:
1. \( x.\text{toNat} * ((y.\text{toNat} + z.\text{toNat}) \% 2^w) \% 2^w = x.\text{toNat} \% 2^w * ((y.\text{toNat} + z.\text{toNat}) \% 2^w \% 2^w) \% 2^w \)
2. \( x.\text{toNat} \% 2^w * ((y.\text{toNat} + z.\text{toNat}) \% 2^w \% 2^w) \% 2^w = x.\text{toNat} \% 2^w * ((y.\text{toNat} + z.\text{toNat}) \% 2^w) \% 2^w \)
3. \( x.\text{toNat} \% 2^w * ((y.\text{toNat} + z.\text{toNat}) \% 2^w) \% 2^w = x.\text{toNat} * (y.\text{toNat} + z.\text{toNat}) \% 2^w \)
4. \( x.\text{toNat} * (y.\text{toNat} + z.\text{toNat}) \% 2^w = (x.\text{toNat} * y.\text{toNat} + x.\text{toNat} * z.\text{toNat}) \% 2^w \)

Since the left-hand side and the right-hand side are now identical, the goal is trivially true. -/
  rw [Nat.mul_mod, Nat.mod_mod (y.toNat + z.toNat),
    ← Nat.mul_mod, Nat.mul_add]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec
open BitVec

"
44218,BitVec.add_sub_cancel,theorem BitVec.add_sub_cancel (x y : BitVec w) : x + y - y = x := by sorry,"Addition and Subtraction Cancellation: \( x + y - y = x \) : For any natural number \( w \) and any bitvectors \( x, y \) of width \( w \), the expression \( x + y - y \) is equal to \( x \), i.e., \( x + y - y = x \).","theorem BitVec.add_sub_cancel (x y : BitVec w) : x + y - y = x := by
  apply eq_of_toNat_eq
  have y_toNat_le := Nat.le_of_lt y.isLt
  rw [toNat_sub, toNat_add, Nat.add_comm, Nat.mod_add_mod, Nat.add_assoc, ← Nat.add_sub_assoc y_toNat_le,
      Nat.add_sub_cancel_left, Nat.add_mod_right, toNat_mod_cancel]","To prove that \( x + y - y = x \), it suffices to show that the natural number representation of \( x + y - y \) is equal to the natural number representation of \( x \), i.e., \((x + y - y).toNat = x.toNat\).

First, we show that \( y.toNat \le 2^w \). This follows from the fact that the natural number representation of any bitvector \( y \) of width \( w \) is strictly less than \( 2^w \), i.e., \( y.toNat < 2^w \).

Next, we simplify the expression \((x + y - y).toNat\) step by step using the following properties and theorems:
1. **Natural Number Representation of Bitvector Subtraction**: \((x - y).toNat = (2^w - y.toNat + x.toNat) \mod 2^w\).
2. **Natural Number Representation of Bitvector Sum**: \((x + y).toNat = (x.toNat + y.toNat) \mod 2^w\).
3. **Commutativity of Addition**: \(a + b = b + a\).
4. **Modulo Addition Identity**: \((m \% n + k) \% n = (m + k) \% n\).
5. **Associativity of Addition**: \(a + (b + c) = (a + b) + c\).
6. **Associativity of Addition and Subtraction**: \(a + b - c = a + (b - c)\).
7. **Left Addition and Subtraction Cancel Each Other**: \(a + b - a = b\).
8. **Right Addition Distributes Over Modulo**: \((x + z) \% z = x \% z\).
9. **Modulo Cancellation for Bitvector to Natural Number Conversion**: \(x.toNat \% 2^w = x.toNat\).

Using these properties, we can rewrite the expression as follows:
\[
(x + y - y).toNat = (2^w - y.toNat + (x + y).toNat) \mod 2^w
\]
\[
= (2^w - y.toNat + (x.toNat + y.toNat) \mod 2^w) \mod 2^w
\]
\[
= ((x.toNat + y.toNat) \mod 2^w + (2^w - y.toNat)) \mod 2^w
\]
\[
= (x.toNat + y.toNat + 2^w - y.toNat) \mod 2^w
\]
\[
= (x.toNat + (y.toNat + 2^w - y.toNat)) \mod 2^w
\]
\[
= (x.toNat + 2^w) \mod 2^w
\]
\[
= x.toNat \mod 2^w
\]
\[
= x.toNat
\]

Thus, we have shown that \((x + y - y).toNat = x.toNat\), which implies \( x + y - y = x \). This completes the proof. \(\blacksquare\)","theorem BitVec.add_sub_cancel (x y : BitVec w) : x + y - y = x := by
/- To prove that \( x + y - y = x \), it suffices to show that the natural number representation of \( x + y - y \) is equal to the natural number representation of \( x \), i.e., \((x + y - y).toNat = x.toNat\). -/
  apply eq_of_toNat_eq
/- We first show that \( y.toNat \le 2^w \). This follows from the fact that the natural number representation of any bitvector \( y \) of width \( w \) is strictly less than \( 2^w \), i.e., \( y.toNat < 2^w \). -/
  have y_toNat_le := Nat.le_of_lt y.isLt
/- We now simplify the expression \((x + y - y).toNat\) step by step using the following properties and theorems:
1. **Natural Number Representation of Bitvector Subtraction**: \((x - y).toNat = (2^w - y.toNat + x.toNat) \mod 2^w\).
2. **Natural Number Representation of Bitvector Sum**: \((x + y).toNat = (x.toNat + y.toNat) \mod 2^w\).
3. **Commutativity of Addition**: \(a + b = b + a\).
4. **Modulo Addition Identity**: \((m \% n + k) \% n = (m + k) \% n\).
5. **Associativity of Addition**: \(a + (b + c) = (a + b) + c\).
6. **Associativity of Addition and Subtraction**: \(a + b - c = a + (b - c)\).
7. **Left Addition and Subtraction Cancel Each Other**: \(a + b - a = b\).
8. **Right Addition Distributes Over Modulo**: \((x + z) \% z = x \% z\).
9. **Modulo Cancellation for Bitvector to Natural Number Conversion**: \(x.toNat \% 2^w = x.toNat\).

Using these properties, we can rewrite the expression as follows:
\[
(x + y - y).toNat = (2^w - y.toNat + (x + y).toNat) \mod 2^w
\]
\[
= (2^w - y.toNat + (x.toNat + y.toNat) \mod 2^w) \mod 2^w
\]
\[
= ((x.toNat + y.toNat) \mod 2^w + (2^w - y.toNat)) \mod 2^w
\]
\[
= (x.toNat + y.toNat + 2^w - y.toNat) \mod 2^w
\]
\[
= (x.toNat + (y.toNat + 2^w - y.toNat)) \mod 2^w
\]
\[
= (x.toNat + 2^w) \mod 2^w
\]
\[
= x.toNat \mod 2^w
\]
\[
= x.toNat
\] -/
  rw [toNat_sub, toNat_add, Nat.add_comm, Nat.mod_add_mod, Nat.add_assoc, ← Nat.add_sub_assoc y_toNat_le,
      Nat.add_sub_cancel_left, Nat.add_mod_right, toNat_mod_cancel]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44220,BitVec.neg_eq_not_add,theorem BitVec.neg_eq_not_add (x : BitVec w) : -x = ~~~x + 1 := by sorry,"Negation of Bitvector Equals Complement Plus One: \(-x = \sim x + 1\) : For any natural number \( w \) and any bitvector \( x \) of width \( w \), the negation of \( x \), denoted as \( -x \), is equal to the complement of \( x \) plus one, i.e., \( -x = \sim x + 1 \).","theorem BitVec.neg_eq_not_add (x : BitVec w) : -x = ~~~x + 1 := by
  apply eq_of_toNat_eq
  simp only [toNat_neg, ofNat_eq_ofNat, toNat_add, toNat_not, toNat_ofNat, Nat.add_mod_mod]
  congr
  have hx : x.toNat < 2^w := x.isLt
  rw [Nat.sub_sub, Nat.add_comm 1 x.toNat, ← Nat.sub_sub, Nat.sub_add_cancel (by omega)]","To prove that \(-x = \sim x + 1\), it suffices to show that the natural number representation of \(-x\) is equal to the natural number representation of \(\sim x + 1\). In other words, we need to show that \((-x).toNat = (\sim x + 1).toNat\).

Using the properties of the natural number representation of bitvectors, we can simplify the goal. Specifically, we use the following properties:
- The natural number representation of the negation of a bitvector \( x \) is \((2^w - x.toNat) \mod 2^w\).
- The natural number representation of the complement of a bitvector \( x \) is \(2^w - 1 - x.toNat\).
- The natural number representation of the sum of two bitvectors is the sum of their natural number representations modulo \(2^w\).
- The natural number representation of a bitvector constructed from a natural number \( x \) is \( x \mod 2^w \).
- The modulo operation distributes over addition with modulo.

After simplification, our goal becomes:
\[
(2^w - x.toNat) \mod 2^w = (2^w - 1 - x.toNat + 1) \mod 2^w
\]

To establish this equality, we decompose it into proving that:
\[
2^w - x.toNat = 2^w - 1 - x.toNat + 1
\]

We know that the natural number representation of \( x \), denoted as \( x.toNat \), is strictly less than \( 2^w \). This is a property of bitvectors, and we denote this fact as \( x.toNat < 2^w \).

Using the following properties:
1. The subtraction identity: \( a - b - c = a - (b + c) \).
2. The commutativity of addition: \( a + b = b + a \).
3. The subtraction identity in reverse: \( a - (b + c) = a - b - c \).
4. The cancellation property of subtraction and addition: \( a - b + b = a \).

We get:
\[
2^w - x.toNat = 2^w - (1 + x.toNat) + 1
\]
\[
2^w - x.toNat = 2^w - (x.toNat + 1) + 1
\]
\[
2^w - x.toNat = 2^w - x.toNat - 1 + 1
\]
\[
2^w - x.toNat = 2^w - x.toNat
\]

Since the left-hand side and the right-hand side are equal, the goal is satisfied. Therefore, we have shown that \(-x = \sim x + 1\). This completes the proof. \(\blacksquare\)","theorem BitVec.neg_eq_not_add (x : BitVec w) : -x = ~~~x + 1 := by
/- To prove that \(-x = \sim x + 1\), it suffices to show that the natural number representation of \(-x\) is equal to the natural number representation of \(\sim x + 1\). In other words, we need to show that \((-x).toNat = (\sim x + 1).toNat\). -/
  apply eq_of_toNat_eq
/- Using the properties of the natural number representation of bitvectors, we can simplify the goal. Specifically, we use the following properties:
- The natural number representation of the negation of a bitvector \( x \) is \((2^w - x.toNat) \mod 2^w\).
- The natural number representation of the complement of a bitvector \( x \) is \(2^w - 1 - x.toNat\).
- The natural number representation of the sum of two bitvectors is the sum of their natural number representations modulo \(2^w\).
- The natural number representation of a bitvector constructed from a natural number \( x \) is \( x \mod 2^w \).
- The modulo operation distributes over addition with modulo.

After simplification, our goal becomes:
\[
(2^w - x.toNat) \mod 2^w = (2^w - 1 - x.toNat + 1) \mod 2^w
\] -/
  simp only [toNat_neg, ofNat_eq_ofNat, toNat_add, toNat_not, toNat_ofNat, Nat.add_mod_mod]
/- To establish the equality \((2^w - x.toNat) \mod 2^w = (2^w - 1 - x.toNat + 1) \mod 2^w\), we can decompose it into proving that:
\[
2^w - x.toNat = 2^w - 1 - x.toNat + 1
\] -/
  congr
/- We know that the natural number representation of \( x \), denoted as \( x.toNat \), is strictly less than \( 2^w \). This is a property of bitvectors, and we denote this fact as \( x.toNat < 2^w \). -/
  have hx : x.toNat < 2^w := x.isLt
/- We use the following properties to simplify the goal:
1. The subtraction identity: \( a - b - c = a - (b + c) \).
2. The commutativity of addition: \( a + b = b + a \).
3. The subtraction identity in reverse: \( a - (b + c) = a - b - c \).
4. The cancellation property of subtraction and addition: \( a - b + b = a \).

Applying these properties, we get:
\[
2^w - x.toNat = 2^w - (1 + x.toNat) + 1
\]
\[
2^w - x.toNat = 2^w - (x.toNat + 1) + 1
\]
\[
2^w - x.toNat = 2^w - x.toNat - 1 + 1
\]
\[
2^w - x.toNat = 2^w - x.toNat
\]

Since the left-hand side and the right-hand side are equal, the goal is satisfied. -/
  rw [Nat.sub_sub, Nat.add_comm 1 x.toNat, ← Nat.sub_sub, Nat.sub_add_cancel (by omega)]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44223,BitVec.toNat_twoPow,theorem BitVec.toNat_twoPow (w : Nat) (i : Nat) : (twoPow w i).toNat = 2^i % 2^w := by sorry,"Underlying Natural Number of Bitvector with \( i \)-th Bit Set to 1 is \( 2^i \mod 2^w \) : For any natural numbers \( w \) and \( i \), the underlying natural number of the bitvector \( \text{twoPow}(w, i) \) is equal to \( 2^i \mod 2^w \), i.e., \(\text{toNat}(\text{twoPow}(w, i)) = 2^i \mod 2^w\).","theorem BitVec.toNat_twoPow (w : Nat) (i : Nat) : (twoPow w i).toNat = 2^i % 2^w := by
  rcases w with rfl | w
  · simp [Nat.mod_one]
  · simp only [twoPow, toNat_shiftLeft, toNat_ofNat]
    have h1 : 1 < 2 ^ (w + 1) := Nat.one_lt_two_pow (by omega)
    rw [Nat.mod_eq_of_lt h1, Nat.shiftLeft_eq, Nat.one_mul]","We need to show that for any natural numbers \( w \) and \( i \), the underlying natural number of the bitvector \( \text{twoPow}(w, i) \) is equal to \( 2^i \mod 2^w \).

1. **Case \( w = 0 \):**
- The goal is to show \((\text{twoPow } 0 \, i).toNat = 2^i \mod 2^0\).
- Since \( 2^i \mod 1 = 0 \) for any natural number \( i \), and the underlying natural number of a bitvector of length 0 is 0, the goal simplifies to \((\text{twoPow } 0 \, i).toNat = 0\), which is true.

2. **Case \( w = w' + 1 \):**
- The goal is to show \((\text{twoPow } (w' + 1) \, i).toNat = 2^i \mod 2^{w' + 1}\).
- Using the definitions of `twoPow`, `toNat_shiftLeft`, and `toNat_ofNat`, we simplify the goal to \((1 \mod 2^{w' + 1}) \lll i \mod 2^{w' + 1} = 2^i \mod 2^{w' + 1}\).
- We construct a lemma \( h1 \) that states \( 1 < 2^{w' + 1} \). This is true because \( 2^{w' + 1} \) is always greater than 1 for any natural number \( w' \).
- Using the modulo identity \( a \mod b = a \) when \( a < b \), we simplify \( 1 \mod 2^{w' + 1} \) to 1.
- Using the property of left shift \( a \lll b = a \cdot 2^b \), we simplify \( 1 \lll i \mod 2^{w' + 1} \) to \( 1 \cdot 2^i \mod 2^{w' + 1} \).
- Using the multiplicative identity \( 1 \cdot a = a \), we simplify \( 1 \cdot 2^i \mod 2^{w' + 1} \) to \( 2^i \mod 2^{w' + 1} \).

Thus, the goal is satisfied in both cases, and the theorem is proved. \(\blacksquare\)","theorem BitVec.toNat_twoPow (w : Nat) (i : Nat) : (twoPow w i).toNat = 2^i % 2^w := by
/- We consider two cases: when \( w = 0 \) and when \( w = w' + 1 \) for some natural number \( w' \). -/
  rcases w with rfl | w
/- First, we show that for \( w = 0 \), the goal \((\text{twoPow } 0 \, i).toNat = 2^i \mod 2^0\) simplifies to \((\text{twoPow } 0 \, i).toNat = 2^i \mod 1\). Since \( 2^i \mod 1 = 0 \) for any natural number \( i \), and the underlying natural number of a bitvector of length 0 is 0, the goal is trivially true. -/
  · simp [Nat.mod_one]
/- Next, we consider the case when \( w = w' + 1 \). Using the definitions of `twoPow`, `toNat_shiftLeft`, and `toNat_ofNat`, we simplify the goal \((\text{twoPow } (w' + 1) \, i).toNat = 2^i \mod 2^{w' + 1}\) to \((1 \mod 2^{w' + 1}) \lll i \mod 2^{w' + 1} = 2^i \mod 2^{w' + 1}\). -/
  · simp only [twoPow, toNat_shiftLeft, toNat_ofNat]
/- We construct a lemma \( h1 \) that states \( 1 < 2^{w + 1} \). This is true because \( 2^{w + 1} \) is always greater than 1 for any natural number \( w \). -/
    have h1 : 1 < 2 ^ (w + 1) := Nat.one_lt_two_pow (by omega)
/- Using the lemma \( h1 \), we apply the modulo identity \( a \mod b = a \) when \( a < b \) to simplify \( 1 \mod 2^{w + 1} \) to 1. Then, we use the property of left shift \( a \lll b = a \cdot 2^b \) to simplify \( 1 \lll i \mod 2^{w + 1} \) to \( 1 \cdot 2^i \mod 2^{w + 1} \). Finally, we use the multiplicative identity \( 1 \cdot a = a \) to simplify \( 1 \cdot 2^i \mod 2^{w + 1} \) to \( 2^i \mod 2^{w + 1} \). This completes the proof. -/
    rw [Nat.mod_eq_of_lt h1, Nat.shiftLeft_eq, Nat.one_mul]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44241,BitVec.mul_twoPow_eq_shiftLeft,"theorem BitVec.mul_twoPow_eq_shiftLeft (x : BitVec w) (i : Nat) :
    x * (twoPow w i) = x <<< i := by sorry","Multiplication by Bitvector with \( i \)-th Bit Set to 1 is Equivalent to Left Shift by \( i \) Positions : For any natural number \( w \), any bitvector \( x \) of width \( w \), and any natural number \( i \), the product of \( x \) and the bitvector with the \( i \)-th bit set to 1 (denoted as \(\text{twoPow}(w, i)\)) is equal to the left shift of \( x \) by \( i \) positions, i.e., \( x * \text{twoPow}(w, i) = x \lll i \).","theorem BitVec.mul_twoPow_eq_shiftLeft (x : BitVec w) (i : Nat) :
    x * (twoPow w i) = x <<< i := by
  apply eq_of_toNat_eq
  simp only [toNat_mul, toNat_twoPow, toNat_shiftLeft, Nat.shiftLeft_eq]
  by_cases hi : i < w
  · have hpow : 2^i < 2^w := Nat.pow_lt_pow_of_lt (by omega) (by omega)
    rw [Nat.mod_eq_of_lt hpow]
  · have hpow : 2 ^ i % 2 ^ w = 0 := by
      rw [Nat.mod_eq_zero_of_dvd]
      apply Nat.pow_dvd_pow 2 (by omega)
    simp [Nat.mul_mod, hpow]","To prove that \( x * \text{twoPow}(w, i) = x \lll i \), it suffices to show that the natural number representation of \( x * \text{twoPow}(w, i) \) is equal to the natural number representation of \( x \lll i \), i.e., \((x * \text{twoPow}(w, i)).\text{toNat} = (x \lll i).\text{toNat}\).

Using the properties of the natural number representation of bitvectors, we can simplify the proposition we want to show to:
\[
x.\text{toNat} \cdot (2^i \mod 2^w) \mod 2^w = x.\text{toNat} \cdot 2^i \mod 2^w
\]

Consider two cases:
1. **Case 1: \( i < w \)**
- We first show that \( 2^i < 2^w \). This follows from the fact that the function \( 2^n \) is strictly increasing for natural numbers \( n \), and since \( i < w \), it follows that \( 2^i < 2^w \).
- Since \( 2^i < 2^w \), we can use the property of the modulo operation that \( a \% b = a \) if \( a < b \). Therefore, \( 2^i \% 2^w = 2^i \).
- Substituting this into our goal, we get:
\[
x.\text{toNat} \cdot 2^i \mod 2^w = x.\text{toNat} \cdot 2^i \mod 2^w
\]
- This is trivially true, so the case \( i < w \) is proved.

2. **Case 2: \( i \geq w \)**
- We first show that \( 2^i \% 2^w = 0 \). This follows from the fact that \( 2^w \) divides \( 2^i \) because \( w \leq i \). Therefore, \( 2^i \% 2^w = 0 \).
- Using the property of the modulo operation for multiplication, we can simplify the proposition we want to show to:
\[
x.\text{toNat} \cdot 0 \mod 2^w = x.\text{toNat} \cdot 2^i \mod 2^w
\]
- Since \( 2^i \% 2^w = 0 \), the left-hand side is \( 0 \), and the right-hand side is also \( 0 \). Therefore, the case \( i \geq w \) is proved.

Since both cases are proved, the theorem is established. \(\blacksquare\)","theorem BitVec.mul_twoPow_eq_shiftLeft (x : BitVec w) (i : Nat) :
    x * (twoPow w i) = x <<< i := by
/- To prove that \( x * \text{twoPow}(w, i) = x \lll i \), it suffices to show that the natural number representation of \( x * \text{twoPow}(w, i) \) is equal to the natural number representation of \( x \lll i \), i.e., \((x * \text{twoPow}(w, i)).\text{toNat} = (x \lll i).\text{toNat}\). -/
  apply eq_of_toNat_eq
/- Using the properties of the natural number representation of bitvectors, we can simplify the proposition we want to show to:
\[
x.\text{toNat} \cdot (2^i \mod 2^w) \mod 2^w = x.\text{toNat} \cdot 2^i \mod 2^w
\] -/
  simp only [toNat_mul, toNat_twoPow, toNat_shiftLeft, Nat.shiftLeft_eq]
/- Consider two cases:
1. Assume \( i < w \).
2. Assume \( i \geq w \). -/
  by_cases hi : i < w
/- In the case where \( i < w \), we first show that \( 2^i < 2^w \). This follows from the fact that the function \( 2^n \) is strictly increasing for natural numbers \( n \), and since \( i < w \), it follows that \( 2^i < 2^w \). -/
  · have hpow : 2^i < 2^w := Nat.pow_lt_pow_of_lt (by omega) (by omega)
/- Since \( 2^i < 2^w \), we can use the property of the modulo operation that \( a \% b = a \) if \( a < b \). Therefore, \( 2^i \% 2^w = 2^i \). Substituting this into our goal, we get:
\[
x.\text{toNat} \cdot 2^i \mod 2^w = x.\text{toNat} \cdot 2^i \mod 2^w
\]
This is trivially true, so the case \( i < w \) is proved. -/
    rw [Nat.mod_eq_of_lt hpow]
/- In the case where \( i \geq w \), we first show that \( 2^i \% 2^w = 0 \). This follows from the fact that \( 2^w \) divides \( 2^i \) because \( w \leq i \). Therefore, \( 2^i \% 2^w = 0 \). -/
  · have hpow : 2 ^ i % 2 ^ w = 0 := by
      rw [Nat.mod_eq_zero_of_dvd]
      apply Nat.pow_dvd_pow 2 (by omega)
/- Using the property of the modulo operation for multiplication, we can simplify the proposition we want to show to:
\[
x.\text{toNat} \cdot 0 \mod 2^w = x.\text{toNat} \cdot 2^i \mod 2^w
\]
Since \( 2^i \% 2^w = 0 \), the left-hand side is \( 0 \), and the right-hand side is also \( 0 \). Therefore, the case \( i \geq w \) is proved. -/
    simp [Nat.mul_mod, hpow]","import Init.Data.Bool
import Init.Data.BitVec.Basic
import Init.Data.Fin.Lemmas
import Init.Data.Nat.Lemmas
import Init.Data.Nat.Mod
import Init.Data.Int.Bitwise.Lemmas
import Init.Data.BitVec.Lemmas

open BitVec

"
44328,Int.le.intro_sub,theorem Int.le.intro_sub {a b : Int} (n : Nat) (h : b - a = n) : a ≤ b := by sorry,"Subtraction and Nonnegativity Imply Less Than or Equal To in Integers : For any integers \(a\) and \(b\), and for any natural number \(n\), if \(b - a = n\), then \(a \le b\).","theorem Int.le.intro_sub {a b : Int} (n : Nat) (h : b - a = n) : a ≤ b := by
  simp [le_def, h]; constructor","To prove that \(a \le b\), we start with the given hypothesis that \(b - a = n\) for some natural number \(n\). By the definition of the less than or equal to relation in the integers, \(a \le b\) if and only if \(b - a\) is a nonnegative integer. Since \(n\) is a natural number, it is nonnegative. Therefore, \(b - a = n\) implies that \(b - a\) is nonnegative. Hence, \(a \le b\). This completes the proof.","theorem Int.le.intro_sub {a b : Int} (n : Nat) (h : b - a = n) : a ≤ b := by
/- First, we simplify the goal using the definition of the less than or equal to relation and the given hypothesis \( h \). The definition of \( a \le b \) in the integers is that \( b - a \) is a nonnegative integer. Given that \( b - a = n \) and \( n \) is a natural number (which is nonnegative), we can conclude that \( b - a \) is nonnegative. Therefore, \( a \le b \). -/
  simp [le_def, h]; constructor","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open le
open Nat
"
44332,Int.ofNat_lt,theorem Int.ofNat_lt {n m : Nat} : (↑n : Int) < ↑m ↔ n < m := by sorry,"Preservation of Strict Inequality under Canonical Map from Natural Numbers to Integers: \( \text{Int.ofNat}(n) < \text{Int.ofNat}(m) \leftrightarrow n < m \) : For any natural numbers \( n \) and \( m \), the canonical map from natural numbers to integers, denoted as \( \mathbb{N} \to \mathbb{Z} \), preserves the strict inequality \( n < m \). Specifically, \( \text{Int.ofNat}(n) < \text{Int.ofNat}(m) \) if and only if \( n < m \).","theorem Int.ofNat_lt {n m : Nat} : (↑n : Int) < ↑m ↔ n < m := by
  rw [lt_iff_add_one_le, ← ofNat_succ, ofNat_le]; rfl","To prove that \( \text{Int.ofNat}(n) < \text{Int.ofNat}(m) \) if and only if \( n < m \), we use the following equivalences:
1. By the definition of strict inequality in natural numbers, \( n < m \) is equivalent to \( n + 1 \leq m \).
2. By the property of the canonical map and the successor function, \( \text{Int.ofNat}(n + 1) = \text{Int.ofNat}(n) + 1 \).
3. By the property of the canonical map preserving the order, \( \text{Int.ofNat}(n) \leq \text{Int.ofNat}(m) \) if and only if \( n \leq m \).

Using these equivalences, we can rewrite the goal to show that \( \text{Int.ofNat}(n) + 1 \leq \text{Int.ofNat}(m) \) if and only if \( n + 1 \leq m \). Since the canonical map preserves the order, this is trivially true by the properties of the canonical map and the order in natural numbers. Therefore, \( \text{Int.ofNat}(n) < \text{Int.ofNat}(m) \) if and only if \( n < m \). This completes the proof.","theorem Int.ofNat_lt {n m : Nat} : (↑n : Int) < ↑m ↔ n < m := by
/- To prove that \( \text{Int.ofNat}(n) < \text{Int.ofNat}(m) \) if and only if \( n < m \), we use the following equivalences:
1. \( n < m \) is equivalent to \( n + 1 \leq m \) (by the definition of strict inequality in natural numbers).
2. \( \text{Int.ofNat}(n + 1) = \text{Int.ofNat}(n) + 1 \) (by the property of the canonical map and the successor function).
3. \( \text{Int.ofNat}(n) \leq \text{Int.ofNat}(m) \) if and only if \( n \leq m \) (by the property of the canonical map preserving the order).

Using these equivalences, we can rewrite the goal to show that \( \text{Int.ofNat}(n) + 1 \leq \text{Int.ofNat}(m) \) if and only if \( n + 1 \leq m \). Since the canonical map preserves the order, this is trivially true by the properties of the canonical map and the order in natural numbers. -/
  rw [lt_iff_add_one_le, ← ofNat_succ, ofNat_le]; rfl","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44333,Int.min_eq_right,theorem Int.min_eq_right {a b : Int} (h : b ≤ a) : min a b = b := by sorry,"Minimum Equals Right if Right is Less Than or Equal to Left : For any integers \(a\) and \(b\), if \(b \leq a\), then the minimum of \(a\) and \(b\) is \(b\), i.e., \(\min(a, b) = b\).","theorem Int.min_eq_right {a b : Int} (h : b ≤ a) : min a b = b := by
  rw [Int.min_comm a b]; exact Int.min_eq_left h","To prove that \(\min(a, b) = b\) given \(b \leq a\), we start by using the commutativity property of the minimum function. This property states that \(\min(a, b) = \min(b, a)\). Therefore, our goal is to show that \(\min(b, a) = b\).

Next, we use the fact that if \(b \leq a\), then \(\min(b, a) = b\). Since we have the assumption \(b \leq a\), it follows directly that \(\min(b, a) = b\).

Thus, we have shown that \(\min(a, b) = b\), completing the proof.","theorem Int.min_eq_right {a b : Int} (h : b ≤ a) : min a b = b := by
/- First, we use the commutativity property of the minimum function, which states that \(\min(a, b) = \min(b, a)\). This transforms our goal to show \(\min(b, a) = b\). Then, we use the fact that if \(b \leq a\), then \(\min(b, a) = b\). Since we have the assumption \(b \leq a\), this directly implies that \(\min(b, a) = b\). -/
  rw [Int.min_comm a b]; exact Int.min_eq_left h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44335,Int.min_le_right,theorem Int.min_le_right (a b : Int) : min a b ≤ b := by sorry,"Minimum is Less Than or Equal to Right Argument in Integers : For any integers \(a\) and \(b\), the minimum of \(a\) and \(b\) is less than or equal to \(b\), i.e., \(\min(a, b) \le b\).","theorem Int.min_le_right (a b : Int) : min a b ≤ b := by
  rw [Int.min_def]; split <;> simp [*]","To prove that \(\min(a, b) \le b\), we start by using the definition of the minimum function in a linear order. According to this definition, \(\min(a, b)\) is given by:
\[
\min(a, b) = \begin{cases}
a & \text{if } a \le b \\
b & \text{if } b \le a
\end{cases}
\]
Thus, the goal of showing \(\min(a, b) \le b\) is equivalent to showing:
\[
(\text{if } a \le b \text{ then } a \text{ else } b) \le b
\]

We consider two cases:

1. **Case 1: \(a \le b\)**

In this case, \(\min(a, b) = a\). Therefore, we need to show that \(a \le b\). This is true by the assumption \(a \le b\).

2. **Case 2: \(b \le a\)**

In this case, \(\min(a, b) = b\). Therefore, we need to show that \(b \le b\). This is trivially true by the reflexive property of the order relation.

In both cases, we have shown that \(\min(a, b) \le b\). Therefore, the theorem is proved. \(\blacksquare\)","theorem Int.min_le_right (a b : Int) : min a b ≤ b := by
  rw [Int.min_def]; split <;> simp [*]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44336,Int.min_eq_left,theorem Int.min_eq_left {a b : Int} (h : a ≤ b) : min a b = a := by sorry,"Minimum Equals Left if Left is Less Than or Equal to Right : For any integers \(a\) and \(b\), if \(a \leq b\), then the minimum of \(a\) and \(b\) is \(a\), i.e., \(\min(a, b) = a\).","theorem Int.min_eq_left {a b : Int} (h : a ≤ b) : min a b = a := by
  simp [Int.min_def, h]","We start with the hypothesis that \(a \leq b\). According to the definition of the minimum function, \(\min(a, b)\) is defined as \(a\) if \(a \leq b\) and \(b\) otherwise. Given that \(a \leq b\), it follows directly from the definition that \(\min(a, b) = a\). Therefore, the minimum of \(a\) and \(b\) is indeed \(a\). This completes the proof.","theorem Int.min_eq_left {a b : Int} (h : a ≤ b) : min a b = a := by
  simp [Int.min_def, h]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44337,Int.max_eq_right,theorem Int.max_eq_right {a b : Int} (h : a ≤ b) : max a b = b := by sorry,"Maximum of Integers Equals Right Argument if Left is Less Than or Equal to Right : For any integers \(a\) and \(b\), if \(a \leq b\), then the maximum of \(a\) and \(b\) is \(b\), i.e., \(\max(a, b) = b\).","theorem Int.max_eq_right {a b : Int} (h : a ≤ b) : max a b = b := by
  simp [Int.max_def, h, Int.not_lt.2 h]","To prove that \(\max(a, b) = b\) given \(a \leq b\), we use the definition of the maximum function. The definition states that for any integers \(a\) and \(b\), \(\max(a, b) = b\) if \(a \leq b\), and \(\max(a, b) = a\) otherwise. Since we are given that \(a \leq b\), it follows directly from the definition that \(\max(a, b) = b\). Therefore, the maximum of \(a\) and \(b\) is indeed \(b\). This completes the proof. \(\blacksquare\)","theorem Int.max_eq_right {a b : Int} (h : a ≤ b) : max a b = b := by
/- Using the definition of the maximum function and the given hypothesis \(a \leq b\), we can simplify the expression \(\max(a, b)\) to \(b\). Specifically, the definition of the maximum function states that \(\max(a, b) = b\) if \(a \leq b\). Since we have \(a \leq b\) by hypothesis, it follows that \(\max(a, b) = b\). -/
  simp [Int.max_def, h, Int.not_lt.2 h]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44339,Int.max_eq_left,theorem Int.max_eq_left {a b : Int} (h : b ≤ a) : max a b = a := by sorry,"Maximum of Integers Equals Left Argument if Right is Less Than or Equal to Left : For any integers \(a\) and \(b\), if \(b \leq a\), then the maximum of \(a\) and \(b\) is equal to \(a\), i.e., \(\max(a, b) = a\).","theorem Int.max_eq_left {a b : Int} (h : b ≤ a) : max a b = a := by
  rw [← Int.max_comm b a]; exact Int.max_eq_right h","To prove that \(\max(a, b) = a\) given \(b \leq a\), we start by using the commutativity of the maximum function. The commutativity property states that \(\max(a, b) = \max(b, a)\). Therefore, we can rewrite our goal \(\max(a, b) = a\) as \(\max(b, a) = a\).

Next, we use the property of the maximum function that if \(b \leq a\), then \(\max(b, a) = a\). Since we have the assumption \(b \leq a\), it follows directly that \(\max(b, a) = a\).

Thus, we have shown that \(\max(a, b) = a\), completing the proof.","theorem Int.max_eq_left {a b : Int} (h : b ≤ a) : max a b = a := by
/- First, we use the commutativity of the maximum function, which states that \(\max(a, b) = \max(b, a)\). This allows us to rewrite the goal \(\max(a, b) = a\) as \(\max(b, a) = a\). Then, we use the fact that if \(b \leq a\), then \(\max(b, a) = a\). Since we have the assumption \(b \leq a\), this directly proves our goal. -/
  rw [← Int.max_comm b a]; exact Int.max_eq_right h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44340,Int.le_max_left,theorem Int.le_max_left (a b : Int) : a ≤ max a b := by sorry,"Left Integer is Less Than or Equal to Maximum : For any integers \(a\) and \(b\), it holds that \(a \leq \max(a, b)\).","theorem Int.le_max_left (a b : Int) : a ≤ max a b := by
  rw [Int.max_def]; split <;> simp [*]","To prove that \(a \leq \max(a, b)\) for any integers \(a\) and \(b\), we start by using the definition of the maximum function. According to the definition, \(\max(a, b)\) is given by:
\[
\max(a, b) = \begin{cases}
b & \text{if } a \leq b \\
a & \text{if } a > b
\end{cases}
\]
Thus, the goal \(a \leq \max(a, b)\) can be rewritten as:
\[
a \leq \text{if } a \leq b \text{ then } b \text{ else } a
\]
We now consider the two cases:

1. **Case 1: \(a \leq b\)**

In this case, \(\max(a, b) = b\). Therefore, the goal becomes:
\[
a \leq b
\]
This is true by the assumption \(a \leq b\).

2. **Case 2: \(a > b\)**

In this case, \(\max(a, b) = a\). Therefore, the goal becomes:
\[
a \leq a
\]
This is true by the reflexive property of the inequality, which states that \(a \leq a\) for any integer \(a\).

Since both cases are true, we conclude that \(a \leq \max(a, b)\) for any integers \(a\) and \(b\). This completes the proof.","theorem Int.le_max_left (a b : Int) : a ≤ max a b := by
  rw [Int.max_def]; split <;> simp [*]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44342,Int.eq_natAbs_of_zero_le,theorem Int.eq_natAbs_of_zero_le {a : Int} (h : 0 ≤ a) : a = natAbs a := by sorry,"Non-negative Integer Equals its Absolute Value as a Natural Number : For any integer \( a \), if \( 0 \leq a \), then \( a \) is equal to its absolute value as a natural number, i.e., \( a = \text{natAbs}(a) \).","theorem Int.eq_natAbs_of_zero_le {a : Int} (h : 0 ≤ a) : a = natAbs a := by
  let ⟨n, e⟩ := eq_ofNat_of_zero_le h
  rw [e]; rfl","Given an integer \( a \) such that \( 0 \leq a \), we know from the property of nonnegative integers that there exists a natural number \( n \) such that \( a = n \). Let \( n \) denote this natural number and \( e \) denote the equality \( a = n \).

Using the equality \( a = n \), we substitute \( a \) with \( n \) in the goal. Since \( n \) is a natural number, the absolute value of \( a \) as a natural number, denoted by \( \text{natAbs}(a) \), is also \( n \). Therefore, \( a = \text{natAbs}(a) \) holds by the reflexivity of equality. This completes the proof.","theorem Int.eq_natAbs_of_zero_le {a : Int} (h : 0 ≤ a) : a = natAbs a := by
/- Since \( 0 \leq a \), by the property that any nonnegative integer \( a \) can be expressed as a natural number \( n \), we can write \( a = n \) for some natural number \( n \). Let \( n \) denote this natural number and \( e \) denote the equality \( a = n \). -/
  let ⟨n, e⟩ := eq_ofNat_of_zero_le h
/- Using the equality \( a = n \), we substitute \( a \) with \( n \) in the goal. Since \( n \) is a natural number, \( \text{natAbs}(a) \) is also \( n \). Therefore, \( a = \text{natAbs}(a) \) holds by the reflexivity of equality. -/
  rw [e]; rfl","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44343,Int.eq_iff_le_and_ge,theorem Int.eq_iff_le_and_ge {x y : Int} : x = y ↔ x ≤ y ∧ y ≤ x := by sorry,"Equality of Integers: \( x = y \leftrightarrow x \le y \land y \le x \) : For any integers \( x \) and \( y \), \( x = y \) if and only if \( x \le y \) and \( y \le x \).","theorem Int.eq_iff_le_and_ge {x y : Int} : x = y ↔ x ≤ y ∧ y ≤ x := by
  constructor
  · simp_all
  · intro ⟨h₁, h₂⟩
    exact Int.le_antisymm h₁ h₂","To prove the equivalence \( x = y \leftrightarrow x \le y \land y \le x \), we need to show both directions:

1. **(\( \rightarrow \))** If \( x = y \), then \( x \le y \) and \( y \le x \):
- Assume \( x = y \).
- By the reflexive property of the order relation, \( x \le x \) and \( y \le y \).
- Since \( x = y \), it follows that \( x \le y \) and \( y \le x \).

2. **(\( \leftarrow \))** If \( x \le y \) and \( y \le x \), then \( x = y \):
- Assume \( x \le y \) and \( y \le x \).
- By the antisymmetry property of the order relation on integers, if \( x \le y \) and \( y \le x \), then \( x = y \).

Thus, we have shown both directions, and the equivalence \( x = y \leftrightarrow x \le y \land y \le x \) is proved. \(\blacksquare\)","theorem Int.eq_iff_le_and_ge {x y : Int} : x = y ↔ x ≤ y ∧ y ≤ x := by
/- To prove the equivalence \( x = y \leftrightarrow x \le y \land y \le x \), it suffices to prove both directions: \( x = y \rightarrow x \le y \land y \le x \) and \( x \le y \land y \le x \rightarrow x = y \). -/
  constructor
/- First, we show that \( x = y \rightarrow x \le y \land y \le x \). This is trivial because if \( x = y \), then \( x \le y \) and \( y \le x \) are both true by the reflexive property of the order relation. Therefore, the first direction is proved. -/
  · simp_all
/- Next, we show that \( x \le y \land y \le x \rightarrow x = y \). Assume \( x \le y \) and \( y \le x \). We need to prove that \( x = y \). -/
  · intro ⟨h₁, h₂⟩
/- Since \( x \le y \) and \( y \le x \), by the antisymmetry property of the order relation on integers, we have \( x = y \). This completes the proof of the second direction. -/
    exact Int.le_antisymm h₁ h₂","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44344,Int.le_add_of_nonneg_right,theorem Int.le_add_of_nonneg_right {a b : Int} (h : 0 ≤ b) : a ≤ a + b := by sorry,"Right Addition Preserves Nonnegative Inequality in Integers : For any integers \(a\) and \(b\), if \(0 \le b\), then \(a \le a + b\).","theorem Int.le_add_of_nonneg_right {a b : Int} (h : 0 ≤ b) : a ≤ a + b := by
  have : a + b ≥ a + 0 := Int.add_le_add_left h a
  rwa [Int.add_zero] at this","To prove that \(a \le a + b\) for any integers \(a\) and \(b\) given that \(0 \le b\), we proceed as follows:

1. **Construct a Lemma:**
We first construct a lemma that \(a + b \ge a + 0\). This follows from the property that adding a nonnegative number to any integer preserves the inequality. Since \(0 \le b\), we have:
\[
a + b \ge a + 0
\]

2. **Simplify the Lemma:**
Next, we use the property that \(a + 0 = a\) to simplify the lemma \(a + b \ge a + 0\) to \(a + b \ge a\). This simplification shows that:
\[
a + b \ge a
\]
which is exactly the same as the goal \(a \le a + b\).

Therefore, we have shown that \(a \le a + b\) under the assumption that \(0 \le b\). This completes the proof. \(\blacksquare\)","theorem Int.le_add_of_nonneg_right {a b : Int} (h : 0 ≤ b) : a ≤ a + b := by
/- First, we construct a lemma that \( a + b \ge a + 0 \) using the fact that \( 0 \le b \). This follows from the property that adding a nonnegative number to any integer preserves the inequality. -/
  have : a + b ≥ a + 0 := Int.add_le_add_left h a
/- Next, we use the property that \( a + 0 = a \) to simplify the lemma \( a + b \ge a + 0 \) to \( a + b \ge a \). This simplification shows that the goal \( a \le a + b \) is exactly the same as the lemma we constructed, which we already know to be true. -/
  rwa [Int.add_zero] at this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44345,Int.negSucc_not_nonneg,theorem Int.negSucc_not_nonneg (n : Nat) : 0 ≤ -[n+1] ↔ False := by sorry,"Negative Successor of a Natural Number is Not Nonnegative : For any natural number \( n \), the negative successor of \( n \) in the integers, denoted as \( - (n + 1) \), is nonnegative if and only if the false proposition holds, i.e., \( 0 \le - (n + 1) \leftrightarrow \text{False} \).","theorem Int.negSucc_not_nonneg (n : Nat) : 0 ≤ -[n+1] ↔ False := by
  simp only [Int.not_le, iff_false]; exact Int.negSucc_lt_zero n","To prove that \( 0 \le - (n + 1) \) is equivalent to the false proposition, we start by noting that \( 0 \le - (n + 1) \) is equivalent to the negation of \( - (n + 1) < 0 \). This is because the statement \( 0 \le - (n + 1) \) is false if and only if \( - (n + 1) < 0 \) is true.

We then use the theorem that states \( - (n + 1) < 0 \) for any natural number \( n \). This theorem is true because the negative of any positive integer is less than zero. Therefore, \( - (n + 1) < 0 \) is always true for any natural number \( n \).

Since \( - (n + 1) < 0 \) is always true, the negation of this statement, \( 0 \le - (n + 1) \), is always false. Hence, \( 0 \le - (n + 1) \) is equivalent to the false proposition. This completes the proof.","theorem Int.negSucc_not_nonneg (n : Nat) : 0 ≤ -[n+1] ↔ False := by
/- To prove that \( 0 \le - (n + 1) \) is equivalent to the false proposition, we first use the fact that \( 0 \le - (n + 1) \) is equivalent to the negation of \( - (n + 1) < 0 \). This is because the statement \( 0 \le - (n + 1) \) is false if and only if \( - (n + 1) < 0 \) is true. We then use the theorem that states \( - (n + 1) < 0 \) for any natural number \( n \). Therefore, \( 0 \le - (n + 1) \) is equivalent to the false proposition. -/
  simp only [Int.not_le, iff_false]; exact Int.negSucc_lt_zero n","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44346,Int.neg_neg_of_pos,theorem Int.neg_neg_of_pos {a : Int} (h : 0 < a) : -a < 0 := by sorry,"Negation of a Positive Integer is Negative: \( 0 < a \to -a < 0 \) : For any integer \( a \), if \( 0 < a \), then \( -a < 0 \).","theorem Int.neg_neg_of_pos {a : Int} (h : 0 < a) : -a < 0 := by
  have : -a < -0 := Int.neg_lt_neg h
  rwa [Int.neg_zero] at this","To prove that for any integer \( a \), if \( 0 < a \), then \( -a < 0 \), we proceed as follows:

1. **Step 1: Construct a Lemma**
- We start with the assumption that \( 0 < a \).
- Using the property of ordered additive commutative groups, we know that if \( 0 < a \), then \(-a < -0\). This is because the negation of a strictly positive element is strictly less than the negation of zero.
- Therefore, we have \(-a < -0\).

2. **Step 2: Simplify the Lemma**
- We use the property that the negation of zero is zero, i.e., \(-0 = 0\).
- Substituting \(-0\) with \(0\) in the lemma \(-a < -0\), we get \(-a < 0\).

Thus, we have shown that if \( 0 < a \), then \(-a < 0\). This completes the proof. \(\blacksquare\)","theorem Int.neg_neg_of_pos {a : Int} (h : 0 < a) : -a < 0 := by
/- First, we construct a lemma that \(-a < -0\) using the fact that \(0 < a\). This follows from the property that the negation of a strictly positive element in an ordered additive commutative group is strictly less than the negation of zero. -/
  have : -a < -0 := Int.neg_lt_neg h
/- Next, we use the property that the negation of zero is zero, i.e., \(-0 = 0\), to simplify the lemma \(-a < -0\) to \(-a < 0\). This completes the proof. -/
  rwa [Int.neg_zero] at this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44347,Int.le_of_add_le_add_left,theorem Int.le_of_add_le_add_left {a b c : Int} (h : a + b ≤ a + c) : b ≤ c := by sorry,"Left Addition Cancellation for Less Than or Equal To in Integers : For any integers \(a\), \(b\), and \(c\), if \(a + b \leq a + c\), then \(b \leq c\).","theorem Int.le_of_add_le_add_left {a b c : Int} (h : a + b ≤ a + c) : b ≤ c := by
  have : -a + (a + b) ≤ -a + (a + c) := Int.add_le_add_left h _
  simp [Int.neg_add_cancel_left] at this
  assumption","We start with the assumption that \(a + b \leq a + c\). To prove that \(b \leq c\), we first construct the inequality \(-a + (a + b) \leq -a + (a + c)\) using the property that adding the same element to both sides of an inequality preserves the inequality. Since \(a + b \leq a + c\) by assumption, we have \(-a + (a + b) \leq -a + (a + c)\).

Next, we simplify the inequality \(-a + (a + b) \leq -a + (a + c)\) using the property of additive groups that \(-a + (a + b) = b\) and \(-a + (a + c) = c\). This simplification yields \(b \leq c\).

Thus, the current goal \(b \leq c\) has been proved, and the proof is complete. \(\blacksquare\)","theorem Int.le_of_add_le_add_left {a b c : Int} (h : a + b ≤ a + c) : b ≤ c := by
/- First, we construct the inequality \(-a + (a + b) \leq -a + (a + c)\) using the fact that adding the same element to both sides of an inequality preserves the inequality. Since \(a + b \leq a + c\) by assumption, we have \(-a + (a + b) \leq -a + (a + c)\). -/
  have : -a + (a + b) ≤ -a + (a + c) := Int.add_le_add_left h _
/- Next, we simplify the inequality \(-a + (a + b) \leq -a + (a + c)\) using the property of additive groups that \(-a + (a + b) = b\) and \(-a + (a + c) = c\). This simplification yields \(b \leq c\). -/
  simp [Int.neg_add_cancel_left] at this
/- The current goal \(b \leq c\) has already been proved in the previous step. Therefore, the proof is complete. -/
  assumption","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44348,Int.neg_pos_of_neg,theorem Int.neg_pos_of_neg {a : Int} (h : a < 0) : 0 < -a := by sorry,"Negation of a Negative Integer is Positive: \( a < 0 \to 0 < -a \) : For any integer \( a \), if \( a < 0 \), then \( 0 < -a \).","theorem Int.neg_pos_of_neg {a : Int} (h : a < 0) : 0 < -a := by
  have : -0 < -a := Int.neg_lt_neg h
  rwa [Int.neg_zero] at this","We start with the assumption that \( a < 0 \). We need to show that \( 0 < -a \).

1. First, we construct a lemma that \(-0 < -a\) using the fact that \(a < 0\). By the property of ordered additive commutative groups, if \(a < 0\), then \(-0 < -a\).

2. Next, we use the property that the negation of zero is zero, i.e., \(-0 = 0\), to replace \(-0\) with \(0\) in our lemma. This simplifies our lemma to \(0 < -a\), which is exactly what we need to prove.

Thus, we have shown that if \(a < 0\), then \(0 < -a\). This completes the proof. \(\blacksquare\)","theorem Int.neg_pos_of_neg {a : Int} (h : a < 0) : 0 < -a := by
/- First, we construct a lemma that \(-0 < -a\) using the fact that \(a < 0\). By the property of ordered additive commutative groups, if \(a < 0\), then \(-0 < -a\). -/
  have : -0 < -a := Int.neg_lt_neg h
/- Next, we use the property that the negation of zero is zero, i.e., \(-0 = 0\), to replace \(-0\) with \(0\) in our lemma. This simplifies our lemma to \(0 < -a\), which is exactly what we need to prove. -/
  rwa [Int.neg_zero] at this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44349,Int.neg_nonpos_of_nonneg,theorem Int.neg_nonpos_of_nonneg {a : Int} (h : 0 ≤ a) : -a ≤ 0 := by sorry,"Negation of Nonnegative Integer is Nonpositive : For any integer \( a \), if \( 0 \leq a \), then \( -a \leq 0 \).","theorem Int.neg_nonpos_of_nonneg {a : Int} (h : 0 ≤ a) : -a ≤ 0 := by
  have : -a ≤ -0 := Int.neg_le_neg h
  rwa [Int.neg_zero] at this","We start by assuming that \( 0 \leq a \). We need to show that \(-a \leq 0\).

1. First, we construct the lemma that \(-a \leq -0\) using the fact that if \(0 \leq a\), then \(-a \leq -0\). This follows from the property that negation reverses the inequality in ordered additive commutative groups.
2. Next, we use the property that the negation of zero is zero, i.e., \(-0 = 0\), to replace \(-0\) with \(0\) in the lemma \(-a \leq -0\). This simplifies our lemma to \(-a \leq 0\), which is exactly what we need to prove.

Thus, we have shown that if \(0 \leq a\), then \(-a \leq 0\). This completes the proof. \(\blacksquare\)","theorem Int.neg_nonpos_of_nonneg {a : Int} (h : 0 ≤ a) : -a ≤ 0 := by
/- First, we construct the lemma that \(-a \leq -0\) using the fact that if \(0 \leq a\), then \(-a \leq -0\). This follows from the property that negation reverses the inequality in ordered additive commutative groups. -/
  have : -a ≤ -0 := Int.neg_le_neg h
/- Next, we use the property that the negation of zero is zero, i.e., \(-0 = 0\), to replace \(-0\) with \(0\) in the lemma \(-a \leq -0\). This simplifies our lemma to \(-a \leq 0\), which is exactly what we need to prove. Since this is the same as our goal, the proof is complete. -/
  rwa [Int.neg_zero] at this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44350,Int.neg_nonneg_of_nonpos,theorem Int.neg_nonneg_of_nonpos {a : Int} (h : a ≤ 0) : 0 ≤ -a := by sorry,"Negation of Nonpositive Integer is Nonnegative : For any integer \( a \), if \( a \leq 0 \), then \( 0 \leq -a \).","theorem Int.neg_nonneg_of_nonpos {a : Int} (h : a ≤ 0) : 0 ≤ -a := by
  have : -0 ≤ -a := Int.neg_le_neg h
  rwa [Int.neg_zero] at this","We start by assuming that \( a \leq 0 \). We need to show that \( 0 \leq -a \).

First, we construct the lemma that \(-0 \leq -a\) by using the fact that if \(a \leq 0\), then \(-0 \leq -a\). This follows from the property that the negation of an inequality in an ordered additive commutative group reverses the inequality.

Next, we use the property that the negation of zero is zero, i.e., \(-0 = 0\), to replace \(-0\) with \(0\) in the lemma \(-0 \leq -a\). This simplifies our lemma to \(0 \leq -a\), which is exactly what we need to prove.

Therefore, we have shown that if \(a \leq 0\), then \(0 \leq -a\). This completes the proof. \(\blacksquare\)","theorem Int.neg_nonneg_of_nonpos {a : Int} (h : a ≤ 0) : 0 ≤ -a := by
/- First, we construct the lemma that \(-0 \leq -a\) by using the fact that if \(a \leq 0\), then \(-0 \leq -a\). This follows from the property that the negation of an inequality in an ordered additive commutative group reverses the inequality. -/
  have : -0 ≤ -a := Int.neg_le_neg h
/- Next, we use the property that the negation of zero is zero, i.e., \(-0 = 0\), to replace \(-0\) with \(0\) in the lemma \(-0 \leq -a\). This simplifies our lemma to \(0 \leq -a\), which is exactly what we need to prove. Since this is exactly the same as the assumption we know already, the proof is complete. -/
  rwa [Int.neg_zero] at this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44351,Int.eq_ofNat_of_zero_le,"theorem Int.eq_ofNat_of_zero_le {a : Int} (h : 0 ≤ a) : ∃ n : Nat, a = n := by sorry","Nonnegative Integer Equals Canonical Image of Natural Number: \( 0 \leq a \to \exists n, a = n \) : For any integer \( a \) such that \( 0 \leq a \), there exists a natural number \( n \) such that \( a = n \).","theorem Int.eq_ofNat_of_zero_le {a : Int} (h : 0 ≤ a) : ∃ n : Nat, a = n := by
  have t := le.dest_sub h; rwa [Int.sub_zero] at t","Given an integer \( a \) such that \( 0 \leq a \), we need to show that there exists a natural number \( n \) such that \( a = n \).

1. **Step 1:**
Since \( 0 \leq a \), by the lemma that nonnegativity implies the existence of a nonnegative difference, there exists an integer \( c \) such that \( a = 0 + c \). Simplifying this, we get \( a = c \).

2. **Step 2:**
Since \( a = c \) and \( 0 \leq a \), it follows that \( c \) is a nonnegative integer. Therefore, \( c \) can be viewed as a natural number. Let \( n = c \). Thus, \( a = n \).

Hence, we have shown that there exists a natural number \( n \) such that \( a = n \). This completes the proof.","theorem Int.eq_ofNat_of_zero_le {a : Int} (h : 0 ≤ a) : ∃ n : Nat, a = n := by
/- First, we use the fact that if \( 0 \leq a \), then there exists an integer \( c \) such that \( a = 0 + c \). This is given by the lemma that nonnegativity implies the existence of a nonnegative difference. We then simplify the expression \( 0 + c \) to \( c \) using the property that subtracting zero from any integer \( a \) results in \( a \). Thus, we have \( a = c \). -/
  have t := le.dest_sub h; rwa [Int.sub_zero] at t","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44352,Int.lt_of_sub_pos,theorem Int.lt_of_sub_pos {a b : Int} (h : 0 < a - b) : b < a := by sorry,"Subtraction of Positive Difference Implies Less Than in Integers : For any integers \(a\) and \(b\), if \(0 < a - b\), then \(b < a\).","theorem Int.lt_of_sub_pos {a b : Int} (h : 0 < a - b) : b < a := by
  have h := Int.add_lt_add_right h b
  rwa [Int.sub_add_cancel, Int.zero_add] at h","To prove that \(b < a\) given \(0 < a - b\), we proceed as follows:

1. **Construct a new hypothesis:**
We start by adding \(b\) to both sides of the inequality \(0 < a - b\). This gives us:
\[
0 + b < a - b + b
\]
Simplifying the right-hand side using the property that \(a - b + b = a\) (subtraction and addition cancel each other), we get:
\[
0 + b < a
\]

2. **Simplify the inequality:**
Using the property that \(0 + b = b\) (zero is the additive identity), we further simplify the inequality to:
\[
b < a
\]

Thus, we have shown that if \(0 < a - b\), then \(b < a\). This completes the proof. \(\blacksquare\)","theorem Int.lt_of_sub_pos {a b : Int} (h : 0 < a - b) : b < a := by
/- First, we construct a new hypothesis \( h \) by adding \( b \) to both sides of the inequality \( 0 < a - b \). This gives us \( 0 + b < a - b + b \). -/
  have h := Int.add_lt_add_right h b
/- Next, we use the properties of integer addition and subtraction to simplify the inequality \( 0 + b < a - b + b \). Specifically, we use the fact that \( a - b + b = a \) (subtraction and addition cancel each other) and \( 0 + b = b \) (zero is the additive identity). This simplifies our inequality to \( b < a \), which is exactly what we need to prove. -/
  rwa [Int.sub_add_cancel, Int.zero_add] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44353,Int.le_of_sub_nonneg,theorem Int.le_of_sub_nonneg {a b : Int} (h : 0 ≤ a - b) : b ≤ a := by sorry,"Non-negative Difference Implies Integer Inequality: \(0 \leq a - b \to b \leq a\) : For any integers \(a\) and \(b\), if \(0 \leq a - b\), then \(b \leq a\).","theorem Int.le_of_sub_nonneg {a b : Int} (h : 0 ≤ a - b) : b ≤ a := by
  have h := Int.add_le_add_right h b
  rwa [Int.sub_add_cancel, Int.zero_add] at h","We start with the given inequality \(0 \leq a - b\). To prove that \(b \leq a\), we use the property that adding the same integer to both sides of an inequality preserves the inequality. Specifically, since \(0 \leq a - b\), we have:
\[
0 + b \leq (a - b) + b
\]
Next, we simplify the right-hand side of the inequality using the property that subtraction and addition cancel each other:
\[
(a - b) + b = a
\]
Additionally, we use the property that adding zero to any integer does not change its value:
\[
0 + b = b
\]
Thus, the inequality \(0 + b \leq (a - b) + b\) simplifies to:
\[
b \leq a
\]
This completes the proof. \(\blacksquare\)","theorem Int.le_of_sub_nonneg {a b : Int} (h : 0 ≤ a - b) : b ≤ a := by
/- First, we use the fact that adding the same integer to both sides of an inequality preserves the inequality. Specifically, since \(0 \leq a - b\), we have \(0 + b \leq (a - b) + b\). -/
  have h := Int.add_le_add_right h b
/- Next, we simplify the expression \(0 + b \leq (a - b) + b\) using the properties of addition and subtraction. By the property that subtraction and addition cancel each other, we have \((a - b) + b = a\). Additionally, by the property that adding zero to any integer does not change its value, we have \(0 + b = b\). Therefore, the inequality \(0 + b \leq (a - b) + b\) simplifies to \(b \leq a\). -/
  rwa [Int.sub_add_cancel, Int.zero_add] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44354,Int.le_add_of_nonneg_left,theorem Int.le_add_of_nonneg_left {a b : Int} (h : 0 ≤ b) : a ≤ b + a := by sorry,"Left Addition Preserves Nonnegative Inequality in Integers : For any integers \(a\) and \(b\), if \(0 \le b\), then \(a \le b + a\).","theorem Int.le_add_of_nonneg_left {a b : Int} (h : 0 ≤ b) : a ≤ b + a := by
  have : 0 + a ≤ b + a := Int.add_le_add_right h a
  rwa [Int.zero_add] at this","To prove the theorem, we start with the given assumption that \(0 \le b\). We need to show that \(a \le b + a\).

1. **Step 1: Construct the inequality \(0 + a \le b + a\):**
- Using the property that adding the same element to both sides of an inequality preserves the inequality, we have \(0 + a \le b + a\) because \(0 \le b\).

2. **Step 2: Simplify the inequality using the additive identity:**
- We know that \(0 + a = a\) for any integer \(a\). Therefore, the inequality \(0 + a \le b + a\) simplifies to \(a \le b + a\).

Since the simplified inequality \(a \le b + a\) is exactly what we needed to prove, the theorem is established. Thus, for any integers \(a\) and \(b\), if \(0 \le b\), then \(a \le b + a\). \(\blacksquare\)","theorem Int.le_add_of_nonneg_left {a b : Int} (h : 0 ≤ b) : a ≤ b + a := by
/- First, we construct the inequality \(0 + a \le b + a\) using the fact that \(0 \le b\). This follows from the property that adding the same element to both sides of an inequality preserves the inequality. -/
  have : 0 + a ≤ b + a := Int.add_le_add_right h a
/- Next, we use the property that \(0 + a = a\) to simplify the inequality \(0 + a \le b + a\) to \(a \le b + a\). This simplification is valid because adding zero to any integer \(a\) does not change its value. Therefore, the goal \(a \le b + a\) is exactly the same as the simplified inequality we have just derived. -/
  rwa [Int.zero_add] at this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44355,Int.sub_pos_of_lt,theorem Int.sub_pos_of_lt {a b : Int} (h : b < a) : 0 < a - b := by sorry,"Positive Difference Implies Less Than in Integers : For any integers \(a\) and \(b\), if \(b < a\), then \(0 < a - b\).","theorem Int.sub_pos_of_lt {a b : Int} (h : b < a) : 0 < a - b := by
  have h := Int.add_lt_add_right h (-b)
  rwa [Int.add_right_neg] at h","To prove that \(0 < a - b\) given \(b < a\), we proceed as follows:

1. **Step 1:**
We use the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, since \( b < a \), adding \(-b\) to both sides gives:
\[
b + (-b) < a + (-b)
\]
We denote this new inequality as \( h \).

2. **Step 2:**
We use the property of additive inverses, which states that for any integer \( b \), \( b + (-b) = 0 \). Applying this property to the inequality \( b + (-b) < a + (-b) \), we get:
\[
0 < a + (-b)
\]
This is equivalent to:
\[
0 < a - b
\]
which is exactly what we need to prove.

Therefore, we have shown that if \( b < a \), then \( 0 < a - b \). This completes the proof. \(\blacksquare\)","theorem Int.sub_pos_of_lt {a b : Int} (h : b < a) : 0 < a - b := by
/- First, we use the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, since \( b < a \), adding \(-b\) to both sides gives \( b + (-b) < a + (-b) \). We denote this new inequality as \( h \). -/
  have h := Int.add_lt_add_right h (-b)
/- Next, we use the property of additive inverses, which states that for any integer \( b \), \( b + (-b) = 0 \). Applying this property to the inequality \( b + (-b) < a + (-b) \), we get \( 0 < a + (-b) \). This is equivalent to \( 0 < a - b \), which is exactly what we need to prove. -/
  rwa [Int.add_right_neg] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44356,Int.le_antisymm,theorem Int.le_antisymm {a b : Int} (h₁ : a ≤ b) (h₂ : b ≤ a) : a = b := by sorry,"Antisymmetry of the Less Than or Equal To Relation in Integers : For any integers \(a\) and \(b\), if \(a \leq b\) and \(b \leq a\), then \(a = b\).","theorem Int.le_antisymm {a b : Int} (h₁ : a ≤ b) (h₂ : b ≤ a) : a = b := by
  let ⟨n, hn⟩ := le.dest h₁; let ⟨m, hm⟩ := le.dest h₂
  have := hn; rw [← hm, Int.add_assoc, ← ofNat_add] at this
  have := Int.ofNat.inj <| Int.add_left_cancel <| this.trans (Int.add_zero _).symm
  rw [← hn, Nat.eq_zero_of_add_eq_zero_left this, ofNat_zero, Int.add_zero a]","We start by noting that if \(a \leq b\), then there exists a natural number \(n\) such that \(a + n = b\). Similarly, if \(b \leq a\), then there exists a natural number \(m\) such that \(b + m = a\). We denote these natural numbers by \(n\) and \(m\) respectively, and the corresponding equalities by \(a + n = b\) and \(b + m = a\).

Next, we use the equality \(a + n = b\) and substitute \(b\) with \(a + m\) from the equality \(b + m = a\). This gives us \(a + n = a + m\). Using the associativity of addition, we rewrite this as \(a + (m + n) = a\). Finally, we use the property that the canonical map from natural numbers to integers preserves addition to get \(a + (m + n) = a\).

We now use the fact that if \(a + (m + n) = a\), then by the cancellation property of addition, \(m + n = 0\). Since the canonical map from natural numbers to integers is injective, this implies \(m + n = 0\).

Finally, we substitute \(n\) with \(0\) in the equality \(a + n = b\) using the fact that \(m + n = 0\) and the property that if the sum of two natural numbers is zero, then both must be zero. This gives us \(a + 0 = b\). Using the property that adding zero to any integer does not change the integer, we get \(a = b\).

Thus, we have shown that if \(a \leq b\) and \(b \leq a\), then \(a = b\). This completes the proof. \(\blacksquare\)","theorem Int.le_antisymm {a b : Int} (h₁ : a ≤ b) (h₂ : b ≤ a) : a = b := by
/- First, we use the fact that if \(a \leq b\), then there exists a natural number \(n\) such that \(a + n = b\). Similarly, if \(b \leq a\), then there exists a natural number \(m\) such that \(b + m = a\). We denote these natural numbers by \(n\) and \(m\) respectively, and the corresponding equalities by \(a + n = b\) and \(b + m = a\). -/
  let ⟨n, hn⟩ := le.dest h₁; let ⟨m, hm⟩ := le.dest h₂
/- Next, we use the equality \(a + n = b\) and substitute \(b\) with \(a + m\) from the equality \(b + m = a\). This gives us \(a + n = a + m\). Using the associativity of addition, we rewrite this as \(a + (m + n) = a\). Finally, we use the property that the canonical map from natural numbers to integers preserves addition to get \(a + (m + n) = a\). -/
  have := hn; rw [← hm, Int.add_assoc, ← ofNat_add] at this
/- We now use the fact that if \(a + (m + n) = a\), then by the cancellation property of addition, \(m + n = 0\). Since the canonical map from natural numbers to integers is injective, this implies \(m + n = 0\). -/
  have := Int.ofNat.inj <| Int.add_left_cancel <| this.trans (Int.add_zero _).symm
/- Finally, we substitute \(n\) with \(0\) in the equality \(a + n = b\) using the fact that \(m + n = 0\) and the property that if the sum of two natural numbers is zero, then both must be zero. This gives us \(a + 0 = b\). Using the property that adding zero to any integer does not change the integer, we get \(a = b\). -/
  rw [← hn, Nat.eq_zero_of_add_eq_zero_left this, ofNat_zero, Int.add_zero a]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44357,Int.sub_nonneg_of_le,theorem Int.sub_nonneg_of_le {a b : Int} (h : b ≤ a) : 0 ≤ a - b := by sorry,"Non-negative Difference for Integer Inequality: \( b \leq a \to 0 \leq a - b \) : For any integers \( a \) and \( b \), if \( b \leq a \), then \( 0 \leq a - b \).","theorem Int.sub_nonneg_of_le {a b : Int} (h : b ≤ a) : 0 ≤ a - b := by
  have h := Int.add_le_add_right h (-b)
  rwa [Int.add_right_neg] at h","To prove that \( 0 \leq a - b \) given \( b \leq a \), we proceed as follows:

1. **Step 1:**
We use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, since \( b \leq a \), we have:
\[
b + (-b) \leq a + (-b)
\]

2. **Step 2:**
We use the property of additive inverses, which states that \( b + (-b) = 0 \). Therefore, the inequality \( b + (-b) \leq a + (-b) \) simplifies to:
\[
0 \leq a + (-b)
\]
Since \( a + (-b) \) is the same as \( a - b \), we have:
\[
0 \leq a - b
\]

Thus, we have shown that if \( b \leq a \), then \( 0 \leq a - b \). This completes the proof. \(\blacksquare\)","theorem Int.sub_nonneg_of_le {a b : Int} (h : b ≤ a) : 0 ≤ a - b := by
/- First, we use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, since \( b \leq a \), we have \( b + (-b) \leq a + (-b) \). -/
  have h := Int.add_le_add_right h (-b)
/- Next, we use the property of additive inverses, which states that \( b + (-b) = 0 \). Therefore, the inequality \( b + (-b) \leq a + (-b) \) simplifies to \( 0 \leq a + (-b) \). Since \( a + (-b) \) is the same as \( a - b \), we have \( 0 \leq a - b \). This completes the proof. -/
  rwa [Int.add_right_neg] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44358,Int.sub_left_le_of_le_add,theorem Int.sub_left_le_of_le_add {a b c : Int} (h : a ≤ b + c) : a - b ≤ c := by sorry,"Subtraction of Left Term Preserves Inequality in Integers: \(a \leq b + c \to a - b \leq c\) : For any integers \(a\), \(b\), and \(c\), if \(a \leq b + c\), then \(a - b \leq c\).","theorem Int.sub_left_le_of_le_add {a b c : Int} (h : a ≤ b + c) : a - b ≤ c := by
  have h := Int.add_le_add_right h (-b)
  rwa [Int.add_comm b c, Int.add_neg_cancel_right] at h","We start with the given inequality \(a \leq b + c\). To prove that \(a - b \leq c\), we first use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, we add \(-b\) to both sides of the inequality \(a \leq b + c\):

\[
a + (-b) \leq (b + c) + (-b)
\]

Next, we use the commutativity of addition to rewrite the right-hand side:

\[
a + (-b) \leq c + (b + (-b))
\]

We then use the property that adding an element and its negation results in the original element, so \(b + (-b) = 0\). Therefore, the inequality simplifies to:

\[
a + (-b) \leq c + 0
\]

This further simplifies to:

\[
a - b \leq c
\]

Thus, we have shown that if \(a \leq b + c\), then \(a - b \leq c\). This completes the proof. \(\blacksquare\)","theorem Int.sub_left_le_of_le_add {a b c : Int} (h : a ≤ b + c) : a - b ≤ c := by
/- First, we use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, since \(a \leq b + c\), we can add \(-b\) to both sides to get \(a + (-b) \leq (b + c) + (-b)\). -/
  have h := Int.add_le_add_right h (-b)
/- Next, we use the commutativity of addition to rewrite \((b + c) + (-b)\) as \(c + (b + (-b))\). Then, we use the property that adding an element and its negation results in the original element, so \(b + (-b) = 0\). Therefore, the inequality \(a + (-b) \leq c + 0\) simplifies to \(a - b \leq c\). This completes the proof. -/
  rwa [Int.add_comm b c, Int.add_neg_cancel_right] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44359,Int.mul_le_mul_of_nonneg_right,"theorem Int.mul_le_mul_of_nonneg_right {a b c : Int}
    (h₁ : a ≤ b) (h₂ : 0 ≤ c) : a * c ≤ b * c := by sorry","Right Multiplication Preserves Nonnegative Inequality in Integers : For any integers \(a\), \(b\), and \(c\), if \(a \le b\) and \(0 \le c\), then \(a \cdot c \le b \cdot c\).","theorem Int.mul_le_mul_of_nonneg_right {a b c : Int}
    (h₁ : a ≤ b) (h₂ : 0 ≤ c) : a * c ≤ b * c := by
  rw [Int.mul_comm, Int.mul_comm b]; exact Int.mul_le_mul_of_nonneg_left h₁ h₂","We start with the given hypotheses \(a \le b\) and \(0 \le c\). To prove \(a \cdot c \le b \cdot c\), we use the commutativity of multiplication to rewrite the goal as \(c \cdot a \le c \cdot b\). By the theorem that states if \(a \le b\) and \(0 \le c\), then \(c \cdot a \le c \cdot b\), and since we have \(a \le b\) and \(0 \le c\) by the given hypotheses, this theorem directly gives us the desired inequality \(c \cdot a \le c \cdot b\). Therefore, we have \(a \cdot c \le b \cdot c\). This completes the proof.","theorem Int.mul_le_mul_of_nonneg_right {a b c : Int}
    (h₁ : a ≤ b) (h₂ : 0 ≤ c) : a * c ≤ b * c := by
/- First, we use the commutativity of multiplication to rewrite the goal \(a \cdot c \le b \cdot c\) as \(c \cdot a \le c \cdot b\). Then, we apply the theorem that states if \(a \le b\) and \(0 \le c\), then \(c \cdot a \le c \cdot b\). Since we have \(a \le b\) and \(0 \le c\) by the given hypotheses, this theorem directly gives us the desired inequality \(c \cdot a \le c \cdot b\), which is equivalent to \(a \cdot c \le b \cdot c\). -/
  rw [Int.mul_comm, Int.mul_comm b]; exact Int.mul_le_mul_of_nonneg_left h₁ h₂","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44360,Int.lt_iff_le_not_le,theorem Int.lt_iff_le_not_le {a b : Int} : a < b ↔ a ≤ b ∧ ¬b ≤ a := by sorry,"Characterization of Strict Inequality in Integers: \( a < b \leftrightarrow a \le b \land b \not\le a \) : For any integers \( a \) and \( b \), the inequality \( a < b \) holds if and only if \( a \le b \) and \( b \not\le a \).","theorem Int.lt_iff_le_not_le {a b : Int} : a < b ↔ a ≤ b ∧ ¬b ≤ a := by
  rw [Int.lt_iff_le_and_ne]
  constructor <;> refine fun ⟨h, h'⟩ => ⟨h, h'.imp fun h' => ?_⟩
  · exact Int.le_antisymm h h'
  · subst h'; apply Int.le_refl","We start by using the equivalence that \( a < b \) if and only if \( a \le b \) and \( a \ne b \). This transforms our goal from \( a < b \leftrightarrow a \le b \land \neg b \le a \) to \( a \le b \land a \ne b \leftrightarrow a \le b \land \neg b \le a \).

To prove this equivalence, we need to show both directions:
1. **If \( a \le b \land a \ne b \), then \( a \le b \land \neg b \le a \):**
- Assume \( a \le b \) and \( a \ne b \).
- We need to show \( a \le b \) and \( \neg b \le a \).
- The first part \( a \le b \) is already given.
- For the second part, assume \( b \le a \). By the antisymmetry property of the partial order on integers, if \( a \le b \) and \( b \le a \), then \( a = b \). This contradicts \( a \ne b \). Therefore, \( \neg b \le a \).

2. **If \( a \le b \land \neg b \le a \), then \( a \le b \land a \ne b \):**
- Assume \( a \le b \) and \( \neg b \le a \).
- We need to show \( a \le b \) and \( a \ne b \).
- The first part \( a \le b \) is already given.
- For the second part, assume \( a = b \). Then \( b \le a \) would hold, which contradicts \( \neg b \le a \). Therefore, \( a \ne b \).

Thus, we have shown both directions, completing the proof. Therefore, \( a < b \) if and only if \( a \le b \) and \( b \not\le a \). \(\blacksquare\)","theorem Int.lt_iff_le_not_le {a b : Int} : a < b ↔ a ≤ b ∧ ¬b ≤ a := by
/- First, we use the equivalence that \( a < b \) if and only if \( a \le b \) and \( a \ne b \). This transforms our goal from \( a < b \leftrightarrow a \le b \land \neg b \le a \) to \( a \le b \land a \ne b \leftrightarrow a \le b \land \neg b \le a \). -/
  rw [Int.lt_iff_le_and_ne]
/- To prove the equivalence \( a \le b \land a \ne b \leftrightarrow a \le b \land \neg b \le a \), we need to show both directions:
1. If \( a \le b \land a \ne b \), then \( a \le b \land \neg b \le a \).
2. If \( a \le b \land \neg b \le a \), then \( a \le b \land a \ne b \).

For the first direction, assume \( a \le b \) and \( a \ne b \). We need to show \( a \le b \) and \( \neg b \le a \). The first part is already given. For the second part, we need to show that if \( b \le a \), then \( a = b \), which contradicts \( a \ne b \).

For the second direction, assume \( a \le b \) and \( \neg b \le a \). We need to show \( a \le b \) and \( a \ne b \). The first part is already given. For the second part, we need to show that \( a \ne b \). -/
  constructor <;> refine fun ⟨h, h'⟩ => ⟨h, h'.imp fun h' => ?_⟩
/- To show \( a = b \) from \( a \le b \) and \( b \le a \), we use the antisymmetry property of the partial order on integers. Since \( a \le b \) and \( b \le a \), it follows that \( a = b \). -/
  · exact Int.le_antisymm h h'
/- To show \( b \le a \) from \( a = b \), we substitute \( a \) with \( b \) in the goal, reducing it to \( a \le a \). By the reflexivity property of the less than or equal to relation, \( a \le a \) is always true. -/
  · subst h'; apply Int.le_refl","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44362,Int.lt_iff_le_and_ne,theorem Int.lt_iff_le_and_ne {a b : Int} : a < b ↔ a ≤ b ∧ a ≠ b := by sorry,"Integer Less-Than Characterization: \( a < b \leftrightarrow a \le b \land a \ne b \) : For any integers \( a \) and \( b \), the inequality \( a < b \) holds if and only if \( a \le b \) and \( a \ne b \).","theorem Int.lt_iff_le_and_ne {a b : Int} : a < b ↔ a ≤ b ∧ a ≠ b := by
  refine ⟨fun h => ⟨Int.le_of_lt h, Int.ne_of_lt h⟩, fun ⟨aleb, aneb⟩ => ?_⟩
  let ⟨n, hn⟩ := le.dest aleb
  have : n ≠ 0 := aneb.imp fun eq => by rw [← hn, eq, ofNat_zero, Int.add_zero]
  apply lt.intro; rwa [← Nat.succ_pred_eq_of_pos (Nat.pos_of_ne_zero this)] at hn","To prove the equivalence \( a < b \leftrightarrow a \le b \land a \ne b \), we need to show both directions.

1. **(\( \rightarrow \)) If \( a < b \), then \( a \le b \) and \( a \ne b \):**
- Assume \( a < b \).
- By the definition of strict inequality, \( a \le b \).
- Also, by the property of strict inequality, \( a \ne b \).

2. **(\( \leftarrow \)) If \( a \le b \) and \( a \ne b \), then \( a < b \):**
- Assume \( a \le b \) and \( a \ne b \).
- By the definition of non-strict inequality, there exists a natural number \( n \) such that \( a + n = b \).
- We need to show that \( n \ne 0 \). Assume for contradiction that \( n = 0 \).
- Substituting \( n = 0 \) into the equation \( a + n = b \), we get \( a + 0 = b \).
- By the property of addition with zero, \( a + 0 = a \), so \( a = b \).
- This contradicts the assumption \( a \ne b \).
- Therefore, \( n \ne 0 \).
- Since \( n \ne 0 \), \( n \) is a positive natural number.
- By the property of positive natural numbers, \( n = \text{succ}(n - 1) \).
- Substituting this into the equation \( a + n = b \), we get \( a + \text{succ}(n - 1) = b \).
- This implies \( a < b \) by the definition of strict inequality.

Thus, we have shown both directions, and the theorem is proved. \(\blacksquare\)","theorem Int.lt_iff_le_and_ne {a b : Int} : a < b ↔ a ≤ b ∧ a ≠ b := by
/- To prove the equivalence \( a < b \leftrightarrow a \le b \land a \ne b \), we need to show both directions. First, if \( a < b \), then \( a \le b \) and \( a \ne b \). Second, if \( a \le b \) and \( a \ne b \), then \( a < b \). We will prove these two implications separately. -/
  refine ⟨fun h => ⟨Int.le_of_lt h, Int.ne_of_lt h⟩, fun ⟨aleb, aneb⟩ => ?_⟩
/- Assume \( a \le b \). By the definition of the non-strict inequality, there exists a natural number \( n \) such that \( a + n = b \). Let \( n \) and the equation \( a + n = b \) be denoted by \( n \) and \( hn \) respectively. -/
  let ⟨n, hn⟩ := le.dest aleb
/- We need to show that \( n \ne 0 \). Assume for contradiction that \( n = 0 \). Then, substituting \( n = 0 \) into the equation \( a + n = b \), we get \( a + 0 = b \). By the property of addition with zero, \( a + 0 = a \), so \( a = b \). This contradicts the assumption \( a \ne b \). Therefore, \( n \ne 0 \). -/
  have : n ≠ 0 := aneb.imp fun eq => by rw [← hn, eq, ofNat_zero, Int.add_zero]
/- To show \( a < b \), we use the definition of strict inequality. Since \( n \ne 0 \), \( n \) is a positive natural number. By the property of positive natural numbers, \( n = \text{succ}(n - 1) \). Substituting this into the equation \( a + n = b \), we get \( a + \text{succ}(n - 1) = b \). This implies \( a < b \) by the definition of strict inequality. -/
  apply lt.intro; rwa [← Nat.succ_pred_eq_of_pos (Nat.pos_of_ne_zero this)] at hn","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44364,Int.mul_lt_mul_of_pos_right,"theorem Int.mul_lt_mul_of_pos_right {a b c : Int}
  (h₁ : a < b) (h₂ : 0 < c) : a * c < b * c := by sorry","Multiplication by Positive Integer Preserves Strict Inequality on the Right : For any integers \(a\), \(b\), and \(c\), if \(a < b\) and \(0 < c\), then \(a \cdot c < b \cdot c\).","theorem Int.mul_lt_mul_of_pos_right {a b c : Int}
  (h₁ : a < b) (h₂ : 0 < c) : a * c < b * c := by
  have : 0 < b - a := Int.sub_pos_of_lt h₁
  have : 0 < (b - a) * c := Int.mul_pos this h₂
  rw [Int.sub_mul] at this
  exact Int.lt_of_sub_pos this","To prove that \(a \cdot c < b \cdot c\) given \(a < b\) and \(0 < c\), we proceed as follows:

1. First, we show that \(0 < b - a\). This follows from the property that if \(a < b\), then \(0 < b - a\).

2. Next, we show that \(0 < (b - a) \cdot c\). This follows from the property that the product of two positive integers is positive, using the facts \(0 < b - a\) and \(0 < c\).

3. We use the distributive property of multiplication over subtraction to rewrite \(0 < (b - a) \cdot c\) as \(0 < b \cdot c - a \cdot c\).

4. Finally, we conclude that \(a \cdot c < b \cdot c\) using the property that if \(0 < b \cdot c - a \cdot c\), then \(a \cdot c < b \cdot c\).

This completes the proof. \(\blacksquare\)","theorem Int.mul_lt_mul_of_pos_right {a b c : Int}
  (h₁ : a < b) (h₂ : 0 < c) : a * c < b * c := by
/- First, we show that \(0 < b - a\) using the fact that \(a < b\). This follows from the property that if \(a < b\), then \(0 < b - a\). -/
  have : 0 < b - a := Int.sub_pos_of_lt h₁
/- Next, we show that \(0 < (b - a) \cdot c\) using the fact that \(0 < b - a\) and \(0 < c\). This follows from the property that the product of two positive integers is positive. -/
  have : 0 < (b - a) * c := Int.mul_pos this h₂
/- We use the distributive property of multiplication over subtraction to rewrite \(0 < (b - a) \cdot c\) as \(0 < b \cdot c - a \cdot c\). -/
  rw [Int.sub_mul] at this
/- Finally, we conclude that \(a \cdot c < b \cdot c\) using the fact that \(0 < b \cdot c - a \cdot c\). This follows from the property that if \(0 < a - b\), then \(b < a\). -/
  exact Int.lt_of_sub_pos this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44365,Int.neg_lt_neg,theorem Int.neg_lt_neg {a b : Int} (h : a < b) : -b < -a := by sorry,"Negation Reverses Strict Inequality in Integers: \( a < b \to -b < -a \) : For any integers \( a \) and \( b \), if \( a < b \), then \( -b < -a \).","theorem Int.neg_lt_neg {a b : Int} (h : a < b) : -b < -a := by
  have : 0 < -a + b := Int.add_left_neg a ▸ Int.add_lt_add_left h (-a)
  have : 0 + -b < -a + b + -b := Int.add_lt_add_right this (-b)
  rwa [Int.add_neg_cancel_right, Int.zero_add] at this","We start with the assumption that \( a < b \). To prove that \( -b < -a \), we proceed as follows:

1. **Step 1:**
We show that \( 0 < -a + b \). This follows from the fact that adding \(-a\) to both sides of the inequality \( a < b \) results in \( 0 < -a + b \), using the property that adding the same element to both sides of a strict inequality preserves the inequality.

2. **Step 2:**
Next, we show that \( 0 + -b < -a + b + -b \). This follows from the fact that adding \(-b\) to both sides of the inequality \( 0 < -a + b \) results in \( 0 + -b < -a + b + -b \), using the property that adding the same element to both sides of a strict inequality preserves the inequality.

3. **Step 3:**
We simplify the inequality \( 0 + -b < -a + b + -b \) using the properties of additive inverses and the additive identity. Specifically, we use the fact that \( a + b + (-b) = a \) (right cancellation of additive inverse) and \( 0 + a = a \) (zero element is the additive identity). This simplifies the inequality to \( -b < -a \).

Thus, we have shown that if \( a < b \), then \( -b < -a \). This completes the proof. \(\blacksquare\)","theorem Int.neg_lt_neg {a b : Int} (h : a < b) : -b < -a := by
/- First, we show that \( 0 < -a + b \). This follows from the fact that adding \(-a\) to both sides of the inequality \( a < b \) results in \( 0 < -a + b \), using the property that adding the same element to both sides of a strict inequality preserves the inequality. -/
  have : 0 < -a + b := Int.add_left_neg a ▸ Int.add_lt_add_left h (-a)
/- Next, we show that \( 0 + -b < -a + b + -b \). This follows from the fact that adding \(-b\) to both sides of the inequality \( 0 < -a + b \) results in \( 0 + -b < -a + b + -b \), using the property that adding the same element to both sides of a strict inequality preserves the inequality. -/
  have : 0 + -b < -a + b + -b := Int.add_lt_add_right this (-b)
/- We simplify the inequality \( 0 + -b < -a + b + -b \) using the properties of additive inverses and the additive identity. Specifically, we use the fact that \( a + b + (-b) = a \) (right cancellation of additive inverse) and \( 0 + a = a \) (zero element is the additive identity). This simplifies the inequality to \( -b < -a \), which is exactly what we need to prove. -/
  rwa [Int.add_neg_cancel_right, Int.zero_add] at this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44366,Int.mul_le_mul_of_nonpos_left,"theorem Int.mul_le_mul_of_nonpos_left {a b c : Int}
    (ha : a ≤ 0) (h : c ≤ b) : a * b ≤ a * c := by sorry","Multiplication by Nonpositive Integer Preserves Inequality on the Left : For any integers \(a\), \(b\), and \(c\), if \(a \leq 0\) and \(c \leq b\), then \(a \cdot b \leq a \cdot c\).","theorem Int.mul_le_mul_of_nonpos_left {a b c : Int}
    (ha : a ≤ 0) (h : c ≤ b) : a * b ≤ a * c := by
  rw [Int.mul_comm a b, Int.mul_comm a c]
  apply Int.mul_le_mul_of_nonpos_right h ha","We start with the given conditions \(a \leq 0\) and \(c \leq b\). Our goal is to prove that \(a \cdot b \leq a \cdot c\).

First, we use the commutativity of multiplication to rewrite the goal:
\[
a \cdot b \leq a \cdot c \quad \text{is equivalent to} \quad b \cdot a \leq c \cdot a.
\]

Next, we apply the theorem that states for any integers \(a, b, c\) in a semiring with a preorder, if \(b \leq c\) and \(a \leq 0\), then \(c \cdot a \leq b \cdot a\). Given that \(c \leq b\) and \(a \leq 0\), this theorem directly implies:
\[
b \cdot a \leq c \cdot a.
\]

Thus, we have shown that \(a \cdot b \leq a \cdot c\), completing the proof. \(\blacksquare\)","theorem Int.mul_le_mul_of_nonpos_left {a b c : Int}
    (ha : a ≤ 0) (h : c ≤ b) : a * b ≤ a * c := by
/- Using the commutativity of multiplication, we can rewrite the goal \( a * b \leq a * c \) as \( b * a \leq c * a \). -/
  rw [Int.mul_comm a b, Int.mul_comm a c]
/- To prove \( b * a \leq c * a \), we use the theorem that states for any integers \( a, b, c \) in a semiring with a preorder, if \( b \leq c \) and \( a \leq 0 \), then \( c * a \leq b * a \). Since we have \( c \leq b \) and \( a \leq 0 \), it suffices to show \( b * a \leq c * a \). -/
  apply Int.mul_le_mul_of_nonpos_right h ha","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44369,Int.natAbs_negOfNat,theorem Int.natAbs_negOfNat (n : Nat) : natAbs (negOfNat n) = n := by sorry,"Absolute Value of Negation of a Natural Number as an Integer Equals the Natural Number : For any natural number \( n \), the absolute value of the negation of \( n \) as an integer, denoted as \(\text{natAbs}(-n)\), is equal to \( n \). In other words, \(\text{natAbs}(\text{Int.negOfNat}(n)) = n\).","theorem Int.natAbs_negOfNat (n : Nat) : natAbs (negOfNat n) = n := by
  cases n <;> rfl","We will consider every possible case of \( n \).

**Case 1: \( n = 0 \)**
The goal is to show that \((\text{negOfNat}(0)).\text{natAbs} = 0\). This is trivially true because the negation of \(0\) as an integer is \(-0\), and the absolute value of \(-0\) is \(0\).

**Case 2: \( n = k + 1 \) for some \( k \in \mathbb{N} \)**
The goal is to show that \((\text{negOfNat}(k + 1)).\text{natAbs} = k + 1\). This is also trivially true because the negation of \(k + 1\) as an integer is \(-(k + 1)\), and the absolute value of \(-(k + 1)\) is \(k + 1\).

Since both cases are trivially true, the theorem holds for all natural numbers \( n \). This completes the proof.","theorem Int.natAbs_negOfNat (n : Nat) : natAbs (negOfNat n) = n := by
/- We will consider every possible case of \( n \).

**Case 1: \( n = 0 \)**
The goal is to show that \((\text{negOfNat}(0)).\text{natAbs} = 0\). This is trivially true because the negation of \(0\) as an integer is \(-0\), and the absolute value of \(-0\) is \(0\).

**Case 2: \( n = k + 1 \) for some \( k \in \mathbb{N} \)**
The goal is to show that \((\text{negOfNat}(k + 1)).\text{natAbs} = k + 1\). This is also trivially true because the negation of \(k + 1\) as an integer is \(-(k + 1)\), and the absolute value of \(-(k + 1)\) is \(k + 1\). -/
  cases n <;> rfl","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44370,Int.toNat_of_nonneg,theorem Int.toNat_of_nonneg {a : Int} (h : 0 ≤ a) : (toNat a : Int) = a := by sorry,"Canonical Map from Non-Negative Integers to Natural Numbers: \( \text{Int.toNat}(a) = a \) for \( 0 \leq a \) : For any integer \( a \) such that \( 0 \leq a \), the canonical map from integers to natural numbers, denoted as \( \text{Int.toNat} \), satisfies \( \text{Int.toNat}(a) = a \). In other words, if \( a \) is a non-negative integer, then \( a \) is mapped to itself as a natural number.","theorem Int.toNat_of_nonneg {a : Int} (h : 0 ≤ a) : (toNat a : Int) = a := by
  rw [toNat_eq_max, Int.max_eq_left h]","To prove that for any integer \( a \) such that \( 0 \leq a \), the canonical map from integers to natural numbers, \( \text{Int.toNat}(a) \), is equal to \( a \), we proceed as follows:

1. By the definition of the canonical map from integers to natural numbers, we have:
\[
a.\text{toNat} = \max(a, 0)
\]
2. Given the hypothesis \( 0 \leq a \), we can use the property of the maximum function that if \( b \leq a \), then \(\max(a, b) = a\). Therefore:
\[
\max(a, 0) = a
\]
3. Combining these results, we get:
\[
a.\text{toNat} = a
\]

Thus, we have shown that for any non-negative integer \( a \), the canonical map from integers to natural numbers, \( \text{Int.toNat}(a) \), is equal to \( a \). This completes the proof. \(\blacksquare\)","theorem Int.toNat_of_nonneg {a : Int} (h : 0 ≤ a) : (toNat a : Int) = a := by
/- First, we use the theorem that the canonical map from integers to natural numbers, \( a.\text{toNat} \), is equal to the maximum of \( a \) and \( 0 \), i.e., \( a.\text{toNat} = \max(a, 0) \). Given the hypothesis \( 0 \leq a \), we can then use the property of the maximum function that if \( b \leq a \), then \(\max(a, b) = a\). Therefore, \(\max(a, 0) = a\). Combining these, we have \( a.\text{toNat} = a \). -/
  rw [toNat_eq_max, Int.max_eq_left h]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44371,Int.lt_add_of_pos_right,theorem Int.lt_add_of_pos_right (a : Int) {b : Int} (h : 0 < b) : a < a + b := by sorry,"Right Addition by Positive Integer Preserves Strict Inequality in Integers : For any integers \(a\) and \(b\), if \(0 < b\), then \(a < a + b\).","theorem Int.lt_add_of_pos_right (a : Int) {b : Int} (h : 0 < b) : a < a + b := by
  have : a + 0 < a + b := Int.add_lt_add_left h a
  rwa [Int.add_zero] at this","To prove that \(a < a + b\) given \(0 < b\), we start by constructing the lemma that \(a + 0 < a + b\). This follows from the property that adding a positive integer \(b\) to any integer \(a\) preserves the strict inequality. Specifically, since \(0 < b\), we have \(a + 0 < a + b\).

Next, we use the property of addition with zero, which states that \(a + 0 = a\). By substituting \(a + 0\) with \(a\) in our lemma, we get \(a < a + b\). This is exactly the goal we need to prove.

Thus, we have shown that if \(0 < b\), then \(a < a + b\). This completes the proof. \(\blacksquare\)","theorem Int.lt_add_of_pos_right (a : Int) {b : Int} (h : 0 < b) : a < a + b := by
/- First, we construct the lemma that \( a + 0 < a + b \) by using the fact that adding a positive integer \( b \) to any integer \( a \) preserves the strict inequality. Specifically, since \( 0 < b \), we have \( a + 0 < a + b \). -/
  have : a + 0 < a + b := Int.add_lt_add_left h a
/- Next, we use the property of addition with zero, which states that \( a + 0 = a \). By substituting \( a + 0 \) with \( a \) in our lemma, we get \( a < a + b \). This is exactly the goal we need to prove. -/
  rwa [Int.add_zero] at this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44372,Int.ofNat_natAbs_of_nonpos,theorem Int.ofNat_natAbs_of_nonpos {a : Int} (H : a ≤ 0) : (natAbs a : Int) = -a := by sorry,"Canonical Map from Absolute Value of Non-Positive Integers to Natural Numbers: \( a.\text{natAbs} = -a \) : For any integer \( a \) such that \( a \leq 0 \), the canonical map from the absolute value of \( a \) to the natural numbers is equal to the negation of \( a \), i.e., \( a.\text{natAbs} = -a \).","theorem Int.ofNat_natAbs_of_nonpos {a : Int} (H : a ≤ 0) : (natAbs a : Int) = -a := by
  rw [← natAbs_neg, natAbs_of_nonneg (Int.neg_nonneg_of_nonpos H)]","We start with the assumption that \( a \leq 0 \). We need to show that the canonical map from the absolute value of \( a \) to the natural numbers, denoted as \( a.\text{natAbs} \), is equal to the negation of \( a \), i.e., \( a.\text{natAbs} = -a \).

First, we use the property that the absolute value of a negative integer is equal to the absolute value of the integer itself. This means:
\[
\text{natAbs}(-a) = \text{natAbs}(a)
\]
Thus, our goal transforms to:
\[
\text{natAbs}(-a) = -a
\]

Next, we use the fact that if \( a \leq 0 \), then \(-a \geq 0\). Since \(-a\) is non-negative, the absolute value of \(-a\) is \(-a\) itself. Therefore:
\[
\text{natAbs}(-a) = -a
\]

This completes the proof, as we have shown that:
\[
a.\text{natAbs} = -a
\]","theorem Int.ofNat_natAbs_of_nonpos {a : Int} (H : a ≤ 0) : (natAbs a : Int) = -a := by
/- First, we use the fact that the absolute value of a negative integer is equal to the absolute value of the integer itself, i.e., \(\text{natAbs}(-a) = \text{natAbs}(a)\). This transforms our goal from \(\text{natAbs}(a) = -a\) to \(\text{natAbs}(-a) = -a\).

Next, we use the fact that if \(a \leq 0\), then \(-a \geq 0\). Since \(-a\) is non-negative, the absolute value of \(-a\) is \(-a\) itself, i.e., \(\text{natAbs}(-a) = -a\). Therefore, our goal is now \(-a = -a\), which is trivially true. -/
  rw [← natAbs_neg, natAbs_of_nonneg (Int.neg_nonneg_of_nonpos H)]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44374,Int.mul_lt_mul_of_pos_left,"theorem Int.mul_lt_mul_of_pos_left {a b c : Int}
  (h₁ : a < b) (h₂ : 0 < c) : c * a < c * b := by sorry","Multiplication by Positive Integer Preserves Strict Inequality on the Left : For any integers \(a\), \(b\), and \(c\), if \(a < b\) and \(0 < c\), then \(c \cdot a < c \cdot b\).","theorem Int.mul_lt_mul_of_pos_left {a b c : Int}
  (h₁ : a < b) (h₂ : 0 < c) : c * a < c * b := by
  have : 0 < c * (b - a) := Int.mul_pos h₂ (Int.sub_pos_of_lt h₁)
  rw [Int.mul_sub] at this
  exact Int.lt_of_sub_pos this","To prove the theorem, we start by noting the given conditions: \(a < b\) and \(0 < c\).

1. **Construct a lemma:**
We first construct a lemma that \(0 < c \cdot (b - a)\). This follows from the fact that \(0 < c\) and \(0 < b - a\) (since \(a < b\)). By the property that the product of two positive integers is positive, we have:
\[
0 < c \cdot (b - a)
\]

2. **Rewrite the lemma:**
Using the distributive property of multiplication over subtraction, we rewrite the lemma:
\[
0 < c \cdot (b - a) \implies 0 < c \cdot b - c \cdot a
\]

3. **Conclude the proof:**
Finally, we use the property that if \(0 < c \cdot b - c \cdot a\), then \(c \cdot a < c \cdot b\). Therefore, we have:
\[
c \cdot a < c \cdot b
\]

This completes the proof. \(\blacksquare\)","theorem Int.mul_lt_mul_of_pos_left {a b c : Int}
  (h₁ : a < b) (h₂ : 0 < c) : c * a < c * b := by
/- First, we construct a lemma that \(0 < c \cdot (b - a)\). This follows from the fact that \(0 < c\) and \(0 < b - a\) (since \(a < b\)). By the property that the product of two positive integers is positive, we have \(0 < c \cdot (b - a)\). -/
  have : 0 < c * (b - a) := Int.mul_pos h₂ (Int.sub_pos_of_lt h₁)
/- Next, we use the distributive property of multiplication over subtraction to rewrite the lemma \(0 < c \cdot (b - a)\) as \(0 < c \cdot b - c \cdot a\). -/
  rw [Int.mul_sub] at this
/- Finally, we use the property that if \(0 < c \cdot b - c \cdot a\), then \(c \cdot a < c \cdot b\). This completes the proof. -/
  exact Int.lt_of_sub_pos this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44375,Int.le_neg_of_le_neg,theorem Int.le_neg_of_le_neg {a b : Int} (h : a ≤ -b) : b ≤ -a := by sorry,"Order Reversal for Negation in Integers: \(a \leq -b \to b \leq -a\) : For any integers \(a\) and \(b\), if \(a \leq -b\), then \(b \leq -a\).","theorem Int.le_neg_of_le_neg {a b : Int} (h : a ≤ -b) : b ≤ -a := by
  have h := Int.neg_le_neg h
  rwa [Int.neg_neg] at h","We start with the assumption that \(a \leq -b\). Using the property that negation reverses inequality in ordered additive commutative groups, we have:
\[
a \leq -b \implies -(-b) \leq -a
\]
By the double negation identity, \(-(-b) = b\). Substituting \(-(-b)\) with \(b\) in the inequality, we get:
\[
b \leq -a
\]
Thus, we have shown that if \(a \leq -b\), then \(b \leq -a\). This completes the proof. \(\blacksquare\)","theorem Int.le_neg_of_le_neg {a b : Int} (h : a ≤ -b) : b ≤ -a := by
/- First, we use the property that negation reverses inequality in ordered additive commutative groups. Since \(a \leq -b\), it follows that \(-(-b) \leq -a\). We denote this new inequality as \(h\). -/
  have h := Int.neg_le_neg h
/- Next, we use the double negation identity, which states that \(-(-b) = b\). By substituting \(-(-b)\) with \(b\) in the inequality \(-(-b) \leq -a\), we get \(b \leq -a\). This is exactly the goal we need to prove. -/
  rwa [Int.neg_neg] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44376,Int.neg_le_of_neg_le,theorem Int.neg_le_of_neg_le {a b : Int} (h : -a ≤ b) : -b ≤ a := by sorry,"Negation Reverses Less Than or Equal To Inequality in Integers: \( -a \le b \to -b \le a \) : For any integers \( a \) and \( b \), if \( -a \le b \), then \( -b \le a \).","theorem Int.neg_le_of_neg_le {a b : Int} (h : -a ≤ b) : -b ≤ a := by
  have h := Int.neg_le_neg h
  rwa [Int.neg_neg] at h","We start with the assumption that \(-a \le b\). Using the property that negation reverses the inequality in an ordered additive commutative group, we deduce that \(-b \le -(-a)\). By the double negation identity, \(-(-a) = a\). Substituting \(-(-a)\) with \(a\) in the inequality \(-b \le -(-a)\), we get \(-b \le a\). Therefore, we have shown that if \(-a \le b\), then \(-b \le a\). This completes the proof.","theorem Int.neg_le_of_neg_le {a b : Int} (h : -a ≤ b) : -b ≤ a := by
/- First, we use the property that negation reverses the inequality in an ordered additive commutative group. Since we have the assumption \(-a \le b\), we can deduce that \(-b \le -(-a)\). -/
  have h := Int.neg_le_neg h
/- Next, we use the double negation identity, which states that \(-(-a) = a\). By substituting \(-(-a)\) with \(a\) in the inequality \(-b \le -(-a)\), we get \(-b \le a\). This is exactly the goal we need to prove. -/
  rwa [Int.neg_neg] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44377,Int.neg_lt_of_neg_lt,theorem Int.neg_lt_of_neg_lt {a b : Int} (h : -a < b) : -b < a := by sorry,"Negation Reverses Strict Inequality in Integers: \(-a < b \to -b < a\) : For any integers \( a \) and \( b \), if \(-a < b\), then \(-b < a\).","theorem Int.neg_lt_of_neg_lt {a b : Int} (h : -a < b) : -b < a := by
  have h := Int.neg_lt_neg h
  rwa [Int.neg_neg] at h","We start with the assumption that \(-a < b\). Using the property that negation reverses strict inequality in ordered additive commutative groups, we have:
\[
-b < -(-a)
\]
By the double negation identity, \(-(-a) = a\). Substituting this into the inequality, we get:
\[
-b < a
\]
Thus, we have shown that if \(-a < b\), then \(-b < a\). This completes the proof. \(\blacksquare\)","theorem Int.neg_lt_of_neg_lt {a b : Int} (h : -a < b) : -b < a := by
/- First, we use the property that negation reverses strict inequality in ordered additive commutative groups. Since \(-a < b\), it follows that \(-b < -(-a)\). We denote this new inequality as \(h\). -/
  have h := Int.neg_lt_neg h
/- Next, we use the double negation identity, which states that \(-(-a) = a\). By substituting \(-(-a)\) with \(a\) in the inequality \(-b < -(-a)\), we get \(-b < a\). This is exactly the goal we need to prove. -/
  rwa [Int.neg_neg] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44378,Int.mul_nonpos_of_nonpos_of_nonneg,"theorem Int.mul_nonpos_of_nonpos_of_nonneg {a b : Int}
  (ha : a ≤ 0) (hb : 0 ≤ b) : a * b ≤ 0 := by sorry","Multiplication of Nonpositive and Nonnegative Integers is Nonpositive : For any integers \(a\) and \(b\), if \(a \leq 0\) and \(0 \leq b\), then \(a \times b \leq 0\).","theorem Int.mul_nonpos_of_nonpos_of_nonneg {a b : Int}
  (ha : a ≤ 0) (hb : 0 ≤ b) : a * b ≤ 0 := by
  have h : a * b ≤ 0 * b := Int.mul_le_mul_of_nonneg_right ha hb
  rwa [Int.zero_mul] at h","To prove the theorem, we start by noting the given conditions: \(a \leq 0\) and \(0 \leq b\). We need to show that \(a \times b \leq 0\).

1. **Construct a lemma:**
We construct a lemma \( h \) that states \( a \times b \leq 0 \times b \). This follows from the property that right multiplication by a nonnegative element preserves inequality. Specifically, since \( a \leq 0 \) and \( 0 \leq b \), we have:
\[
a \times b \leq 0 \times b
\]

2. **Simplify the lemma:**
We use the property that zero multiplied by any integer is zero to simplify the lemma \( h \). Since \( 0 \times b = 0 \), the lemma \( h \) simplifies to:
\[
a \times b \leq 0
\]
This is exactly the goal we need to prove.

Therefore, we have shown that if \(a \leq 0\) and \(0 \leq b\), then \(a \times b \leq 0\). This completes the proof. \(\blacksquare\)","theorem Int.mul_nonpos_of_nonpos_of_nonneg {a b : Int}
  (ha : a ≤ 0) (hb : 0 ≤ b) : a * b ≤ 0 := by
/- First, we construct a lemma \( h \) that states \( a \times b \leq 0 \times b \). This follows from the property that right multiplication by a nonnegative element preserves inequality. Specifically, since \( a \leq 0 \) and \( 0 \leq b \), we have \( a \times b \leq 0 \times b \). -/
  have h : a * b ≤ 0 * b := Int.mul_le_mul_of_nonneg_right ha hb
/- Next, we use the property that zero multiplied by any integer is zero to simplify the lemma \( h \). Since \( 0 \times b = 0 \), the lemma \( h \) simplifies to \( a \times b \leq 0 \). This is exactly the goal we need to prove. -/
  rwa [Int.zero_mul] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44379,Int.self_le_toNat,theorem Int.self_le_toNat (a : Int) : a ≤ toNat a := by sorry,"Integer is Less Than or Equal to its Canonical Image in Natural Numbers: \( a \leq \text{toNat}(a) \) : For any integer \( a \), it holds that \( a \leq \text{toNat}(a) \), where \(\text{toNat}(a)\) is the canonical map from integers to natural numbers. Specifically, if \( a \) is non-negative, \(\text{toNat}(a) = a\), and if \( a \) is negative, \(\text{toNat}(a) = 0\).","theorem Int.self_le_toNat (a : Int) : a ≤ toNat a := by
  rw [toNat_eq_max]; apply Int.le_max_left","To prove that for any integer \( a \), \( a \leq \text{toNat}(a) \), we start by using the property of the canonical map from integers to natural numbers. Specifically, we know that \( a.\text{toNat} = \max(a, 0) \). This means that the canonical map \( a.\text{toNat} \) is the maximum of \( a \) and \( 0 \).

Thus, the goal \( a \leq a.\text{toNat} \) is equivalent to \( a \leq \max(a, 0) \).

- If \( a \geq 0 \), then \( \max(a, 0) = a \). Therefore, \( a \leq a \) is trivially true.
- If \( a < 0 \), then \( \max(a, 0) = 0 \). Therefore, \( a \leq 0 \) is also true since \( a \) is negative.

In both cases, \( a \leq \max(a, 0) \) holds. Hence, \( a \leq \text{toNat}(a) \) for any integer \( a \).

This completes the proof.","theorem Int.self_le_toNat (a : Int) : a ≤ toNat a := by
  rw [toNat_eq_max]; apply Int.le_max_left","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44380,Int.lt_neg_of_lt_neg,theorem Int.lt_neg_of_lt_neg {a b : Int} (h : a < -b) : b < -a := by sorry,"Negation Reverses Strict Inequality in Integers: \( a < -b \to b < -a \) : For any integers \( a \) and \( b \), if \( a < -b \), then \( b < -a \).","theorem Int.lt_neg_of_lt_neg {a b : Int} (h : a < -b) : b < -a := by
  have h := Int.neg_lt_neg h
  rwa [Int.neg_neg] at h","We start with the assumption that \( a < -b \). Using the property that negation reverses strict inequality in ordered additive commutative groups, we have:
\[
a < -b \implies -(-b) < -a
\]
By the double negation identity, \(-(-b) = b\), we can substitute \(-(-b)\) with \(b\) in the inequality:
\[
b < -a
\]
Thus, we have shown that if \( a < -b \), then \( b < -a \). This completes the proof. \(\blacksquare\)","theorem Int.lt_neg_of_lt_neg {a b : Int} (h : a < -b) : b < -a := by
/- First, we use the fact that negation reverses strict inequality in ordered additive commutative groups. Since \( a < -b \), it follows that \( -(-b) < -a \). We denote this new inequality as \( h \). -/
  have h := Int.neg_lt_neg h
/- Next, we use the double negation identity, which states that \(-(-b) = b\). By substituting \(-(-b)\) with \(b\) in the inequality \( -(-b) < -a \), we get \( b < -a \). This is exactly the goal we need to prove. -/
  rwa [Int.neg_neg] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44381,Int.lt_add_of_pos_left,theorem Int.lt_add_of_pos_left (a : Int) {b : Int} (h : 0 < b) : a < b + a := by sorry,"Left Addition by Positive Integer Preserves Strict Inequality in Integers : For any integers \(a\) and \(b\), if \(0 < b\), then \(a < b + a\).","theorem Int.lt_add_of_pos_left (a : Int) {b : Int} (h : 0 < b) : a < b + a := by
  have : 0 + a < b + a := Int.add_lt_add_right h a
  rwa [Int.zero_add] at this","To prove that \(a < b + a\) given \(0 < b\), we start by using the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, since \(0 < b\) (by assumption), we have:
\[
0 + a < b + a
\]
Next, we use the property that adding zero to any integer \(a\) results in \(a\) itself, i.e., \(0 + a = a\). Substituting \(0 + a\) with \(a\) in the inequality \(0 + a < b + a\), we get:
\[
a < b + a
\]
This is exactly the goal we need to prove. Therefore, the theorem is established. \(\blacksquare\)","theorem Int.lt_add_of_pos_left (a : Int) {b : Int} (h : 0 < b) : a < b + a := by
/- First, we construct the inequality \(0 + a < b + a\) using the fact that adding the same element to both sides of a strict inequality preserves the inequality. Since \(0 < b\) (by assumption), we have \(0 + a < b + a\). -/
  have : 0 + a < b + a := Int.add_lt_add_right h a
/- Next, we use the property that adding zero to any integer \(a\) results in \(a\) itself, i.e., \(0 + a = a\). By substituting \(0 + a\) with \(a\) in the inequality \(0 + a < b + a\), we get \(a < b + a\). This is exactly the goal we need to prove. -/
  rwa [Int.zero_add] at this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44383,Int.natAbs_pos,theorem Int.natAbs_pos : 0 < natAbs a ↔ a ≠ 0 := by sorry,"Absolute Value of Integer is Positive if and Only if Integer is Nonzero : For any integer \( a \), the absolute value of \( a \) as a natural number, denoted as \( |a| \), is strictly greater than 0 if and only if \( a \) is not equal to 0. Formally, \( 0 < |a| \) if and only if \( a \neq 0 \).","theorem Int.natAbs_pos : 0 < natAbs a ↔ a ≠ 0 := by
  rw [Nat.pos_iff_ne_zero, Ne, natAbs_eq_zero]","To prove the theorem, we start with the goal \( 0 < a.natAbs \leftrightarrow a \neq 0 \).

1. **Step 1:**
We use the equivalence that for any element \( a \) in a canonically ordered additive commutative monoid, \( 0 < a \) if and only if \( a \neq 0 \). This transforms our goal from \( 0 < a.natAbs \) to \( a.natAbs \neq 0 \).

2. **Step 2:**
We use the definition of inequality \( a \neq 0 \) as \( \neg (a = 0) \). This transforms our goal to \( a.natAbs \neq 0 \leftrightarrow \neg (a = 0) \).

3. **Step 3:**
We use the equivalence that the absolute value of an integer \( a \) is zero if and only if \( a \) itself is zero, which transforms our goal to \( \neg (a = 0) \leftrightarrow a \neq 0 \). This is trivially true by the definition of inequality.

Thus, we have shown that \( 0 < a.natAbs \) if and only if \( a \neq 0 \). This completes the proof. \(\blacksquare\)","theorem Int.natAbs_pos : 0 < natAbs a ↔ a ≠ 0 := by
  rw [Nat.pos_iff_ne_zero, Ne, natAbs_eq_zero]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44384,Int.lt_of_add_lt_add_left,theorem Int.lt_of_add_lt_add_left {a b c : Int} (h : a + b < a + c) : b < c := by sorry,"Left Addition Preserves Strict Inequality in Integers : For any integers \(a\), \(b\), and \(c\), if \(a + b < a + c\), then \(b < c\).","theorem Int.lt_of_add_lt_add_left {a b c : Int} (h : a + b < a + c) : b < c := by
  have : -a + (a + b) < -a + (a + c) := Int.add_lt_add_left h _
  simp [Int.neg_add_cancel_left] at this
  assumption","We start with the given inequality \(a + b < a + c\). To prove that \(b < c\), we first add \(-a\) to both sides of the inequality. By the property that adding the same element to both sides of a strict inequality preserves the inequality, we get:
\[
-a + (a + b) < -a + (a + c)
\]
Next, we simplify the left and right sides of this inequality using the property of additive groups that \(-a + (a + b) = b\) and \(-a + (a + c) = c\). This simplification reduces the inequality to:
\[
b < c
\]
Thus, we have shown that \(b < c\), completing the proof. \(\blacksquare\)","theorem Int.lt_of_add_lt_add_left {a b c : Int} (h : a + b < a + c) : b < c := by
/- First, we construct a new inequality by adding \(-a\) to both sides of the given inequality \(a + b < a + c\). Using the property that adding the same element to both sides of a strict inequality preserves the inequality, we get \(-a + (a + b) < -a + (a + c)\). -/
  have : -a + (a + b) < -a + (a + c) := Int.add_lt_add_left h _
/- Next, we simplify the new inequality \(-a + (a + b) < -a + (a + c)\) using the property of additive groups that \(-a + (a + b) = b\) and \(-a + (a + c) = c\). This simplification reduces the inequality to \(b < c\). -/
  simp [Int.neg_add_cancel_left] at this
/- The current goal \(b < c\) has already been proved in the previous step, so the proof is complete. -/
  assumption","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44385,Int.ne_iff_lt_or_gt,theorem Int.ne_iff_lt_or_gt {a b : Int} : a ≠ b ↔ a < b ∨ b < a := by sorry,"Inequality of Integers: \( a \neq b \leftrightarrow a < b \lor b < a \) : For any integers \( a \) and \( b \), \( a \neq b \) if and only if \( a < b \) or \( b < a \).","theorem Int.ne_iff_lt_or_gt {a b : Int} : a ≠ b ↔ a < b ∨ b < a := by
  constructor
  · intro h
    cases Int.lt_trichotomy a b
    case inl lt => exact Or.inl lt
    case inr h =>
      cases h
      case inl =>simp_all
      case inr gt => exact Or.inr gt
  · intro h
    cases h
    case inl lt => exact Int.ne_of_lt lt
    case inr gt => exact Int.ne_of_gt gt","To prove the equivalence \( a \neq b \leftrightarrow a < b \lor b < a \), we need to prove both directions.

1. **(\( a \neq b \to a < b \lor b < a \))**:
- Let \( h \) be an arbitrary proof that \( a \neq b \).
- We will discuss every possible case of the trichotomy property of the integers \( a \) and \( b \):
- **Case 1**: \( a < b \). By the left introduction of disjunction, \( a < b \lor b < a \) is true.
- **Case 2**: \( a = b \). This contradicts our assumption \( h \) that \( a \neq b \), so this case is impossible.
- **Case 3**: \( b < a \). By the right introduction of disjunction, \( a < b \lor b < a \) is true.
- Therefore, \( a \neq b \to a < b \lor b < a \).

2. **(\( a < b \lor b < a \to a \neq b \))**:
- Let \( h \) be an arbitrary proof that \( a < b \lor b < a \).
- We will discuss every possible case of the disjunction \( a < b \lor b < a \):
- **Case 1**: \( a < b \). By the property that \( a < b \) implies \( a \neq b \), we conclude that \( a \neq b \).
- **Case 2**: \( b < a \). By the property that \( b < a \) implies \( a \neq b \), we conclude that \( a \neq b \).
- Therefore, \( a < b \lor b < a \to a \neq b \).

Since we have proven both directions, we conclude that \( a \neq b \leftrightarrow a < b \lor b < a \). This completes the proof.","theorem Int.ne_iff_lt_or_gt {a b : Int} : a ≠ b ↔ a < b ∨ b < a := by
/- To prove the equivalence \( a \neq b \leftrightarrow a < b \lor b < a \), we need to prove both directions: \( a \neq b \to a < b \lor b < a \) and \( a < b \lor b < a \to a \neq b \). -/
  constructor
/- First, we show that \( a \neq b \to a < b \lor b < a \). Let \( h \) be an arbitrary proof that \( a \neq b \). We need to show that \( a < b \lor b < a \). -/
  · intro h
/- We will discuss every possible case of the trichotomy property of the integers \( a \) and \( b \). The trichotomy property states that one of the following must hold: \( a < b \), \( a = b \), or \( b < a \). -/
    cases Int.lt_trichotomy a b
/- For the case where \( a < b \), we use the left introduction of disjunction to conclude that \( a < b \lor b < a \) is true. -/
    case inl lt => exact Or.inl lt
/- For the case where \( a = b \lor b < a \):
- If \( a = b \), then \( a \neq b \) is false, which contradicts our assumption \( h \). Therefore, this case is impossible.
- If \( b < a \), we use the right introduction of disjunction to conclude that \( a < b \lor b < a \) is true. -/
    case inr h =>
/- We will discuss every possible case of the disjunction \( a < b \lor b < a \):
- If \( a < b \), we use the property that \( a < b \) implies \( a \neq b \) to conclude that \( a \neq b \).
- If \( b < a \), we use the property that \( b < a \) implies \( a \neq b \) to conclude that \( a \neq b \). -/
      cases h
      case inl =>simp_all
      case inr gt => exact Or.inr gt
/- Next, we show that \( a < b \lor b < a \to a \neq b \). Let \( h \) be an arbitrary proof that \( a < b \lor b < a \). We need to show that \( a \neq b \). -/
  · intro h
    cases h
/- For the case where \( a < b \), we use the property that \( a < b \) implies \( a \neq b \) to conclude that \( a \neq b \). -/
    case inl lt => exact Int.ne_of_lt lt
/- For the case where \( b < a \), we use the property that \( b < a \) implies \( a \neq b \) to conclude that \( a \neq b \). -/
    case inr gt => exact Int.ne_of_gt gt","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44386,Int.sub_nonpos_of_le,theorem Int.sub_nonpos_of_le {a b : Int} (h : a ≤ b) : a - b ≤ 0 := by sorry,"Subtraction of Integers is Nonpositive if the First is Less Than or Equal to the Second: \(a \le b \to a - b \le 0\) : For any integers \(a\) and \(b\), if \(a \le b\), then \(a - b \le 0\).","theorem Int.sub_nonpos_of_le {a b : Int} (h : a ≤ b) : a - b ≤ 0 := by
  have h := Int.add_le_add_right h (-b)
  rwa [Int.add_right_neg] at h","To prove that \(a - b \le 0\) given \(a \le b\), we start by using the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, since \(a \le b\), we have:
\[
a + (-b) \le b + (-b)
\]
This simplifies to:
\[
a - b \le 0
\]
Next, we use the property of additive inverses, which states that for any integer \(b\), \(b + (-b) = 0\). Applying this property to the right-hand side of our inequality, we get:
\[
a - b \le 0
\]
This is exactly the inequality we need to prove. Therefore, we have shown that if \(a \le b\), then \(a - b \le 0\). This completes the proof. \(\blacksquare\)","theorem Int.sub_nonpos_of_le {a b : Int} (h : a ≤ b) : a - b ≤ 0 := by
/- First, we use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, since \(a \le b\), we have \(a + (-b) \le b + (-b)\). This gives us the new inequality \(a - b \le 0\). -/
  have h := Int.add_le_add_right h (-b)
/- Next, we use the property of additive inverses, which states that for any integer \(b\), \(b + (-b) = 0\). Applying this property to the right-hand side of our inequality \(a - b \le b + (-b)\), we get \(a - b \le 0\). This is exactly the inequality we need to prove. -/
  rwa [Int.add_right_neg] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44387,Int.le_toNat,theorem Int.le_toNat {n : Nat} {z : Int} (h : 0 ≤ z) : n ≤ z.toNat ↔ (n : Int) ≤ z := by sorry,"Natural Number Less Than or Equal to Integer's Natural Image : For any natural number \( n \) and any integer \( z \) such that \( 0 \le z \), it holds that \( n \le z.toNat \) if and only if \( n \le z \).","theorem Int.le_toNat {n : Nat} {z : Int} (h : 0 ≤ z) : n ≤ z.toNat ↔ (n : Int) ≤ z := by
  rw [← Int.ofNat_le, Int.toNat_of_nonneg h]","We start with the goal of proving that for any natural number \( n \) and any integer \( z \) such that \( 0 \le z \), the inequality \( n \le z.toNat \) holds if and only if \( n \le z \).

1. **Step 1:**
We use the equivalence that for any natural numbers \( m \) and \( n \), \( m \leq n \) if and only if \( \text{ofNat}(m) \leq \text{ofNat}(n) \). This allows us to rewrite the goal \( n \leq z.toNat \) as \( \text{ofNat}(n) \leq \text{ofNat}(z.toNat) \).

2. **Step 2:**
Since \( 0 \leq z \), we use the fact that for any non-negative integer \( a \), \( \text{toNat}(a) = a \). Therefore, \( \text{ofNat}(z.toNat) = z \).

3. **Step 3:**
Combining these, our goal \( n \leq z.toNat \) is equivalent to \( \text{ofNat}(n) \leq z \), which is exactly \( n \leq z \).

Thus, we have shown that \( n \le z.toNat \) if and only if \( n \le z \). This completes the proof. \(\blacksquare\)","theorem Int.le_toNat {n : Nat} {z : Int} (h : 0 ≤ z) : n ≤ z.toNat ↔ (n : Int) ≤ z := by
/- First, we use the equivalence that for any natural numbers \( m \) and \( n \), \( m \leq n \) if and only if \( \text{ofNat}(m) \leq \text{ofNat}(n) \). This allows us to rewrite the goal \( n \leq z.toNat \) as \( \text{ofNat}(n) \leq \text{ofNat}(z.toNat) \). Next, since \( 0 \leq z \), we use the fact that for any non-negative integer \( a \), \( \text{toNat}(a) = a \). Therefore, \( \text{ofNat}(z.toNat) = z \). Combining these, our goal \( n \leq z.toNat \) is equivalent to \( \text{ofNat}(n) \leq z \), which is exactly \( n \leq z \). -/
  rw [← Int.ofNat_le, Int.toNat_of_nonneg h]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44389,Int.add_le_of_le_neg_add,theorem Int.add_le_of_le_neg_add {a b c : Int} (h : b ≤ -a + c) : a + b ≤ c := by sorry,"Addition and Inequality: \(b \leq -a + c \to a + b \leq c\) : For any integers \(a\), \(b\), and \(c\), if \(b \leq -a + c\), then \(a + b \leq c\).","theorem Int.add_le_of_le_neg_add {a b c : Int} (h : b ≤ -a + c) : a + b ≤ c := by
  have h := Int.add_le_add_left h a
  rwa [Int.add_neg_cancel_left] at h","We start with the given inequality \( b \leq -a + c \). To prove that \( a + b \leq c \), we use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, adding \( a \) to both sides of \( b \leq -a + c \) gives us:
\[
a + b \leq a + (-a + c)
\]
Next, we use the cancellation property of addition and negation in the integers, which states that \( a + (-a + c) = c \). Therefore, we can simplify the inequality to:
\[
a + b \leq c
\]
This completes the proof. \(\blacksquare\)","theorem Int.add_le_of_le_neg_add {a b c : Int} (h : b ≤ -a + c) : a + b ≤ c := by
/- First, we use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, since \( b \leq -a + c \), we can add \( a \) to both sides to get \( a + b \leq a + (-a + c) \). -/
  have h := Int.add_le_add_left h a
/- Next, we use the cancellation property of addition and negation in the integers. Since \( a + (-a + c) = c \), we can simplify the inequality \( a + b \leq a + (-a + c) \) to \( a + b \leq c \). This completes the proof. -/
  rwa [Int.add_neg_cancel_left] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44390,Int.le_of_sub_nonpos,theorem Int.le_of_sub_nonpos {a b : Int} (h : a - b ≤ 0) : a ≤ b := by sorry,"Subtraction Nonpositive Implies Less Than or Equal: \(a - b \le 0 \to a \le b\) : For any integers \(a\) and \(b\), if \(a - b \le 0\), then \(a \le b\).","theorem Int.le_of_sub_nonpos {a b : Int} (h : a - b ≤ 0) : a ≤ b := by
  have h := Int.add_le_add_right h b
  rwa [Int.sub_add_cancel, Int.zero_add] at h","To prove that \(a \le b\) given \(a - b \le 0\), we start by using the property that adding the same integer to both sides of an inequality preserves the inequality. Specifically, since \(a - b \le 0\), adding \(b\) to both sides gives:
\[
a - b + b \le 0 + b
\]
Using the property that subtraction and addition cancel each other out, we have:
\[
a - b + b = a
\]
Thus, the inequality simplifies to:
\[
a \le 0 + b
\]
Finally, using the property that adding zero to any integer \(b\) gives \(b\), we have:
\[
0 + b = b
\]
Therefore, the inequality simplifies to:
\[
a \le b
\]
This completes the proof.","theorem Int.le_of_sub_nonpos {a b : Int} (h : a - b ≤ 0) : a ≤ b := by
/- First, we use the property that adding the same integer to both sides of an inequality preserves the inequality. Specifically, since \(a - b \le 0\), adding \(b\) to both sides gives \(a - b + b \le 0 + b\). This simplifies to \(a \le b\). -/
  have h := Int.add_le_add_right h b
/- Next, we simplify the expression \(a - b + b\) using the property that subtraction and addition cancel each other out, i.e., \(a - b + b = a\). Then, we use the property that adding zero to any integer \(b\) gives \(b\), i.e., \(0 + b = b\). Therefore, the inequality \(a - b + b \le 0 + b\) simplifies to \(a \le b\). This is exactly what we needed to show. -/
  rwa [Int.sub_add_cancel, Int.zero_add] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44391,Int.le_neg_add_of_add_le,theorem Int.le_neg_add_of_add_le {a b c : Int} (h : a + b ≤ c) : b ≤ -a + c := by sorry,"Inequality Transformation: \(a + b \le c \to b \le -a + c\) : For any integers \(a\), \(b\), and \(c\), if \(a + b \le c\), then \(b \le -a + c\).","theorem Int.le_neg_add_of_add_le {a b c : Int} (h : a + b ≤ c) : b ≤ -a + c := by
  have h := Int.add_le_add_left h (-a)
  rwa [Int.neg_add_cancel_left] at h","We start with the given inequality \(a + b \le c\). To prove that \(b \le -a + c\), we use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, we add \(-a\) to both sides of the inequality \(a + b \le c\):

\[
-a + (a + b) \le -a + c
\]

Next, we use the property of additive groups that \(-a + (a + b) = b\). Applying this property, we get:

\[
b \le -a + c
\]

Thus, we have shown that if \(a + b \le c\), then \(b \le -a + c\). This completes the proof. \(\blacksquare\)","theorem Int.le_neg_add_of_add_le {a b c : Int} (h : a + b ≤ c) : b ≤ -a + c := by
/- First, we use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, since \(a + b \le c\), we can add \(-a\) to both sides to get \(-a + (a + b) \le -a + c\). -/
  have h := Int.add_le_add_left h (-a)
/- Next, we use the property of additive groups that \(-a + (a + b) = b\). Applying this property to our inequality, we get \(b \le -a + c\). This completes the proof. -/
  rwa [Int.neg_add_cancel_left] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44392,Int.lt_of_sub_neg,theorem Int.lt_of_sub_neg {a b : Int} (h : a - b < 0) : a < b := by sorry,"Subtraction Less Than Zero Implies Less Than in Integers : For any integers \(a\) and \(b\), if \(a - b < 0\), then \(a < b\).","theorem Int.lt_of_sub_neg {a b : Int} (h : a - b < 0) : a < b := by
  have h := Int.add_lt_add_right h b
  rwa [Int.sub_add_cancel, Int.zero_add] at h","To prove the theorem, we start with the given inequality \(a - b < 0\). We construct a new hypothesis by adding \(b\) to both sides of this inequality:
\[
a - b + b < 0 + b
\]
Using the property of subtraction and addition, we know that \(a - b + b = a\). Additionally, using the property of the zero element, we know that \(0 + b = b\). Therefore, the inequality simplifies to:
\[
a < b
\]
This is exactly the goal we need to prove. Hence, we have shown that if \(a - b < 0\), then \(a < b\). This completes the proof. \(\blacksquare\)","theorem Int.lt_of_sub_neg {a b : Int} (h : a - b < 0) : a < b := by
/- First, we construct a new hypothesis \( h \) by adding \( b \) to both sides of the inequality \( a - b < 0 \). This gives us \( a - b + b < 0 + b \). -/
  have h := Int.add_lt_add_right h b
/- Next, we use the properties of subtraction and addition to simplify the inequality \( a - b + b < 0 + b \). By the property that \( a - b + b = a \) and the property that \( 0 + b = b \), we can rewrite the inequality as \( a < b \). This is exactly the goal we need to prove. -/
  rwa [Int.sub_add_cancel, Int.zero_add] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44393,Int.sub_neg_of_lt,theorem Int.sub_neg_of_lt {a b : Int} (h : a < b) : a - b < 0 := by sorry,"Subtraction of Integers is Negative if First is Less Than Second: \(a < b \to a - b < 0\) : For any integers \(a\) and \(b\), if \(a < b\), then \(a - b < 0\).","theorem Int.sub_neg_of_lt {a b : Int} (h : a < b) : a - b < 0 := by
  have h := Int.add_lt_add_right h (-b)
  rwa [Int.add_right_neg] at h","To prove that for any integers \(a\) and \(b\), if \(a < b\), then \(a - b < 0\), we proceed as follows:

1. **Step 1:**
We start with the given inequality \(a < b\). Using the property that adding the same element to both sides of a strict inequality preserves the inequality, we add \(-b\) to both sides:
\[
a + (-b) < b + (-b)
\]
This simplifies to:
\[
a - b < b - b
\]

2. **Step 2:**
Next, we use the property of additive inverses, which states that for any integer \(b\), \(b + (-b) = 0\). Applying this property to the right-hand side of the inequality, we get:
\[
a - b < 0
\]
This is exactly the inequality we needed to prove.

Therefore, we have shown that if \(a < b\), then \(a - b < 0\). This completes the proof. \(\blacksquare\)","theorem Int.sub_neg_of_lt {a b : Int} (h : a < b) : a - b < 0 := by
/- First, we use the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, since \(a < b\), adding \(-b\) to both sides gives \(a + (-b) < b + (-b)\). -/
  have h := Int.add_lt_add_right h (-b)
/- Next, we use the property of additive inverses, which states that for any integer \(b\), \(b + (-b) = 0\). Applying this property to the inequality \(a + (-b) < b + (-b)\), we get \(a + (-b) < 0\). This is exactly the same as \(a - b < 0\), which is what we needed to show. -/
  rwa [Int.add_right_neg] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44394,Int.add_le_of_le_sub_right,theorem Int.add_le_of_le_sub_right {a b c : Int} (h : a ≤ c - b) : a + b ≤ c := by sorry,"Subtraction and Addition Inequality: \(a \leq c - b \to a + b \leq c\) : For any integers \(a\), \(b\), and \(c\), if \(a \leq c - b\), then \(a + b \leq c\).","theorem Int.add_le_of_le_sub_right {a b c : Int} (h : a ≤ c - b) : a + b ≤ c := by
  have h := Int.add_le_add_right h b
  rwa [Int.sub_add_cancel] at h","We start with the given inequality \(a \leq c - b\). To prove that \(a + b \leq c\), we use the property that adding the same integer to both sides of an inequality preserves the inequality. Specifically, since \(a \leq c - b\), we have:
\[
a + b \leq (c - b) + b
\]
Next, we use the property that subtraction and addition cancel each other out in an additive group. Therefore, \((c - b) + b = c\). Substituting this into our inequality, we get:
\[
a + b \leq c
\]
Thus, we have shown that if \(a \leq c - b\), then \(a + b \leq c\). This completes the proof. \(\blacksquare\)","theorem Int.add_le_of_le_sub_right {a b c : Int} (h : a ≤ c - b) : a + b ≤ c := by
/- First, we use the fact that adding the same integer to both sides of an inequality preserves the inequality. Specifically, since \(a \leq c - b\), we have \(a + b \leq (c - b) + b\). -/
  have h := Int.add_le_add_right h b
/- Next, we use the property that subtraction and addition cancel each other out in an additive group. Therefore, \((c - b) + b = c\). Substituting this into our inequality, we get \(a + b \leq c\). This completes the proof. -/
  rwa [Int.sub_add_cancel] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44395,Int.le_add_of_neg_add_le,theorem Int.le_add_of_neg_add_le {a b c : Int} (h : -b + a ≤ c) : a ≤ b + c := by sorry,"Inequality Preservation: \(-b + a \le c \to a \le b + c\) : For any integers \(a\), \(b\), and \(c\), if \(-b + a \le c\), then \(a \le b + c\).","theorem Int.le_add_of_neg_add_le {a b c : Int} (h : -b + a ≤ c) : a ≤ b + c := by
  have h := Int.add_le_add_left h b
  rwa [Int.add_neg_cancel_left] at h","We start with the given inequality \(-b + a \le c\). To prove that \(a \le b + c\), we use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, adding \(b\) to both sides of \(-b + a \le c\) gives:
\[
b + (-b + a) \le b + c
\]
Next, we use the cancellation property of addition and negation in the integers, which states that \(b + (-b + a) = a\). Therefore, the inequality simplifies to:
\[
a \le b + c
\]
This completes the proof. \(\blacksquare\)","theorem Int.le_add_of_neg_add_le {a b c : Int} (h : -b + a ≤ c) : a ≤ b + c := by
/- First, we use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, since \(-b + a \le c\), adding \(b\) to both sides gives \(b + (-b + a) \le b + c\). -/
  have h := Int.add_le_add_left h b
/- Next, we use the cancellation property of addition and negation in the integers. Since \(b + (-b + a) = a\), we can simplify the inequality \(b + (-b + a) \le b + c\) to \(a \le b + c\). This completes the proof. -/
  rwa [Int.add_neg_cancel_left] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44396,Int.add_le_of_le_sub_left,theorem Int.add_le_of_le_sub_left {a b c : Int} (h : b ≤ c - a) : a + b ≤ c := by sorry,"Inequality Transformation: \(b \le c - a \to a + b \le c\) : For any integers \(a\), \(b\), and \(c\), if \(b \le c - a\), then \(a + b \le c\).","theorem Int.add_le_of_le_sub_left {a b c : Int} (h : b ≤ c - a) : a + b ≤ c := by
  have h := Int.add_le_add_left h a
  rwa [← Int.add_sub_assoc, Int.add_comm a c, Int.add_sub_cancel] at h","We start with the given inequality \( b \leq c - a \). By the property that adding the same integer to both sides of an inequality preserves the inequality, we have:
\[ a + b \leq a + (c - a). \]

Next, we simplify the right-hand side of the inequality:
1. Using the associativity of addition and subtraction, we get:
\[ a + (c - a) = a + c - a. \]
2. Using the commutativity of addition, we get:
\[ a + c - a = c + a - a. \]
3. Using the cancellation property of addition and subtraction, we get:
\[ c + a - a = c. \]

Thus, we have:
\[ a + b \leq c. \]

This completes the proof. \(\blacksquare\)","theorem Int.add_le_of_le_sub_left {a b c : Int} (h : b ≤ c - a) : a + b ≤ c := by
/- First, we use the property that adding the same integer to both sides of an inequality preserves the inequality. Specifically, since \( b \leq c - a \), we have \( a + b \leq a + (c - a) \). -/
  have h := Int.add_le_add_left h a
/- Next, we simplify the expression \( a + (c - a) \) using the following properties:
1. The associativity of addition and subtraction: \( a + (c - a) = a + c - a \).
2. The commutativity of addition: \( a + c - a = c + a - a \).
3. The cancellation property of addition and subtraction: \( c + a - a = c \).

Thus, we have \( a + b \leq c \), which is exactly what we need to prove. -/
  rwa [← Int.add_sub_assoc, Int.add_comm a c, Int.add_sub_cancel] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44397,Int.le_sub_left_of_add_le,theorem Int.le_sub_left_of_add_le {a b c : Int} (h : a + b ≤ c) : b ≤ c - a := by sorry,"Subtraction and Addition Inequality: \(a + b \leq c \to b \leq c - a\) : For any integers \(a\), \(b\), and \(c\), if \(a + b \leq c\), then \(b \leq c - a\).","theorem Int.le_sub_left_of_add_le {a b c : Int} (h : a + b ≤ c) : b ≤ c - a := by
  have h := Int.add_le_add_right h (-a)
  rwa [Int.add_comm a b, Int.add_neg_cancel_right] at h","We start with the given inequality \(a + b \leq c\). To prove that \(b \leq c - a\), we first use the property that adding the same integer to both sides of an inequality preserves the inequality. Specifically, adding \(-a\) to both sides of \(a + b \leq c\) gives:
\[
a + b + (-a) \leq c + (-a).
\]
Next, we use the commutativity of addition to rewrite the left-hand side:
\[
b + a + (-a) \leq c + (-a).
\]
Then, we use the property that adding an integer and its negation results in the original integer:
\[
b \leq c + (-a).
\]
Since \(c + (-a)\) is the same as \(c - a\), we have:
\[
b \leq c - a.
\]
Thus, we have shown that if \(a + b \leq c\), then \(b \leq c - a\). This completes the proof. \(\blacksquare\)","theorem Int.le_sub_left_of_add_le {a b c : Int} (h : a + b ≤ c) : b ≤ c - a := by
/- First, we use the property that adding the same integer to both sides of an inequality preserves the inequality. Specifically, since \(a + b \leq c\), adding \(-a\) to both sides gives \(a + b + (-a) \leq c + (-a)\). -/
  have h := Int.add_le_add_right h (-a)
/- Next, we use the commutativity of addition to rewrite \(a + b + (-a)\) as \(b + a + (-a)\). Then, we use the property that adding an integer and its negation results in the original integer, so \(b + a + (-a) = b\). Therefore, the inequality \(a + b + (-a) \leq c + (-a)\) simplifies to \(b \leq c + (-a)\), which is equivalent to \(b \leq c - a\). -/
  rwa [Int.add_comm a b, Int.add_neg_cancel_right] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44398,Int.max_comm,theorem Int.max_comm (a b : Int) : max a b = max b a := by sorry,"Commutativity of Maximum on Integers: \(\max(a, b) = \max(b, a)\) : For any integers \(a\) and \(b\), the maximum of \(a\) and \(b\) is equal to the maximum of \(b\) and \(a\), i.e., \(\max(a, b) = \max(b, a)\).","theorem Int.max_comm (a b : Int) : max a b = max b a := by
  simp only [Int.max_def]
  by_cases h₁ : a ≤ b <;> by_cases h₂ : b ≤ a <;> simp [h₁, h₂]
  · exact Int.le_antisymm h₂ h₁
  · cases not_or_intro h₁ h₂ <| Int.le_total ..","We start by using the definition of the maximum function for integers, which states that \(\max(a, b) = \text{if } a \leq b \text{ then } b \text{ else } a\). Therefore, our goal is to show that \((\text{if } a \leq b \text{ then } b \text{ else } a) = (\text{if } b \leq a \text{ then } a \text{ else } b)\).

We consider the following cases:

1. **Case 1: \(a \leq b\) and \(b \leq a\):**
- Since \(a \leq b\) and \(b \leq a\), by the antisymmetry of the less than or equal to relation, we have \(a = b\).
- Therefore, \((\text{if } a \leq b \text{ then } b \text{ else } a) = b\) and \((\text{if } b \leq a \text{ then } a \text{ else } b) = a\), which simplifies to \(b = a\).

2. **Case 2: \(a \leq b\) and \(\neg (b \leq a)\):**
- Since \(a \leq b\) and \(\neg (b \leq a)\), we have \((\text{if } a \leq b \text{ then } b \text{ else } a) = b\) and \((\text{if } b \leq a \text{ then } a \text{ else } b) = b\), which simplifies to \(b = b\).

3. **Case 3: \(\neg (a \leq b)\) and \(b \leq a\):**
- Since \(\neg (a \leq b)\) and \(b \leq a\), we have \((\text{if } a \leq b \text{ then } b \text{ else } a) = a\) and \((\text{if } b \leq a \text{ then } a \text{ else } b) = a\), which simplifies to \(a = a\).

4. **Case 4: \(\neg (a \leq b)\) and \(\neg (b \leq a)\):**
- Since \(\neg (a \leq b)\) and \(\neg (b \leq a)\), this case is impossible because the totality of the order relation on integers ensures that either \(a \leq b\) or \(b \leq a\) must hold.

In all valid cases, we have shown that \((\text{if } a \leq b \text{ then } b \text{ else } a) = (\text{if } b \leq a \text{ then } a \text{ else } b)\). Therefore, \(\max(a, b) = \max(b, a)\). This completes the proof. \(\blacksquare\)","theorem Int.max_comm (a b : Int) : max a b = max b a := by
/- First, we use the definition of the maximum function for integers, which states that \(\max(a, b) = \text{if } a \leq b \text{ then } b \text{ else } a\). This simplifies our goal to showing that \((\text{if } a \leq b \text{ then } b \text{ else } a) = (\text{if } b \leq a \text{ then } a \text{ else } b)\). -/
  simp only [Int.max_def]
/- We consider two cases for \(a \leq b\) and \(b \leq a\):

1. **Case 1: \(a \leq b\) and \(b \leq a\):**
- Since \(a \leq b\) and \(b \leq a\), by the antisymmetry of the less than or equal to relation, we have \(a = b\).
- Therefore, \((\text{if } a \leq b \text{ then } b \text{ else } a) = b\) and \((\text{if } b \leq a \text{ then } a \text{ else } b) = a\), which simplifies to \(b = a\).

2. **Case 2: \(a \leq b\) and \(\neg (b \leq a)\):**
- Since \(a \leq b\) and \(\neg (b \leq a)\), we have \((\text{if } a \leq b \text{ then } b \text{ else } a) = b\) and \((\text{if } b \leq a \text{ then } a \text{ else } b) = b\), which simplifies to \(b = b\).

3. **Case 3: \(\neg (a \leq b)\) and \(b \leq a\):**
- Since \(\neg (a \leq b)\) and \(b \leq a\), we have \((\text{if } a \leq b \text{ then } b \text{ else } a) = a\) and \((\text{if } b \leq a \text{ then } a \text{ else } b) = a\), which simplifies to \(a = a\).

4. **Case 4: \(\neg (a \leq b)\) and \(\neg (b \leq a)\):**
- Since \(\neg (a \leq b)\) and \(\neg (b \leq a)\), this case is impossible because the totality of the order relation on integers ensures that either \(a \leq b\) or \(b \leq a\) must hold. -/
  by_cases h₁ : a ≤ b <;> by_cases h₂ : b ≤ a <;> simp [h₁, h₂]
/- In the case where \(a \leq b\) and \(b \leq a\), we use the antisymmetry of the less than or equal to relation to conclude that \(a = b\). -/
  · exact Int.le_antisymm h₂ h₁
/- In the case where \(\neg (a \leq b)\) and \(\neg (b \leq a)\), we use the totality of the order relation to derive a contradiction, thus showing that this case is impossible. -/
  · cases not_or_intro h₁ h₂ <| Int.le_total ..","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44401,Int.neg_add_le_left_of_le_add,theorem Int.neg_add_le_left_of_le_add {a b c : Int} (h : a ≤ b + c) : -b + a ≤ c := by sorry,"Negation and Addition Preserve Inequality: \(a \leq b + c \to -b + a \leq c\) : For any integers \(a\), \(b\), and \(c\), if \(a \leq b + c\), then \(-b + a \leq c\).","theorem Int.neg_add_le_left_of_le_add {a b c : Int} (h : a ≤ b + c) : -b + a ≤ c := by
  rw [Int.add_comm]
  exact Int.sub_left_le_of_le_add h","We start with the hypothesis that \(a \leq b + c\). To prove that \(-b + a \leq c\), we first use the commutativity of addition to rewrite the goal \(-b + a \leq c\) as \(a + (-b) \leq c\).

Next, we apply the theorem that states if \(a \leq b + c\), then \(a - b \leq c\). Since \(a \leq b + c\) is given, this theorem directly implies that \(a + (-b) \leq c\). Therefore, we have \(-b + a \leq c\), which completes the proof.","theorem Int.neg_add_le_left_of_le_add {a b c : Int} (h : a ≤ b + c) : -b + a ≤ c := by
/- Since the addition operation is commutative, we can rewrite the goal \(-b + a \leq c\) as \(a + (-b) \leq c\). -/
  rw [Int.add_comm]
/- The current goal \(a + (-b) \leq c\) is exactly proved by the theorem that states if \(a \leq b + c\), then \(a - b \leq c\). Since we have the hypothesis \(a \leq b + c\), this theorem directly implies \(a + (-b) \leq c\). -/
  exact Int.sub_left_le_of_le_add h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44402,Int.le_sub_right_of_add_le,theorem Int.le_sub_right_of_add_le {a b c : Int} (h : a + b ≤ c) : a ≤ c - b := by sorry,"Subtraction and Addition Inequality: \(a + b \leq c \to a \leq c - b\) : For any integers \(a\), \(b\), and \(c\), if \(a + b \leq c\), then \(a \leq c - b\).","theorem Int.le_sub_right_of_add_le {a b c : Int} (h : a + b ≤ c) : a ≤ c - b := by
  have h := Int.add_le_add_right h (-b)
  rwa [Int.add_neg_cancel_right] at h","We start with the given inequality \(a + b \leq c\). To prove that \(a \leq c - b\), we first use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, adding \(-b\) to both sides of \(a + b \leq c\) gives:
\[
a + b + (-b) \leq c + (-b)
\]
Next, we use the property of the additive inverse in the integers, which states that \(a + b + (-b) = a\). Applying this property, we get:
\[
a \leq c + (-b)
\]
Since \(c + (-b) = c - b\), we have:
\[
a \leq c - b
\]
Thus, we have shown that if \(a + b \leq c\), then \(a \leq c - b\). This completes the proof. \(\blacksquare\)","theorem Int.le_sub_right_of_add_le {a b c : Int} (h : a + b ≤ c) : a ≤ c - b := by
/- First, we use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, since \(a + b \leq c\), adding \(-b\) to both sides gives \(a + b + (-b) \leq c + (-b)\). -/
  have h := Int.add_le_add_right h (-b)
/- Next, we use the property of the additive inverse in the integers, which states that \(a + b + (-b) = a\). Applying this property to our inequality, we get \(a \leq c + (-b)\). Since \(c + (-b) = c - b\), our goal is now to show \(a \leq c - b\). This is exactly the same as the assumption we have already derived. -/
  rwa [Int.add_neg_cancel_right] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44403,Int.le_add_of_sub_right_le,theorem Int.le_add_of_sub_right_le {a b c : Int} (h : a - c ≤ b) : a ≤ b + c := by sorry,"Subtraction and Addition Inequality: \(a - c \leq b \to a \leq b + c\) : For any integers \(a\), \(b\), and \(c\), if \(a - c \leq b\), then \(a \leq b + c\).","theorem Int.le_add_of_sub_right_le {a b c : Int} (h : a - c ≤ b) : a ≤ b + c := by
  have h := Int.add_le_add_right h c
  rwa [Int.sub_add_cancel] at h","We start with the given inequality \(a - c \leq b\). To prove that \(a \leq b + c\), we use the property that adding the same integer to both sides of an inequality preserves the inequality. Specifically, adding \(c\) to both sides of \(a - c \leq b\) gives us:
\[
a - c + c \leq b + c
\]
Next, we use the property that subtraction and addition cancel each other out in an additive group. This means that:
\[
a - c + c = a
\]
Thus, the inequality \(a - c + c \leq b + c\) simplifies to:
\[
a \leq b + c
\]
This completes the proof. \(\blacksquare\)","theorem Int.le_add_of_sub_right_le {a b c : Int} (h : a - c ≤ b) : a ≤ b + c := by
/- First, we use the property that adding the same integer to both sides of an inequality preserves the inequality. Specifically, since \(a - c \leq b\), we can add \(c\) to both sides to get \(a - c + c \leq b + c\). -/
  have h := Int.add_le_add_right h c
/- Next, we use the property that subtraction and addition cancel each other out in an additive group. Specifically, \(a - c + c = a\). Therefore, the inequality \(a - c + c \leq b + c\) simplifies to \(a \leq b + c\). This completes the proof. -/
  rwa [Int.sub_add_cancel] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44404,Int.le_add_of_neg_add_le_left,theorem Int.le_add_of_neg_add_le_left {a b c : Int} (h : -b + a ≤ c) : a ≤ b + c := by sorry,"Inequality Preservation by Addition and Negation: \(-b + a \leq c \to a \leq b + c\) : For any integers \(a\), \(b\), and \(c\), if the sum of \(-b\) and \(a\) is less than or equal to \(c\), then \(a\) is less than or equal to the sum of \(b\) and \(c\). In other words, \(-b + a \leq c\) implies \(a \leq b + c\).","theorem Int.le_add_of_neg_add_le_left {a b c : Int} (h : -b + a ≤ c) : a ≤ b + c := by
  rw [Int.add_comm] at h
  exact Int.le_add_of_sub_left_le h","We start with the assumption that \(-b + a \leq c\). By the commutativity of addition in the integers, we can rewrite this assumption as \(a + (-b) \leq c\).

Next, we use the theorem that states if \(a - b \leq c\), then \(a \leq b + c\). Since \(a + (-b) \leq c\) is equivalent to \(a - b \leq c\), this theorem directly applies. Therefore, we conclude that \(a \leq b + c\).

This completes the proof.","theorem Int.le_add_of_neg_add_le_left {a b c : Int} (h : -b + a ≤ c) : a ≤ b + c := by
/- Since the commutativity of addition in the integers states that \( a + (-b) = -b + a \), we can rewrite the assumption \( -b + a \leq c \) as \( a + (-b) \leq c \). -/
  rw [Int.add_comm] at h
/- The current goal \( a \leq b + c \) is exactly proved by the theorem that states if \( a - b \leq c \), then \( a \leq b + c \). Since we have \( a + (-b) \leq c \), which is equivalent to \( a - b \leq c \), the theorem directly applies, and the goal is satisfied. -/
  exact Int.le_add_of_sub_left_le h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44405,Int.lt_neg_add_of_add_lt,theorem Int.lt_neg_add_of_add_lt {a b c : Int} (h : a + b < c) : b < -a + c := by sorry,"Addition Preserves Strict Inequality: \(a + b < c \to b < -a + c\) : For any integers \(a\), \(b\), and \(c\), if \(a + b < c\), then \(b < -a + c\).","theorem Int.lt_neg_add_of_add_lt {a b c : Int} (h : a + b < c) : b < -a + c := by
  have h := Int.add_lt_add_left h (-a)
  rwa [Int.neg_add_cancel_left] at h","We start with the assumption that \(a + b < c\). To prove that \(b < -a + c\), we use the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, adding \(-a\) to both sides of \(a + b < c\) gives:
\[
-a + (a + b) < -a + c
\]
Next, we use the property of additive groups that \(-a + (a + b) = b\). Substituting this into our inequality, we get:
\[
b < -a + c
\]
This is exactly the goal we need to prove. Therefore, the theorem is established. \(\blacksquare\)","theorem Int.lt_neg_add_of_add_lt {a b c : Int} (h : a + b < c) : b < -a + c := by
/- First, we use the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, since \(a + b < c\), adding \(-a\) to both sides gives \(-a + (a + b) < -a + c\). -/
  have h := Int.add_lt_add_left h (-a)
/- Next, we use the property of additive groups that \(-a + (a + b) = b\). Applying this property to our inequality, we get \(b < -a + c\). This is exactly the goal we need to prove. -/
  rwa [Int.neg_add_cancel_left] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44406,Int.add_lt_of_lt_neg_add,theorem Int.add_lt_of_lt_neg_add {a b c : Int} (h : b < -a + c) : a + b < c := by sorry,"Addition Preserves Strict Inequality: \(b < -a + c \implies a + b < c\) : For any integers \(a, b, c\), if \(b < -a + c\), then \(a + b < c\).","theorem Int.add_lt_of_lt_neg_add {a b c : Int} (h : b < -a + c) : a + b < c := by
  have h := Int.add_lt_add_left h a
  rwa [Int.add_neg_cancel_left] at h","We start with the given inequality \( b < -a + c \). To prove that \( a + b < c \), we use the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, since \( b < -a + c \), we have:
\[
a + b < a + (-a + c)
\]
Next, we use the cancellation property of addition and negation in the integers, which states that \( a + (-a + b) = b \). Applying this property to our inequality, we get:
\[
a + b < c
\]
This is exactly the goal we need to prove. Therefore, we have shown that if \( b < -a + c \), then \( a + b < c \). This completes the proof. \(\blacksquare\)","theorem Int.add_lt_of_lt_neg_add {a b c : Int} (h : b < -a + c) : a + b < c := by
/- First, we use the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, since \( b < -a + c \), we have \( a + b < a + (-a + c) \). -/
  have h := Int.add_lt_add_left h a
/- Next, we use the cancellation property of addition and negation in the integers, which states that \( a + (-a + b) = b \). Applying this property to our inequality, we get \( a + b < c \). This is exactly the goal we need to prove. -/
  rwa [Int.add_neg_cancel_left] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44408,Int.sub_right_le_of_le_add,theorem Int.sub_right_le_of_le_add {a b c : Int} (h : a ≤ b + c) : a - c ≤ b := by sorry,"Subtraction Preserves Inequality: \(a \leq b + c \to a - c \leq b\) : For any integers \(a\), \(b\), and \(c\), if \(a \leq b + c\), then \(a - c \leq b\).","theorem Int.sub_right_le_of_le_add {a b c : Int} (h : a ≤ b + c) : a - c ≤ b := by
  have h := Int.add_le_add_right h (-c)
  rwa [Int.add_neg_cancel_right] at h","We start with the given inequality \(a \leq b + c\). To prove that \(a - c \leq b\), we first use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, we add \(-c\) to both sides of the inequality \(a \leq b + c\):

\[
a + (-c) \leq b + c + (-c)
\]

Next, we use the property of additive inverses in the integers, which states that adding an element and its negation results in the original element. Therefore, we have:

\[
b + c + (-c) = b
\]

Substituting this back into our inequality, we get:

\[
a + (-c) \leq b
\]

This is exactly the same as:

\[
a - c \leq b
\]

Thus, we have shown that if \(a \leq b + c\), then \(a - c \leq b\). This completes the proof. \(\blacksquare\)","theorem Int.sub_right_le_of_le_add {a b c : Int} (h : a ≤ b + c) : a - c ≤ b := by
/- First, we use the property that adding the same element to both sides of an inequality preserves the inequality. Specifically, since \(a \leq b + c\), we can add \(-c\) to both sides to get \(a + (-c) \leq b + c + (-c)\). -/
  have h := Int.add_le_add_right h (-c)
/- Next, we use the property of additive inverses in the integers, which states that adding an element and its negation results in the original element. Therefore, \(b + c + (-c) = b\). Substituting this into our inequality, we get \(a + (-c) \leq b\). This is exactly the same as \(a - c \leq b\). -/
  rwa [Int.add_neg_cancel_right] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44409,Int.le_add_of_neg_add_le_right,theorem Int.le_add_of_neg_add_le_right {a b c : Int} (h : -c + a ≤ b) : a ≤ b + c := by sorry,"Inequality Preservation: \(-c + a \leq b \to a \leq b + c\) : For any integers \(a\), \(b\), and \(c\), if \(-c + a \leq b\), then \(a \leq b + c\).","theorem Int.le_add_of_neg_add_le_right {a b c : Int} (h : -c + a ≤ b) : a ≤ b + c := by
  rw [Int.add_comm] at h
  exact Int.le_add_of_sub_right_le h","We start with the assumption that \(-c + a \leq b\). By the commutativity of addition in the integers, we can rewrite \(-c + a\) as \(a + -c\). Thus, the assumption becomes \(a + -c \leq b\).

Next, we use the theorem that states for any integers \(a\), \(b\), and \(c\), if \(a - c \leq b\), then \(a \leq b + c\). Since \(a + -c\) is equivalent to \(a - c\), we have \(a - c \leq b\). By applying this theorem, we conclude that \(a \leq b + c\).

Therefore, the theorem is proved. \(\blacksquare\)","theorem Int.le_add_of_neg_add_le_right {a b c : Int} (h : -c + a ≤ b) : a ≤ b + c := by
/- Since the commutativity of addition in the integers shows that \(-c + a\) is equivalent to \(a + -c\), we can replace \(-c + a\) with \(a + -c\) in the assumption \(-c + a \leq b\). Thus, the assumption becomes \(a + -c \leq b\). -/
  rw [Int.add_comm] at h
/- The current goal \(a \leq b + c\) is exactly proved by the theorem that states for any integers \(a\), \(b\), and \(c\), if \(a - c \leq b\), then \(a \leq b + c\). Since we have \(a + -c \leq b\) (which is equivalent to \(a - c \leq b\)), the theorem directly applies, and we conclude \(a \leq b + c\). -/
  exact Int.le_add_of_sub_right_le h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44410,Int.neg_add_le_right_of_le_add,theorem Int.neg_add_le_right_of_le_add {a b c : Int} (h : a ≤ b + c) : -c + a ≤ b := by sorry,"Inequality Preservation: \(a \le b + c \to -c + a \le b\) : For any integers \(a\), \(b\), and \(c\), if \(a \le b + c\), then \(-c + a \le b\).","theorem Int.neg_add_le_right_of_le_add {a b c : Int} (h : a ≤ b + c) : -c + a ≤ b := by
  rw [Int.add_comm] at h
  exact Int.neg_add_le_left_of_le_add h","We start with the assumption that \(a \le b + c\). By the commutativity of addition in the integers, we can rewrite \(b + c\) as \(c + b\). Therefore, the assumption \(a \le b + c\) is equivalent to \(a \le c + b\).

Next, we use the theorem that states for any integers \(a\), \(b\), and \(c\), if \(a \le c + b\), then \(-c + a \le b\). Since we have \(a \le c + b\) from the previous step, this theorem directly gives us \(-c + a \le b\).

Thus, we have shown that if \(a \le b + c\), then \(-c + a \le b\). This completes the proof.","theorem Int.neg_add_le_right_of_le_add {a b c : Int} (h : a ≤ b + c) : -c + a ≤ b := by
/- Since the commutativity of addition in the integers shows that \(a + b = b + a\), we can replace \(b + c\) with \(c + b\) in the assumption \(a \le b + c\). Thus, the assumption \(a \le b + c\) is equivalent to \(a \le c + b\). -/
  rw [Int.add_comm] at h
/- The current goal \(-c + a \le b\) is exactly proved by the theorem that states for any integers \(a\), \(b\), and \(c\), if \(a \le c + b\), then \(-c + a \le b\). Since we have \(a \le c + b\) from the previous step, this theorem directly gives us \(-c + a \le b\). -/
  exact Int.neg_add_le_left_of_le_add h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44412,Int.lt_add_of_neg_add_lt,theorem Int.lt_add_of_neg_add_lt {a b c : Int} (h : -b + a < c) : a < b + c := by sorry,"Inequality Preservation: \(-b + a < c \to a < b + c\) : For any integers \(a\), \(b\), and \(c\), if \(-b + a < c\), then \(a < b + c\).","theorem Int.lt_add_of_neg_add_lt {a b c : Int} (h : -b + a < c) : a < b + c := by
  have h := Int.add_lt_add_left h b
  rwa [Int.add_neg_cancel_left] at h","We start with the given inequality \(-b + a < c\). To prove that \(a < b + c\), we use the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, adding \(b\) to both sides of \(-b + a < c\) gives:
\[
b + (-b + a) < b + c
\]
Next, we use the cancellation property of addition and negation in the integers, which states that \(b + (-b + a) = a\). Therefore, the inequality simplifies to:
\[
a < b + c
\]
This completes the proof. \(\blacksquare\)","theorem Int.lt_add_of_neg_add_lt {a b c : Int} (h : -b + a < c) : a < b + c := by
/- First, we use the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, since \(-b + a < c\), adding \(b\) to both sides gives \(b + (-b + a) < b + c\). -/
  have h := Int.add_lt_add_left h b
/- Next, we use the cancellation property of addition and negation in the integers. Since \(b + (-b + a) = a\), we can simplify the inequality \(b + (-b + a) < b + c\) to \(a < b + c\). This completes the proof. -/
  rwa [Int.add_neg_cancel_left] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44413,Int.negSucc_not_pos,theorem Int.negSucc_not_pos (n : Nat) : 0 < -[n+1] ↔ False := by sorry,"Negative Successor of a Natural Number is Not Positive: \( 0 < - (n + 1) \leftrightarrow \text{False} \) : For any natural number \( n \), the negative successor of \( n \) in the integers, denoted as \( - (n + 1) \), is not positive, i.e., \( 0 < - (n + 1) \) is false.","theorem Int.negSucc_not_pos (n : Nat) : 0 < -[n+1] ↔ False := by
  simp only [Int.not_lt, iff_false]; constructor","We need to show that for any natural number \( n \), the statement \( 0 < - (n + 1) \) is false.

First, we use the theorems that the negation of \( a < b \) is \( b \le a \) and the equivalence of negations to simplify the goal. This simplifies the goal to showing that \( 0 < - (n + 1) \) implies \(\text{False}\).

To prove this implication, we assume \( 0 < - (n + 1) \) and show that this leads to a contradiction.

Assume \( 0 < - (n + 1) \). By the definition of the negative successor, \( - (n + 1) \) is a negative integer. Therefore, \( - (n + 1) \le 0 \). This contradicts our assumption that \( 0 < - (n + 1) \), because \( 0 < - (n + 1) \) implies \( - (n + 1) > 0 \), which is impossible.

Thus, the assumption \( 0 < - (n + 1) \) leads to a contradiction, and therefore \( 0 < - (n + 1) \) is false. This completes the proof. \(\blacksquare\)","theorem Int.negSucc_not_pos (n : Nat) : 0 < -[n+1] ↔ False := by
/- First, we use the theorems that the negation of \( a < b \) is \( b \le a \) and the equivalence of negations to simplify the goal. This simplifies the goal to showing that \( 0 < -[n+1] \) implies \(\text{False}\). To prove this implication, we assume \( 0 < -[n+1] \) and show that this leads to a contradiction. -/
  simp only [Int.not_lt, iff_false]; constructor","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44417,Int.add_lt_of_lt_sub_left,theorem Int.add_lt_of_lt_sub_left {a b c : Int} (h : b < c - a) : a + b < c := by sorry,"Addition Preserves Strict Inequality: \(b < c - a \to a + b < c\) : For any integers \(a\), \(b\), and \(c\), if \(b < c - a\), then \(a + b < c\).","theorem Int.add_lt_of_lt_sub_left {a b c : Int} (h : b < c - a) : a + b < c := by
  have h := Int.add_lt_add_left h a
  rwa [← Int.add_sub_assoc, Int.add_comm a c, Int.add_sub_cancel] at h","We start with the given inequality \( b < c - a \). To prove that \( a + b < c \), we use the property that adding the same integer to both sides of a strict inequality preserves the inequality. Specifically, since \( b < c - a \), it follows that:
\[ a + b < a + (c - a). \]

Next, we simplify the right-hand side of the inequality:
1. By the associativity of addition and subtraction, we have:
\[ a + (c - a) = a + c - a. \]
2. By the commutativity of addition, we can rewrite this as:
\[ a + c - a = c + a - a. \]
3. By the cancellation property of addition and subtraction, we get:
\[ c + a - a = c. \]

Thus, we have:
\[ a + b < c. \]

This completes the proof. \(\blacksquare\)","theorem Int.add_lt_of_lt_sub_left {a b c : Int} (h : b < c - a) : a + b < c := by
/- First, we use the fact that adding the same integer to both sides of a strict inequality preserves the inequality. Specifically, since \( b < c - a \), it follows that \( a + b < a + (c - a) \). -/
  have h := Int.add_lt_add_left h a
/- Next, we simplify the expression \( a + (c - a) \) using the following properties:
1. The associativity of addition and subtraction: \( a + (c - a) = a + c - a \).
2. The commutativity of addition: \( a + c - a = c + a - a \).
3. The cancellation property of addition and subtraction: \( c + a - a = c \).

Thus, we have \( a + b < c \), which is exactly what we needed to show. -/
  rwa [← Int.add_sub_assoc, Int.add_comm a c, Int.add_sub_cancel] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44418,Int.lt_sub_left_of_add_lt,theorem Int.lt_sub_left_of_add_lt {a b c : Int} (h : a + b < c) : b < c - a := by sorry,"Strict Inequality Preservation: \(a + b < c \to b < c - a\) : For any integers \(a\), \(b\), and \(c\), if \(a + b < c\), then \(b < c - a\).","theorem Int.lt_sub_left_of_add_lt {a b c : Int} (h : a + b < c) : b < c - a := by
  have h := Int.add_lt_add_right h (-a)
  rwa [Int.add_comm a b, Int.add_neg_cancel_right] at h","We start with the given inequality \(a + b < c\). To prove that \(b < c - a\), we first use the property that adding the same integer to both sides of a strict inequality preserves the inequality. Specifically, since \(a + b < c\), we have:
\[
a + b + (-a) < c + (-a)
\]
Next, we use the commutativity of addition to rewrite the left-hand side:
\[
b + a + (-a) < c + (-a)
\]
Then, we use the property that adding an integer and its negation results in the original integer:
\[
b < c + (-a)
\]
This simplifies to:
\[
b < c - a
\]
Thus, we have shown that if \(a + b < c\), then \(b < c - a\). This completes the proof. \(\blacksquare\)","theorem Int.lt_sub_left_of_add_lt {a b c : Int} (h : a + b < c) : b < c - a := by
/- First, we use the property that adding the same integer to both sides of a strict inequality preserves the inequality. Specifically, since \(a + b < c\), we have \(a + b + (-a) < c + (-a)\). -/
  have h := Int.add_lt_add_right h (-a)
/- Next, we use the commutativity of addition to rewrite \(a + b + (-a)\) as \(b + a + (-a)\). Then, we use the property that adding an integer and its negation results in the original integer, so \(b + a + (-a) = b\). Therefore, the inequality \(a + b + (-a) < c + (-a)\) simplifies to \(b < c + (-a)\), which is equivalent to \(b < c - a\). -/
  rwa [Int.add_comm a b, Int.add_neg_cancel_right] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44419,Int.add_lt_of_lt_sub_right,theorem Int.add_lt_of_lt_sub_right {a b c : Int} (h : a < c - b) : a + b < c := by sorry,"Addition Preserves Strict Inequality from Right Subtraction in Integers : For any integers \(a\), \(b\), and \(c\), if \(a < c - b\), then \(a + b < c\).","theorem Int.add_lt_of_lt_sub_right {a b c : Int} (h : a < c - b) : a + b < c := by
  have h := Int.add_lt_add_right h b
  rwa [Int.sub_add_cancel] at h","We need to show that if \(a < c - b\), then \(a + b < c\).

1. **Step 1:**
We start by using the property that right addition preserves strict inequality in ordered monoids. Specifically, since \(a < c - b\), adding \(b\) to both sides gives us:
\[
a + b < (c - b) + b
\]

2. **Step 2:**
Next, we use the property that subtraction and addition cancel each other in additive groups. This means that:
\[
(c - b) + b = c
\]
Therefore, the inequality \(a + b < (c - b) + b\) simplifies to:
\[
a + b < c
\]

This completes the proof. \(\blacksquare\)","theorem Int.add_lt_of_lt_sub_right {a b c : Int} (h : a < c - b) : a + b < c := by
/- We start by using the property that right addition preserves strict inequality in ordered monoids. Specifically, since \(a < c - b\), adding \(b\) to both sides gives us \(a + b < (c - b) + b\). -/
  have h := Int.add_lt_add_right h b
/- Next, we use the property that subtraction and addition cancel each other in additive groups. This means that \((c - b) + b = c\). Therefore, the inequality \(a + b < (c - b) + b\) simplifies to \(a + b < c\). This completes the proof. -/
  rwa [Int.sub_add_cancel] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44420,Int.min_comm,theorem Int.min_comm (a b : Int) : min a b = min b a := by sorry,"Commutativity of Minimum on Integers: \(\min(a, b) = \min(b, a)\) : For any integers \(a\) and \(b\), the minimum of \(a\) and \(b\) is equal to the minimum of \(b\) and \(a\), i.e., \(\min(a, b) = \min(b, a)\).","theorem Int.min_comm (a b : Int) : min a b = min b a := by
  simp [Int.min_def]
  by_cases h₁ : a ≤ b <;> by_cases h₂ : b ≤ a <;> simp [h₁, h₂]
  · exact Int.le_antisymm h₁ h₂
  · cases not_or_intro h₁ h₂ <| Int.le_total ..","We start by using the definition of the minimum function. The minimum of two integers \(a\) and \(b\) is defined as \(a\) if \(a \leq b\), and \(b\) otherwise. Therefore, the goal \(\min(a, b) = \min(b, a)\) is equivalent to \((\text{if } a \leq b \text{ then } a \text{ else } b) = (\text{if } b \leq a \text{ then } b \text{ else } a)\).

We consider the following cases for \(a \leq b\) and \(b \leq a\):

1. **Case 1:** Assume \(a \leq b\) and \(b \leq a\).
- By the antisymmetry of the less than or equal to relation, if \(a \leq b\) and \(b \leq a\), then \(a = b\).
- Therefore, \((\text{if } a \leq b \text{ then } a \text{ else } b) = a\) and \((\text{if } b \leq a \text{ then } b \text{ else } a) = b\), which simplifies to \(a = b\).

2. **Case 2:** Assume \(a \leq b\) and \(\neg (b \leq a)\).
- Since \(a \leq b\) and \(\neg (b \leq a)\), the goal \((\text{if } a \leq b \text{ then } a \text{ else } b) = (\text{if } b \leq a \text{ then } b \text{ else } a)\) simplifies to \(a = a\), which is trivially true.

3. **Case 3:** Assume \(\neg (a \leq b)\) and \(b \leq a\).
- Since \(\neg (a \leq b)\) and \(b \leq a\), the goal \((\text{if } a \leq b \text{ then } a \text{ else } b) = (\text{if } b \leq a \text{ then } b \text{ else } a)\) simplifies to \(b = b\), which is trivially true.

4. **Case 4:** Assume \(\neg (a \leq b)\) and \(\neg (b \leq a)\).
- By the totality of the linear order, if \(\neg (a \leq b)\) and \(\neg (b \leq a)\), then \(a\) and \(b\) cannot be compared, which is a contradiction. Therefore, this case is impossible.

In all valid cases, the goal \(\min(a, b) = \min(b, a)\) holds. Therefore, the commutativity of the minimum function on integers is proved. \(\blacksquare\)","theorem Int.min_comm (a b : Int) : min a b = min b a := by
/- First, we use the definition of the minimum function to simplify the goal. The minimum of two integers \(a\) and \(b\) is defined as \(a\) if \(a \leq b\), and \(b\) otherwise. Therefore, the goal \(\min(a, b) = \min(b, a)\) is equivalent to \((\text{if } a \leq b \text{ then } a \text{ else } b) = (\text{if } b \leq a \text{ then } b \text{ else } a)\). -/
  simp [Int.min_def]
/- We consider two cases for \(a \leq b\) and \(b \leq a\):

1. **Case 1:** Assume \(a \leq b\) and \(b \leq a\).
- By the antisymmetry of the less than or equal to relation, if \(a \leq b\) and \(b \leq a\), then \(a = b\).
- Therefore, \((\text{if } a \leq b \text{ then } a \text{ else } b) = a\) and \((\text{if } b \leq a \text{ then } b \text{ else } a) = b\), which simplifies to \(a = b\).

2. **Case 2:** Assume \(a \leq b\) and \(\neg (b \leq a)\).
- Since \(a \leq b\) and \(\neg (b \leq a)\), the goal \((\text{if } a \leq b \text{ then } a \text{ else } b) = (\text{if } b \leq a \text{ then } b \text{ else } a)\) simplifies to \(a = a\), which is trivially true.

3. **Case 3:** Assume \(\neg (a \leq b)\) and \(b \leq a\).
- Since \(\neg (a \leq b)\) and \(b \leq a\), the goal \((\text{if } a \leq b \text{ then } a \text{ else } b) = (\text{if } b \leq a \text{ then } b \text{ else } a)\) simplifies to \(b = b\), which is trivially true.

4. **Case 4:** Assume \(\neg (a \leq b)\) and \(\neg (b \leq a)\).
- By the totality of the linear order, if \(\neg (a \leq b)\) and \(\neg (b \leq a)\), then \(a\) and \(b\) cannot be compared, which is a contradiction. Therefore, this case is impossible. -/
  by_cases h₁ : a ≤ b <;> by_cases h₂ : b ≤ a <;> simp [h₁, h₂]
/- In the first case where \(a \leq b\) and \(b \leq a\), we use the antisymmetry of the less than or equal to relation to conclude that \(a = b\). -/
  · exact Int.le_antisymm h₁ h₂
/- In the fourth case where \(\neg (a \leq b)\) and \(\neg (b \leq a)\), we use the totality of the linear order to show that this case is impossible. Since \(a\) and \(b\) must be comparable, the assumption \(\neg (a \leq b)\) and \(\neg (b \leq a)\) leads to a contradiction. -/
  · cases not_or_intro h₁ h₂ <| Int.le_total ..","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44421,Int.lt_add_of_neg_add_lt_left,theorem Int.lt_add_of_neg_add_lt_left {a b c : Int} (h : -b + a < c) : a < b + c := by sorry,"Left Addition with Negative Preserves Strict Inequality in Integers: \(-b + a < c \to a < b + c\) : For any integers \(a\), \(b\), and \(c\), if \(-b + a < c\), then \(a < b + c\).","theorem Int.lt_add_of_neg_add_lt_left {a b c : Int} (h : -b + a < c) : a < b + c := by
  rw [Int.add_comm] at h
  exact Int.lt_add_of_sub_left_lt h","We start with the assumption that \(-b + a < c\). Using the commutativity of addition in integers, we can rewrite this assumption as \( a + (-b) < c \). By the theorem that states if \( a - b < c \), then \( a < b + c \), and since we have \( a + (-b) < c \), it follows that \( a < b + c \). This completes the proof.","theorem Int.lt_add_of_neg_add_lt_left {a b c : Int} (h : -b + a < c) : a < b + c := by
/- Since the commutativity of addition in integers states that \( a + (-b) = -b + a \), we can rewrite the assumption \(-b + a < c\) as \( a + (-b) < c \). -/
  rw [Int.add_comm] at h
/- By the theorem that states if \( a - b < c \), then \( a < b + c \), and since we have \( a + (-b) < c \), it follows that \( a < b + c \). This completes the proof. -/
  exact Int.lt_add_of_sub_left_lt h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44422,Int.sub_right_lt_of_lt_add,theorem Int.sub_right_lt_of_lt_add {a b c : Int} (h : a < b + c) : a - c < b := by sorry,"Subtraction on the Right Preserves Strict Inequality in Integers : For any integers \(a\), \(b\), and \(c\), if \(a < b + c\), then \(a - c < b\).","theorem Int.sub_right_lt_of_lt_add {a b c : Int} (h : a < b + c) : a - c < b := by
  have h := Int.add_lt_add_right h (-c)
  rwa [Int.add_neg_cancel_right] at h","We start with the given inequality \(a < b + c\). To prove that \(a - c < b\), we first add \(-c\) to both sides of the inequality \(a < b + c\). This gives us:
\[
a + (-c) < b + c + (-c)
\]
Using the property of additive inverses in the integers, which states that \(a + b + (-b) = a\), we can simplify the right side of the inequality:
\[
a + (-c) < b
\]
This simplifies to:
\[
a - c < b
\]
Thus, we have shown that if \(a < b + c\), then \(a - c < b\). This completes the proof. \(\blacksquare\)","theorem Int.sub_right_lt_of_lt_add {a b c : Int} (h : a < b + c) : a - c < b := by
/- First, we construct a new inequality by adding \(-c\) to both sides of the given inequality \(a < b + c\). This gives us \(a + (-c) < b + c + (-c)\). -/
  have h := Int.add_lt_add_right h (-c)
/- Next, we use the property of additive inverses in the integers, which states that \(a + b + (-b) = a\). Applying this property to the right side of our new inequality, we get \(a + (-c) < b\). This simplifies to \(a - c < b\), which is exactly what we needed to show. -/
  rwa [Int.add_neg_cancel_right] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44423,Int.neg_add_lt_left_of_lt_add,theorem Int.neg_add_lt_left_of_lt_add {a b c : Int} (h : a < b + c) : -b + a < c := by sorry,"Left Addition with Negation Preserves Strict Inequality in Integers : For any integers \(a\), \(b\), and \(c\), if \(a < b + c\), then \(-b + a < c\).","theorem Int.neg_add_lt_left_of_lt_add {a b c : Int} (h : a < b + c) : -b + a < c := by
  rw [Int.add_comm]
  exact Int.sub_left_lt_of_lt_add h","We start with the hypothesis that \(a < b + c\). To prove that \(-b + a < c\), we first use the commutativity of addition in the integers to rewrite the goal \(-b + a < c\) as \(a + (-b) < c\).

Next, we apply the theorem that states if \(a < b + c\), then \(a - b < c\). Since \(a + (-b)\) is equivalent to \(a - b\), and we have the hypothesis \(a < b + c\), this theorem directly implies that \(a + (-b) < c\).

Therefore, we have shown that \(-b + a < c\), completing the proof.","theorem Int.neg_add_lt_left_of_lt_add {a b c : Int} (h : a < b + c) : -b + a < c := by
/- Since the addition operation is commutative in the integers, we can rewrite the goal \(-b + a < c\) as \(a + (-b) < c\). -/
  rw [Int.add_comm]
/- The current goal \(a + (-b) < c\) is exactly proved by the theorem that states if \(a < b + c\), then \(a - b < c\). Since we have the hypothesis \(a < b + c\), this theorem directly implies \(a + (-b) < c\). -/
  exact Int.sub_left_lt_of_lt_add h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44424,Int.lt_add_of_neg_add_lt_right,theorem Int.lt_add_of_neg_add_lt_right {a b c : Int} (h : -c + a < b) : a < b + c := by sorry,"Left Addition with Negation Preserves Strict Inequality in Integers : For any integers \(a\), \(b\), and \(c\), if \(-c + a < b\), then \(a < b + c\).","theorem Int.lt_add_of_neg_add_lt_right {a b c : Int} (h : -c + a < b) : a < b + c := by
  rw [Int.add_comm] at h
  exact Int.lt_add_of_sub_right_lt h","We start with the assumption that \(-c + a < b\). By the commutativity of addition in the integers, we can rewrite \(-c + a\) as \(a + -c\). Thus, the assumption becomes \(a + -c < b\).

Next, we use the theorem that states for any integers \(a, b, c\), if \(a - c < b\), then \(a < b + c\). Since \(a + -c\) is equivalent to \(a - c\), our assumption \(a + -c < b\) directly implies \(a < b + c\).

Therefore, we have shown that if \(-c + a < b\), then \(a < b + c\). This completes the proof.","theorem Int.lt_add_of_neg_add_lt_right {a b c : Int} (h : -c + a < b) : a < b + c := by
/- Since the commutativity of addition in the integers shows that \(-c + a\) is equivalent to \(a + -c\), we can replace \(-c + a\) with \(a + -c\) in the assumption \(-c + a < b\). Thus, the assumption becomes \(a + -c < b\). -/
  rw [Int.add_comm] at h
/- The current goal \(a < b + c\) is exactly proved by the theorem that states for any integers \(a, b, c\), if \(a - c < b\), then \(a < b + c\). Since we have the assumption \(a + -c < b\), which is equivalent to \(a - c < b\), the theorem directly applies, and we conclude \(a < b + c\). -/
  exact Int.lt_add_of_sub_right_lt h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44426,Int.neg_add_lt_right_of_lt_add,theorem Int.neg_add_lt_right_of_lt_add {a b c : Int} (h : a < b + c) : -c + a < b := by sorry,"Right Addition with Negation Preserves Strict Inequality in Integers : For any integers \(a\), \(b\), and \(c\), if \(a < b + c\), then \(-c + a < b\).","theorem Int.neg_add_lt_right_of_lt_add {a b c : Int} (h : a < b + c) : -c + a < b := by
  rw [Int.add_comm] at h
  exact Int.neg_add_lt_left_of_lt_add h","We start with the assumption that \(a < b + c\). By the commutativity of addition in integers, we can rewrite \(b + c\) as \(c + b\). Therefore, the assumption \(a < b + c\) is equivalent to \(a < c + b\).

Next, we use the theorem that for any integers \(a\), \(b\), and \(c\), if \(a < c + b\), then \(-c + a < b\). Since we have \(a < c + b\) from the previous step, this theorem directly implies that \(-c + a < b\).

Thus, we have shown that if \(a < b + c\), then \(-c + a < b\). This completes the proof. \(\blacksquare\)","theorem Int.neg_add_lt_right_of_lt_add {a b c : Int} (h : a < b + c) : -c + a < b := by
/- Since the commutativity of addition in integers shows that \(a + b = b + a\), we can replace \(b + c\) with \(c + b\) in the assumption \(a < b + c\). Thus, the assumption \(a < b + c\) is equivalent to \(a < c + b\). -/
  rw [Int.add_comm] at h
/- The current goal \(-c + a < b\) is exactly proved by the theorem that for any integers \(a\), \(b\), and \(c\), if \(a < c + b\), then \(-c + a < b\). Since we have \(a < c + b\) from the previous step, this theorem directly gives us \(-c + a < b\). -/
  exact Int.neg_add_lt_left_of_lt_add h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44427,Int.sub_left_lt_of_lt_add,theorem Int.sub_left_lt_of_lt_add {a b c : Int} (h : a < b + c) : a - b < c := by sorry,"Subtraction on the Left Implies Addition on the Right in Integers: \(a < b + c \to a - b < c\) : For any integers \(a\), \(b\), and \(c\), if \(a < b + c\), then \(a - b < c\).","theorem Int.sub_left_lt_of_lt_add {a b c : Int} (h : a < b + c) : a - b < c := by
  have h := Int.add_lt_add_right h (-b)
  rwa [Int.add_comm b c, Int.add_neg_cancel_right] at h","We start with the given inequality \(a < b + c\). To prove that \(a - b < c\), we first use the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, since \(a < b + c\), we have:
\[
a + (-b) < (b + c) + (-b)
\]
Next, we use the commutativity of addition to rewrite \((b + c) + (-b)\) as \((c + b) + (-b)\). Then, we use the property of additive inverses to simplify \((c + b) + (-b)\) to \(c\). Therefore, the inequality \(a + (-b) < (b + c) + (-b)\) simplifies to:
\[
a + (-b) < c
\]
This is exactly the same as:
\[
a - b < c
\]
Thus, we have shown that if \(a < b + c\), then \(a - b < c\). This completes the proof. \(\blacksquare\)","theorem Int.sub_left_lt_of_lt_add {a b c : Int} (h : a < b + c) : a - b < c := by
/- First, we use the property that adding the same element to both sides of a strict inequality preserves the inequality. Specifically, since \(a < b + c\), we have \(a + (-b) < (b + c) + (-b)\). -/
  have h := Int.add_lt_add_right h (-b)
/- Next, we use the commutativity of addition to rewrite \((b + c) + (-b)\) as \((c + b) + (-b)\). Then, we use the property of additive inverses to simplify \((c + b) + (-b)\) to \(c\). Therefore, the inequality \(a + (-b) < (b + c) + (-b)\) simplifies to \(a + (-b) < c\). This is exactly the same as \(a - b < c\). -/
  rwa [Int.add_comm b c, Int.add_neg_cancel_right] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44430,Int.natAbs_sign_of_nonzero,theorem Int.natAbs_sign_of_nonzero {z : Int} (hz : z ≠ 0) : z.sign.natAbs = 1 := by sorry,"Absolute Value of Sign of Nonzero Integer is One : For any nonzero integer \( z \), the absolute value of its sign is equal to 1, i.e., \( | \text{sign}(z) | = 1 \).","theorem Int.natAbs_sign_of_nonzero {z : Int} (hz : z ≠ 0) : z.sign.natAbs = 1 := by
  rw [Int.natAbs_sign, if_neg hz]","We start with the assumption that \( z \) is a nonzero integer, i.e., \( z \neq 0 \). According to the definition of the absolute value of the sign of an integer, we have:
\[
| \text{sign}(z) | = \begin{cases}
0 & \text{if } z = 0 \\
1 & \text{if } z \neq 0
\end{cases}
\]
Since \( z \neq 0 \), the expression \( | \text{sign}(z) | \) simplifies to 1. Therefore, we need to show that:
\[
z.sign.natAbs = 1
\]
Given the definition and the assumption, this simplifies to:
\[
1 = 1
\]
which is trivially true. Hence, the absolute value of the sign of any nonzero integer \( z \) is indeed 1. This completes the proof. \(\blacksquare\)","theorem Int.natAbs_sign_of_nonzero {z : Int} (hz : z ≠ 0) : z.sign.natAbs = 1 := by
/- First, we use the definition of the absolute value of the sign of an integer \( z \). According to this definition, \( | \text{sign}(z) | \) is 0 if \( z = 0 \) and 1 if \( z \neq 0 \). Since we have the assumption \( z \neq 0 \), the expression \( | \text{sign}(z) | \) simplifies to 1. Therefore, the goal \( z.sign.natAbs = 1 \) is equivalent to showing that 1 is equal to 1. -/
  rw [Int.natAbs_sign, if_neg hz]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44431,Int.mul_neg_of_pos_of_neg,theorem Int.mul_neg_of_pos_of_neg {a b : Int} (ha : 0 < a) (hb : b < 0) : a * b < 0 := by sorry,"Product of Positive and Negative Integers is Negative: \(0 < a\) and \(b < 0\) implies \(a \cdot b < 0\) : For any integers \(a\) and \(b\), if \(0 < a\) and \(b < 0\), then \(a \cdot b < 0\).","theorem Int.mul_neg_of_pos_of_neg {a b : Int} (ha : 0 < a) (hb : b < 0) : a * b < 0 := by
  have h : a * b < a * 0 := Int.mul_lt_mul_of_pos_left hb ha
  rwa [Int.mul_zero] at h","We start by noting that if \( 0 < a \) and \( b < 0 \), we need to show that \( a \cdot b < 0 \).

1. First, we construct a lemma \( h \) that states \( a \cdot b < a \cdot 0 \). This follows from the fact that if \( b < 0 \) and \( 0 < a \), then multiplying both sides of the inequality \( b < 0 \) by the positive integer \( a \) preserves the inequality, i.e., \( a \cdot b < a \cdot 0 \).

2. Next, we use the property that the product of any integer with zero is zero, i.e., \( a \cdot 0 = 0 \). By substituting \( a \cdot 0 \) with \( 0 \) in the lemma \( h \), we get \( a \cdot b < 0 \). This is exactly the goal we need to prove.

Thus, we have shown that if \( 0 < a \) and \( b < 0 \), then \( a \cdot b < 0 \). This completes the proof. \(\blacksquare\)","theorem Int.mul_neg_of_pos_of_neg {a b : Int} (ha : 0 < a) (hb : b < 0) : a * b < 0 := by
/- First, we construct a lemma \( h \) that states \( a \cdot b < a \cdot 0 \). This follows from the fact that if \( b < 0 \) and \( 0 < a \), then multiplying both sides of the inequality \( b < 0 \) by the positive integer \( a \) preserves the inequality, i.e., \( a \cdot b < a \cdot 0 \). -/
  have h : a * b < a * 0 := Int.mul_lt_mul_of_pos_left hb ha
/- Next, we use the property that the product of any integer with zero is zero, i.e., \( a \cdot 0 = 0 \). By substituting \( a \cdot 0 \) with \( 0 \) in the lemma \( h \), we get \( a \cdot b < 0 \). This is exactly the goal we need to prove. -/
  rwa [Int.mul_zero] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44433,Int.natAbs_mul,theorem Int.natAbs_mul (a b : Int) : natAbs (a * b) = natAbs a * natAbs b := by sorry,"Absolute Value of Product of Integers Equals Product of Absolute Values: \(\text{natAbs}(a * b) = \text{natAbs}(a) * \text{natAbs}(b)\) : For any integers \( a \) and \( b \), the absolute value of their product is equal to the product of their absolute values, i.e., \(\text{natAbs}(a * b) = \text{natAbs}(a) * \text{natAbs}(b)\).","theorem Int.natAbs_mul (a b : Int) : natAbs (a * b) = natAbs a * natAbs b := by
  cases a <;> cases b <;>
    simp only [← Int.mul_def, Int.mul, natAbs_negOfNat] <;> simp only [natAbs]","To prove that \(\text{natAbs}(a * b) = \text{natAbs}(a) * \text{natAbs}(b)\) for any integers \( a \) and \( b \), we will consider every possible case for \( a \) and \( b \).

1. **Case 1: \( a \) and \( b \) are both non-negative integers.**
- Let \( a = \text{ofNat}(a_1) \) and \( b = \text{ofNat}(b_1) \) where \( a_1, b_1 \in \mathbb{N} \).
- We need to show that \(\text{natAbs}(\text{ofNat}(a_1) * \text{ofNat}(b_1)) = \text{natAbs}(\text{ofNat}(a_1)) * \text{natAbs}(\text{ofNat}(b_1))\).
- Simplifying, we get \(\text{natAbs}(\text{ofNat}(a_1 * b_1)) = a_1 * b_1\).
- Since \(\text{natAbs}(\text{ofNat}(a_1)) = a_1\) and \(\text{natAbs}(\text{ofNat}(b_1)) = b_1\), the equation holds.

2. **Case 2: \( a \) is a non-negative integer and \( b \) is a negative integer.**
- Let \( a = \text{ofNat}(a_1) \) and \( b = -\text{ofNat}(b_1 + 1) \) where \( a_1, b_1 \in \mathbb{N} \).
- We need to show that \(\text{natAbs}(\text{ofNat}(a_1) * -\text{ofNat}(b_1 + 1)) = \text{natAbs}(\text{ofNat}(a_1)) * \text{natAbs}(-\text{ofNat}(b_1 + 1))\).
- Simplifying, we get \(\text{natAbs}(-\text{ofNat}(a_1 * (b_1 + 1))) = a_1 * (b_1 + 1)\).
- Since \(\text{natAbs}(\text{ofNat}(a_1)) = a_1\) and \(\text{natAbs}(-\text{ofNat}(b_1 + 1)) = b_1 + 1\), the equation holds.

3. **Case 3: \( a \) is a negative integer and \( b \) is a non-negative integer.**
- Let \( a = -\text{ofNat}(a_1 + 1) \) and \( b = \text{ofNat}(b_1) \) where \( a_1, b_1 \in \mathbb{N} \).
- We need to show that \(\text{natAbs}(-\text{ofNat}(a_1 + 1) * \text{ofNat}(b_1)) = \text{natAbs}(-\text{ofNat}(a_1 + 1)) * \text{natAbs}(\text{ofNat}(b_1))\).
- Simplifying, we get \(\text{natAbs}(-\text{ofNat}((a_1 + 1) * b_1)) = (a_1 + 1) * b_1\).
- Since \(\text{natAbs}(-\text{ofNat}(a_1 + 1)) = a_1 + 1\) and \(\text{natAbs}(\text{ofNat}(b_1)) = b_1\), the equation holds.

4. **Case 4: \( a \) and \( b \) are both negative integers.**
- Let \( a = -\text{ofNat}(a_1 + 1) \) and \( b = -\text{ofNat}(b_1 + 1) \) where \( a_1, b_1 \in \mathbb{N} \).
- We need to show that \(\text{natAbs}(-\text{ofNat}(a_1 + 1) * -\text{ofNat}(b_1 + 1)) = \text{natAbs}(-\text{ofNat}(a_1 + 1)) * \text{natAbs}(-\text{ofNat}(b_1 + 1))\).
- Simplifying, we get \(\text{natAbs}(\text{ofNat}((a_1 + 1) * (b_1 + 1))) = (a_1 + 1) * (b_1 + 1)\).
- Since \(\text{natAbs}(-\text{ofNat}(a_1 + 1)) = a_1 + 1\) and \(\text{natAbs}(-\text{ofNat}(b_1 + 1)) = b_1 + 1\), the equation holds.

In all cases, the equation \(\text{natAbs}(a * b) = \text{natAbs}(a) * \text{natAbs}(b)\) holds. Therefore, the theorem is proved. \(\blacksquare\)","theorem Int.natAbs_mul (a b : Int) : natAbs (a * b) = natAbs a * natAbs b := by
/- We will consider every possible case for the integers \( a \) and \( b \). For each case, we will simplify the expression using the definitions of integer multiplication and the absolute value of the negation of a natural number as an integer. Specifically, we use the fact that the absolute value of the negation of a natural number \( n \) as an integer is equal to \( n \). After simplification, we will further simplify the expression using the definition of the absolute value of an integer. -/
  cases a <;> cases b <;>
    simp only [← Int.mul_def, Int.mul, natAbs_negOfNat] <;> simp only [natAbs]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44434,Int.mul_pos_of_neg_of_neg,theorem Int.mul_pos_of_neg_of_neg {a b : Int} (ha : a < 0) (hb : b < 0) : 0 < a * b := by sorry,"Product of Two Negative Integers is Positive: \( a < 0 \) and \( b < 0 \) implies \( 0 < a \cdot b \) : For any integers \( a \) and \( b \), if \( a < 0 \) and \( b < 0 \), then \( 0 < a \cdot b \).","theorem Int.mul_pos_of_neg_of_neg {a b : Int} (ha : a < 0) (hb : b < 0) : 0 < a * b := by
  have : 0 * b < a * b := Int.mul_lt_mul_of_neg_right ha hb
  rwa [Int.zero_mul] at this","To prove that \(0 < a \cdot b\) for any integers \(a\) and \(b\) where \(a < 0\) and \(b < 0\), we proceed as follows:

1. **Construct a Lemma:**
We first construct a lemma that \(0 \cdot b < a \cdot b\). This follows from the property that if \(a < 0\) and \(b < 0\), then multiplying a negative number \(a\) by a negative number \(b\) results in a product that is greater than the product of zero and \(b\). Formally, this is a consequence of the property that right multiplication by a negative element preserves strict inequality in semirings.

2. **Simplify the Lemma:**
We use the property that \(0 \cdot b = 0\) to simplify the lemma \(0 \cdot b < a \cdot b\) to \(0 < a \cdot b\). Since \(0 \cdot b = 0\), the inequality \(0 < a \cdot b\) is exactly what we need to prove.

Therefore, we have shown that if \(a < 0\) and \(b < 0\), then \(0 < a \cdot b\). This completes the proof. \(\blacksquare\)","theorem Int.mul_pos_of_neg_of_neg {a b : Int} (ha : a < 0) (hb : b < 0) : 0 < a * b := by
/- First, we construct a lemma that \(0 \cdot b < a \cdot b\). This follows from the fact that if \(a < 0\) and \(b < 0\), then multiplying a negative number \(a\) by a negative number \(b\) results in a product that is greater than the product of zero and \(b\). This is a consequence of the property that right multiplication by a negative element preserves strict inequality in semirings. -/
  have : 0 * b < a * b := Int.mul_lt_mul_of_neg_right ha hb
/- Next, we use the property that \(0 \cdot b = 0\) to simplify the lemma \(0 \cdot b < a \cdot b\) to \(0 < a \cdot b\). Since \(0 \cdot b = 0\), the inequality \(0 < a \cdot b\) is exactly what we need to prove. This completes the proof. -/
  rwa [Int.zero_mul] at this","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44436,Int.natAbs_eq_natAbs_iff,theorem Int.natAbs_eq_natAbs_iff {a b : Int} : a.natAbs = b.natAbs ↔ a = b ∨ a = -b := by sorry,"Absolute Value Equality: \( |a| = |b| \leftrightarrow a = b \lor a = -b \) : For any integers \( a \) and \( b \), the absolute values of \( a \) and \( b \) as natural numbers are equal if and only if \( a \) is equal to \( b \) or \( a \) is equal to \(-b\). In other words, \( |a| = |b| \) if and only if \( a = b \) or \( a = -b \).","theorem Int.natAbs_eq_natAbs_iff {a b : Int} : a.natAbs = b.natAbs ↔ a = b ∨ a = -b := by
  constructor <;> intro h
  · cases Int.natAbs_eq a with
    | inl h₁ | inr h₁ =>
      cases Int.natAbs_eq b with
      | inl h₂ | inr h₂ => rw [h₁, h₂]; simp [h]
  · cases h with (subst a; try rfl)
    | inr h => rw [Int.natAbs_neg]","To prove the equivalence \( a.natAbs = b.natAbs \leftrightarrow a = b \lor a = -b \), we need to show both directions.

1. **(\(\rightarrow\)) Assume \( a.natAbs = b.natAbs \) and show \( a = b \lor a = -b \):**
- We consider the cases for the absolute value of \( a \):
- **Case 1:** \( a = \text{natAbs}(a) \)
- **Subcase 1.1:** \( b = \text{natAbs}(b) \)
- Substitute \( a \) and \( b \) with their absolute values: \( a = b \).
- **Subcase 1.2:** \( b = -\text{natAbs}(b) \)
- Substitute \( a \) and \( b \) with their absolute values: \( a = -b \).
- **Case 2:** \( a = -\text{natAbs}(a) \)
- **Subcase 2.1:** \( b = \text{natAbs}(b) \)
- Substitute \( a \) and \( b \) with their absolute values: \( a = -b \).
- **Subcase 2.2:** \( b = -\text{natAbs}(b) \)
- Substitute \( a \) and \( b \) with their absolute values: \( a = b \).

2. **(\(\leftarrow\)) Assume \( a = b \lor a = -b \) and show \( a.natAbs = b.natAbs \):**
- **Case 1:** \( a = b \)
- Substitute \( a \) with \( b \) in the goal \( a.natAbs = b.natAbs \): \( b.natAbs = b.natAbs \), which is trivially true.
- **Case 2:** \( a = -b \)
- Substitute \( a \) with \(-b\) in the goal \( a.natAbs = b.natAbs \): \((-b).natAbs = b.natAbs\).
- Using the property that the absolute value of a negative integer is the same as the absolute value of the integer, this simplifies to \( b.natAbs = b.natAbs \), which is trivially true.

Thus, we have shown both directions, and the theorem is proved. \(\blacksquare\)","theorem Int.natAbs_eq_natAbs_iff {a b : Int} : a.natAbs = b.natAbs ↔ a = b ∨ a = -b := by
/- To prove the equivalence \( a.natAbs = b.natAbs \leftrightarrow a = b \lor a = -b \), we need to show both directions. First, we assume \( a.natAbs = b.natAbs \) and show \( a = b \lor a = -b \). Second, we assume \( a = b \lor a = -b \) and show \( a.natAbs = b.natAbs \). -/
  constructor <;> intro h
/- We consider the cases for the absolute value of \( a \). Specifically, we use the fact that for any integer \( a \), \( a \) is either equal to its absolute value or the negative of its absolute value. This gives us two cases to consider: \( a = \text{natAbs}(a) \) or \( a = -\text{natAbs}(a) \). -/
  · cases Int.natAbs_eq a with
/- We handle the two cases separately:
1. If \( a = \text{natAbs}(a) \), we need to show \( a = b \lor a = -b \).
2. If \( a = -\text{natAbs}(a) \), we need to show \( a = b \lor a = -b \). -/
    | inl h₁ | inr h₁ =>
      cases Int.natAbs_eq b with
/- For the first case \( a = \text{natAbs}(a) \):
- If \( b = \text{natAbs}(b) \), we substitute \( a \) and \( b \) with their absolute values and simplify using the assumption \( a.natAbs = b.natAbs \). This gives us \( a = b \).
- If \( b = -\text{natAbs}(b) \), we substitute \( a \) and \( b \) with their absolute values and simplify using the assumption \( a.natAbs = b.natAbs \). This gives us \( a = -b \). -/
      | inl h₂ | inr h₂ => rw [h₁, h₂]; simp [h]
/- We consider the cases for the disjunction \( a = b \lor a = -b \):
- If \( a = b \), we substitute \( a \) with \( b \) in the goal \( a.natAbs = b.natAbs \), which simplifies to \( b.natAbs = b.natAbs \), which is trivially true.
- If \( a = -b \), we substitute \( a \) with \(-b\) in the goal \( a.natAbs = b.natAbs \), which simplifies to \((-b).natAbs = b.natAbs\). Using the property that the absolute value of a negative integer is the same as the absolute value of the integer, this is also trivially true. -/
  · cases h with (subst a; try rfl)
/- For the second case \( a = -\text{natAbs}(a) \):
- If \( b = \text{natAbs}(b) \), we substitute \( a \) and \( b \) with their absolute values and simplify using the assumption \( a.natAbs = b.natAbs \). This gives us \( a = -b \).
- If \( b = -\text{natAbs}(b) \), we substitute \( a \) and \( b \) with their absolute values and simplify using the assumption \( a.natAbs = b.natAbs \). This gives us \( a = b \). -/
/- For the case \( a = -b \), we use the property that the absolute value of a negative integer is the same as the absolute value of the integer, i.e., \(\text{natAbs}(-b) = \text{natAbs}(b)\). This simplifies the goal to \( b.natAbs = b.natAbs \), which is trivially true. -/
    | inr h => rw [Int.natAbs_neg]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44438,Int.natAbs_mul_self',theorem Int.natAbs_mul_self' (a : Int) : (natAbs a * natAbs a : Int) = a * a := by sorry,"Square of Absolute Value Equals Square of Integer: \( \text{natAbs}(a)^2 = a^2 \) : For any integer \( a \), the product of the canonical image of the absolute value of \( a \) in the natural numbers with itself is equal to the product of \( a \) with itself, i.e., \( \text{natAbs}(a) \times \text{natAbs}(a) = a \times a \).","theorem Int.natAbs_mul_self' (a : Int) : (natAbs a * natAbs a : Int) = a * a := by
  rw [← Int.ofNat_mul, natAbs_mul_self]","To prove that for any integer \( a \), \(\text{natAbs}(a) \times \text{natAbs}(a) = a \times a\), we start by using the property of the canonical map from natural numbers to integers. Specifically, the canonical map preserves multiplication, i.e., \(\uparrow(n \cdot m) = \uparrow n \cdot \uparrow m\). Applying this property, we can rewrite the left-hand side of the goal as follows:
\[
\uparrow a.\text{natAbs} \cdot \uparrow a.\text{natAbs} = \uparrow (a.\text{natAbs} \cdot a.\text{natAbs})
\]
Next, we use the theorem that the square of the absolute value of an integer is equal to the square of the integer itself, i.e., \(\uparrow (a.\text{natAbs} \cdot a.\text{natAbs}) = a \cdot a\). This simplifies our goal to:
\[
\uparrow (a.\text{natAbs} \cdot a.\text{natAbs}) = a \cdot a
\]
Since the left-hand side and the right-hand side are now identical, the goal reduces to:
\[
a \cdot a = a \cdot a
\]
This is trivially true by the properties of equality. Therefore, we have shown that \(\text{natAbs}(a) \times \text{natAbs}(a) = a \times a\), completing the proof. \(\blacksquare\)","theorem Int.natAbs_mul_self' (a : Int) : (natAbs a * natAbs a : Int) = a * a := by
/- First, we use the theorem that the canonical map from natural numbers to integers preserves multiplication, i.e., \(\uparrow(n \cdot m) = \uparrow n \cdot \uparrow m\), to rewrite the goal. This transforms the goal from \(\uparrow a.\text{natAbs} \cdot \uparrow a.\text{natAbs} = a \cdot a\) to \(\uparrow (a.\text{natAbs} \cdot a.\text{natAbs}) = a \cdot a\).

Next, we use the theorem that the square of the absolute value of an integer is equal to the square of the integer itself, i.e., \(\uparrow (a.\text{natAbs} \cdot a.\text{natAbs}) = a \cdot a\), to further simplify the goal. This reduces the goal to \(a \cdot a = a \cdot a\), which is trivially true by the properties of equality. -/
  rw [← Int.ofNat_mul, natAbs_mul_self]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44439,Int.mul_neg_of_neg_of_pos,theorem Int.mul_neg_of_neg_of_pos {a b : Int} (ha : a < 0) (hb : 0 < b) : a * b < 0 := by sorry,"Negative Product of Negative and Positive Integers: \(a \times b < 0\) if \(a < 0\) and \(0 < b\) : For any integers \(a\) and \(b\), if \(a < 0\) and \(0 < b\), then \(a \times b < 0\).","theorem Int.mul_neg_of_neg_of_pos {a b : Int} (ha : a < 0) (hb : 0 < b) : a * b < 0 := by
  have h : a * b < 0 * b := Int.mul_lt_mul_of_pos_right ha hb
  rwa [Int.zero_mul] at h","To prove that \( a \times b < 0 \) given \( a < 0 \) and \( 0 < b \), we proceed as follows:

1. **Construct a lemma \( h \):**
We construct a lemma \( h \) that states \( a \times b < 0 \times b \). This follows from the fact that if \( a < 0 \) and \( 0 < b \), then multiplying both sides of the inequality \( a < 0 \) by the positive integer \( b \) preserves the inequality, i.e., \( a \times b < 0 \times b \).

2. **Simplify the lemma \( h \):**
We use the property that \( 0 \times b = 0 \) to simplify the lemma \( h \). Since \( 0 \times b = 0 \), the lemma \( h \) becomes \( a \times b < 0 \). This is exactly the goal we need to prove.

Therefore, we have shown that \( a \times b < 0 \) if \( a < 0 \) and \( 0 < b \). This completes the proof. \(\blacksquare\)","theorem Int.mul_neg_of_neg_of_pos {a b : Int} (ha : a < 0) (hb : 0 < b) : a * b < 0 := by
/- First, we construct a lemma \( h \) that states \( a \times b < 0 \times b \). This follows from the fact that if \( a < 0 \) and \( 0 < b \), then multiplying both sides of the inequality \( a < 0 \) by the positive integer \( b \) preserves the inequality, i.e., \( a \times b < 0 \times b \). -/
  have h : a * b < 0 * b := Int.mul_lt_mul_of_pos_right ha hb
/- Next, we use the property that \( 0 \times b = 0 \) to simplify the lemma \( h \). Since \( 0 \times b = 0 \), the lemma \( h \) becomes \( a \times b < 0 \). This is exactly the goal we need to prove. -/
  rwa [Int.zero_mul] at h","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44441,Int.negSucc_eq',theorem Int.negSucc_eq' (m : Nat) : -[m+1] = -m - 1 := by sorry,"Negative Successor of a Natural Number in Integers: \(\text{Int.negSucc}(m) = -m - 1\) : For any natural number \( m \), the negative successor of \( m \) in the integers is equal to \(-m - 1\), i.e., \(\text{Int.negSucc}(m) = -m - 1\).","theorem Int.negSucc_eq' (m : Nat) : -[m+1] = -m - 1 := by
  simp only [negSucc_eq, Int.neg_add]; rfl","To prove that \(\text{Int.negSucc}(m) = -m - 1\) for any natural number \( m \), we start by using the definition of the negative successor and the property of negation in a commutative subtraction monoid.

1. By the definition of the negative successor, \(\text{Int.negSucc}(m)\) is defined as \(-[m + 1]\).
2. Using the property of negation in a commutative subtraction monoid, we know that \(-(a + b) = -a + -b\). Applying this property to \(-[m + 1]\), we get:
\[
-[m + 1] = -m + -1
\]
3. Simplifying the right-hand side, we have:
\[
-m + -1 = -m - 1
\]
4. Therefore, we have shown that:
\[
\text{Int.negSucc}(m) = -m - 1
\]

This completes the proof. \(\blacksquare\)","theorem Int.negSucc_eq' (m : Nat) : -[m+1] = -m - 1 := by
  simp only [negSucc_eq, Int.neg_add]; rfl","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44442,Int.eq_natAbs_iff_mul_eq_zero,theorem Int.eq_natAbs_iff_mul_eq_zero : natAbs a = n ↔ (a - n) * (a + n) = 0 := by sorry,"Absolute Value of Integer Equals Natural Number if and only if Product is Zero: \( |a| = n \leftrightarrow (a - n) \cdot (a + n) = 0 \) : For any integer \( a \) and any natural number \( n \), the absolute value of \( a \) as a natural number, denoted \( |a| \), is equal to \( n \) if and only if the product \((a - n) \cdot (a + n)\) is equal to 0, where \( n \) is interpreted as an integer via the canonical map from natural numbers to integers.","theorem Int.eq_natAbs_iff_mul_eq_zero : natAbs a = n ↔ (a - n) * (a + n) = 0 := by
  rw [natAbs_eq_iff, Int.mul_eq_zero, ← Int.sub_neg, Int.sub_eq_zero, Int.sub_eq_zero]","We start by using the equivalence that the absolute value of an integer \( a \) is equal to a natural number \( n \) if and only if \( a \) is equal to \( n \) or \( -n \). This can be written as:
\[ a.natAbs = n \leftrightarrow a = n \lor a = -n. \]

Next, we use the fact that the product of two integers is zero if and only if one of the factors is zero. This gives us:
\[ (a - n) \cdot (a + n) = 0 \leftrightarrow (a - n = 0) \lor (a + n = 0). \]

We then use the property that \( a - (-n) = a + n \) to rewrite the second condition:
\[ (a - n) \cdot (a + n) = 0 \leftrightarrow (a - n = 0) \lor (a - (-n) = 0). \]

Finally, we use the property that \( a - b = 0 \) if and only if \( a = b \) to simplify the conditions:
\[ (a - n = 0) \lor (a - (-n) = 0) \leftrightarrow a = n \lor a = -n. \]

Thus, we have shown that:
\[ a.natAbs = n \leftrightarrow (a - n) \cdot (a + n) = 0. \]

This completes the proof. \(\blacksquare\)","theorem Int.eq_natAbs_iff_mul_eq_zero : natAbs a = n ↔ (a - n) * (a + n) = 0 := by
/- First, we use the equivalence that the absolute value of an integer \( a \) is equal to a natural number \( n \) if and only if \( a \) is equal to \( n \) or \( -n \). This transforms our goal into showing that \( a = n \) or \( a = -n \) if and only if the product \((a - n) \cdot (a + n)\) is equal to zero. Next, we use the fact that the product of two integers is zero if and only if one of the factors is zero. This further simplifies our goal to showing that \( a = n \) or \( a = -n \) if and only if \( a - n = 0 \) or \( a + n = 0 \). We then use the property that \( a - (-n) = a + n \) to rewrite the second condition. Finally, we use the property that \( a - b = 0 \) if and only if \( a = b \) to simplify the conditions to \( a = n \) or \( a = -n \). This completes the proof. -/
  rw [natAbs_eq_iff, Int.mul_eq_zero, ← Int.sub_neg, Int.sub_eq_zero, Int.sub_eq_zero]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44446,Int.sign_neg,theorem Int.sign_neg (z : Int) : Int.sign (-z) = -Int.sign z := by sorry,"Sign of Negated Integer: \(\text{sign}(-z) = -\text{sign}(z)\) : For any integer \( z \), the sign of \(-z\) is equal to the negation of the sign of \( z \), i.e., \(\text{sign}(-z) = -\text{sign}(z)\).","theorem Int.sign_neg (z : Int) : Int.sign (-z) = -Int.sign z := by
  match z with | 0 | succ _ | -[_+1] => rfl","We consider the integer \( z \) in three cases:

1. **Case \( z = 0 \):**
- We have \(\text{sign}(-0) = \text{sign}(0)\).
- Since \(\text{sign}(0) = 0\), the equality \(\text{sign}(-0) = -\text{sign}(0)\) holds trivially.

2. **Case \( z = n + 1 \) where \( n \) is a natural number:**
- We have \(\text{sign}(-(n + 1)) = -\text{sign}(n + 1)\).
- Since \(\text{sign}(n + 1) = 1\) and \(\text{sign}(-(n + 1)) = -1\), the equality \(\text{sign}(-(n + 1)) = -\text{sign}(n + 1)\) holds trivially.

3. **Case \( z = -(m + 1) \) where \( m \) is a natural number:**
- We have \(\text{sign}(-(-(m + 1))) = -\text{sign}(-(m + 1))\).
- Since \(\text{sign}(-(m + 1)) = -1\) and \(\text{sign}(-(-(m + 1))) = 1\), the equality \(\text{sign}(-(-(m + 1))) = -\text{sign}(-(m + 1))\) holds trivially.

In all cases, the equality \(\text{sign}(-z) = -\text{sign}(z)\) holds. Therefore, the theorem is proved.","theorem Int.sign_neg (z : Int) : Int.sign (-z) = -Int.sign z := by
/- We consider the integer \( z \) in three cases: \( z = 0 \), \( z = n + 1 \) for some natural number \( n \), and \( z = -(m + 1) \) for some natural number \( m \). In each case, we show that \(\text{sign}(-z) = -\text{sign}(z)\) holds by the reflexive property. -/
/- For the case \( z = 0 \), we have \(\text{sign}(-0) = \text{sign}(0)\). Since \(\text{sign}(0) = 0\), the equality \(\text{sign}(-0) = -\text{sign}(0)\) holds trivially. -/
/- For the case \( z = n + 1 \) where \( n \) is a natural number, we have \(\text{sign}(-(n + 1)) = -\text{sign}(n + 1)\). Since \(\text{sign}(n + 1) = 1\) and \(\text{sign}(-(n + 1)) = -1\), the equality \(\text{sign}(-(n + 1)) = -\text{sign}(n + 1)\) holds trivially. -/
/- For the case \( z = -(m + 1) \) where \( m \) is a natural number, we have \(\text{sign}(-(-(m + 1))) = -\text{sign}(-(m + 1))\). Since \(\text{sign}(-(m + 1)) = -1\) and \(\text{sign}(-(-(m + 1))) = 1\), the equality \(\text{sign}(-(-(m + 1))) = -\text{sign}(-(m + 1))\) holds trivially. -/
  match z with | 0 | succ _ | -[_+1] => rfl","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44448,Int.sign_nonneg,theorem Int.sign_nonneg : 0 ≤ sign x ↔ 0 ≤ x := by sorry,"Nonnegative Sign of Integer if and only if Integer is Nonnegative: \( 0 \leq \text{sign}(x) \leftrightarrow 0 \leq x \) : For any integer \( x \), the sign of \( x \) is nonnegative if and only if \( x \) itself is nonnegative, i.e., \( 0 \leq \text{sign}(x) \leftrightarrow 0 \leq x \).","theorem Int.sign_nonneg : 0 ≤ sign x ↔ 0 ≤ x := by
  match x with
  | 0 => rfl
  | .ofNat (_ + 1) =>
    simp (config := { decide := true }) only [sign, true_iff]
    exact Int.le_add_one (ofNat_nonneg _)
  | .negSucc _ => simp (config := { decide := true }) [sign]","We consider three cases for the integer \( x \):

1. **Case 1: \( x \) is a negative integer.**
- If \( x \) is a negative integer, then \( x = - (n + 1) \) for some natural number \( n \). The sign of \( x \) is \(-1\). Therefore, \( 0 \leq -1 \) is false, and \( 0 \leq x \) is also false because \( x \) is negative. Hence, \( 0 \leq \text{sign}(x) \leftrightarrow 0 \leq x \) is true in this case.

2. **Case 2: \( x = 0 \).**
- The sign of \( 0 \) is \( 0 \). Therefore, \( 0 \leq 0 \) is true, and the goal \( 0 \leq 0 \leftrightarrow 0 \leq 0 \) is trivially true by reflexivity.

3. **Case 3: \( x \) is a positive integer.**
- If \( x \) is a positive integer, then \( x = n + 1 \) for some natural number \( n \). The sign of \( x \) is \( 1 \). Therefore, \( 0 \leq 1 \) is true. We need to show that \( 0 \leq n + 1 \) is true. Since \( n \) is a natural number, \( 0 \leq n \) is true. By the property that adding one to a non-negative integer preserves the non-strict inequality, \( 0 \leq n + 1 \) is true. Hence, \( 0 \leq \text{sign}(x) \leftrightarrow 0 \leq x \) is true in this case.

Since all cases are covered, the theorem is proved. \(\blacksquare\)","theorem Int.sign_nonneg : 0 ≤ sign x ↔ 0 ≤ x := by
  match x with
/- For the case where \( x = 0 \), the sign of \( 0 \) is \( 0 \). Therefore, \( 0 \leq 0 \) is true, and the goal \( 0 \leq 0 \leftrightarrow 0 \leq 0 \) is trivially true by reflexivity. -/
  | 0 => rfl
/- For the case where \( x \) is a positive integer, we consider \( x = n + 1 \) for some natural number \( n \). We need to show that \( 0 \leq \text{sign}(n + 1) \leftrightarrow 0 \leq n + 1 \). -/
  | .ofNat (_ + 1) =>
/- Using the definition of the sign function, we know that the sign of a positive integer \( n + 1 \) is \( 1 \). Therefore, \( 0 \leq 1 \) is true. The goal simplifies to \( 0 \leq 1 \leftrightarrow 0 \leq n + 1 \). Since \( 0 \leq 1 \) is true, the goal reduces to showing that \( 0 \leq n + 1 \) is true. -/
    simp (config := { decide := true }) only [sign, true_iff]
/- We use the fact that for any natural number \( n \), \( 0 \leq n \) (since natural numbers are non-negative). Therefore, \( 0 \leq n + 1 \) is true by the property that adding one to a non-negative integer preserves the non-strict inequality. This completes the proof for the case where \( x \) is a positive integer. -/
    exact Int.le_add_one (ofNat_nonneg _)
/- For the case where \( x \) is a negative integer, we use the definition of the sign function and the fact that the sign of a negative integer is \(-1\). This simplifies the goal to \( 0 \leq -1 \leftrightarrow 0 \leq x \). Since \( 0 \leq -1 \) is false, the goal reduces to showing that \( 0 \leq x \) is also false, which is true because \( x \) is negative. -/
  | .negSucc _ => simp (config := { decide := true }) [sign]","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
44455,Int.natAbs_sub_le,theorem Int.natAbs_sub_le (a b : Int) : natAbs (a - b) ≤ natAbs a + natAbs b := by sorry,"Triangle Inequality for Integer Subtraction: \((a - b).| \leq |a| + |b|\) : For any integers \(a\) and \(b\), the absolute value of the difference \(a - b\) is less than or equal to the sum of the absolute values of \(a\) and \(b\), i.e., \((a - b).| \leq |a| + |b|\).","theorem Int.natAbs_sub_le (a b : Int) : natAbs (a - b) ≤ natAbs a + natAbs b := by
  rw [← Int.natAbs_neg b]; apply natAbs_add_le","To prove the inequality \((a - b).| \leq |a| + |b|\), we start by using the property that the absolute value of the negation of an integer is equal to the absolute value of the integer itself. Specifically, \(\text{natAbs}(-b) = \text{natAbs}(b)\). This allows us to rewrite the goal as:
\[
(a - b).natAbs = (a + -b).natAbs
\]
Thus, the goal becomes:
\[
(a + -b).natAbs \leq a.natAbs + (-b).natAbs
\]
Next, we apply the triangle inequality for absolute values, which states that for any integers \(a\) and \(b\):
\[
\text{natAbs}(a + b) \leq \text{natAbs}(a) + \text{natAbs}(b)
\]
By substituting \(b\) with \(-b\), we get:
\[
\text{natAbs}(a + -b) \leq \text{natAbs}(a) + \text{natAbs}(-b)
\]
Since \(\text{natAbs}(-b) = \text{natAbs}(b)\), this simplifies to:
\[
\text{natAbs}(a + -b) \leq \text{natAbs}(a) + \text{natAbs}(b)
\]
Therefore, we have:
\[
(a - b).natAbs \leq a.natAbs + b.natAbs
\]
This completes the proof.","theorem Int.natAbs_sub_le (a b : Int) : natAbs (a - b) ≤ natAbs a + natAbs b := by
/- First, we use the property that the absolute value of the negation of an integer is equal to the absolute value of the integer itself, i.e., \(\text{natAbs}(-b) = \text{natAbs}(b)\). This allows us to rewrite the goal \((a - b).natAbs \leq a.natAbs + b.natAbs\) as \((a + -b).natAbs \leq a.natAbs + (-b).natAbs\). Then, we apply the triangle inequality for absolute values, which states that for any integers \(a\) and \(b\), \(\text{natAbs}(a + b) \leq \text{natAbs}(a) + \text{natAbs}(b)\). This directly proves the goal \((a + -b).natAbs \leq a.natAbs + (-b).natAbs\). -/
  rw [← Int.natAbs_neg b]; apply natAbs_add_le","import Init.Data.Int.Lemmas
import Init.ByCases
import Init.Data.Int.Order

open Int
open Nat
"
